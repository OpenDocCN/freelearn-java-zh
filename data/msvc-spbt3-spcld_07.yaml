- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Developing Reactive Microservices
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发反应式微服务
- en: In this chapter, we will learn how to develop reactive microservices, that is,
    how to develop non-blocking synchronous REST APIs and asynchronous event-driven
    services. We will also learn how to choose between these two alternatives. Finally,
    we will see how to create and run manual and automated tests of a reactive microservice
    landscape.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何开发反应式微服务，即如何开发非阻塞同步REST API和异步事件驱动服务。我们还将学习如何在这两种选择之间进行选择。最后，我们将看到如何创建和运行反应式微服务景观的手动和自动化测试。
- en: As already described in *Chapter 1*, *Introduction to Microservices*, the foundation
    for reactive systems is that they are message-driven—they use asynchronous communication.
    This enables them to be elastic, in other words, scalable and resilient, meaning
    that they are tolerant of failures. Elasticity and resilience together enable
    a reactive system to be responsive.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如在第1章*微服务简介*中已描述，反应式系统的基石是它们是消息驱动的——它们使用异步通信。这使得它们具有弹性，换句话说，可扩展性和弹性，意味着它们对失败具有容忍度。弹性和弹性共同使反应式系统能够做出响应。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Choosing between non-blocking synchronous APIs and event-driven asynchronous
    services
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在非阻塞同步API和事件驱动的异步服务之间进行选择
- en: Developing non-blocking synchronous REST APIs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发非阻塞同步REST API
- en: Developing event-driven asynchronous services
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发事件驱动的异步服务
- en: Running manual tests of the reactive microservice landscape
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行反应式微服务景观的手动测试
- en: Running automated tests of the reactive microservice landscape
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行反应式微服务景观的自动化测试
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For instructions on how to install the tools used in this book and how to access
    the source code for this book, see:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何安装本书中使用的工具以及如何访问本书源代码的说明，请参阅：
- en: '*Chapter 21*, *Installation Instructions for macOS*'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第21章*，*macOS的安装说明*'
- en: '*Chapter 22*, *Installation Instructions for Microsoft Windows with WSL 2 and
    Ubuntu*'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第22章*，*使用WSL 2和Ubuntu的Microsoft Windows安装说明*'
- en: The code examples in this chapter all come from the source code in `$BOOK_HOME/Chapter07`.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的代码示例均来自 `$BOOK_HOME/Chapter07` 的源代码。
- en: If you want to view the changes applied to the source code in this chapter,
    that is, see what it takes to make the microservices reactive, you can compare
    it with the source code for *Chapter 6*, *Adding Persistence*. You can use your
    favorite `diff` tool and compare the two folders, that is, `$BOOK_HOME/Chapter06`
    and `$BOOK_HOME/Chapter07`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想查看本章源代码中应用的变化，即查看使微服务反应式所需的内容，你可以将其与第6章*添加持久性*的源代码进行比较。你可以使用你喜欢的`diff`工具比较这两个文件夹，即
    `$BOOK_HOME/Chapter06` 和 `$BOOK_HOME/Chapter07`。
- en: Choosing between non-blocking synchronous APIs and event-driven asynchronous
    services
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在非阻塞同步API和事件驱动的异步服务之间进行选择
- en: When developing reactive microservices, it is not always obvious when to use
    non-blocking synchronous APIs and when to use event-driven asynchronous services.
    In general, to make a microservice robust and scalable, it is important to make
    it as autonomous as possible, for example, by minimizing its runtime dependencies.
    This is also known as **loose coupling**. Therefore, the asynchronous message
    passing of events is preferable over synchronous APIs. This is because the microservice
    will only depend on access to the messaging system at runtime, instead of being
    dependent on synchronous access to a number of other microservices.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发反应式微服务时，并不总是明显何时使用非阻塞同步API，何时使用事件驱动的异步服务。一般来说，为了使微服务健壮和可扩展，重要的是尽可能使其具有自主性，例如，通过最小化其运行时依赖。这也被称为**松耦合**。因此，事件的消息异步传递比同步API更可取。这是因为微服务将只依赖于运行时对消息系统的访问，而不是依赖于对多个其他微服务的同步访问。
- en: 'There are, however, a number of cases where synchronous APIs could be favorable.
    For example:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一些情况下同步API可能是首选的。例如：
- en: For read operations where an end user is waiting for a response
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于需要等待响应的读取操作
- en: Where the client platforms are more suitable for consuming synchronous APIs,
    for example, mobile apps or SPA web applications
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当客户端平台更适合消费同步API时，例如，移动应用或SPA网页应用
- en: Where the clients will connect to the service from other organizations – where
    it might be hard to agree on a common messaging system to use across organizations
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当客户端将从其他组织连接到服务时——在这些组织中可能难以就跨组织使用的一个通用消息系统达成一致
- en: 'For the system landscape in this book, we will use the following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本书中的系统景观，我们将使用以下内容：
- en: The create, read, and delete services exposed by the product composite microservice
    will be based on non-blocking synchronous APIs. The composite microservice is
    assumed to have clients on both web and mobile platforms, as well as clients coming
    from other organizations rather than the ones that operate the system landscape.
    Therefore, synchronous APIs seem like a natural match.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品复合微服务公开的创建、读取和删除服务将基于非阻塞同步API。复合微服务假定在Web和移动平台以及来自其他组织的客户端上都有客户端，而不是操作系统景观的客户端。因此，同步API看起来是一个自然的选择。
- en: The read services provided by the core microservices will also be developed
    as non-blocking synchronous APIs since there is an end user waiting for their
    responses.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心微服务提供的读取服务也将被开发为非阻塞同步API，因为最终用户正在等待它们的响应。
- en: The create and delete services provided by the core microservices will be developed
    as event-driven asynchronous services, meaning that they will listen for create
    and delete events on topics dedicated to each microservice.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心微服务提供的创建和删除服务将被开发为事件驱动的异步服务，这意味着它们将监听每个微服务专属主题上的创建和删除事件。
- en: The synchronous APIs provided by the composite microservices to create and delete
    aggregated product information will publish create and delete events on these
    topics. If the publish operation succeeds, it will return with a 202 (Accepted)
    response; otherwise, an error response will be returned. The 202 response differs
    from a normal 200 (OK) response – it indicates that the request has been accepted,
    but not fully processed. Instead, the processing will be completed asynchronously
    and independently of the 202 response.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复合微服务提供的同步API用于创建和删除聚合产品信息，将在这些主题上发布创建和删除事件。如果发布操作成功，它将返回202（已接受）响应；否则，将返回错误响应。202响应与正常的200（OK）响应不同——它表示请求已被接受，但尚未完全处理。相反，处理将在异步和独立于202响应的情况下完成。
- en: 'This is illustrated by the following diagram:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如下图所示：
- en: '![Graphical user interface, diagram  Description automatically generated](img/B19825_07_01.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，图描述自动生成](img/B19825_07_01.png)'
- en: 'Figure 7.1: The microservice landscape'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1：微服务景观
- en: First, let’s learn how we can develop non-blocking synchronous REST APIs, and
    thereafter, we will look at how to develop event-driven asynchronous services.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们学习如何开发非阻塞同步REST API，然后我们将探讨如何开发事件驱动的异步服务。
- en: Developing non-blocking synchronous REST APIs
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发非阻塞同步REST API
- en: 'In this section, we will learn how to develop non-blocking versions of the
    read APIs. The composite service will make reactive, that is, non-blocking, calls
    in parallel to the three core services. When the composite service has received
    responses from all of the core services, it will create a composite response and
    send it back to the caller. This is illustrated in the following diagram:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何开发读取API的非阻塞版本。复合服务将并行地对三个核心服务进行反应性（即非阻塞）调用。当复合服务从所有核心服务收到响应后，它将创建一个组合响应并将其发送回调用者。如下图所示：
- en: '![Diagram  Description automatically generated](img/B19825_07_02.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图描述自动生成](img/B19825_07_02.png)'
- en: 'Figure 7.2: The getCompositeProduct part of the landscape'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2：景观中的getCompositeProduct部分
- en: 'In this section, we will cover the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将涵盖以下内容：
- en: An introduction to Project Reactor
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Project Reactor简介
- en: Non-blocking persistence using Spring Data for MongoDB
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spring Data for MongoDB的非阻塞持久性
- en: Non-blocking REST APIs in the core services, including how to handle blocking
    code for the JPA-based persistence layer
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心服务中的非阻塞REST API，包括如何处理基于JPA的持久层中的阻塞代码
- en: Non-blocking REST APIs in the composite service
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复合服务中的非阻塞REST API
- en: An introduction to Project Reactor
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Project Reactor简介
- en: As we mentioned in the *Spring WebFlux* section in *Chapter 2*, *Introduction
    to Spring Boot*, the reactive support in Spring 5 is based on **Project Reactor**
    ([https://projectreactor.io](https://projectreactor.io)). Project Reactor is based
    on the *Reactive Streams specification* ([http://www.reactive-streams.org](http://www.reactive-streams.org)),
    a standard for building reactive applications. Project Reactor is fundamental
    – it is what Spring WebFlux, Spring WebClient, and Spring Data rely on to provide
    their reactive and non-blocking features.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在 *第 2 章* 中提到的 *Spring WebFlux* 部分，*Spring Boot 简介*，Spring 5 的响应式支持基于 **Project
    Reactor** ([https://projectreactor.io](https://projectreactor.io))。Project Reactor
    基于 *Reactive Streams 规范* ([http://www.reactive-streams.org](http://www.reactive-streams.org))，这是构建响应式应用程序的标准。Project
    Reactor 是基础的——它是 Spring WebFlux、Spring WebClient 和 Spring Data 依赖以提供其响应式和非阻塞功能的基础。
- en: 'The programming model is based on processing streams of data, and the core
    data types in Project Reactor are **Flux** and **Mono**. A `Flux` object is used
    to process a stream of *0...n* elements and a `Mono` object is used to process
    a stream that either is empty or returns at most one element. We will see numerous
    examples of their usage in this chapter. As a short introduction, let’s look at
    the following test:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 编程模型基于处理数据流，Project Reactor 的核心数据类型是 **Flux** 和 **Mono**。一个 `Flux` 对象用于处理 *0...n*
    元素的流，一个 `Mono` 对象用于处理要么为空要么最多返回一个元素的流。我们将在本章中看到它们使用的许多示例。作为一个简短的介绍，让我们看看以下测试：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here is an explanation of the preceding source code:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是对前面源代码的解释：
- en: We initiate the stream with the integers `1`, `2`, `3`, and `4` using the static
    helper method `Flux.just()`.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用静态辅助方法 `Flux.just()` 以整数 `1`、`2`、`3` 和 `4` 初始化流。
- en: Next, we `filter` out the odd numbers – we only allow even numbers to proceed
    through the stream. In this test, these are `2` and `4`.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们 `filter` 出奇数——我们只允许偶数通过流。在这个测试中，这些是 `2` 和 `4`。
- en: Next, we transform (or `map`) the values in the stream by multiplying them by
    `2`, so they become `4` and `8`.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将流中的值通过乘以 `2` 进行转换（或 `map`），因此它们变为 `4` 和 `8`。
- en: Then, we `log` the data that flows through the stream after the `map` operation.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在 `map` 操作之后 `log` 流中流动的数据。
- en: We use the `collectList` method to collect all items from the stream into a
    `List`, emitted once the stream completes.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 `collectList` 方法将流中的所有项目收集到一个 `List` 中，一旦流完成，就会发出一次。
- en: So far, we have only declared the processing of a stream. To actually get the
    stream processed, we need someone to subscribe to it. The final call to the `block`
    method will register a subscriber that waits for the processing to complete.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 到目前为止，我们只声明了流的处理。要实际获取处理的流，我们需要有人订阅它。对 `block` 方法的最终调用将注册一个等待处理完成的订阅者。
- en: The resulting list is saved in a member variable named `list`.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果列表被保存在名为 `list` 的成员变量中。
- en: We can now wrap up the test by using the `assertThat` method to assert that
    `list` after the processing of the stream contains the expected result – the integers
    `4` and `8`.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以使用 `assertThat` 方法来总结测试，断言流处理后的 `list` 包含预期的结果——整数 `4` 和 `8`。
- en: 'The log output will look like the following:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 日志输出将如下所示：
- en: '![Text  Description automatically generated](img/B19825_07_03.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![文本描述自动生成](img/B19825_07_03.png)'
- en: 'Figure 7.3: Log output for the code above'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3：上述代码的日志输出
- en: 'From the preceding log output, we can see that:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的日志输出中，我们可以看到：
- en: The processing of the stream is started by a subscriber that subscribes to the
    stream and requests its content.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 流的处理由一个订阅流并请求其内容的订阅者启动。
- en: Next, the integers `4` and `8` pass through the `log` operation.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，整数 `4` 和 `8` 通过 `log` 操作。
- en: The processing concludes with a call to the `onComplete` method on the subscriber,
    notifying it that the stream has come to an end.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理通过在订阅者上调用 `onComplete` 方法结束，通知它流已结束。
- en: For the full source code, see the `ReactorTests` test class in the `util` project.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看完整的源代码，请参阅 `util` 项目中的 `ReactorTests` 测试类。
- en: Normally, we don’t initiate the processing of the stream. Instead, we only define
    how it will be processed, and it will be the responsibility of an infrastructure
    component to initiate the processing. For example, Spring WebFlux will do this
    as a response to an incoming HTTP request. An exception to this rule of thumb
    is the case where blocking code needs a response from a reactive stream. In these
    cases, the blocking code can call the `block()` method on the `Flux` or `Mono`
    object to get the response in a blocking way.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们不启动流处理。相反，我们只定义它将如何被处理，并且将由基础设施组件负责启动处理。例如，Spring WebFlux 将作为对传入 HTTP 请求的响应来执行此操作。这个规则的一个例外是，当阻塞代码需要从反应式流中获取响应时。在这些情况下，阻塞代码可以在
    `Flux` 或 `Mono` 对象上调用 `block()` 方法以阻塞方式获取响应。
- en: Non-blocking persistence using Spring Data for MongoDB
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Spring Data 为 MongoDB 实现非阻塞持久化
- en: 'Making the MongoDB-based repositories for the `product` and `recommendation`
    services reactive is very simple:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使 `product` 和 `recommendation` 服务的 MongoDB 基础仓库反应式化非常简单：
- en: Change the base class for the repositories to `ReactiveCrudRepository`
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将仓库的基类更改为 `ReactiveCrudRepository`
- en: Change the custom finder methods to return either a `Mono` or a `Flux` object
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将自定义查找方法更改为返回 `Mono` 或 `Flux` 对象
- en: '`ProductRepository` and `RecommendationRepository` look like the following
    after the change:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 修改后的 `ProductRepository` 和 `RecommendationRepository` 如下所示：
- en: '[PRE1]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: No changes are applied to the persistence code for the `review` service; it
    will remain blocking using the JPA repository. See the following section, *Dealing
    with blocking code*, for how to handle the blocking code in the persistence layer
    of the `review` service.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 `review` 服务的持久化代码没有应用任何更改；它将继续使用 JPA 仓库进行阻塞。有关如何在 `review` 服务的持久化层中处理阻塞代码的详细信息，请参阅以下部分，*处理阻塞代码*。
- en: 'For the full source code, take a look at the following classes:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整源代码，请查看以下类：
- en: '`ProductRepository` in the `product` project'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ProductRepository` 在 `product` 项目中'
- en: '`RecommendationRepository` in the `recommendation` project'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RecommendationRepository` 在 `recommendation` 项目中'
- en: Changes in the test code
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试代码的更改
- en: When it comes to testing the persistence layer, we have to make some changes.
    Since our persistence methods now return a `Mono` or `Flux` object, the test methods
    have to wait for the response to be available in the returned reactive objects.
    The test methods can either use an explicit call to the `block()` method on the
    `Mono`/`Flux` object to wait until a response is available, or they can use the
    `StepVerifier` helper class from Project Reactor to declare a verifiable sequence
    of asynchronous events.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到测试持久化层时，我们必须进行一些更改。由于我们的持久化方法现在返回一个 `Mono` 或 `Flux` 对象，测试方法必须等待返回的反应式对象中响应可用。测试方法可以使用对
    `Mono`/`Flux` 对象上的 `block()` 方法的显式调用等待响应可用，或者它们可以使用来自 Project Reactor 的 `StepVerifier`
    辅助类声明一个可验证的异步事件序列。
- en: 'Let’s see how we can change the following test code to work for the reactive
    version of the repository:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何将以下测试代码更改为适用于仓库的反应式版本：
- en: '[PRE2]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can use the `block()` method on the `Mono` object returned by the `repository.findById()`
    method and keep the imperative programming style, as shown here:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 `repository.findById()` 方法返回的 `Mono` 对象上使用 `block()` 方法，并保持命令式编程风格，如下所示：
- en: '[PRE3]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Alternatively, we can use the `StepVerifier` class to set up a sequence of
    processing steps that both executes the repository find operation and also verifies
    the result. The sequence is initialized by the final call to the `verifyComplete()`
    method like this:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以使用 `StepVerifier` 类来设置一系列处理步骤，这些步骤既执行仓库查找操作，也验证结果。序列通过调用 `verifyComplete()`
    方法初始化，如下所示：
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: For examples of tests that use the `StepVerifier` class, see the `PersistenceTests`
    test class in the `product` project.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用 `StepVerifier` 类的测试示例，请参阅 `product` 项目的 `PersistenceTests` 测试类。
- en: For corresponding examples of tests that use the `block()` method, see the `PersistenceTests`
    test class in the `recommendation` project.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用 `block()` 方法的测试的相应示例，请参阅 `recommendation` 项目的 `PersistenceTests` 测试类。
- en: Non-blocking REST APIs in the core services
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 核心服务中的非阻塞 REST API
- en: 'With a non-blocking persistence layer in place, it’s time to make the APIs
    in the core services non-blocking as well. We need to make the following changes:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在非阻塞持久化层就绪后，是时候使核心服务的 API 也非阻塞了。我们需要进行以下更改：
- en: Change the APIs so that they only return reactive data types
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改 API 以使其仅返回反应式数据类型
- en: Change the service implementations so they don’t contain any blocking code
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改服务实现，使其不包含任何阻塞代码
- en: Change our tests so that they can test the reactive services
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改我们的测试，以便它们可以测试反应式服务
- en: Deal with blocking code – isolate the code that still needs to be blocking from
    the non-blocking code
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理阻塞代码 - 将仍然需要阻塞的代码与非阻塞代码隔离
- en: Changes in the APIs
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: API的更改
- en: To make the APIs of the core services reactive, we need to update their methods
    so that they return either a `Mono` or `Flux` object.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使核心服务的API反应式，我们需要更新它们的方法，使它们返回`Mono`或`Flux`对象。
- en: 'For example, `getProduct()` in the `product` service now returns `Mono<Product>`
    instead of a `Product` object:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`product`服务中的`getProduct()`现在返回`Mono<Product>`而不是`Product`对象：
- en: '[PRE5]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'For the full source code, take a look at the following `core` interfaces in
    the `api` project:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请查看`api`项目中的以下`core`接口：
- en: '`ProductService`'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ProductService`'
- en: '`RecommendationService`'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RecommendationService`'
- en: '`ReviewService`'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ReviewService`'
- en: Changes in the service implementations
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务实现中的更改
- en: 'For the implementations of the services in the `product` and `recommendation`
    projects, which use a reactive persistence layer, we can use the fluent API in
    Project Reactor. For example, the implementation of the `getProduct()` method
    looks like the following code:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`product`和`recommendation`项目中使用反应式持久化层的服务的实现，我们可以使用Project Reactor的流畅API。例如，`getProduct()`方法的实现如下所示：
- en: '[PRE6]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let’s examine what the code does:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看代码做了什么：
- en: The method will return a `Mono` object; the processing is only declared here.
    The processing is triggered by the web framework, Spring WebFlux, subscribing
    to the `Mono` object once it receives a request to this service!
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此方法将返回一个`Mono`对象；处理在这里仅声明。处理由接收此服务请求的Web框架Spring WebFlux在订阅`Mono`对象时触发！
- en: A product will be retrieved using its `productId` from the underlying database
    using the `findByProductId()` method in the persistence repository.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将使用持久化存储库中的`findByProductId()`方法从底层数据库中通过`productId`检索产品。
- en: If no product is found for the given `productId`, a `NotFoundException` will
    be thrown.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果对于给定的`productId`没有找到产品，将抛出`NotFoundException`。
- en: The `log` method will produce log output.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`log`方法将生成日志输出。'
- en: The `mapper.entityToApi()` method will be called to transform the returned entity
    from the persistence layer into an API model object.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将调用`mapper.entityToApi()`方法将持久化层返回的实体转换为API模型对象。
- en: The final `map` method will use a helper method, `setServiceAddress()`, to set
    the DNS name and IP address of the microservices that processed the request in
    the `serviceAddress` field of the model object.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终的`map`方法将使用辅助方法`setServiceAddress()`来设置处理请求的微服务的DNS名称和IP地址，并将其存储在模型对象的`serviceAddress`字段中。
- en: 'Some example log output for successful processing is as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 成功处理的一些示例日志输出如下：
- en: '![Text  Description automatically generated](img/B19825_07_04.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![文本描述自动生成](img/B19825_07_04.png)'
- en: 'Figure 7.4: Log output when processing is successful'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4：处理成功时的日志输出
- en: 'The following is an example log output of a failed processing (throwing a `NotFoundException`):'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个失败处理（抛出`NotFoundException`）的示例日志输出：
- en: '![Text  Description automatically generated](img/B19825_07_05.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![文本描述自动生成](img/B19825_07_05.png)'
- en: 'Figure 7.5: Log output when processing fails'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5：处理失败时的日志输出
- en: 'For the full source code, see the following classes:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请查看以下类：
- en: '`ProductServiceImpl` in the `product` project'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`product`项目中的`ProductServiceImpl`'
- en: '`RecommendationServiceImpl` in the `recommendation` project'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recommendation`项目中的`RecommendationServiceImpl`'
- en: Changes in the test code
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试代码的更改
- en: The test code for service implementations has been changed in the same way as
    the tests for the persistence layer we described previously. To handle the asynchronous
    behavior of the reactive return types, `Mono` and `Flux`, the tests use a mix
    of calling the `block()` method and using the `StepVerifier` helper class.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 服务实现的测试代码已经按照我们之前描述的持久化层测试的方式进行了更改。为了处理反应式返回类型`Mono`和`Flux`的异步行为，测试使用了调用`block()`方法和使用`StepVerifier`辅助类的方法组合。
- en: 'For the full source code, see the following test classes:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请查看以下测试类：
- en: '`ProductServiceApplicationTests` in the `product` project'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`product`项目中的`ProductServiceApplicationTests`'
- en: '`RecommendationServiceApplicationTests` in the `recommendation` project'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recommendation`项目中的`RecommendationServiceApplicationTests`'
- en: Dealing with blocking code
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理阻塞代码
- en: In the case of the `review` service, which uses JPA to access its data in a
    relational database, we don’t have support for a non-blocking programming model.
    Instead, we can run the blocking code using a `Scheduler`, which is capable of
    running the blocking code on a thread from a dedicated thread pool with a limited
    number of threads. Using a thread pool for the blocking code avoids draining the
    available threads in the microservice and avoids affecting concurrent non-blocking
    processing in the microservice, if there is any.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在`review`服务的情况下，该服务使用JPA从关系型数据库中访问其数据，我们并没有支持非阻塞编程模型。相反，我们可以使用`Scheduler`来运行阻塞代码，这个`Scheduler`能够在一个具有有限线程数的专用线程池上运行阻塞代码。使用线程池来运行阻塞代码可以避免耗尽微服务中的可用线程，并且如果有的话，还可以避免影响微服务中的并发非阻塞处理。
- en: 'Let’s see how this can be set up in the following steps:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下步骤如何设置：
- en: 'First, we configure a scheduler bean and its thread pool in the main class
    `ReviewServiceApplication`, as follows:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们在主类`ReviewServiceApplication`中配置一个调度器bean及其线程池，如下所示：
- en: '[PRE7]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'From the preceding code, we can see that the scheduler bean is named `jdbcScheduler`
    and that we can configure its thread pool using the following properties:'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从前面的代码中，我们可以看到调度器bean的名称是`jdbcScheduler`，并且我们可以使用以下属性来配置其线程池：
- en: '`app.threadPoolSize`, specifying the max number of threads in the pool; defaults
    to `10`'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`app.threadPoolSize`，指定池中线程的最大数量；默认为`10`'
- en: '`app.taskQueueSize`, specifying the max number of tasks that are allowed to
    be placed in a queue waiting for available threads; defaults to `100`'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`app.taskQueueSize`，指定允许放置在队列中等待可用线程的最大任务数；默认为`100`'
- en: 'Next, we inject the scheduler named `jdbcScheduler` into the `review` service
    implementation class, as shown here:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将名为`jdbcScheduler`的调度器注入到`review`服务实现类中，如下所示：
- en: '[PRE8]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, we use the scheduler’s thread pool in the reactive implementation
    of the `getReviews()` method, like so:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们在`getReviews()`方法的响应式实现中使用调度器的线程池，如下所示：
- en: '[PRE9]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Here, the blocking code is placed in the `internalGetReviews()` method and is
    wrapped in a `Mono` object using the `Mono.fromCallable()` method. The `getReviews()`
    method uses the `subscribeOn()` method to run the blocking code in a thread from
    the thread pool of `jdbcScheduler`.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，阻塞代码被放置在`internalGetReviews()`方法中，并使用`Mono.fromCallable()`方法包装在一个`Mono`对象中。`getReviews()`方法使用`subscribeOn()`方法在`jdbcScheduler`的线程池中的一个线程上运行阻塞代码。
- en: 'When we run tests later on in this chapter, we can look at the log output from
    the `review` service and see proof that SQL statements are run in threads from
    the scheduler’s dedicated pool. We will be able to see log output like this:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在本章后面运行测试时，我们可以查看`review`服务的日志输出，并看到SQL语句是在调度器的专用池中的线程上运行的证据。我们将能够看到如下日志输出：
- en: '![Text  Description automatically generated](img/B19825_07_06.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![文本描述自动生成](img/B19825_07_06.png)'
- en: 'Figure 7.6: Log output from the review service'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6：`review`服务的日志输出
- en: 'From the preceding log output, we can see the following:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的日志输出中，我们可以看到以下内容：
- en: The first log output is from the `LOG.info()` call in the `getReviews()` method
    and it is executed on an HTTP thread, named `ctor-http-nio-4`, a thread used by
    WebFlux.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一条日志输出来自`getReviews()`方法中的`LOG.info()`调用，它在名为`ctor-http-nio-4`的HTTP线程上执行，这是WebFlux使用的线程。
- en: In the second log output, we can see the SQL statement generated by Spring Data
    JPA, using Hibernate under the hood. The SQL statement corresponds to the method
    call `repository.findByProductId()`. It is executed on a thread named `jdbc-pool-1`,
    meaning it is executed in a thread from the dedicated thread pool for blocking
    code, as expected!
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第二条日志输出中，我们可以看到由Spring Data JPA生成的SQL语句，底层使用Hibernate。该SQL语句对应于`repository.findByProductId()`方法调用。它在名为`jdbc-pool-1`的线程上执行，这意味着它是在预期中的阻塞代码专用线程池中的线程上执行的！
- en: For the full source code, see the `ReviewServiceApplication` and `ReviewServiceImpl`
    classes in the `review` project.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请参阅`review`项目中的`ReviewServiceApplication`和`ReviewServiceImpl`类。
- en: With the logic for handling blocking code in place, we are done with implementing
    the non-blocking REST APIs in the core services. Let’s move on and see how to
    also make the REST APIs in the composite services non-blocking.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理阻塞代码的逻辑就绪后，我们就完成了核心服务中非阻塞REST API的实现。让我们继续看看如何也将组合服务中的REST API变为非阻塞。
- en: Non-blocking REST APIs in the composite services
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组合服务中的非阻塞REST API
- en: 'To make our REST API in the composite service non-blocking, we need to do the
    following:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 要使组合服务中的REST API非阻塞，我们需要做以下操作：
- en: Change the API so that its operations only return reactive data types
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改API，使其操作仅返回反应式数据类型
- en: Change the service implementation so it calls the coreata services’ APIs in
    parallel and in a non-blocking way
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改服务实现，使其以并行和非阻塞的方式调用核心服务的API
- en: Change the integration layer so it uses a non-blocking HTTP client
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改集成层，使其使用非阻塞HTTP客户端
- en: Change our tests so that they can test the reactive service
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改我们的测试，以便它们可以测试反应式服务
- en: Changes in the API
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: API的变更
- en: To make the API of the composite service reactive, we need to apply the same
    type of change that we applied for the APIs of the core services we described
    previously. This means that the return type of the `getProduct()` method, `ProductAggregate`,
    needs to be replaced with `Mono<ProductAggregate>`.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 要使组合服务的API反应式，我们需要应用与之前应用于核心服务API相同的类型变更。这意味着`getProduct()`方法的返回类型`ProductAggregate`需要替换为`Mono<ProductAggregate>`。
- en: The `createProduct()` and `deleteProduct()` methods need to be updated to return
    a `Mono<Void>` instead of a `void`; otherwise, we can’t propagate any error responses
    back to the callers of the API.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '`createProduct()`和`deleteProduct()`方法需要更新为返回`Mono<Void>`而不是`void`；否则，我们无法将任何错误响应传播回API的调用者。'
- en: For the full source code, see the `ProductCompositeService` interface in the
    `api` project.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请参阅`api`项目中的`ProductCompositeService`接口。
- en: Changes in the service implementation
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务实现的变更
- en: 'To be able to call the three APIs in parallel, the service implementation uses
    the static `zip()` method on the `Mono` class. The `zip` method is capable of
    handling a number of parallel reactive requests and zipping them together once
    they all are complete. The code looks like this:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够并行调用三个API，服务实现使用了`Mono`类的静态`zip()`方法。`zip`方法能够处理多个并发的反应式请求，并在所有请求都完成后将它们压缩在一起。代码如下：
- en: '[PRE10]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let’s take a closer look:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看：
- en: The first parameter of the `zip` method is a lambda function that will receive
    the responses in an array, named `values`. The array will contain a product, a
    list of recommendations, and a list of reviews. The actual aggregation of the
    responses from the three API calls is handled by the same helper method as before,
    `createProductAggregate()`, without any changes.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`zip`方法的第一个参数是一个lambda函数，它将接收一个名为`values`的数组中的响应。该数组将包含一个产品、一个推荐列表和一个评论列表。从三个API调用中收集响应的实际聚合操作由与之前相同的辅助方法`createProductAggregate()`处理，没有任何变化。'
- en: The parameters after the lambda function are a list of the requests that the
    `zip` method will call in parallel, one `Mono` object per request. In our case,
    we send in three `Mono` objects that were created by the methods in the integration
    class, one for each request that is sent to each core microservice.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: lambda函数后面的参数是`zip`方法将并行调用的请求列表，每个请求一个`Mono`对象。在我们的情况下，我们发送了三个由集成类中的方法创建的`Mono`对象，每个对象对应于发送到每个核心微服务的每个请求。
- en: For the full source code, see the `ProductCompositeServiceImpl` class in the
    `product-composite` project.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请参阅`product-composite`项目中的`ProductCompositeServiceImpl`类。
- en: For information on how the `createProduct` and `deleteProduct` API operations
    are implemented in the `product-composite` service, see the *Publishing events
    in the composite service* section later on.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何在`product-composite`服务中实现`createProduct`和`deleteProduct` API操作的信息，请参阅后面的*在组合服务中发布事件*部分。
- en: Changes in the integration layer
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集成层的变更
- en: In the `ProductCompositeIntegration` integration class, we have replaced the
    blocking HTTP client, `RestTemplate`, with a non-blocking HTTP client, `WebClient`,
    that comes with Spring 5.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ProductCompositeIntegration`集成类中，我们将阻塞的HTTP客户端`RestTemplate`替换为Spring 5提供的非阻塞HTTP客户端`WebClient`。
- en: To create a `WebClient` instance, a **builder pattern** is used. If customization
    is required, for example, setting up common headers or filters, it can be done
    using the builder. For the available configuration options, see [https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-client-builder](https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-client-builder).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建`WebClient`实例，使用的是**建造者模式**。如果需要定制，例如设置公共头或过滤器，可以使用建造者来完成。有关可用的配置选项，请参阅[https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-client-builder](https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-client-builder)。
- en: 'The `WebClient` is used as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '`WebClient`的使用方式如下：'
- en: 'In the constructor, the `WebClient` is auto-injected. We build the `WebClient`
    instance without any configuration:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在构造函数中，`WebClient`是自动注入的。我们构建`WebClient`实例而不进行任何配置：
- en: '[PRE11]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next, we use the `webClient` instance to make our non-blocking requests for
    calling the `product` service:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们使用`webClient`实例来对我们的`product`服务进行非阻塞请求：
- en: '[PRE12]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: If the API call to the `product` service fails with an HTTP error response,
    the whole API request will fail. The `onErrorMap()` method in `WebClient` will
    call our `handleException(ex)` method, which maps the HTTP exceptions thrown by
    the HTTP layer to our own exceptions, for example, a `NotFoundException` or a
    `InvalidInputException`.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如果对`product`服务的API调用失败并返回HTTP错误响应，整个API请求将失败。`WebClient`中的`onErrorMap()`方法将调用我们的`handleException(ex)`方法，该方法将HTTP层抛出的HTTP异常映射到我们自己的异常，例如`NotFoundException`或`InvalidInputException`。
- en: 'However, if calls to the `product` service succeed but the call to either the
    `recommendation` or `review` API fails, we don’t want to let the whole request
    fail. Instead, we want to return as much information as is available back to the
    caller. Therefore, instead of propagating an exception in these cases, we will
    instead return an empty list of recommendations or reviews. To suppress the error,
    we will make the call `onErrorResume(error -> empty())`. For this, the code looks
    like the following:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果对`product`服务的调用成功，但对`recommendation`或`review` API的调用失败，我们不想让整个请求失败。相反，我们希望将尽可能多的信息返回给调用者。因此，在这些情况下，我们不会传播异常，而是返回一个空的推荐或评论列表。为了抑制错误，我们将调用`onErrorResume(error
    -> empty())`。为此，代码如下所示：
- en: '[PRE13]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The `GlobalControllerExceptionHandler` class, from the `util` project, will,
    as previously, catch exceptions and transform them into proper HTTP error responses
    that are sent back to the caller of the composite API. This way we can decide
    if a specific HTTP error response from the underlying API calls will result in
    an HTTP error response or just a partly empty response.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 来自`util`项目的`GlobalControllerExceptionHandler`类，将像之前一样捕获异常并将它们转换为适当的HTTP错误响应，这些响应将发送回复合API的调用者。这样我们就可以决定来自底层API调用的特定HTTP错误响应是否会引发HTTP错误响应或只是一个部分为空的响应。
- en: For the full source code, see the `ProductCompositeIntegration` class in the
    `product-composite` project.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看完整的源代码，请参阅`product-composite`项目中的`ProductCompositeIntegration`类。
- en: Changes in the test code
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试代码中的更改
- en: 'The only change that’s required in the test classes is to update the setup
    of Mockito and its mock of the integration class. The mock needs to return `Mono`
    and `Flux` objects. The `setup()` method uses the helper methods `Mono.just()`
    and `Flux.fromIterable()`, as shown in the following code:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试类中需要做的唯一更改是更新Mockito及其对集成类的模拟的设置。模拟需要返回`Mono`和`Flux`对象。`setup()`方法使用辅助方法`Mono.just()`和`Flux.fromIterable()`，如下面的代码所示：
- en: '[PRE14]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: For the full source code, see the `ProductCompositeServiceApplicationTests`
    test class in the `product-composite` project.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看完整的源代码，请参阅`product-composite`项目中的`ProductCompositeServiceApplicationTests`测试类。
- en: This completes the implementation of our non-blocking synchronous REST APIs.
    Now it is time to develop our event-driven asynchronous services.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了我们非阻塞同步REST API的实现。现在，是时候开发我们的事件驱动异步服务了。
- en: Developing event-driven asynchronous services
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发事件驱动的异步服务
- en: 'In this section, we will learn how to develop event-driven and asynchronous
    versions of the create and delete services. The composite service will publish
    create and delete events on each core service topic and then return an OK response
    back to the caller without waiting for processing to take place in the core services.
    This is illustrated in the following diagram:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何开发创建和删除服务的事件驱动和异步版本。组合服务将在每个核心服务主题上发布创建和删除事件，然后向调用者返回一个 OK 响应，而不必等待核心服务中的处理完成。这如下面的图示所示：
- en: '![Diagram  Description automatically generated](img/B19825_07_07.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图示 描述自动生成](img/B19825_07_07.png)'
- en: 'Figure 7.7: The createCompositeProduct and deleteCompositeProduct parts of
    the landscape'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.7：创建组合产品和删除组合产品景观的 createCompositeProduct 和 deleteCompositeProduct 部分
- en: 'We will cover the following topics:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Handling challenges with messaging
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理消息挑战
- en: Defining topics and events
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义主题和事件
- en: Changes in Gradle build files
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gradle 构建文件中的更改
- en: Consuming events in the core services
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在核心服务中消费事件
- en: Publishing events in the composite service
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在组合服务中发布事件
- en: Handling challenges with messaging
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理消息挑战
- en: To implement the event-driven create and delete services, we will use Spring
    Cloud Stream. In *Chapter 2*, *Introduction to Spring Boot*, we have already seen
    how easy it is to publish and consume messages on a topic using Spring Cloud Stream.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现事件驱动的创建和删除服务，我们将使用 Spring Cloud Stream。在 *第 2 章*，*Spring Boot 简介* 中，我们已经看到使用
    Spring Cloud Stream 在主题上发布和消费消息是多么容易。
- en: The programming model is based on a functional paradigm, where functions implementing
    one of the functional interfaces `Supplier`, `Function`, or `Consumer` in the
    `java.util.function` package can be chained together to perform decoupled event-based
    processing. To trigger such functional-based processing externally, from non-functional
    code, the helper class `StreamBridge` can be used.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 编程模型基于函数式范式，其中实现 `java.util.function` 包中 `Supplier`、`Function` 或 `Consumer`
    之一的功能接口的函数可以链接在一起以执行解耦的事件驱动处理。要从非功能代码外部触发基于功能的处理，可以使用辅助类 `StreamBridge`。
- en: 'For example, to publish the body of an HTTP request to a topic, we only have
    to write the following:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要将 HTTP 请求的正文发布到主题，我们只需编写以下代码：
- en: '[PRE15]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The helper class `StreamBridge` is used to trigger the processing. It will
    publish a message on a topic. A function that consumes events from a topic (not
    creating new events) can be defined by implementing the functional interface `java.util.function.Consumer`
    as:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 辅助类 `StreamBridge` 用于触发处理。它将在主题上发布一条消息。可以通过实现 `java.util.function.Consumer`
    功能接口来定义一个从主题消费事件（不创建新事件）的函数，如下所示：
- en: '[PRE16]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: To tie the various functions together, we use configuration. We will see examples
    of such configuration below in the sections *Adding configuration for publishing
    events* and *Adding configuration for consuming events*.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将各种功能结合起来，我们使用配置。我们将在下面的部分 *添加发布事件的配置* 和 *添加消费事件的配置* 中看到此类配置的示例。
- en: This programming model can be used independently of the messaging system used,
    for example, RabbitMQ or Apache Kafka!
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 此编程模型可以独立于所使用的消息系统使用，例如 RabbitMQ 或 Apache Kafka！
- en: 'Even though sending asynchronous messages is preferred over synchronous API
    calls, it comes with challenges of its own. We will see how we can use Spring
    Cloud Stream to handle some of them. The following features in Spring Cloud Stream
    will be covered:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管发送异步消息比同步 API 调用更受欢迎，但它也带来了自己的挑战。我们将看到如何使用 Spring Cloud Stream 来处理其中的一些。Spring
    Cloud Stream 将涵盖以下功能：
- en: Consumer groups
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消费者组
- en: Retries and dead-letter queues
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重试和死信队列
- en: Guaranteed orders and partitions
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保证订单和分区
- en: We’ll study each of these in the following sections.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在以下章节中研究这些内容。
- en: Consumer groups
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 消费者组
- en: 'The problem here is, if we scale up the number of instances of a message consumer,
    for example, if we start two instances of the `product` microservice, both instances
    of the `product` microservice will consume the same messages, as illustrated by
    the following diagram:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的问题是，如果我们增加消息消费者实例的数量，例如，如果我们启动两个 `product` 微服务的实例，这两个 `product` 微服务的实例都将消费相同的消息，如下面的图示所示：
- en: '![Diagram  Description automatically generated](img/B19825_07_08.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![图示 描述自动生成](img/B19825_07_08.png)'
- en: 'Figure 7.8: Products #1 and #2 consuming the same messages'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7.8：产品 #1 和 #2 消费相同的消息'
- en: 'This could result in one message being processed two times, potentially leading
    to duplicates or other undesired inconsistencies in the database. Therefore, we
    only want one instance per consumer to process each message. This can be solved
    by introducing a **consumer group**, as illustrated by the following diagram:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能导致一条消息被处理两次，从而在数据库中可能导致重复或其他不希望的不一致性。因此，我们只想让每个消费者实例处理每条消息。这可以通过引入一个**消费者组**来解决，如下面的图所示：
- en: '![Diagram  Description automatically generated](img/B19825_07_09.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![图描述自动生成](img/B19825_07_09.png)'
- en: 'Figure 7.9: Consumer group'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.9：消费者组
- en: 'In Spring Cloud Stream, a consumer group can be configured on the consumer
    side. For example, for the `product` microservice, it will look like this:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spring Cloud Stream中，消费者组可以在消费者端进行配置。例如，对于`product`微服务，它将看起来像这样：
- en: '[PRE17]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'From this configuration, we can learn the following:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个配置中，我们可以了解到以下内容：
- en: 'Spring Cloud Stream applies, by default, a naming convention for binding a
    configuration to a function. For messages sent to a function, the binding name
    is `<functionName>-in-<index>`:'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spring Cloud Stream默认应用了一个命名约定，将配置绑定到函数。对于发送到函数的消息，绑定名称是`<functionName>-in-<index>`：
- en: '`functionName` is the name of the function, `messageProcessor` in the preceding
    example.'
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`functionName`是函数的名称，在前面的示例中为`messageProcessor`。'
- en: '`index` is set to `0`, unless the function requires multiple input or output
    arguments. We will not use multi-argument functions, so `index` will always be
    set to `0` in our examples.'
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`index`被设置为`0`，除非函数需要多个输入或输出参数。我们不会使用多参数函数，所以在我们的示例中`index`将始终设置为`0`。'
- en: For outgoing messages, the binding name convention is `<functionName>-out-<index>`.
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于出站消息，绑定名称约定是`<functionName>-out-<index>`。
- en: The `destination` property specifies the name of the topic that messages will
    be consumed from, `products` in this case.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`destination`属性指定了消息将被消费的主题名称，在本例中为`products`。'
- en: The `group` property specifies what consumer group to add instances of the `product`
    microservice to, `productsGroup` in this example. This means that messages sent
    to the `products` topic will only be delivered by Spring Cloud Stream to one of
    the instances of the `product` microservice.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`group`属性指定了要将`product`微服务的实例添加到哪个消费者组，在本例中为`productsGroup`。这意味着发送到`products`主题的消息将只由Spring
    Cloud Stream交付给`product`微服务的某个实例。'
- en: Retries and dead-letter queues
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重试和死信队列
- en: If a consumer fails to process a message, it may be re-queued for the failing
    consumer until it is successfully processed. If the content of the message is
    invalid, also known as a **poisoned message**, the message will block the consumer
    from processing other messages until it is manually removed. If the failure is
    due to a temporary problem, for example, the database can’t be reached due to
    a temporary network error, the processing will probably succeed after a number
    of retries.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 如果消费者无法处理消息，它可能会被重新排队给失败消费者，直到成功处理。如果消息的内容无效，也称为**毒消息**，该消息将阻止消费者处理其他消息，直到手动删除。如果失败是由于临时问题，例如，由于临时网络错误数据库无法访问，经过几次重试后处理可能会成功。
- en: It must be possible to specify the number of retries until a message is moved
    to another storage for fault analysis and correction. A failing message is typically
    moved to a dedicated queue called a dead-letter queue. To avoid overloading the
    infrastructure during temporary failure, for example, a network error, it must
    be possible to configure how often retries are performed, preferably with an increasing
    length of time between each retry.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 必须能够指定将消息移动到另一个存储进行故障分析和纠正的重试次数。一个失败的消息通常会被移动到一个称为死信队列的专用队列。为了避免在临时故障期间（例如，网络错误）过载基础设施，必须能够配置重试的频率，最好是在每次重试之间增加时间间隔。
- en: 'In Spring Cloud Stream, this can be configured on the consumer side, for example,
    for the `product` microservice, as shown here:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spring Cloud Stream中，这可以在消费者端进行配置，例如，对于`product`微服务，如下所示：
- en: '[PRE18]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In the preceding example, we specify that Spring Cloud Stream should perform
    `3` retries before placing a message on the dead-letter queue. The first retry
    will be attempted after `500` ms and the two other attempts after `1000` ms.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们指定Spring Cloud Stream在将消息放入死信队列之前应该进行`3`次重试。第一次重试将在`500`毫秒后尝试，其他两次尝试将在`1000`毫秒后。
- en: Enabling the use of dead-letter queues is binding-specific; therefore, we have
    one configuration for RabbitMQ and one for Kafka.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 启用死信队列的使用是绑定特定的；因此，我们为RabbitMQ和Kafka分别有一个配置。
- en: Guaranteed order and partitions
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 保证顺序和分区
- en: If the business logic requires that messages are consumed and processed in the
    same order as they were sent, we cannot use multiple instances per consumer to
    increase processing performance; for example, we cannot use consumer groups. This
    might, in some cases, lead to an unacceptable latency in the processing of incoming
    messages.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 如果业务逻辑要求消息的消费和处理顺序与发送顺序相同，我们不能为每个消费者使用多个实例来提高处理性能；例如，我们不能使用消费者组。这可能在某些情况下导致处理传入消息的延迟不可接受。
- en: We can use **partitions** to ensure that messages are delivered in the same
    order as they were sent but without losing performance and scalability.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用**分区**来确保消息按照发送顺序交付，同时不损失性能和可伸缩性。
- en: In most cases, strict order in the processing of messages is only required for
    messages that affect the same business entities. For example, messages affecting
    the product with product ID `1` can, in many cases, be processed independently
    of messages that affect the product with product ID `2`. This means that the order
    only needs to be guaranteed for messages that have the same product ID.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，对消息处理的严格顺序仅适用于影响相同业务实体的消息。例如，影响产品ID为`1`的产品消息，在许多情况下可以独立于影响产品ID为`2`的产品消息进行处理。这意味着只需要保证具有相同产品ID的消息的顺序。
- en: The solution to this is to make it possible to specify a **key** for each message,
    which the messaging system can use to guarantee that the order is kept between
    messages with the same key. This can be solved by introducing sub-topics, also
    known as **partitions**, in a topic. The messaging system places messages in a
    specific partition based on its key.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的方法是使每个消息都可以指定一个**键**，消息系统可以使用它来保证具有相同键的消息之间的顺序。这可以通过在主题中引入子主题，也称为**分区**来实现。消息系统根据其键将消息放置在特定的分区中。
- en: 'Messages with the same key are always placed in the same partition. The messaging
    system only needs to guarantee the delivery order for messages in the same partition.
    To ensure the order of the messages, we configure one consumer instance per partition
    within a consumer group. By increasing the number of partitions, we can allow
    a consumer to increase its number of instances. This increases its message-processing
    performance without losing the delivery order. This is illustrated in the following
    diagram:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 具有相同键的消息总是放置在同一个分区中。消息系统只需要保证同一分区中消息的交付顺序。为了确保消息的顺序，我们在消费者组内为每个分区配置一个消费者实例。通过增加分区的数量，我们可以允许消费者增加其实例数量。这增加了其消息处理性能，同时不丢失交付顺序。这在下图中得到说明：
- en: '![Diagram  Description automatically generated](img/B19825_07_10.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![图描述自动生成](img/B19825_07_10.png)'
- en: 'Figure 7.10: Specifying keys for messages'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.10：指定消息的键
- en: As seen in the preceding diagram, all messages with the `Key` set to `123` always
    go to the `Products-1`, partition while messages with the `Key` set to `456` go
    to the `Products-2` partition.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，所有将`Key`设置为`123`的消息总是发送到`Products-1`分区，而将`Key`设置为`456`的消息则发送到`Products-2`分区。
- en: 'In Spring Cloud Stream, this needs to be configured on both the publisher and
    consumer sides. On the publisher side, the key and number of partitions must be
    specified. For example, for the `product-composite` service, we have the following:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spring Cloud Stream中，这需要在发布者和消费者两端进行配置。在发布者端，必须指定键和分区数。例如，对于`product-composite`服务，我们有以下配置：
- en: '[PRE19]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This configuration means that the key will be taken from the message header
    with the name `partitionKey` and that two partitions will be used.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置意味着键将从名为`partitionKey`的消息头中提取，并且将使用两个分区。
- en: 'Each consumer can specify which partition it wants to consume messages from.
    For example, for the `product` microservice, we have the following:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 每个消费者可以指定它想要从哪个分区消费消息。例如，对于`product`微服务，我们有以下配置：
- en: '[PRE20]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This configuration tells Spring Cloud Stream that this consumer will only consume
    messages from partition number `0`, that is, the first partition.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置告诉Spring Cloud Stream，此消费者将只从分区号`0`（即第一个分区）消费消息。
- en: Defining topics and events
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义主题和事件
- en: As we already mentioned in the *Spring Cloud Stream* section in *Chapter 2*,
    *Introduction to Spring Boot*, Spring Cloud Stream is based on the publish and
    subscribe pattern, where a publisher publishes messages to topics and subscribers
    subscribe to topics they are interested in receiving messages from.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第2章“Spring Boot简介”中的*Spring Cloud Stream*部分所提到的，Spring Cloud Stream基于发布和订阅模式，其中发布者向主题发布消息，而订阅者订阅他们感兴趣接收消息的主题。
- en: 'We will use one **topic** per type of entity: `products`, `recommendations`,
    and `reviews`.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为每种实体类型使用一个**主题**：`products`、`recommendations`和`reviews`。
- en: Messaging systems handle **messages** that typically consist of headers and
    a body. An **event** is a message that describes something that has happened.
    For events, the message body can be used to describe the type of event, the event
    data, and a timestamp for when the event occurred.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 消息系统处理**消息**，这些消息通常由头和正文组成。一个**事件**是描述已发生某事的邮件。对于事件，消息正文可以用来描述事件类型、事件数据和事件发生的时间戳。
- en: 'An event is, for the scope of this book, defined by the following:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的范围内，事件被定义为以下内容：
- en: The **type** of event, for example, a create or delete event
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件的**类型**，例如，创建或删除事件
- en: A **key** that identifies the data, for example, a product ID
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个**键**用于标识数据，例如，产品ID
- en: A **data** element, that is, the actual data in the event
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个**数据**元素，即事件中的实际数据
- en: A **timestamp**, which describes when the event occurred
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个**时间戳**，描述事件发生的时间
- en: 'The event class we will use looks as follows:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要使用的事件类如下所示：
- en: '[PRE21]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let’s explain the preceding source code in detail:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细解释前面的源代码：
- en: The `Event` class is a generic class parameterized over the types of its `key`
    and `data` fields, `K` and `T`
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Event`类是一个泛型类，其`key`和`data`字段由`K`和`T`类型参数化'
- en: The event type is declared as an enumerator with the allowed values, that is,
    `CREATE` and `DELETE`
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件类型被声明为一个枚举，具有允许的值，即`CREATE`和`DELETE`
- en: The class defines two constructors, one empty and one that can be used to initialize
    the type, key, and value members
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该类定义了两个构造函数，一个是空的，另一个可以用来初始化类型、键和值成员
- en: Finally, the class defines getter methods for its member variables
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，该类为其成员变量定义了getter方法
- en: For the full source code, see the `Event` class in the `api` project.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请参阅`api`项目中的`Event`类。
- en: Changes in the Gradle build files
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Gradle构建文件中的更改
- en: 'To bring in Spring Cloud Stream and its binders for RabbitMQ and Kafka, we
    need to add the two starter dependencies known as `spring-cloud-starter-stream-rabbit`
    and `spring-cloud-starter-stream-kafka`. We also need a test dependency in the
    `product-composite` project, `spring-cloud-stream::test-binder`, to bring in test
    support. The following code shows this:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 要引入Spring Cloud Stream及其RabbitMQ和Kafka的绑定器，我们需要添加两个名为`spring-cloud-starter-stream-rabbit`和`spring-cloud-starter-stream-kafka`的启动依赖项。我们还需要在`product-composite`项目中添加一个测试依赖项`spring-cloud-stream::test-binder`，以引入测试支持。以下代码显示了这一点：
- en: '[PRE22]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To specify what version of Spring Cloud we want to use, we first declare a
    variable for the version:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 要指定我们想要使用的Spring Cloud版本，我们首先声明一个用于版本的变量：
- en: '[PRE23]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Next, we use the variable to set up dependency management for the specified
    Spring Cloud version, as seen here:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用变量来设置指定Spring Cloud版本的依赖管理，如下所示：
- en: '[PRE24]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: For the full source code, see the `build.gradle` build file in each of the microservices
    projects.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请参阅每个微服务项目的`build.gradle`构建文件。
- en: With the required dependencies added to the Gradle build files, we can start
    to learn how to consume events in the core services.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在Gradle构建文件中添加所需的依赖项后，我们可以开始学习如何在核心服务中消费事件。
- en: Consuming events in the core services
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在核心服务中消费事件
- en: 'To be able to consume events in the core services, we need to do the following:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够在核心服务中消费事件，我们需要做以下事情：
- en: Declare message processors that consume events published on the core service’s
    topic
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 声明消费核心服务主题上发布的事件的消息处理器
- en: Change our service implementations to use the reactive persistence layer
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将我们的服务实现更改为使用反应式持久化层
- en: Add configuration required for consuming events
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加消费事件所需的配置
- en: Change our tests so that they can test the asynchronous processing of the events
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改我们的测试，以便它们可以测试事件的异步处理
- en: The source code for consuming events is structured in the same way in all three
    core services, so we will only go through the source code for the `product` service.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 消费事件的源代码在所有三个核心服务中结构相同，因此我们只需查看`product`服务的源代码。
- en: Declaring message processors
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 声明消息处理器
- en: The REST APIs for creating and deleting entities have been replaced with a **message
    processor** in each core microservice that consumes create and delete events on
    each entity’s topic. To be able to consume messages that have been published to
    a topic, we need to declare a Spring Bean that implements the functional interface
    `java.util.function.Consumer`.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 创建和删除实体的REST API已被每个核心微服务中的**消息处理器**所取代，这些微服务消费每个实体主题上的创建和删除事件。为了能够消费已发布到主题的消息，我们需要声明一个实现功能接口`java.util.function.Consumer`的Spring
    Bean。
- en: 'The message processor for the `product` service is declared as:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '`product`服务的消息处理器声明如下：'
- en: '[PRE25]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'From the preceding code, we can see that:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码中，我们可以看到：
- en: The class is annotated with `@Configuration`, telling Spring to look for Spring
    beans in the class.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该类使用`@Configuration`注解，告诉Spring在该类中查找Spring Bean。
- en: We inject an implementation of the `ProductService` interface in the constructor.
    The `productService` bean contains the business logic to perform the actual creation
    and deletions of the product entities.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在构造函数中注入了`ProductService`接口的实现。`productService`豆包含执行实际创建和删除产品实体的业务逻辑。
- en: We declare the message processor as a Spring bean that implements the functional
    interface `Consumer`, accepting an event as an input parameter of type `Event<Integer,Product>`.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将消息处理器声明为一个实现功能接口`Consumer`的Spring Bean，接受一个类型为`Event<Integer,Product>`的事件作为输入参数。
- en: 'The implementation of the `Consumer` function looks like this:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '`Consumer`函数的实现如下所示：'
- en: '[PRE26]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The preceding implementation does the following:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的实现执行以下操作：
- en: It takes an event of type `Event<Integer,Product>` as an input parameter
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它接受一个类型为`Event<Integer,Product>`的事件作为输入参数
- en: Using a `switch` statement, based on the event type, it will either create or
    delete a product entity
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`switch`语句，根据事件类型，它将创建或删除产品实体
- en: It uses the injected `productService` bean to perform the actual create and
    delete operation
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使用注入的`productService`豆来执行实际的创建和删除操作
- en: If the event type is neither create nor delete, an exception will be thrown
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果事件类型既不是创建也不是删除，将会抛出异常
- en: To ensure that we can propagate exceptions thrown by the `productService` bean
    back to the messaging system, we call the `block()` method on the responses we
    get back from the `productService` bean. This ensures that the message processor
    waits for the `productService` bean to complete its creation or deletion in the
    underlying database. Without calling the `block()` method, we would not be able
    to propagate exceptions and the messaging system would not be able to re-queue
    a failed attempt or possibly move the message to a dead-letter queue; instead,
    the message would silently be dropped.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们可以将`productService`豆抛出的异常传播回消息系统，我们在从`productService`豆获取的响应上调用`block()`方法。这确保了消息处理器等待`productService`豆在底层数据库中完成创建或删除操作。如果不调用`block()`方法，我们就无法传播异常，消息系统也无法重新排队失败尝试或将消息移动到死信队列；相反，消息将被静默丢弃。
- en: Calling a `block()` method is, in general, considered a bad practice from a
    performance and scalability perspective. But in this case, we will only handle
    a few incoming messages in parallel, one per partition, as described above. This
    means that we will only have a few threads blocked concurrently, which will not
    negatively impact the performance or the scalability.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 从性能和可扩展性的角度来看，调用`block()`方法通常被认为是一种不良实践。但在此情况下，我们只会并行处理少量接收到的消息，每个分区一个，如上所述。这意味着我们只会同时阻塞少量线程，这不会对性能或可扩展性产生负面影响。
- en: For the full source code, see the `MessageProcessorConfig` classes in the `product`,
    `recommendation`, and `review` projects.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请参阅`product`、`recommendation`和`review`项目中的`MessageProcessorConfig`类。
- en: Changes in the service implementations
  id: totrans-290
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务实现中的更改
- en: 'The service implementations of the create and delete methods for the `product`
    and `recommendation` service have been rewritten to use the non-blocking reactive
    persistence layer for MongoDB. For example, creating product entities is done
    as follows:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '`product`和`recommendation`服务的创建和删除方法的服务实现已被重写，以使用非阻塞的MongoDB反应持久层。例如，创建产品实体如下所示：'
- en: '[PRE27]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Note from the preceding code that the `onErrorMap()` method is used to map the
    `DuplicateKeyException` persistence exception to our own `InvalidInputException`
    exception.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，前面的代码中使用了`onErrorMap()`方法将`DuplicateKeyException`持久化异常映射到我们自己的`InvalidInputException`异常。
- en: For the `review` service, which uses the blocking persistence layer for JPA,
    the create and delete methods have been updated in the same way as described in
    the *Dealing with blocking code section*.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用JPA的阻塞持久化层的`review`服务，创建和删除方法已经按照*处理阻塞代码部分*中描述的方式进行了更新。
- en: 'For the full source code, see the following classes:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请参阅以下类：
- en: '`ProductServiceImpl` in the `product` project'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ProductServiceImpl`位于`product`项目中'
- en: '`RecommendationServiceImpl` in the `recommendation` project'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RecommendationServiceImpl`位于`recommendation`项目中'
- en: '`ReviewServiceImpl` in the `review` project'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ReviewServiceImpl`位于`review`项目中'
- en: Adding configuration for consuming events
  id: totrans-299
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加消费事件的配置
- en: 'We also need to set up a configuration for the messaging system to be able
    to consume events. To do this, we need to complete the following steps:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要为消息系统设置一个配置，以便能够消费事件。为此，我们需要完成以下步骤：
- en: 'We declare that RabbitMQ is the default messaging system and that the default
    content type is JSON:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们声明RabbitMQ是默认的消息系统，默认的内容类型是JSON：
- en: '[PRE28]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Next, we bind the input to the message processors to specific topic names,
    as follows:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将输入绑定到具有特定主题名称的消息处理器，如下所示：
- en: '[PRE29]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Finally, we declare connectivity information for both Kafka and RabbitMQ:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们声明了Kafka和RabbitMQ的连接信息：
- en: '[PRE30]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: In the default Spring profile, we specify hostnames to be used when we run our
    system landscape without Docker on `localhost` with the IP address `127.0.0.1`.
    In the `docker` Spring profile, we specify the hostnames we will use when running
    in Docker and using Docker Compose, that is, `rabbitmq` and `kafka`.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在默认的Spring配置文件中，当我们不使用Docker在`localhost`上运行我们的系统架构，并使用IP地址`127.0.0.1`时，我们指定了要使用的主机名。在`docker`
    Spring配置文件中，我们指定了在Docker和Docker Compose中运行时将使用的主机名，即`rabbitmq`和`kafka`。
- en: Added to this configuration, the consumer configuration also specifies consumer
    groups, retry handling, dead-letter queues, and partitions as they were described
    earlier in the *Handling challenges with messaging* section.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在此配置中添加了消费者配置，它还指定了消费者组、重试处理、死信队列和分区，正如在*处理消息挑战*部分中之前所描述的。
- en: For the full source code, see the `application.yml` configuration files in the
    `product`, `recommendation`, and `review` projects.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请参阅`product`、`recommendation`和`review`项目中的`application.yml`配置文件。
- en: Changes in the test code
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试代码中的更改
- en: 'Since the core services now receive events for creating and deleting their
    entities, the tests need to be updated so that they send events instead of calling
    REST APIs, as they did in the previous chapters. To be able to call the message
    processor from the test class, we inject the message processor bean into a member
    variable:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 由于核心服务现在接收创建和删除其实体的事件，因此测试需要更新，以便它们发送事件而不是调用REST API，就像在上一章中做的那样。为了能够从测试类中调用消息处理器，我们需要将消息处理器bean注入到一个成员变量中：
- en: '[PRE31]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: From the preceding code, we can see that we not only inject any `Consumer` function
    but also use the `@Qualifier` annotation to specify that we want to inject the
    `Consumer` function that has the name `messageProcessor`.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码中，我们可以看到我们不仅注入了任何`Consumer`函数，还使用了`@Qualifier`注解来指定我们想要注入名为`messageProcessor`的`Consumer`函数。
- en: 'To send create and delete events to the message processor, we add two helper
    methods, `sendCreateProductEvent` and `sendDeleteProductEvent`, in the test class:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 要将创建和删除事件发送到消息处理器，我们在测试类中添加了两个辅助方法，`sendCreateProductEvent`和`sendDeleteProductEvent`。
- en: '[PRE32]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Note that we use the `accept()` method in the `Consumer` function interface
    declaration to invoke the message processor. This means that we skip the messaging
    system in the tests and call the message processor directly.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们在`Consumer`函数接口声明中使用`accept()`方法来调用消息处理器。这意味着我们在测试中跳过了消息系统，直接调用消息处理器。
- en: The tests for creating and deleting entities are updated to use these helper
    methods.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 创建和删除实体的测试已更新，以使用这些辅助方法。
- en: 'For the full source code, see the following test classes:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请参阅以下测试类：
- en: '`ProductServiceApplicationTests` in the `product` project'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ProductServiceApplicationTests`位于`product`项目中'
- en: '`RecommendationServiceApplicationTests` in the `recommendation` project'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RecommendationServiceApplicationTests`位于`recommendation`项目中'
- en: '`ReviewServiceApplicationTests` in the `review` project'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ReviewServiceApplicationTests`位于`review`项目中'
- en: We have seen what is required to consume events in the core microservices. Now
    let’s see how we can publish events in the composite microservice.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了在核心微服务中消费事件所需的内容。现在让我们看看我们如何在组合微服务中发布事件。
- en: Publishing events in the composite service
  id: totrans-323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在组合服务中发布事件
- en: 'When the composite service receives HTTP requests for the creation and deletion
    of composite products, it will publish the corresponding events to the core services
    on their topics. To be able to publish events in the composite service, we need
    to perform the following steps:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 当组合服务接收到创建和删除组合产品的HTTP请求时，它将向核心服务在其主题上发布相应的事件。为了能够在组合服务中发布事件，我们需要执行以下步骤：
- en: Publish events in the integration layer
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在集成层发布事件
- en: Add configuration for publishing events
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加发布事件的配置
- en: Change tests so that they can test the publishing of events
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改测试用例，以便它们可以测试事件的发布
- en: Note that no changes are required in the composite service implementation class
    – it is taken care of by the integration layer!
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在组合服务实现类中不需要进行任何更改——这是由集成层处理的！
- en: Publishing events in the integration layer
  id: totrans-329
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在集成层发布事件
- en: 'To publish an event in the integration layer, we need to:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 要在集成层发布事件，我们需要：
- en: Create an `Event` object based on the body in the HTTP request
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据HTTP请求正文创建一个`Event`对象
- en: Create a `Message` object where the `Event` object is used as the payload and
    the key field in the `Event` object is used as the partition key in the header
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`Message`对象，其中使用`Event`对象作为有效负载，并将`Event`对象中的键字段用作头部的分区键
- en: Use the helper class `StreamBridge` to publish the event on the desired topic
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用辅助类`StreamBridge`在所需主题上发布事件
- en: 'The code for sending create product events looks like this:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 发送创建产品事件的代码如下：
- en: '[PRE33]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'In the preceding code, we can see:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们可以看到：
- en: The integration layer implements the `createProduct()` method in the `ProductService`
    interface by using a helper method, `sendMessage()`. The helper method takes the
    name of an output binding and an event object. The binding name `products-out-0`
    will be bound to the topic of the `product` service in the configuration below.
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成层通过使用辅助方法`sendMessage()`在`ProductService`接口中实现`createProduct()`方法。辅助方法接受输出绑定的名称和事件对象。以下配置中，绑定名称`products-out-0`将被绑定到`product`服务的主题。
- en: Since the `sendMessage()` uses blocking code, when calling `streamBridge`, it
    is executed on a thread provided by a dedicated scheduler, `publishEventScheduler`.
    This is the same approach as for handling blocking JPA code in the `review` microservice.
    See the section on *Dealing with blocking code* for details.
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于`sendMessage()`使用阻塞代码，当调用`streamBridge`时，它将在由专用调度器`publishEventScheduler`提供的线程上执行。这与在`review`微服务中处理阻塞JPA代码的方法相同。有关详细信息，请参阅*处理阻塞代码*部分。
- en: The helper method, `sendMessage()`, creates a `Message` object and sets the
    `payload` and the `partitionKey` header as described above. Finally, it uses the
    `streamBridge` object to send the event to the messaging system, which will publish
    it on the topic defined in the configuration.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 辅助方法`sendMessage()`创建一个`Message`对象，并设置如上所述的`payload`和`partitionKey`头。最后，它使用`streamBridge`对象将事件发送到消息系统，该系统将在配置中定义的主题上发布它。
- en: For the full source code, see the `ProductCompositeIntegration` class in the
    `product-composite` project.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看完整源代码，请参阅`product-composite`项目中的`ProductCompositeIntegration`类。
- en: Adding configuration for publishing events
  id: totrans-341
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加发布事件的配置
- en: We also need to set up the configuration for the messaging system, to be able
    to publish events; this is similar to what we did for the consumers. Declaring
    RabbitMQ as the default messaging system, JSON as the default content type, and
    Kafka and RabbitMQ for connectivity information is the same as for the consumers.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要设置消息系统的配置，以便能够发布事件；这与我们为消费者所做的类似。将RabbitMQ声明为默认消息系统，JSON作为默认内容类型，以及Kafka和RabbitMQ作为连接信息与消费者相同。
- en: 'To declare what topics should be used for the output binding names, we have
    the following configuration:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 为了声明应该用于输出绑定名称的主题，我们有以下配置：
- en: '[PRE34]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'When using partitions, we also need to specify the partition key and the number
    of partitions that will be used:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用分区时，我们还需要指定分区键和将要使用的分区数量：
- en: '[PRE35]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'In the preceding configuration, we can see that:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的配置中，我们可以看到：
- en: The configuration applies for the binding name `products-out-0`
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该配置适用于绑定名称`products-out-0`
- en: The partition key used will be taken from the message header `partitionKey`
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将使用的分区键将从消息头`partitionKey`中获取
- en: Two partitions will be used
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将使用两个分区
- en: For the full source code, see the `application.yml` configuration file in the
    `product-composite` project.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看完整源代码，请参阅`product-composite`项目中的`application.yml`配置文件。
- en: Changes in the test code
  id: totrans-352
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试代码的更改
- en: Testing asynchronous event-driven microservices is, by its nature, difficult.
    Tests typically need to synchronize on the asynchronous background processing
    in some way to be able to verify the result. Spring Cloud Stream comes with support,
    in the form of a test binder, that can be used to verify what messages have been
    sent without using any messaging system during the tests!
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其本质，测试异步事件驱动的微服务是困难的。测试通常需要以某种方式同步于异步的后台处理，以便能够验证结果。Spring Cloud Stream提供了一个测试绑定器，可以在测试期间不使用任何消息系统来验证已发送的消息！
- en: See the *Changes in the Gradle build files* section earlier for how the test
    support is included in the `product-composite` project.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何在`product-composite`项目中包含测试支持，请参阅前面提到的*Gradle构建文件中的更改*部分。
- en: 'The test support includes an `OutputDestination` helper class, which can be
    used to get the messages that were sent during a test. A new test class, `MessagingTests`,
    has been added to run tests that verify that the expected messages are sent. Let’s
    go through the most important parts of the test class:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 测试支持包括一个`OutputDestination`辅助类，它可以用来获取测试期间发送的消息。已添加一个新的测试类`MessagingTests`，用于运行验证预期消息是否被发送的测试。让我们来看看测试类中最重要的一部分：
- en: 'To be able to inject an `OutputDestination` bean in the test class, we also
    need to bring in its configuration from the class `TestChannelBinderConfiguration`.
    This is done with the following code:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了能够在测试类中注入`OutputDestination`豆，我们还需要从`TestChannelBinderConfiguration`类中引入其配置。这是通过以下代码完成的：
- en: '[PRE36]'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Next, we declare a couple of helper methods for reading messages and also to
    be able to purge a topic. The code looks like this:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们声明了一些用于读取消息和清除主题的辅助方法。代码看起来是这样的：
- en: '[PRE37]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'From the preceding code, we can see that:'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从前面的代码中，我们可以看到：
- en: The `getMessage()` method returns a message from a specified topic using the
    `OutputDestination` bean, named `target`
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getMessage()`方法使用名为`target`的`OutputDestination`豆返回指定主题的消息。'
- en: The `getMessages()` method uses the `getMessage()` method to return all messages
    in a topic
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getMessages()`方法使用`getMessage()`方法返回主题中的所有消息。'
- en: The `purgeMessages()` method uses the `getMessages()` method to purge a topic
    from all current messages
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`purgeMessages()`方法使用`getMessages()`方法从所有当前消息中清除一个主题。'
- en: 'Each test starts with purging all topics involved in the tests using a `setup()`
    method annotated with `@BeforeEach`:'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个测试都以使用带有`@BeforeEach`注解的`setup()`方法清除所有参与测试的主题开始：
- en: '[PRE38]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'An actual test can verify the messages in a topic using the `getMessages()`
    method. For example, see the following test for the creation of a composite product:'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实际测试可以使用`getMessages()`方法验证主题中的消息。例如，查看以下创建组合产品的测试：
- en: '[PRE39]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'From the preceding code, we can see an example where a test:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码中，我们可以看到一个测试的例子：
- en: First makes an HTTP POST request, requesting the creation of a composite product.
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先发起一个HTTP POST请求，请求创建一个组合产品。
- en: Next, gets all messages from the three topics, one for each underlying core
    service.
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，从三个主题中获取所有消息，每个主题对应一个底层核心服务。
- en: For these tests, the specific timestamp for when an event was created is irrelevant.
    To be able to compare an actual event with an expected event, ignoring differences
    in the `eventCreatedAt` field, a helper class called `IsSameEvent` can be used.
    The `sameEventExceptCreatedAt()` method is a static method in the `IsSameEvent`
    class that compares `Event` objects and treats them as equal if all the fields
    are equal, except for the `eventCreatedAt` field.
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于这些测试，事件创建的具体时间戳无关紧要。为了能够比较实际事件与预期事件，忽略`eventCreatedAt`字段中的差异，可以使用一个名为`IsSameEvent`的辅助类。`sameEventExceptCreatedAt()`方法是`IsSameEvent`类中的一个静态方法，它比较`Event`对象，如果所有字段都相等（除了`eventCreatedAt`字段），则将它们视为相等。
- en: Finally, it verifies that the expected events can be found, and no others.
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，它验证了预期的事件可以被找到，且没有其他事件。
- en: For the full source code, see the test classes `MessagingTests` and `IsSameEvent`
    in the `product-composite` project.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看完整的源代码，请参阅`product-composite`项目中的测试类`MessagingTests`和`IsSameEvent`。
- en: Running manual tests of the reactive microservice landscape
  id: totrans-374
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行反应式微服务景观的手动测试
- en: Now, we have fully reactive microservices, both in terms of non-blocking synchronous
    REST APIs and event-driven asynchronous services. Let’s try them out!
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们拥有了完全反应式的微服务，无论是非阻塞同步REST API还是事件驱动的异步服务。让我们试试它们吧！
- en: 'We will learn how to run tests using both RabbitMQ and Kafka as the message
    broker. Since RabbitMQ can be used both with and without partitions, we will test
    both cases. Three different configurations will be used, each defined in a separate
    Docker Compose file:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将学习如何使用RabbitMQ和Kafka作为消息代理来运行测试。由于RabbitMQ可以与或不与分区一起使用，我们将测试这两种情况。将使用三种不同的配置，每个配置定义在一个单独的Docker
    Compose文件中：
- en: Using RabbitMQ without the use of partitions
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不使用分区使用RabbitMQ
- en: Using RabbitMQ with two partitions per topic
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用RabbitMQ时，每个主题有两个分区
- en: Using Kafka with two partitions per topic
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Kafka时，每个主题有两个分区
- en: 'However, before testing these three configurations, we need to add two features
    to be able to test the asynchronous processing:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在测试这三个配置之前，我们需要添加两个功能以便能够测试异步处理：
- en: Saving events for later inspection when using RabbitMQ
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用RabbitMQ时保存事件以供稍后检查
- en: A health API that can be used to monitor the state of the microservice landscape
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可以用来监控微服务景观状态的健康API
- en: Saving events
  id: totrans-383
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保存事件
- en: After running some tests on event-driven asynchronous services, it might be
    of interest to see what events were actually sent. When using Spring Cloud Stream
    with Kafka, events are retained in the topics, even after consumers have processed
    them. However, when using Spring Cloud Stream with RabbitMQ, the events are removed
    after they have been processed successfully.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在对事件驱动的异步服务进行了一些测试之后，查看实际发送了哪些事件可能很有趣。当使用Spring Cloud Stream与Kafka结合时，事件在主题中保留，即使消费者已经处理了它们。然而，当使用Spring
    Cloud Stream与RabbitMQ结合时，事件在成功处理后会被移除。
- en: 'To be able to see what events have been published on each topic, Spring Cloud
    Stream is configured to save published events in a separate consumer group, `auditGroup`,
    per topic. For the `products` topic, the configuration looks like the following:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够看到每个主题上已发布的哪些事件，Spring Cloud Stream被配置为将发布的事件保存到每个主题的单独消费者组`auditGroup`中。对于`products`主题，配置如下所示：
- en: '[PRE40]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: When using RabbitMQ, this will result in extra queues being created where the
    events are stored for later inspection.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用RabbitMQ时，这将导致创建额外的队列来存储事件，以便稍后检查。
- en: For the full source code, see the `application.yml` configuration file in the
    `product-composite` project.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请参阅`product-composite`项目中的`application.yml`配置文件。
- en: Adding a health API
  id: totrans-389
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加健康API
- en: Testing a system landscape of microservices that uses a combination of synchronous
    APIs and asynchronous messaging is challenging.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 测试一个使用同步API和异步消息组合的微服务系统景观具有挑战性。
- en: For example, how do we know when a newly started landscape of microservices,
    together with their databases and messaging system, are ready to process requests
    and messages?
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们如何知道一个新启动的微服务景观，包括其数据库和消息系统，何时准备好处理请求和消息？
- en: To make it easier to know when all the microservices are ready, we have added
    health APIs to the microservices. The health APIs are based on the support for
    **health endpoints** that comes with the Spring Boot module **Actuator**. By default,
    an Actuator-based health endpoint responds with `UP` (and gives 200 as the HTTP
    return status) if the microservice itself and all the dependencies Spring Boot
    knows about are available. Dependencies Spring Boot knows about include databases
    and messaging systems. If the microservice itself or any of its dependencies are
    not available, the health endpoint responds with `DOWN` (and returns 500 as the
    HTTP return status).
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更容易知道所有微服务何时就绪，我们已向微服务中添加了健康API。这些健康API基于Spring Boot模块**Actuator**提供的**健康端点**支持。默认情况下，基于Actuator的健康端点如果微服务本身以及Spring
    Boot所知的所有依赖都可用，则响应`UP`（并返回HTTP状态码200）。Spring Boot所知的依赖包括数据库和消息系统。如果微服务本身或其任何依赖不可用，健康端点将响应`DOWN`（并返回HTTP状态码500）。
- en: We can also extend health endpoints to cover dependencies that Spring Boot is
    not aware of. We will use this feature to extend to the product composite’s `health`
    endpoint, so it also includes the health of the three core services. This means
    that the product composite `health` endpoint will only respond with `UP` if itself
    and the three core microservices are healthy. This can be used either manually
    or automatically by the `test-em-all.bash` script to find out when all the microservices
    and their dependencies are up and running.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以扩展健康端点以覆盖Spring Boot未知的依赖项。我们将使用此功能扩展到产品组合的`health`端点，使其也包含三个核心服务的健康状态。这意味着产品组合`health`端点只有在自身和三个核心微服务都健康时才会响应`UP`。这可以通过`test-em-all.bash`脚本的自动或手动方式来使用，以找出所有微服务和它们的依赖项何时都处于运行状态。
- en: 'In the `ProductCompositeIntegration` class, we have added helper methods for
    checking the health of the three core microservices, as follows:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ProductCompositeIntegration`类中，我们添加了检查三个核心微服务健康的辅助方法，如下所示：
- en: '[PRE41]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This code is similar to the code we used previously to call the core services
    to read APIs. Note that the health endpoint is, by default, set to `/actuator/health`.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码与我们之前用来调用核心服务读取API的代码类似。请注意，健康端点默认设置为`/actuator/health`。
- en: For the full source code, see the `ProductCompositeIntegration` class in the
    `product-composite` project.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整源代码，请参阅`product-composite`项目中的`ProductCompositeIntegration`类。
- en: 'In the configuration class, `HealthCheckConfiguration`, we use these helper
    methods to register a composite health check using the Spring Actuator class `CompositeReactiveHealthContributor`:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置类`HealthCheckConfiguration`中，我们使用这些辅助方法通过Spring Actuator类`CompositeReactiveHealthContributor`注册一个组合健康检查：
- en: '[PRE42]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: For the full source code, see the `HealthCheckConfiguration` class in the `product-composite`
    project.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整源代码，请参阅`product-composite`项目中的`HealthCheckConfiguration`类。
- en: 'Finally, in the `application.yml` configuration file of all four microservices,
    we configure the Spring Boot Actuator so that it does the following:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在所有四个微服务的`application.yml`配置文件中，我们配置Spring Boot Actuator以执行以下操作：
- en: Shows details about the state of health, which not only includes `UP` or `DOWN`,
    but also information about its dependencies
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示有关健康状态的所有详细信息，这不仅包括`UP`或`DOWN`，还包括其依赖项的信息
- en: Exposes all its endpoints over HTTP
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过HTTP暴露所有其端点
- en: 'The configuration for these two settings looks as follows:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个设置的配置如下：
- en: '[PRE43]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: For an example of the full source code, see the `application.yml` configuration
    file in the `product-composite` project.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整源代码的示例，请参阅`product-composite`项目中的`application.yml`配置文件。
- en: '**WARNING**: These configuration settings are helpful during development, but
    it can be a security issue to reveal too much information in actuator endpoints
    in production systems. Therefore, plan to minimize the information exposed by
    the actuator endpoints in production!'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告**：这些配置设置在开发期间很有帮助，但在生产系统中在Actuator端点中透露过多信息可能是一个安全问题。因此，计划在生产系统中最小化Actuator端点暴露的信息！'
- en: This can be done by replacing `"*"` with, for example, `health,info` in the
    setting of the `management.endpoints.web.exposure.include` property above.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过在上面的`management.endpoints.web.exposure.include`属性设置中将`"*"`替换为例如`health,info`来实现。
- en: For details regarding the endpoints that are exposed by Spring Boot Actuator,
    see [https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-endpoints.html](https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-endpoints.html).
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 有关Spring Boot Actuator暴露的端点的详细信息，请参阅[https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-endpoints.html](https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-endpoints.html)。
- en: 'The health endpoint can be used manually with the following command (don’t
    try it yet, wait until we have started up the microservice landscape below!):'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下命令手动使用健康端点（现在不要尝试，等待我们启动下面的微服务景观！）：
- en: '[PRE44]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'This will result in a response containing:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致包含以下内容的响应：
- en: '![Text  Description automatically generated](img/B19825_07_11.png)'
  id: totrans-413
  prefs: []
  type: TYPE_IMG
  zh: '![文本描述自动生成](img/B19825_07_11.png)'
- en: 'Figure 7.11: Health endpoint response'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.11：健康端点响应
- en: In the preceding output, we can see that the composite service reports that
    it is healthy; that is, its status is `UP`. At the end of the response, we can
    see that all three core microservices are also reported as healthy.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，我们可以看到组合服务报告它处于健康状态；也就是说，其状态是`UP`。在响应的末尾，我们可以看到所有三个核心微服务也被报告为健康。
- en: With a health API in place, we are ready to test our reactive microservices.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置了健康API之后，我们就准备好测试我们的响应式微服务了。
- en: Using RabbitMQ without using partitions
  id: totrans-417
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用不使用分区的RabbitMQ
- en: In this section, we will test the reactive microservices together with RabbitMQ
    but without using partitions.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将与RabbitMQ一起测试响应式微服务，但不使用分区。
- en: 'The default `docker-compose.yml` Docker Compose file is used for this configuration.
    The following changes have been added to the file:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的`docker-compose.yml` Docker Compose文件用于此配置。以下更改已添加到文件中：
- en: 'RabbitMQ has been added, as shown here:'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如此所示，已添加RabbitMQ：
- en: '[PRE45]'
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'From the declaration of RabbitMQ above, we can see that:'
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从上述RabbitMQ的声明中，我们可以看到：
- en: We use a Docker image for RabbitMQ v3.11.8 including the management plugin and
    Admin Web UI
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用包含管理插件和Admin Web UI的RabbitMQ v3.11.8 Docker镜像
- en: We expose the standard ports for connecting to RabbitMQ and the Admin Web UI,
    `5672` and `15672`
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们公开了连接到RabbitMQ和管理Web UI的标准端口，分别是`5672`和`15672`
- en: We add a health check so that Docker can find out when RabbitMQ is ready to
    accept connections
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们添加一个健康检查，以便Docker可以找出RabbitMQ何时准备好接受连接
- en: 'The microservices now have a dependency declared on the RabbitMQ service. This
    means that Docker will not start the microservice containers until the RabbitMQ
    service is reported to be healthy:'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务现在在RabbitMQ服务上声明了依赖关系。这意味着Docker不会启动微服务容器，直到RabbitMQ服务报告为健康状态：
- en: '[PRE46]'
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'To run manual tests, perform the following steps:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行手动测试，请执行以下步骤：
- en: 'Build and start the system landscape with the following commands:'
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令构建和启动系统景观：
- en: '[PRE47]'
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Now, we have to wait for the microservice landscape to be up and running. Try
    running the following command a few times:'
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们必须等待微服务景观启动并运行。尝试运行以下命令几次：
- en: '[PRE48]'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: When it returns `UP`, we are ready to run our tests!
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当它返回`UP`时，我们就准备好运行我们的测试了！
- en: 'First, create a composite product with the following commands:'
  id: totrans-434
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，使用以下命令创建一个复合产品：
- en: '[PRE49]'
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: When using Spring Cloud Stream together with RabbitMQ, it will create one RabbitMQ
    exchange per topic and a set of queues, depending on our configuration. Let’s
    see what queues Spring Cloud Stream has created for us!
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当使用Spring Cloud Stream与RabbitMQ一起使用时，它将为每个主题创建一个RabbitMQ交换机以及一组队列，具体取决于我们的配置。让我们看看Spring
    Cloud Stream为我们创建了哪些队列！
- en: 'Open the following URL in a web browser: `http://localhost:15672/#/queues`.
    Log in with the default username/password `guest`/`guest`. You should see the
    following queues:![Graphical user interface, application, table  Description automatically
    generated](img/B19825_07_12.png)Figure 7.12: List of queues'
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在网页浏览器中打开以下URL：`http://localhost:15672/#/queues`。使用默认用户名/密码`guest`/`guest`登录。你应该能看到以下队列：![图形用户界面，应用程序，表格  自动生成的描述](img/B19825_07_12.png)图7.12：队列列表
- en: For each topic, we can see one queue for the **auditGroup**, one queue for the
    consumer group that’s used by the corresponding core microservice, and one dead-letter
    queue. We can also see that the **auditGroup** queues contain messages, as expected!
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于每个主题，我们可以看到一个用于**auditGroup**的队列，一个用于对应核心微服务的消费者组的队列，以及一个死信队列。我们还可以看到，**auditGroup**队列包含消息，正如预期的那样！
- en: 'Click on the **products.auditGroup** queue and scroll down to the **Get messages**
    section, expand it, and click on the button named **Get Message(s)** to see the
    message in the queue:![Graphical user interface, text, application, email  Description
    automatically generated](img/B19825_07_13.png)Figure 7.13: Viewing the message
    in the queue'
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**products.auditGroup**队列，并滚动到**获取消息**部分，展开它，然后点击名为**获取消息(s)**的按钮以查看队列中的消息：![图形用户界面，文本，应用程序，电子邮件  自动生成的描述](img/B19825_07_13.png)图7.13：查看队列中的消息
- en: From the preceding screenshot, note the **Payload** but also the header **partitionKey**,
    which we will use in the next section where we try out RabbitMQ with partitions.
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从前面的屏幕截图，注意**Payload**，但也注意头部**partitionKey**，我们将在下一节中尝试使用分区来测试RabbitMQ。
- en: 'Next, try to get the product composite using the following code:'
  id: totrans-441
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，尝试使用以下代码获取产品组合：
- en: '[PRE50]'
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Finally, delete it with the following command:'
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用以下命令删除它：
- en: '[PRE51]'
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Try to get the deleted product again. It should result in a `404 - "NotFound"`
    response!
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试再次获取已删除的产品。这应该导致一个`404 - "NotFound"`响应！
- en: If you look in the RabbitMQ audit queues again, you should be able to find new
    messages containing delete events.
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您再次查看RabbitMQ审计队列，应该能够找到包含删除事件的新的消息。
- en: 'Wrap up the test by bringing down the microservice landscape with the following
    command:'
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令关闭微服务景观来结束测试：
- en: '[PRE52]'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: This completes the tests where we use RabbitMQ without partitions. Now, let’s
    move on and test RabbitMQ with partitions.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了我们使用不带分区的 RabbitMQ 的测试。现在，让我们继续测试带有分区的 RabbitMQ。
- en: Using RabbitMQ with partitions
  id: totrans-450
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用带有分区的 RabbitMQ
- en: Now, let’s try out the partitioning support in Spring Cloud Stream!
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试 Spring Cloud Stream 中的分区支持！
- en: 'We have a separate Docker Compose file prepared for using RabbitMQ with two
    partitions per topic: `docker-compose-partitions.yml`. It will also start two
    instances per core microservice, one for each partition. For example, a second
    `product` instance is configured as follows:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为使用每个主题两个分区的 RabbitMQ 准备了一个单独的 Docker Compose 文件：`docker-compose-partitions.yml`。它还将为每个核心微服务启动两个实例，每个分区一个。例如，第二个
    `product` 实例配置如下：
- en: '[PRE53]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Here is an explanation of the preceding configuration:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对先前配置的解释：
- en: We use the same source code and Dockerfile that we did for the first `product`
    instance but configure them differently.
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用与第一个 `product` 实例相同的源代码和 Dockerfile，但进行不同的配置。
- en: To make all microservice instances aware that they will use partitions, we have
    added the Spring profile `streaming_partitioned` to their environment variable
    `SPRING_PROFILES_ACTIVE`.
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了让所有微服务实例都知道它们将使用分区，我们在它们的 `SPRING_PROFILES_ACTIVE` 环境变量中添加了 Spring 配置文件 `streaming_partitioned`。
- en: We assign the two `product` instances to different partitions using different
    Spring profiles. The Spring profile `streaming_instance_0` is used by the first
    product instance and `streaming_instance_1` is used by the second instance, `product-p1`.
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用不同的 Spring 配置文件将两个 `product` 实例分配到不同的分区。第一个产品实例使用 Spring 配置文件 `streaming_instance_0`，第二个实例
    `product-p1` 使用 `streaming_instance_1`。
- en: The second `product` instance will only process asynchronous events; it will
    not respond to API calls. Since it has a different name, `product-p1` (also used
    as its DNS name), it will not respond to calls to a URL starting with `http://product:8080`.
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个 `product` 实例将仅处理异步事件；它不会响应 API 调用。由于它有一个不同的名称，`product-p1`（也用作其 DNS 名称），它不会响应以
    `http://product:8080` 开头的 URL 调用。
- en: 'Start up the microservice landscape with the following command:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令启动微服务景观：
- en: '[PRE54]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Create a composite product in the same way as for the tests in the previous
    section but also create a composite product with the product ID set to `2`. If
    you take a look at the queues set up by Spring Cloud Stream, you will see one
    queue per partition and that the product audit queues now contain one message
    each; the event for product ID `1` was placed in one partition and the event for
    product ID `2` was placed in the other partition.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 以与上一节测试相同的方式创建一个复合产品，但还要创建一个产品 ID 设置为 `2` 的复合产品。如果您查看 Spring Cloud Stream 设置的队列，您将看到每个分区一个队列，并且产品审计队列现在每个都包含一条消息；产品
    ID `1` 的事件被放置在一个分区中，而产品 ID `2` 的事件被放置在另一个分区中。
- en: 'If you go back to `http://localhost:15672/#/queues` in your web browser, you
    should see something like the following:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在网页浏览器中返回到 `http://localhost:15672/#/queues`，您应该看到以下内容：
- en: '![Graphical user interface, application  Description automatically generated](img/B19825_07_14.png)'
  id: totrans-463
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，应用描述自动生成](img/B19825_07_14.png)'
- en: 'Figure 7.14: List of queues'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14：队列列表
- en: 'To end the test with RabbitMQ using partitions, bring down the microservice
    landscape with the following command:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用分区结束 RabbitMQ 的测试，请使用以下命令关闭微服务景观：
- en: '[PRE55]'
  id: totrans-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: We are now done with tests using RabbitMQ, both with and without partitions.
    The final test configuration we shall try out is testing the microservices together
    with Kafka.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在完成了使用 RabbitMQ 的测试，无论是带分区还是不带分区。我们将尝试的最终测试配置是测试与 Kafka 一起的微服务。
- en: Using Kafka with two partitions per topic
  id: totrans-468
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用每个主题两个分区的 Kafka
- en: 'Now, we shall try out a very cool feature of Spring Cloud Stream: changing
    the messaging system from RabbitMQ to Apache Kafka!'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将尝试 Spring Cloud Stream 的一个非常酷的功能：将消息系统从 RabbitMQ 更改为 Apache Kafka！
- en: 'This can be done simply by changing the value of the `spring.cloud.stream.defaultBinder`
    property from `rabbit` to `kafka`. This is handled by the `docker-compose-kafka.yml`
    Docker Compose file, which has also replaced RabbitMQ with Kafka and ZooKeeper.
    The configuration of Kafka and ZooKeeper looks as follows:'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过简单地更改 `spring.cloud.stream.defaultBinder` 属性的值从 `rabbit` 到 `kafka` 来完成。这由
    `docker-compose-kafka.yml` Docker Compose 文件处理，该文件还用 Kafka 和 ZooKeeper 替换了 RabbitMQ。Kafka
    和 ZooKeeper 的配置如下所示：
- en: '[PRE56]'
  id: totrans-471
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Kafka is also configured to use two partitions per topic, and like before, we
    start up two instances per core microservice, one for each partition. See the
    Docker Compose file, `docker-compose-kafka.yml`, for details!
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka也被配置为每个主题使用两个分区，并且像之前一样，我们为每个核心微服务启动两个实例，每个分区一个。有关详细信息，请参阅Docker Compose文件`docker-compose-kafka.yml`！
- en: 'Start up the microservice landscape with the following command:'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令启动微服务景观：
- en: '[PRE57]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Repeat the tests from the previous section: create two products, one with the
    product ID set to `1` and one with the product ID set to `2`.'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 重复上一节的测试：创建两个产品，一个产品ID设置为`1`，另一个产品ID设置为`2`。
- en: Unfortunately, Kafka doesn’t come with any graphical tools that can be used
    to inspect topics, partitions, and the messages that are placed within them. Instead,
    we can run CLI commands in the Kafka Docker container.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 很遗憾，Kafka没有附带任何可以用来检查主题、分区以及其中消息的图形工具。相反，我们可以在Kafka Docker容器中运行CLI命令。
- en: 'To see a list of topics, run the following command:'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看主题列表，请运行以下命令：
- en: '[PRE58]'
  id: totrans-478
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Expect an output like the one shown here:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 预期输出将类似于以下所示：
- en: '![Graphical user interface, text, application  Description automatically generated](img/B19825_07_15.png)'
  id: totrans-480
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，文本，应用程序  自动生成的描述](img/B19825_07_15.png)'
- en: 'Figure 7.15: Viewing a list of topics'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.15：查看主题列表
- en: 'Here is what we see in the preceding output:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中我们看到的是：
- en: The topics prefixed with `error` are the topics corresponding to dead-letter
    queues.
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前缀为`error`的主题是对应死信队列的主题。
- en: You will not find any `auditGroup` groups as in the case of RabbitMQ. Since
    events are retained in the topics by Kafka, even after consumers have processed
    them, there is no need for an extra `auditGroup` group.
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你将找不到像RabbitMQ那样的`auditGroup`组。由于事件在Kafka中被保留在主题中，即使消费者已经处理了它们，因此不需要额外的`auditGroup`组。
- en: 'To see the partitions in a specific topic, for example, the `products` topic,
    run the following command:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看特定主题的分区，例如`products`主题，请运行以下命令：
- en: '[PRE59]'
  id: totrans-486
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Expect an output like the one shown here:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 预期输出将类似于以下所示：
- en: '![Graphical user interface, text  Description automatically generated](img/B19825_07_16.png)'
  id: totrans-488
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，文本  自动生成的描述](img/B19825_07_16.png)'
- en: 'Figure 7.16: Viewing partitions in the products topic'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.16：查看产品主题中的分区
- en: 'To see all the messages in a specific partition, for example, partition `1`
    in the `products` topic, run the following command:'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看特定分区的所有消息，例如`products`主题中的分区`1`，请运行以下命令：
- en: '[PRE60]'
  id: totrans-491
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Expect an output like the one shown here:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 预期输出将类似于以下所示：
- en: '![Graphical user interface, text  Description automatically generated](img/B19825_07_17.png)'
  id: totrans-493
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，文本  自动生成的描述](img/B19825_07_17.png)'
- en: 'Figure 7.17: Viewing all messages in partition 1 in the products topic'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.17：查看产品主题中分区1的所有消息
- en: The output will end with a timeout exception since we stop the command by specifying
    a timeout for the command of `1000` ms.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将以超时异常结束，因为我们通过指定命令的`1000`毫秒超时来停止命令。
- en: 'Bring down the microservice landscape with the following command:'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令关闭微服务景观：
- en: '[PRE61]'
  id: totrans-497
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Now, we have learned how Spring Cloud Stream can be used to switch a message
    broker from RabbitMQ to Kafka without requiring any changes in the source code.
    It just requires a few changes in the Docker Compose file.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经学会了如何使用Spring Cloud Stream将消息代理从RabbitMQ切换到Kafka，而无需在源代码中进行任何更改。只需在Docker
    Compose文件中进行一些更改即可。
- en: Let’s move on to the last section of this chapter, learning how to run these
    tests automatically!
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续本章的最后部分，学习如何自动运行这些测试！
- en: Running automated tests of the reactive microservice landscape
  id: totrans-500
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行反应式微服务景观的自动化测试
- en: 'To be able to run tests of the reactive microservice landscape automatically
    instead of manually, the automated `test-em-all.bash` test script has been enhanced.
    The most important changes are as follows:'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够自动运行反应式微服务景观的测试而不是手动运行，已经增强了自动的`test-em-all.bash`测试脚本。最重要的更改如下：
- en: 'The script uses the new `health` endpoint to know when the microservice landscape
    is operational, as shown here:'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 脚本使用新的`health`端点来了解微服务景观何时处于运行状态，如下所示：
- en: '[PRE62]'
  id: totrans-503
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: The script has a new `waitForMessageProcessing()` function, which is called
    after the test data is set up. Its purpose is simply to wait for the creation
    of the test data to be completed by the asynchronous create services.
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 脚本新增了一个`waitForMessageProcessing()`函数，它在测试数据设置完成后被调用。其目的是简单地等待异步创建服务完成测试数据的创建。
- en: 'To use the test script to automatically run the tests with RabbitMQ and Kafka,
    perform the following steps:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用测试脚本自动运行带有 RabbitMQ 和 Kafka 的测试，请执行以下步骤：
- en: 'Run the tests using the default Docker Compose file, that is, with RabbitMQ
    without partitions, with the following commands:'
  id: totrans-506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用默认的 Docker Compose 文件运行测试，即使用不带分区的 RabbitMQ，以下命令：
- en: '[PRE63]'
  id: totrans-507
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Run the tests for RabbitMQ with two partitions per topic using the Docker Compose
    `docker-compose-partitions.yml` file with the following commands:'
  id: totrans-508
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Docker Compose `docker-compose-partitions.yml` 文件，通过以下命令为 RabbitMQ 运行测试，每个主题两个分区：
- en: '[PRE64]'
  id: totrans-509
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Finally, run the tests with Kafka and two partitions per topic using the Docker
    Compose `docker-compose-kafka.yml` file with the following commands:'
  id: totrans-510
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用 Kafka 和每个主题两个分区，通过以下命令使用 Docker Compose `docker-compose-kafka.yml` 文件运行测试：
- en: '[PRE65]'
  id: totrans-511
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: In this section, we have learned how to use the `test-em-all.bash` test script
    to automatically run tests of the reactive microservice landscape, which has been
    configured to use either RabbitMQ or Kafka as its message broker.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了如何使用 `test-em-all.bash` 测试脚本自动运行配置为使用 RabbitMQ 或 Kafka 作为其消息代理的反应式微服务景观的测试。
- en: Summary
  id: totrans-513
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have seen how we can develop reactive microservices!
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到了我们如何开发反应式微服务！
- en: Using Spring WebFlux and Spring WebClient, we can develop non-blocking synchronous
    APIs that can handle incoming HTTP requests and send outgoing HTTP requests without
    blocking any threads. Using Spring Data’s reactive support for MongoDB, we can
    also access MongoDB databases in a non-blocking way, that is, without blocking
    any threads while waiting for responses from the database. Spring WebFlux, Spring
    WebClient, and Spring Data rely on Project Reactor to provide their reactive and
    non-blocking features. When we must use blocking code, for example, when using
    Spring Data for JPA, we can encapsulate the processing of the blocking code by
    scheduling the processing of it in a dedicated thread pool.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Spring WebFlux 和 Spring WebClient，我们可以开发非阻塞同步 API，这些 API 可以处理传入的 HTTP 请求并发送出去的
    HTTP 请求，而不会阻塞任何线程。使用 Spring Data 对 MongoDB 的反应式支持，我们也可以以非阻塞的方式访问 MongoDB 数据库，即在等待数据库响应时不阻塞任何线程。Spring
    WebFlux、Spring WebClient 和 Spring Data 依赖于 Project Reactor 来提供它们的反应式和非阻塞特性。当我们必须使用阻塞代码时，例如使用
    Spring Data for JPA，我们可以通过在专用线程池中安排阻塞代码的处理来封装阻塞代码的处理。
- en: We have also seen how Spring Data Stream can be used to develop event-driven
    asynchronous services that work on both RabbitMQ and Kafka as messaging systems
    without requiring any changes in the code. By doing some configuration, we can
    use features in Spring Cloud Stream such as consumer groups, retries, dead-letter
    queues, and partitions to handle the various challenges of asynchronous messaging.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到了如何使用 Spring Data Stream 来开发在 RabbitMQ 和 Kafka 作为消息系统上工作的事件驱动异步服务，而无需对代码进行任何更改。通过进行一些配置，我们可以使用
    Spring Cloud Stream 中的功能，如消费者组、重试、死信队列和分区来处理异步消息的各个挑战。
- en: We have also learned how to manually and automatically test a system landscape
    consisting of reactive microservices.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还学习了如何手动和自动测试由反应式微服务组成的系统景观。
- en: This was the final chapter on how to use fundamental features in Spring Boot
    and Spring Framework.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关于如何使用 Spring Boot 和 Spring Framework 的基本特性的最后一章。
- en: Next up is an introduction to Spring Cloud and how it can be used to make our
    services production-ready, scalable, robust, configurable, secure, and resilient!
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是 Spring Cloud 的介绍以及如何使用它使我们的服务达到生产就绪、可扩展、健壮、可配置、安全且具有弹性的状态！
- en: Questions
  id: totrans-520
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Why is it important to know how to develop reactive microservices?
  id: totrans-521
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么了解如何开发反应式微服务很重要？
- en: How do you choose between non-blocking synchronous APIs and event-/message-driven
    asynchronous services?
  id: totrans-522
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你是如何在非阻塞同步 API 和事件/消息驱动异步服务之间进行选择的？
- en: What makes an event different from a message?
  id: totrans-523
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 事件与消息有什么不同？
- en: Name some challenges with message-driven asynchronous services. How do we handle
    them?
  id: totrans-524
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列举一些与消息驱动异步服务相关的挑战。我们如何处理它们？
- en: Why is the following test not failing?
  id: totrans-525
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么以下测试没有失败？
- en: '[PRE66]'
  id: totrans-526
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: First, ensure that the test fails. Next, correct the test so that it succeeds.
  id: totrans-527
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，确保测试失败。接下来，修正测试使其成功。
- en: What are the challenges of writing tests with reactive code using JUnit, and
    how can we handle them?
  id: totrans-528
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 JUnit 编写反应式代码的测试有哪些挑战，我们如何处理它们？
