- en: Error Handling and Best Practices
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 错误处理和最佳实践
- en: Serverless architectures are different enough that techniques and best practices
    need to be thought through and evaluated to be successful. Many traditional methods
    for debugging, application development, monitoring, and so on are still applicable
    in a server-based architecture. However, many tried-and-tested techniques that
    you may rely on when working with virtual machines or real hardware will not necessarily
    work with serverless systems. When building on top of a FaaS platform, then, you
    need to keep these differences in mind and have a plan for monitoring, debugging,
    testing, and developing your serverless application.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器架构的不同之处足够大，以至于需要仔细思考和评估技术及最佳实践才能成功。许多传统的调试、应用程序开发、监控等方法在基于服务器的架构中仍然适用。然而，许多你可能依赖的经过验证的技术，在处理虚拟机或真实硬件时可能并不一定适用于无服务器系统。因此，在基于FaaS平台构建时，你需要记住这些差异，并制定监控、调试、测试和开发无服务器应用程序的计划。
- en: In this chapter, we'll review common best practices that will help you to focus
    on building your application rather than getting stuck in the details of organization
    or deployment. We'll also cover the tools and methods available for keeping your
    serverless application secure, easy to develop locally, and observable. We'll
    also discuss the changes you will need to make to track errors and monitor serverless
    applications reliably.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '在本章中，我们将回顾一些常见的最佳实践，这些实践将帮助你专注于构建应用程序，而不是陷入组织或部署的细节。我们还将介绍可用于保持你的无服务器应用程序安全、易于本地开发以及可观察的工具和方法。我们还将讨论你需要做出的更改，以可靠地跟踪错误和监控无服务器应用程序。 '
- en: It's worth noting here that one could dedicate an entire book to best practices
    for serverless applications. This chapter is not exhaustive by any means, but
    it will cover many topics which will definitely help to improve your serverless
    development experience and the overall quality of your application.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，可以专门写一本书来介绍无服务器应用程序的最佳实践。本章并非详尽无遗，但它将涵盖许多肯定有助于提高你的无服务器开发体验和应用程序整体质量的主题。
- en: 'By the end of this chapter, you can expect to understand the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你可以期待理解以下主题：
- en: How to set up your application to track unexpected errors with Sentry and Rollbar
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何设置你的应用程序以使用Sentry和Rollbar跟踪意外错误
- en: Working with cold starts
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理冷启动
- en: Monitoring and alerting around errors, exceptions, or performance degradation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控和警报错误、异常或性能下降
- en: Local development and testing
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地开发和测试
- en: How to manage configuration via environment variables across different stacks
    (development versus production)
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何通过环境变量在不同堆栈（开发与生产）之间管理配置
- en: How to encrypt sensitive environment variables to keep your application secure
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何加密敏感的环境变量以保护你的应用程序安全
- en: Error tracking
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 错误跟踪
- en: Practically speaking, all software systems crash at some point. One of the reasons
    I love working with serverless systems so much is that they, by their very nature,
    keep an application relatively small and more akin to a microservice, rather than
    a broad monolithic application. This fact by itself can drastically reduce the
    number of ways an application can fail. However, at some point, it will fail,
    and an exception you didn't expect will occur. What, then, is the best way to
    handle unexpected exceptions in a serverless system?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 从实际的角度来看，所有的软件系统最终都会崩溃。我之所以非常喜欢与无服务器系统一起工作，其中一个原因就是它们本质上使得应用程序相对较小，更接近于微服务，而不是一个庞大的单体应用程序。这个事实本身就可以极大地减少应用程序可能失败的方式。然而，在某个时刻，它终究会失败，并且会出现你未曾预料到的异常。那么，在无服务器系统中处理意外异常的最佳方法是什么呢？
- en: The good news here is that we have multiple options, and that some systems you
    may already be familiar with can work in the same way as they would in a non-serverless
    system. In the following sections, we'll walk through the steps for integrating
    two popular error tracking services, Sentry and Rollbar. Both services offer similar
    functionality and are equally easy to set up. In the following examples, we'll
    be using Python, but both Sentry and Rollbar support a myriad of languages including
    Node.js, Java, Golang, and C#.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，我们有多种选择，而且你可能已经熟悉的某些系统可以以与无服务器系统相同的方式工作。在接下来的章节中，我们将介绍集成两个流行的错误跟踪服务Sentry和Rollbar的步骤。这两个服务提供类似的功能，并且同样易于设置。在下面的示例中，我们将使用Python，但Sentry和Rollbar支持包括Node.js、Java、Golang和C#在内的多种语言。
- en: Integrating Sentry for error tracking
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成 Sentry 进行错误跟踪
- en: I have used Sentry for many years and highly recommend it. It has a vast feature
    set and many prominent companies use the service. Sentry's free plan gives you
    10,000 events per month, a single login, and a seven-day history of quickly. Whether
    it's for a hobby project or even a medium-scale production system, this free plan
    works out quite well.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经使用了 Sentry 多年，并强烈推荐它。它具有庞大的功能集，许多知名公司都在使用这项服务。Sentry 的免费计划每月提供 10,000 个事件，一个登录账号，以及快速查看七天的历史记录。无论是用于爱好项目还是中等规模的生产系统，这个免费计划都非常适用。
- en: 'To integrate Sentry with your serverless function, you''ll, of course, need
    a Sentry account. Following is a code block for an elementary AWS Lambda function.
    All it will do is calculate the quotient of two numbers. Our goal is to ensure
    that any unhandled exceptions are captured and reported somewhere so that we have
    visibility into what our application is doing and have as much information as
    possible with which to debug it:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 Sentry 集成到您的无服务器函数中，您当然需要一个 Sentry 账户。以下是一个基本的 AWS Lambda 函数的代码块。它所做的只是计算两个数字的商。我们的目标是确保任何未处理的异常都被捕获并报告到某个地方，这样我们就可以了解我们的应用程序正在做什么，并尽可能多地获取调试所需的信息：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We''ve set this up with API Gateway, so we can execute it using `curl` and
    get results for two numbers, as shown in the following snippet:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经使用 API Gateway 设置了它，因此我们可以使用 `curl` 执行它，并获取两个数字的结果，如下面的片段所示：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s see what happens when we divide this by `0`, which we know is undefined
    in mathematics:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看当我们除以 `0` 时会发生什么，我们知道这在数学中是未定义的：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As an application developer, I have no way of knowing that this error has occurred
    as there is no monitoring in place. The only way I can know that an error has
    happened is if I log into the AWS console and look at the execution metrics for
    my Lambda function, or if I happen to be reading through the CloudWatch Logs.
    Of course, you can''t be manually watching for errors day and night. The following
    screenshot shows Invocation errors from the AWS Lambda monitoring page for the `divide`
    function:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名应用程序开发者，我无法知道这个错误是否发生，因为没有设置监控。我唯一知道错误发生的方法是登录 AWS 控制台并查看 Lambda 函数的执行指标，或者我偶然在阅读
    CloudWatch 日志。当然，你不能日夜手动监视错误。以下截图显示了 AWS Lambda 监控页面中 `divide` 函数的调用错误：
- en: '![](img/d9bfc0e4-0e6f-4ec6-9acb-42b4e03bca55.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d9bfc0e4-0e6f-4ec6-9acb-42b4e03bca55.png)'
- en: AWS CloudWatch chart from the Lambda screen, showing a count of the number of
    errors
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 Lambda 屏幕的 AWS CloudWatch 图表，显示了错误数量的计数
- en: 'CloudWatch will capture `stdout` and `stderr` for Lambda functions. Because
    unhandled exceptions are written to `stderr`, we can see the details when looking
    at the CloudWatch logs, as shown in the following screenshot:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: CloudWatch 将捕获 Lambda 函数的 `stdout` 和 `stderr`。因为未处理的异常被写入 `stderr`，所以当我们查看 CloudWatch
    日志时可以看到详细信息，如下面的截图所示：
- en: '![](img/893e8ebd-3c60-4132-adbc-7478e7454366.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/893e8ebd-3c60-4132-adbc-7478e7454366.png)'
- en: AWS CloudWatch logs, showing an unhandled exception due to division by zero
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: AWS CloudWatch 日志，显示了由于除以零而引发的未处理异常
- en: 'Integrating Sentry will capture unexpected errors, store them, and notify us
    via various delivery mechanisms. Getting Sentry reporting for our Lambda functions
    is quite easy. For Python, you can use the `raven-python-lambda` ([https://github.com/Netflix-Skunkworks/raven-python-lambda](https://github.com/Netflix-Skunkworks/raven-python-lambda))
    library and add a decorator around handler functions, as shown in the following
    snippet:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 集成 Sentry 将捕获意外错误，存储它们，并通过各种交付机制通知我们。为我们的 Lambda 函数获取 Sentry 报告相当简单。对于 Python，您可以使用
    `raven-python-lambda` ([https://github.com/Netflix-Skunkworks/raven-python-lambda](https://github.com/Netflix-Skunkworks/raven-python-lambda))
    库，并在处理函数周围添加装饰器，如下面的片段所示：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The only other bit of configuration we need to take care of here is setting
    the Sentry DSN, which tells the library where to send its payload when an error
    occurs. Doing this is it''s just a matter of passing the values from the host
    system''s environment variables into the Lambda function''s environment variables.
    Using the Serverless Framework, this is quite easy, as you can see:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们需要处理的唯一其他配置是设置 Sentry DSN，它告诉库在发生错误时将有效载荷发送到哪里。这样做只是将主机系统的环境变量值传递到 Lambda
    函数的环境变量中。使用 Serverless Framework，这相当简单，如下所示：
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now Sentry will capture any unhandled exceptions and, at a minimum, email them
    to us. In the following screenshot, you can see a list of various exceptions.
    What is neat is that some of these errors were not even deliberate. As you can
    see in the last row, I misspelled a variable name which caused my division calculation
    to throw an error:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 Sentry 会捕获任何未处理的异常，并且至少会将它们通过电子邮件发送给我们。在以下截图中，你可以看到各种异常的列表。很酷的是，其中一些错误甚至不是故意的。正如你在最后一行看到的，我拼写了一个变量名，这导致我的除法计算抛出了错误：
- en: '![](img/3eb588c9-6f0c-4ab4-9a3c-9fd7972095f5.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3eb588c9-6f0c-4ab4-9a3c-9fd7972095f5.png)'
- en: 'Clicking on any of these errors gives us more context into the state of our
    application when the exception was triggered, as shown in the following screenshot:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 点击任何这些错误都会给我们更多关于异常触发时应用程序状态的上下文，如下面的截图所示：
- en: '![](img/e17540fc-b1e4-4260-8077-10f423973e56.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e17540fc-b1e4-4260-8077-10f423973e56.png)'
- en: 'Another lovely feature of the `raven-python-lambda` library is that it will
    raise warnings when your function is getting too close to its timeout value or
    its maximum allocated memory. To test this, we need to set the timeout of the
    `divide` function to 4 seconds and put `time.sleep(3)` in the middle of the application
    code. After executing the divide Lambda function, you should get a result as expected.
    You will also receive an email about the slow execution speed and see the same
    warning on the Sentry website, as shown in the following screenshot:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`raven-python-lambda` 库的另一个出色功能是，当你的函数接近其超时值或最大分配内存时，它会发出警告。为了测试这一点，我们需要将 `divide`
    函数的超时设置为 4 秒，并在应用程序代码的中间放置 `time.sleep(3)`。执行除法 Lambda 函数后，你应该得到预期的结果。你还会收到关于慢速执行速度的电子邮件，并在
    Sentry 网站上看到相同的警告，如下面的截图所示：'
- en: '![](img/ca4319f3-7be6-4f5f-9b9f-f5cd85f49138.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ca4319f3-7be6-4f5f-9b9f-f5cd85f49138.png)'
- en: 'There is much more information included with each exception to help you while
    debugging on the Sentry website. There are also many more features in Sentry that
    we don''t have room for here; however, a few features worth noting are as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Sentry 网站上，每个异常都包含大量信息，有助于你在调试时使用。此外，Sentry 还有很多我们在这里没有空间详细说明的功能；然而，以下是一些值得注意的功能：
- en: Chat integration (Slack, IRC, etc.)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天集成（Slack、IRC 等）
- en: Tracking deployments
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪部署
- en: Issue rollup and status tracking
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题汇总和状态跟踪
- en: Integrating Rollbar
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成 Rollbar
- en: Rollbar plays the same role as Sentry. Integration is equally as simple. We
    will still use a decorator for our handler functions, but we'll need a different
    library with Rollbar. Rollbar provides an official library for Python ([https://github.com/rollbar/pyrollbar](https://github.com/rollbar/pyrollbar))
    and many other languages.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Rollbar 与 Sentry 扮演相同的角色。集成同样简单。我们仍然会为我们的处理函数使用装饰器，但我们需要一个不同的库来与 Rollbar 一起使用。Rollbar
    为 Python 提供了官方库 ([https://github.com/rollbar/pyrollbar](https://github.com/rollbar/pyrollbar))
    以及许多其他语言。
- en: The setup changes slightly with `pyrollbar`, but it's nothing too complicated.
    The following code block shows how to set up an AWS Lambda function for error
    tracking with Rollbar.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `pyrollbar` 进行设置时，变化略有不同，但并不复杂。以下代码块展示了如何为错误跟踪设置 AWS Lambda 函数：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: When we hit an exception, information is delivered to Rollbar. Again, an email
    notification about the `ZeroDivisionError` should be received. Just like Sentry,
    there are plenty of integrations from Rollbar.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们遇到异常时，信息会被发送到 Rollbar。再次强调，应该会收到关于 `ZeroDivisionError` 的电子邮件通知。就像 Sentry
    一样，Rollbar 也有很多集成。
- en: 'The following screenshot shows error details displayed on the Rollbar website:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了在 Rollbar 网站上显示的错误详情：
- en: '![](img/d90ac957-6dfc-43b4-8f62-aeffa0946987.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d90ac957-6dfc-43b4-8f62-aeffa0946987.png)'
- en: Logging
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 记录日志
- en: Tracking exceptions and problems within your application is critical; however,
    there will inevitably be cases where you wish you had more insight into the state
    of your application when a problem occurs. For this task, you will need to set
    yourself up with a good logging strategy. Log messages are a tool we have used
    for a very long time - and still use often. Very often, log messages are sent
    to files on disk and then shipped off to a log aggregator. Since we don't have
    access to these same types of logging system in a serverless architecture, we'll
    need to come up with something new.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪应用程序中的异常和问题至关重要；然而，不可避免地会有一些情况，你希望当问题发生时能更深入地了解应用程序的状态。为此任务，你需要为自己制定一个良好的日志记录策略。日志消息是我们使用很长时间的工具——并且仍然经常使用。非常经常，日志消息会被发送到磁盘上的文件，然后被发送到日志聚合器。由于在无服务器架构中我们没有访问这些相同类型的日志系统，我们需要想出一些新的方法。
- en: AWS Lambda functions and other FaaS providers offer some mechanisms for keeping
    track of `stdout` and `stderr` streams. In the case of Lambda, any `print` statements
    or other error messages will end up in CloudWatch Logs. This delivery to CloudWatch
    happens automatically, and is especially useful as you'll always know where to
    go to check for errors or debugging statements. While this is a helpful feature,
    there are a few improvements we can make to your logging statements so that they're
    easier to search through, find, and categorize.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Lambda函数和其他FaaS提供商提供了一些跟踪`stdout`和`stderr`流的方法。在Lambda的情况下，任何`print`语句或其他错误消息最终都会出现在CloudWatch日志中。这种向CloudWatch的交付是自动发生的，并且特别有用，因为你可以始终知道去哪里检查错误或调试语句。虽然这是一个有用的功能，但我们可以对日志语句进行一些改进，以便它们更容易搜索、查找和分类。
- en: Structuring log messages
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结构化日志消息
- en: Log messages are often used as plain strings via `console.log` or `print` statements.
    These quick and dirty additions to code can be helpful during development but
    won't suffice in a production-level system. Rather than logging flat strings,
    log statements need to be structured so that you can easily find the bits of information
    you're looking for. JSON is an excellent choice for a format since it's widely
    used among different log aggregator services and easy to implement in practically
    any language.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 日志消息通常通过`console.log`或`print`语句作为纯字符串使用。这些在开发期间快速且简单的添加可能很有帮助，但在生产级系统中是不够的。而不是记录平面字符串，日志语句需要被结构化，这样你就可以轻松地找到你想要的信息块。JSON是一个很好的格式选择，因为它在许多不同的日志聚合器服务中广泛使用，并且在任何实际语言中实现起来都很简单。
- en: 'Let''s take the simple case of our previous divide function. At some point,
    we may want to understand how people are using our service: specifically, what
    numerator and denominators they''re sending us. To do this, we will need to structure
    some log messages so that we can quickly search through them, pull out the pertinent
    information, and finally analyze it. The following code block shows some Python
    code to bootstrap the `structlog` library. This library will take care of logging
    structured messages, rather than the flat messages we usually get from the standard
    library''s `logging` module:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以我们之前的除法函数为例。在某个时候，我们可能想了解人们是如何使用我们的服务的：具体来说，他们发送给我们的分子和分母是什么。为此，我们需要构建一些日志消息，以便我们可以快速搜索它们，提取相关信息，并最终进行分析。以下代码块展示了启动`structlog`库的一些Python代码。这个库将负责记录结构化消息，而不是我们从标准库的`logging`模块通常得到的那种平面消息：
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In our divide function, we can now log any data we find interesting as key-value
    pairs, shown as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的除法函数中，我们现在可以记录任何我们感兴趣的数据，如下所示，以键值对的形式：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Log messages will now arrive in CloudWatch as JSON-formatted objects rather
    than Python strings, as shown in the following screenshot:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 日志消息现在将以JSON格式作为对象而不是Python字符串的形式到达CloudWatch，如下面的截图所示：
- en: '![](img/423f0ced-92b0-4a3c-aaec-b420d60f7aef.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/423f0ced-92b0-4a3c-aaec-b420d60f7aef.png)'
- en: This has merely set us up for success; next, we'll work on getting these structured
    log messages to a log aggregator for better discoverability, analysis, and integration
    with other services.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这仅仅为我们成功奠定了基础；接下来，我们将努力将这些结构化日志消息发送到日志聚合器，以便更好地发现、分析和与其他服务的集成。
- en: Digesting structured logs
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结构化日志解析
- en: 'Today, there is a myriad of dedicated logging services, such as:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，有大量的专用日志服务，例如：
- en: Loggly
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Loggly
- en: Sumo Logic
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sumo Logic
- en: Splunk
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Splunk
- en: Papertrail
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Papertrail
- en: Hosted ELK
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主机ELK
- en: The list could go on and on. Many of these hosted services may be more accessible,
    and possibly more powerful, when you send them JSON messages. I have used Loggly
    in different applications and know that this is the case.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 列表可以一直继续下去。许多这些托管服务在发送 JSON 消息时可能更容易访问，也可能更强大。我在不同的应用程序中使用过 Loggly，并知道这是事实。
- en: There are many ways to ship logs to Loggly, and likely for other services. However,
    shipping logs can change when the destination is somewhere other than your FaaS
    provider. CloudWatch logging is built-in to AWS Lamba and offers free performance,
    so how can we get these same logs out to an external service?
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 将日志发送到 Loggly 的方法有很多，可能还有其他服务也是如此。然而，当目标不是你的 FaaS 提供商时，发送日志可能会发生变化。CloudWatch
    日志是 AWS Lambda 内置的，提供免费性能，那么我们如何将这些相同的日志输出到外部服务呢？
- en: With AWS CloudWatch, it's possible to trigger another Lambda function when new
    log messages arrive. That may seem a bit odd, but it's a great trick to keep your
    application lean and decoupled from any logging service while also solving the
    problem of getting your log message to a more powerful service. We won't go into
    all the details on how to set this up here, but there is detailed documentation
    available on the Loggly site: [https://www.loggly.com/docs/cloudwatch-logs/](https://www.loggly.com/docs/cloudwatch-logs/).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 AWS CloudWatch，当新的日志消息到达时可以触发另一个 Lambda 函数。这听起来可能有点奇怪，但这是一个很好的技巧，可以在保持你的应用程序精简并解耦任何日志服务的同时，解决将日志消息发送到更强大的服务的问题。我们在这里不会详细介绍如何设置，但
    Loggly 网站上有详细的文档：[https://www.loggly.com/docs/cloudwatch-logs/](https://www.loggly.com/docs/cloudwatch-logs/)。
- en: This pattern is not unique to Loggly in any way. If you are using another logging
    service and wish to follow the same pattern, it's merely a matter of implementing
    a Lambda function, which is then triggered by CloudWatch events and sent away
    to your logging provider of choice.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式在 Loggly 中并不独特。如果你使用的是其他日志服务，并希望遵循相同的模式，那么这仅仅是一个实现 Lambda 函数的问题，该函数随后由 CloudWatch
    事件触发，并将数据发送到你选择的日志提供商。
- en: Once you have JSON messages arriving at your logging provider, you have many
    more options in terms of data analysis and discovery. Being able to quickly and
    easily find information when a problem occurs is critical for any production-level
    system, serverless or not. Regardless of which FaaS or logging service you're
    using, just make sure that you can easily find the data you need when it's time.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的日志提供商收到了 JSON 消息，你就有更多关于数据分析和服务发现的选择。在出现问题时能够快速轻松地找到信息对于任何生产级系统来说都是至关重要的，无论是无服务器还是有服务器。无论你使用的是哪种
    FaaS 或日志服务，只要确保在需要的时候可以轻松找到所需的数据即可。
- en: Cold starts
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 冷启动
- en: One commonality between most, if not all, FaaS providers is the issue of cold
    starts. Cold starts are defined as the behavior where an invocation of a cloud
    function which has not been executed in a while takes a considerable amount of
    time to initialize before fulfilling the request. If you have used Docker, for
    example, you'll know that creating a new container from an existing image takes
    slightly longer than starting up a container you have previously run. This Docker
    container behavior is analogous to the way cloud functions, whether it be AWS
    Lambda, Google Cloud Functions, or Azure Cloud Functions, behave. If you do any
    searching around the internet for serverless cold starts, you'll find several
    blog posts and documentation on the matter.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数（如果不是所有）FaaS 提供商都存在冷启动问题。冷启动是指一段时间内未执行过的云函数在满足请求之前需要花费相当长的时间来初始化的行为。例如，如果你使用过
    Docker，你会知道从现有镜像创建一个新的容器比启动之前运行过的容器要稍微长一些。这种 Docker 容器行为与云函数的行为类似，无论是 AWS Lambda、Google
    Cloud Functions 还是 Azure Cloud Functions。如果你在网上搜索关于无服务器冷启动的内容，你会找到关于这个问题的几篇博客文章和文档。
- en: There isn't a silver bullet for bypassing the cold start issue. However, there
    are several things to be aware of so that you can minimize their impact on your
    application.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 没有一种万能的解决方案可以绕过冷启动问题。然而，有一些需要注意的事项，以便你可以最小化它们对应用程序的影响。
- en: Keeping cloud functions warm
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保持云函数活跃
- en: There are several tips and tricks you can employ to work around cold starts.
    The most common recommendation is to implement another function on a timer, say
    every 5 minutes, which then invokes your target function. With this pattern, the
    target function is always kept warm, which means it can fulfill a legitimate request
    more quickly. This can be a useful trick; however, it does not always solve the
    problem.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以采用一些技巧和窍门来绕过冷启动。最常见的建议是在定时器上实现另一个函数，比如每 5 分钟一次，然后调用你的目标函数。使用这种模式，目标函数始终处于预热状态，这意味着它可以更快地满足合法请求。这可能是一个有用的技巧；然而，它并不总是能解决问题。
- en: Remember, cloud functions will scale automatically. Think back to some of the
    patterns in this book, specifically the Fanout and MapReduce patterns. In those
    examples, multiple instances of our functions were being executed concurrently.
    In the case of our Fanout pattern for image resizing, a single invocation of our
    initial Lambda function would result in three concurrent image resizing functions.
    If we had a `ping` function to keep the resizing function active, we would have
    a single function warm and ready to process that resizing task. However, when
    three simultaneous invocations occur, a single `ping` function will not help.
    In this scenario, a single resize function would be warm, but the other two would
    pay the cold start cost. If we changed our application to resize an image into
    five different sizes, we would then have four different functions that would start
    from a *cold* state.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，云函数会自动扩展。回想一下这本书中的一些模式，特别是扇出（Fanout）和映射归约（MapReduce）模式。在这些例子中，我们的函数的多个实例是并发执行的。在我们的图像缩放扇出模式中，对初始
    Lambda 函数的单次调用会导致三个并发图像缩放函数。如果我们有一个 `ping` 函数来保持缩放函数活跃，那么我们就会有一个单独的函数预热并准备好处理该缩放任务。然而，当有三个同时调用发生时，单个
    `ping` 函数将无济于事。在这种情况下，单个缩放函数会预热，但其他两个将承担冷启动成本。如果我们改变我们的应用程序，将图像缩放到五种不同的大小，那么我们就会有四个不同的函数，它们将从
    *冷启动* 状态开始。
- en: AWS Lambda functions and VPCs
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS Lambda 函数和 VPC
- en: If you are using AWS, keep in mind that cold starts are much worse when running
    Lambda functions inside a VPC. The reason for this is that Lambda functions in
    a VPC are allocated an **Elastic Network Interface** (**ENI**) to access VPC resources
    such as databases. If you ran the example code [Chapter 2, ](svrls-dsnptn-bstprac_ch02.html)*A
    Three-Tier Web Application Using REST* and [Chapter 3, ](svrls-dsnptn-bstprac_ch03.html)*A
    Three-Tier Web Application Pattern with GraphQL*, you may have noticed that the
    first API call took several seconds. This initial lag is mainly because the Lambda
    functions needed access to the RDS instance inside of a VPC, which means the Lambda
    functions themselves are required to be inside the same VPC.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用 AWS，请注意，在 VPC 内运行 Lambda 函数时，冷启动会变得更糟。原因在于 VPC 中的 Lambda 函数被分配了一个 **弹性网络接口**（**ENI**）来访问
    VPC 资源，如数据库。如果你运行了示例代码 [第 2 章，](svrls-dsnptn-bstprac_ch02.html)*使用 REST 的三层 Web
    应用程序* 和 [第 3 章，](svrls-dsnptn-bstprac_ch03.html)*带有 GraphQL 的三层 Web 应用程序模式*，你可能已经注意到第一次
    API 调用花费了几秒钟。这种初始延迟主要是由于 Lambda 函数需要访问 VPC 内的 RDS 实例，这意味着 Lambda 函数本身也需要位于同一个
    VPC 内。
- en: If at all possible, avoid putting Lambda functions inside a VPC. If your functions
    do not rely on any external resources, or non-VPC resources such as DynamoDB,
    do not put them inside of a VPC. However, if you do need access to VPC resources,
    there aren't many options available. If you are running an API that is talking
    to a VPC resource such as an RDS instance, you could run a `pinger` function,
    but we advise raising the concurrency from 1 to something like 10\. In this case,
    you would then have at least 10 functions always warmed up and ready to serve
    traffic.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可能的话，尽量避免将 Lambda 函数放在 VPC 内。如果你的函数不依赖于任何外部资源，或者非 VPC 资源，如 DynamoDB，不要将它们放在
    VPC 内。然而，如果你确实需要访问 VPC 资源，可用的选项并不多。如果你运行的是一个与 VPC 资源（如 RDS 实例）通信的 API，你可以运行一个
    `pinger` 函数，但我们建议将并发性从 1 提高到 10 左右。在这种情况下，你将至少有 10 个始终处于预热状态并准备好服务的函数。
- en: Start-up times for different languages
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不同语言的启动时间
- en: Each supported language comes with its unique behavior in cloud functions. We
    have not thorough profiled all the different FaaS platforms and languages in this
    book, but we do know that it has been reported that Node.js and Python have lower
    cold start times compared with Java and C# on AWS. However, there are also claims
    that C# functions based on .NET Core 2.0 are significantly faster. AWS recently
    rolled out support for Golang; however, we are currently unclear on its relative
    cold start performance.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 每种受支持的语言在云函数中都有其独特的行为。我们在本书中并没有彻底分析所有不同的 FaaS 平台和语言，但我们确实知道，据报道，与 AWS 上的 Java
    和 C# 相比，Node.js 和 Python 的冷启动时间较低。然而，也有说法称基于 .NET Core 2.0 的 C# 函数速度显著更快。AWS 最近推出了对
    Golang 的支持；然而，我们目前对其相对冷启动性能尚不清楚。
- en: I may be a bit biased, but I do believe using a language with a lower cold start
    time is a better choice, at least on AWS, as you can accomplish pretty much anything
    you need between Node.js and Python. Reading some of the tests people have made,
    the difference between Java or C# and other languages is two to three orders of
    magnitude; in other words, cold start times range from 1,000-4,000 ms with Java
    and C#, whereas Node.js and Python score in the range of 1-10 ms.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我可能有点偏见，但我确实认为使用冷启动时间较短的编程语言是一个更好的选择，至少在 AWS 上是这样，因为您可以在 Node.js 和 Python 之间完成几乎所有您需要的事情。阅读一些人们所做的测试，Java
    或 C# 与其他语言之间的差异是两个到三个数量级；换句话说，冷启动时间在 Java 和 C# 中为 1,000-4,000 毫秒，而 Node.js 和 Python
    的得分在 1-10 毫秒之间。
- en: Allocating more memory
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分配更多内存
- en: At least in the case of AWS Lambda, allocating more memory to your functions
    can result in a faster start-up time. Just as running larger EC2 instances affords
    you more CPU power, so too does allocating more memory to your Lambda functions.
    Allocating more memory to your functions may improve performance, but note that
    this will affect your billing as Lambda functions are billed by the combination
    of execution duration and allocated memory.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 至少在 AWS Lambda 的情况下，为您的函数分配更多内存可以缩短启动时间。正如运行更大的 EC2 实例可以为您提供更多的 CPU 功率一样，为您的
    Lambda 函数分配更多内存也是如此。为您的函数分配更多内存可能会提高性能，但请注意，这将影响您的账单，因为 Lambda 函数的计费是根据执行时间和分配的内存组合来计算的。
- en: You can read about CPU allocation relating to AWS Lambda in the following document: [https://docs.aws.amazon.com/lambda/latest/dg/resource-model.html](https://docs.aws.amazon.com/lambda/latest/dg/resource-model.html).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下文档中了解与 AWS Lambda 相关的 CPU 分配：[https://docs.aws.amazon.com/lambda/latest/dg/resource-model.html](https://docs.aws.amazon.com/lambda/latest/dg/resource-model.html)。
- en: Local development and testing
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本地开发和测试
- en: One challenge we face as serverless engineers is that of convenience. To be
    more specific, it's a swift process writing code, deploying it, and beginning
    testing. Testing a live system will often result in some code or configuration
    issue, but it is quickly fixed and redeployed. The problem we face, therefore,
    is that it's so easy to fix issues and then redeploy that we can get into the
    habit of skipping testing or not running our stack locally.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 作为无服务器工程师，我们面临的一个挑战是便利性。更具体地说，编写代码、部署和开始测试的过程非常快。测试实时系统通常会引发一些代码或配置问题，但这些问题很快就能得到修复并重新部署。因此，我们面临的问题是，由于问题修复和重新部署变得如此容易，我们可能会养成跳过测试或不在本地运行我们的堆栈的习惯。
- en: Local development
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本地开发
- en: One question I answer with some regularity is, *How do I run this locally?*
    When writing a server-based application, one of the first tasks to undertake is
    getting the system set up so that it can be run during development. When building
    a serverless-based application, however, there really is no server to run. So,
    how do we develop our application?
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我经常回答的一个问题是，*我如何在本地运行这个程序？* 当编写基于服务器的应用程序时，首先要执行的任务之一是设置系统，以便在开发期间运行。然而，在构建基于无服务器的应用程序时，实际上并没有服务器可以运行。那么，我们如何开发我们的应用程序呢？
- en: The truthful answer is that this is a challenge, and one that has not been solved
    perfectly yet; to be fair, this issue is difficult with any microservice-based
    system. So, how can we run a system and ensure it's fully functional when it's
    composed of multiple disparate pieces? My belief here is that we need to lean
    on the principles and strengths of a component-based architecture and use common
    tools that make local development and testing easier. As you write your serverless
    application, it's best to focus on the service itself and ensure via unit testing
    that it works as expected. Don't expect to run a full serverless map-reduce system
    on your local machine.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 真实的答案是，这是一个挑战，而且这个挑战尚未得到完美解决；公平地说，任何基于微服务系统的这个问题都很难解决。那么，我们如何运行一个系统并确保它由多个不同的部分组成时能够完全功能正常？我的信念是，我们需要依靠基于组件架构的原则和优势，并使用使本地开发和测试更容易的通用工具。当你编写无服务器应用程序时，最好专注于服务本身，并通过单元测试确保它按预期工作。不要期望在你的本地机器上运行完整的无服务器map-reduce系统。
- en: In the case of a serverless web API, I rely on unit tests rather than a local
    server during development. After all, we've long been taught that unit tests are
    a better approach to development than the manual testing of an API or UI. Regardless
    of where you stand on that topic, local development of serverless systems can
    move along quite quickly when writing unit tests, and testing in these systems
    is relatively simple, as we'll cover in the upcoming section.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在无服务器Web API的情况下，我在开发过程中更依赖单元测试而不是本地服务器。毕竟，我们长期以来一直被教导单元测试是比手动测试API或UI更好的开发方法。无论你对这个话题的看法如何，当编写单元测试时，无服务器系统的本地开发可以相当快速地进行，并且在这些系统中进行测试相对简单，我们将在下一节中介绍。
- en: 'You can read through the repository of community plugins in Serverless Framework
    here: [https://github.com/serverless/plugins](https://github.com/serverless/plugins).'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里阅读Serverless Framework社区插件的存储库：[https://github.com/serverless/plugins](https://github.com/serverless/plugins)。
- en: There *are* options for running a serverless application locally, as mentioned
    previously; however, I have not used these tools myself and cannot speak for the
    ease or difficulty of using them. For Serverless Framework, however, there are
    some plugins with the word offline in the name, where the commonality is that
    they all aim to help you run your application locally. Outside these plugins,
    DynamoDB has, for a long time, offered an offline version that can be run on your
    local system.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，运行无服务器应用程序本地确实有选择；然而，我本人并未使用过这些工具，无法评论使用它们的便捷性或难度。然而，对于Serverless Framework来说，有一些插件名称中包含“离线”一词，它们的共性是都旨在帮助你本地运行应用程序。在这些插件之外，DynamoDB长期以来一直提供可以在本地系统上运行的离线版本。
- en: Serverless systems are still relatively new, and the landscape is maturing and
    changing quickly. It's almost certain that vendors recognize that there are areas
    for improvements in the software development lifecycle of serverless applications;
    I would not be surprised if local development and testing became more comfortable
    in the coming years.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器系统仍然相对较新，该领域正在成熟和快速变化。几乎可以肯定，供应商认识到无服务器应用程序的软件开发生命周期中存在改进的领域；如果未来几年本地开发和测试变得更加舒适，我也不会感到惊讶。
- en: Learning about testing locally
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在本地了解测试
- en: Concerning local development, I believe the best strategy is to set up robust
    and thorough unit tests. Unit-testing serverless applications is no different
    from testing traditional server-based applications. As long as you follow the
    mantra of keeping your serverless code separate from your business logic, it's
    quite simple to get to a very high test coverage.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 关于本地开发，我认为最好的策略是建立健壮和全面的单元测试。对无服务器应用程序进行单元测试与传统基于服务器的应用程序测试并无不同。只要遵循将你的无服务器代码与业务逻辑分离的箴言，实现非常高的测试覆盖率就相当简单。
- en: But what do we do when our application relies on backing services such as databases,
    caches, and the like? Additionally, what do we do when our serverless application
    calls other services that don't exist locally, such as AWS, SNS, and so on?
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 但当我们的应用程序依赖于数据库、缓存等后端服务时，我们该怎么办？此外，当我们的无服务器应用程序调用本地不存在的服务时，例如AWS、SNS等，我们该怎么办？
- en: My approach to common systems such as Postgres or Redis is to use Docker. If
    you look back at the unit tests from [Chapter 2](svrls-dsnptn-bstprac_ch02.html),
    [](svrls-dsnptn-bstprac_ch02.html)*A Three-Tier Web Application Using REST* and
    [Chapter 3](svrls-dsnptn-bstprac_ch03.html),  *A Three-Tier Web Application Pattern
    with GraphQL*, you will see that they rely on a PostgreSQL database. When developing
    that application, we ran a Docker image that the unit tests used.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我对Postgres或Redis等常见系统的方法是使用Docker。如果你回顾一下[第2章](svrls-dsnptn-bstprac_ch02.html)、“使用REST的三层Web应用程序”和[第3章](svrls-dsnptn-bstprac_ch03.html)、“带有GraphQL的三层Web应用程序模式”中的单元测试，你会看到它们依赖于PostgreSQL数据库。在开发该应用程序时，我们运行了一个单元测试使用的Docker镜像。
- en: Another method for dealing with services you cannot easily run locally or code
    which *is* focused on serverless-specific logic is the judicious use of mocks.
    Take, for example, our Messaging Pattern, where our handler function sends messages
    to SQS. To test this code, we would not want to invoke SQS as that would make
    our tests slower and they would likely end up brittle. What's better, in this
    case, is to instead mocking out the API call to SQS and simply test whether the
    request to the SQS publish function was made.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 处理那些难以在本地运行的服务或专注于无服务器特定逻辑的代码的方法之一是明智地使用模拟。以我们的消息模式为例，其中我们的处理函数向SQS发送消息。为了测试这段代码，我们不想调用SQS，因为这会使我们的测试变慢，并且它们很可能会变得脆弱。在这种情况下，更好的做法是模拟对SQS的API调用，并简单地测试是否调用了SQS发布函数。
- en: 'Likewise, when we want to test some code which is specific to our serverless
    implementation, mock can come in handy. This is best explained with an example;
    the following code block shows a single function from our REST API, at the top-level
    `handler.py` function:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，当我们想要测试针对我们无服务器实现特定的代码时，模拟会很有用。这最好用一个例子来说明；下面的代码块展示了我们的REST API中的一个单个函数，位于顶层的`handler.py`函数：
- en: '[PRE8]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As you can see, this code has a bit more going on than delegation. Here, the
    `session_detail` function is catching various errors and setting the HTTP response
    code and message based on those exceptions, if any are raised. Testing the `handle_session_detail`
    function is simple, as it is working solely on our application and doesn't contain
    any reliance on or knowledge of AWS Lambda. However, we do need to test the handling
    of errors in `session_detail`.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这段代码比委托做得更多。在这里，`session_detail`函数正在捕获各种错误，并根据这些异常设置HTTP响应代码和消息，如果有任何异常被抛出。测试`handle_session_detail`函数很简单，因为它只在我们自己的应用程序上工作，不包含对AWS
    Lambda的依赖或知识。然而，我们确实需要测试`session_detail`中的错误处理。
- en: 'To do this, we use a mock object to patch the `handle_session_detail` method.
    The aim of the following code block is to trigger an `Http404` exception so that
    we can verify that the static code and error message are correct. The following
    code block  shows this unit test, where `mocker` is a fixture which comes from
    the `pytest-mock` library:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们使用模拟对象来修补`handle_session_detail`方法。以下代码块的目标是触发一个`Http404`异常，以便我们可以验证静态代码和错误消息是否正确。以下代码块展示了这个单元测试，其中`mocker`是一个来自`pytest-mock`库的固定装置：
- en: '[PRE9]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Testing is as much an art as it is a science, and so I cannot overstate the
    importance of testing in serverless applications. As usual, the better your test
    are, the more confident you'll be when it's time to refactor your code or deploy
    changes.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 测试既是艺术也是科学，因此我无法过分强调在无服务器应用程序中测试的重要性。通常，你的测试做得越好，在重构代码或部署更改时你就越有信心。
- en: Managing different environments
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理不同的环境
- en: With most production-level applications, teams maintain multiple environments
    for different purposes. A `QA` environment may exist for the QA team to run automated
    tests, a `staging` environment may exist for the DevOps team to tests their infrastructure
    changes, and the `production` environment exists to serve live traffic. Very often,
    building and maintaining these different environments can be a full-time job.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数生产级应用程序，团队会维护多个环境以供不同目的使用。可能存在一个`QA`环境，供QA团队运行自动化测试；可能存在一个`staging`环境，供DevOps团队测试其基础设施更改；而`production`环境则用于服务实时流量。非常常见的是，构建和维护这些不同的环境可能是一项全职工作。
- en: With serverless systems, I've found that maintaining different environments
    can be much more straightforward. Some of this may come from the fact that, by
    their nature, serverless applications are inherently smaller. Writing a monolithic
    application in a serverless architecture isn't wise - or even natural. How best,
    then, can we manage and maintain different environments for serverless systems?
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 对于无服务器系统，我发现维护不同的环境可以更加直接。这也许部分来自于无服务器应用本质上更小的这一事实。在无服务器架构中编写单体应用并不明智——甚至不自然。那么，我们如何最好地管理和维护无服务器系统的不同环境呢？
- en: 'For this, turning to tenant III of the 12-Factor App Methodology helps. This
    tenant can be found at [https://12factor.net/config](https://12factor.net/config)
    and states:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这一点，转向12-Factor App Methodology的第三条原则有所帮助。这个原则可以在[https://12factor.net/config](https://12factor.net/config)找到，并声明：
- en: Store config in the environment
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 将配置存储在环境中
- en: An app’s config is everything that is likely to vary between deploys (staging,
    production, developer environments, etc.).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一个应用的配置是所有可能在部署之间（预发布、生产、开发者环境等）发生变化的内容。
- en: 'Throughout this book, I used the Serverless Framework to manage and deploy
    my systems. This framework has built-in support for environment variables, which
    we can use to our advantage to efficiently manage different systems without making
    any code changes. The following code block shows a small snippet from the `serverless.yml`
    file from [Chapter 2](svrls-dsnptn-bstprac_ch02.html), [](svrls-dsnptn-bstprac_ch02.html)*A
    Three-Tier Web Application Using REST* for the coffee cupping REST API:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '在这本书的整个过程中，我使用了Serverless Framework来管理和部署我的系统。这个框架内置了对环境变量的支持，我们可以利用它来高效地管理不同的系统，而无需对代码进行任何更改。以下代码块展示了来自[第2章](svrls-dsnptn-bstprac_ch02.html)，[一个使用REST的三层Web应用](svrls-dsnptn-bstprac_ch02.html)*用于咖啡品尝REST
    API*的`serverless.yml`文件的一个小片段： '
- en: '[PRE10]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here, any reference to `${env:NAME}` will pull the actual value for `NAME`
    from the environment. Additionally, Serverless Framework helps us to keep stacks
    separate by using the `stage` variable to name resources. Whenever deploying code,
    the deployment step includes the stage variable, which we also pull out of the
    environment:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，任何对`${env:NAME}`的引用都将从环境中拉取`NAME`的实际值。此外，Serverless Framework通过使用`stage`变量来命名资源，帮助我们保持栈的分离。在部署代码时，部署步骤包括阶段变量，我们也会从环境中提取出来：
- en: '[PRE11]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: These two techniques combined mean that deploying a `dev` stack or `qa` stack
    is just a matter of loading different environment variables. You can load environment
    variables from a file with tools such as `dotenv`, your shell script, or some
    other tool. My technique uses Docker and a Makefile to load up different variables
    based on the `ENV` I wish to work with. The result is the same, regardless of
    how you solve the problem of variable management. If you can quickly change variables,
    you can easily switch between managing completely different stacks. Remember,
    if you're using the Serverless Framework you will also need to handle the `ENV`
    setting. This variable is a single setting which will control the stack that is
    updated during any deployment.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种技术的结合意味着部署一个`dev`栈或`qa`栈仅仅是一个加载不同环境变量的过程。你可以使用像`dotenv`这样的工具、你的shell脚本或其它工具从文件中加载环境变量。我的技术使用Docker和Makefile根据我想要工作的`ENV`加载不同的变量。无论你如何解决变量管理的问题，结果都是一样的。如果你使用Serverless
    Framework，你还需要处理`ENV`设置。这个变量是一个单独的设置，它将控制任何部署期间更新的栈。
- en: Securing sensitive configuration
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护敏感配置
- en: Throughout this book, and in the previous section about managing environments,
    we've relied heavily on environment variables. One very nice feature of pulling
    a configuration from the environment is that sensitive information never needs
    to be checked into the source control. All of our application code and any framework
    code (such as the Serverless Framework) can look up variable values from the environment
    when needed.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书的整个过程中，以及在前一节关于管理环境的内容中，我们严重依赖环境变量。从环境中拉取配置的一个非常好的特性是，敏感信息永远不需要被检查到源控制中。我们所有的应用程序代码以及任何框架代码（如Serverless
    Framework）在需要时都可以从环境中查找变量值。
- en: 'Configuration via environment variables is all well and good, but our usage
    of these variables is not perfect. The problem with our usage of environment variables
    and Lambda is that the data pulled from the deployment environment is uploaded
    and stored in AWS Lambda functions as plain text. For example, take a look at
    `serverless.yml` from the previous section about error handling using either Sentry
    or Rollbar:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 通过环境变量进行配置是很好，但我们对这些变量的使用并不完美。我们使用环境变量和Lambda的问题在于，从部署环境中提取的数据被上传并存储在AWS Lambda函数中，以明文形式。例如，看看上一节关于使用Sentry或Rollbar处理错误的`serverless.yml`：
- en: '[PRE12]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The keys under the environment key are all set on the AWS Lambda functions.
    While we never check the values of those variables into source control, they persist
    inside AWS. In this case, our `SENTRY_DSN` and `ROLLBAR` values should not be
    shared with anyone. However, if you're working in a team environment, anyone with
    access to the AWS Lambda console can very easily peek inside your Lambda functions
    and see the values for any of these variables.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 环境键下的所有密钥都是在AWS Lambda函数上设置的。虽然我们从未将这些变量的值检查到源代码控制中，但它们在AWS内部持续存在。在这种情况下，我们的`SENTRY_DSN`和`ROLLBAR`值不应该与任何人共享。然而，如果你在一个团队环境中工作，任何可以访问AWS
    Lambda控制台的人都可以非常容易地查看你的Lambda函数并看到这些变量的值。
- en: '![](img/b9f8b4a3-1619-4fd4-ad8e-b74fe0074b50.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b9f8b4a3-1619-4fd4-ad8e-b74fe0074b50.png)'
- en: Encrypting variables
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变量加密
- en: To fix this, we can leverage another AWS service called Key Management Service
    (KMS). KMS works by encrypting data into a string that can only be decrypted using
    KMS itself. What's nice about using KMS is that you can then store, share, or
    even check into source control your encrypted variables, since nobody can decrypt
    them unless they have access to KMS. Your one attack vector here then becomes
    AWS and KMS itself. If anyone has permission to use your KMS key or can gain access
    to a privileged AWS account, they can decrypt any KMS-managed variable.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们可以利用另一个AWS服务，称为密钥管理服务（KMS）。KMS通过将数据加密成一个只能使用KMS本身解密的字符串来工作。使用KMS的好处是，你可以存储、共享，甚至将加密变量检查到源代码控制中，因为除非他们有权访问KMS，否则没有人可以解密它们。因此，你的一个攻击向量变成了AWS和KMS本身。如果任何人有权使用你的KMS密钥或可以访问一个受权的AWS账户，他们就可以解密任何KMS管理的变量。
- en: Azure has something similar called Key Vault, which is something you should
    look into if building on top of Azure. I'm unaware of a similar service within
    Google Compute or other FaaS providers.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Azure有一个类似的服务称为密钥保管库（Key Vault），如果你在Azure上构建，你应该考虑一下。我不知道Google Compute或其他FaaS提供商中是否有类似的服务。
- en: 'Encrypting data with KMS is quite simple. First, you''ll need to create a KMS
    key. Once you have a key generated you will need to copy the AWS `arn` for your
    newly created key. From there, you can use a variety of APIs to encrypt a plaintext
    string. Using the previous example, I''m going to encrypt my `DB_PASSWORD` of
    `supersecret`. The following code block shows how to encrypt a password using
    Python and the `boto3` library:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 使用KMS加密数据相当简单。首先，你需要创建一个KMS密钥。一旦生成了密钥，你需要复制你新创建的密钥的AWS `arn`。从那里，你可以使用各种API来加密一个明文字符串。使用之前的示例，我将加密我的`DB_PASSWORD`变量`supersecret`。下面的代码块展示了如何使用Python和`boto3`库来加密密码：
- en: '[PRE13]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output of this code is an encrypted string, which you can share throughout
    your infrastructure:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码的输出是一个加密的字符串，你可以在你的整个基础设施中共享：
- en: '[PRE14]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'You can accomplish the same task using `aws-cli`, as shown in the following
    snippet:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`aws-cli`完成相同的任务，如下面的代码片段所示：
- en: '[PRE15]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Decrypting variables
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变量解密
- en: The question, of course, is how we can use this within our application; the
    answer is the inverse of what we just did. Now that we have an encrypted variable,
    our application code will need to read that value and decrypt it. Nothing changes
    from the standpoint of using environment variables. All that has changed now is
    that our sensitive variables are no longer stored in plain text anywhere within
    AWS.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，问题是我们在应用程序中如何使用它；答案是刚才所做操作的逆操作。现在我们有了加密变量，我们的应用程序代码需要读取该值并解密它。从使用环境变量的角度来看，没有变化。现在唯一改变的是，我们的敏感变量不再存储在AWS的任何地方以明文形式。
- en: 'After setting the `DB_PASSWORD` environment variable to this new encrypted
    string and redeploying, we can verify that the Lambda console is no longer storing
    the `supersecret` password. The following screenshot shows the value for the `DB_PASSWORD`
    variable from the AWS Lambda page for my function:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在将`DB_PASSWORD`环境变量设置为这个新的加密字符串并重新部署后，我们可以验证Lambda控制台不再存储`supersecret`密码。以下截图显示了AWS
    Lambda页面中我函数的`DB_PASSWORD`变量的值：
- en: '![](img/a9b6d563-5b3f-40d6-a048-306caf139aaf.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a9b6d563-5b3f-40d6-a048-306caf139aaf.png)'
- en: In order for our Lambda functions to use KMS to decrypt this data, we need to
    authorize it explicitly. To accomplish this, let's add an IAM permission in `serverless.yml`.
    In the following snippet, `KMs_KEY_ARN` is referencing the KMS `arn` , as explained
    previously. This value can also be stored as an environment variable which, going
    back to the section on managing different environments, lets us quickly switch
    between different stacks where we'd otherwise be using different KMS keys.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让我们的Lambda函数使用KMS解密这些数据，我们需要明确授权它。为了实现这一点，让我们在`serverless.yml`中添加一个IAM权限。在以下片段中，`KMs_KEY_ARN`引用了之前解释的KMS
    `arn`，此值也可以存储为环境变量，回到管理不同环境的章节，这让我们可以快速在不同的堆栈之间切换，否则我们将使用不同的KMS密钥。
- en: '[PRE16]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Once that is done, we can get the database password with a few lines of code
    to fetch the value and decrypt it into plaintext. The following code block shows
    how to decrypt the password, where the encrypted value is still being pulled out
    of the environment:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些后，我们可以用几行代码获取数据库密码，并将其解密成明文。以下代码块显示了如何解密密码，其中加密值仍然是从环境中提取的：
- en: '[PRE17]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: With that, we can now use the `db_password` value to connect to the database
    as usual.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们现在可以使用`db_password`值像往常一样连接到数据库。
- en: There are a few things to take note of here. First, this adds a small bit of
    latency to your code since each call to `decrypt` is an API call to AWS; you can
    take advantage of the statefulness of warm functions and only perform the decryption
    if it hasn't already been done, using a global variable or some other application-level
    variable that can be initialized on startup. Second, once you have decrypted sensitive
    values like this, the onus is on you to not log them in plain text or otherwise
    advertise or record the plaintext values.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里有几个需要注意的事项。首先，由于每次调用`decrypt`都是一个对AWS的API调用，这会给你的代码增加一点延迟；你可以利用热函数的状态性，只有在尚未进行解密时才执行解密，使用全局变量或某些其他可以在启动时初始化的应用程序级变量。其次，一旦你解密了像这样的敏感值，责任就落在你身上，不要以明文形式记录它们，或者以其他方式公开或记录明文值。
- en: There are many things to consider when dealing with services such as KMS. This section
    is only a very brief introduction, and we've barely scratched the surface. I encourage
    you to read more about the subject and carefully think through how you can make
    your application as secure as you need to.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理KMS等服务时，有许多事情需要考虑。本节仅是一个非常简短的介绍，我们只是触及了表面。我鼓励你阅读更多关于这个主题的内容，并仔细思考如何使你的应用程序尽可能安全。
- en: Trimming AWS Lambda versions
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 剪切AWS Lambda版本
- en: 'This last tip is specific to AWS Lambda. You may have noticed in other chapters
    that there are the following lines in the `serverless.yml` file:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一条提示是针对AWS Lambda的。你可能已经注意到在其他章节中，`serverless.yml`文件中有以下行：
- en: '[PRE18]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: By default, each time you deploy a new version of an AWS Lambda function, AWS
    will help out by keeping the old version around. In a development system where
    you may be deploying dozens of times a day, this can become quite wasteful and,
    as cheap as storage is, it's not unlimited. Also, in the case of a production
    system that has a lifetime of years, the cost of all the old versions can add
    up.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，每次你部署AWS Lambda函数的新版本时，AWS都会帮忙保留旧版本。在一个可能每天部署数十次的开发系统中，这可能会变得相当浪费，尽管存储很便宜，但也不是无限的。此外，对于一个寿命为多年的生产系统，所有旧版本的成本可能会累积起来。
- en: If you're using the Serverless Framework, there is an easy way around this.
    If you're not using the Serverless Framework, however, it would be no more than
    a day's work to write a small script to do this for you. The `serverless-prune-plugin`
    will keep only a certain number of Lambda versions for you and delete the rest.
    The number of versions to keep is configurable and trimming happens whenever you
    perform a full deployment. Additionally, you are given some nice CLI hooks to
    manually delete old versions. You can read the details about this plugin on its
    GitHub page: [https://github.com/claygregory/serverless-prune-plugin](https://github.com/claygregory/serverless-prune-plugin).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用Serverless Framework，有简单的方法绕过这个问题。然而，如果你不使用Serverless Framework，编写一个简单的脚本来为你完成这个任务不会超过一天的工作量。`serverless-prune-plugin`插件会为你保留一定数量的Lambda版本，并删除其余的版本。保留的版本数量是可以配置的，并且修剪操作会在你执行完整部署时发生。此外，你还获得了一些不错的CLI钩子，可以手动删除旧版本。你可以在其GitHub页面上阅读有关此插件的详细信息：[https://github.com/claygregory/serverless-prune-plugin](https://github.com/claygregory/serverless-prune-plugin)。
- en: 'If I add this to my previous divide function, configure the plugin to run automatically,
    and only keep two versions around, you can guess what will happen when I redeploy.
    That configuration I just mentioned will go into a `custom` block in my `serverless.yml`,
    shown as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我将这个函数添加到之前写的分割函数中，配置插件自动运行，并且只保留两个版本，你可以猜到当我重新部署时会发生什么。我刚才提到的配置将会进入我的`serverless.yml`文件中的`custom`块，如下所示：
- en: '[PRE19]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Next, I''ll deploy my code to see the plugin prune the old versions for me.
    The following code block shows the output after running a full deployment, with
    some lines taken out for brevity:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将部署我的代码以查看插件是否为我修剪了旧版本。以下代码块显示了运行完整部署后的输出，为了简洁起见，一些行已被省略：
- en: '[PRE20]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'I recommend always using this plugin for AWS and Serverless Framework, as versioned
    Lambda functions aren''t very useful. Another option is to simply disable function
    versioning completely. This can be accomplished by adding `versionFunctions: false`
    under the `provider` key in the `serverless.yml` file.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '我建议始终为AWS和Serverless Framework使用此插件，因为版本化的Lambda函数并不很有用。另一个选项是简单地完全禁用函数版本化。这可以通过在`serverless.yml`文件中的`provider`键下添加`versionFunctions:
    false`来实现。'
- en: Summary
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered general best practices when deploying serverless
    applications and error tracking. We looked at examples of how to integrate Rollbar
    and Sentry, two error tracking and reporting services, in AWS Lambda functions
    so that unexpected errors do not go unnoticed. We also discussed some strategies
    regarding application logging and methods to ensure you get the metrics and telemetry
    you need. We also addressed the issue of cold starts in cloud functions, and we
    discussed ways of working around them. From there, we walked through some techniques
    to help you with local testing and setting up serverless functions and systems.
    Finally, we reviewed the management of different environments or stacks using
    environment variables and the encryption of sensitive variables using AWS's Key
    Management Service.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了部署无服务器应用程序和错误跟踪的一般最佳实践。我们探讨了如何在AWS Lambda函数中集成Rollbar和Sentry这两个错误跟踪和报告服务，以确保意外错误不会被人忽视。我们还讨论了一些关于应用程序日志记录的策略和方法，以确保你获得所需的指标和遥测数据。我们还讨论了云函数的冷启动问题，并讨论了绕过这些问题的方法。从那里，我们介绍了一些技术，帮助你进行本地测试和设置无服务器函数和系统。最后，我们回顾了使用环境变量管理不同环境或堆栈，以及使用AWS密钥管理服务加密敏感变量的方法。
- en: Best practices for serverless applications could fill an entire book by themselves.
    We touched on many significant topics in this chapter that put you on the right
    trajectory moving forward. While this chapter cannot solve all of the challenges
    you may face in serverless application development, it does provide solutions
    to some of the most common issues and gives you the background necessary to find
    answers to your unique problems. At this point, readers should feel confident
    setting up and managing their own production-level serverless application.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器端无服务器应用程序的最佳实践可以单独填满一本书。在本章中，我们触及了许多重要的主题，帮助你朝着正确的方向前进。虽然本章不能解决你在无服务器应用程序开发中可能遇到的所有挑战，但它确实提供了一些常见问题的解决方案，并为你提供了找到解决你独特问题的背景知识。此时，读者应该有信心设置和管理他们自己的生产级无服务器应用程序。
