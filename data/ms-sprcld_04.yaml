- en: Service Discovery
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务发现
- en: Before we got to this point, we had discussed service discovery many times in
    previous chapters. In fact, it is one of the most popular technical aspects of
    microservice architecture. Such a subject could not have been omitted from the
    Netflix OSS implementation. They did not decide to use any existing tool with
    similar features, but designed and developed a discovery server especially for
    their own needs. Then, it had been open sourced along with several other tools.
    The Netflix OSS discovery server is known as **Eureka**.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们到达这一点之前，在前面的章节中我们已经多次讨论了服务发现。实际上，它是微服务架构中最受欢迎的技术方面之一。这样的主题不可能从Netflix OSS实现中省略。他们没有决定使用具有类似功能的任何现有工具，而是专门为他们的需求设计并开发了一个发现服务器。然后，它与其他几个工具一起开源了。Netflix
    OSS发现服务器被称为**Eureka**。
- en: The Spring Cloud library for integration with Eureka consists of two parts,
    the client side and the server side. The server is launched as a separate Spring
    Boot application and exposes an API that allows for the collection of a list of
    registered services and adding a new service with a location address. The server
    can be configured and deployed to be highly available, with each server replicating
    its state with the others. The client is included in the microservice application
    as a dependency. It is responsible for the registration after startup, the deregistration
    before shutdown, and for keeping the registration list up to date by polling the
    Eureka Server.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 用于与Eureka集成的Spring Cloud库包括两部分，客户端和服务端。服务端作为独立的Spring Boot应用程序启动，并暴露一个API，可以收集注册服务列表以及添加带有位置地址的新服务。服务器可以配置和部署为高可用性，每个服务器都与其它服务器复制其状态。客户端作为微服务应用程序的一个依赖项包含在内。它负责启动后的注册、关机前的注销，并通过轮询Eureka服务器保持注册列表的最新。
- en: 'Here''s a list of topics we will cover in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们在本章中要覆盖的主题列表：
- en: Developing an application that runs embedded Eureka Server
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发运行内嵌Eureka服务器的应用程序
- en: Connecting to the Eureka Server from the client-side application
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从客户端应用程序连接到Eureka服务器
- en: Advanced discovery client configuration
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级发现客户端配置
- en: Enabling secure communication between client and server
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用客户端和服务器之间的安全通信
- en: Configuring failover and peer-to-peer replication mechanisms
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置故障转移和对等复制机制
- en: Registering instances of a client-side application in different zones
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不同区域注册客户端应用程序实例
- en: Running Eureka on the server side
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在服务器端运行Eureka
- en: 'Running the Eureka Server within a Spring Boot application is not a difficult
    task. Let''s take a look at how this can be done:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spring Boot应用程序中运行Eureka服务器并不是一件困难的事情。让我们来看看这是如何做到的：
- en: 'First, the right dependency has to be included to our project. Obviously, we
    will use a starter for that:'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，必须包含正确的依赖项到我们的项目中。显然，我们将使用一个启动器：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Eureka Server should also be enabled on the main application class:'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主应用程序类上启用Eureka服务器：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'It is interesting that together with the server starter, client''s dependencies
    are also included. They can be useful for us, but only when launching Eureka in
    high availability mode with peer-to-peer communication between discovery instances.
    When running a standalone instance, it doesn''t really get us anywhere except
    printing some errors in the logs during startup. We can either exclude `spring-cloud-netflix-eureka-client`
    from the starter dependencies or disable discovery client using configuration
    properties. I prefer the second choice, and also on this occasion, I changed the
    default server port to something other than `8080`. Here''s the fragment of the `application.yml`
    file:'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有趣的是，与服务器启动器一起，客户端的依赖项也包括在内。它们对我们可能有用，但只有在以高可用性模式运行Eureka，并且发现实例之间有对等通信时。当运行独立实例时，它实际上不会带给我们任何东西，除了在启动时在日志中打印一些错误。我们可以从启动器依赖项中排除`spring-cloud-netflix-eureka-client`，或者使用配置属性禁用发现客户端。我更喜欢第二个选择，并且在这个场合，我将默认服务器端口更改为除了`8080`之外的其它值。以下是`application.yml`文件的一个片段：
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: After completing the preceding steps, we can finally launch our first Spring
    Cloud application. Just run the main class from your IDE or build project with
    Maven; run it using the `java -jar` command and wait for the log line, `Started
    Eureka Server`. It's up. A simple UI dashboard is available as a home page at `http://localhost:8761`
    and HTTP API methods may be called with the `/eureka/*` path. The Eureka dashboard
    does not provide many features; in fact, it is mostly used for checking out the
    list of registered services. This could be found out by calling the REST API `http://localhost:8761/eureka/apps`
    endpoint.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在完成前面的步骤之后，我们终于可以启动我们的第一个Spring Cloud应用程序了。只需从你的IDE中运行主类，或者使用Maven构建项目并运行它，使用`java
    -jar`命令等待日志行`Started Eureka Server`出现。它就绪了。一个简单的UI仪表板作为主页可通过`http://localhost:8761`访问，并且可以通过`/eureka/*`路径调用HTTP
    API方法。Eureka仪表板并没有提供很多功能；实际上，它主要用于检查注册的服务列表。这可以通过调用REST API `http://localhost:8761/eureka/apps`端点来实现。
- en: So, to conclude, we know how to run a Eureka standalone server with Spring Boot
    and how to check the list of registered microservices using the UI console and
    HTTP methods. But we still don't have any service that is able to register itself
    in discovery, and it's time to change that. An example application with a discovery
    server and client implementation is available on GitHub ([https://github.com/piomin/sample-spring-cloud-netflix.git](https://github.com/piomin/sample-spring-cloud-netflix.git))
    in the `master` branch.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，总结一下，我们知道如何使用Spring Boot运行一个独立的Eureka服务器，以及如何使用UI控制台和HTTP方法检查注册的微服务列表。但我们仍然没有任何能够自己在发现中注册的服务，是时候改变这一点了。一个带有发现服务器和客户端实现示例应用程序可以在GitHub上的`master`分支找到([https://github.com/piomin/sample-spring-cloud-netflix.git](https://github.com/piomin/sample-spring-cloud-netflix.git))。
- en: Enabling Eureka on the client side
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启用客户端端的Eureka
- en: 'As on the server side, there is only one dependency that has to be included
    to enable a Eureka Client for the application. So, first include the following
    starter to your project''s dependencies:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 与服务器端一样，只需要包含一个依赖项就可以为应用程序启用Eureka客户端。所以，首先在你的项目依赖中包含以下启动器：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The example application does nothing more than communicate with the Eureka
    Server. It has to register itself and send metadata information such as host,
    port, health indicator URL, and home page. Eureka receives heartbeat messages
    from each instance belonging to a service. If the heartbeat isn''t received after
    a configured period of time, the instance is removed from the registry. The second
    responsibility of discovery client is fetching data from the server, then caching
    it and periodically asking for changes. It can be enabled by annotating the main
    class with `@EnableDiscoveryClient`. Surprisingly, there is another way to activate
    this feature. You may use an annotation `@EnableEurekaClient`, especially if there
    are multiple implementations of discovery client within the classpath (Consul,
    Eureka, ZooKeeper). While `@EnableDiscoveryClient` lives in `spring-cloud-commons`,
    `@EnableEurekaClient` lives in `spring-cloud-netflix` and only works for Eureka.
    Here''s the main class of the discovery client''s application:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例应用程序所做的只是与Eureka服务器通信。它必须注册自己并向Eureka发送元数据信息，如主机、端口、健康指标URL和主页。Eureka从属于某个服务的每个实例接收心跳消息。如果在配置的时间段内没有收到心跳消息，实例将被从注册表中移除。发现客户端的第二个责任是从服务器获取数据，然后缓存它并周期性地询问更改。可以通过在主类上使用`@EnableDiscoveryClient`注解来启用它。令人惊讶的是，还有另一种激活此功能的方法。你可以使用`@EnableEurekaClient`注解，特别是如果类路径中有多个发现客户端实现（Consul、Eureka、ZooKeeper）的话。虽然`@EnableDiscoveryClient`位于`spring-cloud-commons`中，`@EnableEurekaClient`位于`spring-cloud-netflix`中，并且只对Eureka有效。以下是发现客户端应用程序的主类：
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The discovery server address doesn''t have to be provided in the client''s
    configuration, because it is available on the default host and port. However,
    we could easily imagine that Eureka is not listening on its default `8761` port.
    The fragment of configuration file is visible below. The discovery server network
    address can be overridden with the `EUREKA_URL` parameter, as can the client''s
    listening port with the `PORT` property. The name under which the application
    is registered in the discovery server is taken from the `spring.application.name`
    property:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端配置中不必提供发现服务器的地址，因为默认的主机和端口上可用。然而，我们很容易想象Eureka没有在其默认的`8761`端口上监听。下面的配置文件片段可见。可以通过`EUREKA_URL`参数覆盖发现服务器的网络地址，也可以通过`PORT`属性覆盖客户端的监听端口。应用程序在发现服务器中注册的名称取自`spring.application.name`属性：
- en: '[PRE5]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let''s run two independent instances of our sample client application on localhost.
    To achieve that, the number of the listening port should be overridden for the
    instance on startup like this:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在本地主机上运行我们示例客户端应用程序的两个独立实例。为了实现这一点，需要在启动时覆盖监听端口的数量，像这样：
- en: '[PRE6]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As you can see in the following screenshot, there are two instances of `client-service`
    registered with the hostname `piomin` and ports `8081 `and `8082`:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在下面的截图所看到的，有一个名为`client-service`的实例注册了`piomin`这个主机名和`8081`和`8082`这两个端口：
- en: '![](img/5b172c1a-67fb-4dfe-a0fb-3249d94261e8.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5b172c1a-67fb-4dfe-a0fb-3249d94261e8.png)'
- en: Deregistration on shutdown
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关机时的注销
- en: 'Checking how a deregistration works with a Eureka Client is a bit more of a
    difficult task. Our application should be shut down gracefully in order to be
    able to intercept a stopped event and send an event to the server. The best way
    for a graceful shutdown is by using the Spring Actuator `/shutdown` endpoint.
    The actuator is a part of Spring Boot and it can be included in the project by
    declaring the `spring-boot-starter-actuator` dependency in `pom.xml`. It is disabled
    by default, so we have to enable it in the configuration properties. For the sake
    of simplicity, it is worth disabling user/password security for that endpoint:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 检查与Eureka客户端的注销工作有点更具挑战性。我们的应用程序应该优雅地关闭，以便能够拦截一个停止事件并向服务器发送一个事件。实现优雅关闭的最佳方式是使用Spring
    Actuator的`/shutdown`端点。Actuator是Spring Boot的一部分，可以通过在`pom.xml`中声明`spring-boot-starter-actuator`依赖项来将其包含在项目中。它默认是禁用的，因此我们必须在配置属性中启用它。为了简单起见，禁用该端点的用户/密码安全性是值得的：
- en: '[PRE7]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To shut down the application, we have to call the `POST /shutdown` API method.
    If you receive the response `{"message": "Shutting down, bye..."}`, it means everything
    went well and the procedure has been started. Before the application is disabled,
    some logs starting from the line Shutting down DiscoveryClient ...will be printed
    out. After that, the service will be unregistered from the discovery server and
    it completely disappears from the list of registered services. I decided to shut
    down client instance #2 by calling `http://localhost:8082/shutdown` (you may call
    it using any REST client, for example, Postman), so only the instance running
    on port `8081` is still visible in the dashboard:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '要关闭应用程序，我们必须调用`POST /shutdown`API方法。如果您收到响应`{"message": "Shutting down, bye..."}`，这意味着一切都很顺利，流程已经开始。在应用程序被禁用之前，从Shutting
    down DiscoveryClient...行开始的某些日志将被打印出来。之后，服务将从发现服务器上注销，并完全消失在注册服务列表中。我决定通过调用`http://localhost:8082/shutdown`（您可以使用任何REST客户端，例如Postman）关闭客户端实例#2，因此只在端口`8081`上运行的实例在仪表板上仍然可见：'
- en: '![](img/0aea89ae-bdfb-43be-9acc-0e13ebf666f9.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0aea89ae-bdfb-43be-9acc-0e13ebf666f9.png)'
- en: 'The Eureka Server dashboard also provides a convenient way to check out the
    history of newly created and canceled leases:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Eureka服务器仪表板还提供了一种方便的方式来查看新创建和取消租约的历史记录：
- en: '![](img/097c33ca-f38d-4501-a15f-1051ccf56d4b.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/097c33ca-f38d-4501-a15f-1051ccf56d4b.png)'
- en: Graceful shutdown is obviously the most suitable way of stopping an application,
    but in the real world, we are not always able to achieve it. Many unexpected things
    can happen, such as a server machine restart, application failure, or just network
    problems at the interface between client and server. Such a situation is the same
    from a discovery server point of view as stopping the client application from
    your IDE or killing the process from the command line. If you try to do that,
    you will see that the discovery client shutdown procedure won't be triggered and
    the service is still visible in the Eureka dashboard with the *UP* status. Moreover,
    the lease will never expire.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 优雅关闭显然是停止应用程序的最合适方式，但在现实世界中，我们并不总是能够实现它。许多意想不到的事情可能发生，例如服务器机器重新启动、应用程序失败或客户端与服务器之间的网络问题。从发现服务器的角度来看，这种情况与从IDE中停止客户端应用程序或从命令行杀死进程相同。如果您尝试这样做，您将发现发现客户端关闭程序不会被触发，服务在Eureka仪表板上仍然显示为*UP*状态。此外，租约永远不会过期。
- en: 'In order to avoid this situation, the default configuration on the server side
    should be changed. *Why does such a problem appear in the default settings?* Eureka
    provides a special mechanism by which the registry stops expiring entries when
    it detects that an certain number of services didn''t renew their lease in time.
    This should protect the registry from clearing all entries when a part of a network
    failure occurs. That mechanism is called **self-preservation mode** and can be
    disabled using the `enableSelfPreservation` property in `application.yml`. Of
    course, it should not be disabled in production:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这种情况，服务器端的默认配置应该进行更改。*为什么在默认设置中会出现这样的问题？* Eureka提供了一个特殊的机制，当检测到一定数量的服务没有及时续租时，注册表停止过期条目。这应该保护注册表在网络部分故障时清除所有条目。这个机制被称为**自我保护模式**，可以在`application.yml`中使用`enableSelfPreservation`属性禁用它。当然，在生产环境中不应该禁用它：
- en: '[PRE8]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Using discovery client programmatically
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用发现客户端程序化
- en: 'After client application startup, the list of registered services is fetched
    from the Eureka Server automatically. However, it might turn out to be necessary
    to use Eureka''s client API programmatically. We have two possibilities:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端应用程序启动后，注册服务列表会自动从Eureka服务器获取。然而，有时可能需要程序化地使用Eureka的客户端API。我们有两种可能性：
- en: '`com.netflix.discovery.EurekaClient`: It implements all HTTP API methods exposed
    by the Eureka Server, which have been described in the Eureka API section.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`com.netflix.discovery.EurekaClient`：它实现了Eureka服务器暴露的所有HTTP API方法，这些方法在Eureka
    API部分已经描述过了。'
- en: '`org.springframework.cloud.client.discovery.DiscoveryClient`: It is a Spring
    Cloud alternative to the native Netflix `EurekaClient`. It provides a simple,
    generic API useful for all of the discovery clients. There are two methods available, `getServices`
    and `getInstances`:'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.springframework.cloud.client.discovery.DiscoveryClient`：这是Spring Cloud的一个替代Netflix
    `EurekaClient`的本地客户端。它提供了一个简单、通用的API，对于所有的发现客户端都很有用。有两个方法可用，`getServices`和`getInstances`：'
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: There is one interesting thing related to the preceding implementation. If you
    call the `/ping` endpoint just after the service startup, it won't display any
    instances. This is related to the response caching mechanisms and it is described
    in detail in the next section.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个与前面实现相关有趣的点。如果你在服务启动后立即调用`/ping`端点，它不会显示任何实例。这与响应缓存机制有关，下一节会详细描述。
- en: Advanced configuration settings
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级配置设置
- en: 'Eureka''s configuration settings may be divided into three parts:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Eureka的配置设置可以分为三部分：
- en: '**Server**: It customizes the server behavior. It includes all of the properties
    with the prefix `eureka.server.*`. The full list of available fields may be found
    in the `EurekaServerConfigBean` class ([https://github.com/spring-cloud/spring-cloud-netflix/blob/master/spring-cloud-netflix-eureka-server/src/main/java/org/springframework/cloud/netflix/eureka/server/EurekaServerConfigBean.java](https://github.com/spring-cloud/spring-cloud-netflix/blob/master/spring-cloud-netflix-eureka-server/src/main/java/org/springframework/cloud/netflix/eureka/server/EurekaServerConfigBean.java)).'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务器**：它定制了服务器的行为。它包括所有带有`eureka.server.*`前缀的属性。可用的字段完整列表可以在`EurekaServerConfigBean`类中找到([https://github.com/spring-cloud/spring-cloud-netflix/blob/master/spring-cloud-netflix-eureka-server/src/main/java/org/springframework/cloud/netflix/eureka/server/EurekaServerConfigBean.java](https://github.com/spring-cloud/spring-cloud-netflix/blob/master/spring-cloud-netflix-eureka-server/src/main/java/org/springframework/cloud/netflix/eureka/server/EurekaServerConfigBean.java))。'
- en: '**Client**: It is the first of two available property sections on the Eureka
    Client''s side. It is responsible for the configuration of how the client can
    query the registry in order to locate other services. It includes all of the properties
    with the prefix `eureka.client.*`. For the full list of available fields, you
    may refer to the `EurekaClientConfigBean` class ([https://github.com/spring-cloud/spring-cloud-netflix/blob/master/spring-cloud-netflix-eureka-client/src/main/java/org/springframework/cloud/netflix/eureka/EurekaClientConfigBean.java](https://github.com/spring-cloud/spring-cloud-netflix/blob/master/spring-cloud-netflix-eureka-client/src/main/java/org/springframework/cloud/netflix/eureka/EurekaClientConfigBean.java)).'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户端**：这是Eureka客户端侧可用的两个属性部分中的第一个。它负责配置客户端如何查询注册表以定位其他服务。它包括所有带有`eureka.client.*`前缀的属性。要查看所有可用字段的全列表，请参考`EurekaClientConfigBean`类
    ([https://github.com/spring-cloud/spring-cloud-netflix/blob/master/spring-cloud-netflix-eureka-client/src/main/java/org/springframework/cloud/netflix/eureka/EurekaClientConfigBean.java](https://github.com/spring-cloud/spring-cloud-netflix/blob/master/spring-cloud-netflix-eureka-client/src/main/java/org/springframework/cloud/netflix/eureka/EurekaClientConfigBean.java))。'
- en: '**Instance**: It customizes the current instance of the Eureka Client''s behavior,
    such as port or name. It includes all of the properties with the prefix `eureka.instance.*`. For
    the full list of available fields, you may refer to the `EurekaInstanceConfigBean` class ([https://github.com/spring-cloud/spring-cloud-netflix/blob/master/spring-cloud-netflix-eureka-client/src/main/java/org/springframework/cloud/netflix/eureka/EurekaInstanceConfigBean.java](https://github.com/spring-cloud/spring-cloud-netflix/blob/master/spring-cloud-netflix-eureka-client/src/main/java/org/springframework/cloud/netflix/eureka/EurekaInstanceConfigBean.java)).'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实例**：它定制了Eureka客户端当前实例的行为，例如端口或名称。它包括所有带有`eureka.instance.*`前缀的属性。要查看所有可用字段的全列表，请参考`EurekaInstanceConfigBean`类
    ([https://github.com/spring-cloud/spring-cloud-netflix/blob/master/spring-cloud-netflix-eureka-client/src/main/java/org/springframework/cloud/netflix/eureka/EurekaInstanceConfigBean.java](https://github.com/spring-cloud/spring-cloud-netflix/blob/master/spring-cloud-netflix-eureka-client/src/main/java/org/springframework/cloud/netflix/eureka/EurekaInstanceConfigBean.java))。'
- en: I have already shown you how to use some of those properties in order to have
    the desired effect. I'm going to talk about some interesting scenarios related
    to configuration settings customization in the next part of this section. It is
    not needed to describe all of the properties. You may read about them in the comments
    included in the source code of all of those classes that were listed previously.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经向你展示了如何使用这些属性以达到预期的效果。在下一部分中，我将讨论一些与配置设置自定义相关有趣的场景。不需要描述所有属性。你可以在前面列出的所有类的源代码中的注释中阅读它们。
- en: Refreshing the registry
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 刷新注册表
- en: 'Let''s back up for a moment to the previous sample. Self-preservation mode
    has been disabled, but it still takes a long time to wait on the lease cancellation
    by the server. There are several reasons for this. The first is that every client
    service sends heartbeats to the server every 30 seconds (default value), which
    is configurable with the `eureka.instance.leaseRenewalIntervalInSeconds` property. If
    the server doesn''t receive a heartbeat, it waits 90 seconds before removing the
    instance from the registry and thereby cutting off traffic sent to that instance. It
    is configurable with the `eureka.instance.leaseExpirationDurationInSeconds` property.
    Those two parameters are set on the client side. For testing purposes, we define
    small values in seconds:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先回到之前的示例。自保模式已被禁用，但仍然需要等待服务器取消租约，这需要很长时间。造成这种情况有几个原因。第一个原因是每个客户端服务会每30秒向服务器发送一次心跳（默认值），这可以通过`eureka.instance.leaseRenewalIntervalInSeconds`属性进行配置。如果服务器没有收到心跳，它会在90秒后从注册表中移除实例，从而切断发送到该实例的交通。这可以通过`eureka.instance.leaseExpirationDurationInSeconds`属性进行配置。这两个参数都是在客户端设置的。出于测试目的，我们在秒中定义了小的值：
- en: '[PRE10]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'There is also one property that should be changed on the server side. Eureka
    runs the evict task in the background, which is responsible for checking whether
    heartbeats from the client are still being received. By default, it is fired every
    60 seconds. So even if the interval of lease renewal and the duration of lease
    expiration are set to relatively low values, the service instance might be removed
    at worst after 60 seconds. The delay between the subsequent timer ticks can be
    configured using the `evictionIntervalTimerInMs` property, which is set, in contrast
    to properties discussed previously, in milliseconds:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在服务器端还应该更改一个属性。Eureka在后台运行evict任务，负责检查客户端的心跳是否仍在接收。默认情况下，它每60秒触发一次。所以，即使租约续订间隔和租约到期时长被设置为相对较低的值，服务实例在最坏的情况下也可能在60秒后被移除。后续计时器滴答之间的延迟可以通过使用`evictionIntervalTimerInMs`属性来配置，与前面讨论的属性不同，这个属性是以毫秒为单位的：
- en: '[PRE11]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'All of the required parameters have been defined on both the client and server
    side. Now, we can run the discovery server again and then three instances of the
    client application on ports `8081`, `8082`, and `8083` using the `-DPORT` VM argument.
    After that, we will shut down the instances on ports `8081 `and `8082` one by
    one, just by killing their processes. What is the result? The disabled instances
    are almost immediately removed from Eureka registry. Here''s the log fragment
    from the Eureka Server:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 所有必需的参数都已分别在客户端和服务端定义。现在，我们可以使用`-DPORT` VM参数再次运行发现服务器，然后在端口`8081`、`8082`和`8083`上启动客户端应用程序的三个实例。在那之后，我们逐一关闭端口`8081`和`8082`上的实例，只需杀死它们的进程即可。结果是什么？禁用的实例几乎立即从Eureka注册表中移除。以下是Eureka服务器的日志片段：
- en: '![](img/9053350f-ae07-434c-ab43-4e1040362e37.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9053350f-ae07-434c-ab43-4e1040362e37.png)'
- en: 'There is still one instance available running on port `8083`. The appropriate
    warning related to the deactivation of the self-preservation mode will be printed
    out on the UI dashboard. Some additional information such as lease expiration
    status or the number of renews during the last minute may also be interesting. By
    manipulating all of those properties, we are able to customize the maintenance
    of the expired lease removal procedure. However, it is important to ensure that
    defined settings would not lack the performance of a system. There are some other
    elements sensitive to the changes of configuration, like load balancers, gateways,
    and circuit breakers. Eureka prints a warning message if you disable the self-preservation
    mode, you can see it in the following screenshot:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 仍有一个实例正在监听端口`8083`。在自我维护模式被禁用时，与之一相关的警告信息将在UI仪表板上打印出来。一些额外的信息，比如租约到期状态或上分钟内续租次数，也许也挺有趣。通过操作所有这些属性，我们能够定制过期的租约移除流程的维护。然而，确保定义的设置不会影响系统的性能是很重要的。还有一些其他元素对配置的变化很敏感，比如负载均衡器、网关和熔断器。如果你禁用了自我维护模式，Eureka会打印一条警告信息，你可以在下面的截图中看到：
- en: '![](img/18a93209-3951-4751-a9a2-d1810cbace4e.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/18a93209-3951-4751-a9a2-d1810cbace4e.png)'
- en: Changing the instance identificator
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更改实例标识符
- en: 'Instances registered on Eureka are grouped by name, but each of them must send
    a unique ID, on the basis of which, the server is able to recognize it. Maybe
    you have noticed that `instanceId` is displayed in the dashboard for every service''s
    group in the Status column. Spring Cloud Eureka automatically generates that number
    and it is equal to the combination of the following fields:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在Eureka上注册的实例按名称分组，但每个实例必须发送一个唯一ID，基于此ID，服务器能够识别它。也许你已经注意到`instanceId`在仪表板上每个服务组的`Status`列中显示。Spring
    Cloud Eureka会自动生成这个数字，它等于以下字段的组合：
- en: '[PRE12]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This identificator may be easily overridden with the `eureka.instance.instanceId`
    property. For testing purposes, let''s launch some instances of the client application
    with the following configuration settings and the `-DSEQUENCE_NO=[n]` VM argument,
    where `[n]` is a sequence number starting from `1`. Here''s a sample configuration
    of a client''s application that dynamically sets the listen port and discovery
    `instanceId` based on the `SEQUENCE_NO` parameter:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这个标识符可以通过`eureka.instance.instanceId`属性轻松覆盖。为了测试目的，让我们启动一些客户端应用程序实例，使用以下配置设置和`-DSEQUENCE_NO=[n]`
    VM参数，其中`[n]`从`1`开始的序列号。以下是一个根据`SEQUENCE_NO`参数动态设置监听端口和发现`instanceId`的客户端应用程序的示例配置：
- en: '[PRE13]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The results may be viewed in the Eureka dashboard:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可以在Eureka仪表板上查看：
- en: '![](img/fdb301da-0900-4cbf-abef-b084cbf557b9.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fdb301da-0900-4cbf-abef-b084cbf557b9.png)'
- en: Preferring the IP address
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优先选择IP地址
- en: By default, all instances are registered under their hostname. It is a very
    convenient approach, on the assumption that we have DNS enabled on our network.
    However, it is not uncommon that DNS is not available for a group of servers used
    as the microservice environment in the organization. I just had that kind of situation
    myself. There remains nothing else to do but to add host names and their IP addresses
    to the `/etc/hosts` file on all of the Linux machines. An alternative to this
    solution is to change the registration process configuration settings to advertise
    the IP addresses of services rather than the hostname. To achieve this, the `eureka.instance.preferIpAddress` property should
    be set to `true` on the client side. Every service instance in the registry will
    still be printed out to a Eureka dashboard with `instanceId` containing a hostname,
    but if you click this link the redirection will be performed based on the IP address.
    The Ribbon client that is responsible for calling other services via HTTP will
    also follow the same principle.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，所有实例都注册在其主机名下。这是一个非常方便的方法，前提是我们在我们的网络上启用了DNS。然而，对于用作组织中微服务环境的服务器组，DNS通常是不可用的，我自己就遇到过这种情况。除了在所有Linux机器上的`/etc/hosts`文件中添加主机名及其IP地址外，别无他法。这种解决方案的替代方法是更改注册过程配置设置，以广告服务的IP地址而不是主机名。为了实现这一点，客户端应将`eureka.instance.preferIpAddress`属性设置为`true`。注册表中的每个服务实例仍然会以`instanceId`包含主机名的形式打印到Eureka仪表板中，但如果你点击这个链接，重定向将基于IP地址进行。负责通过HTTP调用其他服务的Ribbon客户端也将遵循相同的原则。
- en: 'If you decide to use an IP address as a primary method of determining the network
    location of the service, you may have a problem. The problem may arise if you
    have more than one network interface assigned to your machine. For example, in
    one organization where I have been working, there were different networks for
    a management mode (a connection from my workstation to the server) and for a production
    mode (a connection between two servers). In consequence, each server machine had
    two network interfaces assigned with different IP prefixes. To select the right
    interface, you can define a list of ignored patterns in the `application.yml`
    configuration file. For example, we would like to ignore all interfaces where
    the name starts with `eth1`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你决定使用IP地址作为确定服务网络位置的主要方法，你可能会有问题。如果你有多个网络接口分配给你的机器，可能会出现问题。例如，在我曾经工作过的某个组织中，管理模式（我的工作站与服务器之间的连接）和生产模式（两台服务器之间的连接）有不同的网络。因此，每台服务器机器都分配有两个网络接口，具有不同的IP前缀。为了选择正确的接口，你可以在`application.yml`配置文件中定义一个忽略的模式列表。例如，我们希望能够忽略所有接口，其名称以`eth1`开头：
- en: '[PRE14]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'There is also another way to get that effect. We can define network addresses
    that should be preferred:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种方法可以获得那种效果。我们可以定义应该优先的网络地址：
- en: '[PRE15]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Response cache
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 响应缓存
- en: 'The Eureka Server caches responses by default. The cache is invalidated every
    30 seconds. It can be easily checked by calling the HTTP API endpoint `/eureka/apps`.
    If you call it just after the registration of the client application, you will
    figure out that it is still not returned in the response. Try again after 30 seconds,
    and you will see that the new instance appears. The response cache timeout may
    be overridden with the `responseCacheUpdateIntervalMs` property. Interestingly,
    there is no cache while displaying a list of registered instances using the Eureka
    dashboard. In contrast to the REST API, it bypasses the response cache:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Eureka Server默认缓存响应。缓存每30秒失效一次。可以通过调用HTTP API端点`/eureka/apps`轻松检查。如果你在客户端应用程序注册后立即调用它，你会发现响应中仍然没有返回。30秒后再试，你会发现新实例出现了。响应缓存超时可以通过`responseCacheUpdateIntervalMs`属性覆盖。有趣的是，在使用Eureka仪表板显示已注册实例列表时，并没有缓存。与REST
    API相比，它绕过了响应缓存：
- en: '[PRE16]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We should remember that the Eureka registry is also cached on the client side.
    So, even if we changed the cache timeout on the server, it may still take some
    time until it would be refreshed by the client. The registry is periodically refreshed
    in an asynchronous, background task that is scheduled every 30 seconds by default. 
    This setting may be overridden by declaring the `registryFetchIntervalSeconds` property.
    It only fetches the delta in comparison to the last fetch attempt. This option
    may be disabled using the `shouldDisableDelta` property. I defined `3` seconds
    timeouts on both the server and client sides. If you start the sample application
    with such settings, `/eureka/apps` will show the newly registered instance of
    the service, probably at your first attempt. Unless caching on the client side
    makes sense, I''m not sure about the sense of caching on the server side, especially
    since Eureka doesn''t have any backend store. Personally, I have never had any
    need to change the values of those properties, but I guess it can be important,
    for example, if you develop unit tests with Eureka and you need an immediate response
    without caching:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该记住，Eureka注册表也缓存在客户端。所以，即使我们在服务器端更改了缓存超时时间，它可能仍然需要一段时间才能被客户端刷新。注册表通过一个默认每30秒调度一次的异步后台任务定期刷新。这个设置可以通过声明`registryFetchIntervalSeconds`属性来覆盖。它只获取与上一次抓取尝试相比的增量。可以通过使用`shouldDisableDelta`属性来禁用此选项。我在服务器和客户端两边都定义了`3`秒的超时时间。如果你用这样的设置启动示例应用程序，`/eureka/apps`将显示新注册服务的实例，可能在你的第一次尝试中。除非客户端端的缓存有意义，否则我不确定在服务器端缓存是否有意义，尤其是因为Eureka没有后端存储。就个人而言，我从未需要更改这些属性的值，但我猜想它可能很重要，例如，如果你使用Eureka开发单元测试，并且需要无缓存的即时响应：
- en: '[PRE17]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Enabling secure communication between client and server
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启用客户端和服务器之间的安全通信
- en: 'Until now, none of the client''s connections were being authenticated by the
    Eureka Server. While in the development mode, security doesn''t really matter
    as much as in the production mode. The lack of it may be a problem. We would like
    to have, as a bare minimum, the discovery server secured with basic authentication
    to prevent unauthorized access to any service that knows its network address.
    Although Spring Cloud reference material claims that *HTTP basic authentication
    will be automatically added to your Eureka Client*, I had to include a starter
    with security to the project dependencies:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，Eureka服务器没有对客户端的任何连接进行身份验证。在开发模式下，安全性并不像在生产模式下那么重要。缺乏安全性可能是一个问题。我们希望能够至少确保发现服务器通过基本身份验证进行安全，以防止任何知道其网络地址的服务遭受未经授权的访问。尽管Spring
    Cloud参考资料声称*HTTP基本身份验证将自动添加到您的Eureka客户端*，但我还是不得不将带有安全性的启动器添加到项目依赖中：
- en: '[PRE18]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then, we should enable security and set the default credentials by changing
    the configuration settings in the `application.yml` file:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们应该启用安全功能，并通过在`application.yml`文件中更改配置设置来设置默认凭据：
- en: '[PRE19]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, all HTTP API endpoints and the Eureka dashboard are secured. To enable
    the basic authentication mode on the client side, the credentials should be provided
    within the URL connection address, as you can see in the following configuration
    settings. An example application that implements secure discovery is available
    in the same repository ([https://github.com/piomin/sample-spring-cloud-netflix.git](https://github.com/piomin/sample-spring-cloud-netflix.git))
    as the basic example, but you need to switch to the `security` branch ([https://github.com/piomin/sample-spring-cloud-netflix/tree/security](https://github.com/piomin/sample-spring-cloud-netflix/tree/security)).
    Here''s the configuration that enabled HTTP basic authentication on the client
    side:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，所有HTTP API端点和Eureka仪表板都得到了保护。要在客户端启用基本身份验证模式，应在URL连接地址中提供凭据，正如您在以下配置设置中所看到的那样。一个实现了安全发现示例应用程序在同一个存储库中
    basic example，但您需要切换到`security`分支([https://github.com/piomin/sample-spring-cloud-netflix/tree/security](https://github.com/piomin/sample-spring-cloud-netflix/tree/security))。以下是客户端启用HTTP基本身份验证的配置：
- en: '[PRE20]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: For more advanced use, such as secure SSL connection with certificate authentication between
    discovery client and server, we should provide a custom implementation of `DiscoveryClientOptionalArgs`.
    We will discuss such an example in [Chapter 12](b7e73d3e-b31b-4127-bb1a-54f527ac98a8.xhtml),
    *Securing an API*, specifically dedicated to security for Spring Cloud applications.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更高级的使用，例如在发现客户端和服务器之间使用证书认证的安全SSL连接，我们应该提供一个`DiscoveryClientOptionalArgs`的自定义实现。我们将在[第12章](b7e73d3e-b31b-4127-bb1a-54f527ac98a8.xhtml)，*保护API*，专门讨论Spring
    Cloud应用程序的安全性，讨论这样一个例子。
- en: Registering a secure service
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 注册安全服务
- en: 'Securing the server side is one thing; registering a secure application is
    something else. Let''s look at how we can do this:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 保护服务器端是一回事，注册安全应用程序是另一回事。让我们看看我们如何做到这一点：
- en: 'To enable SSL for a Spring Boot application, we need to start with generating
    a self-signed certificate. I recommend you use `keytool` for that, which is available
    under your JRE root in the `bin` catalog:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了给Spring Boot应用程序启用SSL，我们需要从生成自签名证书开始。我建议你使用`keytool`，它可以在你JRE根目录下的`bin`目录中找到：
- en: '[PRE21]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Enter the required data and copy the generated keystore file `keystore.p12`
    to your application''s `src/main/resources` catalog. The next step is to enable
    HTTPS for Spring Boot using configuration properties in `application.yml`:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入所需数据，并将生成的密钥库文件`keystore.p12`复制到您应用程序的`src/main/resources`目录中。下一步是使用`application.yml`中的配置属性为Spring
    Boot启用HTTPS：
- en: '[PRE22]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'After running the application, you should be able to call the secure endpoint
    `https://localhost:8761/info`. We also need to perform some changes in the Eureka
    client instance configuration:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在运行应用程序之后，您应该能够调用安全端点`https://localhost:8761/info`。我们还需要对Eureka客户端实例配置进行一些更改：
- en: '[PRE23]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Eureka API
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Eureka API
- en: 'Spring Cloud Netflix provides a client written in Java that hides the Eureka
    HTTP API from the developer. In case we use other frameworks than Spring, Netflix
    OSS provides a vanilla Eureka client that can be included as a dependency. However,
    we may imagine a need to call the Eureka API directly, for example, if the application
    is written in another language than Java, or we need such information as a list
    of registered services in the Continuous Delivery process. Here''s a table for
    quick reference:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Netflix提供了一个用Java编写的客户端，将Eureka HTTP API隐藏在开发者面前。如果我们使用除Spring之外的其他框架，Netflix
    OSS提供了一个原味的Eureka客户端，可以作为依赖项包含在内。然而，我们可能需要直接调用Eureka API，例如，如果应用程序是用Java以外的语言编写的，或者我们需要在持续交付过程中注册的服务列表等信息。以下是一个快速参考表：
- en: '| **HTTP endpoint** | **Description** |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| **HTTP端点** | **描述** |'
- en: '| `POST /eureka/apps/appID` | Add a new instance of the service to the registry
    |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| `POST /eureka/apps/appID` | 将服务的新实例注册到注册表 |'
- en: '| `DELETE /eureka/apps/appID/instanceID` | Remove the instance of the service
    from the registry |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| `DELETE /eureka/apps/appID/instanceID` | 从注册表中删除服务实例 |'
- en: '| `PUT /eureka/apps/appID/instanceID` | Send a heartbeat to the server |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| `PUT /eureka/apps/appID/instanceID` | 向服务器发送心跳 |'
- en: '| `GET /eureka/apps` | Get details about the list of all registered instances
    of services |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| `GET /eureka/apps` | 获取有关所有注册服务实例列表的详细信息 |'
- en: '| `GET /eureka/apps/appID`  | Get details about the list of all registered
    instances of a specific service |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| `GET /eureka/apps/appID` | 获取特定服务所有注册实例列表的详细信息 |'
- en: '| `GET /eureka/apps/appID/instanceID` | Get details about a single instance
    of the service |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| `GET /eureka/apps/appID/instanceID` | 获取特定服务实例的详细信息 |'
- en: '| `PUT /eureka/apps/appID/instanceID/metadata?key=value` | Update metadata
    parameters |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| `PUT /eureka/apps/appID/instanceID/metadata?key=value` | 更新元数据参数 |'
- en: '| `GET /eureka/instances/instanceID` | Get details about all registered instances
    with a specific ID  |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| `GET /eureka/instances/instanceID` | 获取具有特定ID的所有注册实例的详细信息 |'
- en: '| `PUT /eureka/apps/appID/instanceID/status?value=DOWN` | Update the status
    of the instance |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| `PUT /eureka/apps/appID/instanceID/status?value=DOWN` | 更新实例的状态 |'
- en: Replication and high availability
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 复制和高度可用性
- en: We have already discussed some useful Eureka settings, but until now we have
    analyzed only a system with a single service discovery server. Such a configuration
    is valid, but only in development mode. For production mode, we would like to
    have at least two discovery servers running in case one of them fails or a network
    problem occurs. Eureka is by definition built for availability and resiliency,
    two primary pillars of development at Netflix. But it does not provide standard
    clustering mechanisms such as leadership election or automatically joining to
    the cluster. It is based on the peer-to-peer replication model. It means that
    all of the servers replicate data and send heartbeats to all of the peers, which
    are set in configuration for the current server node. Such an algorithm is simple
    and effective for containing data, but it also has some drawbacks. It limits scalability,
    because every node has to withstand the entire write load on the server.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了一些有用的Eureka设置，但到目前为止，我们只分析了一个单一服务发现服务器的系统。这种配置是有效的，但只适用于开发模式。对于生产模式，我们希望能够至少运行两个发现服务器，以防其中一个失败或发生网络问题。Eureka按定义是为了可用性和弹性而构建的，这是Netflix开发的主要支柱之二。但它不提供标准的集群机制，如领导选举或自动加入集群。它是基于对等复制模型。这意味着所有服务器复制数据并向所有对等节点发送心跳，这些节点在当前服务器节点的配置中设置。这种算法简单有效，用于包含数据，但它也有一些缺点。它限制了可扩展性，因为每个节点都必须承受服务器上的整个写入负载。
- en: Architecture of the sample solution
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例解决方案的架构
- en: Interestingly, a replication mechanism was one of the major motivations to begin
    work on the new version of the Eureka Server. Eureka 2.0 is still under active
    development. Besides optimized replication, it will also provide some interesting
    features such as a push model from the server to clients for any changes in the
    registration list, auto-scaled servers, and a rich dashboard. This solution seems
    promising, but Spring Cloud Netflix still uses version 1 and to be honest I was
    not able to find any plans for the migration to version 2\. The current Eureka
    version for Dalston.SR4 Release Train is 1.6.2\. The configuration of the clustering
    mechanism on the server side comes down to one thing, the set URL of another discovery
    server using `eureka.client.*` properties section. The selected server would just
    register itself in the other servers, which were chosen to be a part of the created
    cluster. The best way to show how this solution works in practice is of course
    by example.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，复制机制是新版本Eureka Server开始工作的主要动机之一。Eureka 2.0仍然处于积极开发中。除了优化的复制功能外，它还将提供一些有趣的功能，如服务器向客户端推送注册列表中任何更改的推送模型，自动扩展服务器和一个丰富的仪表板。这个解决方案看起来很有希望，但Spring
    Cloud Netflix仍然使用版本1，老实说我没有找到任何迁移到版本2的计划。Dalston.SR4发布列车当前的Eureka版本是1.6.2。服务器端复制机制的配置归结为一点，即使用`eureka.client.*`属性部分设置另一个发现服务器的URL。所选服务器只需在其他服务器中注册自己，这些服务器被选择作为创建的集群的一部分。展示这个解决方案在实践中如何工作的最好方式当然是通过示例。
- en: 'Let''s begin with the architecture of the example system, which is shown in
    the following diagram. All of our applications will be run locally on different
    ports. At this stage, we have to introduce the example of the API gateway based
    on Netflix Zuul. It would be helpful for the purpose of load balancing tests between
    three instances of a service registered in different zones:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从示例系统的架构开始，如下面的图表所示。我们的所有应用程序都将在本地不同端口上运行。在这个阶段，我们必须介绍基于Netflix Zuul的API网关的示例。这对于在不同区域的三个服务实例之间进行负载均衡测试非常有帮助：
- en: '![](img/39bca4a7-e902-4c34-bdd1-b5118fd74640.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/39bca4a7-e902-4c34-bdd1-b5118fd74640.png)'
- en: Building the example application
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建示例应用程序
- en: 'For the Eureka Server, all of the required changes may be defined in configuration
    properties. In the `application.yml` file, I defined three different profiles
    for each instance of the discovery service. Now, if you try to run Eureka Server
    embedded in the Spring Boot application, you need to activate the specific profile
    by providing the VM argument `-Dspring.profiles.active=peer[n]`, where `[n]` is
    the instance sequence number:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Eureka Server，所有必需的更改可能定义在配置属性中。在`application.yml`文件中，我为每个发现服务实例定义了三个不同的配置文件。现在，如果您尝试在Spring
    Boot应用程序中运行Eureka Server，您需要通过提供VM参数`-Dspring.profiles.active=peer[n]`来激活特定的配置文件，其中`[n]`是实例序列号：
- en: '[PRE24]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'After running all three instances of Eureka using different profile names,
    we created a local discovery cluster. If you take a look at the Eureka dashboard
    for any instance just after startup, it always looks the same, we have three instances
    of DISCOVERY-SERVICE visible:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用不同配置文件名称运行所有三个Eureka实例之后，我们创建了一个本地发现集群。如果您在启动后立即查看任何Eureka实例的仪表板，它总是看起来一样，我们可以看到三个DISCOVERY-SERVICE实例：
- en: '![](img/82c4f7d9-4624-4b6b-ae20-729088d40aff.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/82c4f7d9-4624-4b6b-ae20-729088d40aff.png)'
- en: 'The next step is to run the client application. The configuration settings
    in the projects are very similar to those for the application with the Eureka
    Server. The order of addresses provided in the `defaultZone` field determines
    the sequence of connection attempts to different discovery services. If the connection
    to the first server cannot be established, it tries to connect with the second
    one from the list, and so on. The same as earlier, we should set the VM argument `-Dspring.profiles.active=zone[n]` 
    to select the right profile. I also suggest you set the `-Xmx192m` parameter,
    keeping in mind that we test all of the services locally. If you do not provide
    any memory limits for the Spring Cloud application it consumes around 350 MB of
    heap after starting, and about 600 MB of total memory. Unless you have got a lot
    of RAM it may make it difficult to run multiple instances of microservices on
    your local machine:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是运行客户端应用程序。项目中的配置设置与Eureka服务器的应用程序非常相似。`defaultZone`字段中提供的地址顺序决定了尝试连接不同发现服务的顺序。如果无法连接到第一个服务器，它会尝试从列表中连接第二个服务器，依此类推。与之前一样，我们应该设置VM参数`-Dspring.profiles.active=zone[n]`以选择正确的配置文件。我还建议您设置`-Xmx192m`参数，考虑到我们本地测试所有的服务。如果您不为Spring
    Cloud应用程序提供任何内存限制，它在启动后大约会消耗350MB的堆内存，总内存大约600MB。除非您有很多RAM，否则它可能会使您在本地机器上运行微服务的多个实例变得困难：
- en: '[PRE25]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Let''s take a look at the Eureka dashboard again. We have three instances of
    `client-service` registered everywhere, although the application has been originally
    connected to only one instance of the discovery service. The result is the same
    no matter which discovery service instance''s dashboard we go into to look at.
    It was the exact purpose of this exercise. Now, we create some additional implementation
    only to demonstrate that everything works in accordance with the assumptions:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次查看Eureka仪表板。我们有`client-service`的三个实例在所有地方注册，尽管应用程序最初只连接到一个发现服务实例。无论我们进入哪个发现服务实例的仪表板查看，结果都是一样的。这正是这次练习的目的。现在，我们创建一些额外的实现仅为了证明一切按预期工作：
- en: '![](img/8fd6c50b-fd76-4f61-8b37-2459cbbf63f0.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8fd6c50b-fd76-4f61-8b37-2459cbbf63f0.png)'
- en: 'The client application does nothing more than expose a REST endpoint that prints
    the selected profile name. The profile name points to the primary discovery service
    instance for the particular application instance. Here''s a simple `@RestController`
    implementation that prints the name of the current zone:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端应用程序所做的不仅仅是暴露一个打印所选配置文件名称的REST端点。配置文件名称指向特定应用程序实例的主要发现服务实例。下面是一个简单的`@RestController`实现，打印当前区域的名称：
- en: '[PRE26]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Finally, we can proceed to the implementation of API gateway. It''s out of
    the scope of this chapter to go into detail about features provided by Zuul, Netflix''s
    API gateway, and router. We will discuss it in the next chapters. Zuul will now
    be helpful in testing our sample solution, because it is able to retrieve the
    list of services registered in the discovery server and perform load balancing
    between all of the running instances of the client application. As you can see
    in the following configuration fragment, we use a discovery server listening on
    port `8763`. All incoming requests with the `/api/client/**` path would be routed
    to `client-service`:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以继续实现API网关。在本章范围内详细介绍Zuul，Netflix的API网关和路由功能是不合适的。我们将在下一章讨论它。Zuul现在将有助于测试我们的示例解决方案，因为它能够检索在发现服务器中注册的服务列表，并在客户端应用程序的所有运行实例之间执行负载均衡。正如您在下面的配置片段中所看到的，我们使用一个在端口`8763`上监听的发现服务器。所有带有`/api/client/**`路径的传入请求将被路由到`client-service`：
- en: '[PRE27]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let''s move on to the testing. Our application with the Zuul proxy should be
    launched using the `java -jar` command and unlike previous services, there is
    no need to set any additional parameters, including a profile name. It is connected
    by default with discovery service number #3\. To invoke the client API via the
    Zuul proxy, you have to type the following address into your web browser, `http://localhost:8765/api/client/ping`.
    The result is visible in the following screenshot:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来让我们进行测试。我们的应用通过Zuul代理启动时应使用`java -jar`命令，与之前的服务不同，这里无需设置任何额外参数，包括配置文件名。它默认与编号为#3的发现服务相连。要通过Zuul代理调用客户端API，你需要在网页浏览器中输入以下地址，`http://localhost:8765/api/client/ping`。结果如下截图所示：
- en: '![](img/82dce964-212f-4a2b-8fd2-f8aa4db10fdc.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/82dce964-212f-4a2b-8fd2-f8aa4db10fdc.png)'
- en: 'If you retry the request a few times in a row, it should be load balanced between
    all of the existing `client-service` instances in the proportions 1:1:1, although
    our gateway is connected only to discovery #3\. This example fully demonstrates
    how to build service discovery with multiple Eureka instances.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你连续重试几次请求，它应该在所有现有的`client-service`实例之间进行负载均衡，比例为1:1:1，尽管我们的网关只连接到发现#3。这个例子充分展示了如何使用多个Eureka实例构建服务发现。
- en: The preceding example application is available on GitHub ([https://github.com/piomin/sample-spring-cloud-netflix.git](https://github.com/piomin/sample-spring-cloud-netflix.git))
    in the `cluster` branch ([https://github.com/piomin/sample-spring-cloud-netflix/tree/cluster_no_zones](https://github.com/piomin/sample-spring-cloud-netflix/tree/cluster_no_zones)).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 前面提到的示例应用程序在GitHub上可获得，位于`cluster`分支中([https://github.com/piomin/sample-spring-cloud-netflix.git](https://github.com/piomin/sample-spring-cloud-netflix.git))([https://github.com/piomin/sample-spring-cloud-netflix/tree/cluster_no_zones](https://github.com/piomin/sample-spring-cloud-netflix/tree/cluster_no_zones))。
- en: Failover
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 故障转移
- en: 'You probably wish to ask what''s going to happen if one instance of service
    discovery breaks down? In order to check how the cluster would behave in case
    of failure, we are going to modify the earlier sample a little. Now, Zuul has
    a failover connection to the second service discovery available on port `8762` set
    in its configuration settings. For testing purposes, we shut down the third instance
    of the discovery service available on port `8763`:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想知道如果服务发现的一个实例崩溃了会发生什么？为了检查集群在故障发生时的行为，我们将稍稍修改之前的示例。现在，Zuul在其配置设置中有一个到第二个服务发现的故障转移连接，端口为`8762`。为了测试目的，我们关闭了端口`8763`上的第三个发现服务实例：
- en: '[PRE28]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The current situation is illustrated in the following diagram. Testing is performed
    in the same way as earlier, by calling the gateway''s endpoint available under
    the `http://localhost:8765/api/client/ping address`. And the result is also the
    same as for the previous test, load balancing is performed equally among all three
    `client-service` instances as expected. Although discovery service #3 has been
    disabled, two other instances are still able to communicate with each other and
    have information about the network location of the third client application instance
    replicated from instance #3 as long as it was active. Now, even if we restart
    our gateway, it is still able to connect the discovery cluster using the second
    address in order, set inside the `defaultZone` field `http://localhost:8762/eureka`.
    The same applies to the third instance of the client application, which in turn
    has discovery service #1 as a backup connection:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 当前情况在下图中说明。测试通过调用网关端点进行，端点地址为`http://localhost:8765/api/client/ping`。结果与之前测试相同，负载均衡在所有三个`client-service`实例之间平均进行，符合预期。尽管发现服务#3已被禁用，但另外两个实例仍能相互通信，并从实例#3复制第三个客户端应用实例的网络位置信息，只要实例#3处于活动状态。现在，即使我们重新启动网关，它仍能够使用`defaultZone`字段中的第二个地址顺序连接发现集群，地址为`http://localhost:8762/eureka`。对于客户端应用的第三个实例也适用，该实例反过来将发现服务#1作为备份连接：
- en: '![](img/6a432d7f-3bbb-4afb-89e2-a306aa26fa2d.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6a432d7f-3bbb-4afb-89e2-a306aa26fa2d.png)'
- en: Zones
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 区域
- en: 'A cluster-based on a peer-to-peer replication model is a good way to go in
    most cases, but not always enough. Eureka has one more interesting feature that
    can be very useful in a clustered environment. A zone mechanism is, in fact, the
    default behavior. Even if we have a single standalone service discovery instance,
    every client''s property has to be set to `eureka.client.serviceUrl.defaultZone`
    in the configuration settings. When will this be useful to us? To analyze it,
    we go back to the example from the previous section. Let''s imagine that now we
    have our environment divided into three different physical networks, or we just
    have three different machines processing the incoming requests. Of course, discovery
    services are still grouped logically in the cluster, but each instance is placed
    in a separated zone. Every client application would be registered in the same
    zone as its main discovery server. Instead of one instance of the Zuul gateway,
    we are going to launch three instances, each one for a single zone. If the request
    comes into a gateway, it should prefer those clients that leverage services within
    the same zone before trying to call services registered in another zone. The current
    system architecture is visualized in the following diagram. Of course, for example
    purposes, the architecture was simplified to be able to run on a single local
    machine. In the real world, like I mentioned before, it would be launched on three
    different machines or even on three different groups of machines, physically separated
    into other networks:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 基于对等复制的集群在大多数情况下是一个不错的选择，但并非总是足够。Eureka还有一个在集群环境中可能非常有用的有趣特性。实际上，区域机制是默认行为。即使我们有一个单独的独立服务发现实例，每个客户端的属性也必须在配置设置中设置为`eureka.client.serviceUrl.defaultZone`。这什么时候对我们有用呢？为了解析它，我们回到前面章节中的示例。让我们假设现在我们的环境被划分为三个不同的物理网络，或者我们只是有三台不同的机器处理传入的请求。当然，服务发现服务在逻辑上仍然分组在集群中，但每个实例都位于一个单独的区域。每个客户端应用程序都将注册在与其主要服务发现服务器相同的区域。我们不是要启动一个Zuul网关的实例，而是要启动三个实例，每个实例对应一个单一的区域。如果请求进入网关，它应该在尝试调用注册在其他区域的服务之前，优先考虑利用同一区域内的服务客户端。当前系统架构在下图中可视化。当然，为了示例的目的，架构被简化为能够在单个本地机器上运行。在现实世界中，如我之前提到的，它将在三台不同的机器上启动，甚至可能在其他网络上物理分离成三组机器：
- en: '![](img/76b111a0-a8bf-4152-bc6b-da28a8e922c4.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/76b111a0-a8bf-4152-bc6b-da28a8e922c4.png)'
- en: Zones with a standalone server
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 具有独立服务器的区域
- en: 'At this stage, we should emphasize one important thing, the zoning mechanism
    is realized only on the client side. This means that the service discovery instance
    is not assigned to any zone. So the preceding diagram may be slightly confusing,
    but it indicates which Eureka is the default service discovery for all client
    applications and gateways registered in the specific zone. Our purpose is to check
    out the mechanisms in the high availability mode, but we may as well build it
    only with a single discovery server. The following diagram illustrates a similar
    situation as the previous diagram, except that it assumes the existence of only
    a single discovery server for all of the applications:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们应该强调一点，区域机制仅在客户端实现。这意味着服务发现实例没有被分配到任何区域。所以前一个图表可能有些令人困惑，但它指示了哪个Eureka是特定区域中所有客户端应用程序和网关的默认服务发现。我们的目的是检查高可用性模式下的机制，但我们也可以只构建一个单一的服务发现服务器。以下图表展示了与前一个图表类似的情况，不同之处在于它假设只有一个服务发现服务器为所有应用程序服务：
- en: '![](img/d2c54f1c-e08d-48f7-a360-5ae1a1153c36.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d2c54f1c-e08d-48f7-a360-5ae1a1153c36.png)'
- en: Building an example application
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建示例应用程序
- en: 'To enable zone handling, we need to perform some changes in the client''s and
    gateway''s configuration settings. Here''s a modified `application.yml` file from
    the client application:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 为了启用区域处理，我们需要对客户端和网关的配置设置进行一些更改。以下是从客户端应用程序中修改的`application.yml`文件：
- en: '[PRE29]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The only thing that had to be updated is the `eureka.instance.metadataMap.zone `property,
    where we set the names of the zone and our service had been registered.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一需要更新的是`eureka.instance.metadataMap.zone `属性，我们在其中设置了区域名称和我们的服务已注册的服务名称。
- en: 'More changes have to be made in the gateway configuration. First, we need to
    add three profiles to be able to run an application registered in three different
    zones and three different discovery servers. Now when launching the gateway application,
    we should set the VM argument `-Dspring.profiles.active=zone[n]` to select the
    right profile. Similar to `client-service`, we also had to add the `eureka.instance.metadataMap.zone`
    property within the configuration settings. There is also one property, `eureka.client.preferSameZoneEureka`,
    used for the first time in the example, which had to be equal to `true` if the
    gateway should prefer instances of the client application registered in the same
    zone:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在网关配置中必须进行更多更改。首先，我们需要添加三个配置文件，以便能够在三个不同区域和三个不同的发现服务器上运行一个应用程序。现在当启动网关应用程序时，我们应该设置VM参数`-Dspring.profiles.active=zone[n]`以选择正确的配置文件。与`client-service`类似，我们还必须在配置设置中添加`eureka.instance.metadataMap.zone`属性。还有一个属性`eureka.client.preferSameZoneEureka`，在示例中首次使用，如果网关应该优先选择注册在同一区域的客户端应用程序实例，则必须将其设置为`true`：
- en: '[PRE30]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'After launching all of the instances of discovery, client, and gateway applications,
    we can try to call endpoints available under the `http://localhost:8765/api/client/ping`,
    `http://localhost:8766/api/client/ping`, and `http://localhost:8767/api/client/ping`
    addresses. Every one of them would always be communicating with the client instance
    registered in the same zone. So in contrast to tests without a preferred zone,
    for example, the first instance of gateway available under port `8765` always
    prints I''m in zone zone1 while calling the ping endpoint:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动发现、客户端和网关应用程序的所有实例后，我们可以尝试调用在`http://localhost:8765/api/client/ping`、`http://localhost:8766/api/client/ping`和`http://localhost:8767/api/client/ping`地址下可用的端点。它们都将始终与注册在相同区域的客户端实例进行通信。因此，与没有首选区域的测试相比，例如，端口`8765`上可用的第一个网关实例始终打印出“我在zone1区域”并在调用ping端点时：
- en: '![](img/df5918ad-c4b6-477b-a705-6ff4a7ba736d.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/df5918ad-c4b6-477b-a705-6ff4a7ba736d.png)'
- en: 'What will happen when client #1 is not available? The incoming requests would
    be load balanced 50/50 between two other instances of the client application,
    because they are both in different zones than gateway #1.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 当客户端#1不可用时会发生什么？因为它们都位于与网关#1不同的区域，所以传入的请求将被负载均衡50/50分配到两个其他客户端应用程序实例。
- en: Summary
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we had the opportunity to develop applications using Spring
    Cloud for the first time in this book. In my opinion, the best way to start an
    adventure with a framework for microservices is with trying to figure out how
    to implement service discovery properly. Starting with the simplest use cases
    and examples, we have been going through advanced and production-ready features
    provided by the Netflix OSS Eureka project. I have shown you how to create and
    run a basic client and a standalone discovery server in *five minutes*. Based
    on that implementation, I have introduced how to customize the Eureka client and
    server to meet our specific needs, placing the emphasis on negative scenarios
    such as network or application failure. Such features as the REST API or UI dashboard
    have been discussed in detail. Finally, I have shown you how to create a production-ready
    environment using Eureka's mechanisms such as replication, zones, and high availability.
    With that knowledge, you should be able to choose those features of Eureka through
    which you build a service discovery adapted to the specifics of your microservice-based
    architecture.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们有机会首次在本书中使用Spring Cloud开发应用程序。在我看来，开始微服务框架冒险的最佳方式是尝试弄清楚如何正确实现服务发现。从最简单的用例和示例开始，我们已经经历了Netflix
    OSS Eureka项目提供的先进且生产就绪的功能。我向您展示了如何在*五分钟内*创建和运行一个基本客户端和一个独立的发现服务器。基于该实现，我介绍了如何自定义Eureka客户端和服务器以满足我们的特定需求，重点放在网络或应用程序失败等负面场景上。诸如REST
    API或UI仪表板等特性已经详细讨论。最后，我向您展示了如何使用Eureka的机制（如复制、区域和高可用性）创建一个生产就绪环境。有了这些知识，您应该能够选择通过Eureka构建适合您微服务架构特性的服务发现功能。
- en: Once we have discussed service discovery, we may proceed to the next essential
    element in microservice-based architecture, a configuration server. Both discovery
    and configuration services are usually based on key/value stores, so they may
    be provided with the same products. However, since Eureka is dedicated only to
    discovery, Spring Cloud introduces their own framework for managing distributed
    configurations, Spring Cloud Config.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们讨论了服务发现，我们就可以继续探讨微服务架构中的下一个关键元素：配置服务器。服务和配置服务通常都基于键/值存储，因此它们可能由相同的产品提供。然而，由于Eureka只专注于发现，Spring
    Cloud引入了自己的框架来管理分布式配置，即Spring Cloud Config。
