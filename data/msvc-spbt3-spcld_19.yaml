- en: '19'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '19'
- en: Centralized Logging with the EFK Stack
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用EFK堆栈进行集中日志记录
- en: 'In this chapter, we will learn how to collect and store log records from microservice
    instances, as well as how to search and analyze log records. As we mentioned in
    *Chapter 1*, *Introduction to Microservices*, it is difficult to get an overview
    of what is going on in a system landscape of microservices when each microservice
    instance writes log records to its local filesystem. We need a component that
    can collect the log records from the microservice’s local filesystem and store
    them in a central database for analysis, search, and visualization. A popular
    open-source-based solution for this is based on the following tools:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何从微服务实例收集和存储日志记录，以及如何搜索和分析日志记录。正如我们在*第1章*，*微服务介绍*中提到的，当每个微服务实例将其日志记录写入其本地文件系统时，在微服务系统景观中很难获得整体概览。我们需要一个组件可以从微服务的本地文件系统中收集日志记录，并将它们存储在中央数据库中以供分析、搜索和可视化。针对此问题的流行开源解决方案基于以下工具：
- en: '**Elasticsearch**, a distributed database with great capabilities for searching
    and analyzing large datasets'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Elasticsearch**，一个具有强大搜索和分析大数据集能力的分布式数据库'
- en: '**Fluentd**, a data collector that can be used to collect log records from
    various sources, filter and transform the collected information, and finally send
    it to various consumers, for example, Elasticsearch'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Fluentd**，一种可以用于从各种来源收集日志记录、过滤和转换收集到的信息，并将其最终发送到各种消费者（例如，Elasticsearch）的数据收集器'
- en: '**Kibana**, a graphical frontend to Elasticsearch that can be used to visualize
    search results and run analyses of the collected log records'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kibana**，Elasticsearch的图形前端，可用于可视化搜索结果和运行收集到的日志记录的分析'
- en: Together, these tools are called the **EFK stack**, named after the initials
    of each tool.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具一起被称为**EFK堆栈**，以每个工具的首字母命名。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Configuring Fluentd
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置Fluentd
- en: Deploying the EFK stack on Kubernetes for development and test usage
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Kubernetes上部署EFK堆栈以供开发和测试使用
- en: Analyzing the collected log records
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析收集到的日志记录
- en: Discovering log records from the microservices and finding related log records
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从微服务中发现日志记录并找到相关的日志记录
- en: Performing root cause analysis
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行根本原因分析
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For instructions on how to install the tools used in this book and how to access
    the source code for this book, see:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何安装本书中使用的工具以及如何访问本书源代码的说明，请参阅：
- en: '*Chapter 21*, *Installation Instructions for macOS*'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第21章*，*macOS安装说明*'
- en: '*Chapter 22*, *Installation Instructions for Microsoft Windows with WSL 2 and
    Ubuntu*'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第22章*，*使用WSL 2和Ubuntu的Microsoft Windows安装说明*'
- en: The code examples in this chapter all come from the source code in `$BOOK_HOME/Chapter19`.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的代码示例均来自`$BOOK_HOME/Chapter19`的源代码。
- en: If you want to view the changes applied to the source code in this chapter,
    that is, see the changes we made so that we can use the EFK stack for centralized
    log analysis, you can compare it with the source code for *Chapter 18*, *Using
    a Service Mesh to Improve Observability and Management*. You can use your favorite
    `diff` tool and compare the two folders, `$BOOK_HOME/Chapter18` and `$BOOK_HOME/Chapter19`.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想查看本章源代码中应用的变化，即查看我们做出的更改，以便我们可以使用EFK堆栈进行集中日志分析，你可以将其与*第18章*，*使用服务网格提高可观察性和管理*的源代码进行比较。你可以使用你喜欢的`diff`工具比较两个文件夹，`$BOOK_HOME/Chapter18`和`$BOOK_HOME/Chapter19`。
- en: Introducing Fluentd
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Fluentd
- en: In this section, we will learn the basics of how to configure Fluentd. Before
    we do that, let’s learn a bit about the background of Fluentd and how it works
    at a high level.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何配置Fluentd的基础知识。在我们这样做之前，让我们了解一下Fluentd的背景以及它在高层次上是如何工作的。
- en: Overview of Fluentd
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Fluentd概述
- en: Historically, one of the most popular open source stacks for handling log records
    has been the ELK stack from Elastic ([https://www.elastic.co](https://www.elastic.co)),
    based on Elasticsearch, Logstash (used for log collection and transformation),
    and Kibana. Since Logstash runs on a Java VM, it requires a relatively large amount
    of memory. Over the years, a number of open source alternatives have been developed
    that require significantly less memory than Logstash, one of them being Fluentd
    ([https://www.fluentd.org](https://www.fluentd.org)).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，处理日志记录最受欢迎的开源堆栈之一是 Elastic 的 ELK 堆栈（[https://www.elastic.co](https://www.elastic.co)），它基于
    Elasticsearch、Logstash（用于日志收集和转换）和 Kibana。由于 Logstash 运行在 Java 虚拟机上，它需要相对较大的内存量。多年来，已经开发出许多开源替代方案，这些方案比
    Logstash 需要的内存量少得多，其中之一就是 Fluentd（[https://www.fluentd.org](https://www.fluentd.org)）。
- en: Fluentd is managed by the **Cloud Native Computing Foundation** (**CNCF**) ([https://www.cncf.io](https://www.cncf.io)),
    the same organization that manages the Kubernetes project. Therefore, Fluentd
    has become a natural choice as an open-source-based log collector that runs in
    Kubernetes. Together with Elastic and Kibana, it forms the EFK stack.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd 由 **云原生计算基金会**（**CNCF**）（[https://www.cncf.io](https://www.cncf.io)）管理，该基金会还管理着
    Kubernetes 项目。因此，Fluentd 成为了一个基于开源的日志收集器，它自然地成为在 Kubernetes 中运行的日志收集器的首选。与 Elastic
    和 Kibana 一起，它形成了 EFK 堆栈。
- en: CNCF maintains a list of alternative products for several categories, for example,
    for logging. For alternatives to Fluentd listed by CNCF, see [https://landscape.cncf.io/card-mode?category=logging&grouping=category](https://landscape.cncf.io/card-mode?category=logging&grouping=category).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: CNCF 维护了多个类别的替代产品列表，例如，对于日志记录。有关 CNCF 列出的 Fluentd 替代方案，请参阅 [https://landscape.cncf.io/card-mode?category=logging&grouping=category](https://landscape.cncf.io/card-mode?category=logging&grouping=category)。
- en: Fluentd is written in a mix of C and Ruby, using C for the performance-critical
    parts and Ruby where flexibility is of more importance, for example, allowing
    the simple installation of third-party plugins using Ruby’s `gem install` command.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd 是用 C 和 Ruby 混合编写的，使用 C 语言处理性能关键的部分，而在需要更多灵活性的地方使用 Ruby，例如，允许使用 Ruby
    的 `gem install` 命令简单地安装第三方插件。
- en: 'A log record is processed as an event in Fluentd and consists of the following
    information:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录在 Fluentd 中作为事件进行处理，并包含以下信息：
- en: A `time` field describing when the log record was created
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个描述日志记录创建时间的 `time` 字段
- en: A `tag` field that identifies what type of log record it is – the tag is used
    by Fluentd’s routing engine to determine how a log record will be processed
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个标识日志记录类型的 `tag` 字段——该标签由 Fluentd 的路由引擎用于确定日志记录的处理方式
- en: A `record` that contains the actual log information, which is stored as a JSON
    object
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含实际日志信息的 `record`，该信息存储为 JSON 对象
- en: 'A Fluentd configuration file is used to tell Fluentd how to collect, process,
    and finally send log records to various targets, such as Elasticsearch. A configuration
    file consists of the following types of core elements:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd 配置文件用于告诉 Fluentd 如何收集、处理，并将日志记录最终发送到各种目标，例如 Elasticsearch。配置文件由以下类型的核心元素组成：
- en: '`<source>`: Source elements describe where Fluentd will collect log records,
    for example, tailing log files that have been written to by Docker containers.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<source>`：源元素描述 Fluentd 将收集日志记录的位置，例如，收集由 Docker 容器写入的日志文件。'
- en: '*Tailing a log file* means monitoring what is written to a log file. A frequently
    used Unix/Linux tool for monitoring what is appended to a file is named `tile`.'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*跟踪日志文件*意味着监控写入日志文件的内容。一个常用的 Unix/Linux 工具，用于监控文件附加的内容，名为 `tile`。'
- en: Source elements typically tag the log records, describing the type of log record.
    They could, for example, be used to tag log records to state that they come from
    containers running in Kubernetes.
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 源元素通常会对日志记录进行标记，描述日志记录的类型。例如，它们可以用来标记日志记录，表明它们来自在 Kubernetes 中运行的容器。
- en: '`<filter>`: Filter elements are used to process the log records. For example,
    a filter element can parse log records that come from Spring Boot-based microservices
    and extract interesting parts of the log message into separate fields in the log
    record. Extracting information into separate fields in the log record makes the
    information searchable by Elasticsearch. A filter element selects the log records
    to process based on their tags.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<filter>`：过滤器元素用于处理日志记录。例如，一个过滤器元素可以解析来自基于 Spring Boot 的微服务的日志记录，并将日志消息的有趣部分提取到日志记录中的单独字段。将信息提取到日志记录中的单独字段使得信息可以通过
    Elasticsearch 进行搜索。过滤器元素根据日志记录的标签选择要处理的日志记录。'
- en: '`<match>`: Match elements decide where to send log records, acting as output
    elements. They are used to perform two main tasks:'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<match>`：匹配元素决定将日志记录发送到何处，充当输出元素。它们用于执行两个主要任务：'
- en: Sending processed log records to targets such as Elasticsearch.
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将处理后的日志记录发送到目标，例如 Elasticsearch。
- en: 'Routing to decide how to process log records. A routing rule can rewrite the
    tag and re-emit the log record into the Fluentd routing engine for further processing.
    A routing rule is expressed as an embedded `<rule>` element inside the `<match>`
    element. Output elements decide what log records to process, in the same way as
    a filter: based on the tag of the log records.'
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路由决定如何处理日志记录。路由规则可以重写标记并将日志记录重新发射到 Fluentd 路由引擎以进行进一步处理。路由规则以 `<match>` 元素内部的嵌入式
    `<rule>` 元素表示。输出元素决定要处理哪些日志记录，与过滤器类似：基于日志记录的标记。
- en: Fluentd comes with a number of built-in and external third-party plugins that
    are used by the source, filter, and output elements. We will see some of them
    in action when we walk through the configuration file in the next section. For
    more information on the available plugins, see Fluentd’s documentation, which
    is available at [https://docs.fluentd.org](https://docs.fluentd.org).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd 随带一些内置和外部第三方插件，这些插件被源、过滤器和输出元素使用。在下一节中，我们将通过配置文件了解其中的一些插件。有关可用插件的信息，请参阅
    Fluentd 的文档，可在 [https://docs.fluentd.org](https://docs.fluentd.org) 找到。
- en: With this overview of Fluentd out of the way, we are ready to see how Fluentd
    can be configured to process the log records from our microservices.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成对 Fluentd 的概述之后，我们准备了解 Fluentd 如何配置以处理来自我们的微服务的日志记录。
- en: Configuring Fluentd
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置 Fluentd
- en: The configuration of Fluentd is based on the configuration files from a Fluentd
    project on GitHub, `fluentd-kubernetes-daemonset`. The project contains Fluentd
    configuration files for how to collect log records from containers that run in
    Kubernetes and how to send them to Elasticsearch once they have been processed.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd 的配置基于 GitHub 上 Fluentd 项目的配置文件，即 `fluentd-kubernetes-daemonset`。该项目包含
    Fluentd 配置文件，说明如何从在 Kubernetes 中运行的容器收集日志记录，以及一旦处理完毕如何将它们发送到 Elasticsearch。
- en: We will reuse this configuration without changes, and it will simplify our own
    configuration to a great extent. The Fluentd configuration files can be found
    at [https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/archived-image/v1.4/debian-elasticsearch/conf](https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/archived-image/v1.4/debian-elasticsearch/conf).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将不修改地重用此配置，这将极大地简化我们的配置。Fluentd 配置文件可以在 [https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/archived-image/v1.4/debian-elasticsearch/conf](https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/archived-image/v1.4/debian-elasticsearch/conf)
    找到。
- en: 'The configuration files that provide this functionality are `kubernetes.conf`
    and `fluent.conf`. The `kubernetes.conf` configuration file contains the following
    information:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 提供此功能的配置文件是 `kubernetes.conf` 和 `fluent.conf`。`kubernetes.conf` 配置文件包含以下信息：
- en: Source elements that tail container log files and log files from processes that
    run outside of Kubernetes, for example, `kubelet` and the Docker daemon. The source
    elements also tag the log records from Kubernetes with the full name of the log
    file with `/` replaced by `.` and prefixed with `kubernetes`. Since the tag is
    based on the full filename, the name contains the name of the namespace, pod,
    and container, among other things. So, the tag is very useful for finding log
    records of interest by matching the tag.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源元素跟踪容器日志文件以及运行在 Kubernetes 外部的进程（例如，`kubelet` 和 Docker 守护进程）的日志文件。源元素还会将 Kubernetes
    的日志记录标记为具有完整文件名的全名，其中 `/` 被替换为 `.` 并以 `kubernetes` 为前缀。由于标记基于完整文件名，因此名称包含命名空间、Pod
    和容器等名称。因此，标记对于通过匹配标记查找感兴趣的日志记录非常有用。
- en: For example, the tag from the `product-composite` microservice could be something
    like `kubernetes.var.log.containers.product-composite-7...s_hands-on_comp-e...b.log`,
    while the tag for the corresponding `istio-proxy` in the same Pod could be something
    like `kubernetes.var.log.containers.product-composite-7...s_hands-on_istio-proxy-1...3.log`.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，来自 `product-composite` 微服务的标记可能类似于 `kubernetes.var.log.containers.product-composite-7...s_hands-on_comp-e...b.log`，而同一
    Pod 中相应的 `istio-proxy` 的标记可能类似于 `kubernetes.var.log.containers.product-composite-7...s_hands-on_istio-proxy-1...3.log`。
- en: A filter element that enriches the log records that come from containers running
    inside Kubernetes, along with Kubernetes-specific fields that contain information
    such as the names of the containers and the namespace they run in.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个过滤器元素，丰富了来自运行在Kubernetes内部容器中的日志记录，以及包含容器名称和运行命名空间等信息的特定于Kubernetes的字段。
- en: 'The main configuration file, `fluent.conf`, contains the following information:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 主配置文件`fluent.conf`包含以下信息：
- en: '`@include` statements for other configuration files, for example, the `kubernetes.conf`
    file we described previously. It also includes custom configuration files that
    are placed in a specific folder, making it very easy for us to reuse these configuration
    files without any changes and provide our own configuration file that only handles
    processing related to our own log records. We simply need to place our own configuration
    file in the folder specified by the `fluent.conf` file.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@include`语句用于其他配置文件，例如我们之前描述的`kubernetes.conf`文件。它还包括放置在特定文件夹中的自定义配置文件，这使得我们能够非常容易地重用这些配置文件而无需任何更改，并提供我们自己的配置文件，该文件仅处理与我们的日志记录相关的处理。我们只需将我们的配置文件放置在`fluent.conf`文件指定的文件夹中即可。'
- en: An output element that sends log records to Elasticsearch.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个输出元素，将日志记录发送到Elasticsearch。
- en: As described in the *Deploying Fluentd* section later on, these two configuration
    files will be packaged into the Docker image we will build for Fluentd.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如后续的*部署Fluentd*部分所述，这两个配置文件将被打包到我们将为Fluentd构建的Docker镜像中。
- en: 'What’s left to cover in our own configuration file is the following:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们自己的配置文件中需要覆盖的内容如下：
- en: Detecting and parsing Spring Boot-formatted log records from our microservices.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别和解析来自我们的微服务的Spring Boot格式日志记录。
- en: Handling multiline stack traces. Stack traces are written to log files using
    multiple lines. This makes it hard for Fluentd to handle a stack trace as a single
    log record.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理多行堆栈跟踪。堆栈跟踪使用多行写入日志文件，这使得Fluentd难以将堆栈跟踪作为一个单独的日志记录处理。
- en: Separating log records from the `istio-proxy` sidecars from the log records
    that were created by the microservices running in the same Pod. The log records
    that are created by `istio-proxy` don’t follow the same pattern as the log patterns
    that are created by our Spring Boot-based microservices. Therefore, they must
    be handled separately so that Fluentd doesn’t try to parse them as Spring Boot-formatted
    log records.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将来自`istio-proxy`边车和同一Pod中运行的微服务创建的日志记录分开。由`istio-proxy`创建的日志记录不遵循我们基于Spring
    Boot的微服务创建的日志模式。因此，它们必须单独处理，以免Fluentd尝试将它们解析为Spring Boot格式的日志记录。
- en: To achieve this, the configuration is, to a large extent, based on using the
    `rewrite_tag_filter` plugin. This plugin can be used for routing log records based
    on the concept of changing the name of a tag and then re-emitting the log record
    to the Fluentd routing engine.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，配置在很大程度上是基于使用`rewrite_tag_filter`插件。此插件可用于根据更改标签名称的概念路由日志记录，然后将日志记录重新发射到Fluentd路由引擎。
- en: 'This processing is summarized by the following UML activity diagram:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 该处理由以下UML活动图总结：
- en: '![A picture containing text, screenshot, diagram, line  Description automatically
    generated](img/B19825_19_01.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![包含文本、截图、图表的图片，自动生成描述](img/B19825_19_01.png)'
- en: 'Figure 19.1: Fluentd processing of log records'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图19.1：Fluentd处理日志记录
- en: 'At a high level, the design of the configuration file looks as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，配置文件的设计如下：
- en: The tags of all log records from Istio, including `istio-proxy`, are prefixed
    with `istio` so that they can be separated from the Spring Boot-based log records.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Istio的所有日志记录的标签，包括`istio-proxy`，都以前缀`istio`开头，以便它们可以与基于Spring Boot的日志记录分开。
- en: The tags of all log records from the `hands-on` namespace (except for the log
    records from `istio-proxy`) are prefixed with `spring-boot`.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自`hands-on`命名空间的所有日志记录的标签（`istio-proxy`的日志记录除外）都以前缀`spring-boot`开头。
- en: The log records from Spring Boot are checked for the presence of multiline stack
    traces. If the log record is part of a multiline stack trace, it is processed
    by the third-party `detect-exceptions` plugin to recreate the stack trace. Otherwise,
    it is parsed using a regular expression to extract information of interest. See
    the *Deploying Fluentd* section for details on this third-party plugin.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spring Boot 的日志记录会检查是否存在多行堆栈跟踪。如果日志记录是多行堆栈跟踪的一部分，它将由第三方 `detect-exceptions`
    插件处理以重新创建堆栈跟踪。否则，它将使用正则表达式解析以提取感兴趣的信息。有关此第三方插件的详细信息，请参阅 *Deploying Fluentd* 部分。
- en: 'The `fluentd-hands-on.conf` configuration file implements this activity diagram.
    The configuration file is placed inside a Kubernetes ConfigMap (see `kubernetes/efk/fluentd-hands-on-configmap.yml`).
    Let’s go through this step by step, as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`fluentd-hands-on.conf` 配置文件实现了此活动图。配置文件放置在 Kubernetes ConfigMap 内（参见 `kubernetes/efk/fluentd-hands-on-configmap.yml`）。让我们一步一步地来了解这个过程，如下所示：'
- en: 'First comes the definition of the ConfigMap and the filename of the configuration
    file, `fluentd-hands-on.conf`. It looks as follows:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先是 ConfigMap 的定义和配置文件名，`fluentd-hands-on.conf`。它看起来如下：
- en: '[PRE0]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We can see that the `data` element will contain the configuration of Fluentd.
    It starts with the filename and uses a vertical bar, `|`, to mark the beginning
    of the embedded configuration file for Fluentd.
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以看到，`data` 元素将包含 Fluentd 的配置。它以文件名开始，并使用垂直线 `|` 标记 Fluentd 嵌入式配置文件的开始。
- en: 'The first `<match>` element matches the log records from Istio, that is, tags
    that are prefixed with `Kubernetes` and contain `istio` as either part of their
    namespace or part of their container name. It looks like this:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个 `<match>` 元素匹配来自 Istio 的日志记录，即以 `Kubernetes` 开头并包含 `istio` 作为其命名空间或容器名称一部分的标签。它看起来像这样：
- en: '[PRE1]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s explain the preceding source code:'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们解释前面的源代码：
- en: The `<match>` element matches any tags that follow the `kubernetes.**istio**`
    pattern, that is, tags that start with `Kubernetes` and then contain the word
    `istio` somewhere in the tag name. `istio` can come from the name of either the
    namespace or the container; both are part of the tag.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<match>` 元素匹配任何符合 `kubernetes.**istio**` 模式的标签，即以 `Kubernetes` 开头并在标签名称中包含
    `istio` 的标签。`istio` 可以来自命名空间或容器的名称；两者都是标签的一部分。'
- en: The `<match>` element contains only one `<rule>` element, which prefixes the
    tag with `istio`. The `${tag}` variable holds the current value of the tag.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<match>` 元素只包含一个 `<rule>` 元素，该元素将标签前缀设置为 `istio`。`${tag}` 变量持有当前标签的值。'
- en: Since this is the only `<rule>` element in the `<match>` element, it is configured
    to match all log records.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于这是 `<match>` 元素中的唯一 `<rule>` 元素，因此它被配置为匹配所有日志记录。
- en: Since all log records that come from Kubernetes have a `log` field, the `key`
    field is set to `log`, that is, the rule looks for a `log` field in the log records.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于所有来自 Kubernetes 的日志记录都有一个 `log` 字段，因此 `key` 字段被设置为 `log`，即规则在日志记录中查找 `log`
    字段。
- en: To match any string in the `log` field, the `pattern` field is set to the `^(.*)$`
    regular expression. `^` marks the beginning of a string, while `$` marks the end
    of a string. `(.*)` matches any number of characters, except for line breaks.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了匹配 `log` 字段中的任何字符串，`pattern` 字段被设置为 `^(.*)$` 正则表达式。`^` 标记字符串的开始，而 `$` 标记字符串的结束。`(.*)`
    匹配任意数量的字符，除了换行符。
- en: The log records are re-emitted to the Fluentd routing engine. Since no other
    elements in the configuration file match tags starting with `istio`, the log records
    will be sent directly to the output element for Elasticsearch, which is defined
    in the `fluent.conf` file we described previously.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志记录被重新发送到 Fluentd 路由引擎。由于配置文件中没有其他元素匹配以 `istio` 开头的标签，因此日志记录将直接发送到之前描述的 `fluent.conf`
    文件中定义的 Elasticsearch 输出元素。
- en: 'The second `<match>` element matches all log records from the `hands-on` namespace,
    that is, the log records that are emitted by our microservices. It looks like
    this:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个 `<match>` 元素匹配来自 `hands-on` 命名空间的所有日志记录，即由我们的微服务发出的日志记录。它看起来像这样：
- en: '[PRE2]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'From the source code, we can see that:'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从源代码中，我们可以看到：
- en: The log records emitted by our microservices use formatting rules for the log
    message defined by Spring Boot, so their tags are prefixed with `spring-boot`.
    Then, they are re-emitted for further processing.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们微服务发出的日志记录使用由 Spring Boot 定义的日志消息格式规则，因此它们的标签以 `spring-boot` 开头。然后，它们被重新发送以进行进一步处理。
- en: The `<match>` element is configured in the same way as the `<match kubernetes.**istio**>`
    element we looked at previously, to match all records.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<match>` 元素配置方式与之前查看的 `<match kubernetes.**istio**>` 元素相同，以匹配所有记录。'
- en: The third `<match>` element matches `spring-boot` log records and determines
    whether they are ordinary Spring Boot log records or part of a multiline stack
    trace. Since Spring Boot 3, Project Reactor has added extra information to stack
    traces to clarify what caused an exception. (For details, see [https://projectreactor.io/docs/core/release/reference/#_reading_a_stack_trace_in_debug_mode](https://projectreactor.io/docs/core/release/reference/#_reading_a_stack_trace_in_debug_mode).)
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三个 `<match>` 元素匹配 `spring-boot` 日志记录，并确定它们是普通 Spring Boot 日志记录还是多行堆栈跟踪的一部分。自
    Spring Boot 3 以来，Project Reactor 已向堆栈跟踪添加了额外信息，以澄清导致异常的原因。（有关详细信息，请参阅 [https://projectreactor.io/docs/core/release/reference/#_reading_a_stack_trace_in_debug_mode](https://projectreactor.io/docs/core/release/reference/#_reading_a_stack_trace_in_debug_mode)。）
- en: 'To be able to parse the actual stack trace, we will filter out this information.
    The `<match>` element looks like this:'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了能够解析实际的堆栈跟踪，我们将过滤掉此信息。`<match>` 元素看起来像这样：
- en: '[PRE3]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As seen in the source code, this is determined by using six `<rule>` elements:'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如源代码所示，这是通过使用六个 `<rule>` 元素来确定的：
- en: The first uses a regular expression to check whether the `log` field in the
    log element starts with a timestamp or not.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个使用正则表达式检查日志元素中的 `log` 字段是否以时间戳开头。
- en: If the `log` field starts with a timestamp, the log record is treated as an
    ordinary Spring Boot log record and its tag is prefixed with `parse`.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 `log` 字段以时间戳开头，则该日志记录被视为普通的 Spring Boot 日志记录，并且其标签以 `parse` 为前缀。
- en: Next follows four rule elements that are used to filter out the extra information
    added by Project Reactor; they all prefix the tag with `skip`.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来是四个规则元素，用于过滤掉 Project Reactor 添加的额外信息；它们都将标签前缀设置为 `skip`。
- en: Otherwise, the last `<rule>` element will match, and the log record is handled
    as a multiline log record. Its tag is prefixed with `check.exception`.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 否则，最后一个 `<rule>` 元素将匹配，并将日志记录作为多行日志记录处理。其标签以 `check.exception` 为前缀。
- en: The log record is re-emitted in either case and its tag will either start with
    `check.exception.spring-boot`, `skip.spring-boot,` or `parse.spring-boot` after
    this processing.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在此处理之后，日志记录将重新发射，并且其标签将开始于 `check.exception.spring-boot`、`skip.spring-boot`
    或 `parse.spring-boot`。
- en: 'The fourth `<match>` element is used to get rid of the log output from Project
    Reactor, i.e. match tags starting with `skip.spring-boot`. The `<match>` element
    applies the `null` output plugin that throws away the events. It looks like this:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第四个 `<match>` 元素用于消除 Project Reactor 的日志输出，即以 `skip.spring-boot` 开头的匹配标签。该 `<match>`
    元素应用了 `null` 输出插件，丢弃事件。它看起来像这样：
- en: '[PRE4]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the fifth `<match>` element, the selected log records have a tag that starts
    with `check.exception.spring-boot`, that is, log records that are part of a multiline
    stack trace. It looks like this:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第五个 `<match>` 元素中，选定的日志记录具有以 `check.exception.spring-boot` 开头的标签，即作为多行堆栈跟踪一部分的日志记录。它看起来像这样：
- en: '[PRE5]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `detect_exceptions` plugin works like this:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`detect_exceptions` 插件的工作方式如下：'
- en: The `detect_exceptions` plugin is used to combine multiple one-line log records
    into a single log record that contains a complete stack trace.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`detect_exceptions` 插件用于将多个单行日志记录合并成一个包含完整堆栈跟踪的单个日志记录。'
- en: Before a multiline log record is re-emitted into the routing engine, the `check`
    prefix is removed from the tag to prevent a never-ending processing loop of the
    log record.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在多行日志记录重新发射到路由引擎之前，将 `check` 前缀从标签中移除，以防止日志记录的无限循环处理。
- en: 'Finally, the configuration file consists of a `<filter>` element that parses
    Spring Boot log messages using a regular expression, extracting information of
    interest. It looks like this:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，配置文件由一个 `<filter>` 元素组成，该元素使用正则表达式解析 Spring Boot 日志消息，提取感兴趣的信息。它看起来像这样：
- en: '[PRE6]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note that filter elements don’t re-emit log records; instead, they just pass
    them on to the next element in the configuration file that matches the log record’s
    tag.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，过滤器元素不会重新发射日志记录；相反，它们只是将它们传递到配置文件中匹配日志记录标签的下一个元素。
- en: 'The following fields are extracted from the Spring Boot log message that’s
    stored in the `log` field in the log record:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 从存储在日志记录中 `log` 字段的 Spring Boot 日志消息中提取以下字段：
- en: '`<time>`: The timestamp for when the log record was created'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<time>`：日志记录创建时的日期和时间戳'
- en: '`<spring.level>`: The log level of the log record: `FATAL`, `ERROR`, `WARN`,
    `INFO`, `DEBUG`, or `TRACE`'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<spring.level>`：日志记录的日志级别：`FATAL`、`ERROR`、`WARN`、`INFO`、`DEBUG` 或 `TRACE`'
- en: '`<spring.service>`: The name of the microservice'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<spring.service>`：微服务的名称'
- en: '`<spring.trace>`: The trace ID used to perform distributed tracing'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<spring.trace>`：用于执行分布式跟踪的跟踪 ID'
- en: '`<spring.span>`: The span ID, the ID of the part of the distributed processing
    that this microservice executed'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<spring.span>`：span ID，表示分布式处理中该微服务执行的部分的 ID'
- en: '`<spring.pid>`: The process ID'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<spring.pid>`：进程 ID'
- en: '`<spring.thread>`: The thread ID'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<spring.thread>`：线程 ID'
- en: '`<spring.class>`: The name of the Java class'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<spring.class>`：Java 类的名称'
- en: '`<log>`: The actual log message'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<log>`：实际的日志消息'
- en: The names of Spring Boot-based microservices are specified using the `spring.application.name`
    property. This property has been added to each microservice-specific property
    file in the config repository, in the `config-repo` folder.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `spring.application.name` 属性指定基于 Spring Boot 的微服务的名称。此属性已添加到配置仓库中每个微服务特定的属性文件，位于
    `config-repo` 文件夹中。
- en: 'Getting regular expressions right can be challenging, to say the least. Thankfully,
    there are several websites that can help. When it comes to using regular expressions
    together with Fluentd, I recommend using the following site: [https://fluentular.herokuapp.com/](https://fluentular.herokuapp.com/).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 正确使用正则表达式可能具有挑战性，至少可以说。幸运的是，有几个网站可以帮助。当涉及到与 Fluentd 一起使用正则表达式时，我建议使用以下网站：[https://fluentular.herokuapp.com/](https://fluentular.herokuapp.com/)。
- en: Now that we have been introduced to how Fluentd works and how the configuration
    file is constructed, we are ready to deploy the EFK stack.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了 Fluentd 的工作原理以及配置文件的构建方式，我们准备部署 EFK 栈。
- en: Deploying the EFK stack on Kubernetes
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上部署 EFK 栈
- en: 'Deploying the EFK stack on Kubernetes will be done in the same way as we have
    deployed our own microservices: using Kubernetes manifest files for objects such
    as Deployments, Services, and ConfigMaps.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上部署 EFK 栈将与我们的微服务部署方式相同：使用 Kubernetes 清单文件来部署对象，如 Deployments、Services
    和 ConfigMaps。
- en: 'The deployment of the EFK stack is divided into three parts:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: EFK 栈的部署分为三个部分：
- en: Deploying Elasticsearch and Kibana
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署 Elasticsearch 和 Kibana
- en: Deploying Fluentd
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署 Fluentd
- en: Setting up access to Elasticsearch and Kibana
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置访问 Elasticsearch 和 Kibana
- en: But first, we need to build and deploy our own microservices.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 但首先，我们需要构建和部署我们自己的微服务。
- en: Building and deploying our microservices
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建和部署我们的微服务
- en: Building, deploying, and verifying the deployment using the `test-em-all.bash`
    test script is done in the same way as it was done in *Chapter 18*, *Using a Service
    Mesh to Improve Observability and Management*, in the *Running commands to create
    the service mesh* section. These instructions assume that the cert-manager and
    Istio are installed as instructed in *Chapters 17* and *18*.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `test-em-all.bash` 测试脚本构建、部署和验证部署的方式与第 18 章 *使用服务网格提高可观察性和管理* 中 *运行命令创建服务网格*
    部分的方式相同。这些说明假定 cert-manager 和 Istio 已按第 17 章和第 18 章中的说明安装。
- en: 'Run the following commands to get started:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下命令开始：
- en: 'First, build the Docker images from the source with the following commands:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，使用以下命令从源代码构建 Docker 镜像：
- en: '[PRE7]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `eval $(minikube docker-env -u)` command ensures that the `./gradlew build`
    command uses the host’s Docker engine and not the Docker engine in the Minikube
    instance. The `build` command uses Docker to run test containers.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`eval $(minikube docker-env -u)` 命令确保 `./gradlew build` 命令使用主机的 Docker 引擎，而不是
    Minikube 实例中的 Docker 引擎。`build` 命令使用 Docker 运行测试容器。'
- en: 'Recreate the namespace, `hands-on`, and set it as the default namespace:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新创建 `hands-on` 命名空间并将其设置为默认命名空间：
- en: '[PRE8]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Resolve the Helm chart dependencies with the following commands.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令解决 Helm 图表的依赖关系。
- en: 'First, we update the dependencies in the `components` folder:'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，我们更新 `components` 文件夹中的依赖项：
- en: '[PRE9]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, we update the dependencies in the `environments` folder:'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，我们更新 `environments` 文件夹中的依赖项：
- en: '[PRE10]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Deploy the system landscape using Helm and wait for all deployments to complete:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Helm 部署系统景观并等待所有部署完成：
- en: '[PRE11]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Start the Minikube tunnel in a separate terminal window, if it’s not already
    running (see *Chapter 18*, the *Setting up access to Istio services* section,
    for a recap, if required):'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '如果 Minikube 隧道尚未运行，请在单独的终端窗口中启动它（如需回顾，请参阅第 18 章，*设置访问 Istio 服务*部分）： '
- en: '[PRE12]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Remember that this command requires that your user has `sudo` privileges and
    that you enter your password during startup. It takes a couple of seconds before
    the command asks for the password, so it is easy to miss!
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 记住，这个命令要求你的用户具有`sudo`权限，并且在启动时输入你的密码。在命令请求密码之前需要几秒钟的时间，所以很容易错过！
- en: 'Run the normal tests to verify the deployment with the following command:'
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令运行正常测试以验证部署：
- en: '[PRE13]'
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Expect the output to be similar to what we saw in the previous chapters:'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出将与我们在前几章中看到的结果相似：
- en: '![A screenshot of a computer  Description automatically generated](img/B19825_19_02.png)'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![计算机屏幕截图  自动生成的描述](img/B19825_19_02.png)'
- en: 'Figure 19.2: Tests running fine'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图19.2：测试运行良好
- en: 'You can also try out the APIs manually by running the following commands:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你也可以通过运行以下命令手动尝试API：
- en: '[PRE14]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Expect the requested product ID, `1`, in the response.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 预期在响应中收到请求的产品ID，`1`。
- en: With the microservices deployed, we can move on and deploy Elasticsearch and
    Kibana!
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 部署了微服务后，我们可以继续部署Elasticsearch和Kibana！
- en: Deploying Elasticsearch and Kibana
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署Elasticsearch和Kibana
- en: We will deploy Elasticsearch and Kibana to their own namespace, `logging`. Both
    Elasticsearch and Kibana will be deployed for development and test usage using
    a Kubernetes Deployment and Service object. The services will expose the standard
    ports for Elasticsearch and Kibana internally in the Kubernetes cluster, that
    is, port `9200` for Elasticsearch and port `5601` for Kibana.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将部署Elasticsearch和Kibana到它们自己的命名空间`logging`。Elasticsearch和Kibana将使用Kubernetes
    Deployment和Service对象进行开发和测试部署。服务将在Kubernetes集群内部公开Elasticsearch和Kibana的标准端口，即Elasticsearch的端口`9200`和Kibana的端口`5601`。
- en: To provide external HTTP access to Elasticsearch and Kibana, we will create
    Istio objects as we did in *Chapter 18**, Using a Service Mesh to Improve Observability
    and Management*, for Kiali and Jaeger – see the *Setting up access to Istio services*
    section for a recap, if required. This will result in Elasticsearch and Kibana
    being available at [https://elasticsearch.minikube.me](https://elasticsearch.minikube.me)
    and [https://kibana.minikube.me](https://kibana.minikube.me).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 要为Elasticsearch和Kibana提供外部HTTP访问，我们将创建与第18章中相同的Istio对象，即使用服务网格来提高可观察性和管理性，用于Kiali和Jaeger
    – 如果需要，请参阅“设置对Istio服务的访问”部分进行回顾。这将使Elasticsearch和Kibana在[https://elasticsearch.minikube.me](https://elasticsearch.minikube.me)和[https://kibana.minikube.me](https://kibana.minikube.me)可用。
- en: The manifest files have been packaged in a Helm chart in the `kubernetes/helm/environments/logging`
    folder.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 清单文件已打包在`kubernetes/helm/environments/logging`文件夹中的Helm图表中。
- en: For recommended deployment options for Elasticsearch and Kibana in a production
    environment on Kubernetes, see [https://www.elastic.co/elastic-cloud-kubernetes](https://www.elastic.co/elastic-cloud-kubernetes).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 有关在Kubernetes生产环境中部署Elasticsearch和Kibana的推荐选项，请参阅[https://www.elastic.co/elastic-cloud-kubernetes](https://www.elastic.co/elastic-cloud-kubernetes)。
- en: 'We will use the latest versions that were available for version 7 when this
    chapter was written:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用在撰写本章时7.0版本可用的最新版本：
- en: Elasticsearch version 7.17.10
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elasticsearch版本7.17.10
- en: Kibana version 7.17.10
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kibana版本7.17.10
- en: Elasticsearch version 8 is not used, due to limited support in the Fluentd plugin
    for Elasticsearch; see [https://github.com/uken/fluent-plugin-elasticsearch/issues/1005](https://github.com/uken/fluent-plugin-elasticsearch/issues/1005).
    The base Docker image, `fluentd-kubernetes-daemonset`, that we will use in the
    following section to install Fluentd uses this plugin.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Fluentd插件对Elasticsearch的支持有限，因此没有使用Elasticsearch版本8；请参阅[https://github.com/uken/fluent-plugin-elasticsearch/issues/1005](https://github.com/uken/fluent-plugin-elasticsearch/issues/1005)。我们将在下一节中使用此插件来安装Fluentd的基Docker镜像，即`fluentd-kubernetes-daemonset`。
- en: Before we deploy, let’s look at the most interesting parts of the manifest files
    in the Helm chart’s `template` folder.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们部署之前，让我们看看Helm图表的`template`文件夹中清单文件中最有趣的部分。
- en: A walkthrough of the manifest files
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 清单文件的概述
- en: 'The manifest file for Elasticsearch, `elasticsearch.yml`, contains a standard
    Kubernetes Deployment and Service object that we have seen multiple times before,
    for example, in *Chapter 15*, *Introduction to Kubernetes*, in the *Trying out
    a sample deployment* section. The most interesting part of the manifest file is
    the following:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch的清单文件`elasticsearch.yml`包含了一个标准的Kubernetes Deployment和Service对象，我们之前已经多次见过，例如在*第15章*，*Kubernetes简介*中的*尝试示例部署*部分。清单文件中最有趣的部分如下：
- en: '[PRE15]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let’s explain some of this manifest:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解释一下这些清单文件中的某些内容：
- en: We use an official Docker image from Elastic that’s available at `docker.elastic.co`.
    The version is set to `7.17.10`.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用来自 Elastic 的官方 Docker 镜像，可在 `docker.elastic.co` 获取。版本设置为 `7.17.10`。
- en: The Elasticsearch container is allowed to allocate a relatively large amount
    of memory – 2 GB – to be able to run queries with good performance. The more memory,
    the better the performance.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elasticsearch 容器允许分配相对较大的内存量——2 GB——以便能够以良好的性能运行查询。内存越多，性能越好。
- en: 'The manifest file for Kibana, `kibana.yml`, also contains a standard Kubernetes
    Deployment and Service object. The most interesting parts in the manifest file
    are as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Kibana 的配置文件 `kibana.yml` 也包含标准的 Kubernetes 部署和服务对象。配置文件中最有趣的部分如下：
- en: '[PRE16]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Let’s explain some of the manifest:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解释一下一些配置文件：
- en: For Kibana, we also use an official Docker image from Elastic that’s available
    at `docker.elastic.co`. The version is set to `7.17.10`.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于 Kibana，我们也使用来自 Elastic 的官方 Docker 镜像，可在 `docker.elastic.co` 获取。版本设置为 `7.17.10`。
- en: To connect Kibana with the Elasticsearch Pod, an environment variable, `ELASTICSEARCH_URL`,
    is defined to specify the address to the Elasticsearch service, `http://elasticsearch:9200`.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了将 Kibana 连接到 Elasticsearch Pod，定义了一个环境变量 `ELASTICSEARCH_URL`，用于指定 Elasticsearch
    服务的地址，`http://elasticsearch:9200`。
- en: 'Finally, the Istio manifests for setting up external access are found in the
    files `expose-elasticsearch.yml` and `expose-kibana.yml`. For a recap on how the
    `Gateway`, `VirtualService`, and `DestinationRule` objects are used, see the section
    *Creating the service mesh* in *Chapter 18*. They will provide the following forwarding
    of external requests:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，设置外部访问的 Istio 配置文件位于 `expose-elasticsearch.yml` 和 `expose-kibana.yml` 文件中。关于如何使用
    `Gateway`、`VirtualService` 和 `DestinationRule` 对象的复习，请参阅第 18 章的 *创建服务网格* 部分。它们将提供以下外部请求转发：
- en: '[https://elasticsearch.minikube.me](https://elasticsearch.minikube.me) → `http://elasticsearch:9200`'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://elasticsearch.minikube.me](https://elasticsearch.minikube.me) → `http://elasticsearch:9200`'
- en: '[https://kibana.minikube.me](https://kibana.minikube.me) → `http://kibana:5601`'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://kibana.minikube.me](https://kibana.minikube.me) → `http://kibana:5601`'
- en: With these insights, we are ready to perform the deployment of Elasticsearch
    and Kibana.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这些见解，我们准备部署 Elasticsearch 和 Kibana。
- en: Running the deploy commands
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 执行部署命令
- en: 'Deploy Elasticsearch and Kibana by performing the following steps:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以下步骤部署 Elasticsearch 和 Kibana：
- en: 'To make the deployment steps run faster, prefetch the Docker images for Elasticsearch
    and Kibana with the following commands:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使部署步骤运行得更快，使用以下命令预取 Elasticsearch 和 Kibana 的 Docker 镜像：
- en: '[PRE17]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Use the Helm chart to create the `logging` namespace, deploy Elasticsearch
    and Kibana in it, and wait for the Pods to be ready:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Helm 图表创建 `logging` 命名空间，在其中部署 Elasticsearch 和 Kibana，并等待 Pod 准备就绪：
- en: '[PRE18]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Verify that Elasticsearch is up and running with the following command:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令验证 Elasticsearch 是否正在运行：
- en: '[PRE19]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Expect `You Know, for Search` as a response.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期响应为 `You Know, for Search`。
- en: Depending on your hardware, you might need to wait for a minute or two before
    Elasticsearch responds with this message.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的硬件配置，您可能需要等待一分钟或两分钟，Elasticsearch 才会响应此消息。
- en: 'Verify that Kibana is up and running with the following command:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令验证 Kibana 是否正在运行：
- en: '[PRE20]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Expect `200` as the response.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 预期响应为 `200`。
- en: Again, you might need to wait for a minute or two before Kibana is initialized
    and responds with `200`.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，您可能需要等待一分钟或两分钟，Kibana 才会初始化并响应 `200`。
- en: With Elasticsearch and Kibana deployed, we can start to deploy Fluentd.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 部署了 Elasticsearch 和 Kibana 后，我们可以开始部署 Fluentd。
- en: Deploying Fluentd
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署 Fluentd
- en: Deploying Fluentd is a bit more complex compared to deploying Elasticsearch
    and Kibana. To deploy Fluentd, we will use a Docker image that’s been published
    by the Fluentd project on Docker Hub, `fluent/fluentd-kubernetes-daemonset`, and
    the sample Kubernetes manifest files from a Fluentd project on GitHub, `fluentd-kubernetes-daemonset`.
    It is located at [https://github.com/fluent/fluentd-kubernetes-daemonset](https://github.com/fluent/fluentd-kubernetes-daemonset).
    As is implied by the name of the project, Fluentd will be deployed as a DaemonSet,
    running one Pod per Node in the Kubernetes cluster. Each Fluentd Pod is responsible
    for collecting log output from processes and containers that run on the same Node
    as the Pod. Since we are using Minikube with a single Node cluster, we will only
    have one Fluentd Pod.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 相比于部署 Elasticsearch 和 Kibana，部署 Fluentd 要复杂一些。为了部署 Fluentd，我们将使用 Fluentd 项目在
    Docker Hub 上发布的 Docker 镜像 `fluent/fluentd-kubernetes-daemonset` 以及来自 GitHub 上
    Fluentd 项目的示例 Kubernetes 清单文件 `fluentd-kubernetes-daemonset`。它位于 [https://github.com/fluent/fluentd-kubernetes-daemonset](https://github.com/fluent/fluentd-kubernetes-daemonset)。正如项目名称所暗示的，Fluentd
    将作为 DaemonSet 部署，在每个 Kubernetes 集群的节点上运行一个 Pod。每个 Fluentd Pod 负责收集与 Pod 在同一节点上运行的进程和容器的日志输出。由于我们使用的是具有单个节点集群的
    Minikube，因此我们只有一个 Fluentd Pod。
- en: To handle multiline log records that contain stack traces from exceptions, we
    will use a third-party Fluentd plugin provided by Google, `fluent-plugin-detect-exceptions`,
    which is available at [https://github.com/GoogleCloudPlatform/fluent-plugin-detect-exceptions](https://github.com/GoogleCloudPlatform/fluent-plugin-detect-exceptions).
    To be able to use this plugin, we will build our own Docker image where the `fluent-plugin-detect-exceptions`
    plugin will be installed.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理包含异常堆栈跟踪的多行日志记录，我们将使用由 Google 提供的第三方 Fluentd 插件 `fluent-plugin-detect-exceptions`，该插件可在
    [https://github.com/GoogleCloudPlatform/fluent-plugin-detect-exceptions](https://github.com/GoogleCloudPlatform/fluent-plugin-detect-exceptions)
    找到。为了能够使用此插件，我们将构建自己的 Docker 镜像，其中将安装 `fluent-plugin-detect-exceptions` 插件。
- en: Fluentd’s Docker image, `fluentd-kubernetes-daemonset`, will be used as the
    base image.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd 的 Docker 镜像 `fluentd-kubernetes-daemonset` 将用作基础镜像。
- en: 'We will use the following versions:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下版本：
- en: Fluentd version 1.4.2
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fluentd 版本 1.4.2
- en: '`fluent-plugin-detect-exceptions` version 0.0.12'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fluent-plugin-detect-exceptions` 版本 0.0.12'
- en: Before we deploy, let’s look at the most interesting parts of the manifest files.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们部署之前，让我们看看清单文件中最有趣的部分。
- en: A walkthrough of the manifest files
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对清单文件的概述
- en: 'The Dockerfile that’s used to build the Docker image, `kubernetes/efk/Dockerfile`,
    looks as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 用于构建 Docker 镜像的 Dockerfile，`kubernetes/efk/Dockerfile`，如下所示：
- en: '[PRE21]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let’s explain this in detail:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细解释一下：
- en: The base image is Fluentd’s Docker image, `fluentd-kubernetes-daemonset`. The
    `v1.4.2-debian-elasticsearch-1.1` tag specifies that version 1.4.2 will be used
    with a package that contains built-in support for sending log records to Elasticsearch.
    The base Docker image contains the Fluentd configuration files that were mentioned
    in the *Configuring Fluentd* section.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础镜像是 Fluentd 的 Docker 镜像 `fluentd-kubernetes-daemonset`。`v1.4.2-debian-elasticsearch-1.1`
    标签指定将使用包含内置支持将日志记录发送到 Elasticsearch 的软件包的 1.4.2 版本。基础 Docker 镜像包含在 *配置 Fluentd*
    部分中提到的 Fluentd 配置文件。
- en: The Google plugin, `fluent-plugin-detect-exceptions`, is installed using Ruby’s
    package manager, `gem`.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google 插件 `fluent-plugin-detect-exceptions` 使用 Ruby 的包管理器 `gem` 进行安装。
- en: The manifest file of the DaemonSet, `kubernetes/efk/fluentd-ds.yml`, is based
    on a sample manifest file in the `fluentd-kubernetes-daemonset` project, which
    can be found at [https://github.com/fluent/fluentd-kubernetes-daemonset/blob/master/fluentd-daemonset-elasticsearch.yaml](https://github.com/fluent/fluentd-kubernetes-daemonset/blob/master/fluentd-daemonset-elasticsearch.yaml).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: DaemonSet 的清单文件 `kubernetes/efk/fluentd-ds.yml` 基于在 `fluentd-kubernetes-daemonset`
    项目中的一个示例清单文件，该文件可以在 [https://github.com/fluent/fluentd-kubernetes-daemonset/blob/master/fluentd-daemonset-elasticsearch.yaml](https://github.com/fluent/fluentd-kubernetes-daemonset/blob/master/fluentd-daemonset-elasticsearch.yaml)
    找到。
- en: 'This file is a bit complex, so let’s go through the most interesting parts
    separately:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文件有点复杂，所以让我们分别查看最有趣的部分：
- en: 'First, here’s the declaration of the DaemonSet:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，这是 DaemonSet 的声明：
- en: '[PRE22]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The `kind` key specifies that this is a DaemonSet. The `namespace` key specifies
    that the DaemonSet will be created in the `kube-system` namespace and not in the
    `logging` namespace where Elasticsearch and Kibana are deployed.
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`kind` 键指定这是一个 DaemonSet。`namespace` 键指定 DaemonSet 将在 `kube-system` 命名空间中创建，而不是在
    Elasticsearch 和 Kibana 部署的 `logging` 命名空间中。'
- en: 'The next part specifies the template for the Pods that are created by the DaemonSet.
    The most interesting parts are as follows:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个部分指定由DaemonSet创建的Pod的模板。最有趣的部分如下：
- en: '[PRE23]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The Docker image that’s used for the Pods is `hands-on/fluentd:v1`. We will
    build this Docker image after walking through the manifest files using the Dockerfile
    we described previously.
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用于Pod的Docker镜像为`hands-on/fluentd:v1`。我们将使用之前描述的Dockerfile构建此Docker镜像。
- en: 'A number of environment variables are supported by the Docker image and are
    used to customize it. The two most important ones are as follows:'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Docker镜像支持多个环境变量，并用于自定义它。其中两个最重要的如下：
- en: '`FLUENT_ELASTICSEARCH_HOST`, which specifies the hostname of the Elasticsearch
    service, `elasticsearch.logging`'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FLUENT_ELASTICSEARCH_HOST`，指定Elasticsearch服务的域名，`elasticsearch.logging`'
- en: '`FLUENT_ELASTICSEARCH_PORT`, which specifies the port that’s used to communicate
    with Elasticsearch, `9200`'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FLUENT_ELASTICSEARCH_PORT`，指定用于与Elasticsearch通信的端口，`9200`'
- en: Since the Fluentd Pod runs in a different namespace to Elasticsearch, the hostname
    cannot be specified using its short name, that is, `elasticsearch`. Instead, the
    namespace part of the DNS name must also be specified, that is, `elasticsearch.logging`.
    As an alternative, the **fully qualified domain name** (**FQDN**), `elasticsearch.logging.svc.cluster.local`,
    can also be used. But since the last part of the DNS name, `svc.cluster.local`,
    is shared by all DNS names inside a Kubernetes cluster, it does not need to be
    specified.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Fluentd Pod运行在不同的命名空间中，因此不能使用其短名称`elasticsearch`来指定主机名。相反，DNS名称的命名空间部分也必须指定，即`elasticsearch.logging`。作为替代，也可以使用**完全限定域名**（**FQDN**）`elasticsearch.logging.svc.cluster.local`。但由于DNS名称的最后部分`svc.cluster.local`在Kubernetes集群内的所有DNS名称中都是共享的，因此不需要指定。
- en: 'Finally, a number of volumes, that is, filesystems, are mapped to the Pod,
    as follows:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，将多个卷（即文件系统）映射到Pod，如下所示：
- en: '[PRE24]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let’s take a look at the source code in detail:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细查看源代码：
- en: Three folders on the host (that is, the Node) are mapped to the Fluentd Pod.
    These folders contain the log files that Fluentd will tail and collect log records
    from. The folders are `/var/log`, `/var/lib/docker/containers`, and `/run/log/journal`.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主机（即节点）上的三个文件夹映射到Fluentd Pod。这些文件夹包含Fluentd将跟踪和收集日志记录的日志文件。这些文件夹是`/var/log`、`/var/lib/docker/containers`和`/run/log/journal`。
- en: Our own configuration file, which specifies how Fluentd will process log records
    from our microservices, is mapped using a ConfigMap called `fluentd-hands-on-config`
    to the `/fluentd/etc/conf.d` folder. The base Docker image configures Fluentd
    to include any configuration file that’s found in the `/fluentd/etc/conf.d` folder.
    See the *Configuring Fluentd* section for details.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们自己的配置文件，该文件指定了Fluentd如何处理来自我们的微服务的日志记录，通过名为`fluentd-hands-on-config`的ConfigMap映射到`/fluentd/etc/conf.d`文件夹。基础Docker镜像配置Fluentd以包含在`/fluentd/etc/conf.d`文件夹中找到的任何配置文件。有关详细信息，请参阅*配置Fluentd*部分。
- en: For the full source code of the manifest file for the DaemonSet, see the `kubernetes/efk/fluentd-ds.yml`
    file.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 对于DaemonSet的完整源代码清单文件，请参阅`kubernetes/efk/fluentd-ds.yml`文件。
- en: Now that we’ve walked through everything, we are ready to perform the deployment
    of Fluentd.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了所有内容，我们准备执行Fluentd的部署。
- en: Running the deploy commands
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行部署命令
- en: 'To deploy Fluentd, we have to build the Docker image, create the ConfigMap,
    and finally deploy the DaemonSet. Run the following commands to perform these
    steps:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署Fluentd，我们必须构建Docker镜像，创建ConfigMap，最后部署DaemonSet。运行以下命令执行这些步骤：
- en: 'Build the Docker image and tag it with `hands-on/fluentd:v1` using the following
    command:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令构建Docker镜像并使用`hands-on/fluentd:v1`标记它：
- en: '[PRE25]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Create the ConfigMap, deploy Fluentd’s DaemonSet, and wait for the Pod to be
    ready with the following commands:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建ConfigMap，部署Fluentd的DaemonSet，并等待Pod就绪：
- en: '[PRE26]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Verify that the Fluentd Pod is healthy with the following command:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令验证Fluentd Pod是否健康：
- en: '[PRE27]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Expect a response of `2023-05-22 14:59:46 +0000 [info]: #0 fluentd worker is
    now running worker=0`.'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '预期响应为`2023-05-22 14:59:46 +0000 [info]: #0 fluentd worker is now running worker=0`。'
- en: As for Elasticsearch and Kibana, you might need to wait for a minute or two
    before Fluentd responds with this message.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Elasticsearch和Kibana，在Fluentd响应此消息之前，可能需要等待一分钟或两分钟。
- en: 'Fluentd will start to collect a considerable number of log records from the
    various containers in the Minikube instance. After a minute or so, you can ask
    Elasticsearch how many log records have been collected with the following command:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Fluentd将从Minikube实例中的各种容器开始收集相当数量的日志记录。大约一分钟后，你可以使用以下命令询问Elasticsearch收集了多少日志记录：
- en: '[PRE28]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The command can be a bit slow the first time it is executed but should return
    a total count of several thousands of log records. In my case, it returned `55607`.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一次执行此命令时可能会有些慢，但应该返回数千条日志记录的总数。在我的情况下，它返回了`55607`。
- en: This completes the deployment of the EFK stack. Now, it’s time to try it out
    and find out what all the collected log records are about!
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了EFK堆栈的部署。现在，是时候尝试它并找出所有收集到的日志记录的内容了！
- en: Trying out the EFK stack
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 尝试EFK堆栈
- en: The first thing we need to do before we can try out the EFK stack is to initialize
    Kibana so it knows what indices to use in Elasticsearch.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们尝试EFK堆栈之前，我们需要先初始化Kibana，以便它知道在Elasticsearch中使用哪些索引。
- en: An **index** in Elasticsearch corresponds to a **database** in SQL concepts.
    The SQL concepts **table**, **row**, and **column** correspond to **type**, **document**,
    and **property** in Elasticsearch.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在Elasticsearch中，**索引**对应于SQL概念中的**数据库**。SQL概念中的**表**、**行**和**列**对应于Elasticsearch中的**类型**、**文档**和**属性**。
- en: 'Once that is done, we will try out the following common tasks:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 完成上述操作后，我们将尝试以下常见任务：
- en: We will start by analyzing what types of log records Fluentd has collected and
    stored in Elasticsearch. Kibana has a very useful visualization capability that
    can be used for this.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先分析Fluentd收集并存储在Elasticsearch中的日志记录类型。Kibana具有非常实用的可视化功能，可用于此目的。
- en: Next, we will learn how to find all related log records created by the microservices
    while processing an external request. We will use the **trace ID** in the log
    records as a correlation ID to find related log records.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将学习如何在处理外部请求时查找由微服务创建的所有相关日志记录。我们将使用日志记录中的**跟踪ID**作为关联ID来查找相关日志记录。
- en: Finally, we will learn how to use Kibana to perform **root cause analysis**,
    finding the actual reason for an error.
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将学习如何使用Kibana进行**根本原因分析**，找到错误的真正原因。
- en: Initializing Kibana
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始化Kibana
- en: Before we start to use Kibana, we must specify what search indices to use in
    Elasticsearch and what field in the indices holds the timestamps for the log records.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始使用Kibana之前，我们必须指定在Elasticsearch中使用哪些搜索索引以及索引中哪个字段持有日志记录的时间戳。
- en: Just a quick reminder that we are using a certificate created by our own CA,
    meaning that it is not trusted by web browsers! For a recap on how to make web
    browsers accept our certificate, see the *Observing the service mesh* section
    of *Chapter 18*.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒一下，我们使用的是由我们自己的CA创建的证书，这意味着它不被网络浏览器信任！有关如何使网络浏览器接受我们的证书的复习，请参阅第18章的*观察服务网格*部分。
- en: 'Perform the following steps to initialize Kibana:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以初始化Kibana：
- en: Open Kibana’s web UI using the [https://kibana.minikube.me](https://kibana.minikube.me)
    URL in a web browser.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用网络浏览器中的[https://kibana.minikube.me](https://kibana.minikube.me) URL打开Kibana的Web
    UI。
- en: On the **Welcome home** page, click on the hamburger menu **≡** (three horizontal
    lines) in the upper-left corner, and click on **Stack Management** at the bottom
    of the menu to the left.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**欢迎主页**上，点击左上角的汉堡菜单**≡**（三条横线）并在菜单底部点击左侧的**堆栈管理**。
- en: In the **Management** menu, go to the bottom and select **Index Patterns**.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**管理**菜单中，滚动到最底部并选择**索引模式**。
- en: Click on the button named **Create index pattern**.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击名为**创建索引模式**的按钮。
- en: Enter `logstash-*` as the index pattern name and click on the **Next Step**
    button.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将索引模式名称输入为`logstash-*`并点击**下一步**按钮。
- en: Indices are, by default, named `logstash` for historical reasons, even though
    Fluentd is used for log collection.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 由于历史原因，索引默认命名为`logstash`，尽管使用了Fluentd进行日志收集。
- en: Click on the drop-down list for the **Timestamp field** and select the only
    available field, `@timestamp`.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**时间戳字段**的下拉列表并选择唯一可用的字段，`@timestamp`。
- en: Click on the **Create index pattern** button.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建索引模式**按钮。
- en: Kibana will show a page that summarizes the fields that are available in the
    selected indices.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: Kibana将显示一个页面，总结所选索引中可用的字段。
- en: With Kibana initialized, we are ready to examine the collected log records.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kibana初始化后，我们准备好检查收集到的日志记录。
- en: Analyzing the log records
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析日志记录
- en: From the deployment of Fluentd, we know that it immediately started to collect
    a significant number of log records. So, the first thing we need to do is get
    an understanding of what types of log records Fluentd has collected and stored
    in Elasticsearch.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 从Fluentd的部署开始，我们就知道它立即开始收集大量的日志记录。因此，我们首先需要做的是了解Fluentd收集并存储在Elasticsearch中的日志记录类型。
- en: 'We will use Kibana’s visualization feature to divide the log records by the
    Kubernetes namespace and then ask Kibana to show us how the log records are divided
    by the type of container within each namespace. A pie chart is a suitable chart
    type for this type of analysis. Perform the following steps to create a pie chart:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Kibana的可视化功能按Kubernetes命名空间划分日志记录，然后要求Kibana显示每个命名空间内日志记录按容器类型划分的情况。饼图是此类分析合适的图表类型。按照以下步骤创建饼图：
- en: In Kibana’s web UI, click on the hamburger menu again and select **Visualize
    Library** under **Analytics** in the menu.
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Kibana的Web UI中，再次点击汉堡菜单，并在菜单中选择**分析**下的**可视化库**。
- en: 'Click on the **Create new visualization** button and select the **Lens** type
    on the next page. A web page like the following will be displayed:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建新可视化**按钮，并在下一页选择**透镜**类型。将显示如下网页：
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B19825_19_03.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![计算机截图  描述自动生成，置信度中等](img/B19825_19_03.png)'
- en: 'Figure 19.3: Starting to analyze log records in Kibana'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 图19.3：在Kibana中开始分析日志记录
- en: Verify that **logstash-*** is the selected index pattern in the top-left drop-down
    menu.
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确认**logstash-***是左上角下拉菜单中选定的索引模式。
- en: In the **Bar vertical stacked** drop-down menu next to the index pattern, select
    **Pie** as the visualization type.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在索引模式旁边的**垂直堆叠条形图**下拉菜单中，选择**饼图**作为可视化类型。
- en: In the time picker (a date interval selector) above the pie chart, set a date
    interval large enough to cover log records of interest (set to the **Last 15 minutes**
    in the following screenshot). Click on its calendar icon to adjust the time interval.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在饼图上方的日期选择器（一个日期区间选择器）中，设置一个足够大的日期区间以覆盖感兴趣的日志记录（在下述截图中设置为**最后15分钟**）。点击其日历图标以调整时间区间。
- en: In the field named **Search field names** below the index pattern, enter `kubernetes.namespace_name.keyword`.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在索引模式下方名为**搜索字段名称**的域中，输入`kubernetes.namespace_name.keyword`。
- en: Under the **Available fields** list, the field **kubernetes.namespace_name.keyword**
    is now present. Drag this field into the big box in the middle of the page, named
    **Drop some fields here to start**. Kibana will immediately start to analyze log
    records and render a pie chart divided into Kubernetes namespaces.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**可用字段**列表下，现在出现了字段**kubernetes.namespace_name.keyword**。将此字段拖放到页面中间名为**在此处放下一些字段以开始**的大框中。Kibana将立即开始分析日志记录并按Kubernetes命名空间绘制饼图。
- en: 'In my case, it looks like:'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在我的情况下，看起来是这样的：
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B19825_19_04.png)'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![计算机截图  描述自动生成，置信度中等](img/B19825_19_04.png)'
- en: 'Figure 19.4: Kibana analysis of log records per Kubernetes namespace'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图19.4：Kibana按Kubernetes命名空间分析日志记录
- en: 'We can see that the log records are divided into the Namespaces we have been
    working with in the previous chapters: `kube-system`, `istio-system`, `logging`,
    and our own `hands-on` Namespace. To see what containers have created the log
    records per Namespace, we need to add a second field.'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以看到日志记录被分为我们在前几章中一直在使用的命名空间：`kube-system`、`istio-system`、`logging`以及我们自己的`hands-on`命名空间。要查看每个命名空间中创建了哪些容器日志记录，我们需要添加第二个字段。
- en: In the **Search field names** field, enter `kubernetes.container_name.keyword`.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**搜索字段名称**字段中，输入`kubernetes.container_name.keyword`。
- en: In the **Available fields** list, the field `kubernetes.container_name.keyword`
    is now present. Drag this field into the big box in the middle of the page showing
    the pie chart. Kibana will immediately start to analyze log records and render
    a pie chart divided by Kubernetes namespace and container name.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**可用字段**列表中，现在出现了字段`kubernetes.container_name.keyword`。将此字段拖放到页面中间显示饼图的较大框中。Kibana将立即开始分析日志记录并按Kubernetes命名空间和容器名称绘制饼图。
- en: 'In the result of *step 9*, we can see a lot of log records coming from `coredns`,
    67% in my case. Since we are not particularly interested in these log records,
    we can remove them by adding a filter with the following steps:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*步骤9*的结果中，我们可以看到来自`coredns`的大量日志记录，在我的情况下占67%。由于我们对此类日志记录不特别感兴趣，我们可以通过以下步骤添加过滤器来删除它们：
- en: Click on **+ Add filter** (in the top-left corner).
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**+ 添加过滤器**（在左上角）。
- en: Select the **Field** `kubernetes.container_name.keyword` and the **is not -****Operator**.
    Finally, enter the **Value** `coredns` and click on the **Save** button.
  id: totrans-275
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**字段**`kubernetes.container_name.keyword`和**不是**`-****Operator`。最后，输入**值**`coredns`并点击**保存**按钮。
- en: In my case, the rendered pie chart now looks like this:![A screenshot of a computer  Description
    automatically generated with medium confidence](img/B19825_19_05.png)
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我的情况下，渲染的饼图现在看起来是这样的：![计算机屏幕截图  描述由中等置信度自动生成](img/B19825_19_05.png)
- en: 'Figure 19.5: Kibana analysis of log records per namespace and container'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图19.5：Kibana按命名空间和容器分析日志记录
- en: Here, we can find the log records from our microservices. Most of the log records
    come from the `review` and `recommendation` microservices. The `product` and `product-composite`
    microservices can be found under the **other** section of the pie chart.
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们可以找到我们的微服务的日志记录。大多数日志记录来自`review`和`recommendation`微服务。`product`和`product-composite`微服务可以在饼图的**其他**部分找到。
- en: Wrap up this introduction to how to analyze what types of log records we have
    collected by saving this pie chart in a dashboard. Click on the **Save** button
    in the top-right corner.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在仪表板中保存此饼图来总结如何分析我们收集的日志记录类型。点击右上角的**保存**按钮。
- en: 'On the page named **Save Lens visualization**, do the following:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在名为**保存透镜可视化**的页面上，执行以下操作：
- en: Give it a **Title**, for example, `hands-on-visualization`.
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给它一个**标题**，例如，`hands-on-visualization`。
- en: Enter a **Description**, for example, `This is my first visualization in Kibana`.
  id: totrans-282
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入一个**描述**，例如，`这是我在Kibana中的第一个可视化`。
- en: 'In the **Add to dashboard** box, select **New**. The page should look like
    this:'
  id: totrans-283
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**添加到仪表板**框中，选择**新建**。页面应该看起来像这样：
- en: '![A screenshot of a computer  Description automatically generated](img/B19825_19_06.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  描述由中等置信度自动生成](img/B19825_19_06.png)'
- en: 'Figure 19.6: Creating a dashboard in Kibana'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 图19.6：在Kibana中创建仪表板
- en: 'Click on the button named **Save and go to Dashboard**. A dashboard like the
    following should be presented:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击名为**保存并转到仪表板**的按钮。应该会呈现以下仪表板：
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B19825_19_07.png)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  描述由中等置信度自动生成](img/B19825_19_07.png)'
- en: 'Figure 19.7: The new dashboard in Kibana'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 图19.7：Kibana中的新仪表板
- en: Click on the **Save** button in the top-right corner, give the dashboard a name,
    for example, `hands-on-dashboard`, and click on the **Save** button.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击右上角的**保存**按钮，给仪表板起一个名字，例如，`hands-on-dashboard`，然后点击**保存**按钮。
- en: You can now always go back to this dashboard by selecting **Dashboard** from
    the hamburger menu.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以通过从汉堡菜单中选择**仪表板**始终返回此仪表板。
- en: Kibana contains tons of features for analyzing log records – feel free to try
    them out on your own. For inspiration, see [https://www.elastic.co/guide/en/kibana/7.17/dashboard.html](https://www.elastic.co/guide/en/kibana/7.17/dashboard.html).
    We will now move on and start to locate the actual log records from our microservice.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: Kibana包含大量用于分析日志记录的功能——请随意尝试。为了获得灵感，请参阅[https://www.elastic.co/guide/en/kibana/7.17/dashboard.html](https://www.elastic.co/guide/en/kibana/7.17/dashboard.html)。现在，我们将继续前进，开始从我们的微服务中定位实际的日志记录。
- en: Discovering the log records from microservices
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发现微服务的日志记录
- en: In this section, we will learn how to utilize one of the main features of centralized
    logging, finding log records from our microservices. We will also learn how to
    use the trace ID in the log records to find log records from other microservices
    that belong to the same process, for example, processing an external request sent
    to the public API.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何利用集中式日志记录的主要功能之一，即从我们的微服务中查找日志记录。我们还将学习如何使用日志记录中的跟踪ID来查找属于同一进程的其他微服务的日志记录，例如，处理发送到公共API的外部请求。
- en: Let’s start by creating some log records that we can look up with the help of
    Kibana. We will use the API to create a product with a unique product ID and then
    retrieve information about the product. After that, we can try to find the log
    records that were created when retrieving the product information.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先创建一些日志记录，我们可以借助Kibana来查找它们。我们将使用API创建一个具有唯一产品ID的产品，然后检索有关该产品的信息。之后，我们可以尝试查找在检索产品信息时创建的日志记录。
- en: 'The creation of log records in the microservices has been updated a bit from
    the previous chapter so that the `product-composite` and the three core microservices,
    `product`, `recommendation`, and `review`, all write a log record with the log
    level set to `INFO` when they begin processing a `get` request. Let’s go over
    the source code that’s been added to each microservice:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务中的日志记录创建与上一章略有不同，以便 `product-composite` 和三个核心微服务 `product`、`recommendation`
    和 `review` 在开始处理 `get` 请求时都记录一个日志级别设置为 `INFO` 的日志记录。让我们回顾每个微服务中添加的源代码：
- en: 'Product composite microservice log creation:'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品组合微服务日志创建：
- en: '[PRE29]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Product microservice log creation:'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品微服务日志创建：
- en: '[PRE30]'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Recommendation microservice log creation:'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐微服务日志创建：
- en: '[PRE31]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Review microservice log creation:'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 审查微服务日志创建：
- en: '[PRE32]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: For more details, see the source code in the `microservices` folder.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 更多详细信息，请参阅 `microservices` 文件夹中的源代码。
- en: 'Perform the following steps to use the API to create log records and, after
    that, use Kibana to look up the log records:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以使用 API 创建日志记录，然后使用 Kibana 查找日志记录：
- en: 'Get an access token with the following command:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令获取访问令牌：
- en: '[PRE33]'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'As mentioned in the introduction to this section, we will start by creating
    a product with a unique product ID. Create a minimalistic product (without recommendations
    and reviews) for `"productId" :1234` by executing the following command:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如本节介绍中所述，我们将首先创建一个具有唯一产品 ID 的产品。通过执行以下命令创建一个最小化产品（没有推荐和评论）为 `"productId" :1234`：
- en: '[PRE34]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Read the product with the following command:'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用以下命令读取产品：
- en: '[PRE35]'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Expect a response similar to the following:'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期响应类似于以下内容：
- en: '![A screenshot of a computer program  Description automatically generated with
    medium confidence](img/B19825_19_08.png)'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![计算机程序屏幕截图  描述自动生成，置信度中等](img/B19825_19_08.png)'
- en: 'Figure 19.8: Look up the product with productId = 1234'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 19.8：查找 productId = 1234 的产品
- en: Hopefully, we got some log records created by these API calls. Let’s jump over
    to Kibana and find out!
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 希望我们能通过这些 API 调用创建一些日志记录。让我们跳转到 Kibana 并查看一下！
- en: On the Kibana web page, click **Discover** from the hamburger menu. You will
    see something like the following:![A screenshot of a computer  Description automatically
    generated with medium confidence](img/B19825_19_09.png)
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Kibana 网页上，从汉堡菜单点击 **Discover**。你会看到如下内容：![计算机屏幕截图  描述自动生成，置信度中等](img/B19825_19_09.png)
- en: 'Figure 19.9: Kibana web UI with its major parts'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 19.9：Kibana 网页 UI 及其主要部分
- en: In the top-left corner, we can see that Kibana has found **5,350** log records.
    The time picker shows that they are from the **Last 15 minutes**. In the histogram,
    we can see how the log records are spread out over time. Below the histogram is
    a table showing the most recent log events that were found by the query.
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在左上角，我们可以看到 Kibana 找到了 **5,350** 条日志记录。时间选择器显示它们来自 **过去 15 分钟**。在直方图中，我们可以看到日志记录随时间分布的情况。直方图下方是一个表格，显示了查询找到的最新的日志事件。
- en: If you want to change the time interval, you can use the time picker. Click
    on its calendar icon to adjust the time interval.
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你想更改时间间隔，可以使用时间选择器。点击其日历图标以调整时间间隔。
- en: To get a better view of the content in the log records, add some fields from
    the log records as columns in the table under the histogram.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了更好地查看日志记录中的内容，将一些日志记录字段添加到直方图下方的表格中的列。
- en: To be able to see all available fields, click on the down arrow to the right
    of the **Filter by type** label, and unselect **Hide empty fields**.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查看所有可用字段，点击 **按类型筛选** 标签右侧的向下箭头，并取消选择 **隐藏空字段**。
- en: Select the fields from the list of **Available fields** to the left. Scroll
    down until the field is found. To find the fields more easily, use the field named
    **Search field names** to filter the list of available fields.
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧的 **可用字段** 列表中选择字段。向下滚动直到找到该字段。为了更容易地找到字段，使用名为 **搜索字段名称** 的字段来过滤可用字段列表。
- en: 'Hold the cursor over the field and a **+** button will appear (a white cross
    in a blue circle); click on it to add the field as a column in the table. Select
    the following fields, in order:'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将光标悬停在字段上，将出现一个 **+** 按钮（蓝色圆圈中的白色十字）；点击它将字段添加为表格中的列。按以下顺序选择以下字段：
- en: '`spring.level`, the log level'
  id: totrans-324
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`spring.level`，日志级别'
- en: '`kubernetes.namespace_name`, the Kubernetes namespace'
  id: totrans-325
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kubernetes.namespace_name`，Kubernetes 命名空间'
- en: '`kubernetes.container_name`, the name of the container'
  id: totrans-326
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kubernetes.container_name`，容器的名称'
- en: '`spring.trace`, the trace ID used for distributed tracing'
  id: totrans-327
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`spring.trace`，用于分布式跟踪的跟踪 ID'
- en: '`log`, the actual log message'
  id: totrans-328
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`log`，实际的日志消息'
- en: To save some space, you can hide the list of fields by clicking on the collapse
    icon next to the index pattern field (containing the text `logstash-*`).
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了节省空间，你可以通过点击索引模式字段（包含文本`logstash-*`）旁边的折叠图标来隐藏字段列表。
- en: 'The web page should look something like the following:'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 网页应该看起来像以下这样：
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B19825_19_10.png)'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![计算机屏幕截图  描述自动生成，置信度中等](img/B19825_19_10.png)'
- en: 'Figure 19.10: Kibana web UI showing log records'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图19.10：Kibana网页UI显示日志记录
- en: The table now contains information that is of interest regarding the log records!
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在表格中包含了一些关于日志记录的有用信息！
- en: To find log records from the call to the `GET` API, we can ask Kibana to find
    log records where the log field contains the text `product.id=1234`. This matches
    the log output from the `product-composite` microservice that was shown previously.
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要找到来自`GET` API调用的日志记录，我们可以要求Kibana找到日志字段包含文本`product.id=1234`的日志记录。这与之前显示的`product-composite`微服务的日志输出相匹配。
- en: 'This can be done by entering `log:"product.id=1234"` in the top-left **Search**
    field and clicking on the **Update** button (this button can also be named **Refresh**).
    Expect one log record to be found:'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这可以通过在左上角的**搜索**字段中输入`log:"product.id=1234"`并点击**更新**按钮（此按钮也可以命名为**刷新**）来完成。预期会找到一条日志记录：
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B19825_19_11.png)'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![计算机屏幕截图  描述自动生成，置信度中等](img/B19825_19_11.png)'
- en: 'Figure 19.11: Kibana web UI showing a log record for productId = 1234'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图19.11：Kibana网页UI显示productId = 1234的日志记录
- en: Verify that the timestamp is from when you called the `GET` API and verify that
    the name of the container that created the log record is `product-composite`,
    that is, verify that the log record was sent by the product composite microservice.
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确认时间戳是你调用`GET` API时的时间，并确认创建日志记录的容器名称是`product-composite`，也就是说，确认日志记录是由产品组合微服务发送的。
- en: Now, we want to see the related log records from the other microservices that
    participated in the process of returning information about the product with product
    ID `1234`. In other words, we want to find log records with the same **trace ID**
    as that of the log record we found.
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们想看到参与返回产品ID为`1234`的产品信息过程的其它微服务的相关日志记录。换句话说，我们想找到与我们所找到的日志记录具有相同**跟踪ID**的日志记录。
- en: To do this, place the cursor over the `spring.trace` field for the log record.
    Two small magnifying glasses will be shown to the right of the field, one with
    a **+** sign and one with a **-** sign. Click on the magnifying glass with the
    **+** sign to filter on the trace ID.
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要做到这一点，将光标移至日志记录的`spring.trace`字段。字段右侧将显示两个小放大镜，一个带有**+**符号，一个带有**-**符号。点击带有**+**符号的放大镜以过滤跟踪ID。
- en: Clear the **Search** field so that the only search criterion is the filter of
    the trace field. Then, click on the **Update** button to see the result. Expect
    a response like the following:![A screenshot of a computer  Description automatically
    generated with medium confidence](img/B19825_19_12.png)
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清除**搜索**字段，以便唯一的搜索条件是跟踪字段的过滤器。然后，点击**更新**按钮查看结果。预期会得到以下类似的响应：![计算机屏幕截图  描述自动生成，置信度中等](img/B19825_19_12.png)
- en: 'Figure 19.12: Kibana web UI showing log records for a trace ID'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图19.12：Kibana网页UI显示跟踪ID的日志记录
- en: We can see some detailed debug messages that clutter the view; let’s get rid
    of them!
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以看到一些详细的调试消息，它们使视图变得杂乱；让我们去掉它们！
- en: Place the cursor over a **DEBUG** value and click on the magnifying glass with
    the **–** sign to filter out log records with the log level set to **DEBUG**.
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将光标移至**DEBUG**值上，并点击带有**–**符号的放大镜以过滤出日志级别设置为**DEBUG**的日志记录。
- en: 'We should now be able to see the four expected log records, one for each microservice
    involved in the lookup of product information for the product with product ID
    `1234`:'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们应该能够看到四个预期的日志记录，每个对应于查找产品ID为`1234`的产品信息时涉及的每个微服务：
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B19825_19_13.png)'
  id: totrans-346
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  描述自动生成，置信度中等](img/B19825_19_13.png)'
- en: 'Figure 19.13: Kibana web UI showing log records for a trace ID with log level
    = INFO'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 图19.13：Kibana网页UI显示日志级别为INFO的跟踪ID的日志记录
- en: Also, note that the filters that were applied included the trace ID but excluded
    log records with the log level set to **DEBUG**.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请注意，应用的过滤器包括跟踪ID，但排除了日志级别设置为**DEBUG**的日志记录。
- en: Now that we know how to find the expected log records, we are ready to take
    the next step. This will be to learn how to find unexpected log records, that
    is, error messages, and how to perform root cause analysis to find the reason
    for these error messages.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了如何找到预期的日志记录，我们就可以进行下一步了。这将是学习如何找到意外的日志记录，即错误信息，以及如何进行根本原因分析以找到这些错误信息的原因。
- en: Performing root cause analyses
  id: totrans-350
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进行根本原因分析
- en: One of the most important features of centralized logging is that it makes it
    possible to analyze errors using log records from many sources and, based on that,
    perform root cause analysis, finding the actual reason for the error message.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 集中日志最重要的特性之一是它使得使用来自许多来源的日志记录来分析错误成为可能，并且基于这些分析进行根本原因分析，找出错误信息的真正原因。
- en: 'In this section, we will simulate an error and see how we can find information
    about it all the way down to the line of source code that caused the error in
    one of the microservices in the system landscape. To simulate an error, we will
    reuse the fault parameter we introduced in *Chapter 13*, *Improving Resilience
    Using Resilience4j*, in the *Adding programmable delays and random errors* section.
    We can use this to force the `product` microservice to throw an exception. Perform
    the following steps:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将模拟一个错误，并查看我们如何能够找到关于它的所有信息，直到找到在系统景观中某个微服务中引起错误的源代码行。为了模拟错误，我们将重用我们在第13章的*使用Resilience4j提高弹性*部分中引入的故障参数，在*添加可编程延迟和随机错误*部分中使用它来强制`product`微服务抛出异常。执行以下步骤：
- en: 'Run the following command to generate a fault in the `product` microservice
    while searching for product information on the product with product ID `1234`:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令在搜索产品ID为`1234`的产品信息时在`product`微服务中生成故障：
- en: '[PRE36]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Expect the following error in response:'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期以下错误响应：
- en: '![A picture containing text, screenshot, software, multimedia  Description
    automatically generated](img/B19825_19_14.png)'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![包含文本、截图、软件、多媒体的图片，自动生成描述](img/B19825_19_14.png)'
- en: 'Figure 19.14: A request that caused an error in the processing'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图19.14：一个在处理中引起错误的请求
- en: Now, we must pretend that we have no clue about the reason for this error! Otherwise,
    the root cause analysis wouldn’t be very exciting, right?
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们必须假装我们对这个错误的原因一无所知！否则，根本原因分析就不会那么令人兴奋，对吧？
- en: Let’s assume that we work in a support organization and have been asked to investigate
    a problem that just occurred when an end user tried to look up information regarding
    a product with product ID `1234` but got an error message saying “`500 Internal
    Server Error`" in response.
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 假设我们在一个支持组织中工作，并被要求调查一个问题，即当最终用户尝试查找产品ID为`1234`的产品信息时，却收到了显示“`500 Internal Server
    Error`”错误信息的响应。
- en: Before we start to analyze the problem, let’s delete the previous search filters
    in the Kibana web UI so that we can start from scratch. For each filter we defined
    in the previous section, click on its close icon (an **x**) to remove it.
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们开始分析问题之前，让我们在Kibana web UI中删除之前的搜索过滤器，以便我们可以从头开始。对于我们在上一节中定义的每个过滤器，点击其关闭图标（一个**x**）来移除它。
- en: Start by using the time picker to select a time interval that includes the point
    in time when the problem occurred. In my case, 15 minutes is sufficient.
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，使用时间选择器选择一个包含问题发生时间点的时段。在我的情况下，15分钟就足够了。
- en: 'Select log records belonging to our namespace, `hands-on`. This can be done
    by the following steps:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择属于我们的命名空间`hands-on`的日志记录。可以通过以下步骤完成：
- en: Expand the list of fields to the left, by clicking on the hamburger icon (**≡**)
    in the top-left corner.
  id: totrans-363
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击左上角的汉堡图标（**≡**）来展开左侧的字段列表。
- en: Click on the field **kubernetes.namespace_name** in the list of **Selected fields**.
    A list of the top five namespaces is shown.
  id: totrans-364
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击列表中的**kubernetes.namespace_name**字段。显示的是前五个命名空间列表。
- en: Click on the **+** sign after the **hands-on** namespace.
  id: totrans-365
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**hands-on**命名空间后面的**+**号。
- en: Next, search for log records with the log level set to **WARN** within this
    time frame where the log message mentions product ID `1234`. This can be done
    by clicking on the `spring.level` field in the list of selected fields. When you
    click on this field, its most used values will be displayed under it. Filter on
    the **WARN** value by clicking on its **+** sign. Kibana will now show log records
    within the selected time frame with their log level set to **WARN** from the **hands-on**
    namespace, like this:![A screenshot of a computer  Description automatically generated
    with medium confidence](img/B19825_19_15.png)
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，搜索在此时间范围内设置日志级别为**WARN**的日志记录，其中日志消息提到了产品ID `1234`。这可以通过点击所选字段列表中的`spring.level`字段来完成。当你点击这个字段时，其最常用的值将显示在其下方。通过点击其**+**号来过滤**WARN**值。Kibana现在将显示在所选时间范围内设置日志级别为**WARN**的日志记录，来自**hands-on**命名空间，如下所示：![计算机的截图  描述自动生成，置信度中等](img/B19825_19_15.png)
- en: 'Figure 19.15: Kiali web UI, showing log records that report ERRORs'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图19.15：Kiali网页UI，显示报告ERRORs的日志记录
- en: We can see a number of error messages related to product ID `1234`. The top
    log entries have the same trace ID, so this seems like a trace ID of interest
    to use for further investigation. The first log entry also contains the text reported
    by the end user **500** and **Internal Server Error**, and the error message **Something
    went wrong…**, which probably has to do with the root cause of the error.
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以看到与产品ID `1234`相关的多个错误消息。顶部日志条目具有相同的跟踪ID，因此这似乎是一个值得进一步调查的跟踪ID。第一条日志条目还包含最终用户报告的文本**500**和**Internal
    Server Error**，以及错误消息**Something went wrong…**，这可能与错误的根本原因有关。
- en: Filter on the trace ID of the first log record as we did in the previous section.
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在上一节中，我们按照同样的方式过滤了第一条日志记录的跟踪ID。
- en: Remove the filter of the `WARN` log level to be able to see all the records
    belonging to this trace ID. Expect Kibana to respond with a lot of log records
    looking something like this:![A screenshot of a computer  Description automatically
    generated with medium confidence](img/B19825_19_16.png)
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移除`WARN`日志级别的过滤器，以便能够看到属于此跟踪ID的所有记录。预期Kibana将响应大量类似以下的日志记录：![计算机的截图  描述自动生成，置信度中等](img/B19825_19_16.png)
- en: 'Figure 19.16: Kiali web UI, looking for the root cause'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图19.16：Kiali网页UI，寻找根本原因
- en: Unfortunately, we cannot find any stack trace identifying the root cause by
    using trace IDs. This is due to a limitation in the Fluentd plugin we use for
    collecting multiline exceptions, `fluent-plugin-detect-exceptions`. It cannot
    relate stack traces to the trace ID that was used. Instead, we can use a feature
    in Kibana to find surrounding log records that have occurred near in time to a
    specific log record.
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 很遗憾，我们无法通过使用跟踪ID来找到识别根本原因的堆栈跟踪。这是由于我们用于收集多行异常的Fluentd插件`fluent-plugin-detect-exceptions`的限制。它无法将堆栈跟踪与所使用的跟踪ID相关联。相反，我们可以使用Kibana中的功能来查找在特定日志记录附近发生的时间相近的日志记录。
- en: 'Expand the log record that says **Error body: {… status”:500,”error”:”Internal
    Server Error”,”message”:”Something went wrong...”…}** using the arrow to the left
    of the log record. Detailed information about this specific log record will be
    revealed:'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '使用日志记录左侧的箭头展开显示**Error body: {… status”:500,”error”:”Internal Server Error”,”message”:”Something
    went wrong...”…}**的日志记录。关于此特定日志记录的详细信息将被揭示：'
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B19825_19_17.png)'
  id: totrans-374
  prefs: []
  type: TYPE_IMG
  zh: '![计算机的截图  描述自动生成，置信度中等](img/B19825_19_17.png)'
- en: 'Figure 19.17: Kiali web UI, expanding the log record with the root cause log
    message'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 图19.17：Kiali网页UI，展开带有根本原因日志消息的日志记录
- en: 'There is also a link named **View surrounding documents**; click on it to see
    nearby log records. Scroll down to the bottom of the page to find a **Load** field
    where the number of records can be specified. Increase the default value, from
    5 to 10\. Expect a web page like the following:'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还有一个名为**查看周围文档**的链接；点击它以查看附近的日志记录。滚动到页面底部以找到可以指定记录数量的**加载**字段。将默认值从5增加到10。预期网页如下所示：
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B19825_19_18.png)'
  id: totrans-377
  prefs: []
  type: TYPE_IMG
  zh: '![计算机的截图  描述自动生成，置信度中等](img/B19825_19_18.png)'
- en: 'Figure 19.18: Kiali web UI, the root cause found'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 图19.18：Kiali网页UI，找到了根本原因
- en: 'The third log record below the expanded log record contains the stack trace
    for the error message **Something went wrong...**. This error message looks interesting.
    It was logged by the `product` microservice just five milliseconds before the
    expanded log record. They seem to be related! The stack trace in that log record
    points to line 104 in `ProductServiceImpl.java`. Looking at the source code (see
    `microservices/product-service/src/main/java/se/magnus/microservices/core/product/services/ProductServiceImpl.java`),
    line 104 looks as follows:'
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在展开的日志记录下方第三条日志记录包含了错误消息**出了点问题...**的堆栈跟踪。这个错误消息看起来很有趣。它是在展开的日志记录前五毫秒由`product`微服务记录的。它们似乎有关联！该日志记录中的堆栈跟踪指向`ProductServiceImpl.java`中的第104行。查看源代码（见`microservices/product-service/src/main/java/se/magnus/microservices/core/product/services/ProductServiceImpl.java`），第104行如下：
- en: '[PRE37]'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This is the root cause of the error. We did know this in advance, but now we
    have seen how we can navigate to it as well.
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是错误的根本原因。我们事先确实知道这一点，但现在我们也看到了如何导航到它。
- en: In this case, the problem is quite simple to resolve; simply omit the `faultPercent`
    parameter in the request to the API. In other cases, resolving the root cause
    can be much harder to figure out!
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，问题非常简单就能解决；只需在 API 请求中省略`faultPercent`参数即可。在其他情况下，确定根本原因可能要困难得多！
- en: This concludes the root cause analysis. Click on the back button in the web
    browser to get back to the main page.
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这就结束了根本原因分析。点击网页浏览器中的后退按钮返回主页。
- en: To be able to reuse the configuration of the search criteria and table layout,
    its definition can be saved by Kibana. Select, for example, to filter on log records
    from the `hands-on` namespace and click on the **Save** link in the top-right
    menu. Give the search definition a name and click on the **Save** button. The
    search definition can be restored when required using the **Open** link in the
    menu.
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了能够重用搜索条件和表格布局的配置，可以通过 Kibana 保存其定义。例如，选择对`hands-on`命名空间中的日志记录进行过滤，然后在右上角的菜单中点击**保存**链接。为搜索定义命名并点击**保存**按钮。当需要时，可以使用菜单中的**打开**链接恢复搜索定义。
- en: This concludes this chapter on using the EFK stack for centralized logging.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了关于使用 EFK 栈进行集中日志记录的章节。
- en: Summary
  id: totrans-386
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about the importance of collecting log records from
    microservices in a system landscape into a common centralized database where analysis
    and searches of the stored log records can be performed. We used the EFK stack,
    Elasticsearch, Fluentd, and Kibana, to collect, process, store, analyze, and search
    for log records.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了在系统视图中从微服务收集日志记录并将其放入一个公共集中数据库的重要性，在那里可以对存储的日志记录进行分析和搜索。我们使用了 EFK
    栈，包括 Elasticsearch、Fluentd 和 Kibana，来收集、处理、存储、分析和搜索日志记录。
- en: Fluentd was used to collect log records not only from our microservices but
    also from the various supporting containers in the Kubernetes cluster. Elasticsearch
    was used as a text search engine. Together with Kibana, we saw how easy it is
    to get an understanding of what types of log records we have collected.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd 不仅用于从我们的微服务中收集日志记录，还用于 Kubernetes 集群中的各种支持容器。Elasticsearch 被用作文本搜索引擎。与
    Kibana 一起，我们看到了理解我们收集了哪些类型日志记录是多么容易。
- en: We also learned how to use Kibana to perform important tasks such as finding
    related log records from cooperating microservices and how to perform root cause
    analysis, finding the real problem for an error message.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还学习了如何使用 Kibana 执行重要任务，例如从协作微服务中查找相关日志记录以及如何进行根本原因分析，找到错误消息的真实问题。
- en: Being able to collect and analyze log records in this way is an important capability
    in a production environment, but these types of activities are always done afterward
    once the log record has been collected. Another important capability is to be
    able to monitor the current health of the microservices, collecting and visualizing
    runtime metrics in terms of the use of hardware resources, response times, and
    so on. We touched on this subject in the previous chapter, and in the next chapter,
    we will learn more about monitoring microservices.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 能够以这种方式收集和分析日志记录在生产环境中是一个重要的能力，但这些类型的活动总是在收集日志记录之后才进行。另一个重要的能力是能够监控微服务的当前健康状况，从硬件资源的使用、响应时间等方面收集和可视化运行时指标。我们在上一章中提到了这个主题，在下一章中，我们将学习更多关于监控微服务的内容。
- en: Questions
  id: totrans-391
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: A user searched for `ERROR` log messages in the `hands-on` namespace for the
    last 30 days using the search criteria shown in the following screenshot, but
    none were found. Why?
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户使用以下截图所示的搜索条件在“hands-on”命名空间中搜索了最后30天的`ERROR`日志消息，但没有找到任何结果。为什么？
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B19825_19_19.png)'
  id: totrans-393
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  描述自动生成，置信度中等](img/B19825_19_19.png)'
- en: 'Figure 19.19: Kiali web UI, not showing expected log records'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 图19.19：Kiali网页界面，未显示预期的日志记录
- en: A user has found a log record of interest (shown below). How can the user find
    related log records from this and other microservices, for example, that come
    from processing an external API request?
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户发现了一条有趣的日志记录（如下所示）。用户如何从这条和其他微服务中找到相关的日志记录，例如，来自处理外部API请求的微服务？
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B19825_19_20.png)'
  id: totrans-396
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  描述自动生成，置信度中等](img/B19825_19_20.png)'
- en: 'Figure 19.20: Kiali web UI; how do we find related log records?'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 图19.20：Kiali网页界面；我们如何找到相关的日志记录？
- en: A user has found a log record that seems to indicate the root cause of a problem
    that was reported by an end user. How can the user find the stack trace that shows
    where in the source code the error occurred?
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户发现了一条日志记录，似乎表明了由最终用户报告的问题的根本原因。用户如何找到显示错误发生位置的源代码中的堆栈跟踪？
- en: '![A screen shot of a computer  Description automatically generated with low
    confidence](img/B19825_19_21.png)'
  id: totrans-399
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  描述自动生成，置信度低](img/B19825_19_21.png)'
- en: 'Figure 19.21: Kiali web UI; how do we find the root cause?'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 图19.21：Kiali网页界面；我们如何找到根本原因？
- en: Why doesn’t the following Fluentd configuration element work?
  id: totrans-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么以下Fluentd配置元素不起作用？
- en: '[PRE38]'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: How can you determine whether Elasticsearch is up and running?
  id: totrans-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你如何确定Elasticsearch是否正在运行？
- en: You suddenly lose connection to Kibana from your web browser. What could have
    caused this problem?
  id: totrans-404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你突然从网络浏览器中失去了与Kibana的连接。可能是什么原因导致了这个问题？
