- en: Part 2. Module 2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2部分。模块2
- en: '**Clojure High Performance Programming, Second Edition**'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**《Clojure高性能编程，第二版》**'
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Become an expert at writing fast and high performant code in Clojure 1.7.0*'
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*成为在Clojure 1.7.0中编写快速且高性能代码的专家*'
- en: Chapter 1. Performance by Design
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章。设计性能
- en: Clojure is a safe, functional programming language that brings great power and
    simplicity to the user. Clojure is also dynamically and strongly typed, and has
    very good performance characteristics. Naturally, every activity performed on
    a computer has an associated cost. What constitutes acceptable performance varies
    from one use-case and workload to another. In today's world, performance is even
    the determining factor for several kinds of applications. We will discuss Clojure
    (which runs on the **JVM** (**Java Virtual Machine**)), and its runtime environment
    in the light of performance, which is the goal of this book.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure是一种安全、函数式编程语言，它为用户带来了巨大的力量和简洁性。Clojure也是动态和强类型化的，并且具有非常好的性能特性。自然地，计算机上进行的每一项活动都有相应的成本。构成可接受性能的因素因用例和工作负载而异。在当今世界，性能甚至成为几种类型应用程序的决定性因素。我们将从性能的角度讨论Clojure（它运行在**JVM**（**Java虚拟机**）上），以及其运行环境，这正是本书的目标。
- en: 'The performance of Clojure applications depend on various factors. For a given
    application, understanding its use cases, design and implementation, algorithms,
    resource requirements and alignment with the hardware, and the underlying software
    capabilities is essential. In this chapter, we will study the basics of performance
    analysis, including the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure应用程序的性能取决于各种因素。对于给定的应用程序，理解其用例、设计、实现、算法、资源需求和与硬件的匹配，以及底层软件能力是至关重要的。在本章中，我们将研究性能分析的基础，包括以下内容：
- en: Classifying the performance anticipations by the use cases types
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过用例类型对性能预期进行分类
- en: Outlining the structured approach to analyze performance
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概述分析性能的结构化方法
- en: A glossary of terms, commonly used to discuss performance aspects
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一份术语表，通常用于讨论性能方面
- en: The performance numbers that every programmer should know
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个程序员都应该知道的性能数字
- en: Use case classification
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用例分类
- en: The performance requirements and priority vary across the different kinds of
    use cases. We need to determine what constitutes acceptable performance for the
    various kinds of use cases. Hence, we classify them to identify their performance
    model. When it comes to details, there is no sure shot performance recipe for
    any kind of use case, but it certainly helps to study their general nature. Note
    that in real life, the use cases listed in this section may overlap with each
    other.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型的用例的性能需求和优先级各不相同。我们需要确定各种类型用例的可接受性能构成。因此，我们将它们分类以识别其性能模型。在细节上，对于任何类型的用例，都没有一成不变的性能秘方，但研究它们的普遍性质肯定是有帮助的。请注意，在现实生活中，本节中列出的用例可能相互重叠。
- en: The user-facing software
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 面向用户的软件
- en: The performance of user-facing applications is strongly linked to the user's
    anticipation. Having a difference of a good number of milliseconds may not be
    perceptible for the user but at the same time, a wait of more than a few seconds
    may not be taken kindly. One important element in normalizing anticipation is
    to engage the user by providing duration-based feedback. A good idea to deal with
    such a scenario would be to start the task asynchronously in the background, and
    poll it from the UI layer to generate a duration-based feedback for the user.
    Another way could be to incrementally render the results to the user to even out
    the anticipation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 面向用户的软件性能与用户的预期紧密相关。差异可能有好几毫秒，对用户来说可能不明显，但与此同时，等待几秒钟以上可能不会受到欢迎。在正常化预期的一个重要元素是通过提供基于持续时间的反馈来吸引用户。处理此类场景的一个好主意是在后台异步启动任务，并从UI层轮询它以生成基于持续时间的用户反馈。另一种方法是对用户逐步渲染结果，以平衡预期。
- en: Anticipation is not the only factor in user facing performance. Common techniques
    like staging or precomputation of data, and other general optimization techniques
    can go a long way to improve the user experience with respect to performance.
    Bear in mind that all kinds of user facing interfaces fall into this use case
    category—the Web, mobile web, GUI, command line, touch, voice-operated, gesture...you
    name it.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 预期并非用户界面性能的唯一因素。常见的技巧，如数据分阶段或预计算，以及其他一般优化技术，可以在很大程度上改善性能方面的用户体验。请记住，所有类型的用户界面都归属于此类用例范畴——网页、移动网页、图形用户界面、命令行、触摸、语音控制、手势……无论你叫它什么。
- en: Computational and data-processing tasks
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算和数据处理任务
- en: Non-trivial compute intensive tasks demand a proportional amount of computational
    resources. All of the CPU, cache, memory, efficiency and the parallelizability
    of the computation algorithms would be involved in determining the performance.
    When the computation is combined with distribution over a network or reading from/staging
    to disk, I/O bound factors come into play. This class of workloads can be further
    subclassified into more specific use cases.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 非平凡的密集型计算任务需要相应数量的计算资源。所有CPU、缓存、内存、计算算法的效率和并行化都会涉及到性能的确定。当计算与网络分布或从磁盘读取/分阶段到磁盘结合时，I/O密集型因素就会发挥作用。这类工作负载可以进一步细分为更具体的用例。
- en: A CPU bound computation
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CPU密集型计算
- en: A CPU bound computation is limited by the CPU cycles spent on executing it.
    Arithmetic processing in a loop, small matrix multiplication, determining whether
    a number is a **Mersenne prime**, and so on, would be considered CPU bound jobs.
    If the algorithm complexity is linked to the number of iterations/operations *N*,
    such as *O(N)*, *O(N* *²)* and more, then the performance depends on how big *N*
    is, and how many CPU cycles each step takes. For parallelizable algorithms, performance
    of such tasks may be enhanced by assigning multiple CPU cores to the task. On
    virtual hardware, the performance may be impacted if the CPU cycles are available
    in bursts.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: CPU密集型计算受限于执行它所花费的CPU周期。循环中的算术处理、小矩阵乘法、判断一个数是否为**梅森素数**等，都会被认为是CPU密集型工作。如果算法复杂度与迭代/操作次数*N*相关，例如*O(N)*，*O(N²)*等，那么性能取决于*N*的大小以及每一步所需的CPU周期数。对于可并行化的算法，可以通过分配多个CPU核心给任务来提高此类任务的性能。在虚拟硬件上，如果CPU周期是突发性的，性能可能会受到影响。
- en: A memory bound task
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内存密集型任务
- en: A memory bound task is limited by the availability and bandwidth of the memory.
    Examples include large text processing, list processing, and more. For example,
    specifically in Clojure, the `(reduce f (pmap g coll))` operation would be memory
    bound if `coll` is a large sequence of big maps, even though we parallelize the
    operation using `pmap` here. Note that higher CPU resources cannot help when memory
    is the bottleneck, and vice versa. Lack of availability of memory may force you
    to process smaller chunks of data at a time, even if you have enough CPU resources
    at your disposal. If the maximum speed of your memory is *X* and your algorithm
    on single the core accesses the memory at speed *X/3*, the multicore performance
    of your algorithm cannot exceed three times the current performance, no matter
    how many CPU cores you assign to it. The memory architecture (for example, SMP
    and NUMA) contributes to the memory bandwidth in multicore computers. Performance
    with respect to memory is also subject to page faults.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 内存密集型任务受限于内存的可用性和带宽。例如，大文本处理、列表处理等。例如，在Clojure中，如果`coll`是一个由大映射组成的大序列，那么`(reduce
    f (pmap g coll))`操作将是内存密集型的，即使我们在这里使用`pmap`并行化操作。请注意，当内存成为瓶颈时，更高的CPU资源无法帮助，反之亦然。内存不可用可能迫使你一次处理更小的数据块，即使你有足够的CPU资源可用。如果你的内存最大速度是*X*，而你的算法在单个核心上以速度*X/3*访问内存，那么你的算法的多核性能不能超过当前性能的三倍，无论你分配多少CPU核心给它。内存架构（例如，SMP和NUMA）对多核计算机的内存带宽有贡献。与内存相关的性能也受页面错误的影响。
- en: A cache bound task
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缓存密集型任务
- en: A task is cache bound when its speed is constrained by the amount of cache available.
    When a task retrieves values from a small number of repeated memory locations,
    for example a small matrix multiplication, the values may be cached and fetched
    from there. Note that CPUs (typically) have multiple layers of cache, and the
    performance will be at its best when the processed data fits in the cache, but
    the processing will still happen, more slowly, when the data does not fit into
    the cache. It is possible to make the most of the cache using **cache-oblivious**
    algorithms. A higher number of concurrent cache/memory bound threads than CPU
    cores is likely to flush the instruction pipeline, as well as the cache at the
    time of context switch, likely leading to a severely degraded performance.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个任务的速度受可用缓存量限制时，它就是缓存受限的。当一个任务从少量重复的内存位置检索值时，例如一个小矩阵乘法，这些值可能会被缓存并从那里获取。请注意，CPU（通常是）有多个缓存层，当处理的数据适合缓存时，性能将达到最佳，但当数据不适合缓存时，处理仍然会发生，但速度会慢一些。可以使用**缓存无关**算法最大限度地利用缓存。当并发缓存/内存受限线程的数量高于CPU核心数时，很可能会在上下文切换时清空指令流水线和缓存，这可能导致性能严重下降。
- en: An input/output bound task
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输入/输出边界任务
- en: An **input/output** (**I/O**) bound task would go faster if the I/O subsystem,
    that it depends on, goes faster. Disk/storage and network are the most commonly
    used I/O subsystems in data processing, but it can be serial port, a USB-connected
    card reader, or any I/O device. An I/O bound task may consume very few CPU cycles.
    Depending on the speed of the device, connection pooling, data compression, asynchronous
    handling, application caching, and more, may help in performance. One notable
    aspect of I/O bound tasks is that performance is usually dependent on the time
    spent waiting for connection/seek, and the amount of serialization that we do,
    and hardly on the other resources.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果依赖的I/O子系统运行得更快，那么**输入/输出**（**I/O**）边界任务会运行得更快。磁盘/存储和网络是数据处理中最常用的I/O子系统，但它可以是串行端口、USB连接的卡片阅读器或任何I/O设备。I/O边界任务可能消耗很少的CPU周期。根据设备速度、连接池、数据压缩、异步处理、应用缓存等，可能会有助于性能。I/O边界任务的一个显著方面是，性能通常取决于等待连接/查找的时间以及我们进行的序列化程度，而与其他资源关系不大。
- en: In practice, many data processing workloads are usually a combination of CPU
    bound, memory bound, cache bound, and I/O bound tasks. The performance of such
    mixed workloads effectively depends on the even distribution of CPU, cache, memory,
    and I/O resources over the duration of the operation. A bottleneck situation arises
    only when one resource gets too busy to make way for another.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，许多数据处理工作负载通常是CPU受限、内存受限、缓存受限和I/O受限任务的组合。这种混合工作负载的性能实际上取决于在整个操作期间CPU、缓存、内存和I/O资源的均匀分布。只有当某个资源变得过于繁忙，以至于无法为另一个资源让路时，才会出现瓶颈情况。
- en: Online transaction processing
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在线事务处理
- en: '**Online transaction processing** (**OLTP**) systems process the business transactions
    on demand. They can sit behind systems such as a user-facing ATM machine, point-of-sale
    terminal, a network-connected ticket counter, ERP systems, and more. The OLTP
    systems are characterized by low latency, availability, and data integrity. They
    run day-to-day business transactions. Any interruption or outage is likely to
    have a direct and immediate impact on sales or service. Such systems are expected
    to be designed for resiliency rather than delayed recovery from failures. When
    the performance objective is unspecified, you may like to consider graceful degradation
    as a strategy.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**在线事务处理**（**OLTP**）系统按需处理业务交易。它们可以位于用户界面ATM机、销售点终端、网络连接的票务柜台、ERP系统等系统之后。OLTP系统以低延迟、可用性和数据完整性为特征。它们运行日常业务交易。任何中断或故障都可能对销售或服务产生直接和立即的影响。这些系统预计将被设计为具有弹性，而不是从故障中延迟恢复。当性能目标未指定时，您可能希望考虑优雅降级作为策略。'
- en: It is a common mistake to ask the OLTP systems to answer analytical queries,
    something that they are not optimized for. It is desirable for an informed programmer
    to know the capability of the system, and suggest design changes as per the requirements.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 要求OLTP系统回答分析查询是一个常见的错误，它们并不是为此优化的。一个有经验的程序员了解系统的能力，并根据需求提出设计更改是可取的。
- en: Online analytical processing
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在线分析处理
- en: '**Online analytical processing** (**OLAP**) systems are designed to answer
    analytical queries in a short time. They typically get data from the OLTP operations,
    and their data model is optimized for querying. They basically provide for consolidation
    (roll-up), drill-down and slicing and dicing of data for analytical purposes.
    They often use specialized data stores that can optimize ad-hoc analytical queries
    on the fly. It is important for such databases to provide pivot-table like capability.
    Often, the OLAP cube is used to get fast access to the analytical data.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**在线分析处理**（**OLAP**）系统旨在短时间内回答分析查询。它们通常从OLTP操作中获取数据，并且其数据模型针对查询进行了优化。它们基本上提供数据合并（汇总）、钻取和切片切块，以用于分析目的。它们通常使用可以即时优化即席分析查询的特殊数据存储。对于此类数据库来说，提供类似交叉表的功能非常重要。通常，OLAP立方体用于快速访问分析数据。'
- en: Feeding the OLTP data into the OLAP systems may entail workflows and multistage
    batch processing. The performance concern of such systems is to efficiently deal
    with large quantities of data while also dealing with inevitable failures and
    recovery.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 将OLTP数据输入到OLAP系统中可能涉及工作流和多阶段批量处理。这些系统的性能关注点是高效处理大量数据，同时处理不可避免的故障和恢复。
- en: Batch processing
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 批量处理
- en: '**Batch processing** is automated execution of predefined jobs. These are typically
    bulk jobs that are executed during off-peak hours. Batch processing may involve
    one or more stages of job processing. Often batch processing is clubbed with workflow
    automation, where some workflow steps are executed offline. Many of the batch
    processing jobs work on staging of data, and on preparing data for the next stage
    of processing to pick up.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**批量处理**是指预定义任务的自动化执行。这些通常是批量作业，在非高峰时段执行。批量处理可能涉及一个或多个作业处理阶段。通常，批量处理与工作流自动化结合使用，其中一些工作流步骤是在线执行的。许多批量处理作业处理数据阶段，并为下一阶段的处理准备数据。'
- en: Batch jobs are generally optimized for the best utilization of the computing
    resources. Since there is little to moderate the demand to lower the latencies
    of some particular subtasks, these systems tend to optimize for throughput. A
    lot of batch jobs involve largely I/O processing and are often distributed over
    a cluster. Due to distribution, the data locality is preferred when processing
    the jobs; that is, the data and processing should be local in order to avoid network
    latency in reading/writing data.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 批量作业通常针对最佳计算资源利用率进行优化。由于对降低某些特定子任务的延迟需求很少或适中，这些系统倾向于优化吞吐量。许多批量作业涉及大量的I/O处理，并且通常分布在集群上。由于分布，处理作业时优先考虑数据局部性；也就是说，数据和处理应该是本地的，以避免在读写数据时的网络延迟。
- en: A structured approach to the performance
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能的有序方法
- en: In practice, the performance of non-trivial applications is rarely a function
    of coincidence or prediction. For many projects, performance is not an option
    (it is rather a necessity), which is why this is even more important today. Capacity
    planning, determining performance objectives, performance modeling, measurement,
    and monitoring are key.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，非平凡应用程序的性能很少是巧合或预测的结果。对于许多项目来说，性能不是一种选择（它更是一种必需品），这就是为什么今天这更加重要。容量规划、确定性能目标、性能建模、测量和监控是关键。
- en: Tuning a poorly designed system to perform is significantly harder, if not practically
    impossible, than having a system well-designed from the start. In order to meet
    a performance goal, performance objectives should be known before the application
    is designed. The performance objectives are stated in terms of latency, throughput,
    resource utilization, and workload. These terms are discussed in the following
    section in this chapter.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 调整设计不良的系统以实现性能，如果不说实际上不可能，那么至少比从一开始就设计良好的系统要困难得多。为了达到性能目标，在应用程序设计之前应该知道性能目标。性能目标用延迟、吞吐量、资源利用率和工作负载等术语来表述。这些术语将在本章下一节中讨论。
- en: The resource cost can be identified in terms of application scenarios, such
    as browsing of products, adding products to shopping cart, checkout, and more.
    Creating workload profiles that represent users performing various operations
    is usually helpful.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 资源成本可以根据应用场景来识别，例如浏览产品、将产品添加到购物车、结账等。创建代表用户执行各种操作的工作负载配置文件通常是有帮助的。
- en: '**Performance modeling** is a reality check for whether the application design
    will support the performance objectives. It includes performance objectives, application
    scenarios, constraints, measurements (benchmark results), workload objectives
    and if available, the performance baseline. It is not a replacement for measurement
    and load testing, rather, the model is validated using these. The performance
    model may include the performance test cases to assert the performance characteristics
    of the application scenarios.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能建模**是检查应用设计是否支持性能目标的一种现实检验。它包括性能目标、应用场景、约束、测量（基准结果）、工作负载目标，如果有的话，还有性能基线。它不是测量和负载测试的替代品，而是使用这些来验证模型。性能模型可能包括性能测试用例，以断言应用场景的性能特征。'
- en: Deploying an application to production almost always needs some form of **capacity
    planning**. It has to take into account the performance objectives for today and
    for the foreseeable future. It requires an idea of the application architecture,
    and an understanding of how the external factors translate into the internal workload.
    It also requires informed expectations about the responsiveness and the level
    of service to be provided by the system. Often, capacity planning is done early
    in a project to mitigate the risk of provisioning delays.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 将应用程序部署到生产环境中几乎总是需要某种形式的**容量规划**。它必须考虑今天的性能目标和可预见的未来的性能目标。它需要了解应用程序架构，以及外部因素如何转化为内部工作负载。它还需要对系统提供的响应性和服务水平的了解。通常，容量规划在项目早期进行，以减轻配置延迟的风险。
- en: The performance vocabulary
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能词汇表
- en: There are several technical terms that are heavily used in performance engineering.
    It is important to understand these, as they form the cornerstone of the performance-related
    discussions. Collectively, these terms form a performance vocabulary. The performance
    is usually measured in terms of several parameters, where every parameter has
    roles to play—such parameters are a part of the vocabulary.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在性能工程中，有几个术语被广泛使用。理解这些术语非常重要，因为它们构成了性能相关讨论的基础。这些术语共同构成了一个性能词汇表。性能通常通过几个参数来衡量，每个参数都有其作用——这样的参数是词汇表的一部分。
- en: Latency
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 延迟
- en: '**Latency** is the time taken by an individual unit of work to complete the
    task. It does not imply successful completion of a task. Latency is not collective,
    it is linked to a particular task. If two similar jobs—`j1` and `j2` took 3 ms
    and 5 ms respectively, their latencies would be treated as such. If `j1` and `j2`
    were dissimilar tasks, it would have made no difference. In many cases the average
    latency of similar jobs is used in the performance objectives, measurement, and
    monitoring results.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**延迟**是指单个工作单元完成任务所需的时间。它并不表示任务的顺利完成。延迟不是集体的，它与特定的任务相关联。如果两个类似的工作`j1`和`j2`分别耗时3毫秒和5毫秒，它们的延迟将如此处理。如果`j1`和`j2`是不同的任务，这就没有区别。在许多情况下，类似工作的平均延迟被用于性能目标、测量和监控结果。'
- en: Latency is an important indicator of the health of a system. A high performance
    system often thrives on low latency. Higher than normal latency can be caused
    due to load or bottleneck. It helps to measure the latency distribution during
    a load test. For example, if more than 25 percent of similar jobs, under a similar
    load, have significantly higher latency than others, then it may be an indicator
    of a bottleneck scenario that is worth investigating.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟是衡量系统健康状况的重要指标。高性能系统通常依赖于低延迟。高于正常水平的延迟可能由负载或瓶颈引起。在负载测试期间测量延迟分布很有帮助。例如，如果超过25%的类似工作，在相似负载下，其延迟显著高于其他工作，那么这可能是值得调查的瓶颈场景的指标。
- en: When a task called `j1` consists of smaller tasks called `j2`, `j3`, and `j4`,
    the latency of `j1` is not necessarily the sum of the latencies of each of `j2`,
    `j3`, and `j4`. If any of the subtasks of `j1` are concurrent with another, the
    latency of `j1` will turn out to be less than the sum of the latencies of `j2`,
    `j3`, and `j4`. The I/O bound tasks are generally more prone to higher latency.
    In network systems, latency is commonly based on the round-trip to another host,
    including the latency from source to destination, and then back to source.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个名为`j1`的任务由名为`j2`、`j3`和`j4`的较小任务组成时，`j1`的延迟不一定是`j2`、`j3`和`j4`各自延迟的总和。如果`j1`的任何子任务与另一个任务并发，`j1`的延迟将小于`j2`、`j3`和`j4`延迟的总和。I/O受限的任务通常更容易出现更高的延迟。在网络系统中，延迟通常基于往返到另一个主机，包括从源到目的地的延迟，然后返回源。
- en: Throughput
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Throughput（吞吐量）
- en: '**Throughput** is the number of successful tasks or operations performed in
    a unit of time. The top-level operations performed in a unit of time are usually
    of a similar kind, but with a potentially different from latencies. So, what does
    throughput tell us about the system? It is the rate at which the system is performing.
    When you perform load testing, you can determine the maximum rate at which a particular
    system can perform. However, this is not a guarantee of the conclusive, overall,
    and maximum rate of performance.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**吞吐量**是在单位时间内完成的成功任务或操作的数量。在单位时间内执行的最顶层操作通常属于同一类型，但延迟可能不同。那么，吞吐量告诉我们关于系统的什么信息？它是系统执行的速度。当你进行负载测试时，你可以确定特定系统可以执行的最大速率。然而，这并不能保证结论性的、整体的和最大性能速率。'
- en: Throughput is one of the factors that determine the scalability of a system.
    The throughput of a higher level task depends on the capacity to spawn multiple
    such tasks in parallel, and also on the average latency of those tasks. The throughput
    should be measured during load testing and performance monitoring to determine
    the peak-measured throughput, and the maximum-sustained throughput. These factors
    contribute to the scale and performance of a system.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 吞吐量是决定系统可扩展性的因素之一。较高层次任务的吞吐量取决于并行生成多个此类任务的能力，以及这些任务的平均延迟。吞吐量应在负载测试和性能监控期间进行测量，以确定峰值吞吐量和最大持续吞吐量。这些因素有助于系统的规模和性能。
- en: Bandwidth
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Bandwidth（带宽）
- en: '**Bandwidth** is the raw data rate over a communication channel, measured in
    a certain number of bits per second. This includes not only the payload, but also
    all the overhead necessary to carry out the communication. Some examples are:
    Kbits/sec, Mbits/sec, and more. An uppercase B such as KB/sec denotes Bytes, as
    in kilobytes per second. Bandwidth is often compared to throughput. While bandwidth
    is the raw capacity, throughput for the same system is the successful task completion
    rate, which usually involves a round-trip. Note that throughput is for an operation
    that involves latency. To achieve maximum throughput for a given bandwidth, the
    communication/protocol overhead and operational latency should be minimal.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**带宽**是指通信通道上的原始数据速率，以每秒一定数量的比特来衡量。这包括不仅包括有效载荷，还包括执行通信所需的所有开销。一些例子包括：Kbits/sec，Mbits/sec，等等。大写B，如KB/sec表示字节，即每秒千字节。带宽通常与吞吐量进行比较。虽然带宽是原始容量，但对于同一系统，吞吐量是成功任务完成率，这通常涉及往返。请注意，吞吐量是指涉及延迟的操作。为了在给定的带宽下实现最大吞吐量，通信/协议开销和操作延迟应尽可能小。'
- en: For storage systems (such as hard disks, solid-state drives, and more) the predominant
    way to measure performance is **IOPS** (**Input-output per second**), which is
    multiplied by the transfer size and represented as bytes per second, or further
    into MB/sec, GB/sec, and more. IOPS is usually derived for sequential and random
    workloads for read/write operations.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 对于存储系统（如硬盘、固态硬盘等），衡量性能的主要方式是**IOPS**（每秒输入输出），它是通过传输大小乘以的，表示为每秒字节数，或者进一步表示为MB/sec，GB/sec等等。IOPS通常用于顺序和随机工作负载的读写操作。
- en: 'Mapping the throughput of a system to the bandwidth of another may lead to
    dealing with an impedance mismatch between the two. For example, an order processing
    system may perform the following tasks:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个系统的吞吐量映射到另一个系统的带宽可能会导致处理两个系统之间的阻抗不匹配。例如，一个订单处理系统可能执行以下任务：
- en: Transact with the database on disk
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与磁盘上的数据库进行交易
- en: Post results over the network to an external system
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将结果通过网络发送到外部系统
- en: Depending on the bandwidth of the disk sub-system, the bandwidth of the network,
    and the execution model of order processing, the throughput may depend not only
    on the bandwidth of the disk sub-system and network, but also on how loaded they
    currently are. Parallelism and pipelining are common ways to increase the throughput
    over a given bandwidth.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 根据磁盘子系统的带宽、网络的带宽以及订单处理的执行模型，吞吐量可能不仅取决于磁盘子系统和网络的带宽，还取决于它们当前的负载情况。并行性和流水线是增加给定带宽吞吐量的常见方法。
- en: Baseline and benchmark
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基准和基准测试
- en: The performance **baseline**, or simply baseline, is the reference point, including
    measurements of well-characterized and understood performance parameters for a
    known configuration. The baseline is used to collect performance measurements
    for the same parameters that we may benchmark later for another configuration.
    For example, collecting "throughput distribution over 10 minutes at a load of
    50 concurrent threads" is one such performance parameter that we can use for baseline
    and benchmarking. A baseline is recorded together with the hardware, network,
    OS and JVM configuration.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能基准**，或简称为基准，是参考点，包括对已知配置中良好定义和理解的性能参数的测量。基准用于收集我们可能稍后为另一个配置基准测试的相同参数的性能测量。例如，收集“在50个并发线程负载下10分钟内的吞吐量分布”是我们可以使用作基准和基准测试的这样一个性能参数。基准与硬件、网络、操作系统和JVM配置一起记录。'
- en: The performance **benchmark**, or simply benchmark, is the recording of the
    performance parameter measurements under various test conditions. A benchmark
    can be composed of a performance test suite. A benchmark may collect small to
    large amounts of data, and may take varying durations depending on the use-cases,
    scenarios, and environment characteristics.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能基准测试**，或简称为基准测试，是在各种测试条件下记录性能参数测量的过程。基准测试可以由性能测试套件组成。基准测试可能收集从小到大的数据量，并且可能根据用例、场景和环境特性而持续不同的时间。'
- en: A baseline is a result of the benchmark that was conducted at one point in time.
    However, a benchmark is independent of the baseline.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 基准是某个时间点进行的基准测试的结果。然而，基准与基准无关。
- en: Profiling
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能分析
- en: '**Performance** **profiling** , or simply profiling, is the analysis of the
    execution of a program at its runtime. A program can perform poorly for a variety
    of reasons. A **profiler** can analyze and find out the execution time of various
    parts of the program. It is possible to put statements in a program manually to
    print the execution time of the blocks of code, but it gets very cumbersome as
    you try to refine the code iteratively.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能分析**，或简称为分析，是对程序在运行时执行的分析。程序可能由于各种原因表现不佳。分析器可以分析和找出程序各部分的执行时间。可以在程序中手动放置语句以打印代码块的执行时间，但随着您尝试迭代地改进代码，这会变得非常繁琐。'
- en: A profiler is of great assistance to the developer. Going by how profilers work,
    there are three major kinds—instrumenting, sampling, and event-based.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 分析器对开发者非常有帮助。根据分析器的工作原理，主要有三种类型——仪器化、采样和基于事件的。
- en: '**Event-based profilers**: These profilers work only for selected language
    platforms, and provide a good balance between the overhead and results; Java supports
    event-based profiling via the JVMTI interface.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于事件的性能分析器**：这些分析器仅适用于选定的语言平台，并在开销和结果之间提供良好的平衡；Java通过JVMTI接口支持基于事件的性能分析。'
- en: '**The instrumenting profilers**: These profilers modify code at either compile
    time, or runtime to inject performance counters. They are intrusive by nature
    and add significant performance overhead. However, you can profile the regions
    of code very selectively using the instrumenting profilers.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仪器化分析器**：这些分析器在编译时或运行时修改代码以注入性能计数器。它们本质上是侵入性的，并增加了显著的性能开销。然而，您可以使用仪器化分析器非常选择性地分析代码区域。'
- en: '**The sampling profilers**: These profilers pause the runtime and collect its
    state at "sampling intervals". By collecting enough samples, they get to know
    where the program is spending most of its time. For example, at a sampling interval
    of 1 millisecond, the profiler would have collected 1000 samples in a second.
    A sampling profiler also works for code that executes faster than the sampling
    interval (as in, the code may perform several iterations of work between the two
    sampling events), as the frequency of pausing and sampling is proportional to
    the overall execution time of any code.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**采样分析器**：这些分析器在“采样间隔”暂停运行时并收集其状态。通过收集足够的样本，它们可以了解程序大部分时间花在了哪里。例如，在1毫秒的采样间隔下，分析器在一秒钟内会收集1000个样本。采样分析器也适用于执行速度超过采样间隔的代码（即，代码可能在两次采样事件之间执行几个工作迭代），因为暂停和采样的频率与任何代码的整体执行时间成比例。'
- en: Profiling is not meant only for measuring execution time. Capable profilers
    can provide a view of memory analysis, garbage collection, threads, and more.
    A combination of such tools is helpful to find memory leaks, garbage collection
    issues, and so on.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 分析的目的不仅仅是测量执行时间。有能力的分析器可以提供内存分析、垃圾回收、线程等方面的视图。这些工具的组合有助于找到内存泄漏、垃圾回收问题等。
- en: Performance optimization
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能优化
- en: Simply put, **optimization** is enhancing a program's resource consumption after
    a performance analysis. The symptoms of a poorly performing program are observed
    in terms of high latency, low throughput, unresponsiveness, instability, high
    memory consumption, high CPU consumption, and more. During the performance analysis,
    one may profile the program in order to identify the bottlenecks and tune the
    performance incrementally by observing the performance parameters.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，**优化**是在性能分析之后增强程序资源消耗的过程。性能不佳的程序的症状可以从高延迟、低吞吐量、无响应、不稳定、高内存消耗、高CPU消耗等方面观察到。在性能分析期间，一个人可以对程序进行性能分析，以确定瓶颈并通过观察性能参数逐步调整性能。
- en: Better and suitable algorithms are an all-around good way to optimize code.
    The CPU bound code can be optimized with computationally cheaper operations. The
    cache bound code can try using less memory lookups to keep a good hit ratio. The
    memory bound code can use an adaptive memory usage and conservative data representation
    to store in memory for optimization. The I/O bound code can attempt to serialize
    as little data as possible, and batching of operations will make the operation
    less chatty for better performance. Parallelism and distribution are other, overall
    good ways to increase performance.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 更好和合适的算法是优化代码的全方面好方法。CPU密集型代码可以通过计算成本更低的操作进行优化。缓存密集型代码可以尝试使用更少的内存查找来保持良好的命中率。内存密集型代码可以使用自适应内存使用和保守的数据表示来存储在内存中，以进行优化。I/O密集型代码可以尝试尽可能少地序列化数据，并且操作批处理将使操作更少地聊天，从而提高性能。并行性和分布式是其他，整体上好的提高性能的方法。
- en: Concurrency and parallelism
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发与并行性
- en: Most of the computer hardware and operating systems that we use today provide
    concurrency. On the x86 architecture, hardware support for concurrency can be
    traced as far back as the 80286 chip. **Concurrency** is the simultaneous execution
    of more than one process on the same computer. In older processors, concurrency
    was implemented using the context switch by the operating system kernel. When
    concurrent parts are executed in parallel by the hardware instead of merely the
    switching context, it is called **parallelism**. Parallelism is the property of
    the hardware, though the software stack must support it in order for you to leverage
    it in your programs. We must write your program in a concurrent way to exploit
    the parallelism features of the hardware.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们今天使用的绝大多数计算机硬件和操作系统都提供了并发性。在x86架构中，对并发的硬件支持可以追溯到80286芯片。**并发**是指在同一台计算机上同时执行多个进程。在较老的处理器中，并发是通过操作系统内核的上下文切换来实现的。当并发部分由硬件并行执行而不是仅仅切换上下文时，这被称为**并行性**。并行性是硬件的特性，尽管软件堆栈必须支持它，你才能在你的程序中利用它。我们必须以并发的方式编写你的程序，以利用硬件的并行性特性。
- en: While concurrency is a natural way to exploit hardware parallelism and speed
    up operations, it is worth bearing in mind that having significantly higher concurrency
    than the parallelism that your hardware can support is likely to schedule tasks
    to varying processor cores thereby, lowering the branch prediction and increasing
    cache misses.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然并发是利用硬件并行性和加快操作的自然方式，但值得记住的是，如果并发显著高于硬件支持的并行度，可能会将任务调度到不同的处理器核心，从而降低分支预测并增加缓存未命中。
- en: At a low level, spawning the processes/threads, mutexes, semaphores, locking,
    shared memory, and interprocess communication are used for concurrency. The JVM
    has an excellent support for these concurrency primitives and interthread communication.
    Clojure has both—the low and higher level concurrency primitives that we will
    discuss in the concurrency chapter.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在较低级别，使用进程/线程、互斥锁、信号量、锁定、共享内存和进程间通信来实现并发。JVM对这些并发原语和线程间通信有出色的支持。Clojure既有低级也有高级并发原语，我们将在并发章节中讨论。
- en: Resource utilization
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源利用率
- en: R**esource utilization** is the measure of the server, network, and storage
    resources that is consumed by an application. Resources include CPU, memory, disk
    I/O, network I/O, and more. The application can be analyzed in terms of CPU bound,
    memory bound, cache bound, and I/O bound tasks. Resource utilization can be derived
    by means of benchmarking, by measuring the utilization at a given throughput.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源利用率**是指应用程序消耗的服务器、网络和存储资源。资源包括CPU、内存、磁盘I/O、网络I/O等。可以从CPU密集型、内存密集型、缓存密集型和I/O密集型任务的角度分析应用程序。资源利用率可以通过基准测试和测量特定吞吐量下的利用率来得出。'
- en: Workload
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作负载
- en: '**Workload** is the quantification of how much work is there in hand to be
    carried out by the application. It is measured in the total numbers of users,
    the concurrent active users, the transaction volume, the data volume, and more.
    Processing a workload should take in to account the load conditions, such as how
    much data the database currently holds, how filled up the message queues are,
    the backlog of I/O tasks after which the new load will be processed, and more.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**工作负载**是指应用程序需要完成的工作量量化。它包括总用户数、并发活跃用户数、交易量、数据量等。处理工作负载时应考虑负载条件，例如数据库当前持有的数据量、消息队列的填充程度、I/O任务的积压情况以及更多。'
- en: The latency numbers that every programmer should know
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 每个程序员都应该知道的延迟数字
- en: 'Hardware and software have progressed over the years. Latencies for various
    operations put things in perspective. The latency numbers for the year 2015, reproduced
    with the permission of Aurojit Panda and Colin Scott of Berkeley University ([http://www.eecs.berkeley.edu/~rcs/research/interactive_latency.html](http://www.eecs.berkeley.edu/~rcs/research/interactive_latency.html)).
    Latency numbers that every programmer should know are as shown in the following
    table:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，硬件和软件都取得了进步。各种操作的延迟使事情变得有对比性。以下表格展示了2015年的延迟数字，经加州大学伯克利分校的Aurojit Panda和Colin
    Scott许可复制([http://www.eecs.berkeley.edu/~rcs/research/interactive_latency.html](http://www.eecs.berkeley.edu/~rcs/research/interactive_latency.html))。每个程序员都应该知道的延迟数字如下所示：
- en: '| Operation | Time taken as of 2015 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | 2015年所需时间 |'
- en: '| --- | --- |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| L1 cache reference | 1ns (nano second) |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| L1缓存引用 | 1ns (纳秒) |'
- en: '| Branch mispredict | 3 ns |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 分支预测错误 | 3 ns |'
- en: '| L2 cache reference | 4 ns |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| L2缓存引用 | 4 ns |'
- en: '| Mutex lock/unlock | 17 ns |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 互斥锁锁定/解锁 | 17 ns |'
- en: '| Compress 1KB with Zippy(Zippy/Snappy: [http://code.google.com/p/snappy/](http://code.google.com/p/snappy/))
    | 2μs (1000 ns = 1μs: micro second) |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 使用Zippy(Zippy/Snappy: [http://code.google.com/p/snappy/](http://code.google.com/p/snappy/))压缩1KB
    | 2μs (1000 ns = 1μs: 微秒) |'
- en: '| Send 2000 bytes over the commodity network | 200ns (that is, 0.2μs) |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 在商品网络上发送2000字节 | 200ns（即0.2μs）|'
- en: '| SSD random read | 16 μs |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| SSD随机读取 | 16 μs |'
- en: '| Round-trip in the same datacenter | 500 μs |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 同一数据中心内的往返 | 500 μs |'
- en: '| Read 1,000,000 bytes sequentially from SSD | 200 μs |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 从SSD顺序读取1,000,000字节 | 200 μs |'
- en: '| Disk seek | 4 ms (1000 μs = 1 ms) |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 磁盘寻道 | 4 ms (1000 μs = 1 ms) |'
- en: '| Read 1,000,000 bytes sequentially from disk | 2 ms |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 从磁盘顺序读取1,000,000字节 | 2 ms |'
- en: '| Packet roundtrip CA to Netherlands | 150 ms |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 数据包往返CA到荷兰 | 150 ms |'
- en: The preceding table shows the operations in a computer vis-a-vis the latency
    incurred due to the operation. When a CPU core processes some data in a CPU register,
    it may take a few CPU cycles (for reference, a 3 GHz CPU runs 3000 cycles per
    nanosecond), but the moment it has to fall back on L1 or L2 cache, the latency
    becomes thousands of times slower. The preceding table does not show main memory
    access latency, which is roughly 100 ns (it varies, based on the access pattern)—about
    25 times slower than the L2 cache.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的表格显示了计算机中的操作及其因操作而产生的延迟。当CPU核心在CPU寄存器中处理一些数据时，它可能需要几个CPU周期（以3 GHz CPU为例，每纳秒运行3000个周期），但一旦它必须回退到L1或L2缓存，延迟就会慢数千倍。前面的表格没有显示主内存访问延迟，大约为100纳秒（根据访问模式而变化）——大约是L2缓存的25倍。
- en: Summary
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: We learned about the basics of what it is like to think more deeply about performance.
    We saw the common performance vocabulary, and also the use cases by which performance
    aspects might vary. We concluded by looking at the performance numbers for the
    different hardware components, which is how performance benefits reach our applications.
    In the next chapter, we will dive into the performance aspects of the various
    Clojure abstractions.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了深入思考性能的基础知识。我们了解了常见的性能词汇，以及性能方面可能变化的用例。通过查看不同硬件组件的性能数据，我们得出了性能优势如何达到应用中的结论。在下一章中，我们将深入探讨各种Clojure抽象的性能方面。
- en: Chapter 2. Clojure Abstractions
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章 Clojure 抽象
- en: Clojure has four founding ideas. Firstly, it was set up to be a functional language.
    It is not pure (as in purely functional), but emphasizes immutability. Secondly,
    it is a dialect of Lisp; Clojure is malleable enough that users can extend the
    language without waiting for the language implementers to add new features and
    constructs. Thirdly, it was built to leverage concurrency for the new generation
    challenges. Lastly, it was designed to be a hosted language. As of today, Clojure
    implementations exist for the JVM, CLR, JavaScript, Python, Ruby, and Scheme.
    Clojure blends seamlessly with its host language.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure有四个基本理念。首先，它被建立为一个函数式语言。它不是纯函数式（如纯粹函数式），但强调不可变性。其次，它是一种Lisp方言；Clojure足够灵活，用户可以在不等待语言实现者添加新特性和结构的情况下扩展语言。第三，它是为了利用并发来应对新一代挑战而构建的。最后，它被设计为托管语言。截至目前，Clojure的实现存在于JVM、CLR、JavaScript、Python、Ruby和Scheme上。Clojure与宿主语言无缝融合。
- en: 'Clojure is rich in abstractions. Though the syntax itself is very minimal,
    the abstractions are finely grained, mostly composable, and designed to tackle
    a wide variety of concerns in the least complicated way. In this chapter, we will
    discuss the following topics:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure在抽象方面非常丰富。尽管语法本身非常简洁，但抽象是细粒度的，大多数是可组合的，并且旨在以最简单的方式解决广泛的问题。在本章中，我们将讨论以下主题：
- en: Performance characteristics of non-numeric scalars
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非数值标量的性能特性
- en: Immutability and epochal time model paving the way for performance by isolation
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不可变性和纪元时间模型通过隔离铺平了性能的道路
- en: Persistent data structures and their performance characteristics
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持久数据结构和它们的性能特性
- en: Laziness and its impact on performance
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 惰性及其对性能的影响
- en: Transients as a high-performance, short-term escape hatch
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 临时数据结构作为高性能、短期逃生通道
- en: Other abstractions, such as tail recursion, protocols/types, multimethods, and
    many more
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他抽象，如尾递归、协议/类型、多方法等
- en: Non-numeric scalars and interning
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非数值标量和内联
- en: 'Strings and characters in Clojure are the same as in Java. The string literals
    are implicitly interned. Interning is a way of storing only the unique values
    in the heap and sharing the reference everywhere it is required. Depending on
    the JVM vendor and the version of Java you use, the interned data may be stored
    in a string pool, Permgen, ordinary heap, or some special area in the heap marked
    for interned data. Interned data is subject to garbage collection when not in
    use, just like ordinary objects. Take a look at the following code:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure中的字符串和字符与Java中的相同。字符串字面量是隐式内联的。内联是一种只存储唯一值在堆中并在需要的地方共享引用的方法。根据JVM供应商和您使用的Java版本，内联数据可能存储在字符串池、Permgen、普通堆或堆中标记为内联数据特殊区域。当不使用时，内联数据会像普通对象一样受到垃圾回收。请看以下代码：
- en: '[PRE0]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that `identical?` in Clojure is the same as `==` in Java. The benefit of
    interning a string is that there is no memory allocation overhead for duplicate
    strings. Commonly, applications on the JVM spend quite some time on string processing.
    So, it makes sense to have them interned whenever there is a chance of duplicate
    strings being simultaneously processed. Most of the JVM implementations today
    have an extremely fast intern operation; however, you should measure the overhead
    for your JVM if you have an older version.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，Clojure 中的 `identical?` 与 Java 中的 `==` 是相同的。字符串池化的好处是对于重复的字符串没有内存分配的开销。通常，运行在
    JVM 上的应用程序在字符串处理上花费相当多的时间。因此，当有机会同时处理重复字符串时，将它们池化是有意义的。如今，大多数 JVM 实现都有一个非常快的池化操作；然而，如果你使用的是较旧版本，你应该测量
    JVM 的开销。
- en: Another benefit of string interning is that when you know that two string tokens
    are interned, you can compare them faster for equality using `identical?` than
    non-interned string tokens. The equivalence function `=` first checks for identical
    references before conducting a content check.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串池化的另一个好处是，当你知道两个字符串标记被池化时，你可以使用 `identical?` 比较它们以进行相等性检查，比非池化字符串标记更快。等价函数
    `=` 首先检查相同的引用，然后再进行内容检查。
- en: 'Symbols in Clojure always contain interned string references within them, so
    generating a symbol from a given string is nearly as fast as interning a string.
    However, two symbols created from the same string will not be identical:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 中的符号总是包含池化字符串引用，因此从给定字符串生成符号几乎与池化字符串一样快。然而，从同一字符串创建的两个符号不会是相同的：
- en: '[PRE1]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Keywords are, on the basis of their implementation, built on top of symbols
    and are designed to work with the `identical?` function for equivalence. So, comparing
    keywords for equality using `identical?` would be faster, just as with interned
    string tokens.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 关键字基于其实现建立在符号之上，并设计为与 `identical?` 函数一起用于等价性。因此，使用 `identical?` 比较关键字进行相等性检查会更快，就像与池化字符串标记一样。
- en: Clojure is increasingly being used for large-volume data processing, which includes
    text and composite data structures. In many cases, the data is either stored as
    JSON or EDN ([http://edn-format.org](http://edn-format.org)). When processing
    such data, you can save memory by interning strings or using symbols/keywords.
    Remember that string tokens read from such data would not be automatically interned,
    whereas the symbols and keywords read from EDN data would invariably be interned.
    You may come across such situations when dealing with relational or NoSQL databases,
    web services, CSV or XML files, log parsing, and so on.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 越来越多地被用于大量数据处理，这包括文本和复合数据结构。在许多情况下，数据要么以 JSON 或 EDN（[http://edn-format.org](http://edn-format.org)）格式存储。在处理此类数据时，你可以通过池化字符串或使用符号/关键字来节省内存。记住，从此类数据中读取的字符串标记不会自动池化，而从
    EDN 数据中读取的符号和关键字则会不可避免地池化。当你处理关系型数据库或 NoSQL 数据库、Web 服务、CSV 或 XML 文件、日志解析等情况时，可能会遇到这种情况。
- en: Interning is linked to the JVM **Garbage Collection** (**GC**), which, in turn,
    is closely linked to performance. When you do not intern the string data and let
    duplicates exist, they end up being allocated on the heap. More heap usage leads
    to GC overhead. Interning a string has a tiny but measurable and upfront performance
    overhead, whereas GC is often unpredictable and unclear. GC performance, in most
    JVM implementations, has not increased in a similar proportion to the performance
    advances in hardware. So, often, effective performance depends on preventing GC
    from becoming the bottleneck, which in most cases means minimizing it.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 池化与 JVM 的垃圾回收（**GC**）相关联，而垃圾回收又与性能密切相关。当你不池化字符串数据并允许重复存在时，它们最终会在堆上分配。更多的堆使用会导致
    GC 开销。池化字符串有一个微小但可测量且即时的性能开销，而 GC 往往是不可预测且不清晰的。在大多数 JVM 实现中，GC 性能并没有像硬件性能提升那样以相似的比例增长。因此，通常，有效的性能取决于防止
    GC 成为瓶颈，这在大多数情况下意味着最小化它。
- en: Identity, value, and epochal time model
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 身份、值和历法时间模型
- en: One of the principal virtues of Clojure is its simple design that results in
    malleable, beautiful composability. Using symbols in place of pointers is a programming
    practice that has existed for several decades now. It has found widespread adoption
    in several imperative languages. Clojure dissects that notion in order to uncover
    the core concerns that need to be addressed. The following subsections illustrate
    this aspect of Clojure.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure的一个主要优点是其简单的设计，这导致了可塑性和美丽的可组合性。用符号代替指针是一种存在了几十年的编程实践。它已经在几个命令式语言中得到广泛应用。Clojure剖析了这个概念，以揭示需要解决的核心问题。以下小节将说明Clojure的这一方面。
- en: We program using logical entities to represent values. For example, a value
    of `30` means nothing unless it is associated with a logical entity, let's say
    `age`. The logical entity `age` is the identity here. Now, even though `age` represents
    a value, the value may change with time; this brings us to the notion of `state`,
    which represents the value of the identity at a certain time. Hence, `state` is
    a function of time and is causally related to what we do in the program. Clojure's
    power lies in binding an identity with its value that holds true at the time and
    the identity remains isolated from any new value it may represent later. We will
    discuss state management in [Chapter 5](ch12.html "Chapter 5. Concurrency"), *Concurrency*.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用逻辑实体来表示值。例如，`30`这个值如果没有与逻辑实体关联，比如`age`，就没有意义。逻辑实体`age`在这里是身份。现在，尽管`age`代表一个值，但这个值可能会随时间改变；这引出了`状态`的概念，它代表某个时间点的身份值。因此，`状态`是时间的函数，并且与我们在程序中执行的操作有因果关系。Clojure的力量在于将身份与其在特定时间保持为真的值绑定在一起，并且身份与其后来可能代表的任何新值保持隔离。我们将在[第5章](ch12.html
    "第5章。并发") *并发* 中讨论状态管理。
- en: Variables and mutation
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变量和修改
- en: If you have previously worked with an imperative language (C/C++, Java, and
    so on), you may be familiar with the concept of a variable. A **variable** is
    a reference to a block of memory. When we update its value, we essentially update
    the place in memory where the value is stored. The variable continues to point
    to the place where the older version of the value was stored. So, essentially,
    a variable is an alias for the place of storage of values.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你之前使用过命令式语言（C/C++、Java等），你可能熟悉变量的概念。**变量**是对内存块的一个引用。当我们更新其值时，我们实际上是在更新存储值的内存位置。变量继续指向存储旧版本值的那个位置。所以，本质上，变量是存储值位置的别名。
- en: A little analysis would reveal that variables are strongly linked to the processes
    that read or mutate their values. Every mutation is a state transition. The processes
    that read/update the variable should be aware of the possible states of the variable
    to make sense of the state. Can you see a problem here? It conflates identity
    and state! It is impossible to refer to a value or a state in time when dealing
    with a variable—the value could change at any time unless you have complete control
    over the process accessing it. The mutability model does not accommodate the concept
    of time that causes its state transition.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一点分析就能揭示变量与读取或修改其值的进程之间有着强烈的联系。每一次修改都是一个状态转换。读取/更新变量的进程应该了解变量的可能状态，以便理解该状态。你在这里看到问题了吗？它混淆了身份和状态！在处理变量时，在时间上引用一个值或状态是不可能的——除非你完全控制访问它的进程，否则值可能会随时改变。可变模型无法容纳导致其状态转换的时间概念。
- en: The issues with mutability do not stop here. When you have a composite data
    structure containing mutable variables, the entire data structure becomes mutable.
    How can we mutate it without potentially undermining the other processes that
    might be observing it? How can we share this data structure with concurrent processes?
    How can we use this data structure as a key in a hash-map? This data structure
    does not convey anything. Its meaning could change with mutation! How do we send
    such a thing to another process without also compensating for the time, which
    can mutate it in different ways?
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 可变性的问题并不止于此。当你有一个包含可变变量的复合数据结构时，整个数据结构就变得可变了。我们如何在不破坏可能正在观察它的其他进程的情况下修改它？我们如何与并发进程共享这个数据结构？我们如何将这个数据结构用作哈希表中的键？这个数据结构什么也没传达。它的意义可能会随着修改而改变！我们如何将这样的事物发送给另一个进程，而不补偿可能以不同方式修改它的时间？
- en: Immutability is an important tenet of functional programming. It not only simplifies
    the programming model, but also paves the way for safety and concurrency. Clojure
    supports immutability throughout the language. Clojure also supports fast, mutation-oriented
    data structures as well as thread-safe state management via concurrency primitives.
    We will discuss these topics in the forthcoming sections and chapters.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 不可变性是函数式编程的一个重要原则。它不仅简化了编程模型，而且为安全和并发铺平了道路。Clojure 在整个语言中支持不可变性。Clojure 还支持通过并发原语实现快速、面向变动的数据结构以及线程安全的状态管理。我们将在接下来的章节中讨论这些主题。
- en: Collection types
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集合类型
- en: 'There are a few types of collections in Clojure, which are categorized based
    on their properties. The following Venn diagram depicts this categorization on
    the basis of whether the collections are counted (so that `counted?` returns `true`)
    or associative (so that `associative?` returns `true`) or sequential (so that
    `sequential?` returns `true`):'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 中有一些集合类型，它们根据其属性进行分类。以下维恩图根据集合是否计数（`counted?` 返回 `true`）、是否关联（`associative?`
    返回 `true`）或是否顺序（`sequential?` 返回 `true`）来描述这种分类：
- en: '![Collection types](img/B04596_02_01.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![集合类型](img/B04596_02_01.jpg)'
- en: The previous diagram illustrates the characteristics that different kinds of
    data structures share. The sequential structures let us iterate over the items
    in the collection, the item count of counted structures can be found constant
    with respect to time, and associative structures can be looked at with keys for
    corresponding values. The **CharSequence** box shows the character sequence Java
    types that can be converted to a Clojure sequence using (`seq charseq`).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的图示展示了不同类型的数据结构所共有的特性。顺序结构允许我们对集合中的项目进行迭代，计数结构的项数可以随时间保持恒定，而关联结构可以通过键来查找相应的值。**CharSequence**
    框展示了可以转换为 Clojure 序列的 Java 字符序列类型（使用 `seq charseq`）。
- en: Persistent data structures
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持久数据结构
- en: As we've noticed in the previous section, Clojure's data structures are not
    only immutable, but can produce new values without impacting the old version.
    Operations produce these new values in such a way that old values remain accessible;
    the new version is produced in compliance with the complexity guarantees of that
    data structure, and both the old and new versions continue to meet the complexity
    guarantees. The operations can be recursively applied and can still meet the complexity
    guarantees. Such immutable data structures as the ones provided by Clojure are
    called **persistent data structures**. They are "persistent", as in, when a new
    version is created, both the old and new versions "persist" in terms of both the
    value and complexity guarantee. They have nothing to do with storage or durability
    of data. Making changes to the old version doesn't impede working with the new
    version and vice versa. Both versions persist in a similar way.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一节中注意到的，Clojure 的数据结构不仅不可变，而且可以在不影响旧版本的情况下产生新值。操作以这种方式产生新值，使得旧值仍然可访问；新版本的产生符合该数据结构的复杂度保证，并且旧版本和新版本都继续满足复杂度保证。这些操作可以递归地应用，并且仍然可以满足复杂度保证。Clojure
    提供的这种不可变数据结构被称为 **持久数据结构**。它们是“持久”的，即当创建新版本时，旧版本和新版本在值和复杂度保证方面都“持续”存在。这与数据的存储或持久性无关。对旧版本的更改不会妨碍与新版本一起工作，反之亦然。两个版本都以类似的方式持续存在。
- en: Among the publications that have inspired the implementation of Clojure's persistent
    data structures, two of them are well known. Chris Okasaki's *Purely Functional
    Data Structures* has influenced the implementation of persistent data structures
    and lazy sequences/operations. Clojure's persistent queue implementation is adapted
    from Okasaki's *Batched Queues*. Phil Bagwell's *Ideal Hash Tries*, though meant
    for mutable and imperative data structures, was adapted to implement Clojure's
    persistent map/vector/set.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在启发 Clojure 持久数据结构实现的出版物中，其中两种是众所周知的。Chris Okasaki 的 *Purely Functional Data
    Structures* 对持久数据结构和惰性序列/操作的实施产生了影响。Clojure 的持久队列实现是从 Okasaki 的 *Batched Queues*
    中改编的。Phil Bagwell 的 *Ideal Hash Tries*，尽管是为可变和命令式数据结构设计的，但被改编用于实现 Clojure 的持久映射/向量/集合。
- en: Constructing lesser-used data structures
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建较少使用的数据结构
- en: 'Clojure supports a well-known literal syntax for lists, vectors, sets, and
    maps. Shown in the following list are some less-used methods for creating other
    data structures:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure支持列表、向量、集合和映射的知名字面语法。以下列表展示了创建其他数据结构的较少使用的方法：
- en: 'Map (`PersistentArrayMap` and `PersistentHashMap`):'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '映射 (`PersistentArrayMap` 和 `PersistentHashMap`):'
- en: '[PRE2]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Sorted map (`PersistentTreeMap`):'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '排序映射 (`PersistentTreeMap`):'
- en: '[PRE3]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Sorted set (`PersistentTreeSet`):'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '排序集合 (`PersistentTreeSet`):'
- en: '[PRE4]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Queue (`PersistentQueue`):'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '队列 (`PersistentQueue`):'
- en: '[PRE5]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As you can see, abstractions such as `TreeMap` (sorted by key), `TreeSet` (sorted
    by element), and `Queue` should be instantiated by calling their respective APIs.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，诸如 `TreeMap`（按键排序）、`TreeSet`（按元素排序）和 `Queue` 这样的抽象应该通过调用它们各自的API来实例化。
- en: Complexity guarantee
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 复杂度保证
- en: 'The following table gives a summary of the complexity guarantees (using the
    Big-O notation) of various kinds of persistent data structures in Clojure:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格给出了Clojure中各种持久数据结构复杂度保证（使用大O符号）的摘要：
- en: '| Operation | PersistentList | PersistentHashMap | PersistentArrayMap | PersistentVector
    | PersistentQueue | PersistentTreeMap |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | 持久列表 | 持久哈希映射 | 持久数组映射 | 持久向量 | 持久队列 | 持久树映射 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| `count` | O(1) | O(1) | O(1) | O(1) | O(1) | O(1) |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| `count` | O(1) | O(1) | O(1) | O(1) | O(1) | O(1) |'
- en: '| `conj` | O(1) |   |   | O(1) | O(1) |   |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| `conj` | O(1) |   |   | O(1) | O(1) |   |'
- en: '| `first` | O(1) |   |   | O(<7) | O(<7) |   |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| `first` | O(1) |   |   | O(<7) | O(<7) |   |'
- en: '| `rest` | O(1) |   |   | O(<7) | O(<7) |   |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| `rest` | O(1) |   |   | O(<7) | O(<7) |   |'
- en: '| `doseq` | O(n) | O(n) | O(n) | O(n) | O(n) |   |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| `doseq` | O(n) | O(n) | O(n) | O(n) | O(n) |   |'
- en: '| `nth` | O(n) |   |   | O(<7) | O(<7) |   |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| `nth` | O(n) |   |   | O(<7) | O(<7) |   |'
- en: '| `last` | O(n) |   |   | O(n) | O(n) |   |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| `last` | O(n) |   |   | O(n) | O(n) |   |'
- en: '| `get` |   | O(<7) | O(1) | O(<7) | O(<7) | O(log n) |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| `get` |   | O(<7) | O(1) | O(<7) | O(<7) | O(log n) |'
- en: '| `assoc` |   | O(<7) | O(1) | O(<7) |   | O(log n) |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| `assoc` |   | O(<7) | O(1) | O(<7) |   | O(log n) |'
- en: '| `dissoc` |   | O(<7) | O(1) | O(<7) |   | O(log n) |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| `dissoc` |   | O(<7) | O(1) | O(<7) |   | O(log n) |'
- en: '| `peek` |   |   |   | O(1) | O(1) |   |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| `peek` |   |   |   | O(1) | O(1) |   |'
- en: '| `pop` |   |   |   | O(<7) | O(1) |   |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| `pop` |   |   |   | O(<7) | O(1) |   |'
- en: A **list** is a sequential data structure. It provides constant time access
    for count and for anything regarding the first element only. For example, `conj`
    adds the element to the head and guarantees *O(1)* complexity. Similarly, `first`
    and `rest` provide *O(1)* guarantees too. Everything else provides an *O(n)* complexity
    guarantee.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**列表**是一种顺序数据结构。它为计数和与第一个元素相关的内容提供常数时间访问。例如，`conj` 将元素添加到头部并保证 *O(1)* 复杂度。同样，`first`
    和 `rest` 也提供 *O(1)* 保证。其他所有内容都提供 *O(n)* 复杂度保证。'
- en: Persistent hash-maps and vectors use the trie data structure with a branching
    factor of 32 under the hood. So, even though the complexity is *O(log* *[32]*
    *n)*, only 2^(32) hash codes can fit into the trie nodes. Hence, log[32] 2^(32),
    which turns out to be `6.4` and is less than `7`, is the worst-case complexity
    and can be considered near-constant time. As the trie grows larger, the portion
    to copy gets proportionately tiny due to structure sharing. Persistent hash-set
    implementation is also based on hash-map; hence, the hash-sets share the characteristics
    of the hash-maps. In a persistent vector, the last incomplete node is placed at
    the tail, which is always directly accessible from the root. This makes using
    `conj` to the end a constant time operation.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 持久哈希映射和向量在底层使用32个分支因子的trie数据结构。因此，尽管复杂度是 *O(log* *[32]* *n)*，但只有2^(32)个哈希码可以放入trie节点中。因此，log[32]
    2^(32)，结果是 `6.4` 并且小于 `7`，是最坏情况下的复杂度，可以认为是接近常数时间。随着trie的增长，由于结构共享，要复制的部分成比例地变得很小。持久哈希集实现也是基于哈希映射的；因此，哈希集与哈希映射具有相同的特征。在持久向量中，最后一个不完整的节点放置在尾部，这总是可以从根直接访问。这使得使用
    `conj` 到末尾的操作是常数时间操作。
- en: Persistent tree-maps and tree-sets are basically sorted maps and sets respectively.
    Their implementation uses red-black trees and is generally more expensive than
    hash-maps and hash-sets. A persistent queue uses a persistent vector under the
    hood for adding new elements. Removing an element from a persistent queue takes
    the head off `seq`, which is created from the vector where new elements are added.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 持久性树映射和树集基本上是分别按顺序排列的映射和集合。它们的实现使用红黑树，通常比哈希映射和哈希集更昂贵。持久性队列在底层使用持久性向量来添加新元素。从持久性队列中删除一个元素需要从向量中移除头部
    `seq`，该向量是从添加新元素的位置创建的。
- en: The complexity of an algorithm over a data structure is not an absolute measure
    of its performance. For example, working with hash-maps involves computing the
    hashCode, which is not included in the complexity guarantee. Our choice of data
    structures should be based on the actual use case. For example, when should we
    use a list instead of a vector? Probably when we need sequential or **last-in-first-out**
    (**LIFO**) access, or when constructing an **abstract-syntax-tree** (**AST**)
    for a function call.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 算法在数据结构上的复杂度并不是其性能的绝对度量。例如，使用哈希表涉及计算 hashCode，这并不包括在复杂度保证中。我们应该根据实际用例来选择数据结构。例如，我们应该在什么情况下使用列表而不是向量？可能是在我们需要顺序或
    **后进先出** (**LIFO**) 访问时，或者当为函数调用构造 **抽象语法树** (**AST**) 时。
- en: O(<7) implies near constant time
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: O(<7) 表示接近常数时间
- en: You may know that the **Big-O** notation is used to express the upper bound
    (worst case) of the efficiency of any algorithm. The variable *n* is used to express
    the number of elements in the algorithm. For example, a binary search on a sorted
    associative collection, such as a sorted vector, is a logarithmic time, that is
    an *O(log* *[2]* *n)* or simply an *O(log n)* algorithm. Since there can be a
    maximum of 2^(32) (technically 2^(31) due to a signed positive integer) elements
    in a Java collection and log[2] 2^(32) is 32, the binary search can be *O(≤32)*
    in the worst case. Similarly, though operations on persistent collections are
    O(log[32] n), in the worst case they actually turn out to be O(log[32] 2^(32))
    at maximum, which is *O(<7)*. Note that this is much lower than logarithmic time
    and approaches near constant time. This implies not so bad performance for persistent
    collections even in the worst possible scenario.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能知道，**大O** 表示法用于表达任何算法效率的上限（最坏情况）。变量 *n* 用于表示算法中的元素数量。例如，在一个排序的关联集合上的二分搜索，如排序向量，是对数时间，即
    *O(log* *[2]* *n*) 或简单地 *O(log n*) 算法。由于 Java 集合中最多可以有 2^(32)（技术上由于有符号正整数，为 2^(31)）个元素，且
    log[2] 2^(32) 是 32，因此二分搜索在最坏情况下可以是 *O(≤32)*。同样，尽管持久集合的操作是 O(log[32] n)，但在最坏情况下实际上最多是
    O(log[32] 2^(32))，即 *O(<7)*。请注意，这比对数时间低得多，接近常数时间。这意味着即使在最坏的情况下，持久集合的性能也不是很糟糕。
- en: The concatenation of persistent data structures
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 持久数据结构的连接
- en: 'While persistent data structures have excellent performance characteristics,
    the concatenation of two persistent data structures has been a linear time *O(N)*
    operation, except for some recent developments. The `concat` function, as of Clojure
    1.7, still provides linear time concatenation. Experimental work on **Relaxed
    Radix Balanced** (**RRB**) trees is going on in the **core.rrb-vector** contrib
    project ([https://github.com/clojure/core.rrb-vector](https://github.com/clojure/core.rrb-vector)),
    which may provide logarithmic time *O(log N)* concatenation. Readers interested
    in the details should refer to the following links:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管持久数据结构具有出色的性能特性，但两个持久数据结构的连接一直是一个线性时间 *O(N)* 操作，除了最近的一些发展。截至 Clojure 1.7，`concat`
    函数仍然提供线性时间连接。在 **core.rrb-vector** 贡献项目中正在进行对 **Relaxed Radix Balanced** (**RRB**)
    树的实验工作 ([https://github.com/clojure/core.rrb-vector](https://github.com/clojure/core.rrb-vector))，这可能提供对数时间
    *O(log N)* 连接。对细节感兴趣的读者应参考以下链接：
- en: The RRB-trees paper at [http://infoscience.epfl.ch/record/169879/files/RMTrees.pdf](http://infoscience.epfl.ch/record/169879/files/RMTrees.pdf)
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RRB-trees 论文在 [http://infoscience.epfl.ch/record/169879/files/RMTrees.pdf](http://infoscience.epfl.ch/record/169879/files/RMTrees.pdf)
- en: Phil Bagwell's talk at [http://www.youtube.com/watch?v=K2NYwP90bNs](http://www.youtube.com/watch?v=K2NYwP90bNs)
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Phil Bagwell 的演讲在 [http://www.youtube.com/watch?v=K2NYwP90bNs](http://www.youtube.com/watch?v=K2NYwP90bNs)
- en: Tiark Rompf's talk at [http://skillsmatter.com/podcast/scala/fast-concatenation-immutable-vectors](http://skillsmatter.com/podcast/scala/fast-concatenation-immutable-vectors)
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tiark Rompf 在 [http://skillsmatter.com/podcast/scala/fast-concatenation-immutable-vectors](http://skillsmatter.com/podcast/scala/fast-concatenation-immutable-vectors)
    的演讲
- en: Sequences and laziness
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序列和惰性
- en: '|   | *"A seq is like a logical cursor."* |   |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '|   | *"一个序列就像一个逻辑游标。" |   |'
- en: '|   | --*Rich Hickey* |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '|   | --*Rich Hickey* |'
- en: '**Sequences** (commonly known as **seqs**) are a way to sequentially consume
    a succession of data. As with iterators, they let a user begin consuming elements
    from the head and proceed realizing one element after another. However, unlike
    iterators, sequences are immutable. Also, since sequences are only a view of the
    underlying data, they do not modify the storage structure of the data.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**序列**（通常称为**seqs**）是按顺序消费一系列数据的一种方式。与迭代器类似，它们允许用户从头部开始消费元素，并逐个实现一个元素。然而，与迭代器不同，序列是不可变的。此外，由于序列只是底层数据的视图，它们不会修改数据的存储结构。'
- en: What makes sequences stand apart is they are not data structures per se; rather,
    they are a data abstraction over a stream of data. The data may be produced by
    an algorithm or a data source connected to an I/O operation. For example, the
    `resultset-seq` function accepts a `java.sql.ResultSet` JDBC instance as an argument
    and produces lazily realized rows of data as `seq`.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 使序列与众不同的地方在于，它们本身不是数据结构；相反，它们是对数据流的数据抽象。数据可能由算法或与I/O操作连接的数据源产生。例如，`resultset-seq`函数接受一个`java.sql.ResultSet`
    JDBC实例作为参数，并以`seq`的形式产生惰性实现的数据行。
- en: Clojure data structures can be turned into sequences using the `seq` function.
    For example, (`seq [:a :b :c :d]`) returns a sequence. Calling `seq` over an empty
    collection returns nil.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure数据结构可以通过`seq`函数转换为序列。例如，（`seq [:a :b :c :d]`）返回一个序列。对空集合调用`seq`返回nil。
- en: 'Sequences can be consumed by the following functions:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 序列可以通过以下函数进行消费：
- en: '`first`: This returns the head of the sequence'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`first`：这个函数返回序列的头部。'
- en: '`rest`: This returns the remaining sequence, even if it''s empty, after removing
    the head'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rest`：这个函数返回移除头部后的剩余序列，即使它是空的。'
- en: '`next`: This returns the remaining sequence or nil, if it''s empty, after removing
    the head'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`next`：这个函数返回移除头部后的剩余序列或空，如果它是空的。'
- en: Laziness
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 惰性
- en: Clojure is a strict (as in, the opposite of "lazy") language, which can choose
    to explicitly make use of laziness when required. Anybody can create a lazily
    evaluated sequence using the `lazy-seq` macro. Some Clojure operations over collections,
    such as `map`, `filter`, and more are intentionally lazy.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure是一种严格的（即“惰性”的对立面）语言，可以在需要时显式地利用惰性。任何人都可以使用`lazy-seq`宏创建一个惰性评估的序列。一些Clojure对集合的操作，如`map`、`filter`等，都是有意为之的惰性操作。
- en: '**Laziness** simply means that the value is not computed until actually required.
    Once the value is computed, it is cached so that any future reference to the value
    need not re-compute it. The caching of the value is called **memoization**. Laziness
    and memoization often go hand in hand.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '**惰性**简单地说，就是值在真正需要时才计算。一旦值被计算，它就会被缓存，以便任何未来的值引用都不需要重新计算。值的缓存称为**记忆化**。惰性和记忆化常常是相辅相成的。'
- en: Laziness in data structure operations
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据结构操作中的惰性
- en: 'Laziness and memoization together form an extremely useful combination to keep
    the single-threaded performance of functional algorithms comparable to its imperative
    counterparts. For an example, consider the following Java code:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 惰性和记忆化结合使用，可以形成一个极其有用的组合，以保持函数式算法的单线程性能与其命令式对应物相当。例如，考虑以下Java代码：
- en: '[PRE6]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As is clear from the preceding snippet, it has a linear time complexity, that
    is, *O(n)*, and the whole operation is performed in a single pass. The comparable
    Clojure code is as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码片段中可以看出，它具有线性时间复杂度，即*O(n)*，整个操作都在单次遍历中完成。与之相当的Clojure代码如下：
- en: '[PRE7]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now, since we know `map` and `filter` are lazy, we can deduce that the Clojure
    version also has linear time complexity, that is, *O(n)*, and finishes the task
    in one pass with no significant memory overhead. Imagine, for a moment, that `map`
    and `filter` are not lazy—what would be the complexity then? How many passes would
    it make? It's not just that map and filter would both have taken one pass, that
    is, *O(n)*, each; they would each have taken as much memory as the original collection
    in the worst case, due to storing the intermediate results.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，既然我们知道`map`和`filter`是惰性的，我们可以推断Clojure版本也具有线性时间复杂度，即*O(n)*，并且在一个遍历中完成任务，没有显著的内存开销。想象一下，如果`map`和`filter`不是惰性的，那么复杂度会是什么？需要多少次遍历？不仅仅是map和filter各自都只进行了一次遍历，即*O(n)*，每个；在最坏的情况下，它们各自会占用与原始集合一样多的内存，因为需要存储中间结果。
- en: It is important to know the value of laziness and memoization in an immutability-emphasizing
    functional language such as Clojure. They form a basis for **amortization** in
    persistent data structures, which is about focusing on the overall performance
    of a composite operation instead of microanalyzing the performance of each operation
    in it; the operations are tuned to perform faster in those operations that matter
    the most.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在强调不可变性的函数式语言Clojure中，了解惰性和缓存的重要性非常重要。它们是持久数据结构中**摊销**的基础，这涉及到关注复合操作的整体性能，而不是微观分析其中每个操作的性能；操作被调整以在最重要的操作中更快地执行。
- en: Another important bit of detail is that when a lazy sequence is realized, the
    data is memoized and stored. On the JVM, all the heap references that are reachable
    in some way are not garbage collected. So, as a consequence, the entire data structure
    is kept in the memory unless you lose the head of the sequence. When working with
    lazy sequences using local bindings, make sure you don't keep referring to the
    lazy sequence from any of the locals. When writing functions that may accept lazy
    sequence(s), take care that any reference to the lazy `seq` does not outlive the
    execution of the function in the form of a closure or some such.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的细节是，当惰性序列被实现时，数据会被缓存并存储。在JVM上，所有以某种方式可达的堆引用都不会被垃圾回收。因此，结果就是，整个数据结构除非你丢失序列的头部，否则会一直保留在内存中。当使用局部绑定处理惰性序列时，确保你不会从任何局部变量中持续引用惰性序列。当编写可能接受惰性序列（s）的函数时，注意任何对惰性`seq`的引用都不应该超出函数执行的寿命，无论是以闭包或其他形式。
- en: Constructing lazy sequences
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建惰性序列
- en: 'Now that we know what lazy sequences are, let''s try to create a retry counter
    that should return true only as many times as the retry can be performed. This
    is shown in the following code:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了惰性序列是什么，让我们尝试创建一个重试计数器，它应该只返回重试可以执行次数的次数。这在上面的代码中有所展示：
- en: '[PRE8]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `lazy-seq` macro makes sure that the stack is not used for recursion. We
    can see that this function would return endless values. Hence, in order to inspect
    what it returns, we should limit the number of elements as shown in the following
    code:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '`lazy-seq`宏确保栈不被用于递归。我们可以看到这个函数会返回无限值。因此，为了检查它返回的内容，我们应该限制元素的数量，如下面的代码所示：'
- en: '[PRE9]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, let''s try using it in a mock fashion:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试以模拟的方式使用它：
- en: '[PRE10]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'As expected, the output should print `Retrying` five times before printing
    `No more retries` and exiting as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期，输出应该打印`Retrying`五次，然后打印`No more retries`并退出，如下所示：
- en: '[PRE11]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s take another simpler example of constructing a lazy sequence, which
    gives us a countdown from a specified number to zero:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再举一个更简单的例子来构建一个惰性序列，它从指定的数字倒数到零：
- en: '[PRE12]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can inspect the values it returns as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以如下检查它返回的值：
- en: '[PRE13]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Lazy sequences can loop indefinitely without exhausting the stack and can come
    in handy when working with other lazy operations. To maintain a balance between
    space-saving and performance, consuming lazy sequences results in the chunking
    of elements by a factor of 32\. That means lazy seqs are realized in a chunk-size
    of 32, even though they are consumed sequentially.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 惰性序列可以无限循环而不会耗尽栈，当与其他惰性操作一起工作时可能会很有用。为了在节省空间和性能之间保持平衡，消费惰性序列会导致元素以32的倍数分块。这意味着即使它们是顺序消费的，惰性序列也是以32的块大小实现的。
- en: Custom chunking
  id: totrans-206
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自定义分块
- en: 'The default chunk size 32 may not be optimum for all lazy sequences—you can
    override the chunking behavior when you need to. Consider the following snippet
    (adapted from Kevin Downey''s public gist at [https://gist.github.com/hiredman/324145](https://gist.github.com/hiredman/324145)):'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的块大小32可能不是所有惰性序列的最佳选择——当你需要时可以覆盖分块行为。考虑以下片段（改编自Kevin Downey在[https://gist.github.com/hiredman/324145](https://gist.github.com/hiredman/324145)的公开gist）：
- en: '[PRE14]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'As per the previous snippet, the user is allowed to pass a chunk size that
    is used to produce the lazy sequence. A larger chunk size may be useful when processing
    large text files, such as when processing CSV or log files. You would notice the
    following four less-known functions used in the snippet:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的片段，用户可以传递一个块大小，该大小用于生成惰性序列。较大的块大小在处理大型文本文件时可能很有用，例如在处理CSV或日志文件时。你会在片段中注意到以下四个不太为人所知的函数：
- en: '`clojure.core/chunk-cons`'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clojure.core/chunk-cons`'
- en: '`clojure.core/chunk-buffer`'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clojure.core/chunk-buffer`'
- en: '`clojure.core/chunk-append`'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clojure.core/chunk-append`'
- en: '`clojure.core/chunk`'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clojure.core/chunk`'
- en: While `chunk-cons` is the equivalent of `clojure.core/cons` for chunked sequences,
    `chunk-buffer` creates a mutable chunk buffer (controls the chunk size), `chunk-append`
    appends an item to the end of a mutable chunk buffer, and chunk turns a mutable
    chunk buffer into an immutable chunk.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 `chunk-cons` 是分块序列中 `clojure.core/cons` 的等价物，但 `chunk-buffer` 创建一个可变的分块缓冲区（控制分块大小），`chunk-append`
    将一个项目追加到可变分块缓冲区的末尾，而分块将可变分块缓冲区转换为不可变分块。
- en: 'The `clojure.core` namespace has several functions related to chunked sequences
    listed as follows:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`clojure.core` 命名空间中列出了与分块序列相关的几个函数，如下所示：'
- en: '`chunk`'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk`'
- en: '`chunk-rest`'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk-rest`'
- en: '`chunk-cons`'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk-cons`'
- en: '`chunk-next`'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk-next`'
- en: '`chunk-first`'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk-first`'
- en: '`chunk-append`'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk-append`'
- en: '`chunked-seq?`'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunked-seq?`'
- en: '`chunk-buffer`'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk-buffer`'
- en: These functions are not documented, so although I would encourage you to study
    their source code to understand what they do, I would advise you not to make any
    assumptions about their support in future Clojure versions.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这些函数没有文档说明，所以我鼓励你研究它们的源代码以了解它们的功能，但我建议你不要对未来 Clojure 版本中它们的支持做出任何假设。
- en: Macros and closures
  id: totrans-225
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 宏和闭包
- en: 'Often, we define a macro so as to turn the parameter body of code into a closure
    and delegate it to a function. See the following example:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们定义一个宏，以便将代码参数体转换为闭包并将其委托给函数。请看以下示例：
- en: '[PRE15]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'When using such code, if the body binds a local to a lazy sequence it may be
    retained longer than necessary, likely with bad consequences on memory consumption
    and performance. Fortunately, this can be easily fixed:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用此类代码时，如果主体将局部变量绑定到惰性序列，它可能比必要的保留时间更长，这可能会对内存消耗和性能产生不良影响。幸运的是，这可以很容易地修复：
- en: '[PRE16]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Notice the `^:once` hint and the `fn*` macro, which make the Clojure compiler
    clear the closed-over references, thus avoiding the problem. Let''s see this in
    action (Alan Malloy''s example from [https://groups.google.com/d/msg/clojure/Ys3kEz5c_eE/3St2AbIc3zMJ](https://groups.google.com/d/msg/clojure/Ys3kEz5c_eE/3St2AbIc3zMJ)):'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 `^:once` 提示和 `fn*` 宏，这使得 Clojure 编译器清除闭包引用，从而避免问题。让我们看看这个例子（来自 Alan Malloy
    的 [https://groups.google.com/d/msg/clojure/Ys3kEz5c_eE/3St2AbIc3zMJ](https://groups.google.com/d/msg/clojure/Ys3kEz5c_eE/3St2AbIc3zMJ)）：
- en: '[PRE17]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The manifestation of the previous condition depends on the available heap space.
    This issue is tricky to detect as it only raises `OutOfMemoryError`, which is
    easy to misunderstand as a heap space issue instead of a memory leak. As a preventive
    measure, I would suggest using `^:once` with `fn*` in all cases where you close
    over any potentially lazy sequence.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 前述条件的体现取决于可用的堆空间。这个问题很难检测，因为它只会引发 `OutOfMemoryError`，这很容易被误解为堆空间问题而不是内存泄漏。作为预防措施，我建议在所有关闭任何可能惰性序列的情况下使用
    `^:once` 与 `fn*`。
- en: Transducers
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转换器
- en: Clojure 1.7 introduced a new abstraction called transducers for "composable
    algorithmic transformations", commonly used to apply a series of transformations
    over collections. The idea of transducers follows from the **reducing function**,
    which accepts arguments of the form (`result, input`) and returns `result`. A
    reducing function is what we typically use with reduce. A **transducer** accepts
    a reducing function, wraps/composes over its functionality to provide something
    extra, and returns another reducing function.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 1.7 引入了一个名为转换器的新抽象，用于“可组合的算法转换”，通常用于在集合上应用一系列转换。转换器的想法源于**减少函数**，它接受形式为
    (`result, input`) 的参数并返回 `result`。减少函数是我们通常与 `reduce` 一起使用的。**转换器**接受一个减少函数，将其功能包装/组合以提供额外的功能，并返回另一个减少函数。
- en: The functions in `clojure.core` that deal with collections have acquired an
    `arity-1` variant, which returns a transducer, namely `map`, `cat`, `mapcat`,
    `filter`, `remove`, `take`, `take-while`, `take-nth`, `drop`, `drop-while`, `replace`,
    `partition-by`, `partition-all`, `keep`, `keep-indexed`, `dedupe` and `random-sample`.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '`clojure.core` 中处理集合的函数已经获得了一个 `arity-1` 变体，它返回一个转换器，即 `map`、`cat`、`mapcat`、`filter`、`remove`、`take`、`take-while`、`take-nth`、`drop`、`drop-while`、`replace`、`partition-by`、`partition-all`、`keep`、`keep-indexed`、`dedupe`
    和 `random-sample`。'
- en: 'Consider the following few examples, all of which do the same thing:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下几个示例，它们都做同样的事情：
- en: '[PRE18]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here, (`filter odd?`) returns a transducer—in the first example the transducer
    wraps over the reducer function `+` to return another combined reducing function.
    While we use the ordinary `reduce` function in the first example, in the second
    example we use the `transduce` function that accepts a transducer as an argument.
    In the third example, we write a transducer `filter-odd?`, which emulates what
    (`filter odd?`) does. Let''s see how the performance varies between traditional
    and transducer versions:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，（`filter odd?`）返回一个 transducer——在第一个例子中，transducer 包装了 reducer 函数 `+`，以返回另一个组合的减少函数。虽然我们在第一个例子中使用普通的
    `reduce` 函数，但在第二个例子中，我们使用接受 transducer 作为参数的 `transduce` 函数。在第三个例子中，我们编写了一个 transducer
    `filter-odd?`，它模拟了（`filter odd?`）的行为。让我们看看传统版本和 transducer 版本之间的性能差异：
- en: '[PRE19]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Performance characteristics
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能特征
- en: The key point behind transducers is how orthogonal each transformation is allowed
    to be, yet highly composable also. At the same time, transformations can happen
    in lockstep for the entire sequence instead of each operation producing lazy chunked
    sequences. This often causes significant performance benefits with transducers.
    Lazy sequences are still going to be useful when the final result is too large
    to realize at once—for other use cases transducers should fit the need aptly with
    improved performance. Since the core functions have been overhauled to work with
    transducers, it makes sense to model transformations more often than not in terms
    of transducers.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: transducers 的关键点在于每个转换可以允许多么正交，同时又是高度可组合的。同时，转换可以在整个序列上同步进行，而不是每个操作都产生懒加载的块序列。这通常会导致
    transducers 有显著的性能优势。当最终结果太大而无法一次性实现时，懒加载序列仍然会很有用——对于其他用例，transducers 应该能够适当地满足需求并提高性能。由于核心函数已经被彻底改造以与
    transducers 一起工作，因此，在大多数情况下，用 transducers 来建模转换是有意义的。
- en: Transients
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Transients
- en: Earlier in this chapter, we discussed the virtues of immutability and the pitfalls
    of mutability. However, even though mutability is fundamentally unsafe, it also
    has very good single-threaded performance. Now, what if there was a way to restrict
    the mutable operation in a local context in order to provide safety guarantees?
    That would be equivalent to combining the performance advantage and local safety
    guarantees. That is exactly the abstraction called **transients**, which is provided
    by Clojure.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '在本章早期，我们讨论了不可变性的优点和可变性的陷阱。然而，尽管可变性在本质上是不安全的，但它也具有非常好的单线程性能。现在，如果有一种方法可以限制局部上下文中的可变操作，以提供安全性保证，那将等同于结合性能优势和局部安全性保证。这正是
    Clojure 提供的称为 **transients** 的抽象。 '
- en: 'Firstly, let''s verify that it is safe (up to Clojure 1.6 only):'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们验证它是安全的（仅限于 Clojure 1.6）：
- en: '[PRE20]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'As we can see previously, up to Clojure 1.6, a transient created in one thread
    cannot be accessed by another. However, this operation is allowed in Clojure 1.7
    in order for transducers to play well with the `core.async` ([https://github.com/clojure/core.async](https://github.com/clojure/core.async))
    library —the developer should maintain operational consistency on transients across
    threads:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在 Clojure 1.6 之前，一个线程中创建的 transient 不能被另一个线程访问。然而，在 Clojure 1.7 中允许这种操作，以便
    transducers 能够与 `core.async` ([https://github.com/clojure/core.async](https://github.com/clojure/core.async))
    库良好地协同工作——开发者应在跨线程的 transient 上保持操作一致性：
- en: '[PRE21]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'So, transients cannot be converted to seqs. Hence, they cannot participate
    in the birthing of new persistent data structures and leak out of the scope of
    execution. Consider the following code:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，transients 不能转换为 seqs。因此，它们不能参与新持久数据结构的生成，也不能从执行范围中泄漏出来。考虑以下代码：
- en: '[PRE22]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The `persistent!` function permanently converts `transient` into an equivalent
    persistent data structure. Effectively, transients are for one-time use only.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '`persistent!` 函数将 `transient` 永久转换为等效的持久数据结构。实际上，transients 只能用于一次性使用。'
- en: 'Conversion between `persistent` and `transient` data structures (the `transient`
    and `persistent!` functions) is constant time, that is, it is an *O(1)* operation.
    Transients can be created from unsorted maps, vectors, and sets only. The functions
    that mutate transients are: `conj!`, `disj!`, `pop!`, `assoc!`, and `dissoc!`.
    Read-only operations such as `get`, `nth`, `count`, and many more work as usual
    on transients, but functions such as `contains?` and those that imply seqs, such
    as `first`, `rest`, and `next`, do not.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在`persistent`和`transient`数据结构之间（`transient`和`persistent!`函数）的转换是常数时间，即它是一个*O(1)*操作。可以从未排序的映射、向量和集合中创建瞬态。修改瞬态的函数有：`conj!`、`disj!`、`pop!`、`assoc!`和`dissoc!`。只读操作，如`get`、`nth`、`count`等，在瞬态上按常规工作，但像`contains?`这样的函数以及暗示序列的函数，如`first`、`rest`和`next`，则不行。
- en: Fast repetition
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速重复
- en: 'The function `clojure.core/repeatedly` lets us execute a function many times
    and produces a lazy sequence of results. Peter Taoussanis, in his open source
    serialization library **Nippy** ([https://github.com/ptaoussanis/nippy](https://github.com/ptaoussanis/nippy)),
    wrote a transient-aware variant that performs significantly better. It is reproduced,
    as shown, with his permission (note that the arity of the function is not the
    same as `repeatedly`):'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`clojure.core/repeatedly`允许我们多次执行一个函数，并产生一个结果序列的懒序列。Peter Taoussanis在他的开源序列化库**Nippy**（[https://github.com/ptaoussanis/nippy](https://github.com/ptaoussanis/nippy)）中编写了一个瞬态感知的变体，它性能显著更好。它在他的许可下被复制，如下所示（注意，函数的arity与`repeatedly`不同）：
- en: '[PRE23]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Performance miscellanea
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能杂项
- en: Besides the major abstractions we saw earlier in the chapter, there are other
    smaller, but nevertheless very performance-critical, parts of Clojure that we
    will see in this section.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们在本章前面看到的重大抽象之外，Clojure还有一些其他较小但同样非常关键的性能部分，我们将在本节中看到。
- en: Disabling assertions in production
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 禁用生产环境中的断言
- en: Assertions are very useful to catch logical errors in the code during development,
    but they impose a runtime overhead that you may like to avoid in the production
    environment. Since `assert` is a compile time variable, the assertions can be
    silenced either by binding `assert` to false or by using `alter-var-root` before
    the code is loaded. Unfortunately, both the techniques are cumbersome to use.
    Paul Stadig's library called **assertions** ([https://github.com/pjstadig/assertions](https://github.com/pjstadig/assertions))
    helps with this exact use-case by enabling or disabling assertions via the command-line
    argument `-ea` to the Java runtime.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 断言在开发过程中非常有用，可以捕获代码中的逻辑错误，但它们在运行时会产生开销，你可能希望在生产环境中避免。由于`assert`是一个编译时变量，断言可以通过将`assert`绑定到`false`或在使用代码之前使用`alter-var-root`来静默。不幸的是，这两种技术都使用起来很麻烦。Paul
    Stadig的名为**assertions**的库（[https://github.com/pjstadig/assertions](https://github.com/pjstadig/assertions)）通过通过命令行参数`-ea`到Java运行时启用或禁用断言，帮助解决这个特定用例。
- en: 'To use it, you must include it in your Leiningen `project.clj` file as a dependency:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用它，你必须将其包含在你的Leiningen `project.clj`文件中作为依赖项：
- en: '[PRE24]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'You must use this library''s `assert` macro instead of Clojure''s own, so each
    `ns` block in the application should look similar to this:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须使用这个库的`assert`宏而不是Clojure自己的，因此应用程序中的每个`ns`块都应该看起来像这样：
- en: '[PRE25]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'When running the application, you should include the `-ea` argument to the
    JRE to enable assertions, whereas its exclusion implies no assertion at runtime:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行应用程序时，你应该将`-ea`参数包含到JRE中，以启用断言，而排除它则意味着在运行时不进行断言：
- en: '[PRE26]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Note that this usage will not automatically avoid assertions in the dependency
    libraries.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这种用法不会自动避免依赖库中的断言。
- en: Destructuring
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解构
- en: '**Destructuring** is one of Clojure''s built-in mini languages and, arguably,
    a top productivity booster during development. This feature leads to the parsing
    of values to match the left-hand side of the binding forms. The more complicated
    the binding form, the more work there is that needs to be done. Not surprisingly,
    this has a little bit of performance overhead.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '**解构**是Clojure的内置迷你语言之一，并且可以说是开发期间的一个顶级生产力提升器。这个特性导致将值解析以匹配绑定形式的左侧。绑定形式越复杂，需要完成的工作就越多。不出所料，这会有一点性能开销。'
- en: It is easy to avoid this overhead by using explicit functions to unravel data
    in the tight loops and other performance-critical code. After all, it all boils
    down to making the program work less and do more.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用显式函数在紧密循环和其他性能关键代码中展开数据，可以轻松避免这种开销。毕竟，这一切都归结于让程序工作得少，做得多。
- en: Recursion and tail-call optimization (TCO)
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 递归和尾调用优化（TCO）
- en: Functional languages have this concept of tail-call optimization related to
    recursion. So, the idea is that when a recursive call is at the tail position,
    it does not take up space on the stack for recursion. Clojure supports a form
    of user-assisted recursive call to make sure the recursive calls do not blow the
    stack. This is kind of an imperative looping, but is extremely fast.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 函数式语言有与递归相关的尾调用优化概念。因此，当递归调用处于尾位置时，它不会占用递归的栈空间。Clojure 支持一种用户辅助的递归调用形式，以确保递归调用不会耗尽栈空间。这有点像命令式循环，但速度极快。
- en: 'When carrying out computations, it may make a lot of sense to use `loop-recur`
    in the tight loops instead of iterating over synthetic numbers. For example, we
    want to add all odd integers from zero through to 1,000,000\. Let''s compare the
    code:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行计算时，在紧密循环中使用 `loop-recur` 而不是迭代合成数字可能非常有意义。例如，我们想要将0到1,000,000之间的所有奇数相加。让我们比较一下代码：
- en: '[PRE27]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'When we run the code, we get interesting results:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行代码时，我们得到了有趣的结果：
- en: '[PRE28]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The `time` macro is far from perfect as the performance-benchmarking tool, but
    the relative numbers indicate a trend—in the subsequent chapters, we will look
    at the *Criterium* library for more scientific benchmarking. Here, we use `loop-recur`
    not only to iterate faster, but we are also able to change the algorithm itself
    by iterating only about half as many times as we did in the other example.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '`time` 宏作为性能基准工具远非完美，但相对数值表明了一种趋势——在随后的章节中，我们将探讨 *Criterium* 库以进行更科学的基准测试。在这里，我们使用
    `loop-recur` 不仅是为了更快地迭代，而且我们还能通过只迭代大约其他示例一半的次数来改变算法本身。'
- en: Premature end of iteration
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 迭代提前结束
- en: 'When accumulating over a collection, in some cases, we may want to end it prematurely.
    Prior to Clojure 1.5, `loop-recur` was the only way to do it. When using `reduce`,
    we can do just that using the `reduced` function introduced in Clojure 1.5 as
    shown:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在对集合进行累积时，在某些情况下，我们可能希望提前结束。在 Clojure 1.5 之前，`loop-recur` 是唯一的方法。当使用 `reduce`
    时，我们可以使用 Clojure 1.5 中引入的 `reduced` 函数做到这一点，如下所示：
- en: '[PRE29]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Here, we multiply all the numbers in a collection and, upon finding any of the
    numbers as zero, immediately return the result zero instead of continuing up to
    the last element.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们乘以集合中的所有数字，并在发现任何数字为零时，立即返回结果零，而不是继续到最后一个元素。
- en: The function `reduced?` helps detect when a reduced value is returned. Clojure
    1.7 introduces the `ensure-reduced` function to box up non-reduced values as reduced.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 `reduced?` 帮助检测何时返回了已减少（reduced）的值。Clojure 1.7 引入了 `ensure-reduced` 函数，将非减少值装箱为减少值。
- en: Multimethods versus protocols
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多方法与协议的比较
- en: '**Multimethods** are a fantastic expressive abstraction for a polymorphic dispatch
    on the dispatch function''s return value. The `dispatch` functions associated
    with a multimethod are maintained at runtime and are looked up whenever a multimethod
    call is invoked. While multimethods provide a lot of flexibility in determining
    the dispatch, the performance overhead is simply too high compared to that of
    protocol implementations.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '**多方法** 是一个针对分派函数返回值的泛型分派（polymorphic dispatch）的出色表达抽象。与多方法关联的分派函数在运行时维护，并在调用多方法时被查找。虽然多方法在确定分派时提供了很多灵活性，但与协议实现相比，性能开销实在太高。'
- en: Protocols (`defprotocol`) are implemented using reify, records (`defrecord`),
    and types (`deftype`, `extend-type`) in Clojure. This is a big discussion topic—since
    we are discussing the performance characteristics, it should suffice to say that
    protocol implementations dispatch on polymorphic types and are significantly faster
    than multimethods. Protocols and types are generally the implementation detail
    of an API, so they are usually fronted by functions.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 协议（`defprotocol`）在 Clojure 中使用 reify、记录（`defrecord`）和类型（`deftype`、`extend-type`）实现。这是一个大讨论话题——既然我们在讨论性能特性，那么只需说协议实现基于多态类型进行分派，并且比多方法快得多就足够了。协议和类型通常是
    API 的实现细节，因此它们通常由函数来呈现。
- en: Due to the multimethods' flexibility, they still have a place. However, in performance-critical
    code it is advisable to use protocols, records, and types instead.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 由于多方法（multimethods）的灵活性，它们仍然有其位置。然而，在性能关键代码中，建议使用协议（protocols）、记录（records）和类型（types）。
- en: Inlining
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内联
- en: 'It is well known that macros are expanded inline at the call site and avoid
    a function call. As a consequence, there is a small performance benefit. There
    is also a `definline` macro that lets you write a function just like a normal
    macro. It creates an actual function that gets inlined at the call site:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 众所周知，宏在调用位置处内联展开，避免了函数调用。因此，这带来了一点点性能上的好处。还有一个`definline`宏，允许你像写正常宏一样编写一个函数。它创建了一个实际函数，该函数在调用位置处被内联：
- en: '[PRE30]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Note
  id: totrans-288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that the JVM also analyzes the code it runs and does its own inlining of
    code at runtime. While you may choose to inline the hot functions, this technique
    is known to give only a modest performance boost.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，JVM也会分析其运行的代码，并在运行时进行自己的代码内联。虽然你可以选择内联热函数，但这种技术已知只能提供适度的性能提升。
- en: 'When we define a `var` object, its value is looked up each time it is used.
    When we define a `var` object using a `:const` meta pointing to a `long` or `double`
    value, it is inlined from wherever it is called:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们定义一个`var`对象时，每次使用它时都会查找其值。当我们使用指向`long`或`double`值的`:const`元数据定义`var`对象时，它从调用位置处内联：
- en: '[PRE31]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This is known to give a decent performance boost when applicable. See the following
    example:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 当适用时，这已知可以提供相当的性能提升。请看以下示例：
- en: '[PRE32]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Summary
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Performance is one of the cornerstones of Clojure's design. Abstractions in
    Clojure are designed for simplicity, power, and safety, with performance firmly
    in mind. We saw the performance characteristics of various abstractions and also
    how to make decisions about abstractions depending on performance use cases.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 性能是Clojure设计的基础之一。Clojure中的抽象设计用于简单性、强大性和安全性，同时牢记性能。我们看到了各种抽象的性能特征，以及如何根据性能用例做出抽象决策。
- en: In the next chapter, we will see how Clojure interoperates with Java and how
    we can extract Java's power to derive optimum performance.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到Clojure如何与Java互操作，以及我们如何提取Java的力量以获得最佳性能。
- en: Chapter 3. Leaning on Java
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章。依赖Java
- en: 'Being hosted on the JVM, there are several aspects of Clojure that really help
    to understand about the Java language and platform. The need is not only due to
    interoperability with Java or understanding its implementation, but also for performance
    reasons. In certain cases, Clojure may not generate optimized JVM bytecode by
    default; in some other cases, you may want to go beyond the performance that Clojure
    data structures offer—you can use the Java alternatives via Clojure to get better
    performance. This chapter discusses those aspects of Clojure. In this chapter
    we will discuss:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Clojure托管在JVM上，Clojure的几个方面确实有助于理解Java语言和平台。这种需求不仅是因为与Java的互操作性或理解其实现，还因为性能原因。在某些情况下，Clojure默认可能不会生成优化的JVM字节码；在另一些情况下，你可能希望超越Clojure数据结构提供的性能——你可以通过Clojure使用Java替代方案来获得更好的性能。本章讨论了Clojure的这些方面。在本章中，我们将讨论：
- en: Inspecting Java and bytecode generated from a Clojure source
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查从Clojure源生成的Java和字节码
- en: Numerics and primitives
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数值和原始类型
- en: Working with arrays
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与数组一起工作
- en: Reflection and type hinting
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反射和类型提示
- en: Inspecting the equivalent Java source for Clojure code
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查Clojure代码的等效Java源代码
- en: Inspecting the equivalent Java source for a given Clojure code provides great
    insight into how that might impact its performance. However, Clojure generates
    only Java bytecodes at runtime unless we compile a namespace out to the disk.
    When developing with Leiningen, only selected namespaces under the `:aot` vector
    in the `project.clj` file are output as the compiled `.class` files containing
    bytecodes. Fortunately, an easy and quick way to know the equivalent Java source
    for the Clojure code is to AOT-compile namespaces and then decompile the bytecodes
    into equivalent Java sources, using a Java bytecode decompiler.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 检查给定Clojure代码的等效Java源代码可以提供对它可能如何影响性能的深入了解。然而，除非我们将命名空间编译到磁盘上，否则Clojure在运行时只生成Java字节码。当使用Leiningen进行开发时，只有`project.clj`文件中`:aot`向量下的选定命名空间被输出为包含字节码的编译`.class`文件。幸运的是，有一种简单快捷的方法可以知道Clojure代码的等效Java源代码，那就是通过AOT编译命名空间，然后使用Java字节码反编译器将字节码反编译成等效的Java源代码。
- en: There are several commercial and open source Java bytecode decompilers available.
    One of the open source decompilers we will discuss here is **JD-GUI**, which you
    can download from its website ([http://jd.benow.ca/#jd-gui](http://jd.benow.ca/#jd-gui)).
    Use a version suitable for your operating system.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个商业和开源的 Java 字节码反编译器可用。我们将在这里讨论的一个开源反编译器是 **JD-GUI**，您可以从其网站下载（[http://jd.benow.ca/#jd-gui](http://jd.benow.ca/#jd-gui)）。请使用适合您操作系统的版本。
- en: Creating a new project
  id: totrans-306
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建一个新的项目
- en: 'Let''s see how exactly to arrive at the equivalent Java source code from Clojure.
    Create a new project using Leiningen: `lein new foo`. Then edit the `src/foo/core.clj`
    file with a `mul` function to find out the product of two numbers:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何从 Clojure 生成等效的 Java 源代码。使用 Leiningen 创建一个新的项目：`lein new foo`。然后编辑 `src/foo/core.clj`
    文件，添加一个 `mul` 函数来找出两个数字的乘积：
- en: '[PRE33]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Compiling the Clojure sources into Java bytecode
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将 Clojure 源代码编译成 Java 字节码
- en: 'Now, to compile Clojure sources into bytecodes and output them as `.class`
    files, run the `lein compile :all` command. It creates the `.class` files in the
    `target/classes` directory of the project as follows:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，要将 Clojure 源代码编译成字节码并以 `.class` 文件的形式输出，请运行 `lein compile :all` 命令。它将在项目的
    `target/classes` 目录中创建 `.class` 文件，如下所示：
- en: '[PRE34]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: You can see that the `foo.core` namespace has been compiled into four `.class`
    files.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到 `foo.core` 命名空间已被编译成四个 `.class` 文件。
- en: Decompiling the .class files into Java source
  id: totrans-313
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将 .class 文件反编译成 Java 源代码
- en: Assuming that you have already installed JD-GUI, decompiling the `.class` files
    is as simple as opening them using the JD-GUI application.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您已经安装了 JD-GUI，反编译 `.class` 文件就像使用 JD-GUI 应用程序打开它们一样简单。
- en: '![Decompiling the .class files into Java source](img/B04596_03_01.jpg)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![将 .class 文件反编译成 Java 源代码](img/B04596_03_01.jpg)'
- en: 'On inspection, the code for the `foo.core/mul` function looks as follows:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 检查 `foo.core/mul` 函数的代码如下：
- en: '[PRE35]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: It is easy to understand from the decompiled Java source that the foo.core/mul
    function is an instance of the core$mul class in the foo package extending the
    clojure.lang.AFunction class. We can also see that the argument types are of the
    Object type in method invoke(Object, Object), which implies the numbers will be
    boxed. In a similar fashion, you can decompile class files of any Clojure code
    to inspect the equivalent Java code. If you can combine this with knowledge about
    Java types and potential reflection and boxing, you can find the suboptimal spots
    in code and focus on what to improve upon.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 从反编译的 Java 源代码中很容易理解，foo.core/mul 函数是 foo 包中 core$mul 类的一个实例，它扩展了 clojure.lang.AFunction
    类。我们还可以看到，方法调用（Object, Object）中的参数类型是 Object 类型，这意味着数字将被装箱。以类似的方式，您可以反编译任何 Clojure
    代码的类文件来检查等效的 Java 代码。如果您能结合对 Java 类型以及可能的反射和装箱的了解，您就可以找到代码中的次优位置，并专注于要改进的地方。
- en: Compiling the Clojure source without locals clearing
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不进行局部变量清除的 Clojure 源代码编译
- en: Note the Java code in the method invoke where it says `x = null; y = null;`
    —how is it possible that the code throws away the arguments, sets them to null,
    and effectively multiplies two null objects? This misleading decompilation happens
    due to locals clearing, a feature of the JVM bytecode implementation of Clojure,
    which has no equivalent in the Java language.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 注意方法调用中的 Java 代码，其中说 `x = null; y = null;` ——代码是如何丢弃参数，将它们设置为 null，并实际上将两个 null
    对象相乘的呢？这种误导性的反编译是由于局部变量清除引起的，这是 Clojure JVM 字节码实现的一个特性，在 Java 语言中没有等效功能。
- en: 'Starting with Clojure 1.4, the compiler supports the `:disable-locals-clearing`
    key in the dynamic `clojure.core/*compiler-options*` var that we cannot configure
    in the `project.clj` file. So, we cannot use the `lein compile` command, but we
    can start a **REPL** with the `lein repl` command to compile the classes:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Clojure 1.4 开始，编译器支持 `:disable-locals-clearing` 键，这是在 `project.clj` 文件中无法配置的
    `clojure.core/*compiler-options*` 动态变量。因此，我们无法使用 `lein compile` 命令，但我们可以使用 `lein
    repl` 命令启动一个 **REPL** 来编译类：
- en: '[PRE36]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: This generates the class files in the same location as we saw earlier in this
    section, but without `x = null; y = null;` because locals clearing is omitted.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在本节前面看到的相同位置生成类文件，但不会出现 `x = null; y = null;`，因为省略了局部变量清除。
- en: Numerics, boxing, and primitives
  id: totrans-324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数字、装箱和原始类型
- en: '**Numerics** are scalars. The discussion on numerics was deferred till this
    chapter for the sole reason that the numerics implementation in Clojure has strong
    Java underpinnings. Since version 1.3, Clojure has settled with 64-bit numerics
    as the default. Now, `long` and `double` are idiomatic and the default numeric
    types. Note that these are primitive Java types, not objects. Primitives in Java
    lead to high performance and have several optimizations associated with them at
    compiler and runtime levels. A local primitive is created on the stack (hence
    does not contribute to heap allocation and GC) and can be accessed directly without
    any kind of dereferencing. In Java, there also exist object equivalents of the
    numeric primitives, known as **boxed numerics**—these are regular objects that
    are allocated on the heap. The boxed numerics are also immutable objects, which
    mean not only does the JVM need to dereference the stored value when reading it,
    but also needs to create a new boxed object when a new value needs to be created.'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值**是标量。关于数值的讨论被推迟到本章，唯一的原因是 Clojure 中数值实现的强大 Java 基础。自 1.3 版本以来，Clojure
    已经确定使用 64 位数值作为默认值。现在，`long` 和 `double` 是惯用的默认数值类型。请注意，这些是原始 Java 类型，而不是对象。Java
    中的原始类型导致高性能，并在编译器和运行时级别具有多个优化。局部原始类型在栈上创建（因此不会对堆分配和 GC 贡献），可以直接访问而无需任何类型的解引用。在
    Java 中，也存在数值原始类型的对象等价物，称为 **包装数值**——这些是分配在堆上的常规对象。包装数值也是不可变对象，这意味着不仅 JVM 在读取存储的值时需要解引用，而且在需要创建新值时还需要创建一个新的包装对象。'
- en: 'It should be obvious that boxed numerics are slower than their primitive equivalents.
    The Oracle HotSpot JVM, when started with the `-server` option, aggressively inlines
    those functions (on frequent invocation) that contain a call to primitive operations.
    Clojure automatically uses **primitive numerics** at several levels. In the `let`
    blocks, `loop` blocks, arrays, and arithmetic operations (`+`, `-`, `*`, `/`,
    `inc`, `dec`, `<`, `<=`, `>`, `>=`), primitive numerics are detected and retained.
    The following table describes the primitive numerics with their boxed equivalents:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，包装数值比它们的原始等价类型要慢。当使用 `-server` 选项启动 Oracle HotSpot JVM 时，它会积极内联那些包含对原始操作调用的函数（在频繁调用时）。Clojure
    在多个级别自动使用 **原始数值**。在 `let` 块、`loop` 块、数组以及算术运算（`+`、`-`、`*`、`/`、`inc`、`dec`、`<`、`<=`、`>`、`>=`）中，会检测并保留原始数值。以下表格描述了原始数值及其包装等价类型：
- en: '| Primitive numeric type | Boxed equivalent |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| 原始数值类型 | 包装等价类型 |'
- en: '| --- | --- |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| byte (1 byte) | `java.lang.Byte` |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| byte（1字节） | `java.lang.Byte` |'
- en: '| short (2 bytes) | `java.lang.Short` |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| short（2字节） | `java.lang.Short` |'
- en: '| int (4 bytes) | `java.lang.Integer` |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| int（4字节） | `java.lang.Integer` |'
- en: '| float (4 bytes) | `java.lang.Float` |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| float（4字节） | `java.lang.Float` |'
- en: '| long (8 bytes) | `java.lang.Long` |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| long（8字节） | `java.lang.Long` |'
- en: '| double (8 bytes) | `java.lang.Double` |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| double（8字节） | `java.lang.Double` |'
- en: In Clojure, sometimes you may find the numerics are passed or returned as boxed
    objects to or from functions due to the lack of type information at runtime. Even
    if you have no control over such functions, you can coerce the values to be treated
    as primitives. The `byte`, `short`, `int`, `float`, `long`, and `double` functions
    create primitive equivalents from given boxed numeric values.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Clojure 中，有时你可能会发现数值作为包装对象传递或从函数返回，这是由于运行时缺乏类型信息所致。即使你无法控制此类函数，你也可以强制转换值以将其视为原始类型。`byte`、`short`、`int`、`float`、`long`
    和 `double` 函数从给定的包装数值值创建原始等价类型。
- en: 'One of the Lisp traditions is to provide correct ([http://en.wikipedia.org/wiki/Numerical_tower](http://en.wikipedia.org/wiki/Numerical_tower))
    arithmetic implementation. A lower type should not truncate values when overflow
    or underflow happens, but rather should be promoted to construct a higher type
    to maintain correctness. Clojure follows this constraint and provides **autopromotion**
    via prime ([http://en.wikipedia.org/wiki/Prime_(symbol)](http://en.wikipedia.org/wiki/Prime_(symbol)))
    functions: `+''`, `-''`, `*''`, `inc''`, and `dec''`. Autopromotion provides correctness
    at the cost of some performance.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: Lisp 传统之一是提供正确的 ([http://en.wikipedia.org/wiki/Numerical_tower](http://en.wikipedia.org/wiki/Numerical_tower))
    算术实现。当发生溢出或下溢时，低类型不应截断值，而应提升到更高类型以保持正确性。Clojure 遵循此约束，并通过素数 ([http://en.wikipedia.org/wiki/Prime_(symbol)](http://en.wikipedia.org/wiki/Prime_(symbol)))
    函数：`+'`、`-'`、`*'`、`inc'` 和 `dec'` 提供自动提升。自动提升以牺牲一些性能为代价提供正确性。
- en: There are also arbitrary length or precision numeric types in Clojure that let
    us store unbounded numbers but have poorer performance compared to primitives.
    The `bigint` and `bigdec` functions let us create numbers of arbitrary length
    and precision.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure中也有任意长度或精度的数值类型，允许我们存储无界数值，但与原始类型相比性能较差。`bigint`和`bigdec`函数允许我们创建任意长度和精度的数值。
- en: If we try to carry out any operations with primitive numerics that may result
    in a number beyond its maximum capacity, the operation maintains correctness by
    throwing an exception. On the other hand, when we use the prime functions, they
    autopromote to provide correctness. There is another set of operations called
    unchecked operations, which do not check for overflow or underflow and can potentially
    return incorrect results.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试执行任何可能产生超出其最大容量的原始数值的操作，该操作将通过抛出异常来保持正确性。另一方面，当我们使用素数函数时，它们会自动提升以提供正确性。还有另一组称为未检查操作的操作，这些操作不检查溢出或下溢，可能返回不正确的结果。
- en: 'In some cases, they may be faster than regular and prime functions. Such functions
    are `unchecked-add`, `unchecked-subtract`, `unchecked-multiply`, `unchecked-divide`,
    `unchecked-inc`, and `unchecked-dec`. We can also enable unchecked math behavior
    for regular arithmetic functions using the `*unchecked-math*` var; simply include
    the following in your source code file:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，它们可能比常规和素数函数更快。这些函数包括`unchecked-add`、`unchecked-subtract`、`unchecked-multiply`、`unchecked-divide`、`unchecked-inc`和`unchecked-dec`。我们还可以通过使用`*unchecked-math*`变量来启用常规算术函数的未检查数学行为；只需在您的源代码文件中包含以下内容：
- en: '[PRE37]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: One of the common needs in the arithmetic is the division used to find out the
    quotient and remainder after a natural number division. Clojure's `/` function
    provides a rational number division yielding a ratio, and the `mod` function provides
    a true modular arithmetic division. These functions are slower than the `quot`
    and `rem` functions that compute the division quotient and the remainder, respectively.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 在算术中，一个常见的需求是用于在自然数除法后找到商和余数的除法。Clojure的`/`函数提供有理数除法，产生一个比例，而`mod`函数提供真正的模除法。这些函数比计算除法商和余数的`quot`和`rem`函数要慢。
- en: Arrays
  id: totrans-342
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数组
- en: Besides objects and primitives, Java has a special type of collection storage
    structure called **arrays**. Once created, arrays cannot be grown or shrunk without
    copying data and creating another array to hold the result. Array elements are
    always homogeneous in type. The array elements are similar to places where you
    can mutate them to hold new values. Unlike collections such as list and vector,
    arrays can contain primitive elements, which make them a very fast storage mechanism
    without GC overhead.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对象和原始类型之外，Java还有一种特殊的集合存储结构类型，称为**数组**。一旦创建，数组在无需复制数据的情况下不能增长或缩小，需要创建另一个数组来存储结果。数组元素在类型上始终是同质的。数组元素类似于可以对其进行修改以保存新值的位置。与列表和向量等集合不同，数组可以包含原始元素，这使得它们成为一种非常快速的存储机制，没有GC开销。
- en: 'Arrays often form a basis for mutable data structures. For example, Java''s
    `java.lang.ArrayList` implementation uses arrays internally. In Clojure, arrays
    can be used for fast numeric storage and processing, efficient algorithms, and
    so on. Unlike collections, arrays can have one or more dimensions. So you could
    layout data in an array such as a matrix or cube. Let''s see Clojure''s support
    for arrays:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 数组通常构成可变数据结构的基础。例如，Java的`java.lang.ArrayList`实现内部使用数组。在Clojure中，数组可用于快速数值存储和处理、高效算法等。与集合不同，数组可以有一个或多个维度。因此，您可以在数组中布局数据，如矩阵或立方体。让我们看看Clojure对数组的支持：
- en: '| Description | Example | Notes |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| 描述 | 示例 | 备注 |'
- en: '| --- | --- | --- |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Create array | `(make-array Integer 20)` | Array of type (boxed) integer
    |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| 创建数组 | `(make-array Integer 20)` | 类型为（装箱）整数的数组 |'
- en: '|   | `(make-array Integer/TYPE 20)` | Array of primitive type integer |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '|   | `(make-array Integer/TYPE 20)` | 基本类型整数的数组 |'
- en: '|   | `(make-array Long/TYPE 20 10)` | Two-dimensional array of primitive long
    |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '|   | `(make-array Long/TYPE 20 10)` | 基本类型长整数的二维数组 |'
- en: '| Create array of primitives | `(int-array 20)` | Array of primitive integer
    of size 20 |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| 创建原始数组 | `(int-array 20)` | 大小为20的原始整数数组 |'
- en: '|   | `(int-array [10 20 30 40])` | Array of primitive integer created from
    a vector |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '|   | `(int-array [10 20 30 40])` | 由向量创建的基本整数数组 |'
- en: '| Create array from coll | `(to-array [10 20 30 40])` | Array from sequable
    |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| 从集合创建数组 | `(to-array [10 20 30 40])` | 可序列的数组 |'
- en: '|   | `(to-array-2d [[10 20 30][40 50 60]])` | Two-dimensional array from collection
    |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '|   | `(to-array-2d [[10 20 30][40 50 60]])` | 从集合中创建二维数组 |'
- en: '| Clone an array | `(aclone (to-array [:a :b :c]))` |   |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| 克隆数组 | `(aclone (to-array [:a :b :c]))` |   |'
- en: '| Get array element | `(aget array-object 0 3)` | Get element at index [0][3]
    in a 2-D array |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| 获取数组元素 | `(aget array-object 0 3)` | 获取二维数组中索引 [0][3] 的元素 |'
- en: '| Mutate array element | `(aset array-object 0 3 :foo)` | Set obj :foo at index
    [0][3] in a 2-D array |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| 修改数组元素 | `(aset array-object 0 3 :foo)` | 在一个二维数组中设置 obj :foo 在索引 [0][3]
    |'
- en: '| Mutate primitive array element | `(aset-int int-array-object 2 6 89)` | Set
    value 89 at index [2][6] in 2-D array |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| 修改原始数组元素 | `(aset-int int-array-object 2 6 89)` | 在二维数组中索引 [2][6] 设置值为 89
    |'
- en: '| Find length of array | `(alength array-object)` | `alength` is significantly
    faster than count |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| 获取数组长度 | `(alength array-object)` | `alength` 比count 快得多 |'
- en: '| Map over an array | `(def a (int-array [10 20 30 40 50 60]))``(seq``(amap
    a idx ret``(do (println idx (seq ret))``(inc (aget a idx)))))` | Unlike map, `amap`
    returns a non-lazy array, which is significantly faster over array elements. Note
    that `amap` is faster only when properly type hinted. See next section for type
    hinting. |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| 遍历数组 | `(def a (int-array [10 20 30 40 50 60]))``(seq``(amap a idx ret``(do
    (println idx (seq ret))``(inc (aget a idx)))))` | 与 map 不同，`amap` 返回一个非惰性数组，在遍历数组元素时速度更快。注意，`amap`
    只有在正确类型提示的情况下才更快。有关类型提示，请参阅下一节。 |'
- en: '| Reduce over an array | `(def a (int-array [10 20 30 40 50 60]))``(areduce
    a idx ret 0``(do (println idx ret)``(+ ret idx)))` | Unlike reduce, `areduce`
    is significantly faster over array elements. Note that reduce is faster only when
    properly type hinted. See next section for type hinting. |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| 遍历数组 | `(def a (int-array [10 20 30 40 50 60]))``(areduce a idx ret 0``(do
    (println idx ret)``(+ ret idx)))` | 与 reduce 不同，`areduce` 在遍历数组元素时速度更快。注意，reduce
    只有在正确类型提示的情况下才更快。有关类型提示，请参阅下一节。 |'
- en: '| Cast to primitive arrays | `(ints int-array-object)` | Used with type hinting
    (see next section) |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| 转换为原始数组 | `(ints int-array-object)` | 与类型提示一起使用（见下一节） |'
- en: 'Like `int-array` and `ints`, there are functions for other types as well:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `int-array` 和 `ints` 一样，也有其他类型的函数：
- en: '| Array construction function | Primitive-array casting function | Type hinting
    (does not work for vars) | Generic array type hinting |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| 数组构造函数 | 原始数组转换函数 | 类型提示（不适用于 vars） | 通用数组类型提示 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| boolean-array | booleans | `^booleans` | `^"[Z"` |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| boolean-array | booleans | `^booleans` | `^"[Z"` |'
- en: '| byte-array | bytes | `^bytes` | `^"[B"` |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| byte-array | bytes | `^bytes` | `^"[B"` |'
- en: '| short-array | shorts | `^shorts` | `^"[S"` |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| short-array | shorts | `^shorts` | `^"[S"` |'
- en: '| char-array | chars | `^chars` | `^"[C"` |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| char-array | chars | `^chars` | `^"[C"` |'
- en: '| int-array | ints | `^ints` | `^"[I"` |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| int-array | ints | `^ints` | `^"[I"` |'
- en: '| long-array | longs | `^longs` | `^"[J"` |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| long-array | longs | `^longs` | `^"[J"` |'
- en: '| float-array | floats | `^floats` | `^"[F"` |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| float-array | floats | `^floats` | `^"[F"` |'
- en: '| double-array | doubles | `^doubles` | `^"[D"` |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| double-array | doubles | `^doubles` | `^"[D"` |'
- en: '| object-array | –– | `^objects` | `^"[Ljava.lang.Object"` |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| 对象数组 | –– | `^objects` | `^"[Ljava.lang.Object"` |'
- en: Arrays are favored over other data structures mainly due to performance, and
    sometimes due to interop. Extreme care should be taken to type hint the arrays
    and use the appropriate functions to work with them.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 数组之所以受到青睐，主要是因为性能，有时也因为互操作性。在为数组添加类型提示和使用适当的函数处理它们时，应特别小心。
- en: Reflection and type hints
  id: totrans-375
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 反射和类型提示
- en: Sometimes, as Clojure is dynamically typed, the Clojure compiler is unable to
    figure out the type of object to invoke a certain method. In such cases, Clojure
    uses **reflection**, which is considerably slower than the direct method dispatch.
    Clojure's solution to this is something called **type hints**. Type hints are
    a way to annotate arguments and objects with static types, so that the Clojure
    compiler can emit bytecodes for efficient dispatch.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，由于 Clojure 是动态类型的，Clojure 编译器无法确定要调用某个方法的对象类型。在这种情况下，Clojure 使用 **反射**，这比直接方法分派慢得多。Clojure
    的解决方案是称为 **类型提示** 的东西。类型提示是一种用静态类型注解参数和对象的方法，以便 Clojure 编译器可以生成用于高效分派的字节码。
- en: 'The easiest way to know where to put type hints is to turn on reflection warning
    in the code. Consider this code that determines the length of a string:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 知道在哪里放置类型提示的最简单方法是打开代码中的反射警告。考虑以下确定字符串长度的代码：
- en: '[PRE38]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'In the previous snippet, we can clearly see there is a very big difference
    in performance in the code that uses reflection versus the code that does not.
    When working on a project, you may want reflection warning to be turned on for
    all files. You can do it easily in Leiningen. Just put the following entry in
    your `project.clj` file:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们可以清楚地看到，使用反射的代码与不使用反射的代码在性能上有很大的差异。在处理项目时，你可能希望所有文件都开启反射警告。在 Leiningen
    中可以轻松实现。只需在你的 `project.clj` 文件中添加以下条目：
- en: '[PRE39]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This will automatically turn on warning reflection every time you begin any
    kind of invocation via Leiningen in the dev workflow such as REPL and test.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在你通过 Leiningen 在开发工作流程中开始任何类型的调用时自动开启反射警告，例如 REPL 和测试。
- en: An array of primitives
  id: totrans-382
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 原始类型数组
- en: 'Recall the examples on `amap` and `areduce` from the previous section. If we
    run them with reflection warning on, we''d be warned that it uses reflection.
    Let''s type hint them:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 回忆一下上一节中关于 `amap` 和 `areduce` 的例子。如果我们开启反射警告运行它们，我们会收到警告说它们使用了反射。让我们给它们添加类型提示：
- en: '[PRE40]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Note that the primitive array hint `^ints` does not work at the var level.
    So, it would not work if you defined the var `a`, as in the following:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，原始数组提示 `^ints` 在变量级别上不起作用。因此，如果你定义了变量 `a`，如下所示，它将不起作用：
- en: '[PRE41]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This notation is for an array of integers. Other primitive array types have
    similar type hints. Refer to the previous section for type hinting for various
    primitive array types.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 这个符号表示整数数组。其他原始数组类型有类似的类型提示。请参考前面的章节了解各种原始数组类型的类型提示。
- en: Primitives
  id: totrans-388
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基本类型
- en: 'The type hinting of primitive locals is neither required nor allowed. However,
    you can type hint function arguments as primitives. Clojure allows up to four
    arguments in functions to be type hinted:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 原始局部变量的类型提示既不是必需的，也不允许。然而，你可以将函数参数作为原始类型进行类型提示。Clojure 允许在函数中最多有四个参数可以进行类型提示：
- en: '[PRE42]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Note
  id: totrans-391
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Boxing may result in something not always being a primitive. In those cases,
    you can coerce those using respective primitive types.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 封装箱可能会导致某些情况下的对象不是基本类型。在这种情况下，你可以使用相应的原始类型强制转换它们。
- en: Macros and metadata
  id: totrans-393
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 宏和元数据
- en: 'In macros, type hinting does not work the way it does in the other parts of
    the code. Since macros are about transforming the **Abstract Syntax Tree** (**AST**),
    we need to have a mental map of the transformation and we should add type hints
    as metadata in the code. For example, if `str-len` is a macro to find the length
    of a string, we make use of the following code:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 在宏中，类型提示的工作方式与其他代码部分不同。由于宏是关于转换**抽象语法树**（**AST**），我们需要有一个心理图来表示转换，并且我们应该在代码中添加类型提示作为元数据。例如，如果
    `str-len` 是一个用于查找字符串长度的宏，我们使用以下代码：
- en: '[PRE43]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'In the preceding code, we alter the metadata of the symbol `s` by tagging it
    with the type `String`, which happens to be the `java.lang.String` class in this
    case. For array types, we can use `[Ljava.lang.String` for an array of string
    objects and similarly for others. If you try to use `str-len` listed previously,
    you may notice this works only when we pass the string bound to a local or a var,
    not as a string literal. To mitigate this, we can write the macro as follows:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们通过将类型 `String` 标记到符号 `s` 上来改变其元数据，在这种情况下，它恰好是 `java.lang.String` 类。对于数组类型，我们可以使用
    `[Ljava.lang.String` 来表示字符串对象的数组，以及其他类似情况。如果你尝试使用之前列出的 `str-len`，你可能会注意到这仅在将字符串绑定到本地变量或变量时才有效，而不是作为字符串字面量。为了减轻这种情况，我们可以将宏编写如下：
- en: '[PRE44]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Here we bind the argument to a type-hinted gensym local, hence calling `.length`
    on it does not use reflection and there is no reflection warning emitted as such.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将参数绑定到一个带有类型提示的 gensym 本地变量上，因此在对它调用 `.length` 时不会使用反射，并且不会发出任何反射警告。
- en: 'Type hinting via metadata also works with functions, albeit in a different
    notation:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 通过元数据进行的类型提示也适用于函数，尽管符号不同：
- en: '[PRE45]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Except for the first example in the preceding snippet, they are type hinted
    to return the `java.lang.String` type.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 除了前面代码片段中的第一个例子外，它们都被类型提示为返回 `java.lang.String` 类型。
- en: String concatenation
  id: totrans-402
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 字符串连接
- en: 'The `str` function in Clojure is used to concatenate and convert to string
    tokens. In Java, when we write `"hello" + e`, the Java compiler translates this
    to an equivalent code that uses `StringBuilder` and is considerably faster than
    the `str` function in micro-benchmarks. To obtain close-to-Java performance, in
    Clojure we can use a similar mechanism with a macro directly using Java interop
    to avoid the indirection via the `str` function. The **Stringer** ([https://github.com/kumarshantanu/stringer](https://github.com/kumarshantanu/stringer))
    library adopts the same technique to come up with fast string concatenation in
    Clojure:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure中的`str`函数用于连接和转换为字符串标记。在Java中，当我们编写`"hello" + e`时，Java编译器将其转换为使用`StringBuilder`的等效代码，在微基准测试中比`str`函数快得多。为了获得接近Java的性能，在Clojure中我们可以使用一个类似的机制，通过宏直接使用Java互操作来避免通过`str`函数的间接操作。**Stringer**
    ([https://github.com/kumarshantanu/stringer](https://github.com/kumarshantanu/stringer))库采用了相同的技巧，在Clojure中实现快速字符串连接：
- en: '[PRE46]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Here, Stringer also aggressively concatenates the literals during the compile
    phase.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，Stringer在编译阶段也积极地连接了字面量。
- en: Miscellaneous
  id: totrans-406
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 杂项
- en: 'In a type (as in `deftype`), the mutable instance variables can be optionally
    annotated as `^:volatile-mutable` or `^:unsynchronized-mutable`. For example:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 在类型（如`deftype`）中，可变实例变量可以可选地注解为`^:volatile-mutable`或`^:unsynchronized-mutable`。例如：
- en: '[PRE47]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Unlike `defprotocol`, the `definterface` macro lets us provide a return type
    hint for methods:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 与`defprotocol`不同，`definterface`宏允许我们为方法提供返回类型提示：
- en: '[PRE48]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The `proxy-super` macro (which is used inside the `proxy` macro) is a special
    case where you cannot directly apply a type hint. The reason being that it relies
    on the implicit this object that is automatically created by the `proxy` macro.
    In this case, you must explicitly bind this to a type:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '`proxy-super`宏（在`proxy`宏内部使用）是一个特殊情况，你不能直接应用类型提示。原因是它依赖于`proxy`宏自动创建的隐式`this`对象。在这种情况下，你必须显式地将`this`绑定到一个类型：'
- en: '[PRE49]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Type hinting is quite important for performance in Clojure. Fortunately, we
    need to type hint only when required and it's easy to find out when. In many cases,
    a gain from type hinting overshadows the gains from code inlining.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 类型提示对于Clojure的性能非常重要。幸运的是，我们只需要在需要时进行类型提示，而且很容易找出何时需要。在许多情况下，类型提示带来的收益会超过代码内联的收益。
- en: Using array/numeric libraries for efficiency
  id: totrans-414
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用数组/数值库以提高效率
- en: You may have noticed in the previous sections, when working with numerics, performance
    depends a lot on whether the data is based on arrays and primitives. It may take
    a lot of meticulousness on the programmer's part to correctly coerce data into
    primitives and arrays at all stages of the computation in order to achieve optimum
    efficiency. Fortunately, the high-performance enthusiasts from the Clojure community
    realized this issue early on and created some dedicated open source libraries
    to mitigate the problem.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到在前面的章节中，当处理数值时，性能很大程度上取决于数据是否基于数组和原始类型。为了实现最佳效率，程序员可能需要在计算的各个阶段都非常细致地将数据正确地强制转换为原始类型和数组。幸运的是，Clojure社区的高性能爱好者们很早就意识到了这个问题，并创建了一些专门的开源库来减轻这个问题。
- en: HipHip
  id: totrans-416
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HipHip
- en: '**HipHip** is a Clojure library used to work with arrays of primitive types.
    It provides a safety net, that is, it strictly accepts only primitive array arguments
    to work with. As a result, passing silently boxed primitive arrays as arguments
    always results in an exception. HipHip macros and functions rarely need the programmer
    to type hint anything during the operations. It supports arrays of primitive types
    such as `int`, `long`, `float`, and `double`.'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: '**HipHip**是一个Clojure库，用于处理原始类型数组。它提供了一个安全网，即它严格只接受原始数组参数来工作。因此，静默传递装箱的原始数组作为参数总是会导致异常。HipHip宏和函数很少需要在操作期间进行类型提示。它支持原始类型的数组，如`int`、`long`、`float`和`double`。'
- en: The HipHip project is available at [https://github.com/Prismatic/hiphip](https://github.com/Prismatic/hiphip).
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: HipHip项目可在[https://github.com/Prismatic/hiphip](https://github.com/Prismatic/hiphip)找到。
- en: 'As of writing, HipHip''s most recent version is 0.2.0 that supports Clojure
    1.5.x or above, and is tagged as an Alpha release. There is a standard set of
    operations provided by HipHip for arrays of all of the four primitive types: integer
    array operations are in the namespace `hiphip.int`; double precision array operations
    in `hiphip.double`; and so on. The operations are all type hinted for the respective
    types. All of the operations for `int`, `long`, `float`, and `double` in respective
    namespaces are essentially the same except for the array type:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，HipHip 的最新版本是 0.2.0，支持 Clojure 1.5.x 或更高版本，并标记为 Alpha 版本。HipHip 为所有四种原始数据类型的数组提供了一套标准的操作：整数数组操作在命名空间
    `hiphip.int` 中；双精度数组操作在 `hiphip.double` 中；等等。所有操作都为相应类型提供了类型提示。在相应命名空间中，`int`、`long`、`float`
    和 `double` 的所有操作基本上是相同的，除了数组类型：
- en: '| Category | Function/macro | Description |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 函数/宏 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Core functions | `aclone` | Like `clojure.core/aclone`, for primitives |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| 核心函数 | `aclone` | 类似于 `clojure.core/aclone`，用于原始数据类型 |'
- en: '|   | `alength` | Like `clojure.core/alength`, for primitives |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '|   | `alength` | 类似于 `clojure.core/alength`，用于原始数据类型 |'
- en: '|   | `aget` | Like `clojure.core/aget`, for primitives |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '|   | `aget` | 类似于 `clojure.core/aget`，用于原始数据类型 |'
- en: '|   | `aset` | Like `clojure.core/aset`, for primitives |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '|   | `aset` | 类似于 `clojure.core/aset`，用于原始数据类型 |'
- en: '|   | `ainc` | Increment array element by specified value |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '|   | `ainc` | 将数组元素按指定值增加 |'
- en: '| Equiv hiphip.array operations | `amake` | Make a new array and fill values
    computed by expression |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| 等价的 hiphip.array 操作 | `amake` | 创建新数组并用表达式计算出的值填充 |'
- en: '|   | `areduce` | Like `clojure.core/areduce`, with HipHip array bindings |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '|   | `areduce` | 类似于 `clojure.core/areduce`，带有 HipHip 数组绑定 |'
- en: '|   | `doarr` | Like `clojure.core/doseq`, with HipHip array bindings |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '|   | `doarr` | 类似于 `clojure.core/doseq`，带有 HipHip 数组绑定 |'
- en: '|   | `amap` | Like `clojure.core/for`, creates new array |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '|   | `amap` | 类似于 `clojure.core/for`，创建新数组 |'
- en: '|   | `afill!` | Like preceding `amap`, but overwrites array argument |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '|   | `afill!` | 类似于前面的 `amap`，但覆盖数组参数 |'
- en: '| Mathy operations | `asum` | Compute sum of array elements using expression
    |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| 数学运算 | `asum` | 使用表达式计算数组元素的总和 |'
- en: '|   | `aproduct` | Compute product of array elements using expression |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '|   | `aproduct` | 使用表达式计算数组元素乘积 |'
- en: '|   | `amean` | Compute mean over array elements |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '|   | `amean` | 计算数组元素的平均值 |'
- en: '|   | `dot-product` | Compute dot product of two arrays |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '|   | `dot-product` | 计算两个数组的点积 |'
- en: '| Finding minimum/maximum, Sorting | `amax-index` | Find maximum value in array
    and return the index |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| 查找最小/最大值，排序 | `amax-index` | 在数组中找到最大值并返回索引 |'
- en: '|   | `amax` | Find maximum value in array and return it |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '|   | `amax` | 在数组中找到最大值并返回它 |'
- en: '|   | `amin-index` | Find minimum value in array and return the index |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '|   | `amin-index` | 在数组中找到最小值并返回索引 |'
- en: '|   | `amin` | Find minimum value in array and return it |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '|   | `amin` | 在数组中找到最小值并返回它 |'
- en: '|   | `apartition!` | Three-way partition of array: less, equal, greater than
    pivot |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '|   | `apartition!` | 数组的三向划分：小于、等于、大于枢轴 |'
- en: '|   | `aselect!` | Gather smallest `k` elements at the beginning of array |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '|   | `aselect!` | 将最小的 `k` 个元素收集到数组的开头 |'
- en: '|   | `asort!` | Sort array in-place using Java''s built-in implementation
    |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '|   | `asort!` | 使用 Java 内置实现就地排序数组 |'
- en: '|   | `asort-max!` | Partial in-place sort gathering top `k` elements to the
    end |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '|   | `asort-max!` | 部分就地排序，将前 `k` 个元素收集到末尾 |'
- en: '|   | `asort-min!` | Partial in-place sort gathering min `k` elements to the
    top |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '|   | `asort-min!` | 部分就地排序，将最小的 `k` 个元素收集到顶部 |'
- en: '|   | `apartition-indices!` | Like `apartition!` but mutates index-array instead
    of values |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '|   | `apartition-indices!` | 类似于 `apartition!`，但修改索引数组而不是值 |'
- en: '|   | `aselect-indices!` | Like `aselect!` but mutates index-array instead
    of values |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '|   | `aselect-indices!` | 类似于 `aselect!`，但修改索引数组而不是值 |'
- en: '|   | `asort-indices!` | Like `asort!` but mutates index-array instead of values
    |'
  id: totrans-447
  prefs: []
  type: TYPE_TB
  zh: '|   | `asort-indices!` | 类似于 `asort!`，但修改索引数组而不是值 |'
- en: '|   | `amax-indices` | Get index-array; last `k` indices pointing to max `k`
    values |'
  id: totrans-448
  prefs: []
  type: TYPE_TB
  zh: '|   | `amax-indices` | 获取索引数组；最后 `k` 个索引指向最大的 `k` 个值 |'
- en: '|   | `amin-indices` | Get index-array; first `k` indices pointing to min `k`
    values |'
  id: totrans-449
  prefs: []
  type: TYPE_TB
  zh: '|   | `amin-indices` | 获取索引数组；前 `k` 个索引指向最小的 `k` 个值 |'
- en: 'To include HipHip as a dependency in your Leiningen project, specify it in
    `project.clj`:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Leiningen 项目中包含 HipHip 作为依赖项，请在 `project.clj` 中指定：
- en: '[PRE50]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'As an example of how to use HipHip, let''s see how to compute the normalized
    values of an array:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何使用 HipHip 的一个示例，让我们看看如何计算数组的归一化值：
- en: '[PRE51]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Unless we make sure that `xs` is an array of primitive doubles, HipHip will
    throw `ClassCastException` when the type is incorrect, and `IllegalArgumentException`
    in other cases. I recommend exploring the HipHip project to gain more insight
    into using it effectively.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 除非我们确保 `xs` 是原始双精度浮点数数组，否则 HipHip 在类型不正确时会抛出 `ClassCastException`，在其他情况下会抛出
    `IllegalArgumentException`。我建议您探索 HipHip 项目，以获得更深入的使用见解。
- en: primitive-math
  id: totrans-455
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基础数学运算
- en: We can set `*warn-on-reflection*` to true to let Clojure warn us when the reflection
    is used at invocation boundaries. However, when Clojure has to implicitly use
    reflection to perform math, the only resort is to either use a profiler or compile
    the Clojure source down to bytecode, and analyze boxing and reflection with a
    decompiler. This is where the `primitive-math` library helps, by producing extra
    warnings and throwing exceptions.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将 `*warn-on-reflection*` 设置为 true，让 Clojure 在调用边界处使用反射时警告我们。然而，当 Clojure
    必须隐式使用反射进行数学运算时，唯一的办法是使用分析器或将 Clojure 源代码编译成字节码，然后使用反编译器分析装箱和反射。这就是 `primitive-math`
    库发挥作用的地方，它通过产生额外的警告和抛出异常来帮助。
- en: The `primitive-math` library is available at [https://github.com/ztellman/primitive-math](https://github.com/ztellman/primitive-math).
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: '`primitive-math` 库可在 [https://github.com/ztellman/primitive-math](https://github.com/ztellman/primitive-math)
    找到。'
- en: 'As of writing, primitive-math is at version 0.1.4; you can include it as a
    dependency in your Leiningen project by editing `project.clj` as follows:'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 截至撰写本文时，`primitive-math` 的版本为 0.1.4；您可以通过编辑 `project.clj` 文件将其作为依赖项包含到您的 Leiningen
    项目中，具体方法如下：
- en: '[PRE52]'
  id: totrans-459
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The following code is how it can be used (recall the example from the *Decompiling
    the .class files into Java source* section):'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何使用它的代码示例（回想一下 *将 .class 文件反编译成 Java 源代码* 部分的示例）：
- en: '[PRE53]'
  id: totrans-461
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: While `primitive-math` is a useful library, the problem it solves is mostly
    taken care of by the boxing detection feature in Clojure 1.7 (see next section
    *Detecting boxed math*). However, this library is still useful if you are unable
    to use Clojure 1.7 or higher.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 `primitive-math` 是一个有用的库，但它解决的问题大多已由 Clojure 1.7 的装箱检测功能处理（参见下一节 *检测装箱数学*）。然而，如果您无法使用
    Clojure 1.7 或更高版本，此库仍然很有用。
- en: Detecting boxed math
  id: totrans-463
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 检测装箱数学
- en: '**Boxed math** is hard to detect and is a source of performance issues. Clojure
    1.7 introduces a way to warn the user when boxed math happens. This can be configured
    in the following way:'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '**装箱数学**难以检测，是性能问题的来源。Clojure 1.7 引入了一种方法，当发生装箱数学时警告用户。这可以通过以下方式进行配置：'
- en: '[PRE54]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'When working with Leiningen, you can enable boxed math warnings by putting
    the following entry in the `project.clj` file:'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用 Leiningen 时，您可以通过在 `project.clj` 文件中添加以下条目来启用装箱数学警告：
- en: '[PRE55]'
  id: totrans-467
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: The math operations in `primitive-math` (like HipHip) are implemented via macros.
    Therefore, they cannot be used as higher order functions and, as a consequence,
    may not compose well with other code. I recommend exploring the project to see
    what suits your program use case. Adopting Clojure 1.7 obviates the boxing discovery
    issues by means of a boxed-warning feature.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: '`primitive-math` 中的数学运算（如 HipHip）是通过宏实现的。因此，它们不能用作高阶函数，并且因此可能与其他代码组合不佳。我建议您探索该项目，看看哪些适合您的程序用例。采用
    Clojure 1.7 通过装箱警告功能消除了装箱发现问题。'
- en: Resorting to Java and native code
  id: totrans-469
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 依赖 Java 和本地代码
- en: In a handful of cases, where the lack of imperative, stack-based, mutable variables
    in Clojure may make the code not perform as well as Java, we may need to evaluate
    alternatives to make it faster. I would advise you to consider writing such code
    directly in Java for better performance.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 在少数情况下，由于 Clojure 缺乏命令式、基于栈的、可变变量，这可能导致代码的性能不如 Java，我们可能需要评估替代方案以提高其性能。我建议您考虑直接用
    Java 编写此类代码以获得更好的性能。
- en: Another consideration is to use native OS capabilities, such as memory-mapped
    buffers ([http://docs.oracle.com/javase/7/docs/api/java/nio/MappedByteBuffer.html](http://docs.oracle.com/javase/7/docs/api/java/nio/MappedByteBuffer.html))
    or files and unsafe operations ([http://highlyscalable.wordpress.com/2012/02/02/direct-memory-access-in-java/](http://highlyscalable.wordpress.com/2012/02/02/direct-memory-access-in-java/)).
    Note that unsafe operations are potentially hazardous and not recommended in general.
    Such times are also an opportunity to consider writing performance-critical pieces
    of code in C or C++ and then access them via the **Java Native Interface** (**JNI**).
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个考虑因素是使用原生操作系统功能，例如内存映射缓冲区（[http://docs.oracle.com/javase/7/docs/api/java/nio/MappedByteBuffer.html](http://docs.oracle.com/javase/7/docs/api/java/nio/MappedByteBuffer.html)）或文件和不受保护的操作（[http://highlyscalable.wordpress.com/2012/02/02/direct-memory-access-in-java/](http://highlyscalable.wordpress.com/2012/02/02/direct-memory-access-in-java/)）。请注意，不受保护的操作可能具有潜在风险，通常不建议使用。这些时刻也是考虑将性能关键代码用
    C 或 C++ 编写，然后通过 **Java 本地接口**（**JNI**）访问它们的时机。
- en: Proteus – mutable locals in Clojure
  id: totrans-472
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Proteus – Clojure 中的可变局部变量
- en: Proteus is an open source Clojure library that lets you treat a local as a local
    variable, thereby allowing its unsynchronized mutation within the local scope
    only. Note that this library depends on the internal implementation structure
    of Clojure as of Clojure 1.5.1\. The **Proteus** project is available at [https://github.com/ztellman/proteus](https://github.com/ztellman/proteus).
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: Proteus 是一个开源的 Clojure 库，允许您将局部变量视为局部变量，从而使其在局部作用域内仅允许非同步修改。请注意，此库依赖于 Clojure
    1.5.1 的内部实现结构。**Proteus** 项目可在 [https://github.com/ztellman/proteus](https://github.com/ztellman/proteus)
    找到。
- en: 'You can include Proteus as a dependency in the Leiningen project by editing
    `project.clj`:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过编辑 `project.clj` 将 Proteus 包含为 Leiningen 项目的依赖项：
- en: '[PRE56]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Using Proteus in code is straightforward, as shown in the following code snippet:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中使用 Proteus 很简单，如下面的代码片段所示：
- en: '[PRE57]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Since Proteus allows mutation only in the local scope, the following throws
    an exception:'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Proteus 只允许在局部作用域中进行可变操作，以下代码会抛出异常：
- en: '[PRE58]'
  id: totrans-479
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The mutable locals are very fast and may be quite useful in tight loops. Proteus
    is unconventional by Clojure idioms, but it may give the required performance
    boost without having to write Java code.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 可变局部变量非常快，在紧密循环中可能非常有用。Proteus 在 Clojure 习惯用法上是非传统的，但它可能在不编写 Java 代码的情况下提供所需的性能提升。
- en: Summary
  id: totrans-481
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Clojure has strong Java interoperability and underpinning, due to which programmers
    can leverage the performance benefits nearing those of Java. For performance-critical
    code, it is sometimes necessary to understand how Clojure interacts with Java
    and how to turn the right knobs. Numerics is a key area where Java interoperability
    is required to get optimum performance. Type hints are another important performance
    trick that is frequently useful. There are several open source Clojure libraries
    that make such activities easier for the programmer.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Clojure 具有强大的 Java 互操作性和基础，程序员可以利用接近 Java 的性能优势。对于性能关键代码，有时有必要了解 Clojure
    如何与 Java 交互以及如何调整正确的旋钮。数值是一个需要 Java 互操作以获得最佳性能的关键领域。类型提示是另一个重要的性能技巧，通常非常有用。有几个开源的
    Clojure 库使程序员更容易进行此类活动。
- en: In the next chapter, we will dig deeper below Java and see how the hardware
    and the JVM stack play a key role in offering the performance we get, what their
    constraints are, and how to use their understanding to get better performance.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入探讨 Java 之下，看看硬件和 JVM 堆栈如何在我们获得性能中发挥关键作用，它们的限制是什么，以及如何利用对这些理解的使用来获得更好的性能。
- en: Chapter 4. Host Performance
  id: totrans-484
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 4 章。主机性能
- en: 'In the previous chapters, we noted how Clojure interoperates with Java. In
    this chapter we will go a bit deeper to understand the internals better. We will
    touch upon several layers of the entire stack, but our major focus will be the
    JVM, in particular the Oracle HotSpot JVM, though there are several JVM vendors
    to choose from ([http://en.wikipedia.org/wiki/List_of_Java_virtual_machines](http://en.wikipedia.org/wiki/List_of_Java_virtual_machines)).
    At the time of writing this, Oracle JDK 1.8 is the latest stable release and early
    OpenJDK 1.9 builds are available. In this chapter we will discuss:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们注意到了 Clojure 与 Java 的互操作性。在本章中，我们将更深入地探讨，以更好地理解内部结构。我们将触及整个堆栈的几个层次，但我们的主要焦点将是
    JVM，特别是 Oracle HotSpot JVM，尽管有多个 JVM 供应商可供选择（[http://en.wikipedia.org/wiki/List_of_Java_virtual_machines](http://en.wikipedia.org/wiki/List_of_Java_virtual_machines)）。在撰写本文时，Oracle
    JDK 1.8 是最新的稳定版本，早期 OpenJDK 1.9 构建也已可用。在本章中，我们将讨论：
- en: How the hardware subsystems function from the performance viewpoint
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从性能角度来看，硬件子系统是如何工作的
- en: Organization of the JVM internals and how that is related to performance
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JVM内部结构的组织以及它与性能的关系
- en: How to measure the amount of space occupied by various objects in the heap
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何测量堆中各种对象占用的空间量
- en: Profile Clojure code for latency using Criterium
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Criterium对Clojure代码进行延迟分析
- en: The hardware
  id: totrans-490
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 硬件
- en: There are various hardware components that may impact the performance of software
    in different ways. The processors, caches, memory subsystem, I/O subsystems, and
    so on, all have varying degrees of performance impact depending upon the use cases.
    In the following sections we look into each of those aspects.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种硬件组件可能会以不同的方式影响软件的性能。处理器、缓存、内存子系统、I/O子系统等，根据用例的不同，都有不同程度的影响。在接下来的章节中，我们将探讨这些方面的每一个。
- en: Processors
  id: totrans-492
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理器
- en: 'Since about the late 1980s, microprocessors have been employing pipelining
    and instruction-level parallelism to speed up their performance. Processing an
    instruction at the CPU level consists of typically four cycles: **fetch**, **decode**,
    **execute**, and **writeback**. Modern processors optimize the cycles by running
    them in parallel—while one instruction is executed, the next instruction is being
    decoded, and the one after that is being fetched, and so on. This style is called
    **instruction pipelining**.'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 自1980年代末以来，微处理器一直采用流水线和指令级并行性来提高其性能。在CPU级别处理指令通常包括四个周期：**取指令**、**解码**、**执行**和**写回**。现代处理器通过并行运行这些周期来优化它们——当一条指令正在执行时，下一条指令正在被解码，再下一条正在被取，依此类推。这种风格被称为**指令流水线**。
- en: In practice, in order to speed up execution even further, the stages are subdivided
    into many shorter stages, thus leading to deeper super-pipeline architecture.
    The length of the longest stage in the pipeline limits the clock speed of the
    CPU. By splitting stages into substages, the processor can be run at a higher
    clock speed, where more cycles are required for each instruction, but the processor
    still completes one instruction per cycle. Since there are more cycles per second
    now, we get better performance in terms of throughput per second even though the
    latency of each instruction is now higher.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，为了进一步加快执行速度，阶段被细分为许多更短的阶段，从而导致了更深的超级流水线架构。流水线中最长阶段的长度限制了CPU的时钟速度。通过将阶段细分为子阶段，处理器可以以更高的时钟速度运行，每个指令需要更多的周期，但处理器仍然在每个周期内完成一条指令。由于现在每秒有更多的周期，尽管每个指令的延迟现在更高，但我们仍然在每秒吞吐量方面获得了更好的性能。
- en: Branch prediction
  id: totrans-495
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分支预测
- en: The processor must fetch and decode instructions in advance even when it encounters
    instructions of the conditional `if-then` form. Consider an equivalent of the
    (`if (test a) (foo a) (bar a)`) Clojure expression. The processor must choose
    a branch to fetch and decode, the question is should it fetch the `if` branch
    or the `else` branch? Here, the processor makes a guess as to which instruction
    to fetch/decode. If the guess turns out to be correct, it is a performance gain
    as usual; otherwise, the processor has to throw away the result of the fetch/decode
    process and start on the other branch afresh.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 即使处理器遇到条件`if-then`形式的指令，也必须提前取指令和解码。考虑一个Clojure表达式(`if (test a) (foo a) (bar
    a)`)的等价物。处理器必须选择一个分支来取指令和解码，问题是它应该取`if`分支还是`else`分支？在这里，处理器对要取/解码的指令进行猜测。如果猜测是正确的，就像往常一样，这是一个性能提升；否则，处理器必须丢弃取/解码过程的结果，并从另一个分支重新开始。
- en: Processors deal with branch prediction using an on-chip branch prediction table.
    It contains recent code branches and two bits per branch, indicating whether or
    not the branch was taken, while also accommodating one-off, not-taken occurrences.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器使用片上分支预测表来处理分支预测。它包含最近的代码分支和每个分支两个比特，指示分支是否被采取，同时也容纳了单次未采取的情况。
- en: Today, branch prediction is extremely important in processors for performance,
    so modern processors dedicate hardware resources and special predication instructions
    to improve the prediction accuracy and lower the cost of a mispredict penalty.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，分支预测对于处理器的性能至关重要，因此现代处理器专门分配硬件资源和特殊的预测指令来提高预测准确性并降低误预测的代价。
- en: Instruction scheduling
  id: totrans-499
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指令调度
- en: High-latency instructions and branching usually lead to empty cycles in the
    instruction pipeline known as **stalls** or **bubbles**. These cycles are often
    used to do other work by the means of instruction reordering. Instruction reordering
    is implemented at the hardware level via out of order execution and at the compiler
    level via compile time instruction scheduling (also called **static instruction
    scheduling**).
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 高延迟指令和分支通常会导致指令流水线中的空周期，称为**停顿**或**气泡**。这些周期通常通过指令重排来完成其他工作。指令重排通过乱序执行在硬件级别实现，通过编译时指令调度（也称为**静态指令调度**）在编译器级别实现。
- en: The processor needs to remember the dependencies between instructions when carrying
    out the out-of-order execution. This cost is somewhat mitigated by using renamed
    registers, wherein register values are stored into / loaded from memory locations,
    potentially on different physical registers, so that they can be executed in parallel.
    This necessitates that out-of-order processors always maintain a mapping of instructions
    and corresponding registers they use, which makes their design complex and power
    hungry. With a few exceptions, almost all high-performance CPUs today have out-of-order
    designs.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器在执行乱序执行时需要记住指令之间的依赖关系。这种成本可以通过使用重命名寄存器来在一定程度上减轻，其中寄存器值存储到/从内存位置加载，可能在不同物理寄存器上，这样它们可以并行执行。这需要乱序处理器始终维护指令及其使用的寄存器的映射，这使得它们的设计复杂且功耗大。除了一些例外，今天几乎所有高性能CPU都具有乱序设计。
- en: Good compilers are usually extremely aware of processors, and are capable of
    optimizing the code by rearranging processor instructions in a way that there
    are fewer bubbles in the processor instruction pipeline. A few high-performance
    CPUs still rely on only static instruction reordering instead of out-of-order
    instruction reordering and, in turn, save chip area due to simpler design—the
    saved area is used to accommodate extra cache or CPU cores. Low-power processors,
    such as those from the ARM and Atom family, use in-order design. Unlike most CPUs,
    the modern GPUs use in-order design with deep pipelines, which is compensated
    by very fast context switching. This leads to high latency and high throughput
    on GPUs.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 良好的编译器通常对处理器有极高的了解，并且能够通过重新排列处理器指令来优化代码，从而在处理器指令流水线中减少气泡。一些高性能CPU仍然只依赖于静态指令重排而不是乱序指令重排，从而节省芯片面积——节省的面积用于容纳额外的缓存或CPU核心。低功耗处理器，如ARM和Atom系列，使用顺序设计。与大多数CPU不同，现代GPU使用具有深流水线的顺序设计，这通过非常快的上下文切换得到补偿。这导致GPU具有高延迟和高吞吐量。
- en: Threads and cores
  id: totrans-503
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 线程和核心
- en: Concurrency and parallelism via context switches, hardware threads, and cores
    are very common today and we have accepted them as a norm to implement in our
    programs. However, we should understand why we needed such a design in the first
    place. Most of the real-world code we write today does not have more than a modest
    scope for instruction-level parallelism. Even with hardware-based, out-of-order
    execution and static instruction reordering, no more than two instructions per
    cycle are truly parallel. Hence, another potential source of instructions that
    can be pipelined and executed in parallel are the programs other than the currently
    running one.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 通过上下文切换、硬件线程和核心实现并发性和并行性在当今非常普遍，并且我们已经将它们视为实现我们程序的规范。然而，我们应该理解为什么我们最初需要这样的设计。我们今天编写的绝大多数现实世界代码在指令级并行性方面没有超过适度范围。即使基于硬件的乱序执行和静态指令重排，每个周期也真正并行执行的指令不超过两个。因此，另一个潜在的指令来源是除了当前运行的程序之外的程序，这些程序可以被流水线和并行执行。
- en: The empty cycles in a pipeline can be dedicated to other running programs, which
    assume that there are other currently running programs that need the processor's
    attention. **Simultaneous multithreading** (**SMT**) is a hardware design that
    enables such kinds of parallelism. Intel implements SMT named as **HyperThreading**
    in some of its processors. While SMT presents a single physical processor as two
    or more logical processors, a true multiprocessor system executes one thread per
    processor, thus achieving simultaneous execution. A multicore processor includes
    two or more processors per chip, but has the properties of a multiprocessor system.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 管道中的空闲周期可以被分配给其他正在运行的程序，这些程序假设还有其他当前正在运行且需要处理器注意力的程序。**同时多线程**（**SMT**）是一种硬件设计，它使得这种并行成为可能。英特尔在其某些处理器中实现了名为**HyperThreading**的SMT。虽然SMT将单个物理处理器呈现为两个或更多逻辑处理器，但真正的多处理器系统每个处理器执行一个线程，从而实现同时执行。多核处理器每个芯片包含两个或更多处理器，但具有多处理器系统的特性。
- en: In general, multicore processors significantly outperform SMT processors. Performance
    on SMT processors can vary by the use case. It peaks in those cases where code
    is highly variable or threads do not compete for the same hardware resources,
    and dips when the threads are cache-bound on the same processor. What is also
    important is that some programs are simply not inherently parallel. In such cases
    it may be hard to make them go faster without the explicit use of threads in the
    program.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，多核处理器的性能显著优于SMT处理器。SMT处理器的性能可能会根据使用案例而变化。在代码高度可变或线程不竞争相同硬件资源的情况下，性能达到峰值，而当线程在相同处理器上缓存绑定时，性能则会下降。同样重要的是，有些程序本身并不是天生并行的。在这种情况下，如果没有在程序中显式使用线程，可能很难使它们运行得更快。
- en: Memory systems
  id: totrans-507
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存系统
- en: It is important to understand the memory performance characteristics to know
    the likely impact on the programs we write. Data-intensive programs that are also
    inherently parallel, such as audio/video processing and scientific computation,
    are largely limited by memory bandwidth, not by the processor. Adding processors
    would not make them faster unless the memory bandwidth is also increased. Consider
    another class of programs, such as 3D graphics rendering or database systems that
    are limited mainly by memory latency but not the memory bandwidth. SMT can be
    highly suitable for such programs, where threads do not compete for the same hardware
    resources.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 理解内存性能特性对于了解我们编写的程序可能产生的影响非常重要。数据密集型且天生并行的程序，如音频/视频处理和科学计算，主要受限于内存带宽，而不是处理器。除非增加内存带宽，否则增加处理器不会使它们更快。考虑另一类程序，如3D图形渲染或主要受限于内存延迟但不是内存带宽的数据库系统。SMT对于这类程序非常适用，在这些程序中，线程不竞争相同的硬件资源。
- en: Memory access roughly constitutes a quarter of all instructions executed by
    a processor. A code block typically begins with memory-load instructions and the
    remainder portion depends on the loaded data. This stalls the instructions and
    prevents large-scale, instruction-level parallelism. As if that was not bad enough,
    even superscalar processors (which can issue more than one instruction per clock
    cycle) can issue, at most, two memory instructions per cycle. Building fast memory
    systems is limited by natural factors such as the speed of light. It impacts the
    signal round trip to the RAM. This is a natural hard limit and any optimization
    can only work around it.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 内存访问大致占处理器执行的所有指令的四分之一。代码块通常以内存加载指令开始，其余部分取决于加载的数据。这会导致指令停滞，并防止大规模的指令级并行。更糟糕的是，即使是超标量处理器（每时钟周期可以发出多个指令）也最多只能在每个周期发出两个内存指令。构建快速内存系统受限于自然因素，如光速。它影响信号往返到RAM。这是一个自然的硬限制，任何优化都只能绕过它。
- en: Data transfer between the processor and motherboard chipset is one of the factors
    that induce memory latency. This is countered using a **faster front-side bus**
    (**FSB**). Nowadays, most modern processors fix this problem by integrating the
    memory controller directly at the chip level. The significant difference between
    the processor versus memory latencies is known as the **memory wall**. This has
    plateaued in recent times due to processor clock speeds hitting power and heat
    limits, but notwithstanding this, memory latency continues to be a significant
    problem.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器和主板芯片组之间的数据传输是导致内存延迟的因素之一。这个问题通过使用**更快的前端总线**（**FSB**）来抵消。如今，大多数现代处理器通过在芯片级别直接集成内存控制器来解决这个问题。处理器与内存延迟之间的显著差异被称为**内存墙**。由于处理器时钟速度达到功率和热量限制，近年来这一现象已经趋于平稳，但尽管如此，内存延迟仍然是一个重大问题。
- en: Unlike CPUs, GPUs typically realize a sustained high-memory bandwidth. Due to
    latency hiding, they utilize the bandwidth even during a high number-crunching
    workload.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 与CPU不同，GPU通常实现持续的高内存带宽。由于延迟隐藏，它们在高数值计算工作负载期间也利用带宽。
- en: Cache
  id: totrans-512
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**缓存**'
- en: 'To overcome the memory latency, modern processors employ a special type of
    very fast memory placed onto the processor chip or close to the chip. The purpose
    of the cache is to store the most recently used data from the memory. Caches are
    of different levels: **L1** cache is located on the processor chip; **L2** cache
    is bigger and located farther away from the processor compared to L1\. There is
    often an **L3** cache, which is even bigger and located farther from the processor
    than L2\. In Intel''s Haswell processor, the L1 cache is generally 64 kilobytes
    (32 KB instruction plus 32 KB data) in size, L2 is 256 KB per core, and L3 is
    8 MB.'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服内存延迟，现代处理器在处理器芯片上或靠近芯片的地方放置了一种非常快速的内存。缓存的目的就是存储最近使用过的内存数据。缓存有不同的级别：**L1**缓存位于处理器芯片上；**L2**缓存比L1大，且比L1远离处理器。通常还有一个**L3**缓存，它比L2更大，且比L2更远离处理器。在英特尔的Haswell处理器中，L1缓存的大小通常是64千字节（32
    KB指令加32 KB数据），L2每个核心256 KB，L3是8 MB。
- en: While memory latency is very bad, fortunately caches seem to work very well.
    The L1 cache is much faster than accessing the main memory. The reported cache
    hit rates in real-world programs is 90 percent, which makes a strong case for
    caches. A cache works like a dictionary of memory addresses to a block of data
    values. Since the value is a block of memory, the caching of adjacent memory locations
    has mostly no additional overhead. Note that L2 is slower and bigger than L1,
    and L3 is slower and bigger than L2\. On Intel Sandybridge processors, register
    lookup is instantaneous; L1 cache lookup takes three clock cycles, L2 takes nine,
    L3 takes 21, and main memory access takes 150 to 400 clock cycles.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然内存延迟非常糟糕，幸运的是缓存似乎工作得非常好。L1缓存比访问主内存要快得多。在现实世界的程序中报告的缓存命中率是90%，这为缓存提供了强有力的论据。缓存就像是一个内存地址到数据值块的字典。由于值是一块内存，因此相邻内存位置的缓存几乎没有额外的开销。请注意，L2比L1慢且大，L3比L2慢且大。在英特尔的Sandybridge处理器上，寄存器查找是瞬时的；L1缓存查找需要三个时钟周期，L2需要九个，L3需要21个，而主内存访问需要150到400个时钟周期。
- en: Interconnect
  id: totrans-515
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**互连**'
- en: 'A processor communicates with the memory and other processors via interconnect
    that are generally of two types of architecture: **Symmetric multiprocessing**
    (**SMP**) and **Non-uniform memory access** (**NUMA**). In SMP, a bus interconnects
    processors and memory with the help of bus controllers. The bus acts as a broadcast
    device for the end points. The bus often becomes a bottleneck with a large number
    of processors and memory banks. SMP systems are cheaper to build and harder to
    scale to a large number of cores compared to NUMA. In a NUMA system, collections
    of processors and memory are connected point to point to other such groups of
    processors and memory. Every such group is called a node. Local memory of a node
    is accessible by other nodes and vice versa. Intel''s **HyperTransport** and **QuickPath**
    interconnect technologies support NUMA.'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器通过两种类型的架构的互连与内存和其他处理器进行通信：**对称多处理**（**SMP**）和**非一致性内存访问**（**NUMA**）。在SMP中，总线通过总线控制器将处理器和内存互连。总线充当广播设备。当处理器和内存银行数量较多时，总线往往会成为瓶颈。与NUMA相比，SMP系统在构建成本上更低，但扩展到大量核心更困难。在NUMA系统中，处理器和内存的集合通过点到点的方式连接到其他类似的处理器和内存组。每个这样的组被称为一个节点。节点的本地内存可以被其他节点访问，反之亦然。英特尔公司的**HyperTransport**和**QuickPath**互连技术支持NUMA。
- en: Storage and networking
  id: totrans-517
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**存储和网络**'
- en: Storage and networking are the most commonly used hardware components besides
    the processor, cache, and memory. Many of the real-world applications are more
    often I/O bound than execution-bound. Such I/O technologies are continuously advancing
    and there is a wide variety of components available in the market. The consideration
    of such devices should be based on the exact performance and reliability characteristics
    for the use case. Another important criterion is to know how well they are supported
    by the target operating system drivers. Current day storage technologies mostly
    build upon hard disks and solid state drives. The applicability of network devices
    and protocols vary widely as per the business use case. A detailed discussion
    of I/O hardware is beyond the scope of this book.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 存储和网络是除了处理器、缓存和内存之外最常用的硬件组件。许多现实世界应用程序往往是 I/O 密集型而不是执行密集型。这样的 I/O 技术正在不断进步，市场上可供选择的组件种类繁多。考虑这些设备应基于具体的使用案例的性能和可靠性特征。另一个重要标准是了解它们在目标操作系统驱动程序中的支持情况。当前存储技术大多基于硬盘和固态硬盘。网络设备和协议的适用性根据业务用例而大相径庭。I/O
    硬件的详细讨论超出了本书的范围。
- en: The Java Virtual Machine
  id: totrans-519
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java 虚拟机
- en: The Java Virtual Machine is a bytecode-oriented, garbage-collected virtual machine
    that specifies its own instruction set. The instructions have equivalent bytecodes
    that are interpreted and compiled to the underlying OS and hardware by the **Java
    Runtime Environment** (**JRE**). Objects are referred to using symbolic references.
    The data types in the JVM are fully standardized as a single spec across all JVM
    implementations on all platforms and architectures. The JVM also follows the network
    byte order, which means communication between Java programs on different architectures
    can happen using the big-endian byte order. **Jvmtop** ([https://code.google.com/p/jvmtop/](https://code.google.com/p/jvmtop/))
    is a handy JVM monitoring tool similar to the top command in Unix-like systems.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: Java 虚拟机是一个以字节码为导向、具有垃圾回收功能的虚拟机，它指定了自己的指令集。指令有等效的字节码，由 **Java 运行时环境**（**JRE**）解释和编译为底层操作系统和硬件。对象通过符号引用来引用。JVM
    中的数据类型在所有平台和架构上的 JVM 实现中都是完全标准化的，作为一个单一的规范。JVM 还遵循网络字节序，这意味着在不同架构上的 Java 程序之间的通信可以使用大端字节序进行。**Jvmtop**（[https://code.google.com/p/jvmtop/](https://code.google.com/p/jvmtop/))
    是一个方便的 JVM 监控工具，类似于 Unix-like 系统中的 top 命令。
- en: The just-in-time compiler
  id: totrans-521
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 即时编译器
- en: The **just-in-time** (**JIT**) compiler is part of the JVM. When the JVM starts
    up, the JIT compiler knows hardly anything about the running code so it simply
    interprets the JVM bytecodes. As the program keeps running, the JIT compiler starts
    profiling the code by collecting statistics and analyzing the call and bytecode
    patterns. When a method call count exceeds a certain threshold, the JIT compiler
    applies a number of optimizations to the code. Most common optimizations are inlining
    and native code generating. The final and static methods and classes are great
    candidates for inlining. JIT compilation does not come without a cost; it occupies
    memory to store the profiled code and sometimes it has to revert the wrong speculative
    optimization. However, JIT compilation is almost always amortized over a long
    duration of code execution. In rare cases, turning off JIT compilation may be
    useful if either the code is too large or there are no hotspots in the code due
    to infrequent execution.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: '**即时编译器**（**JIT**）是 JVM 的一部分。当 JVM 启动时，JIT 编译器对正在运行的代码几乎一无所知，因此它只是简单地解释 JVM
    字节码。随着程序的持续运行，JIT 编译器开始通过收集统计数据和分析调用和字节码模式来分析代码。当方法调用次数超过某个阈值时，JIT 编译器会对代码应用一系列优化。最常见的优化是内联和本地代码生成。最终和静态方法和类是内联的绝佳候选者。JIT
    编译并非没有代价；它占用内存来存储分析过的代码，有时它还必须撤销错误的推测性优化。然而，JIT 编译几乎总是被长期代码执行所摊销。在罕见的情况下，如果代码太大或者由于执行频率低而没有热点，关闭
    JIT 编译可能是有用的。'
- en: 'A JRE has typically two kinds of JIT compilers: client and server. Which JIT
    compiler is used by default depends on the type of hardware and platform. The
    client JIT compiler is meant for client programs such as command-line and desktop
    applications. We can start the JRE with the `-server` option to invoke the server
    JIT compiler, which is really meant for long-running programs on a server. The
    threshold for JIT compilation is higher in the server than the client. The difference
    in the two kinds of JIT compilers is that the client targets upfront, visible
    lower latency, and the server is assumed to be running on a high-resource hardware
    and tries to optimize for throughput.'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: JRE 通常有两种类型的 JIT 编译器：客户端和服务器。默认使用哪种 JIT 编译器取决于硬件和平台类型。客户端 JIT 编译器是为客户端程序（如命令行和桌面应用程序）设计的。我们可以通过使用
    `-server` 选项启动 JRE 来调用服务器 JIT 编译器，它实际上是为服务器上运行的长运行程序设计的。服务器中 JIT 编译的阈值高于客户端。两种类型
    JIT 编译器的区别在于，客户端针对的是低延迟，而服务器假设运行在高资源硬件上，并试图优化吞吐量。
- en: The JIT compiler in the Oracle HotSpot JVM observes the code execution to determine
    the most frequently invoked methods, which are hotspots. Such hotspots are usually
    just a fraction of the entire code that can be cheap to focus on and optimize.
    The **HotSpot JIT** compiler is lazy and adaptive. It is lazy because it compiles
    only those methods to native code that have crossed a certain threshold, and not
    all the code that it encounters. Compiling to native code is a time-consuming
    process and compiling all code would be wasteful. It is adaptive to gradually
    increasing the aggressiveness of its compilation on frequently called code, which
    implies that the code is not optimized only once but many times over as the code
    gets executed repeatedly. After a method call crosses the first JIT compiler threshold,
    it is optimized and the counter is reset to zero. At the same time, the optimization
    count for the code is set to one. When the call exceeds the threshold yet again,
    the counter is reset to zero and the optimization count is incremented; and this
    time a more aggressive optimization is applied. This cycle continues until the
    code cannot be optimized anymore.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: Oracle HotSpot JVM 中的 JIT 编译器会观察代码执行以确定最频繁调用的方法，这些方法是热点。这些热点通常只是整个代码的一小部分，可以低成本地关注和优化。**HotSpot
    JIT** 编译器是懒惰和自适应的。它是懒惰的，因为它只编译那些超过一定阈值的、被调用的方法到原生代码，而不是它遇到的全部代码。编译到原生代码是一个耗时的过程，编译所有代码将是浪费的。它是自适应的，因为它会逐渐增加对频繁调用代码编译的积极性，这意味着代码不是只优化一次，而是在代码重复执行的过程中多次优化。当一个方法调用超过第一个
    JIT 编译器的阈值后，它就会被优化，计数器重置为零。同时，代码的优化计数设置为1。当调用再次超过阈值时，计数器重置为零，优化计数增加；这次应用更积极的优化。这个过程会一直持续到代码不能再被优化为止。
- en: 'The HotSpot JIT compiler does a whole bunch of optimizations. Some of the most
    prominent ones are as follows:'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: HotSpot JIT 编译器执行了许多优化。其中一些最显著的优化如下：
- en: '**Inlining**: Inlining of methods—very small methods, the static and final
    methods, methods in final classes, and small methods involving only primitive
    numerics are prime candidates for inlining.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内联**：方法内联——非常小的方法、静态和最终方法、最终类中的方法以及只涉及原始数值的小方法是最适合内联的候选者。'
- en: '**Lock elimination**: Locking is a performance overhead. Fortunately, if the
    lock object monitor is not reachable from other threads, the lock is eliminated.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**锁消除**：锁定是一个性能开销。幸运的是，如果锁对象监视器无法从其他线程访问，则可以消除锁。'
- en: '**Virtual call elimination**: Often, there is only one implementation for an
    interface in a program. The JIT compiler eliminates the virtual call and replaces
    that with a direct method call on the class implementation object.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**虚拟调用消除**：通常，程序中一个接口只有一个实现。JIT 编译器消除虚拟调用，并用类实现对象上的直接方法调用替换它。'
- en: '**Non-volatile memory write elimination**: The non-volatile data members and
    references in an object are not guaranteed to be visible by the threads other
    than the current thread. This criterion is utilized not to update such references
    in memory and rather use hardware registers or the stack via native code.'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非易失性内存写入消除**：对象中的非易失性数据成员和引用不一定能被除当前线程外的其他线程看到。这个标准被用来不在内存中更新这样的引用，而是通过原生代码使用硬件寄存器或栈。'
- en: '**Native code generation**: The JIT compiler generates native code for frequently
    invoked methods together with the arguments. The generated native code is stored
    in the code cache.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**原生代码生成**：JIT编译器为频繁调用的方法及其参数生成原生代码。生成的原生代码存储在代码缓存中。'
- en: '**Control flow and local optimizations**: The JIT compiler frequently reorders
    and splits the code for better performance. It also analyzes the branching of
    control and optimizes code based on that.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**控制流和局部优化**：JIT编译器经常重新排序和拆分代码以提高性能。它还分析控制流的分支，并根据这些分析优化代码。'
- en: There should rarely be any reason to disable JIT compilation, but it can be
    done by passing the `-Djava.compiler=NONE` parameter when starting the JRE. The
    default compile threshold can be changed by passing `-XX:CompileThreshold=9800`
    to the JRE executable where `9800` is the example threshold. The `XX:+PrintCompilation`
    and `-XX:-CITime` options make the JIT compiler print the JIT statistics and time
    spent on JIT.
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: 很少有理由禁用JIT编译，但可以通过在启动JRE时传递`-Djava.compiler=NONE`参数来实现。默认的编译阈值可以通过传递`-XX:CompileThreshold=9800`到JRE可执行文件来更改，其中`9800`是示例阈值。`XX:+PrintCompilation`和`-XX:-CITime`选项使JIT编译器打印JIT统计信息和JIT花费的时间。
- en: Memory organization
  id: totrans-533
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存组织
- en: 'The memory used by the JVM is divided into several segments. JVM, being a stack-based
    execution model, one of the memory segments is the stack area. Every thread is
    given a stack where the stack frames are stored in **Last-in-First-out** (**LIFO**)
    order. The stack includes a **program counter** (**PC**) that points to the instruction
    in the JVM memory currently being executed. When a method is called, a new stack
    frame is created containing the local variable array and the operand stack. Contrary
    to conventional stacks, the operand stack holds instructions to load local variable
    / field values and computation results—a mechanism that is also used to prepare
    method parameters before a call and to store the return value. The stack frame
    itself may be allocated on the heap. The easiest way to inspect the order of stack
    frames in the current thread is to execute the following code:'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: JVM使用的内存被划分为几个部分。作为基于栈的执行模型，JVM的一个内存段是栈区。每个线程都有一个栈，其中栈帧以**后进先出**（**LIFO**）的顺序存储。栈包括一个**程序计数器**（**PC**），它指向JVM内存中当前正在执行的指令。当调用一个方法时，会创建一个新的栈帧，其中包含局部变量数组和操作数栈。与传统栈不同，操作数栈包含加载局部变量/字段值和计算结果的指令——这种机制也用于在调用之前准备方法参数以及存储返回值。栈帧本身可能分配在堆上。要检查当前线程中栈帧的顺序，最简单的方法是执行以下代码：
- en: '[PRE59]'
  id: totrans-535
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: When a thread requires more stack space than what the JVM can provide, `StackOverflowError`
    is thrown.
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 当线程需要的栈空间超过JVM能提供的空间时，会抛出`StackOverflowError`。
- en: The heap is the main memory area where the object and array allocations are
    done. It is shared across all JVM threads. The heap may be of a fixed size or
    expanding, depending on the arguments passed to the JRE on startup. Trying to
    allocate more heap space than what the JVM can make room for results in `OutOfMemoryError`
    to be thrown. The allocations in the heap are subject to garbage collection. When
    an object is no more reachable via any reference, it is garbage collected, with
    the notable exception of weak, soft, and phantom references. Objects pointed to
    by non-strong references take longer to GC.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 堆是对象和数组分配的主要内存区域，它被所有JVM线程共享。堆的大小可能是固定的或可扩展的，这取决于启动JRE时传递的参数。尝试分配比JVM能提供的空间更多的堆空间会导致抛出`OutOfMemoryError`。堆上的分配受垃圾回收的影响。当一个对象不再通过任何引用可达时，它将被垃圾回收，值得注意的是，弱、软和虚引用除外。由非强引用指向的对象在GC（垃圾回收）中花费的时间更长。
- en: The method area is logically a part of the heap memory and contains per-class
    structures such as the field and method information, runtime constant pool, code
    for method, and constructor bodies. It is shared across all JVM threads. In the
    Oracle HotSpot JVM (up to Version 7), the method area is found in a memory area
    called the **permanent generation**. In HotSpot Java 8, the permanent generation
    is replaced by a native memory area called **Metaspace**.
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 方法区在逻辑上是堆内存的一部分，包含诸如字段和方法信息、运行时常量池、方法代码和构造函数体等类结构。它是所有JVM线程共享的。在Oracle HotSpot
    JVM（至版本7）中，方法区位于一个称为**永久代**的内存区域。在HotSpot Java 8中，永久代被一个称为**元空间**的本地内存区域所取代。
- en: '![Memory organization](img/3642_04_01.jpg)'
  id: totrans-539
  prefs: []
  type: TYPE_IMG
  zh: '![内存组织](img/3642_04_01.jpg)'
- en: The JVM contains the native code and the Java bytecode to be provided to the
    Java API implementation and the JVM implementation. The native code call stack
    is maintained separately for each thread stack. The JVM stack contains the Java
    method calls. Please note that the JVM spec for Java SE 7 and 8 does not imply
    a native method stack, but for Java SE 5 and 6, it does.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: JVM 包含了提供给 Java API 实现和 JVM 实现的本地代码和 Java 字节码。每个线程堆栈维护一个独立的本地代码调用栈。JVM 堆栈包含
    Java 方法调用。请注意，Java SE 7 和 8 的 JVM 规范并不暗示存在本地方法栈，但对于 Java SE 5 和 6，则存在。
- en: HotSpot heap and garbage collection
  id: totrans-541
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HotSpot 堆和垃圾回收
- en: The Oracle HotSpot JVM uses a generational heap. The three main generations
    are **Young**, **Tenured** (old), and **Perm** (permanent) (up to HotSpot JDK
    1.7 only). As objects survive garbage collection, they move from **Eden** to **Survivor**
    and from **Survivor** to **Tenured** spaces. The new instances are allocated in
    the **Eden** segment, which is a very cheap operation (as cheap as a pointer bump,
    and faster than a C `malloc` call), if it already has sufficient free space. When
    the Eden area does not have enough free space, a minor GC is triggered. This copies
    the live objects from **Eden** into the **Survivor** space. In the same operation,
    live objects are checked in **Survivor-1** and copied over to **Survivor-2**,
    thus keeping the live objects only in **Survivor-2**. This scheme keeps **Eden**
    and **Survivor-1** empty and unfragmented to make new allocations, and is known
    as **copy collection**.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: Oracle HotSpot JVM 使用代际堆。三个主要代是 **年轻**、**持久**（旧）和 **永久**（仅限于 HotSpot JDK 1.7）。随着对象在垃圾回收中存活，它们从
    **伊甸园**移动到 **幸存者**，再从 **幸存者**移动到 **持久**空间。新实例在 **伊甸园**段分配，这是一个非常便宜的操作（和指针增加一样便宜，比
    C 的 `malloc` 调用更快），如果它已经有足够的空闲空间。当伊甸园区域没有足够的空闲空间时，会触发一次小垃圾回收。这次操作会将 **伊甸园**中的活动对象复制到
    **幸存者**空间。在相同操作中，活动对象在 **幸存者-1**中检查，并复制到 **幸存者-2**，从而只保留 **幸存者-2**中的活动对象。这种方案保持
    **伊甸园**和 **幸存者-1**为空且无碎片，以便进行新的分配，这被称为 **复制收集**。
- en: '![HotSpot heap and garbage collection](img/3642_04_02.jpg)'
  id: totrans-543
  prefs: []
  type: TYPE_IMG
  zh: '![HotSpot 堆和垃圾回收](img/3642_04_02.jpg)'
- en: 'After a certain survival threshold in the young generation, the objects are
    moved to the tenured/old generation. If it is not possible to do a minor GC, a
    major GC is attempted. The major GC does not use copying, but rather relies on
    mark-and-sweep algorithms. We can use throughput collectors (**Serial**, **Parallel**,
    and **ParallelOld**) or low-pause collectors (**Concurrent** and **G1**) for the
    old generation. The following table shows a non-exhaustive list of options to
    be used for each collector type:'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 在年轻代达到一定的存活阈值后，对象会被移动到持久/旧代。如果无法进行小垃圾回收，则会尝试进行大垃圾回收。大垃圾回收不使用复制，而是依赖于标记-清除算法。我们可以使用吞吐量收集器（**序列**、**并行**和
    **并行老**）或低延迟收集器（**并发**和 **G1**）来处理旧代。以下表格显示了一个非详尽的选项列表，用于每个收集器类型：
- en: '| Collector name | JVM flag |'
  id: totrans-545
  prefs: []
  type: TYPE_TB
  zh: '| 收集器名称 | JVM 标志 |'
- en: '| --- | --- |'
  id: totrans-546
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Serial | -XX:+UseSerialGC |'
  id: totrans-547
  prefs: []
  type: TYPE_TB
  zh: '| 序列 | -XX:+UseSerialGC |'
- en: '| Parallel | -XX:+UseParallelGC |'
  id: totrans-548
  prefs: []
  type: TYPE_TB
  zh: '| 并行 | -XX:+UseParallelGC |'
- en: '| Parallel Compacting | -XX:+UseParallelOldGC |'
  id: totrans-549
  prefs: []
  type: TYPE_TB
  zh: '| 并行压缩 | -XX:+UseParallelOldGC |'
- en: '| Concurrent | -XX:+UseConcMarkSweepGC-XX:+UseParNewGC-XX:+CMSParallelRemarkEnabled
    |'
  id: totrans-550
  prefs: []
  type: TYPE_TB
  zh: '| 并发 | -XX:+UseConcMarkSweepGC-XX:+UseParNewGC-XX:+CMSParallelRemarkEnabled
    |'
- en: '| G1 | -XX:+UseG1GC |'
  id: totrans-551
  prefs: []
  type: TYPE_TB
  zh: '| G1 | -XX:+UseG1GC |'
- en: 'The previously mentioned flags can be used to start the Java runtime. For example,
    in the following command, we start the server JVM with a 4 GB heap using Parallel
    compacting GC:'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 之前提到的标志可以用来启动 Java 运行时。例如，在以下命令中，我们使用并行压缩垃圾回收器启动具有 4 GB 堆的服务器 JVM：
- en: '[PRE60]'
  id: totrans-553
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Sometimes, due to running full GC multiple times, the tenured space may have
    become so fragmented that it may not be feasible to move objects from Survivor
    to Tenured spaces. In those cases, a full GC with compaction is triggered. During
    this period, the application may appear unresponsive due to the full GC in action.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，由于多次运行完全垃圾回收，持久空间可能变得非常碎片化，以至于可能无法将对象从幸存者空间移动到持久空间。在这些情况下，会触发带有压缩的完全垃圾回收。在此期间，由于完全垃圾回收正在进行，应用程序可能看起来没有响应。
- en: Measuring memory (heap/stack) usage
  id: totrans-555
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测量内存（堆/栈）使用情况
- en: One of the prime reasons for a performance hit in the JVM is garbage collection.
    It certainly helps to know how heap memory is used by the objects we create and
    how to reduce the impact on GC by means of a lower footprint. Let's inspect how
    the representation of an object may lead to heap space.
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: JVM 性能下降的一个主要原因是垃圾回收。当然，了解我们创建的对象如何使用堆内存以及如何通过降低足迹来减少对垃圾回收的影响是很有帮助的。让我们检查对象表示如何导致堆空间。
- en: 'Every (uncompressed) object or array reference on a 64-bit JVM is 16 bytes
    long. On a 32-bit JVM, every reference is 8 bytes long. As the 64-bit architecture
    is becoming more commonplace now, the 64-bit JVM is more likely to be used on
    servers. Fortunately, for a heap size of up to 32 GB, the JVM (Java 7) can use
    compressed pointers (default behavior) that are only 4 bytes in size. Java 8 VMs
    can address up to 64 GB heap size via compressed pointers as seen in the following
    table:'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 在64位JVM上，每个（未压缩的）对象或数组引用都是16字节长。在32位JVM上，每个引用都是8字节长。由于64位架构现在越来越普遍，64位JVM更有可能在服务器上使用。幸运的是，对于高达32GB的堆大小，JVM（Java
    7）可以使用压缩指针（默认行为），其大小仅为4字节。Java 8虚拟机可以通过压缩指针访问高达64GB的堆大小，如下表所示：
- en: '|   | Uncompressed | Compressed | 32-bit |'
  id: totrans-558
  prefs: []
  type: TYPE_TB
  zh: '|   | 未压缩 | 压缩 | 32 位 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-559
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Reference (pointer) | 8 | 4 | 4 |'
  id: totrans-560
  prefs: []
  type: TYPE_TB
  zh: '| 引用（指针） | 8 | 4 | 4 |'
- en: '| Object header | 16 | 12 | 8 |'
  id: totrans-561
  prefs: []
  type: TYPE_TB
  zh: '| 对象头部 | 16 | 12 | 8 |'
- en: '| Array header | 24 | 16 | 12 |'
  id: totrans-562
  prefs: []
  type: TYPE_TB
  zh: '| 数组头部 | 24 | 16 | 12 |'
- en: '| Superclass padding | 8 | 4 | 4 |'
  id: totrans-563
  prefs: []
  type: TYPE_TB
  zh: '| 超类填充 | 8 | 4 | 4 |'
- en: 'This table illustrates pointer sizes in different modes (reproduced with permission
    from Attila Szegedi: [http://www.slideshare.net/aszegedi/everything-i-ever-learned-about-jvm-performance-tuning-twitter/20](http://www.slideshare.net/aszegedi/everything-i-ever-learned-about-jvm-performance-tuning-twitter/20)).'
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 此表说明了不同模式下的指针大小（经Attila Szegedi许可复制：[http://www.slideshare.net/aszegedi/everything-i-ever-learned-about-jvm-performance-tuning-twitter/20](http://www.slideshare.net/aszegedi/everything-i-ever-learned-about-jvm-performance-tuning-twitter/20))。
- en: 'We saw in the previous chapter how many bytes each primitive type takes. Let''s
    see how the memory consumption of the composite types looks with compressed pointers
    (a common case) on a 64-bit JVM with a heap size smaller than 32 GB:'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中，我们看到了每种原始类型占用多少字节。让我们看看在压缩指针（常见情况）下，64位JVM（堆大小小于32GB）中复合类型的内存消耗情况：
- en: '| Java Expression | 64-bit memory usage | Description (b = bytes, padding toward
    memory word size in approximate multiples of 8) |'
  id: totrans-566
  prefs: []
  type: TYPE_TB
  zh: '| Java 表达式 | 64 位内存使用 | 描述（b = 字节，内存字大小的8的倍数近似值）|'
- en: '| --- | --- | --- |'
  id: totrans-567
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `new Object()` | 16 bytes | 12 b header + 4 b padding |'
  id: totrans-568
  prefs: []
  type: TYPE_TB
  zh: '| `new Object()` | 16 字节 | 12 字节头部 + 4 字节填充 |'
- en: '| `new byte[0]` | 16 bytes | 12 b `obj` header + 4 b `int` length = 16 b array
    header |'
  id: totrans-569
  prefs: []
  type: TYPE_TB
  zh: '| `new byte[0]` | 16 字节 | 12 字节 `obj` 头部 + 4 字节 `int` 长度 = 16 字节数组头部 |'
- en: '| `new String("foo")` | 40 bytes (interned for literals) | 12 b header + (12
    b array header + 6 b char-array content + 4 b length + 2 b padding = 24 b) + 4
    b hash |'
  id: totrans-570
  prefs: []
  type: TYPE_TB
  zh: '| `new String("foo")` | 40 字节（内部化字面量）| 12 字节头部 + (12 字节数组头部 + 6 字节字符数组内容 +
    4 字节长度 + 2 字节填充 = 24 字节) + 4 字节哈希 |'
- en: '| `new Integer(3)` | 16 bytes (boxed integer) | 12 b header + 4 b `int` value
    |'
  id: totrans-571
  prefs: []
  type: TYPE_TB
  zh: '| `new Integer(3)` | 16 字节（装箱的整型）| 12 字节头部 + 4 字节 `int` 值 |'
- en: '| `new Long(4)` | 24 bytes (boxed long) | 12 b header + 8 b `long` value +
    4 b padding |'
  id: totrans-572
  prefs: []
  type: TYPE_TB
  zh: '| `new Long(4)` | 24 字节（装箱的长整型）| 12 字节头部 + 8 字节 `long` 值 + 4 字节填充 |'
- en: '| `class A { byte x; }``new A();` | 16 bytes | 12 b header + 1 b value + 3
    b padding |'
  id: totrans-573
  prefs: []
  type: TYPE_TB
  zh: '| `class A { byte x; }``new A();` | 16 字节 | 12 字节头部 + 1 字节值 + 3 字节填充 |'
- en: '| `class B extends A {byte y;}``new B();` | 24 bytes (subclass padding) | 12
    b reference + (1 b value + 7 b padding = 8 b) for A + 1 b for value of `y` + 3
    b padding |'
  id: totrans-574
  prefs: []
  type: TYPE_TB
  zh: '| `class B extends A {byte y;}``new B();` | 24 字节（子类填充）| 12 字节引用 + (1 字节值 +
    7 字节填充 = 8 字节) 用于A + 1 字节用于 `y` 的值 + 3 字节填充 |'
- en: '| `clojure.lang.Symbol.intern("foo")``// clojure ''foo` | 104 bytes (40 bytes
    interned) | 12 b header + 12 b ns reference + (12 b name reference + 40 b interned
    chars) + 4 b `int` hash + 12 b meta reference + (12 b `_str` reference + 40 b
    interned chars) – 40 b interned `str` |'
  id: totrans-575
  prefs: []
  type: TYPE_TB
  zh: '| `clojure.lang.Symbol.intern("foo")``// clojure ''foo` | 104 字节（40字节内部化）|
    12 字节头部 + 12 字节命名空间引用 + (12 字节名称引用 + 40 字节内部化字符) + 4 字节 `int` 哈希 + 12 字节元数据引用
    + (12 字节 `_str` 引用 + 40 字节内部化字符) - 40 字节内部化 `str` |'
- en: '| `clojure.lang.Keyword.intern("foo")``// clojure :foo` | 184 bytes (fully
    interned by factory method) | 12 b reference + (12 b symbol reference + 104 b
    interned value) + 4 b `int` hash + (12 b `_str` reference + 40 b interned `char`)
    |'
  id: totrans-576
  prefs: []
  type: TYPE_TB
  zh: '| `clojure.lang.Keyword.intern("foo")``// clojure :foo` | 184 字节（由工厂方法完全内部化）|
    12 字节引用 + (12 字节符号引用 + 104 字节内部化值) + 4 字节 `int` 哈希 + (12 字节 `_str` 引用 + 40 字节内部化
    `char`) |'
- en: A comparison of space taken by a symbol and a keyword created from the same
    given string demonstrates that even though a keyword has slight overhead over
    a symbol, the keyword is fully interned and would provide better guard against
    memory consumption and thus GC over time. Moreover, the keyword is interned as
    a weak reference, which ensures that it is garbage collected when no keyword in
    memory is pointing to the interned value anymore.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 通过比较由同一给定字符串创建的符号和关键字所占用的空间，可以证明尽管关键字相对于符号有轻微的开销，但关键字是完全内部化的，这将提供更好的内存消耗和随时间进行的垃圾回收保护。此外，关键字作为弱引用进行内部化，这确保了当内存中没有关键字指向内部化值时，它将被垃圾回收。
- en: Determining program workload type
  id: totrans-578
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 确定程序工作负载类型
- en: We often need to determine whether a program is CPU/cache bound, memory bound,
    I/O bound or contention bound. When a program is I/O or contention bound, the
    CPU usage is generally low. You may have to use a profiler (we will see this in
    [Chapter 7](ch14.html "Chapter 7. Performance Optimization"), *Performance Optimization*)
    to find out whether threads are stuck due to resource contention. When a program
    is CPU/cache or memory bound, CPU usage may not be a clear indicator of the source
    of the bottleneck. In such cases, you may want to make an educated guess by inspecting
    cache misses in the program. On Linux systems tools such as **perf** ([https://perf.wiki.kernel.org/](https://perf.wiki.kernel.org/)),
    **cachegrind** ([http://valgrind.org/info/tools.html#cachegrind](http://valgrind.org/info/tools.html#cachegrind))
    and **oprofile** ([http://oprofile.sourceforge.net/](http://oprofile.sourceforge.net/))
    can help determine the volume of cache misses—a higher threshold may imply that
    the program is memory bound. However, using these tools with Java is not straightforward
    because Java's JIT compiler needs a warm-up until meaningful behavior can be observed.
    The project **perf-map-agent** ([https://github.com/jrudolph/perf-map-agent](https://github.com/jrudolph/perf-map-agent))
    can help generate method mappings that you can correlate using the `perf` utility.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常需要确定程序是CPU/缓存绑定、内存绑定、I/O绑定还是竞争绑定。当一个程序是I/O或竞争绑定时，CPU使用率通常较低。你可能需要使用分析器（我们将在第7章[性能优化](ch14.html
    "第7章。性能优化")中看到，*性能优化*)来确定线程是否因为资源竞争而陷入停滞。当一个程序是CPU/缓存或内存绑定时，CPU使用率可能不是瓶颈来源的明确指标。在这种情况下，你可能想要通过检查程序中的缓存缺失来进行有根据的猜测。在Linux系统上，工具如**perf**
    ([https://perf.wiki.kernel.org/](https://perf.wiki.kernel.org/))、**cachegrind**
    ([http://valgrind.org/info/tools.html#cachegrind](http://valgrind.org/info/tools.html#cachegrind))和**oprofile**
    ([http://oprofile.sourceforge.net/](http://oprofile.sourceforge.net/))可以帮助确定缓存缺失的数量——更高的阈值可能意味着程序是内存绑定的。然而，由于Java的JIT编译器需要预热才能观察到有意义的行为，因此使用这些工具与Java结合并不简单。项目**perf-map-agent**
    ([https://github.com/jrudolph/perf-map-agent](https://github.com/jrudolph/perf-map-agent))可以帮助生成你可以使用`perf`实用程序关联的方法映射。
- en: Tackling memory inefficiency
  id: totrans-580
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决内存效率低下问题
- en: 'In earlier sections in this chapter we discussed that unchecked memory access
    may become a bottleneck. As of Java 8, due to the way the heap and object references
    work, we cannot fully control the object layout and memory access patterns. However,
    we can take care of the frequently executed blocks of code to consume less memory
    and attempt to make them cache-bound instead of memory-bound at runtime. We can
    consider a few techniques to lower memory consumption and randomness in access:'
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章前面的部分，我们讨论了未经检查的内存访问可能成为瓶颈。截至Java 8，由于堆和对象引用的工作方式，我们无法完全控制对象布局和内存访问模式。然而，我们可以关注频繁执行的代码块，以减少内存消耗，并尝试在运行时使它们成为缓存绑定而不是内存绑定。我们可以考虑一些降低内存消耗和访问随机性的技术：
- en: Primitive locals (long, double, boolean, char, etc) in the JVM are created on
    the stack. The rest of the objects are created on the heap and only their references
    are stored in the stack. Primitives have a low overhead and do not require memory
    indirection for access, and are hence recommended.
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JVM中的原始本地变量（如long、double、boolean、char等）是在栈上创建的。其余的对象是在堆上创建的，并且只有它们的引用存储在栈上。原始变量具有较低的开销，并且不需要内存间接访问来访问，因此推荐使用。
- en: Data laid out in the main memory in a sequential fashion is faster to access
    than randomly laid out data. When we use a large (say more than eight elements)
    persistent map, the data stored in tries may not be sequentially laid out in memory,
    rather they would be randomly laid out in the heap. Moreover both keys and values
    are stored and accessed. When you use records (`defrecord`) and types (`deftype`),
    not only do they provide array/class semantics for the layout of fields within
    them, they do not store the keys, which is very efficient compared to regular
    maps.
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以顺序方式在主内存中布局的数据比随机布局的数据访问更快。当我们使用一个大的（比如说超过八个元素）持久映射时，存储在tries中的数据可能不会在内存中顺序布局，而是在堆中随机布局。此外，键和值都会被存储和访问。当你使用记录（`defrecord`）和类型（`deftype`）时，它们不仅为它们内部的字段布局提供数组/类语义，而且它们不存储键，与常规映射相比，这非常高效。
- en: Reading large content from a disk or the network may have an adverse impact
    on performance due to random memory roundtrips. In [Chapter 3](ch10.html "Chapter 3. Leaning
    on Java"), *Leaning on Java*, we briefly discussed memory-mapped byte buffers.
    You can leverage memory-mapped buffers to minimize fragmented object allocation/access
    on the heap. While libraries such as `nio` ([https://github.com/pjstadig/nio/](https://github.com/pjstadig/nio/))
    and `clj-mmap` ([https://github.com/thebusby/clj-mmap](https://github.com/thebusby/clj-mmap))
    help us deal with memory-mapped buffers, `bytebuffer` ([https://github.com/geoffsalmon/bytebuffer](https://github.com/geoffsalmon/bytebuffer)),
    and `gloss` ([https://github.com/ztellman/gloss](https://github.com/ztellman/gloss))
    let us work with byte buffers. There are also alternate abstractions such as iota
    ([https://github.com/thebusby/iota](https://github.com/thebusby/iota)) that help
    us deal with large files as collections.
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从磁盘或网络读取大量内容可能会由于随机内存往返而对性能产生不利影响。在[第3章](ch10.html "第3章。依赖Java")《依赖Java》中，我们简要讨论了内存映射字节数组缓冲区。你可以利用内存映射缓冲区来最小化堆上的碎片化对象分配/访问。虽然像`nio`([https://github.com/pjstadig/nio/](https://github.com/pjstadig/nio/))和`clj-mmap`([https://github.com/thebusby/clj-mmap](https://github.com/thebusby/clj-mmap))这样的库帮助我们处理内存映射缓冲区，`bytebuffer`([https://github.com/geoffsalmon/bytebuffer](https://github.com/geoffsalmon/bytebuffer))和`gloss`([https://github.com/ztellman/gloss](https://github.com/ztellman/gloss))则让我们能够处理字节数组缓冲区。还有其他抽象，如iota([https://github.com/thebusby/iota](https://github.com/thebusby/iota))，它帮助我们以集合的形式处理大文件。
- en: Given that memory bottleneck is a potential performance issue in data-intensive
    programs, lowering memory overhead goes a long way in avoiding performance risk.
    Understanding low-level details of the hardware, the JVM and Clojure's implementation
    helps us choose the appropriate techniques to tackle the memory bottleneck issue.
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 由于内存瓶颈是数据密集型程序中潜在的性能问题，降低内存开销在很大程度上有助于避免性能风险。了解硬件、JVM和Clojure实现的低级细节有助于我们选择适当的技巧来解决内存瓶颈问题。
- en: Measuring latency with Criterium
  id: totrans-586
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Criterium测量延迟
- en: 'Clojure has a neat little macro called `time` that evaluates the body of code
    passed to it, and then prints out the time it took and simply returns the value.
    However, we can note that often the time taken to execute the code varies quite
    a bit across various runs:'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure有一个叫做`time`的小巧的宏，它会评估传递给它的代码的主体，然后打印出所花费的时间，并简单地返回值。然而，我们可以注意到，执行代码所需的时间在不同的运行中变化很大：
- en: '[PRE61]'
  id: totrans-588
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: There are several reasons associated to this variance in behavior. When cold
    started, the JVM has its heap segments empty and is unaware of the code path.
    As the JVM keeps running, the heap fills up and the GC patterns start becoming
    noticeable. The JIT compiler gets a chance to profile the different code paths
    and optimize them. Only after quite some GC and JIT compilation rounds, does the
    JVM performance become less unpredictable.
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 与此行为差异相关的有几个原因。当JVM冷启动时，其堆段为空，并且对代码路径一无所知。随着JVM的持续运行，堆开始填满，GC模式开始变得明显。JIT编译器有机会分析不同的代码路径并进行优化。只有在经过相当多的GC和JIT编译轮次之后，JVM的性能才变得不那么不可预测。
- en: 'Criterium ([https://github.com/hugoduncan/criterium](https://github.com/hugoduncan/criterium))
    is a Clojure library to scientifically measure the latency of Clojure expressions
    on a machine. A summary of how it works can be found at the Criterium project
    page. The easiest way to use Criterium is to use it with Leiningen. If you want
    Criterium to be available only in the REPL and not as a project dependency, add
    the following entry to the `~/.lein/profiles.clj` file:'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: Criterium ([https://github.com/hugoduncan/criterium](https://github.com/hugoduncan/criterium))
    是一个Clojure库，用于在机器上科学地测量Clojure表达式的延迟。关于其工作原理的摘要可以在Criterium项目页面上找到。使用Criterium最简单的方法是使用Leiningen。如果你只想在REPL中使用Criterium，而不是将其作为项目依赖项，请将以下条目添加到`~/.lein/profiles.clj`文件中：
- en: '[PRE62]'
  id: totrans-591
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Another way is to include `criterium` in your project in the `project.clj`
    file:'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是在`project.clj`文件中包含`criterium`：
- en: '[PRE63]'
  id: totrans-593
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Once done with the editing of the file, launch REPL using `lein repl`:'
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 完成文件编辑后，使用`lein repl`启动REPL：
- en: '[PRE64]'
  id: totrans-595
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Now, we can see that, on average, the expression took 31.6 ms on a certain test
    machine.
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以看到，在某个测试机器上，平均而言，该表达式花费了31.6毫秒。
- en: Criterium and Leiningen
  id: totrans-597
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Criterium和Leiningen
- en: 'By default, Leiningen starts the JVM in a low-tiered compilation mode, which
    causes it to start up faster but impacts the optimizations that the JRE can perform
    at runtime. To get the best effects when running tests with Criterium and Leiningen
    for a server-side use case, be sure to override the defaults in `project.clj`
    as follows:'
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Leiningen以低级编译模式启动JVM，这导致它启动更快，但会影响JRE在运行时可以执行的优化。为了在服务器端用例中使用Criterium和Leiningen进行测试时获得最佳效果，请确保在`project.clj`中覆盖默认设置，如下所示：
- en: '[PRE65]'
  id: totrans-599
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: The `^:replace` hint causes Leiningen to replace its own defaults with what
    is provided under the `:jvm-opts` key. You may like to add more parameters as
    needed, such as a minimum and maximum heap size to run the tests.
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: '`^:replace`提示使Leiningen用`:jvm-opts`键下提供的值替换其默认设置。你可能需要根据需要添加更多参数，例如运行测试的最小和最大堆大小。'
- en: Summary
  id: totrans-601
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: The performance of a software system is directly impacted by its hardware components,
    so understanding how the hardware works is crucial. The processor, caches, memory,
    and I/O subsystems have different performance behaviors. Clojure, being a hosted
    language, understanding the performance properties of the host, that is, the JVM,
    is equally important. The Criterium library is useful for measuring the latency
    of the Clojure code—we will discuss Criterium again in [Chapter 6](ch13.html "Chapter 6. Measuring
    Performance"), *Measuring Performance*. In the next chapter we will look at the
    concurrency primitives in Clojure and their performance characteristics.
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 软件系统的性能直接受其硬件组件的影响，因此了解硬件的工作原理至关重要。处理器、缓存、内存和I/O子系统具有不同的性能行为。Clojure作为一种托管语言，理解宿主（即JVM）的性能特性同样重要。Criterium库用于测量Clojure代码的延迟——我们将在第6章[测量性能](ch13.html
    "Chapter 6. Measuring Performance")中再次讨论Criterium。在下一章中，我们将探讨Clojure中的并发原语及其性能特性。
- en: Chapter 5. Concurrency
  id: totrans-603
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章. 并发
- en: 'Concurrency was one of the chief design goals of Clojure. Considering the concurrent
    programming model in Java (the comparison with Java is due to it being the predominant
    language on the JVM), it is not only too low level, but rather tricky to get right
    that without strictly following the patterns, one is more likely to shoot oneself
    in the foot. Locks, synchronization, and unguarded mutation are recipes for the
    concurrency pitfalls, unless exercised with extreme caution. Clojure''s design
    choices deeply influence the way in which the concurrency patterns can be achieved
    in a safe and functional manner. In this chapter, we will discuss:'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: 并发是Clojure的主要设计目标之一。考虑到Java的并发编程模型（与Java的比较是因为它是JVM上的主导语言），它不仅太低级，而且如果不严格遵循模式，很容易出错，甚至可能自食其果。锁、同步和无保护变异是并发陷阱的配方，除非极端谨慎地使用。Clojure的设计选择深刻影响了以安全和函数式方式实现并发模式的方式。在本章中，我们将讨论：
- en: The low level concurrency support at the hardware and JVM level
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 硬件和JVM级别的低级并发支持
- en: The concurrency primitives of Clojure—atoms, agents, refs and vars
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Clojure的并发原语——原子、代理、refs和vars
- en: The built-in concurrency that features in Java safe, and its usefulness with
    Clojure
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java内置的并发特性是安全的，并且与Clojure一起使用很有用
- en: Parallelization with the Clojure features and reducers
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Clojure特性和reducers进行并行化
- en: Low-level concurrency
  id: totrans-609
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 低级并发
- en: Concurrency cannot be achieved without explicit hardware support. We discussed
    about SMT and the multi-core processors in the previous chapters. Recall that
    every processor core has its own L1 cache, and several cores share the L2 cache.
    The shared L2 cache provides a fast mechanism to the processor cores to coordinate
    their cache access, eliminating the comparatively expensive memory access. Additionally,
    a processor buffers the writes to memory into something known as a **dirty write-buffer**.
    This helps the processor to issue a batch of memory update requests, reorder the
    instructions, and determine the final value to write to memory, known as **write
    absorption**.
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: 没有显式的硬件支持，无法实现并发。我们在前几章讨论了SMT和多核处理器。回想一下，每个处理器核心都有自己的L1缓存，几个核心共享L2缓存。共享的L2缓存为处理器核心提供了一个快速机制来协调它们的缓存访问，消除了相对昂贵的内存访问。此外，处理器将写入内存的操作缓冲到一个称为**脏写缓冲区**的东西中。这有助于处理器发布一系列内存更新请求，重新排序指令，并确定写入内存的最终值，称为**写吸收**。
- en: Hardware memory barrier (fence) instructions
  id: totrans-611
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 硬件内存屏障（fence）指令
- en: Memory access reordering is great for a sequential (single-threaded) program
    performance, but it is hazardous for the concurrent programs where the order of
    memory access in one thread may disrupt the expectations in another thread. The
    processor needs the means of synchronizing the access in such a way that memory
    reordering is either compartmentalized in code segments that do not care, or is
    prevented where it might have undesirable consequences. The hardware supports
    such a safety measure in terms of a "memory barrier" (also known as "fence").
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: 内存访问重排序对于顺序（单线程）程序性能很有用，但对于并发程序来说却很危险，因为一个线程中内存访问的顺序可能会破坏另一个线程的预期。处理器需要同步访问的手段，以便内存重排序要么被限制在代码段中，这些代码段不关心，要么在可能产生不良后果的地方被阻止。硬件通过“内存屏障”（也称为“fence”）提供这种安全措施。
- en: There are several kinds of memory barrier instructions found in different architectures,
    with potentially different performance characteristics. The compiler (or the JIT
    compiler in the case of the JVM) usually knows about the fence instructions on
    the architectures that it runs on. The common fence instructions are read, write,
    acquire, and release barrier, and more. The barriers do not guarantee the latest
    data, rather they only control the relative ordering of memory access. Barriers
    cause the write-buffer to be flushed after all the writes are issued, before the
    barrier is visible to the processor that issued it.
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同的架构中发现了多种内存屏障指令，具有不同的性能特征。编译器（或JVM中的JIT编译器）通常了解它在上面运行的架构上的fence指令。常见的fence指令有读、写、获取和释放屏障等。屏障不保证最新的数据，而是只控制内存访问的相对顺序。屏障导致在屏障对发出它的处理器可见之前，将写缓冲区刷新完毕。
- en: Read and write barriers control the order of reads and writes respectively.
    Writes happen via a write-buffer; but reads may happen out of order, or from the
    write-buffer. To guarantee the correct ordering, acquire, and release, blocks/barriers
    are used. Acquire and release are considered "half barriers"; both of them together
    (acquire and release) form a "full barrier". A full barrier is more expensive
    than a half barrier.
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 读写屏障分别控制读和写的顺序。写操作通过写缓冲区进行；但读操作可能发生顺序混乱，或者来自写缓冲区。为了保证正确的顺序，使用获取和释放块/屏障。获取和释放被认为是“半屏障”；两者结合（获取和释放）形成一个“全屏障”。全屏障比半屏障更昂贵。
- en: Java support and the Clojure equivalent
  id: totrans-615
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Java支持和Clojure的等效功能
- en: 'In Java, the memory barrier instructions are inserted by the higher level coordination
    primitives. Even though fence instructions are expensive (hundreds of cycles)
    to run, they provide a safety net that makes accessing shared variables safe within
    the critical sections. In Java, the `synchronized` keyword marks a "critical section",
    which can be executed by only one thread at a time, thus making is a tool for
    "mutual exclusion". In Clojure, the equivalent of Java''s `synchronized` is the
    `locking` macro:'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: 在Java中，内存屏障指令是通过高级协调原语插入的。尽管fence指令的运行成本很高（数百个周期），但它们提供了一个安全网，使得在关键部分内访问共享变量是安全的。在Java中，`synchronized`关键字标记一个“关键部分”，一次只能由一个线程执行，因此它是一个“互斥”工具。在Clojure中，Java的`synchronized`的等价物是`locking`宏：
- en: '[PRE66]'
  id: totrans-617
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: The `locking` macro builds upon two special forms, `monitor-enter` and `monitor-exit`.
    Note that the `locking` macro is a low-level and imperative solution just like
    Java's `synchronized` – their use is not considered idiomatic Clojure. The special
    forms `monitor-enter` and `monitor-exit` respectively enter and exit the lock
    object's "monitor" – they are even lower level and not recommended for direct
    use.
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: '`locking` 宏建立在两个特殊形式 `monitor-enter` 和 `monitor-exit` 之上。请注意，`locking` 宏是一个低级和命令式的解决方案，就像
    Java 的 `synchronized` 一样——它们的使用不被认为是 Clojure 的惯用法。特殊形式 `monitor-enter` 和 `monitor-exit`
    分别进入和退出锁对象的“监视器”——它们甚至更低级，不建议直接使用。'
- en: Someone measuring the performance of the code that uses such locking should
    be aware of its single-threaded versus the multi-threaded latencies. Locking in
    a single thread is cheap. However, the performance penalty starts kicking in when
    there are two or more threads contending for a lock on the same object monitor.
    A lock is acquired on the monitor of an object called the "intrinsic" or "monitor"
    lock. Object equivalence (that is, when the `=` function returns as true) is never
    used for the purpose of locking. Make sure that the object references are the
    same (that is, when `identical?` returns as true) when locking from different
    threads.
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: 测量使用此类锁定代码的性能的人应该意识到其单线程与多线程延迟之间的差异。在单个线程中锁定是廉价的。然而，当有两个或更多线程争夺同一对象监视器的锁时，性能惩罚就开始显现。锁是在称为“内在”或“监视器”锁的对象监视器上获得的。对象等价性（即当
    `=` 函数返回 true 时）永远不会用于锁定目的。确保从不同线程锁定时对象引用是相同的（即当 `identical?` 返回 true 时）。
- en: Acquiring a monitor lock by a thread entails a read barrier, which invalidates
    the thread-local cached data, the corresponding processor registers, and the cache
    lines. This forces a reread from the memory. On the other hand, releasing the
    monitor lock results in a write barrier, which flushes all the changes to memory.
    These are expensive operations that impact parallelism, but they ensure consistency
    of data for all threads.
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 通过线程获取监视器锁涉及一个读屏障，这会使得线程局部缓存的、相应的处理器寄存器和缓存行无效。这迫使从内存中重新读取。另一方面，释放监视器锁会导致一个写屏障，将所有更改刷新到内存中。这些操作成本高昂，会影响并行性，但它们确保了所有线程的数据一致性。
- en: 'Java supports a `volatile` keyword for the data members in a class that guarantees
    read and write to an attribute outside of a synchronized block that would not
    be reordered. It is interesting to note that unless an attribute is declared `volatile`,
    it is not guaranteed to be visible in all the threads that are accessing it. The
    Clojure equivalent of Java''s `volatile` is the metadata called `^:volatile-mutable`
    that we discussed in [Chapter 3](ch10.html "Chapter 3. Leaning on Java"), *Leaning
    on Java*. An example of `volatile` in Java and Clojure is as follows:'
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: Java 支持一个 `volatile` 关键字，用于类中的数据成员，它保证了在同步块之外对属性的读写不会发生重排序。值得注意的是，除非一个属性被声明为
    `volatile`，否则它不能保证在所有访问它的线程中都是可见的。Clojure 中 Java 的 `volatile` 对应的元数据是我们在 [第 3
    章](ch10.html "第 3 章。依赖 Java") 中讨论的 `^:volatile-mutable`，即 *依赖 Java*。以下是一个 Java
    和 Clojure 中 `volatile` 的示例：
- en: '[PRE67]'
  id: totrans-622
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Reading and writing a `volatile` data requires read-acquire or write-release
    respectively, which means we need only a half-barrier to individually read or
    write the value. Note that due to a half-barrier, the read-followed-by-write operations
    are not guaranteed to be atomic. For example, the `age++` expression first reads
    the value, then increments and sets it. This makes two memory operations, which
    is no more a half-barrier.
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: 读取和写入 `volatile` 数据需要分别使用读获取或写释放，这意味着我们只需要一个半屏障来单独读取或写入值。请注意，由于半屏障，读取后跟写入的操作不保证是原子的。例如，`age++`
    表达式首先读取值，然后增加并设置它。这使得两个内存操作，这不再是半屏障。
- en: 'Clojure 1.7 introduced a first class support for the volatile data using a
    new set of functions: `volatile!`, `vswap!`, `vreset!,` and `volatile?` These
    functions define volatile (mutable) data and work with that. However, make a note
    that these functions do not work with the volatile fields in `deftype`. You can
    see how to use them as follows:'
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 1.7 引入了一套新的函数来支持可变数据，这些函数是：`volatile!`、`vswap!`、`vreset!` 和 `volatile?`。这些函数定义了可变（可变）数据并与之交互。然而，请注意，这些函数不与
    `deftype` 中的可变字段一起工作。以下是如何使用它们的示例：
- en: '[PRE68]'
  id: totrans-625
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Operations on volatile data are not atomic, which is why even creating a volatile
    (using `volatile!`) is considered potentially unsafe. In general, volatiles may
    be useful where read consistency is not a high priority but writes must be fast,
    such as real-time trend analysis, or other such analytics reporting. Volatiles
    may also be very useful when writing stateful transducers (refer to [Chapter 2](ch09.html
    "Chapter 2. Clojure Abstractions"), *Clojure Abstractions*), serving as very fast
    state containers. In the next sub-section, we will see the other state abstractions
    that are safer (and mostly slower) than volatiles.
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 对 volatile 数据的操作不是原子的，这就是为什么即使创建 volatile（使用 `volatile!`）也被认为可能是危险的。一般来说，volatile
    可能适用于读取一致性不是高优先级但写入必须快速的场景，例如实时趋势分析或其他此类分析报告。volatile 在编写有状态转换器（参考[第 2 章](ch09.html
    "第 2 章。Clojure 抽象"), *Clojure 抽象*)时也非常有用，作为非常快速的状态容器。在下一小节中，我们将看到其他比 volatile
    更安全（但大多数情况下更慢）的状态抽象。
- en: Atomic updates and state
  id: totrans-627
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原子更新和状态
- en: It is a common use case to read a data element, execute some logic, and update
    with a new value. For single-threaded programs, it bears no consequences; but
    for concurrent scenarios, the entire operation must be carried out in a lockstep,
    as an atomic operation. This case is so common that many processors support this
    at the hardware level using a special Compare-and-swap (CAS) instruction, which
    is much cheaper than locking. On x86/x64 architectures, the instruction is called
    CompareExchange (CMPXCHG).
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: 读取数据元素，执行一些逻辑，然后用新值更新，这是一个常见的用例。对于单线程程序，这没有任何后果；但对于并发场景，整个操作必须作为一个原子操作同步执行。这种情况如此常见，以至于许多处理器在硬件级别使用特殊的比较和交换（CAS）指令来支持它，这比锁定要便宜得多。在
    x86/x64 架构上，这个指令被称为 CompareExchange (CMPXCHG)。
- en: Unfortunately, it is possible that another thread updates the variable with
    the same value that the thread, which is working on the atomic update, is going
    to compare the old value against. This is known as the "ABA" problem. The set
    of instructions such as "Load-linked" (LL) and "Store-conditional" (SC), which
    are found in some other architectures, provide an alternative to CAS without the
    ABA problem. After the LL instruction reads the value from an address, the SC
    instruction to update the address with a new value will only go through if the
    address has not been updated since the LL instruction was successful.
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，可能存在另一个线程更新了变量，其值与正在执行原子更新的线程将要比较的旧值相同。这被称为“ABA”问题。一些其他架构中发现的“Load-linked”（LL）和“Store-conditional”（SC）等指令集合提供了没有
    ABA 问题的 CAS 的替代方案。在 LL 指令从地址读取值之后，SC 指令将更新地址为新值，只有当地址自 LL 指令成功以来未被更新时，SC 指令才会执行。
- en: Atomic updates in Java
  id: totrans-630
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Java 中的原子更新
- en: 'Java has a bunch of built-in lock free, atomic, thread safe compare-and-swap
    abstractions for the state management. They live in the `java.util.concurrent.atomic`
    package. For primitive types, such as boolean, integer, and long, there are the
    `AtomicBoolean`, `AtomicInteger`, and `AtomicLong` classes respectively. The latter
    two classes support additional atomic add/subtract operations. For atomic reference
    updates, there are the `AtomicReference`, `AtomicMarkableReference`, and `AtomicStampedReference`
    classes for the arbitrary objects. There is also a support available for arrays
    where the array elements can be updated atomically—`AtomicIntegerArray`, `AtomicLongArray`,
    and `AtomicReferenceArray`. They are easy to use; here is the example:'
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: Java 有许多内置的无锁、原子、线程安全的比较和交换抽象用于状态管理。它们位于 `java.util.concurrent.atomic` 包中。对于布尔型、整型和长整型等原始类型，分别有
    `AtomicBoolean`、`AtomicInteger` 和 `AtomicLong` 类。后两个类支持额外的原子加减操作。对于原子引用更新，有 `AtomicReference`、`AtomicMarkableReference`
    和 `AtomicStampedReference` 类用于任意对象。还有对数组的支持，其中数组元素可以原子性地更新——`AtomicIntegerArray`、`AtomicLongArray`
    和 `AtomicReferenceArray`。它们易于使用；以下是一个示例：
- en: '[PRE69]'
  id: totrans-632
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: However, where and how to use it is subjected to the update points and the logic
    in the code. The atomic updates are not guaranteed to be non-blocking. Atomic
    updates are not a substitute to locking in Java, but rather a convenience, only
    when the scope is limited to a compare and swap operation for one mutable variable.
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在哪里以及如何使用它则取决于更新点和代码中的逻辑。原子更新并不保证是非阻塞的。原子更新不是 Java 中锁的替代品，而是一种便利，仅当范围限制为对一个可变变量的比较和交换操作时。
- en: Clojure's support for atomic updates
  id: totrans-634
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Clojure 对原子更新的支持
- en: 'Clojure''s atomic update abstraction is called "atom". It uses `AtomicReference`
    under the hood. An operation on `AtomicInteger` or `AtomicLong` may be slightly
    faster than on the Clojure `atom`, because the former uses primitives. But neither
    of them are too cheap, due to the compare-and-swap instruction that they use in
    the CPU. The speed really depends on how frequently the mutation happens, and
    how the JIT compiler optimizes the code. The benefit of speed may not show up
    until the code is run several hundred thousand times, and having an atom mutated
    very frequently will increase the latency due to the retries. Measuring the latency
    under actual (or similar to actual) load can tell better. An example of using
    an atom is as follows:'
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 的原子更新抽象称为 "atom"。它底层使用 `AtomicReference`。对 `AtomicInteger` 或 `AtomicLong`
    的操作可能比 Clojure 的 `atom` 略快，因为前者使用原语。但由于它们在 CPU 中使用的比较和交换指令，它们都不太便宜。速度实际上取决于突变发生的频率以及
    JIT 编译器对代码的优化程度。速度的好处可能不会在代码运行了几十万次之后显现出来，并且原子频繁突变会增加重试的延迟。在实际（或类似实际）负载下测量延迟可以提供更好的信息。以下是一个使用原子的示例：
- en: '[PRE70]'
  id: totrans-636
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: The `swap!` function provides a notably different style of carrying out atomic
    updates than the `compareAndSwap(oldval, newval)` methods. While `compareAndSwap()`
    compares and sets the value, returning true if it's a success and false if it's
    a failure, `swap!` keeps on trying to update in an endless loop until it succeeds.
    This style is a popular pattern that is followed among Java developers. However,
    there is also a potential pitfall associated with the update-in-loop style. As
    the concurrency of the updaters gets higher, the performance of the update may
    gradually degrade. Then again, high concurrency on the atomic updates raises a
    question of whether or not uncoordinated updates was a good idea at all for the
    use-case. The `compare-and-set!` and `reset!` are pretty straightforward.
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: '`swap!` 函数在执行原子更新方面提供了一种与 `compareAndSwap(oldval, newval)` 方法明显不同的风格。当 `compareAndSwap()`
    比较并设置值时，如果成功则返回 true，如果失败则返回 false，而 `swap!` 则会持续在一个无限循环中尝试更新，直到成功。这种风格是 Java
    开发者中流行的模式。然而，与更新循环风格相关的潜在陷阱也存在。随着更新者的并发性提高，更新的性能可能会逐渐下降。再次，原子更新的高并发性引发了一个问题：对于使用案例来说，是否真的有必要进行无协调的更新。《compare-and-set!`
    和 `reset!` 则相当直观。'
- en: The function passed to `swap!` is required to be pure (as in side effect free),
    because it is retried several times in a loop during contention. If the function
    is not pure, the side effect may happen as many times as the retries.
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: 传递给 `swap!` 的函数必须是无副作用的（即无副作用），因为在竞争期间它会在循环中多次重试。如果函数不是无副作用的，副作用可能会在重试的次数内发生。
- en: 'It is noteworthy that atoms are not "coordinated", which means that when an
    atom is used concurrently by different threads, we cannot predict the order in
    which the operations work on it, and we cannot guarantee the end result as a consequence.
    The code we write around atoms should be designed with this constraint in mind.
    In many scenarios, atoms may not be a good fit due to the lack of coordination—watch
    out for that in the program design. Atoms support meta data and basic validation
    mechanism via extra arguments. The following examples illustrate these features:'
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，原子不是“协调”的，这意味着当原子被不同的线程并发使用时，我们无法预测操作它的顺序，也无法保证最终结果。围绕原子的代码应该考虑到这种约束来设计。在许多场景中，由于缺乏协调，原子可能不是最佳选择——在设计程序时要注意这一点。原子通过额外的参数支持元数据和基本验证机制。以下示例说明了这些功能：
- en: '[PRE71]'
  id: totrans-640
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: The second important thing is that atoms support is adding and removing watches
    on them. We will discuss watches later in the chapter.
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个重要的事情是，原子支持对其添加和删除监视。我们将在本章后面讨论监视。
- en: Faster writes with atom striping
  id: totrans-642
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用原子条带化进行更快的写入
- en: 'We know that atoms present contention when multiple threads try to update the
    state at the same time. This implies that atoms have great performance when the
    writes are infrequent. There are some use cases, for example metrics counters,
    where the writes need to be fast and frequent, but the reads are fewer and can
    tolerate some inconsistency. For such use cases, instead of directing all the
    updates to a single atom, we can maintain a bunch of atoms where each thread updates
    a different atom, thus reducing contention. Reads from these atoms cannot be guaranteed
    to be consistent. Let''s develop an example of such a counter:'
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，当多个线程试图同时更新状态时，原子会出现竞争。这意味着当写入操作不频繁时，原子具有很高的性能。有些用例，例如度量计数器，需要快速且频繁的写入，但读取较少，可以容忍一些不一致性。对于此类用例，我们不必将所有更新都指向单个原子，而可以维护一组原子，其中每个线程更新不同的原子，从而减少竞争。从这些原子中读取的数据不能保证一致性。让我们开发一个这样的计数器示例：
- en: '[PRE72]'
  id: totrans-644
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'In the previous example, we created a vector called `counters` of the same
    size as the number of CPU cores in the computer, and initialize each element with
    an atom of initial value 0\. The function called `inc!` updates the counter by
    picking up a random atom from `counters`, and incrementing the value by 1\. We
    also assumed that `rand-int` distributes the picking up of atom uniformly across
    all the processor cores, so that we have almost zero contention. The `value` function
    simply walks over all the atoms and adds up their `deref`''ed values to return
    the counter value. The example uses `clojure.core/rand-int`, which depends on
    `java.lang.Math/random` (due to Java 6 support) to randomly find out the next
    counter atom. Let''s see how we can optimize this when using Java 7 or above:'
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们创建了一个名为 `counters` 的向量，其大小与计算机中CPU核心的数量相同，并将每个元素初始化为初始值为0的原子。名为 `inc!`
    的函数通过从 `counters` 中随机选择一个原子并增加1来更新计数器。我们还假设 `rand-int` 在所有处理器核心之间均匀分布地选择原子，因此我们几乎零竞争。`value`
    函数简单地遍历所有原子，将它们的 `deref`'ed 值相加以返回计数器值。此示例使用 `clojure.core/rand-int`，它依赖于 `java.lang.Math/random`（由于Java
    6支持）来随机找到下一个计数器原子。让我们看看在使用Java 7或更高版本时如何优化：
- en: '[PRE73]'
  id: totrans-646
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Here, we `import` the `java.util.concurrent.ThreadLocalRandom` class, and define
    the `inc!` function to pick up the next random atom using `ThreadLocalRandom`.
    Everything else remains the same.
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们 `import` `java.util.concurrent.ThreadLocalRandom` 类，并定义 `inc!` 函数使用 `ThreadLocalRandom`
    来选择下一个随机原子。其他一切保持不变。
- en: Asynchronous agents and state
  id: totrans-648
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异步代理和状态
- en: 'While atoms are synchronous, agents are the asynchronous mechanism in Clojure
    to effect any change in the state. Every agent is associated with a mutable state.
    We pass a function (known as "action") to an agent with the optional additional
    arguments. This function gets queued for processing in another thread by the agent.
    All the agents share two common thread pools—one for the low-latency (potentially
    CPU-bound, cache-bound, or memory-bound) jobs, and one for the blocking (potentially
    I/O related or lengthy processing) jobs. Clojure provides the `send` function
    for the low-latency actions, `send-off` for blocking actions, and `send-via` to
    have the action executed on the user-specified thread-pool, instead of either
    of the preconfigured thread pools. All of `send`, `send-off`, and `send-via` return
    immediately. Here is how we can use them:'
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然原子是同步的，但代理是Clojure中实现状态变化的异步机制。每个代理都与一个可变状态相关联。我们向代理传递一个函数（称为“操作”），并可选地传递额外的参数。此函数由代理排队在另一个线程中处理。所有代理共享两个公共线程池——一个用于低延迟（可能为CPU密集型、缓存密集型或内存密集型）作业，另一个用于阻塞（可能为I/O相关或长时间处理）作业。Clojure提供了
    `send` 函数用于低延迟操作，`send-off` 用于阻塞操作，`send-via` 用于在用户指定的线程池上执行操作，而不是预配置的线程池之一。所有
    `send`、`send-off` 和 `send-via` 都立即返回。以下是它们的用法：
- en: '[PRE74]'
  id: totrans-650
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'When we inspect the Clojure (as of version 1.7.0) source code, we can find
    that the thread-pool for the low-latency actions is named as `pooledExecutor`
    (a bounded thread-pool, initialized to max ''2 + number of hardware processors''
    threads), and the thread-pool for the high-latency actions is named as `soloExecutor`
    (an unbounded thread pool). The premise of this default configuration is that
    the CPU/cache/memory-bound actions run most optimally on a bounded thread-pool,
    with the default number of threads. The I/O bound tasks do not consume CPU resources.
    Hence, a relatively larger number of such tasks can execute at the same time,
    without significantly affecting the performance of the CPU/cache/memory-bound
    jobs. Here is how you can access and override the thread-pools:'
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们检查Clojure（截至版本1.7.0）的源代码时，我们可以发现低延迟动作的线程池被命名为 `pooledExecutor`（一个有界线程池，初始化为最大
    '2 + 硬件处理器数量' 线程），而高延迟动作的线程池被命名为 `soloExecutor`（一个无界线程池）。这种默认配置的前提是，CPU/缓存/内存绑定动作在默认线程数的有界线程池上运行最优化。I/O绑定任务不消耗CPU资源。因此，可以同时执行相对较多的此类任务，而不会显著影响CPU/缓存/内存绑定作业的性能。以下是访问和覆盖线程池的方法：
- en: '[PRE75]'
  id: totrans-652
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: If a program carries out a large number of I/O or blocking operations through
    agents, it probably makes sense to limit the number of threads dedicated for such
    actions. Overriding the `send-off` thread-pool using `set-agent-send-off-executor!`
    is the easiest way to limit the thread-pool size. A more granular way to isolate
    and limit the I/O actions on the agents is to use `send-via` with the thread-pools
    of appropriate sizes for various kinds of I/O and blocking operations.
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个程序通过代理执行大量I/O或阻塞操作，限制为这些动作分配的线程数量可能是有意义的。使用 `set-agent-send-off-executor!`
    覆盖 `send-off` 线程池是限制线程池大小的最简单方法。为了隔离和限制代理上的I/O动作，可以使用 `send-via` 与各种I/O和阻塞操作适当大小的线程池。
- en: Asynchrony, queueing, and error handling
  id: totrans-654
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异步、排队和错误处理
- en: Sending an action to an agent returns immediately without blocking. If the agent
    is not already busy in executing any action, it "reacts" by enqueuing the action
    that triggers the execution of the action, in a thread, from the respective thread-pool.
    If the agent is busy in executing another action, the new action is simply enqueued.
    Once an action is executed from the action queue, the queue is checked for more
    entries and triggers the next action, if found. This whole "reactive" mechanism
    of triggering actions obviates the need of a message loop, polling the queue.
    This is only possible, because the entry points to an agent's queue are controlled.
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: 向代理发送动作会立即返回，而不会阻塞。如果代理尚未忙于执行任何动作，它会通过将触发动作执行的队列操作入队，在相应的线程池中“反应”。如果代理正在忙于执行另一个动作，新动作将简单地入队。一旦从动作队列中执行了动作，队列将检查是否有更多条目，并触发下一个动作（如果找到）。这个触发动作的整个“反应”机制消除了需要消息循环和轮询队列的需要。这之所以可能，是因为控制了指向代理队列的入口点。
- en: 'Actions are executed asynchronously on agents, which raises the question of
    how the errors are handled. Error cases need to be handled with an explicit, predefined
    function. When using a default agent construction, such as `(agent :foo)`, the
    agent is created without any error handler, and gets suspended in the event of
    any exception. It caches the exception, and refuses to accept any more actions.
    It throws the cached exception upon sending any action until the agent is restarted.
    A suspended agent can be reset using the `restart-agent` function. The objective
    of such suspension is safety and supervision. When the asynchronous actions are
    executed on an agent and suddenly an error occurs, it will require attention.
    Check out the following code:'
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: 动作在代理上异步执行，这引发了如何处理错误的疑问。错误情况需要通过一个显式、预定义的函数来处理。当使用默认的代理构造，如 `(agent :foo)`
    时，代理在没有错误处理程序的情况下创建，并在发生任何异常时挂起。它缓存异常，并拒绝接受更多动作。在代理重启之前，它会在发送任何动作时抛出缓存的异常。可以使用
    `restart-agent` 函数重置挂起的代理。这种挂起的目的是安全和监督。当异步动作在代理上执行并突然发生错误时，它将需要关注。查看以下代码：
- en: '[PRE76]'
  id: totrans-657
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'There are two optional parameters `:error-handler` and `:error-mode, which`
    we can configure on an agent to have finer control over the error handling and
    suspension as shown in the following code snippet:'
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个可选参数 `:error-handler` 和 `:error-mode`，我们可以在代理上配置这些参数以获得对错误处理和挂起的更精细控制，如下代码片段所示：
- en: '[PRE77]'
  id: totrans-659
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Why you should use agents
  id: totrans-660
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么你应该使用代理
- en: Just as the "atom" implementation uses only compare-and-swap instead of locking,
    the underlying "agent" specific implementation uses mostly the compare-and-swap
    operations. The agent implementation uses locks only when dispatching action in
    a transaction (discussed in the next section), or when restarting an agent. All
    the actions are queued and dispatched serially in the agents, regardless of the
    concurrency level. The serial nature makes it possible to execute the actions
    in an independent and contention-free manner. For the same agent, there can never
    be more than one action being executed. Since there is no locking, reads (`deref`
    or `@`) on agents are never blocked due to writes. However, all the actions are
    independent of each other—there is no overlap in their execution.
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: 正如“原子”实现只使用比较和交换而不是锁定一样，底层的“代理”特定实现主要使用比较和交换操作。代理实现仅在事务中调度动作（将在下一节中讨论）或重新启动代理时使用锁。所有动作都在代理中以串行方式排队和调度，无论并发级别如何。串行性质使得可以独立且无竞争地执行动作。对于同一代理，永远不会同时执行多个动作。由于没有锁定，对代理的读取（`deref`或`@`）永远不会因为写入而被阻塞。然而，所有动作都是相互独立的——它们的执行没有重叠。
- en: The implementation goes so far as to ensure that the execution of an action
    blocks other actions, which follow in the queue. Even though the actions are executed
    in a thread-pool, actions for the same agent are never executed concurrently.
    This is an excellent ordering guarantee that also extends a natural coordination
    mechanism, due to its serial nature. However, note that this ordering coordination
    is limited to only a single agent. If an agent action sends actions to two other
    agents, they are not automatically coordinated. In this situation, you may want
    to use transactions (which will be covered in the next section).
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: 实现甚至确保了执行一个动作会阻塞队列中后续的动作。尽管动作是在线程池中执行的，但同一代理的动作永远不会并发执行。这是一个出色的排序保证，也由于其串行性质而扩展了自然的协调机制。然而，请注意，这种排序协调仅限于单个代理。如果一个代理的动作发送动作给两个其他代理，它们不会自动协调。在这种情况下，你可能想使用事务（将在下一节中介绍）。
- en: Since agents distinguish between the low-latency and blocking jobs, the jobs
    are executed in an appropriate kind of thread-pools. Actions on different agents
    may execute concurrently, thereby making optimum use of the threading resources.
    Unlike atoms, the performance of the agents is not impeded by high contention.
    In fact, for many cases, agents make a lot of sense due to the serial buffering
    of actions. In general, agents are great for high volume I/O tasks, or where the
    ordering of operations provides a win in the high contention scenarios.
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: 由于代理区分低延迟和阻塞作业，作业将在适当的线程池中执行。不同代理上的动作可以并发执行，从而最大限度地利用线程资源。与原子不同，代理的性能不会因高竞争而受阻。事实上，对于许多情况，由于动作的串行缓冲，代理非常有意义。一般来说，代理非常适合高容量I/O任务，或者在操作顺序在高竞争场景中提供优势的情况下。
- en: Nesting
  id: totrans-664
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 嵌套
- en: When an agent action sends another action to the same agent, that is a case
    of nesting. This would have been nothing special if agents didn't participate
    in STM transactions (which will be covered in the next section). However, agents
    do participate in STM transactions and that places certain constraints on agent
    implementation that warrants a second-layer buffering of actions. For now, it
    should suffice to say that the nested sends are queued in a thread-local queue
    instead of the regular queue in the agent. The thread-local queue is visible only
    to the thread in which the action is executed. Upon executing an action, unless
    there was an error, the agent implicitly calls the equivalent of `release-pending-sends`
    function, which transfers the actions from second level thread-local queue to
    the normal action queue. Note that nesting is simply an implementation detail
    of agents and has no other impact.
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个代理动作向同一代理发送另一个动作时，这就是嵌套的情况。如果代理没有参与STM事务（将在下一节中介绍），这本来就不会有什么特别之处。然而，代理确实参与了STM事务，这给代理的实现带来了一定的约束，需要对动作进行第二层缓冲。目前，可以说嵌套发送被排队在代理的线程局部队列中，而不是常规队列。线程局部队列仅对执行动作的线程可见。在执行动作时，除非出现错误，否则代理会隐式调用相当于`release-pending-sends`函数的功能，该函数将动作从第二级线程局部队列转移到正常动作队列。请注意，嵌套只是代理的实现细节，没有其他影响。
- en: Coordinated transactional ref and state
  id: totrans-666
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 协调的事务引用和状态
- en: We saw in an earlier section that an atom provides atomic read-and-update operation.
    What if we need to perform an atomic read-and-update operation across two or even
    more number of atoms? This clearly poses a coordination problem. Some entity has
    to watch over the process of reading and updating, so that the values are not
    corrupted. This is what a ref provides—a **Software Transactional Memory** (**STM**)
    based system that takes care of concurrent atomic read-and-update operations across
    multiple refs, such that either all the updates go through, or in the case of
    failure, none does. Like atoms, on failure, refs retry the whole operation from
    scratch with the new values.
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分中，我们看到了原子提供了原子读取和更新操作。如果我们需要在两个或更多原子之间执行原子读取和更新操作怎么办？这显然提出了一个协调问题。某个实体必须监视读取和更新的过程，以确保值不被破坏。这就是
    ref 提供的——一个基于 **软件事务内存**（**STM**）的系统，它负责在多个 refs 之间执行并发原子读取和更新操作，以确保要么所有更新都通过，要么在失败的情况下，没有任何更新。像原子一样，在失败的情况下，refs
    会从零开始重试整个操作，使用新的值。
- en: Clojure's STM implementation is coarse grained. It works at the application
    level objects and aggregates (that is, references to aggregates), scoped to only
    all the refs in a program, constituting the "Ref world". Any update to a ref can
    only happen synchronously, in a transaction, in a `dosync` block of code, within
    the same thread. It cannot span beyond the current thread. The implementation
    detail reveals that a thread-local transaction context is maintained during a
    lifetime of a transaction. The same context ceases to be available, the moment
    the control reaches another thread.
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 的 STM 实现是粗粒度的。它在应用级对象和聚合（即聚合的引用）上工作，范围仅限于程序中的所有 refs，构成了“Ref 世界”。对 ref
    的任何更新都只能以同步方式发生，在事务中，在 `dosync` 代码块内，在同一线程中。它不能跨越当前线程。实现细节揭示了在事务的生命周期内维护了一个线程局部事务上下文。一旦控制达到另一个线程，相同的上下文就不再可用。
- en: Like the other reference types in Clojure, reads on a ref are never blocked
    by the updates, and vice versa. However, unlike the other reference types, the
    implementation of ref does not depend on a lock-free spinning, but rather, it
    internally uses locks, a low-level wait/notify, a deadlock detection, and the
    age-based barging.
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Clojure 中的其他引用类型一样，对 ref 的读取永远不会因为更新而被阻塞，反之亦然。然而，与其他引用类型不同，ref 的实现不依赖于无锁自旋，而是内部使用锁、低级等待/通知、死锁检测和基于年龄的抢占。
- en: 'The `alter` function is used to read-and-update the value of a ref, and `ref-set`
    is used to reset the value. Roughly, `alter` and `ref-set,` for the refs, are
    analogous to `swap!` and `reset!` for the atoms. Just like `swap!`, `alter` accepts
    a function (and arguments) with no side effects, and may be retried several times
    during the contention. However, unlike with the atoms, not only `alter` but also
    `ref-set` and simple `deref`, may cause a transaction to be retried during the
    contention. Here is a very simple example on how we may use a transaction:'
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: '`alter` 函数用于读取和更新一个 ref 的值，而 `ref-set` 用于重置值。大致来说，对于 refs 来说，`alter` 和 `ref-set`
    类似于原子操作中的 `swap!` 和 `reset!`。就像 `swap!` 一样，`alter` 接受一个无副作用的函数（和参数），并且可能在竞争期间重试多次。然而，与原子不同，不仅
    `alter`，而且 `ref-set` 和简单的 `deref` 也可能在竞争期间导致事务重试。以下是一个如何使用事务的非常简单的例子：'
- en: '[PRE78]'
  id: totrans-671
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Ref characteristics
  id: totrans-672
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ref 特性
- en: Clojure maintains the **Atomicity**, **Consistency**, and **Isolation** (**ACI**)
    characteristics in a transaction. This overlaps with A, C, and I of the ACID guarantee
    that many databases provide. Atomicity implies that either all of the updates
    in a transaction will complete successfully or none of them do. Consistency means
    that the transaction must maintain general correctness, and should honor the constraints
    set by the validation—any exception or validation error should roll back the transaction.
    Unless a shared state is guarded, concurrent updates on it may lead a multi-step
    transaction into seeing different values at different steps. Isolation implies
    that all the steps in a transaction will see the same value, no matter how concurrent
    the updates are.
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 在事务中维护了 **原子性**、**一致性**和**隔离性**（**ACI**）。这与许多数据库提供的 ACID 保证中的 A、C 和
    I 相重叠。原子性意味着事务中的所有更新要么全部成功完成，要么全部不完成。一致性意味着事务必须保持一般正确性，并应遵守验证设置的约束——任何异常或验证错误都应回滚事务。除非共享状态受到保护，否则对它的并发更新可能导致多步事务在不同步骤中看到不同的值。隔离性意味着无论更新多么并发，事务中的所有步骤都将看到相同的值。
- en: The Clojure refs use something known as **Multi Version Concurrency Control**
    (**MVCC**) to provide **Snapshot Isolation** to the transactions. In MVCC, instead
    of locking (which could block the transactions), the queues are maintained, so
    that each transaction can occur using its own snapshot copy, taken at its "read
    point", independent of other transactions. The main benefit of this approach is
    that the read-only out-of-transaction operations can go through without any contention.
    Transactions without the ref contention go through concurrently. In a rough comparison
    with the database systems, the Clojure ref isolation level is "Read Committed"
    for reading a Ref outside of a transaction, and "Repeatable Read" by default when
    inside the transaction.
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 引用使用一种称为**多版本并发控制（MVCC**）的技术来为事务提供**快照隔离**。在MVCC中，不是锁定（可能会阻塞事务），而是维护队列，以便每个事务都可以使用自己的快照副本进行，这个副本是在其“读点”拍摄的，独立于其他事务。这种方法的主要好处是，只读事务外的操作可以无冲突地通过。没有引用冲突的事务可以并发进行。在与数据库系统的粗略比较中，Clojure
    引用隔离级别在事务外读取引用时为“读取已提交”，而在事务内默认为“可重复读”。
- en: Ref history and in-transaction deref operations
  id: totrans-675
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引用历史和事务中解引用操作
- en: We discussed earlier that both, read and update operations, on a ref, may cause
    a transaction to be retried. The reads in a transaction can be configured to use
    the ref history in such a manner that the snapshot isolation instances are stored
    in the history queues, and are used by the read operations in the transactions.
    The default, which is not supposed to use the history queues, conserves heap space,
    and provides strong consistency (avoids the staleness of data) in the transactions.
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论过，对一个引用的读和更新操作都可能导致事务重试。事务中的读操作可以配置为使用引用历史，这样快照隔离实例就被存储在历史队列中，并由事务中的读操作使用。默认情况下，不使用历史队列，这可以节省堆空间，并在事务中提供强一致性（避免数据陈旧）。
- en: 'Using the ref history reduces the likelihood of the transaction retries caused
    by read contention, thereby providing a weak consistency. Therefore, it is a tool
    for performance optimization, which comes at the cost of consistency. In many
    scenarios, programs do not need strong consistency—we can choose appropriately
    if we know the trade-off, and what we need. The snapshot isolation mechanism in
    the Clojure ref implementation is backed by the adaptive history queues. The history
    queues grow dynamically to meet the read requests, and do not overshoot the maximum
    limit that is set for the ref. By default, the history is not enabled, so we need
    to specify it during the initialization or set it later. Here is an example of
    how to use the history:'
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: 使用引用历史可以降低由于读冲突导致的交易重试的可能性，从而提供弱一致性。因此，它是一种性能优化的工具，但以一致性为代价。在许多场景中，程序不需要强一致性——如果我们知道权衡利弊以及我们的需求，我们可以适当选择。Clojure
    引用实现中的快照隔离机制由自适应历史队列支持。历史队列会动态增长以满足读请求，并且不会超过为引用设置的极限。默认情况下，历史记录是禁用的，因此我们需要在初始化时指定它，或者稍后设置。以下是如何使用历史的示例：
- en: '[PRE79]'
  id: totrans-678
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: Minimum/maximum history limits are proportional to the length of the staleness
    window of the data. It also depends on the relative latency difference of the
    update and read operations to see what the range of the min-history and the max-history
    works well on a given host system. It may take some amount of trial and error
    to get the range right. As a ballpark figure, read operations only need as many
    min-history elements to avoid the transaction retries, as many updates can go
    through during one read operation. The max-history elements can be a multiple
    of min-history to cover for any history overrun or underrun. If the relative latency
    difference is unpredictable, then we have to either plan a min-history for the
    worst case scenario, or consider other approaches.
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: 最小/最大历史限制与数据陈旧窗口的长度成比例。它还取决于更新和读操作之间的相对延迟差异，以确定在给定主机系统上最小历史和最大历史的工作范围。可能需要一些尝试和错误才能得到正确的范围。作为一个粗略的估计，读操作只需要足够的min-history元素来避免事务重试，因为在一次读操作期间可以有那么多更新。max-history元素可以是min-history的倍数，以覆盖任何历史超限或欠限。如果相对延迟差异不可预测，那么我们必须为最坏情况规划min-history，或者考虑其他方法。
- en: Transaction retries and barging
  id: totrans-680
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事务重试和闯入
- en: A transaction can internally be in one of the five distinct states—Running,
    Committing, Retry, Killed, and Committed. A transaction can be killed for various
    reasons. Exceptions are the common reasons for killing a transaction. But let's
    consider the corner case where a transaction is retried many times, but it does
    not appear to commit successfully—what is the resolution? Clojure supports age-based
    barging, wherein an older transaction automatically tries to abort a younger transaction,
    so that the younger transaction is retried later. If the barging still doesn't
    work, as a last resort, the transaction is killed after a hard limit of 10,000
    retry attempts, and then the exception is thrown.
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: 事务可以在以下五种不同的状态之一内部运行——运行中、提交中、重试、已杀死和已提交。事务可能因各种原因而被杀死。异常是杀死事务的常见原因。但是，让我们考虑一个特殊情况，即事务多次重试，但似乎没有成功提交——解决方案是什么？Clojure
    支持基于年龄的抢占，其中较旧的事务会自动尝试中止较新的事务，以便较新的事务稍后重试。如果抢占仍然不起作用，作为最后的手段，在达到 10,000 次重试尝试的硬性限制后，事务将被杀死，然后抛出异常。
- en: Upping transaction consistency with ensure
  id: totrans-682
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 ensure 提高事务一致性
- en: Clojure's transactional consistency is a good balance between performance and
    safety. However, at times, we may need the **Serializable** consistency in order
    to preserve the correctness of the transaction. Concretely, in the face of the
    transaction retries, when a transaction's correctness depends on the state of
    a ref, in the transaction, wherein the ref is updated simultaneously in another
    transaction, we have a condition called "write skew". The Wikipedia entry on the
    write skew, [https://en.wikipedia.org/wiki/Snapshot_isolation](https://en.wikipedia.org/wiki/Snapshot_isolation),
    describes it well, but let's see a more concrete example. Let's say we want to
    design a flight simulation system with two engines, and one of the system level
    constraints is not to switch off both engines at the same time. If we model each
    engine as a ref, and certain maneuvers do require us to switch off an engine,
    we must ensure that the other engine is on. We can do it with `ensure`. Usually,
    `ensure` is required when maintaining a consistent relationship (invariants) across
    the refs is necessary. This cannot be ensured by the validator functions, because
    they do not come into play until the transaction commits. The validator functions
    will see the same value hence cannot help.
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 的事务一致性在性能和安全之间取得了良好的平衡。然而，有时我们可能需要 **可序列化** 的一致性来保留事务的正确性。具体来说，在面临事务重试的情况下，当事务的正确性依赖于
    ref 的状态，在事务中，ref 在另一个事务中同时被更新时，我们有一个称为“写偏斜”的条件。维基百科上关于写偏斜的条目 [https://en.wikipedia.org/wiki/Snapshot_isolation](https://en.wikipedia.org/wiki/Snapshot_isolation)
    描述得很好，但让我们看看一个更具体的例子。假设我们想要设计一个具有两个引擎的飞行模拟系统，并且系统级约束之一是不要同时关闭两个引擎。如果我们将每个引擎建模为一个
    ref，并且某些机动确实需要我们关闭一个引擎，我们必须确保另一个引擎是开启的。我们可以使用 `ensure` 来做到这一点。通常，当需要维护跨 ref 的一致性关系（不变性）时，需要
    `ensure`。这不能通过验证函数来确保，因为它们只有在事务提交时才会发挥作用。验证函数将看到相同的值，因此无法提供帮助。
- en: The write-skew can be solved using the namesake `ensure` function that essentially
    prevents a ref from modification by other transactions. It is similar to a locking
    operation, but in practice, it provides better concurrency than the explicit read-and-update
    operations, when the retries are expensive. Using `ensure` is quite simple—`(ensure
    ref-object).` However, it may be performance-wise expensive, due to the locks
    it holds during the transaction. Managing performance with `ensure` involves a
    trade-off between the retry latency, and the lost throughput due to the ensured
    state.
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用同名的 `ensure` 函数来解决写偏斜问题，该函数本质上防止其他事务修改 ref。它类似于锁定操作，但在实践中，当重试代价高昂时，它提供了比显式的读取和更新操作更好的并发性。使用
    `ensure` 非常简单——`(ensure ref-object)`。然而，由于它在事务期间持有的锁，它可能在性能上代价高昂。使用 `ensure` 管理性能需要在重试延迟和由于确保状态而丢失的吞吐量之间进行权衡。
- en: Lesser transaction retries with commutative operations
  id: totrans-685
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用交换操作减少事务重试次数
- en: Commutative operations are independent of the order in which they are applied.
    For example, incrementing a counter ref c1 from transactions t1 and t2 would have
    the same effect irrespective of the order in which t1 and t2 commit their changes.
    Refs have a special optimization for changing functions that are commutative for
    transactions—the `commute` function, which is similar to `alter` (same syntax),
    but with different semantics. Like `alter`, the `commute` functions are applied
    atomically during the transaction commit. However, unlike `alter`, `commute` does
    not cause the transaction retry on contention, and there is no guarantee about
    the order in which the `commute` functions are applied. This effectively makes
    `commute` nearly useless for returning a meaningful value as a result of the operation.
    All the commute functions in a transaction are reapplied with the final in transaction
    ref values during the transaction commit.
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: 交换操作与它们应用顺序无关。例如，从事务t1和t2中递增计数器引用c1将产生相同的效果，无论t1和t2提交它们的变化的顺序如何。引用对事务中交换的函数有特殊的优化——`commute`函数，它与`alter`（相同的语法）类似，但具有不同的语义。像`alter`一样，`commute`函数在事务提交期间原子性地应用。然而，与`alter`不同，`commute`不会因为竞争而导致事务重试，并且没有关于`commute`函数应用顺序的保证。这实际上使得`commute`在作为操作结果返回有意义值时几乎无用。在事务中，所有的`commute`函数都会在事务提交时使用事务引用的最终值重新应用。
- en: As we can see, commute reduces the contention, thereby optimizing the performance
    of the overall transaction throughput. Once we know that an operation is commutative
    and we are not going to use its return value in a meaningful way, there is hardly
    any trade-off deciding on whether to use it—we should just go ahead and use it.
    In fact, a program design, with respect to the ref transactions, with commute
    in mind, is not a bad idea.
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: 事务只确保发送给代理的变化在事务提交发生前被排队。正如我们所见，交换操作（commute）减少了竞争，从而优化了整体事务吞吐量的性能。一旦我们知道一个操作是交换的，并且我们不会以有意义的方式使用它的返回值，那么在决定是否使用它时几乎没有什么权衡——我们只需继续使用它。实际上，考虑到引用事务，以交换为设计考虑的程序设计不是一个坏主意。
- en: Agents can participate in transactions
  id: totrans-688
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代理可以参与交易
- en: In the previous section on agents, we discussed how agents work with the queued
    change functions. Agents can also participate in the ref transactions, thereby
    making it possible to combine the use of refs and agents in the transactions.
    However, agents are not included in the "Ref world", hence a transaction scope
    is not extended till the execution of the change function in an agent. Rather,
    the transactions only make sure that the changes sent to the agents are queued
    until the transaction commit happens.
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节关于代理的部分，我们讨论了代理如何与排队的变化函数协同工作。代理还可以参与引用事务（ref transactions），从而使得在事务中结合使用引用和代理成为可能。然而，代理并不包含在“引用世界”中，因此事务作用域不会扩展到代理中变化函数的执行。
- en: The *Nesting* sub-section, in the earlier section on agents, discusses about
    a second-layer thread-local queue. This thread-local queue is used during a transaction
    to hold the sent changes to an agent until the commit. The thread-local queue
    does not block the other changes that are being sent to an agent. The out-of-transaction
    changes are never buffered in the thread-local queue; rather, they are added to
    the regular queue in the agent.
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期关于代理的部分的*嵌套*子节中，讨论了第二层线程局部队列。这个线程局部队列在事务期间用于持有发送给代理的变化，直到提交。线程局部队列不会阻塞发送给代理的其他变化。事务之外的变化永远不会在线程局部队列中缓冲；相反，它们被添加到代理中的常规队列中。
- en: The participation of agents in the transactions provides an interesting angle
    of design, where the coordinated and independent/sequential operations can be
    pipelined as a workflow for better throughput and performance.
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: 代理参与交易提供了一个有趣的设计角度，其中协调的以及独立/顺序的操作可以被作为工作流程进行流水线处理，以实现更好的吞吐量和性能。
- en: Nested transactions
  id: totrans-692
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 嵌套事务
- en: Clojure transactions are nesting aware and they compose well. But, why would
    one need a nested transaction? Often, independent units of code may have their
    own low-granularity transactions that a higher level code can make use of. When
    the higher level caller itself needs to wrap actions in a transaction, nested
    transactions occur. Nested transactions have their own lifecycle and run-state.
    However, an outer transaction can abort an inner transaction on the detection
    of failure.
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure事务具有嵌套意识，并且组合良好。但是，为什么需要嵌套事务呢？通常，独立的代码单元可能有自己的低粒度事务，而高级别代码可以利用这些事务。当高级别调用者本身需要将操作包装在事务中时，就会发生嵌套事务。嵌套事务有自己的生命周期和运行状态。然而，外部事务可以在检测到失败时取消内部事务。
- en: The "ref world" snapshot `ensure`s and `commute`s are shared among all (that
    is, outer and inner) levels of a nested transaction. Due to this, the inner transaction
    is treated as any other ref change operation (similar to `alter`, `ref-set` and
    so on) within an outer transaction. The watches and internal lock implementation
    are handled at the respective nesting level. The detection of contention in the
    inner transactions causes a restart of not only the inner but also the outer transaction.
    Commits at all the levels are effected as a global state finally when the outermost
    transaction commits. The watches, even though tracked at each individual transaction
    level, are finally effected during the commit. A closer look at the nested transaction
    implementation shows that nesting has little or no impact on the performance of
    transactions.
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
  zh: “引用世界”快照的`ensure`和`commute`在嵌套事务的所有（即外部和内部）级别之间共享。因此，内部事务被视为在外部事务内部进行的任何其他引用更改操作（类似于`alter`、`ref-set`等）。监视和内部锁定实现由各自的嵌套级别处理。内部事务中的竞争检测会导致内部事务以及外部事务的重新启动。所有级别的提交最终都会在最外层事务提交时作为一个全局状态生效。尽管监视在每个单独的事务级别上都有跟踪，但最终在提交时生效。仔细观察嵌套事务实现可以看出，嵌套对事务性能的影响很小或没有。
- en: Performance considerations
  id: totrans-695
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能考虑
- en: Clojure Ref is likely to be the most complex reference type implemented yet.
    Due to its characteristics, especially its transaction retry mechanism, it may
    not be immediately apparent that such a system would have good performance during
    the high-contention scenarios.
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure引用可能是迄今为止实现的最复杂的引用类型。由于其特性，特别是其事务重试机制，在高度竞争的场景中，这种系统可能会有良好的性能可能并不立即明显。
- en: 'Understanding its nuances and best ways of use should help:'
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
  zh: 理解其细微差别和最佳使用方式将有所帮助：
- en: We do not use changes with the side effects in a transaction, except for possibly
    sending the I/O changes to agents, where the changes are buffered until the commit.
    So by definition, we do not carry out any expensive I/O work in a transaction.
    Hence, a retry of this work would be cheap as well.
  id: totrans-698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在事务中不使用具有副作用的变化，除非可能将I/O变化发送到代理，其中变化被缓冲直到提交。因此，根据定义，我们不会在事务中执行任何昂贵的I/O工作。因此，这项工作的重试成本也会很低。
- en: A change function for a transaction should be as small as possible. This lowers
    the latency and hence, the retries will also be cheaper.
  id: totrans-699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事务的更改函数应该尽可能小。这降低了延迟，因此重试的成本也会更低。
- en: Any ref that is not updated along with at least one more ref simultaneously
    needs not be a ref—atoms would do just fine in this case. Now that the refs make
    sense only in a group, their contention is directly proportional to the group
    size. Small groups of refs used in the transactions lead to a low contention,
    lower latency, and a higher throughput.
  id: totrans-700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何没有至少与另一个引用同时更新的引用不需要是引用——在这种情况下原子就足够好了。现在，引用只有在组中才有意义，它们的竞争直接与组大小成正比。在事务中使用的小型引用组会导致低竞争、低延迟和高吞吐量。
- en: Commutative functions provide a good opportunity to enhance the transaction
    throughput without any penalty. Identifying such cases and designing with commute
    in mind can help performance significantly.
  id: totrans-701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交换函数提供了在不产生任何惩罚的情况下提高事务吞吐量的好机会。识别这些情况并考虑交换进行设计可以帮助显著提高性能。
- en: Refs are very coarse grained—they work at the application aggregate level. Often
    a program may need to have more fine-grained control over the transaction resources.
    This can be enabled by Ref striping, such as Megaref ([https://github.com/cgrand/megaref](https://github.com/cgrand/megaref)),
    by providing a scoped view on the associative refs, thereby allowing higher concurrency.
  id: totrans-702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引用非常粗粒度——它们在应用聚合级别工作。通常，程序可能需要更细粒度地控制事务资源。这可以通过引用条带化来实现，例如Megaref ([https://github.com/cgrand/megaref](https://github.com/cgrand/megaref))，通过提供关联引用的受限视图，从而允许更高的并发性。
- en: In the high contention scenarios in which the ref group size in a transaction
    cannot be small, consider using agents, as they have no contention due to the
    serial nature. Agents may not be a replacement for the transactions, but rather
    we can employ a pipeline consisting of atoms, refs, and agents to ease out the
    contention versus latency concerns.
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在高竞争场景中，如果事务中的引用组大小不能小，考虑使用代理，因为它们由于序列性质而没有竞争。代理可能不是事务的替代品，但我们可以使用由原子、引用和代理组成的管道来减轻竞争与延迟的担忧。
- en: Refs and transactions have an intricate implementation. Fortunately, we can
    inspect the source code, and browse through available online and offline resources.
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
  zh: 引用和事务具有复杂的实现。幸运的是，我们可以检查源代码，并浏览可用的在线和离线资源。
- en: Dynamic var binding and state
  id: totrans-705
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态变量绑定和状态
- en: 'The fourth kind among the Clojure''s reference types is the dynamic var. Since
    Clojure 1.3, all the vars are static by default. A var must be explicitly declared
    so in order to be dynamic. Once declared, a dynamic var can be bound to new values
    on per-thread basis. Binding on different threads do not block each other. An
    example is shown here:'
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
  zh: 在Clojure的引用类型中，第四种是动态变量。自从Clojure 1.3以来，所有变量默认都是静态的。必须显式声明变量以使其成为动态的。一旦声明，动态变量就可以在每线程的基础上绑定到新的值。不同线程上的绑定不会相互阻塞。以下是一个示例：
- en: '[PRE80]'
  id: totrans-707
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: As the dynamic binding is thread-local, it may be tricky to use in multi-threaded
    scenarios. Dynamic vars have been long abused by libraries and applications as
    a means to pass in a common argument to be used by several functions. However,
    this style is acknowledged to be an anti-pattern, and is discouraged. Typically,
    in the anti-pattern dynamic, vars are wrapped by a macro to contain the dynamic
    thread-local binding in the lexical scope. This causes problems with the multi-threading
    and lazy sequences.
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
  zh: 由于动态绑定是线程局部的，因此在多线程场景中使用可能会很棘手。动态变量长期以来一直被库和应用作为传递给多个函数使用的通用参数的手段所滥用。然而，这种风格被认为是一种反模式，并受到谴责。通常，在反模式动态中，变量会被宏包装以在词法作用域中包含动态线程局部绑定，这会导致多线程和懒序列出现问题。
- en: So, how can the dynamic vars be used effectively? A dynamic var lookup is more
    expensive than looking up a static var. Even passing a function argument is performance-wise
    much cheaper than looking up a dynamic var. Binding a dynamic var incurs additional
    cost. Clearly, in performance sensitive code, dynamic vars are best not used at
    all. However, dynamic vars may prove to be useful to hold a temporary thread-local
    state in a complex, or recursive call-graph scenario, where the performance does
    not matter significantly, without being advertised or leaked into the public API.
    The dynamic var bindings can nest and unwind like a stack, which makes them both
    attractive and suitable for such tasks.
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如何有效地使用动态变量呢？动态变量查找比查找静态变量更昂贵。即使是传递函数参数，在性能上也要比查找动态变量便宜得多。绑定动态变量会产生额外的开销。显然，在性能敏感的代码中，最好根本不使用动态变量。然而，在复杂或递归调用图场景中，动态变量可能非常有用，以持有临时的线程局部状态，在这些场景中，性能并不重要，而且不会被宣传或泄露到公共API中。动态变量绑定可以像堆栈一样嵌套和展开，这使得它们既吸引人又适合此类任务。
- en: Validating and watching the reference types
  id: totrans-710
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 验证和监视引用类型
- en: 'Vars (both static and dynamic), atoms, refs, and agents provide a way to validate
    the value being set as state—a `validator` function that accepts new value as
    argument, and returns the logical as true if it succeeds, or throws exception/returns
    logical as false (the false and nil values) if there''s an error. They all honor
    what the validator function returns. If it is a success, the update goes through,
    and if an error, an exception is thrown instead. Here is the syntax on how the
    validators can be declared and associated with the reference types:'
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
  zh: 变量（静态和动态）、原子、引用和代理提供了一种验证作为状态设置值的途径——一个接受新值作为参数的`validator`函数，如果成功则返回逻辑值为真，如果出错则抛出异常/返回逻辑值为假（假和nil值）。它们都尊重验证函数返回的结果。如果成功，更新将通过，如果出错，则抛出异常。以下是声明验证器并将其与引用类型关联的语法：
- en: '[PRE81]'
  id: totrans-712
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: Validators cause actual failure within a reference type while updating them.
    For vars and atoms, they simply prevent the update by throwing an exception. In
    an agent, a validation failure causes agent failure, and needs the agent to restart.
    Inside a ref, the validation failure causes the transaction to rollback and rethrow
    the exception.
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
  zh: 验证器在更新引用类型时会导致实际失败。对于变量和原子，它们通过抛出异常简单地阻止更新。在代理中，验证失败会导致代理失败，需要代理重启。在引用内部，验证失败会导致事务回滚并重新抛出异常。
- en: 'Another mechanism to observe the changes to the reference types is a "watcher".
    Unlike validators, a watcher is passive—it is notified of the update after the
    fact. Hence, a watcher cannot prevent updates from going through, because it is
    only a notification mechanism. For transactions, a watcher is invoked only after
    the transaction commit. While only one validator can be set on a reference type,
    it is possible to associate multiple watchers to a reference type on the other
    hand. Secondly, when adding a watch, we can specify a key, so that the notifications
    can be identified by the key, and be dealt accordingly by the watcher. Here is
    the syntax on how to use watchers:'
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
  zh: 观察引用类型变化的另一种机制是“观察者”。与验证器不同，观察者是被动的——它在更新发生后才会被通知。因此，观察者不能阻止更新通过，因为它只是一个通知机制。对于事务，观察者仅在事务提交后调用。虽然只能对一个引用类型设置一个验证器，但另一方面，可以将多个观察者与一个引用类型关联。其次，在添加观察时，我们可以指定一个键，这样通知就可以通过键来识别，并由观察者相应处理。以下是使用观察者的语法：
- en: '[PRE82]'
  id: totrans-715
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Like validators, the watchers are executed synchronously in the thread of the
    reference type. For atoms and refs, this may be fine, since the notification to
    the watchers goes on, the other threads may proceed with their updates. However
    in agents, the notification happens in the same thread where the update happens—this
    makes the update latency higher, and the throughput potentially lower.
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: 与验证器一样，观察者是在引用类型的线程中同步执行的。对于原子和引用，这可能没问题，因为通知观察者的同时，其他线程可以继续进行它们的更新。然而，在代理中，通知发生在更新发生的同一线程中——这使得更新延迟更高，吞吐量可能更低。
- en: Java concurrent data structures
  id: totrans-717
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java并发数据结构
- en: Java has a number of mutable data structures that are meant for concurrency
    and thread-safety, which implies that multiple callers can safely access these
    data structures at the same time, without blocking each other. When we need only
    the highly concurrent access without the state management, these data structures
    may be a very good fit. Several of these employ lock free algorithms. We discussed
    about the Java atomic state classes in the *Atomic updates and state section*,
    so we will not repeat them here. Rather, we will only discuss the concurrent queues
    and other collections.
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: Java有几个可变数据结构，旨在用于并发和线程安全，这意味着多个调用者可以同时安全地访问这些数据结构，而不会相互阻塞。当我们只需要高度并发访问而不需要状态管理时，这些数据结构可能非常适合。其中一些采用了无锁算法。我们已经在*原子更新和状态部分*讨论了Java原子状态类，所以这里不再重复。相反，我们只讨论并发队列和其他集合。
- en: All of these data structures live in the `java.util.concurrent` package. These
    concurrent data structures are tailored to leverage the JSR 133 "Java Memory Model
    and Thread Specification Revision" ([http://gee.cs.oswego.edu/dl/jmm/cookbook.html](http://gee.cs.oswego.edu/dl/jmm/cookbook.html))
    implementation that first appeared in Java 5.
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些数据结构都位于`java.util.concurrent`包中。这些并发数据结构是根据JSR 133 "Java内存模型和线程规范修订"（[http://gee.cs.oswego.edu/dl/jmm/cookbook.html](http://gee.cs.oswego.edu/dl/jmm/cookbook.html)）的实现定制的，该实现首次出现在Java
    5中。
- en: Concurrent maps
  id: totrans-720
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发映射
- en: Java has a mutable concurrent hash map—`java.util.concurrent.ConcurrentHashMap`
    (CHM in short). The concurrency level can be optionally specified when instantiating
    the class, which is 16 by default. The CHM implementation internally partitions
    the map entries into the hash buckets, and uses multiple locks to reduce the contention
    on each bucket. Reads are never blocked by writes, therefore they may be stale
    or inconsistent—this is countered by built-in detection of such situations, and
    issuing a lock in order to read the data again in the synchronized fashion. This
    is an optimization for the scenarios, where reads significantly outnumber writes.
    In CHM, all the individual operations are near constant-time unless stuck in a
    retry loop due to the lock contention.
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
  zh: Java拥有一个可变的并发哈希表——`java.util.concurrent.ConcurrentHashMap`（简称CHM）。在实例化类时，可以可选地指定并发级别，默认为16。CHM内部将映射条目分区到哈希桶中，并使用多个锁来减少每个桶的竞争。读取操作永远不会被写入操作阻塞，因此它们可能过时或不一致——这种情况通过内置的检测机制得到解决，并发出锁以再次以同步方式读取数据。这是针对读取操作远多于写入操作的场景的优化。在CHM中，所有单个操作几乎都是常数时间，除非由于锁竞争陷入重试循环。
- en: 'In contrast with Clojure''s persistent map, CHM cannot accept `null` (`nil`)
    as the key or value. Clojure''s immutable scalars and collections are automatically
    well-suited for use with CHM. An important thing to note is that only the individual
    operations in CHM are atomic, and exhibit strong consistency. As CHM operations
    are concurrent, the aggregate operations provide a rather weak consistency than
    the true operation-level consistency. Here is how we can use CHM. The individual
    operations in CHM, which provide a better consistency, are safe to use. The aggregate
    operations should be reserved for when we know its consistency characteristics,
    and the related trade-off:'
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: 与Clojure的持久映射相比，CHM不能接受`null`（`nil`）作为键或值。Clojure的不可变标量和集合自动适合与CHM一起使用。需要注意的是，只有CHM中的单个操作是原子的，并表现出强一致性。由于CHM操作是并发的，聚合操作提供的致性比真正的操作级致性要弱。以下是我们可以使用CHM的方式。CHM中的单个操作提供了更好的致性，因此是安全的。聚合操作应保留在我们知道其致性特征和相关权衡时使用：
- en: '[PRE83]'
  id: totrans-723
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: The `java.util.concurrent.ConcurrentSkipListMap` class (CSLM in short) is another
    concurrent mutable map data structure in Java. The difference between CHM and
    CSLM is that CSLM offers a sorted view of the map at all times with the O(log
    N) time complexity. The sorted view has the natural order of keys by default,
    which can be overridden by specifying a Comparator implementation when instantiating
    CSLM. The implementation of CSLM is based on the Skip List, and provides navigation
    operations.
  id: totrans-724
  prefs: []
  type: TYPE_NORMAL
  zh: '`java.util.concurrent.ConcurrentSkipListMap`类（简称CSLM）是Java中另一种并发可变映射数据结构。CHM和CSLM之间的区别在于CSLM始终提供具有O(log
    N)时间复杂度的排序视图。默认情况下，排序视图具有键的自然顺序，可以通过在实例化CSLM时指定Comparator实现来覆盖。CSLM的实现基于跳表，并提供导航操作。'
- en: The `java.util.concurrent.ConcurrentSkipListSet` class (CSLS in short) is a
    concurrent mutable set based on the CSLM implementation. While CSLM offers the
    map API, CSLS behaves as a set data structure while borrowing features of CSLM.
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
  zh: '`java.util.concurrent.ConcurrentSkipListSet`类（简称CSLS）是基于CSLM实现的并发可变集合。虽然CSLM提供映射API，但CSLS在行为上类似于集合数据结构，同时借鉴了CSLM的功能。'
- en: Concurrent queues
  id: totrans-726
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发队列
- en: Java has a built-in implementation of several kinds of mutable and concurrent
    in-memory queues. The queue data structure is a useful tool for buffering, producer-consumer
    style implementation, and for pipelining such units together to form the high-performance
    workflows. We should not confuse them with durable queues that are used for similar
    purpose in the batch jobs for a high throughput. Java's in-memory queues are not
    transactional, but they provide atomicity and strong consistency guarantee for
    the individual queue operations only. Aggregate operations offer weaker consistency.
  id: totrans-727
  prefs: []
  type: TYPE_NORMAL
  zh: Java内置了多种可变和并发内存队列的实现。队列数据结构是用于缓冲、生产者-消费者风格实现以及将这些单元管道化以形成高性能工作流程的有用工具。我们不应将它们与用于批量作业中类似目的的持久队列混淆，这些队列用于高吞吐量。Java的内存队列不是事务性的，但它们只为单个队列操作提供原子性和强一致性保证。聚合操作提供较弱的致性。
- en: 'The `java.util.concurrent.ConcurrentLinkedQueue` (CLQ) is a lock-free, wait-free
    unbounded "First In First Out" (FIFO) queue. FIFO implies that the order of the
    queue elements will not change once added to the queue. CLQ''s `size()` method
    is not a constant time operation; it depends on the concurrency level. Few examples
    of using CLQ are here:'
  id: totrans-728
  prefs: []
  type: TYPE_NORMAL
  zh: '`java.util.concurrent.ConcurrentLinkedQueue` (CLQ) 是一个无锁、无等待的无界“先进先出” (FIFO)
    队列。FIFO 表示一旦元素被添加到队列中，队列元素的顺序将不会改变。CLQ 的 `size()` 方法不是一个常数时间操作；它取决于并发级别。以下是一些使用
    CLQ 的示例：'
- en: '[PRE84]'
  id: totrans-729
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '| Queue | Blocking? | Bounded? | FIFO? | Fairness? | Notes |'
  id: totrans-730
  prefs: []
  type: TYPE_TB
  zh: '| 队列 | 阻塞？ | 有界？ | FIFO？ | 公平性？ | 备注 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-731
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| CLQ | No | No | Yes | No | Wait-free, but the size() is not constant time
    |'
  id: totrans-732
  prefs: []
  type: TYPE_TB
  zh: '| CLQ | 否 | 否 | 是 | 否 | 无等待，但 size() 不是常数时间 |'
- en: '| ABQ | Yes | Yes | Yes | Optional | The capacity is fixed at instantiation
    |'
  id: totrans-733
  prefs: []
  type: TYPE_TB
  zh: '| ABQ | 是 | 是 | 是 | 可选 | 容量在实例化时固定 |'
- en: '| DQ | Yes | No | No | No | The elements implement the Delayed interface |'
  id: totrans-734
  prefs: []
  type: TYPE_TB
  zh: '| DQ | 是 | 否 | 否 | 否 | 元素实现了 Delayed 接口 |'
- en: '| LBQ | Yes | Optional | Yes | No | The capacity is flexible, but with no fairness
    option |'
  id: totrans-735
  prefs: []
  type: TYPE_TB
  zh: '| LBQ | 是 | 可选 | 是 | 否 | 容量是灵活的，但没有公平性选项 |'
- en: '| PBQ | Yes | No | No | No | The elements are consumed in a priority order
    |'
  id: totrans-736
  prefs: []
  type: TYPE_TB
  zh: '| PBQ | 是 | 否 | 否 | 否 | 元素按优先级顺序消费 |'
- en: '| SQ | Yes | – | – | Optional | It has no capacity; it serves as a channel
    |'
  id: totrans-737
  prefs: []
  type: TYPE_TB
  zh: '| SQ | 是 | – | – | 可选 | 它没有容量；它充当一个通道 |'
- en: In the `java.util.concurrent` package, `ArrayBlockingQueue` (ABQ), `DelayQueue`
    (DQ), `LinkedBlockingQueue` (LBQ), `PriorityBlockingQueue` (PBQ), and `SynchronousQueue`
    (SQ) implement the `BlockingQueue` (BQ) interface. Its Javadoc describes the characteristics
    of its method calls. ABQ is a fixed-capacity, FIFO queue backed by an array. LBQ
    is also a FIFO queue, backed by the linked nodes, and is optionally bounded (default
    `Integer.MAX_VALUE`). ABQ and LBQ generate "Back pressure" by blocking the enqueue
    operations on full capacity. ABQ supports optional fairness (with performance
    overhead) in the order of the threads that access it.
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `java.util.concurrent` 包中，`ArrayBlockingQueue` (ABQ)，`DelayQueue` (DQ)，`LinkedBlockingQueue`
    (LBQ)，`PriorityBlockingQueue` (PBQ) 和 `SynchronousQueue` (SQ) 实现了 `BlockingQueue`
    (BQ) 接口。它的 Javadoc 描述了其方法调用的特性。ABQ 是一个固定容量的 FIFO 队列，由数组支持。LBQ 也是一个 FIFO 队列，由链表节点支持，并且可以选择性地有界（默认为
    `Integer.MAX_VALUE`）。ABQ 和 LBQ 通过阻塞在满容量时的入队操作来生成“背压”。ABQ 支持可选的公平性（但会有性能开销），按照访问它的线程的顺序。
- en: DQ is an unbounded queue that accepts the elements associated with the delay.
    The queue elements cannot be null, and must implement the `java.util.concurrent.Delayed`
    interface. Elements are available for removal from the queue only after the delay
    has been expired. DQ can be very useful for scheduling the processing of the elements
    at different times.
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: DQ 是一个无界队列，接受与延迟相关的元素。队列元素不能为 null，并且必须实现 `java.util.concurrent.Delayed` 接口。元素只有在延迟过期后才能从队列中移除。DQ
    可以非常有助于在不同时间安排元素的处理。
- en: PBQ is unbounded and blocking while letting elements be consumed from the queue
    as per priority. Elements have the natural ordering by default that can be overridden
    by specifying a Comparator implementation when instantiating the queue.
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: PBQ 是无界且阻塞的，同时允许根据优先级从队列中消费元素。元素默认具有自然排序，可以通过在实例化队列时指定 Comparator 实现来覆盖。
- en: SQ is not really a queue at all. Rather, it's just a barrier for a producer
    or consumer thread. The producer blocks until a consumer removes the element and
    vice versa. SQ does not have a capacity. However, SQ supports optional fairness
    (with performance overhead), in the order, in which the threads access it.
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: SQ 实际上根本不是一个队列。相反，它只是生产者或消费者线程的一个屏障。生产者会阻塞，直到消费者移除元素，反之亦然。SQ 没有容量。然而，SQ 支持可选的公平性（但会有性能开销），按照线程访问它的顺序。
- en: There are some new concurrent queue types introduced after Java 5\. Since JDK
    1.6, in the `java.util.concurrent` package Java has **BlockingDeque** (**BD**)
    with **LinkedBlockingDeque** (**LBD**) as the only available implementation. BD
    builds on BQ by adding the **Deque** (**double-ended queue**) operations, that
    is, the ability to add elements and consume the elements from both the ends of
    the queue. LBD can be instantiated with an optional capacity (bounded) to block
    the overflow. JDK 1.7 introduced **TransferQueue** (**TQ**) with **LinkedTransferQueue**
    (**LTQ**) as the only implementation. TQ extends the concept of SQ in such a way
    that the producers and consumers block a queue of elements. This will help utilize
    the producer and consumer threads better by keeping them busy. LTQ is an unbounded
    implementation of TQ where the `size()` method is not a constant time operation.
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: Java 5 之后引入了一些新的并发队列类型。自从 JDK 1.6 以来，在 `java.util.concurrent` 包中，Java 有 **BlockingDeque**（**BD**）和
    **LinkedBlockingDeque**（**LBD**）作为唯一可用的实现。BD 通过添加 **Deque**（**双端队列**）操作来构建在 BQ
    之上，即从队列两端添加元素和消费元素的能力。LBD 可以用一个可选的容量（有限制）来实例化，以阻塞溢出。JDK 1.7 引入了 **TransferQueue**（**TQ**）和
    **LinkedTransferQueue**（**LTQ**）作为唯一实现。TQ 以一种方式扩展了 SQ 的概念，即生产者和消费者阻塞一个元素队列。这将通过保持它们忙碌来更好地利用生产者和消费者线程。LTQ
    是 TQ 的无限制实现，其中 `size()` 方法不是一个常数时间操作。
- en: Clojure support for concurrent queues
  id: totrans-743
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Clojure 对并发队列的支持
- en: We covered the persistent queue in [Chapter 2](ch09.html "Chapter 2. Clojure
    Abstractions"), *Clojure Abstractions* earlier. Clojure has a built-in `seque`
    function that builds over a BQ implementation (LBQ by default) to expose a write-ahead
    sequence. The sequence is potentially lazy, and the write-ahead buffer throttles
    how many elements to realize. As opposed to the chunked sequences (of chunk size
    32), the size of the write-ahead buffer is controllable and potentially populated
    at all times until the source sequence is exhausted. Unlike the chunked sequences,
    the realization doesn't happen suddenly for a chunk of 32 elements. It does so
    gradually and smoothly.
  id: totrans-744
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 [第 2 章](ch09.html "第 2 章。Clojure 抽象") *Clojure 抽象* 中较早地介绍了持久队列。Clojure 有一个内置的
    `seque` 函数，它基于 BQ 实现（默认为 LBQ）来暴露预写序列。这个序列可能是惰性的，预写缓冲区控制要实现多少个元素。与块序列（块大小为 32）不同，预写缓冲区的大小是可控制的，并且可能在所有时间都充满，直到源序列耗尽。与块序列不同，32
    个元素的块不会突然实现。它是逐渐和平稳地实现的。
- en: Under the hood, Clojure's `seque` uses an agent to the backfill data in the
    write-ahead buffer. In the arity-2 variant of `seque`, the first argument should
    either be a positive integer, or an instance of BQ (ABQ, LBQ, and more) that is
    preferably bounded.
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，Clojure 的 `seque` 使用代理在预写缓冲区中填充数据。在 `seque` 的 2 参数版本中，第一个参数应该是正整数，或者是一个
    BQ（ABQ、LBQ 等）的实例，最好是有限制的。
- en: Concurrency with threads
  id: totrans-746
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程的并发
- en: On the JVM, threads are the de-facto fundamental instrument of concurrency.
    Multiple threads live in the same JVM; they share the heap space, and compete
    for the resources.
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: 在 JVM 上，线程是事实上的基本并发工具。多个线程生活在同一个 JVM 中；它们共享堆空间，并竞争资源。
- en: JVM support for threads
  id: totrans-748
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: JVM 对线程的支持
- en: 'The JVM threads are the Operating System threads. Java wraps an underlying
    OS thread as an instance of the `java.lang.Thread` class, and builds up an API
    around it to work with threads. A thread on the JVM has a number of states: New,
    Runnable, Blocked, Waiting, Timed_Waiting, and Terminated. A thread is instantiated
    by overriding the `run()` method of the `Thread` class, or by passing an instance
    of the `java.lang.Runnable` interface to the constructor of the `Thread` class.'
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
  zh: JVM 线程是操作系统线程。Java 将底层 OS 线程包装为 `java.lang.Thread` 类的实例，并在其周围构建一个 API 来处理线程。JVM
    上的线程有多个状态：新建、可运行、阻塞、等待、定时等待和终止。线程通过覆盖 `Thread` 类的 `run()` 方法或通过将 `java.lang.Runnable`
    接口的实例传递给 `Thread` 类的构造函数来实例化。
- en: Invoking the `start()` method of a `Thread` instance starts its execution in
    a new thread. Even if just a single thread runs in the JVM, the JVM would not
    shut down. Calling the `setDaemon(boolean)` method of a thread with argument `true`
    tags the thread as a daemon that can be automatically shut down if no other non-daemon
    thread is running.
  id: totrans-750
  prefs: []
  type: TYPE_NORMAL
  zh: 调用一个 `Thread` 实例的 `start()` 方法将在新线程中启动其执行。即使 JVM 中只有一个线程运行，JVM 也不会关闭。调用带有参数
    `true` 的 `setDaemon(boolean)` 方法将线程标记为守护线程，如果没有其他非守护线程正在运行，则可以自动关闭。
- en: 'All Clojure functions implement the `java.lang.Runnable` interface. Therefore,
    invoking a function in a new thread is very easy:'
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的Clojure函数都实现了`java.lang.Runnable`接口。因此，在新的线程中调用函数非常简单：
- en: '[PRE85]'
  id: totrans-752
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: The `run()` method does not accept any argument. We can work around it by creating
    a higher order function that needs no arguments, but internally applies the argument
    `3`.
  id: totrans-753
  prefs: []
  type: TYPE_NORMAL
  zh: '`run()`方法不接受任何参数。我们可以通过创建一个不需要参数的高阶函数来解决这个问题，但内部应用参数`3`。'
- en: Thread pools in the JVM
  id: totrans-754
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: JVM中的线程池
- en: 'Creating threads leads to the Operating System API calls, which is not always
    a cheap operation. The general practice is to create a pool of threads that can
    be recycled for different tasks. Java has a built-in support for threads pools.
    The interface called `java.util.concurrent.ExecutorService` represents the API
    for a thread pool. The most common way to create a thread pool is to use a factory
    method in the `java.util.concurrent.Executors` class:'
  id: totrans-755
  prefs: []
  type: TYPE_NORMAL
  zh: 创建线程会导致操作系统API调用，这并不总是个低成本的操作。通常的做法是创建一个线程池，这些线程可以被回收用于不同的任务。Java内置了对线程池的支持。名为`java.util.concurrent.ExecutorService`的接口代表了线程池的API。创建线程池最常见的方式是使用`java.util.concurrent.Executors`类中的工厂方法：
- en: '[PRE86]'
  id: totrans-756
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: The previous example is equivalent of the examples with raw threads that we
    saw in the previous sub-section. Thread pools are also capable of helping to track
    the completion, and the return value of a function, executed in a new thread.
    An ExecutorService accepts an instance of the `java.util.concurrent.Callable`
    instance as an argument to several methods that launch a task, and return `java.util.concurrent.Future`
    to track the final result.
  id: totrans-757
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的例子等同于我们在前一小节中看到的原始线程的例子。线程池也能够帮助跟踪新线程中执行函数的完成情况和返回值。ExecutorService接受一个`java.util.concurrent.Callable`实例作为参数，用于启动任务的几个方法，并返回`java.util.concurrent.Future`以跟踪最终结果。
- en: 'All the Clojure functions also implement the `Callable` interface, so we can
    use them as follows:'
  id: totrans-758
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的Clojure函数也实现了`Callable`接口，因此我们可以像下面这样使用它们：
- en: '[PRE87]'
  id: totrans-759
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: The thread pools described here are the same as the ones that we saw briefly
    in the Agents section earlier. Thread pools need to be shut down by calling the
    `shutdown()` method when no longer required.
  id: totrans-760
  prefs: []
  type: TYPE_NORMAL
  zh: 这里描述的线程池与我们在前面的代理部分简要看到的线程池相同。当不再需要时，线程池需要通过调用`shutdown()`方法来关闭。
- en: Clojure concurrency support
  id: totrans-761
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Clojure并发支持
- en: Clojure has some nifty built-in features to deal with concurrency. We already
    discussed about the agents, and how they use the thread pools, in an earlier section.
    There are some more concurrency features in Clojure to deal with the various use
    cases.
  id: totrans-762
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure有一些巧妙的内置功能来处理并发。我们已经在前面的小节中讨论了代理，以及它们如何使用线程池。Clojure还有一些其他并发特性来处理各种用例。
- en: Future
  id: totrans-763
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 未来
- en: 'We saw earlier in this section how to use the Java API to launch a new thread,
    to execute a function. Also, we learned how to get the result back. Clojure has
    a built-in support called "futures" to do these things in a much smoother and
    integrated manner. The basis of the futures is the function `future-call` (it
    takes a `no-arg` function as an argument), and the macro `future` (it takes the
    body of code) that builds on the former. Both of them immediately start a thread
    to execute the supplied code. The following snippet illustrates the functions
    that work with the future, and how to use them:'
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节前面，我们看到了如何使用Java API启动新线程，执行函数，以及如何获取结果。Clojure有一个内置的支持称为“futures”，可以以更平滑和集成的方式完成这些事情。futures的基础是`future-call`函数（它接受一个无参数函数作为参数），以及基于前者的宏`future`（它接受代码体）。两者都会立即启动一个线程来执行提供的代码。以下代码片段说明了与future一起工作的函数以及如何使用它们：
- en: '[PRE88]'
  id: totrans-765
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'One of the interesting aspects of `future-cancel` is that it can sometimes
    not only cancel tasks that haven''t started yet, but may also abort those that
    are halfway through execution:'
  id: totrans-766
  prefs: []
  type: TYPE_NORMAL
  zh: '`future-cancel`的一个有趣方面是，它有时不仅可以取消尚未开始的任务，还可以中止那些正在执行中的任务：'
- en: '[PRE89]'
  id: totrans-767
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: The previous scenario happens because Clojure's `future-cancel` cancels a future
    in such a way that if the execution has already started, it may be interrupted
    causing `InterruptedException`, which, if not explicitly caught, would simply
    abort the block of code. Beware of exceptions arising from the code that is executed
    in a future, because, by default, they are not reported verbosely! Clojure futures
    use the "solo" thread pool (used to execute the potentially blocking actions)
    that we discussed earlier with respect to the agents.
  id: totrans-768
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的情况发生是因为Clojure的`future-cancel`以这种方式取消future：如果执行已经启动，它可能会被中断，导致`InterruptedException`，如果没有显式捕获，则简单地终止代码块。注意来自future中执行代码的异常，因为默认情况下，它们不会被详细报告！Clojure的future使用“solo”线程池（用于执行可能阻塞的操作），这是我们之前在讨论agents时提到的。
- en: Promise
  id: totrans-769
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Promise
- en: A promise is a placeholder for the result of a computation that may or may not
    have occurred. A promise is not directly associated with any computation. By definition,
    a promise does not imply when the computation might occur, hence realizing the
    promise.
  id: totrans-770
  prefs: []
  type: TYPE_NORMAL
  zh: Promise是计算结果的占位符，该计算可能已经发生或尚未发生。Promise不直接与任何计算相关联。根据定义，promise不暗示计算何时可能发生，因此实现promise。
- en: Typically, a promise originates from one place in the code, and is realized
    by some other portion of the code that knows when and how to realize the promise.
    Very often, this happens in a multi-threaded code. If a promise is not realized
    yet, any attempt to read the value blocks all callers. If a promise is realized,
    then all the callers can read the value without being blocked. As with futures,
    a promise can be read with a timeout using `deref`.
  id: totrans-771
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，promise起源于代码的一个地方，由知道何时以及如何实现promise的代码的其他部分实现。这种情况通常发生在多线程代码中。如果promise尚未实现，任何尝试读取值的操作都会阻塞所有调用者。如果promise已经实现，那么所有调用者都可以读取值而不会被阻塞。与future一样，可以使用`deref`带有超时地读取promise。
- en: 'Here is a very simple example showing how to use promises:'
  id: totrans-772
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个非常简单的例子，展示了如何使用promise：
- en: '[PRE90]'
  id: totrans-773
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: A promise is a very powerful tool that can be passed around as function arguments.
    It can be stored in a reference type, or simply be used for a high level coordination.
  id: totrans-774
  prefs: []
  type: TYPE_NORMAL
  zh: Promise是一个非常强大的工具，可以作为函数参数传递。它可以存储在引用类型中，或者简单地用于高级协调。
- en: Clojure parallelization and the JVM
  id: totrans-775
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Clojure并行化和JVM
- en: We observed in [Chapter 1](ch15.html "Chapter 8. Application Performance"),
    *Performance by Design* that parallelism is a function of the hardware, whereas
    concurrency is a function of the software, assisted by the hardware support. Except
    for the algorithms that are purely sequential by nature, concurrency is the favored
    means to facilitate parallelism, and achieve better performance. Immutable and
    stateless data is a catalyst to concurrency, as there is no contention between
    threads, due to absence of mutable data.
  id: totrans-776
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第1章](ch15.html "第8章 应用性能") *设计性能* 中观察到，并行性是硬件的函数，而并发性是软件的函数，由硬件支持辅助。除了本质上纯粹是顺序的算法之外，并发性是促进并行性和提高性能的首选方法。不可变和无状态数据是并发的催化剂，因为没有可变数据，线程之间没有竞争。
- en: Moore's law
  id: totrans-777
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Moore's law
- en: In 1965, Intel's cofounder, Gordon Moore, made an observation that the number
    of transistors per square inch on Integrated Circuits doubles every 24 months.
    He also predicted that the trend would continue for 10 years, but in practice,
    it has continued till now, marking almost half a century. More transistors have
    resulted in more computing power. With a greater number of transistors in the
    same area, we need higher clock speed to transmit signals to all of the transistors.
    Secondly, transistors need to get smaller in size to fit in. Around 2006-2007,
    the clock speed that the circuitry could work with topped out at about 2.8GHz,
    due to the heating issues and the laws of physics. Then, the multi-core processors
    were born.
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: 在1965年，英特尔联合创始人戈登·摩尔观察到，集成电路每平方英寸的晶体管数量每24个月翻一番。他还预测这种趋势将持续10年，但实际上，它一直持续到现在，几乎半个世纪。更多的晶体管导致了更多的计算能力。在相同面积内晶体管数量更多，我们需要更高的时钟速度来传输所有晶体管的信号。其次，晶体管需要变得更小以适应。大约在2006-2007年，电路能够工作的时钟速度达到了大约2.8GHz，这是由于散热问题和物理定律。然后，多核处理器诞生了。
- en: Amdahl's law
  id: totrans-779
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amdahl's law
- en: The multi-core processors naturally require splitting up computation in order
    to achieve parallelization. Here begins a conflict—a program that was made to
    be run sequentially cannot make use of the parallelization features of the multi-core
    processors. The program must be altered to find the opportunity to split up computation
    at every step, while keeping the cost of coordination in mind. This results in
    a limitation that a program can be no more faster than its longest sequential
    part (*contention*, or *seriality*), and the coordination overhead. This characteristic
    was described by Amdahl's law.
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
  zh: 多核处理器自然需要分割计算以实现并行化。从这里开始出现冲突——原本设计为顺序运行的程序无法利用多核处理器的并行化特性。程序必须进行修改，以便在每一步找到分割计算的机会，同时考虑到协调成本。这导致了一个限制，即程序的速度不能超过其最长的顺序部分（*竞争*，或*串行性*），以及协调开销。这一特性被Amdahl定律所描述。
- en: Universal Scalability Law
  id: totrans-781
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通用可扩展性定律
- en: 'Dr Neil Gunther''s Universal Scalability Law (USL) is a superset of Amdahl''s
    Law that makes both: *contention (α)* and *coherency (β)* the first class concerns
    in quantifying the scalability very closely to the realistic parallel systems.
    Coherency implies the coordination overhead (latency) in making the result of
    one part of a parallelized program to be available to another. While Amdahl''s
    Law states that contention (seriality) causes performance to level off, USL goes
    to show that the performance actually degrades with excessive parallelization.
    USL is described with the following formula:'
  id: totrans-782
  prefs: []
  type: TYPE_NORMAL
  zh: 尼尔·冈瑟博士的通用可扩展性定律（USL）是Amdahl定律的超集，它将*竞争（α）*和*一致性（β）*作为量化可扩展性的第一类关注点，使其非常接近现实并行系统的可扩展性。一致性意味着协调开销（延迟）在使并行程序的一部分结果可供另一部分使用时的协调。虽然Amdahl定律表明竞争（串行性）会导致性能水平化，但USL表明，性能实际上随着过度并行化而下降。USL用以下公式描述：
- en: C(N) = N / (1 + α ((N – 1) + β N (N – 1)))
  id: totrans-783
  prefs: []
  type: TYPE_NORMAL
  zh: C(N) = N / (1 + α ((N – 1) + β N (N – 1)))
- en: Here, C(N) implies relative capacity or throughput in terms of the source of
    concurrency, such as physical processors, or the users driving the software application.
    α implies the degree of contention because of the shared data or the sequential
    code, and β implies penalty incurred for maintaining the consistency of shared
    data. I would encourage you to pursue USL further ([http://www.perfdynamics.com/Manifesto/USLscalability.html](http://www.perfdynamics.com/Manifesto/USLscalability.html)),
    as this is a very important resource for studying the impact of concurrency on
    scalability and the performance of the systems.
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，C(N)表示根据并发源（如物理处理器或驱动软件应用的用户）的相对容量或吞吐量。α表示由于共享数据或顺序代码引起的竞争程度，而β表示维护共享数据一致性所承受的惩罚。我鼓励您进一步研究USL（[http://www.perfdynamics.com/Manifesto/USLscalability.html](http://www.perfdynamics.com/Manifesto/USLscalability.html)），因为这是研究并发对可扩展性和系统性能影响的重要资源。
- en: Clojure support for parallelization
  id: totrans-785
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Clojure对并行化的支持
- en: A program that relies on mutation cannot parallelize its parts without creating
    contention on the mutable state. It requires coordination overhead, which makes
    the situation worse. Clojure's immutable nature is better suited to parallelize
    the parts of a program. Clojure also has some constructs that are suited for parallelism
    by the virtue of Clojure's consideration of available hardware resources. The
    result is, the operations execute optimized for certain use case scenarios.
  id: totrans-786
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖于变异的程序不能在不创建可变状态竞争的情况下并行化其部分。它需要协调开销，这使情况变得更糟。Clojure的不可变特性更适合并行化程序的部分。Clojure还有一些结构，由于Clojure考虑了可用的硬件资源，因此适合并行化。结果是，操作针对某些用例场景进行了优化。
- en: pmap
  id: totrans-787
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: pmap
- en: The `pmap` function (similar to `map`) accepts as arguments a function and one,
    or more collections of data elements. The function is applied to each of the data
    elements in such a way that some of the elements are processed by the function
    in parallel. The parallelism factor is chosen at runtime by the `pmap` implementation,
    as two greater than the total number of available processors. It still processes
    the elements lazily, but the realization factor is same as the parallelism factor.
  id: totrans-788
  prefs: []
  type: TYPE_NORMAL
  zh: '`pmap`函数（类似于`map`）接受一个函数和一个或多个数据元素集合作为参数。该函数应用于数据元素中的每一个，使得一些元素由函数并行处理。并行化因子由`pmap`实现选择，在运行时选择大于可用处理器总数的值。它仍然以惰性方式处理元素，但实现因子与并行化因子相同。'
- en: 'Check out the following code:'
  id: totrans-789
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下代码：
- en: '[PRE91]'
  id: totrans-790
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: To use `pmap` effectively, it is imperative that we understand what it is meant
    for. As the documentation says, it is meant for computationally intensive functions.
    It is optimized for CPU-bound and cache-bound jobs. High latency and low CPU tasks,
    such as blocking I/O, are a gross misfit for `pmap`. Another pitfall to be aware
    of is whether the function used in `pmap` performs a lot of memory operations
    or not. Since the same function will be applied across all the threads, all the
    processors (or cores) may compete for the memory interconnect and the sub-system
    bandwidth. If the parallel memory access becomes a bottleneck, `pmap` cannot make
    the operation truly parallel, due to the contention on the memory access.
  id: totrans-791
  prefs: []
  type: TYPE_NORMAL
  zh: 要有效地使用 `pmap`，我们必须了解它的用途。正如文档所述，它适用于计算密集型函数。它针对 CPU 密集型和缓存密集型工作进行了优化。高延迟和低 CPU
    任务，如阻塞 I/O，与 `pmap` 不太匹配。另一个需要注意的陷阱是 `pmap` 中使用的函数是否执行了大量的内存操作。由于相同的函数将在所有线程中应用，所有处理器（或核心）可能会竞争内存互连和子系统带宽。如果并行内存访问成为瓶颈，由于内存访问的竞争，`pmap`
    无法真正实现并行操作。
- en: Another concern is what happens when several `pmap` operations run concurrently?
    Clojure does not attempt to detect multiple `pmap`s running concurrently. The
    same number of threads will be launched afresh for every new `pmap` operation.
    The developer is responsible to ensure the performance characteristics, and the
    response time of the program resulting from the concurrent pmap executions. Usually,
    when the latency reasons are paramount, it is advisable to limit the concurrent
    instances of `pmap` running in the program.
  id: totrans-792
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个关注点是当多个 `pmap` 操作并发运行时会发生什么？Clojure 不会尝试检测并发运行的多 `pmap`。对于每个新的 `pmap` 操作，都会重新启动相同数量的线程。开发者负责确保并发
    `pmap` 执行产生的程序的性能特征和响应时间。通常，当延迟原因是首要考虑时，建议限制程序中运行的并发 `pmap` 实例数量。
- en: pcalls
  id: totrans-793
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: pcalls
- en: The `pcalls` function is built using `pmap`, so it borrows properties from the
    latter. However, the `pcalls` function accepts zero or more functions as arguments
    and executes them in parallel, returning the result values of the calls as a list.
  id: totrans-794
  prefs: []
  type: TYPE_NORMAL
  zh: '`pcalls` 函数是用 `pmap` 构建的，因此它借鉴了后者的属性。然而，`pcalls` 函数接受零个或多个函数作为参数，并并行执行它们，将调用结果作为列表返回。'
- en: pvalues
  id: totrans-795
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: pvalues
- en: The `pvalues` macro is built using `pcalls`, so it transitively shares the properties
    of `pmap`. It's behavior is similar to `pcalls`, but instead of functions, it
    accepts zero or more S-expressions that are evaluated in the parallel using `pmap`.
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
  zh: '`pvalues` 宏是用 `pcalls` 构建的，因此它间接共享 `pmap` 的属性。它的行为类似于 `pcalls`，但它接受零个或多个在并行中使用
    `pmap` 评估的 S-表达式，而不是函数。'
- en: Java 7's fork/join framework
  id: totrans-797
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Java 7 的 fork/join 框架
- en: Java 7 introduced a new framework for parallelism called "fork/join," based
    on divide-and-conquer and the work-stealing scheduler algorithms. The basic idea
    of how to use the fork/join framework is fairly simple—if the work is small enough,
    then do it directly in the same thread; otherwise, split the work into two pieces,
    invoke them in a fork/join thread pool, and wait for the results to combine.
  id: totrans-798
  prefs: []
  type: TYPE_NORMAL
  zh: Java 7 引入了一个名为 "fork/join" 的新并行框架，该框架基于分治和窃取工作调度算法。使用 fork/join 框架的基本思路相当简单——如果工作足够小，则直接在同一线程中执行；否则，将工作分成两部分，在
    fork/join 线程池中调用它们，并等待结果合并。
- en: This way, the job gets recursively split into smaller parts such as an inverted
    tree, until the smallest part can be carried out in just a single thread. When
    the leaf/subtree jobs return, the parent combines the result of all children,
    and returns the results.
  id: totrans-799
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，工作会递归地分成更小的部分，例如倒置树，直到最小部分可以仅用单个线程执行。当叶/子树工作返回时，父工作将所有子工作的结果合并，并返回结果。
- en: 'The fork/join framework is implemented in Java 7 in terms of a special kind
    of thread pool; check out `java.util.concurrent.ForkJoinPool`. The specialty of
    this thread pool is that it accepts the jobs of `java.util.concurrent.ForkJoinTask`
    type, and whenever these jobs block, waiting for the child jobs to finish, the
    threads used by the waiting jobs are allocated to the child jobs. When the child
    finishes its work, the thread is allocated back to the blocked parent jobs in
    order to continue. This style of dynamic thread allocation is described as "work-stealing".
    The fork/join framework can be used from within Clojure. The `ForkJoinTask` interface
    has two implementations: `RecursiveAction` and `RecursiveTask` in the `java.util.concurrent`
    package. Concretely, `RecursiveTask` maybe more useful with Clojure, as `RecursiveAction`
    is designed to work with mutable data, and does not return any value from its
    operation.'
  id: totrans-800
  prefs: []
  type: TYPE_NORMAL
  zh: Fork/join 框架是用 Java 7 实现的，它是一种特殊的线程池；请查看 `java.util.concurrent.ForkJoinPool`。这个线程池的特殊之处在于它接受
    `java.util.concurrent.ForkJoinTask` 类型的作业，并且每当这些作业阻塞，等待子作业完成时，等待作业使用的线程被分配给子作业。当子作业完成其工作后，线程被分配回阻塞的父作业以继续。这种动态线程分配的方式被称为“工作窃取”。Fork/join
    框架可以从 Clojure 内部使用。`ForkJoinTask` 接口有两个实现：`java.util.concurrent` 包中的 `RecursiveAction`
    和 `RecursiveTask`。具体来说，`RecursiveTask` 可能对 Clojure 更有用，因为 `RecursiveAction` 是为与可变数据一起工作而设计的，并且其操作不返回任何值。
- en: Using the fork-join framework entails choosing the batch size to split a job
    into, which is a crucial factor in parallelizing a long job. Too large a batch
    size may not utilize all the CPU cores enough; on the other hand, a small batch
    size may lead to a longer overhead, coordinating across the parent/child batches.
    As we will see in the next section, Clojure integrates with the Fork/join framework
    to parallelize the reducers implementation.
  id: totrans-801
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 fork-join 框架意味着选择将作业拆分成批次的批次大小，这是并行化长时间作业的一个关键因素。批次大小过大可能无法充分利用所有 CPU 核心；另一方面，批次大小过小可能会导致更长的开销，在父/子批次之间进行协调。正如我们将在下一节中看到的，Clojure
    集成了 Fork/join 框架以并行化 Reducer 的实现。
- en: Parallelism with reducers
  id: totrans-802
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Reducer 的并行性
- en: Reducers are a new abstraction introduced in Clojure 1.5, and are likely to
    have a wider impact on the rest of the Clojure implementation in the future versions.
    They depict a different way of thinking about processing collections in Clojure—the
    key concept is to break down the notion that collections can be processed only
    sequentially, lazily, or producing a seq, and more. Moving away from such a behavior
    guarantee raises the potential for eager and parallel operations on one hand,
    whereas incurring constraints on the other. Reducers are compatible with the existing
    collections.
  id: totrans-803
  prefs: []
  type: TYPE_NORMAL
  zh: Reducer 是 Clojure 1.5 中引入的一种新抽象，未来版本中可能会对 Clojure 的其余实现产生更广泛的影响。它们描绘了在 Clojure
    中处理集合的另一种思考方式——关键概念是打破集合只能顺序、惰性或产生序列处理的观念，以及更多。摆脱这种行为的保证一方面提高了进行贪婪和并行操作的可能性，另一方面则带来了约束。Reducer
    与现有集合兼容。
- en: For an example, a keen observation of the regular `map` function reveals that
    its classic definition is tied to the mechanism (recursion), order (sequential),
    laziness (often), and representation (list/seq/other) aspects of producing the
    result. Most of this actually defines "how" the operation is performed, rather
    than "what" needs to be done. In the case of `map`, the "what" is all about applying
    a function to each element of its collection arguments. But since the collection
    types can be of various types (tree-structured, sequence, iterator, and more),
    the operating function cannot know how to navigate the collection. Reducers decouple
    the "what" and "how" parts of the operation.
  id: totrans-804
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对常规的 `map` 函数的敏锐观察揭示，其经典定义与产生结果时的机制（递归）、顺序（顺序）、惰性（通常）和表示（列表/序列/其他）方面紧密相关。实际上，这大部分定义了“如何”执行操作，而不是“需要做什么”。在
    `map` 的情况下，“需要做什么”就是将函数应用于其集合参数的每个元素。但由于集合类型可以是各种类型（树状结构、序列、迭代器等），操作函数无法知道如何遍历集合。Reducer
    将操作中的“需要做什么”和“如何做”部分解耦。
- en: Reducible, reducer function, reduction transformation
  id: totrans-805
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可约性、Reducer 函数、缩减变换
- en: Collections are of various kinds, hence only a collection knows how to navigate
    itself. In the reducers model at a fundamental level, an internal "reduce" operation
    in each collection type has access to its properties and behavior, and access
    to what it returns. This makes all the collection types essentially "reducible".
    All the operations that work with collections can be modeled in terms of the internal
    "reduce" operation. The new modeled form of such operations is a "reducing function",
    which is typically a function of two arguments, the first argument being the accumulator,
    and the second being the new input.
  id: totrans-806
  prefs: []
  type: TYPE_NORMAL
  zh: 集合种类繁多，因此只有集合本身知道如何导航自己。在reducers模型的基本层面上，每个集合类型的内部“reduce”操作可以访问其属性和行为，以及返回的内容。这使得所有集合类型本质上都是“可还原”的。所有与集合一起工作的操作都可以用内部“reduce”操作来建模。这种操作的新建模形式是一个“reducing函数”，通常是一个接受两个参数的函数，第一个参数是累加器，第二个是新输入。
- en: How does it work when we need to layer several functions upon another, over
    the elements of a collection? For an example, let's say first we need to "filter",
    "map," and then "reduce". In such cases, a "transformation function" is used to
    model a reducer function (for example, for "filter") as another reducer function
    (for "map") in such a way that it adds the functionality during the transformation.
    This is called "reduction transformation".
  id: totrans-807
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们需要在集合的元素上叠加多个函数时，它是如何工作的？例如，假设我们首先需要“过滤”、“映射”，然后“减少”。在这种情况下，使用“转换函数”来建模reducer函数（例如，对于“过滤”），作为另一个reducer函数（对于“映射”）的建模方式，这样在转换过程中添加功能。这被称为“减少转换”。
- en: Realizing reducible collections
  id: totrans-808
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现可还原集合
- en: While the reducer functions retain the purity of the abstraction, they are not
    useful all by themselves. The reducer operations in the namespace called as `clojure.core.reducers`
    similar to `map`, `filter`, and more, basically return a reducible collection
    that embed the reducer functions within themselves. A reducible collection is
    not realized, not even lazily realized—rather, it is just a recipe that is ready
    to be realized. In order to realize a reducible collection, we must use one of
    the `reduce` or `fold` operations.
  id: totrans-809
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然reducer函数保留了抽象的纯洁性，但它们本身并没有什么用处。在名为`clojure.core.reducers`的命名空间中的reducer操作，类似于`map`、`filter`等，基本上返回一个包含reducer函数在内的可还原集合。可还原集合并不是实际实现的，甚至不是懒实现的——而只是一个准备好的实现方案。为了实现一个可还原集合，我们必须使用`reduce`或`fold`操作之一。
- en: The `reduce` operation that realizes a reducible collection is strictly sequential,
    albeit with the performance gains compared to `clojure.core/reduce`, due to reduced
    object allocations on the heap. The `fold` operation, which realizes a reducible
    collection, is potentially parallel, and uses a "reduce-combine" approach over
    the fork-join framework. Unlike the traditional "map-reduce" style, the use of
    fork/join the reduce-combine approach reduces at the bottom, and subsequently
    combines by the means of reduction again. This makes the `fold` implementation
    less wasteful and better performing.
  id: totrans-810
  prefs: []
  type: TYPE_NORMAL
  zh: 实现可还原集合的`reduce`操作是严格顺序的，尽管与`clojure.core/reduce`相比有性能提升，这是因为减少了堆上的对象分配。实现可还原集合的`fold`操作可能是并行的，并使用“reduce-combine”方法在fork-join框架上。与传统的“map-reduce”风格不同，使用fork/join的reduce-combine方法在底层进行减少，然后通过减少的方式再次合并。这使得`fold`实现更加节省资源，性能更优。
- en: Foldable collections and parallelism
  id: totrans-811
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可折叠集合与并行性
- en: Parallel reduction by `fold` puts certain constraints on the collections and
    operations. The tree-based collection types (persistent map, persistent vector,
    and persistent set) are amenable to parallelization. At the same time, the sequences
    may not be parallelized by `fold`. Secondly, `fold` requires that the individual
    reducer functions should be "associative", that is, the order of the input arguments
    applied to the reducer function should not matter. The reason being, `fold` can
    segment the elements of the collection to process in parallel, and the order in
    which they may be combined is not known in advance.
  id: totrans-812
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`fold`进行的并行减少对集合和操作施加了某些约束。基于树的集合类型（持久化映射、持久化向量和持久化集合）适合并行化。同时，序列可能无法通过`fold`并行化。其次，`fold`要求单个reducer函数应该是“结合律”，即应用于reducer函数的输入参数的顺序不应影响结果。原因是`fold`可以将集合的元素分割成可以并行处理的段，而它们可能合并的顺序是事先不知道的。
- en: 'The `fold` function accepts few extra arguments, such as the "combine function,"
    and the partition batch size (default being 512) for the parallel processing.
    Choosing the optimum partition size depends on the jobs, host capabilities, and
    the performance benchmarking. There are certain functions that are foldable (that
    is, parallelizable by `fold`), and there are others that are not, as shown here.
    They live in the `clojure.core.reducers` namespace:'
  id: totrans-813
  prefs: []
  type: TYPE_NORMAL
  zh: '`fold` 函数接受一些额外的参数，例如“组合函数”和用于并行处理的分区批量大小（默认为 512）。选择最佳分区大小取决于工作负载、主机能力和性能基准测试。某些函数是可折叠的（即可以通过
    `fold` 并行化），而其他则不是，如下所示。它们位于 `clojure.core.reducers` 命名空间中：'
- en: '**Foldable**: `map`, `mapcat`, `filter`, `remove`, and `flatten`'
  id: totrans-814
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可折叠**：`map`、`mapcat`、`filter`、`remove` 和 `flatten`'
- en: '**Non-foldable**: `take-while`, `take`, and `drop`'
  id: totrans-815
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不可折叠**：`take-while`、`take` 和 `drop`'
- en: '**Combine functions**: `cat`, `foldcat`, and `monoid`'
  id: totrans-816
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**组合函数**：`cat`、`foldcat` 和 `monoid`'
- en: A notable aspect of reducers is that it is foldable in parallel only when the
    collection is a tree type. This implies that the entire data set must be loaded
    in the heap memory when folding over them. This has the downside of memory consumption
    during the high load on a system. On the other hand, a lazy sequence is a perfectly
    reasonable solution for such scenarios. When processing large amount of data,
    it may make sense to use a combination of lazy sequences and reducers for performance.
  id: totrans-817
  prefs: []
  type: TYPE_NORMAL
  zh: Reducers 的一个显著特点是，只有在集合是树类型时才能并行折叠。这意味着在折叠它们时，整个数据集必须加载到堆内存中。这导致在系统高负载期间内存消耗增加。另一方面，对于此类场景，一个惰性序列是一个完全合理的解决方案。在处理大量数据时，使用惰性序列和
    Reducers 的组合来提高性能可能是有意义的。
- en: Summary
  id: totrans-818
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: Concurrency and parallelism are extremely important for performance in this
    multi-core age. Effective use of concurrency requires substantial understanding
    of the underlying principles and details. Fortunately, Clojure provides safe and
    elegant ways to deal with concurrency and state. Clojure's new feature called
    "reducers" provides a way to achieve granular parallelism. In the coming years,
    we are likely to see more and more processor cores, and an increasing demand to
    write code that takes advantage of these. Clojure places us in the right spot
    to meet such challenges.
  id: totrans-819
  prefs: []
  type: TYPE_NORMAL
  zh: 并发和并行性在多核时代对性能至关重要。有效利用并发需要深入了解其底层原理和细节。幸运的是，Clojure 提供了安全且优雅的方式来处理并发和状态。Clojure
    的新特性“reducers”提供了一种实现细粒度并行化的方法。在未来的几年里，我们可能会看到越来越多的处理器核心，以及编写利用这些核心的代码的需求不断增加。Clojure
    将我们置于应对这些挑战的正确位置。
- en: In the next chapter, we will look at the performance measurement, analysis,
    and monitoring.
  id: totrans-820
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨性能测量、分析和监控。
- en: Chapter 6. Measuring Performance
  id: totrans-821
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 6 章。测量性能
- en: 'Depending on the expected and actual performance, and the lack or presence
    of a measuring system, performance analysis and tuning can be a fairly elaborate
    process. Now we will discuss the analysis of performance characteristics and ways
    to measure and monitor them. In this chapter we will cover the following topics:'
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
  zh: 根据预期的和实际的表现，以及是否存在测量系统，性能分析和调整可能是一个相当复杂的过程。现在我们将讨论性能特性的分析以及测量和监控它们的方法。在本章中，我们将涵盖以下主题：
- en: Measuring performance and understanding the results
  id: totrans-823
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量性能和理解结果
- en: What performance tests to carry out for different purposes
  id: totrans-824
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据不同目的进行性能测试
- en: Monitoring performance and obtaining metrics
  id: totrans-825
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控性能和获取指标
- en: Profiling Clojure code to identify performance bottlenecks
  id: totrans-826
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析 Clojure 代码以识别性能瓶颈
- en: Performance measurement and statistics
  id: totrans-827
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能测量和统计
- en: Measuring performance is the stepping stone to performance analysis. As we noted
    earlier in this book, there are several performance parameters to be measured
    with respect to various scenarios. Clojure's built-in `time` macro is a tool to
    measure the amount of time elapsed while executing a body of code. Measuring performance
    factors is a much more involved process. The measured performance numbers may
    have linkages with each other that we need to analyze. It is a common practice
    to use statistical concepts to establish the linkage factors. We will discuss
    some basic statistical concepts in this section and use that to explain how the
    measured data gives us the bigger picture.
  id: totrans-828
  prefs: []
  type: TYPE_NORMAL
  zh: 测量性能是性能分析的基础。正如我们在这本书中之前提到的，我们需要根据各种场景来测量几个性能参数。Clojure 内置的 `time` 宏是一个用于测量执行代码体所花费时间的工具。测量性能因素是一个更为复杂的过程。测量的性能数值之间可能存在关联，我们需要进行分析。使用统计概念来建立关联因素是一种常见的做法。在本节中，我们将讨论一些基本的统计概念，并使用这些概念来解释如何通过测量的数据获得更全面的视角。
- en: A tiny statistics terminology primer
  id: totrans-829
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一份微小的统计学术语入门指南
- en: 'When we have a series of quantitative data, such as latency in milliseconds
    for the same operation (measured over a number of executions), we can observe
    a number of things. First, and the most obvious, are the minimum and maximum values
    in the data. Let''s take an example dataset to analyze further:'
  id: totrans-830
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有一系列定量数据，例如相同操作的延迟（在多次执行中测量）时，我们可以观察到许多事情。首先，也是最明显的，是数据中的最小值和最大值。让我们用一个示例数据集来进一步分析：
- en: '| 23 | 19 | 21 | 24 | 26 | 20 | 22 | 21 | 25 | 168 | 23 | 20 | 29 | 172 | 22
    | 24 | 26 |'
  id: totrans-831
  prefs: []
  type: TYPE_TB
  zh: '| 23 | 19 | 21 | 24 | 26 | 20 | 22 | 21 | 25 | 168 | 23 | 20 | 29 | 172 | 22
    | 24 | 26 |'
- en: Median, first quartile, third quartile
  id: totrans-832
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 中位数，第一四分位数，第三四分位数
- en: 'We can see that the minimum latency here is 19 ms whereas the maximum latency
    is 172ms. We can also observe that the average latency here is about 40ms. Let''s
    sort this data in ascending order:'
  id: totrans-833
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，这里的最低延迟是19毫秒，而最高延迟是172毫秒。我们还可以观察到这里的平均延迟大约是40毫秒。让我们按升序排序这些数据：
- en: '| 19 | 20 | 20 | 21 | 21 | 22 | 22 | 23 | 23 | 24 | 24 | 25 | 26 | 26 | 29
    | 168 | 172 |'
  id: totrans-834
  prefs: []
  type: TYPE_TB
  zh: '| 19 | 20 | 20 | 21 | 21 | 22 | 22 | 23 | 23 | 24 | 24 | 25 | 26 | 26 | 29
    | 168 | 172 |'
- en: 'The center element of the previous dataset, that is the ninth element (value
    23), is considered the **median** of the dataset. It is noteworthy that the median
    is a better representative of the center of the data than the **average** or **mean**.
    The center element of the left half, that is the fifth element (value 21), is
    considered the **first quartile**. Similarly, the value in the center of the right
    half, that is the 13th element (value 26), is considered the **third quartile**
    of the dataset. The difference between the third quartile and the first quartile
    is called **Inter Quartile Range (IQR)**, which is 5 in this case. This can be
    illustrated with a **boxplot** , as follows:'
  id: totrans-835
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个数据集的中心元素，即第九个元素（值为23），被认为是数据集的**中位数**。值得注意的是，中位数比**平均数**或**均值**更能代表数据的中心。左半部分的中心元素，即第五个元素（值为21），被认为是**第一四分位数**。同样，右半部分的中心值，即第13个元素（值为26），被认为是数据集的**第三四分位数**。第三四分位数与第一四分位数之间的差称为**四分位距（IQR）**，在本例中为5。这可以通过以下**箱线图**来表示：
- en: '![Median, first quartile, third quartile](img/3642_06_01.jpg)'
  id: totrans-836
  prefs: []
  type: TYPE_IMG
  zh: '![中位数，第一四分位数，第三四分位数](img/3642_06_01.jpg)'
- en: A boxplot highlights the first quartile, median and the third quartile of a
    dataset. As you can see, two "outlier" latency numbers (168 and 172) are unusually
    higher than the others. Median makes no representation of outliers in a dataset,
    whereas the mean does.
  id: totrans-837
  prefs: []
  type: TYPE_NORMAL
  zh: 箱线图突出了数据集的第一四分位数、中位数和第三四分位数。如您所见，两个“异常值”延迟数（168和172）异常高于其他数值。中位数在数据集中不表示异常值，而均值则表示。
- en: '![Median, first quartile, third quartile](img/3642_06_02.jpg)'
  id: totrans-838
  prefs: []
  type: TYPE_IMG
  zh: '![中位数，第一四分位数，第三四分位数](img/3642_06_02.jpg)'
- en: A histogram (the diagram shown previously) is another way to display a dataset
    where we batch the data elements in **periods** and expose the **frequency** of
    such periods. A period contains the elements in a certain range. All periods in
    a histogram are generally the same size; however, it is not uncommon to omit certain
    periods when there is no data.
  id: totrans-839
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图（之前显示的图表）是另一种显示数据集的方式，我们将数据元素分批处理在**时间段**内，并展示这些时间段的**频率**。一个时间段包含一定范围内的元素。直方图中的所有时间段通常大小相同；然而，当没有数据时，省略某些时间段并不罕见。
- en: Percentile
  id: totrans-840
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 百分位数
- en: A **percentile** is expressed with a parameter, such as 99 percentile, or 95
    percentile etc. A percentile is the value below which all the specified percentage
    of data elements exist. For example, 95 percentile means the value *N* among a
    dataset, such that 95 percent of elements in the dataset are below *N* in value.
    As a concrete example, 85 percentile from the dataset of latency numbers we discussed
    earlier in this section is 29, because out of 17 total elements, 14 (which is
    85 percent of 17) other elements in the dataset have a value below 29\. A quartile
    splits a dataset into chunks of 25 percent elements each. Therefore, the first
    quartile is actually 25 percentile, the median is 50 percentile, and the third
    quartile is 75 percentile.
  id: totrans-841
  prefs: []
  type: TYPE_NORMAL
  zh: '**百分位数**用参数表示，例如99百分位数，或95百分位数等。百分位数是指所有指定百分比的数值都存在的值。例如，95百分位数意味着数据集中第 *N*
    个值，使得数据集中95%的元素值低于 *N*。作为一个具体的例子，我们之前在本节中讨论的延迟数据集的85百分位数是29，因为总共有17个元素，其中14个（即17的85%）其他元素在数据集中的值低于29。四分位数将数据集分成每个25%元素的块。因此，第一个四分位数实际上是25百分位数，中位数是50百分位数，第三个四分位数是75百分位数。'
- en: Variance and standard deviation
  id: totrans-842
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 方差和标准差
- en: 'The spread of the data, that is, how far away the data elements are from the
    center value, gives us further insight into the data. Consider the *i^(th)* deviation
    as the difference between the *i^(th)* dataset element value (in statistics terms,
    a "variable" value) and its mean; we can represent it as ![Variance and standard
    deviation](img/image006.jpg). We can express its "variance" and "standard deviation"
    as follows:'
  id: totrans-843
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的分布范围，即数据元素与中心值的距离，为我们提供了对数据的进一步洞察。考虑第 *i* 个偏差作为第 *i* 个数据集元素值（在统计学中称为“变量”值）与其均值的差；我们可以将其表示为![方差和标准差](img/image006.jpg)。我们可以用以下方式表示其“方差”和“标准差”：
- en: Variance = ![Variance and standard deviation](img/image008.jpg), standard deviation
    (σ) = ![Variance and standard deviation](img/image010.jpg) = ![Variance and standard
    deviation](img/image012.jpg)
  id: totrans-844
  prefs: []
  type: TYPE_NORMAL
  zh: 方差 = ![方差和标准差](img/image008.jpg)，标准差（σ）= ![方差和标准差](img/image010.jpg) = ![方差和标准差](img/image012.jpg)
- en: 'Standard deviation is shown as the Greek letter "sigma", or simply "s". Consider
    the following Clojure code to determine variance and standard deviation:'
  id: totrans-845
  prefs: []
  type: TYPE_NORMAL
  zh: 标准差用希腊字母“sigma”表示，或简单地表示为“s”。考虑以下Clojure代码来确定方差和标准差：
- en: '[PRE92]'
  id: totrans-846
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: You can use the Clojure-based platform Incanter ([http://incanter.org/](http://incanter.org/))
    for statistical computations. For example, you can find standard deviation using
    `(incanter.stats/sd tdata)` in Incanter.
  id: totrans-847
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用基于Clojure的平台Incanter([http://incanter.org/](http://incanter.org/))进行统计分析。例如，您可以在Incanter中使用`(incanter.stats/sd
    tdata)`来找到标准差。
- en: The **empirical rule** states the relationship between the elements of a dataset
    and SD. It says that 68.3 percent of all elements in a dataset lie in the range
    of one (positive or negative) SD from the mean, 95.5 percent of all elements lie
    in two SDs from the mean, and 99.7 percent of all data elements lie in three SDs
    from the mean.
  id: totrans-848
  prefs: []
  type: TYPE_NORMAL
  zh: '**经验法则**说明了数据集元素与标准差（SD）之间的关系。它指出，数据集中所有元素的68.3%位于均值一个（正或负）标准差的范围内，95.5%的所有元素位于均值的两个标准差范围内，而99.7%的所有数据元素位于均值的三个标准差范围内。'
- en: Looking at the latency dataset we started out with, one SD from the mean is
    ![Variance and standard deviation](img/image014.jpg)(![Variance and standard deviation](img/image016.jpg)
    range -9 to 89) containing 88 percent of all elements. Two SDs from the mean is
    ![Variance and standard deviation](img/image014.jpg) range -58 to 138) containing
    the same 88 percent of all elements. However, three SDs from the mean is(![Variance
    and standard deviation](img/image018.jpg)range -107 to 187) containing 100 percent
    of all elements. There is a mismatch between what the empirical rule states and
    the results we found, because the empirical rule applies generally to uniformly
    distributed datasets with a large number of elements.
  id: totrans-849
  prefs: []
  type: TYPE_NORMAL
  zh: 观察我们最初开始讨论的延迟数据集，从均值的一个标准差是![方差和标准差](img/image014.jpg)(![方差和标准差](img/image016.jpg)范围
    -9 到 89)包含88%的所有元素。从均值的两个标准差是![方差和标准差](img/image014.jpg)范围 -58 到 138)包含相同88%的所有元素。然而，从均值的三个标准差是(![方差和标准差](img/image018.jpg)范围
    -107 到 187)包含100%的所有元素。经验法则所陈述的内容与我们的结果之间存在不匹配，因为经验法则通常适用于具有大量元素的均匀分布数据集。
- en: Understanding Criterium output
  id: totrans-850
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解Criterium输出
- en: 'In [Chapter 4](ch11.html "Chapter 4. Host Performance"), *Host Performance*,
    we introduced the Clojure library *Criterium* to measure the latency of Clojure
    expressions. A sample benchmarking result is as follows:'
  id: totrans-851
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](ch11.html "第4章。主机性能")中，我们介绍了Clojure库*Criterium*来测量Clojure表达式的延迟。以下是一个基准测试结果的示例：
- en: '[PRE93]'
  id: totrans-852
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: We can see that the result has some familiar terms we discussed earlier in this
    section. A high mean and low standard deviation indicate that there is not a lot
    of variation in the execution times. Likewise, the lower (first) and upper (third)
    quartiles indicate that they are not too far away from the mean. This result implies
    that the body of code is more or less stable in terms of response time. Criterium
    repeats the execution many times to collect the latency numbers.
  id: totrans-853
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，结果中包含了一些我们在本节前面讨论过的熟悉术语。高平均值和低标准差表明执行时间的变化不大。同样，下四分位数（第一个）和上四分位数（第三个）表明它们与平均值并不太远。这一结果意味着代码在响应时间方面相对稳定。Criterium重复执行多次以收集延迟数值。
- en: However, why does Criterium attempt to do a statistical analysis of the execution
    time? What would be amiss if we simply calculate the mean? It turns out that the
    response times of all executions are not always stable and there is often disparity
    in how the response time shows up. Only upon running sufficient times under correctly
    simulated load we can get complete data and other indicators about the latency.
    A statistical analysis gives insight into whether there is something wrong with
    the benchmark.
  id: totrans-854
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为什么Criterium试图对执行时间进行统计分析？如果我们简单地计算平均值，会有什么遗漏呢？实际上，所有执行的响应时间并不总是稳定的，响应时间的显示往往存在差异。只有在正确模拟负载下运行足够的时间，我们才能获得关于延迟的完整数据和其它指标。统计分析有助于了解基准测试是否存在问题。
- en: Guided performance objectives
  id: totrans-855
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指导性能目标
- en: We only briefly discussed performance objectives in [Chapter 1](ch15.html "Chapter 8. Application
    Performance"), *Performance by Design* because that discussion needs a reference
    to statistical concepts. Let's say we identified the functional scenarios and
    the corresponding response time. Should response time remain fixed? Can we constrain
    throughput in order to prefer a stipulated response time?
  id: totrans-856
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第1章](ch15.html "第8章。应用性能")中仅简要讨论了性能目标，*设计性能*，因为那次讨论需要参考统计概念。假设我们确定了功能场景和相应的响应时间。响应时间应该保持固定吗？我们可以限制吞吐量以优先考虑规定的响应时间吗？
- en: The performance objective should specify the worst-case response time, that
    is, maximum latency, the average response time and the maximum standard deviation.
    Similarly, the performance objective should also mention the worst-case throughput,
    maintenance window throughput, average throughput, and the maximum standard deviation.
  id: totrans-857
  prefs: []
  type: TYPE_NORMAL
  zh: 性能目标应指定最坏情况的响应时间，即最大延迟、平均响应时间和最大标准差。同样，性能目标还应提及最坏情况的吞吐量、维护窗口吞吐量、平均吞吐量和最大标准差。
- en: Performance testing
  id: totrans-858
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能测试
- en: Testing for performance requires us to know what we are going to test, how we
    want to test, and what environment to set up for the tests to execute. There are
    several pitfalls to be aware of, such as a lack of near-real hardware and resources
    of production use, similar OS and software environments, diversity of representative
    data for test cases, and so on. Lack of diversity in test inputs may lead to a
    monotonic branch prediction, hence introducing a "bias" in test results.
  id: totrans-859
  prefs: []
  type: TYPE_NORMAL
  zh: 性能测试需要我们知道我们将要测试什么，我们想要如何测试，以及为测试执行设置什么环境。有几个需要注意的陷阱，例如缺乏接近真实硬件和生产使用的资源、类似的操作系统和软件环境、测试用例的代表性数据的多样性等等。测试输入的多样性不足可能导致单调分支预测，从而在测试结果中引入“偏差”。
- en: The test environment
  id: totrans-860
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试环境
- en: Concerns about the test environment begin with the hardware representative of
    the production environment. Traditionally, the test environment hardware has been
    a scaled-down version of the production environment. The performance analysis
    done on non-representative hardware is almost certain to skew the results. Fortunately,
    in recent times, thanks to the commodity hardware and cloud systems, provisioning
    test environment hardware that is similar to the production environment is not
    too difficult.
  id: totrans-861
  prefs: []
  type: TYPE_NORMAL
  zh: 对测试环境的担忧始于生产环境的硬件代表。传统上，测试环境硬件是生产环境的缩小版。在非代表性硬件上进行的性能分析几乎肯定会歪曲结果。幸运的是，近年来，得益于通用硬件和云系统，提供与生产环境相似的测试环境硬件并不太难。
- en: The network and storage bandwidth, operating system, and software used for performance
    testing should of course be the same as in production. What is also important
    is to have a "load" representative of the test scenarios. The load comes in different
    combinations including the concurrency of requests, the throughput and standard
    deviation of requests, the current population level in the database or in the
    message queue, CPU and heap usage, and so on. It is important to simulate a representative
    load.
  id: totrans-862
  prefs: []
  type: TYPE_NORMAL
  zh: 网络和存储带宽、用于性能测试的操作系统和软件当然应该与生产环境相同。同样重要的是要有一个能代表测试场景的“负载”。负载可以有多种组合，包括请求的并发性、请求的吞吐量和标准偏差、数据库或消息队列中的当前人口水平、CPU和堆使用情况等。模拟一个代表性的负载是很重要的。
- en: Testing often requires quite some work on the part of the piece of code that
    carries out the test. Be sure to keep its overhead to a minimum so that it does
    not impact the benchmark results. Wherever possible, use a system other than the
    test target to generate requests.
  id: totrans-863
  prefs: []
  type: TYPE_NORMAL
  zh: 测试通常需要对执行测试的代码部分进行相当多的工作。务必将其开销降至最低，以免影响基准测试结果。在可能的情况下，使用除测试目标之外的系统来生成请求。
- en: What to test
  id: totrans-864
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 要测试的内容
- en: Any implementation of a non-trivial system typically involves many hardware
    and software components. Performance testing a certain feature or a service in
    the entire system needs to account for the way it interacts with the various sub-systems.
    For example, a web service call may touch multiple layers such as the web server
    (request/response marshaling and unmarshaling), URI-based routing, service handler,
    application-database connector, the database layer, logger component, and so on.
    Testing only the service handler would be a terrible mistake, because that is
    not exactly the performance what the web client will experience. The performance
    test should test at the perimeter of a system to keep the results realistic, preferably
    with a third-party observer.
  id: totrans-865
  prefs: []
  type: TYPE_NORMAL
  zh: 任何非平凡系统的实现通常涉及许多硬件和软件组件。对整个系统中的某个特定功能或服务进行性能测试时，需要考虑它与各个子系统的交互方式。例如，一个Web服务调用可能会触及多个层次，如Web服务器（请求/响应打包和解包）、基于URI的路由、服务处理程序、应用程序-数据库连接器、数据库层、日志组件等。仅测试服务处理程序将是一个严重的错误，因为这并不是Web客户端将体验到的性能。性能测试应该在系统的外围进行，以保持结果的现实性，最好有第三方观察者。
- en: The performance objectives state the criteria for testing. It would be useful
    to test what is not required by the objective, especially when the tests are run
    concurrently. Running meaningful performance tests may require a certain level
    of isolation.
  id: totrans-866
  prefs: []
  type: TYPE_NORMAL
  zh: 性能目标规定了测试的标准。测试不需要的内容可能是有用的，尤其是在测试并发运行时。运行有意义的性能测试可能需要一定程度的隔离。
- en: Measuring latency
  id: totrans-867
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测量延迟
- en: The latency obtained by executing a body of code may vary slightly on each run.
    This necessitates that we execute the code many times and collect samples. The
    latency numbers may be impacted by the JVM warm-up time, garbage collection and
    the JIT compiler kicking in. So, the test and sample collection should ensure
    that these conditions do not impact the results. Criterium follows such methods
    to produce the results. When we test a very small piece of code this way, it is
    called a **Micro-benchmark**.
  id: totrans-868
  prefs: []
  type: TYPE_NORMAL
  zh: 执行一段代码所获得的延迟可能因每次运行而略有不同。这需要我们多次执行代码并收集样本。延迟数字可能会受到JVM预热时间、垃圾收集和JIT编译器启动的影响。因此，测试和样本收集应确保这些条件不会影响结果。Criterium遵循这种方法来产生结果。当我们以这种方式测试非常小的代码片段时，它被称为**微基准测试**。
- en: As the latency of some operations may vary during runs, it is important to collect
    all samples and segregate them into periods and frequencies turning up into a
    histogram. The maximum latency is an important metric when measuring latency—it
    indicates the worst-case latency. Besides the maximum, the 99 percentile and 95
    percentile latency numbers are also important to put things in perspective. It's
    important to actually collect the latency numbers instead of inferring them from
    standard deviation, as we noted earlier that the empirical rule works only for
    normal distributions without significant outliers.
  id: totrans-869
  prefs: []
  type: TYPE_NORMAL
  zh: 由于某些操作的延迟在运行期间可能会变化，因此收集所有样本并将它们分成出现频率的时期和频率，形成直方图是很重要的。在测量延迟时，最大延迟是一个重要的指标——它表示最坏情况的延迟。除了最大值之外，99百分位和95百分位的延迟数字也很重要，以便从不同角度看待问题。实际上收集延迟数字比从标准偏差中推断它们更重要，正如我们之前提到的，经验法则仅适用于没有显著异常值的高斯分布。
- en: The outliers are an important data point when measuring latency. A proportionately
    higher count of outliers indicates a possibility of degradation of service.
  id: totrans-870
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值在测量延迟时是一个重要的数据点。异常值的比例越高，表明服务可能存在退化的可能性。
- en: Comparative latency measurement
  id: totrans-871
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 比较延迟测量
- en: When evaluating libraries for use in projects, or when coming up with alternate
    solutions against some baseline, comparative latency benchmarks are useful to
    determine the performance trade-offs. We will inspect two comparative benchmarking
    tools based on Criterium, called Perforate and Citius. Both make it easy to run
    Criterium benchmarks grouped by context, and to easily view the benchmark results.
  id: totrans-872
  prefs: []
  type: TYPE_NORMAL
  zh: 当评估用于项目的库或提出针对某些基线的替代解决方案时，比较延迟基准测试有助于确定性能权衡。我们将检查基于Criterium的两个比较基准测试工具，称为Perforate和Citius。两者都使得按上下文分组运行Criterium基准测试变得容易，并且可以轻松查看基准测试结果。
- en: 'Perforate ([https://github.com/davidsantiago/perforate](https://github.com/davidsantiago/perforate))
    is a Leiningen plugin that lets one define goals; a goal (defined using `perforate.core/defgoal`)
    is a common task or context having one or more benchmarks. Each benchmark is defined
    using `perforate.core/defcase`. As of version 0.3.4, a sample benchmark code may
    look like the following code snippet:'
  id: totrans-873
  prefs: []
  type: TYPE_NORMAL
  zh: Perforate ([https://github.com/davidsantiago/perforate](https://github.com/davidsantiago/perforate))
    是一个Leiningen插件，允许定义目标；一个目标（使用 `perforate.core/defgoal` 定义）是一个具有一个或多个基准的常见任务或上下文。每个基准都是使用
    `perforate.core/defcase` 定义的。截至版本 0.3.4，一个示例基准代码可能看起来像以下代码片段：
- en: '[PRE94]'
  id: totrans-874
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: You can declare the test environments in `project.clj` and provide the setup/cleanup
    code when defining the goal. Perforate provides ways to run the benchmarks from
    the command-line.
  id: totrans-875
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 `project.clj` 中声明测试环境，并在定义目标时提供设置/清理代码。Perforate提供了从命令行运行基准测试的方法。
- en: Citius ([https://github.com/kumarshantanu/citius](https://github.com/kumarshantanu/citius))
    is a library that provides integration hooks for clojure.test and other forms
    of invocation. It imposes more rigid constraints than Perforate, and renders additional
    comparative information about the benchmarks. It presumes a fixed number of targets
    (cases) per test suite where there may be several goals.
  id: totrans-876
  prefs: []
  type: TYPE_NORMAL
  zh: Citius ([https://github.com/kumarshantanu/citius](https://github.com/kumarshantanu/citius))
    是一个提供对 clojure.test 和其他调用形式的集成钩子的库。它比Perforate施加更严格的约束，并为基准测试提供额外的比较信息。它假设每个测试套件中有一个固定数量的目标（案例），其中可能有多个目标。
- en: 'As of version 0.2.1, a sample benchmark code may look like the following code
    snippet:'
  id: totrans-877
  prefs: []
  type: TYPE_NORMAL
  zh: 截至 0.2.1 版本，一个示例基准代码可能看起来像以下代码片段：
- en: '[PRE95]'
  id: totrans-878
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: In the previous example, the code runs the benchmarks, reports the comparative
    summary, and draws a bar chart image of the mean latencies.
  id: totrans-879
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个例子中，代码运行基准测试，报告比较摘要，并绘制平均延迟的条形图。
- en: Latency measurement under concurrency
  id: totrans-880
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 并发情况下的延迟测量
- en: When we benchmark a piece of code with Criterium, it uses just a single thread
    to determine results. That gives us a fair output in terms of single-threaded
    result, but there are many benchmarking scenarios where single-threaded latency
    is far from what we need. Under concurrency, the latency often differs quite a
    bit from single-threaded latency. Especially when we deal with *stateful* objects
    (e.g. drawing a connection from a JDBC connection pool, updating shared in-memory
    state etc.), the latency is likely to vary in proportion with the contention.
    In such scenarios it is useful to find out the latency patterns of the code under
    various concurrency levels.
  id: totrans-881
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用Criterium对一段代码进行基准测试时，它仅使用单个线程来确定结果。这为我们提供了关于单线程结果的公平输出，但在许多基准测试场景中，单线程延迟远非我们所需要的。在并发情况下，延迟往往与单线程延迟有很大差异。特别是当我们处理*有状态*对象（例如，从JDBC连接池中绘制连接，更新共享内存状态等）时，延迟很可能会随着竞争程度成比例变化。在这种情况下，了解代码在不同并发级别下的延迟模式是有用的。
- en: 'The Citius library we discussed in the previous sub-section supports tunable
    concurrency levels. Consider the following benchmark of implementations of shared
    counters:'
  id: totrans-882
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个子节中讨论的Citius库支持可调的并发级别。考虑以下共享计数器实现的基准测试：
- en: '[PRE96]'
  id: totrans-883
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: When I ran this benchmark on a 4th generation quad-core Intel Core i7 processor
    (Mac OSX 10.10), the mean latency at concurrency level 04 was 38 to 42 times the
    value of the mean latency at concurrency level 01\. Since, in many cases, the
    JVM is used to run server-side applications, benchmarking under concurrency becomes
    all the more important.
  id: totrans-884
  prefs: []
  type: TYPE_NORMAL
  zh: 当我在第四代四核英特尔酷睿i7处理器（Mac OSX 10.10）上运行这个基准测试时，在并发级别04的平均延迟是并发级别01平均延迟的38到42倍。由于在许多情况下，JVM用于运行服务器端应用程序，因此在并发下的基准测试变得尤为重要。
- en: Measuring throughput
  id: totrans-885
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测量吞吐量
- en: Throughput is expressed per unit of time. Coarse-grained throughput, that is,
    the throughput number collected over a long period of time, may hide the fact
    when the throughput is actually delivered in bursts instead of a uniform distribution.
    Granularity of the throughput test is subject to the nature of the operation.
    A batch process may process bursts of data, whereas a web service may deliver
    uniformly distributed throughput.
  id: totrans-886
  prefs: []
  type: TYPE_NORMAL
  zh: 吞吐量以时间单位表示。粗粒度吞吐量，即收集了很长时间的吞吐量数字，可能隐藏了吞吐量实际上是分批而不是均匀分布的事实。吞吐量测试的粒度取决于操作的特性。批量处理可能处理数据爆发，而网络服务可能提供均匀分布的吞吐量。
- en: Average throughput test
  id: totrans-887
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 平均吞吐量测试
- en: 'Though Citius (as of version 0.2.1) shows extrapolated throughput (per second,
    per thread) in benchmark results, that throughput number may not represent the
    actual throughput very well for a variety of reasons. Let''s construct a simple
    throughput benchmark harness as follows, beginning with the helper functions:'
  id: totrans-888
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Citius（截至版本0.2.1）在基准测试结果中显示了外推的吞吐量（每秒，每线程），但由于各种原因，这个吞吐量数字可能并不能很好地代表实际的吞吐量。以下是一个简单的吞吐量基准测试工具的构建方法，从辅助函数开始：
- en: '[PRE97]'
  id: totrans-889
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'Now that we have the helper functions defined, let''s see the benchmarking
    code:'
  id: totrans-890
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了辅助函数，让我们看看基准测试代码：
- en: '[PRE98]'
  id: totrans-891
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'Let''s now see how to test some code for throughput using the harness:'
  id: totrans-892
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看如何使用工具测试代码的吞吐量：
- en: '[PRE99]'
  id: totrans-893
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: This harness provides only a simple throughput test. To inspect the throughput
    pattern you may want to bucket the throughput across rolling fixed-duration windows
    (e.g. per second throughput.) However, that topic is beyond the scope of this
    text, though we will touch upon it in the *Performance monitoring* section later
    in this chapter.
  id: totrans-894
  prefs: []
  type: TYPE_NORMAL
  zh: 此工具仅提供简单的吞吐量测试。要检查吞吐量模式，您可能希望将吞吐量分配到滚动固定持续时间窗口中（例如，每秒吞吐量）。然而，这个主题超出了本文的范围，尽管我们将在本章后面的*性能监控*部分中提及它。
- en: The load, stress, and endurance tests
  id: totrans-895
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负载、压力和耐久性测试
- en: One of the characteristics of tests is each run only represents the slice of
    time it is executed through. Repeated runs establish their general behavior. But
    how many runs should be enough? There may be several anticipated load scenarios
    for an operation. So, there is a need to repeat the tests at various load scenarios.
    Simple test runs may not always exhibit the long-term behavior and response of
    the operation. Running the tests under varying high load for longer duration allows
    us to observe them for any odd behavior that may not show up in a short test cycle.
  id: totrans-896
  prefs: []
  type: TYPE_NORMAL
  zh: 测试的一个特点是每次运行只代表执行过程中的一个时间片段。重复运行建立它们的总体行为。但应该运行多少次才算足够？一个操作可能有几个预期的负载场景。因此，需要在各种负载场景下重复测试。简单的测试运行可能并不总是表现出操作的长期行为和响应。在变化的高负载下长时间运行测试，使我们能够观察任何可能不会在短期测试周期中出现的异常行为。
- en: When we test an operation at a load far beyond its anticipated latency and throughput
    objectives, that is **stress testing**. The intent of a stress test is to ascertain
    a reasonable behavior exhibited by the operation beyond the maximum load it was
    developed for. Another way to observe the behavior of an operation is to see how
    it behaves when run for a very long duration, typically for several days or weeks.
    Such prolonged tests are called **endurance tests**. While a stress test checks
    the graceful behavior of the operation, an endurance test checks the consistent
    behavior of the operation over a long period.
  id: totrans-897
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在远超预期延迟和吞吐量目标负载下测试一个操作时，这就是**压力测试**。压力测试的目的是确定操作在超出其开发的最大负载后所表现出的合理行为。观察操作行为的另一种方法是观察它在非常长时间内运行的情况，通常为几天或几周。这种长时间的测试被称为**耐久性测试**。虽然压力测试检查操作的良好行为，但耐久性测试检查操作在长时间内的持续行为。
- en: There are several tools that may help with load and stress testing. Engulf ([http://engulf-project.org/](http://engulf-project.org/))
    is a distributed HTTP-based, load-generation tool written in Clojure. Apache JMeter
    and Grinder are Java-based load-generation tools. Grinder can be scripted using
    Clojure. Apache Bench is a load-testing tool for web systems. Tsung is an extensible,
    high-performance, load-testing tool written in Erlang.
  id: totrans-898
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种工具可以帮助进行负载和压力测试。Engulf ([http://engulf-project.org/](http://engulf-project.org/))
    是一个基于 Clojure 的分布式 HTTP-based 负载生成工具。Apache JMeter 和 Grinder 是基于 Java 的负载生成工具。Grinder
    可以使用 Clojure 脚本化。Apache Bench 是用于 Web 系统的负载测试工具。Tsung 是一个可扩展的、高性能的、基于 Erlang 的负载测试工具。
- en: Performance monitoring
  id: totrans-899
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能监控
- en: During prolonged testing or after the application has gone to production, we
    need to monitor its performance to make sure the application continues to meet
    the performance objectives. There may be infrastructure or operational issues
    impacting the performance or availability of the application, or occasional spikes
    in latency or dips in throughput. Generally, monitoring alleviates such risk by
    generating a continuous feedback stream.
  id: totrans-900
  prefs: []
  type: TYPE_NORMAL
  zh: 在长时间测试期间或应用程序上线后，我们需要监控其性能，以确保应用程序继续满足性能目标。可能存在影响应用程序性能或可用性的基础设施或运营问题，或者偶尔的延迟峰值或吞吐量下降。通常，监控通过生成连续的反馈流来减轻这种风险。
- en: Roughly there are three kinds of components used to build a monitoring stack.
    A **collector** sends the numbers from each host that needs to be monitored. The
    collector gets host information and the performance numbers and sends them to
    an **aggregator**. An aggregator receives the data sent by the collector and persists
    them until asked by a **visualizer** on behalf of the user.
  id: totrans-901
  prefs: []
  type: TYPE_NORMAL
  zh: 大概有三种组件用于构建监控堆栈。一个 **收集器** 从每个需要监控的主机发送数字。收集器获取主机信息和性能数字，并将它们发送到一个 **聚合器**。聚合器接收收集器发送的数据，并在用户代表请求时将它们持久化。
- en: The project **metrics-clojure** ([https://github.com/sjl/metrics-clojure](https://github.com/sjl/metrics-clojure))
    is a Clojure wrapper over the **Metrics** ([https://github.com/dropwizard/metrics](https://github.com/dropwizard/metrics))
    Java framework, which acts as a collector. **Statsd** is a well-known aggregator
    that does not persist data by itself but passes it on to a variety of servers.
    One of the popular visualizer projects is **Graphite** that stores the data as
    well as produces graphs for requested periods. There are several other alternatives
    to these, notably **Riemann** ([http://riemann.io/](http://riemann.io/)) that
    is written in Clojure and Ruby. Riemann is an event processing-based aggregator.
  id: totrans-902
  prefs: []
  type: TYPE_NORMAL
  zh: 项目 **metrics-clojure** ([https://github.com/sjl/metrics-clojure](https://github.com/sjl/metrics-clojure))
    是一个 Clojure 包装器，覆盖了 **Metrics** ([https://github.com/dropwizard/metrics](https://github.com/dropwizard/metrics))
    Java 框架，它充当收集器。**Statsd** 是一个知名的聚合器，它本身不持久化数据，而是将其传递给各种服务器。其中一个流行的可视化项目是 **Graphite**，它不仅存储数据，还为请求的时段生成图表。还有其他几种替代方案，值得注意的是
    **Riemann** ([http://riemann.io/](http://riemann.io/))，它是用 Clojure 和 Ruby 编写的。Riemann
    是一个基于事件处理的聚合器。
- en: Monitoring through logs
  id: totrans-903
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过日志进行监控
- en: One of the popular performance monitoring approaches that has emerged in recent
    times is via logs. The idea is simple—the application emits metrics data as logs,
    which are shipped from the individual machine to a central log aggregation service.
    Then, those metrics data are aggregated for each time window and further moved
    for archival and visualization.
  id: totrans-904
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来出现的一种流行的性能监控方法是通过日志。这个想法很简单——应用程序以日志的形式发出指标数据，这些数据从单个机器发送到中央日志聚合服务。然后，这些指标数据在每个时间窗口内进行聚合，并进一步移动以进行归档和可视化。
- en: 'As a high-level example of such a monitoring system, you may like to use **Logstash-forwarder**
    ([https://github.com/elastic/logstash-forwarder](https://github.com/elastic/logstash-forwarder))
    to grab the application logs from the local filesystem and ship to **Logstash**
    ([https://www.elastic.co/products/logstash](https://www.elastic.co/products/logstash)),
    where it forwards the metrics logs to **StatsD** ([https://github.com/etsy/statsd](https://github.com/etsy/statsd))
    for metrics aggregation or to Riemann ([http://riemann.io/](http://riemann.io/))
    for events analysis and monitoring alerts. StatsD and/or Riemann can forward the
    metrics data to Graphite ([http://graphite.wikidot.com/](http://graphite.wikidot.com/))
    for archival and graphing of the time-series metrics data. Often, people want
    to plug in a non-default time-series data store (such as **InfluxDB**: [https://influxdb.com/](https://influxdb.com/))
    or a visualization layer (such as **Grafana**: [http://grafana.org/](http://grafana.org/))
    with Graphite.'
  id: totrans-905
  prefs: []
  type: TYPE_NORMAL
  zh: 作为这样一个监控系统的高级示例，你可能想使用 **Logstash-forwarder** ([https://github.com/elastic/logstash-forwarder](https://github.com/elastic/logstash-forwarder))
    从本地文件系统抓取应用程序日志并将其发送到 **Logstash** ([https://www.elastic.co/products/logstash](https://www.elastic.co/products/logstash))，在那里它将指标日志转发到
    **StatsD** ([https://github.com/etsy/statsd](https://github.com/etsy/statsd))
    进行指标聚合或转发到 **Riemann** ([http://riemann.io/](http://riemann.io/)) 进行事件分析和监控警报。StatsD
    和/或 Riemann 可以将指标数据转发到 Graphite ([http://graphite.wikidot.com/](http://graphite.wikidot.com/))
    以归档和绘制时间序列指标数据。通常，人们希望将非默认的时间序列数据存储（例如 **InfluxDB**：[https://influxdb.com/](https://influxdb.com/))
    或可视化层（例如 **Grafana**：[http://grafana.org/](http://grafana.org/)) 与 Graphite 连接起来。
- en: A detailed discussion on this topic is out of the scope of this text, but I
    think exploring this area would serve you well.
  id: totrans-906
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个话题的详细讨论超出了本文的范围，但我认为探索这个领域对你大有裨益。
- en: Ring (web) monitoring
  id: totrans-907
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ring（Web）监控
- en: 'If you develop web software using Ring ([https://github.com/ring-clojure/ring](https://github.com/ring-clojure/ring))
    then you may find the Ring extension of the metrics-clojure library useful: [http://metrics-clojure.readthedocs.org/en/latest/ring.html](http://metrics-clojure.readthedocs.org/en/latest/ring.html)
    —this tracks a number of useful metrics that can be queried in JSON format and
    integrated with visualization via the web browser.'
  id: totrans-908
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用 Ring ([https://github.com/ring-clojure/ring](https://github.com/ring-clojure/ring))
    开发 Web 软件，那么 metrics-clojure 库的 Ring 扩展可能对你很有用：[http://metrics-clojure.readthedocs.org/en/latest/ring.html](http://metrics-clojure.readthedocs.org/en/latest/ring.html)
    ——它跟踪了许多有用的指标，这些指标可以以 JSON 格式查询，并通过网页浏览器进行可视化集成。
- en: To emit a continuous stream of metrics data from the web layer, **Server-Sent
    Events** (**SSE**) may be a good idea due to its low overhead. Both **http-kit**
    ([http://www.http-kit.org/](http://www.http-kit.org/)) and **Aleph** ([http://aleph.io/](http://aleph.io/)),
    which work with Ring, support SSE today.
  id: totrans-909
  prefs: []
  type: TYPE_NORMAL
  zh: 要从网络层发出连续的指标数据流，**服务器端事件**（**SSE**）可能是一个不错的选择，因为它开销较低。**http-kit** ([http://www.http-kit.org/](http://www.http-kit.org/))
    和 **Aleph** ([http://aleph.io/](http://aleph.io/))，它们与 Ring 一起工作，今天都支持 SSE。
- en: Introspection
  id: totrans-910
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内省
- en: Both Oracle JDK and OpenJDK provide two GUI tools called **JConsole** (executable
    name `jconsole`) and **JVisualVM** (executable name `jvisualvm`) that we can use
    to introspect into running JVMs for instrumentation data. There are also some
    command-line tools ([http://docs.oracle.com/javase/8/docs/technotes/tools/](http://docs.oracle.com/javase/8/docs/technotes/tools/))
    in the JDK to peek into the inner details of the running JVMs.
  id: totrans-911
  prefs: []
  type: TYPE_NORMAL
  zh: Oracle JDK 和 OpenJDK 都提供了两个名为 **JConsole**（可执行名称 `jconsole`）和 **JVisualVM**（可执行名称
    `jvisualvm`）的 GUI 工具，我们可以使用它们来对正在运行的 JVM 进行内省以获取仪表数据。JDK 中还有一些命令行工具（[http://docs.oracle.com/javase/8/docs/technotes/tools/](http://docs.oracle.com/javase/8/docs/technotes/tools/）），可以用来窥探正在运行的
    JVM 的内部细节。
- en: A common way to introspect a running Clojure application is to have an **nREPL**
    ([https://github.com/clojure/tools.nrepl](https://github.com/clojure/tools.nrepl))
    service running so that we can connect to it later using an nREPL client. Interactive
    introspection over nREPL using the Emacs editor (embedded nREPL client) is popular
    among some, whereas others prefer to script an nREPL client to carry out tasks.
  id: totrans-912
  prefs: []
  type: TYPE_NORMAL
  zh: 内省一个正在运行的 Clojure 应用程序的一个常见方法是运行一个 **nREPL** ([https://github.com/clojure/tools.nrepl](https://github.com/clojure/tools.nrepl))
    服务，这样我们就可以稍后使用 nREPL 客户端连接到它。使用 Emacs 编辑器（内嵌 nREPL 客户端）进行 nREPL 的交互式内省在一些人中很受欢迎，而其他人则更喜欢编写
    nREPL 客户端脚本来执行任务。
- en: JVM instrumentation via JMX
  id: totrans-913
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过 JMX 进行 JVM 仪表化
- en: The JVM has a built-in mechanism to introspect managed resources via the extensible
    **Java Management Extensions** (**JMX**) API. It provides a way for application
    maintainers to expose manageable resources as "MBeans". Clojure has an easy-to-use
    `contrib` library called `java.jmx` ([https://github.com/clojure/java.jmx](https://github.com/clojure/java.jmx))
    to access JMX. There is a decent amount of open source tooling for visualization
    of JVM instrumentation data via JMX, such as `jmxtrans` and `jmxetric`, which
    integrate with Ganglia and Graphite.
  id: totrans-914
  prefs: []
  type: TYPE_NORMAL
  zh: JVM有一个内置机制，通过可扩展的**Java管理扩展**(**JMX**) API来检查管理资源。它为应用程序维护者提供了一种将可管理资源作为“MBeans”公开的方法。Clojure有一个易于使用的`contrib`库，名为`java.jmx`([https://github.com/clojure/java.jmx](https://github.com/clojure/java.jmx))，用于访问JMX。还有相当数量的开源工具，可以通过JMX可视化JVM仪器数据，例如`jmxtrans`和`jmxetric`，它们与Ganglia和Graphite集成。
- en: 'Getting quick memory stats of the JVM is pretty easy using Clojure:'
  id: totrans-915
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Clojure获取JVM的快速内存统计信息相当简单：
- en: '[PRE100]'
  id: totrans-916
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: Profiling
  id: totrans-917
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析
- en: 'We briefly discussed profiler types in [Chapter 1](ch15.html "Chapter 8. Application
    Performance"), *Performance by Design*. The JVisualVM tool we discussed with respect
    to introspection in the previous section is also a CPU and memory profiler that
    comes bundled with the JDK. Let''s see them in action— consider the following
    two Clojure functions that stress the CPU and memory respectively:'
  id: totrans-918
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第1章](ch15.html "第8章 应用性能")*设计性能*中简要讨论了分析器类型。在前一节中我们讨论的JVisualVM工具也是一个与JDK捆绑的CPU和内存分析器。让我们看看它们在实际中的应用——考虑以下两个Clojure函数，它们分别对CPU和内存进行压力测试：
- en: '[PRE101]'
  id: totrans-919
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: Using JVisualVM is pretty easy—open the Clojure JVM process from the left pane.
    It has sampler and regular profiler styles of profiling. Start profiling for CPU
    or memory use when the code is running and wait for it to collect enough data
    to plot on the screen.
  id: totrans-920
  prefs: []
  type: TYPE_NORMAL
  zh: 使用JVisualVM相当简单——从左侧面板打开Clojure JVM进程。它具有采样和常规分析器风格的剖析。当代码运行时，开始对CPU或内存使用进行剖析，并等待收集足够的数据以在屏幕上绘制。
- en: '![Profiling](img/3642_06_03.jpg)'
  id: totrans-921
  prefs: []
  type: TYPE_IMG
  zh: '![分析](img/3642_06_03.jpg)'
- en: 'The following shows memory profiling in action:'
  id: totrans-922
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的示例展示了内存分析的实际应用：
- en: '![Profiling](img/3642_06_04.jpg)'
  id: totrans-923
  prefs: []
  type: TYPE_IMG
  zh: '![分析](img/3642_06_04.jpg)'
- en: Note that JVisualVM is a very simple, entry-level profiler. There are several
    commercial JVM profilers on the market for sophisticated needs.
  id: totrans-924
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，JVisualVM是一个非常简单、入门级分析器。市场上有多款商业JVM分析器，用于更复杂的需求。
- en: OS and CPU/cache-level profiling
  id: totrans-925
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作系统和CPU/缓存级别分析
- en: Profiling only the JVM may not always tell the whole story. Getting down to
    OS and hardware-level profiling often provides better insight into what is going
    on with the application. On Unix-like operating systems, command-line tools such
    as `top`, `htop`, `perf`, `iota`, `netstat`, `vista`, `upstate`, `pidstat` etc
    can help. Profiling the CPU for cache misses and other information is a useful
    source to catch performance issues. Among open source tools for Linux, **Likwid**
    ([http://code.google.com/p/likwid/](http://code.google.com/p/likwid/) and [https://github.com/rrze-likwid/likwid](https://github.com/rrze-likwid/likwid))
    is small yet effective for Intel and AMD processors; **i7z** ([https://code.google.com/p/i7z/](https://code.google.com/p/i7z/)
    and [https://github.com/ajaiantilal/i7z](https://github.com/ajaiantilal/i7z))
    is specifically for Intel processors. There are also dedicated commercial tools
    such as **Intel VTune Analyzer** for more elaborate needs.
  id: totrans-926
  prefs: []
  type: TYPE_NORMAL
  zh: 仅对JVM进行剖析可能并不总是能说明全部情况。深入到操作系统和硬件级别的剖析通常能更好地了解应用程序的情况。在类Unix操作系统中，如`top`、`htop`、`perf`、`iota`、`netstat`、`vista`、`upstate`、`pidstat`等命令行工具可以帮助进行剖析。对CPU进行缓存缺失和其他信息的剖析是捕捉性能问题的有用来源。在Linux的开源工具中，**Likwid**([http://code.google.com/p/likwid/](http://code.google.com/p/likwid/)
    和 [https://github.com/rrze-likwid/likwid](https://github.com/rrze-likwid/likwid))是一个针对Intel和AMD处理器的轻量级但有效的工具；**i7z**([https://code.google.com/p/i7z/](https://code.google.com/p/i7z/)
    和 [https://github.com/ajaiantilal/i7z](https://github.com/ajaiantilal/i7z))是专门针对Intel处理器的。还有针对更复杂需求的专用商业工具，如**Intel
    VTune Analyzer**。
- en: I/O profiling
  id: totrans-927
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I/O分析
- en: Profiling I/O may require special tools too. Besides `iota` and `blktrace`,
    `ioping` ([https://code.google.com/p/ioping/](https://code.google.com/p/ioping/)
    and [https://github.com/koct9i/ioping](https://github.com/koct9i/ioping)) is useful
    to measure real-time I/O latency on Linux/Unix systems. The **vnStat** tool is
    useful to monitor and log network traffic on Linux. The IOPS of a storage device
    may not tell the whole truth unless it is accompanied by latency information for
    different operations, and how many reads and writes can simultaneously happen.
  id: totrans-928
  prefs: []
  type: TYPE_NORMAL
  zh: 分析I/O可能也需要特殊的工具。除了`iota`和`blktrace`之外，`ioping`（[https://code.google.com/p/ioping/](https://code.google.com/p/ioping/)
    和 [https://github.com/koct9i/ioping](https://github.com/koct9i/ioping)）对于测量Linux/Unix系统上的实时I/O延迟很有用。**vnStat**工具对于监控和记录Linux上的网络流量很有用。存储设备的IOPS可能无法完全反映真相，除非它伴随着不同操作的延迟信息，以及可以同时发生的读取和写入次数。
- en: In an I/O bound workload one has to look for the read and write IOPS over time
    and set a threshold to achieve optimum performance. The application should throttle
    the I/O access so that the threshold is not crossed.
  id: totrans-929
  prefs: []
  type: TYPE_NORMAL
  zh: 在I/O密集型的工作负载中，必须随着时间的推移寻找读取和写入IOPS，并设置一个阈值以实现最佳性能。应用程序应限制I/O访问，以确保不会超过阈值。
- en: Summary
  id: totrans-930
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Delivering high-performance applications not only requires care for performance
    but also systematic effort to measure, test, monitor, and optimize the performance
    of various components and subsystems. These activities often require the right
    skill and experience. Sometimes, performance considerations may even bring system
    design and architecture back to the drawing board. Early structured steps taken
    to achieve performance go a long way to ensuring that the performance objectives
    are being continuously met.
  id: totrans-931
  prefs: []
  type: TYPE_NORMAL
  zh: 提供高性能应用程序不仅需要关注性能，还需要系统地测量、测试、监控和优化各种组件和子系统的性能。这些活动通常需要正确的技能和经验。有时，性能考虑甚至可能将系统设计和架构带回设计图板。为实现性能而采取的早期结构化步骤对于确保持续满足性能目标至关重要。
- en: In the next chapter, we will look into performance optimization tools and techniques.
  id: totrans-932
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨性能优化工具和技术。
- en: Chapter 7. Performance Optimization
  id: totrans-933
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章. 性能优化
- en: 'Performance optimization is additive by nature, as in it works by adding performance
    tuning to the knowledge of how the underlying system works, and to the result
    of performance measurement. This chapter builds on the previous ones that covered
    "how the underlying system works" and "performance measurement". Though you will
    notice some recipe-like sections in this chapter, you already know the pre-requisite
    in order to exploit those well. Performance tuning is an iterative process of
    measuring performance, determining bottlenecks, applying knowledge in order to
    experiment with tuning the code, and repeating it all until performance improves.
    In this chapter, we will cover:'
  id: totrans-934
  prefs: []
  type: TYPE_NORMAL
  zh: 性能优化本质上具有累加性，因为它通过将性能调优添加到对底层系统如何工作的了解以及性能测量结果中来实现。本章建立在之前涵盖“底层系统如何工作”和“性能测量”的章节之上。尽管你会在本章中注意到一些类似食谱的部分，但你已经知道为了充分利用这些内容所必需的先决条件。性能调优是一个测量性能、确定瓶颈、应用知识以尝试调整代码，并重复这一过程直到性能提高的迭代过程。在本章中，我们将涵盖：
- en: Setting up projects for better performance
  id: totrans-935
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置项目以获得更好的性能
- en: Identifying performance bottlenecks in the code
  id: totrans-936
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别代码中的性能瓶颈
- en: Profiling code with VisualVM
  id: totrans-937
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用VisualVM分析代码
- en: Performance tuning of Clojure code
  id: totrans-938
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Clojure代码的性能调优
- en: JVM performance tuning
  id: totrans-939
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JVM性能调优
- en: Project setup
  id: totrans-940
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目设置
- en: While finding bottlenecks is essential to fixing performance problems in the
    code, there are several things one can do right from the start to ensure better
    performance.
  id: totrans-941
  prefs: []
  type: TYPE_NORMAL
  zh: 在寻找瓶颈以修复代码中的性能问题至关重要时，从一开始就可以做一些事情来确保更好的性能。
- en: Software versions
  id: totrans-942
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 软件版本
- en: 'Usually, new software versions include bug fixes, new features, and performance
    improvements. Unless advised to the contrary, it is better to use newer versions.
    For development with Clojure, consider the following software versions:'
  id: totrans-943
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，新的软件版本包括错误修复、新功能和性能改进。除非有相反的建议，最好使用较新版本。对于使用Clojure的开发，请考虑以下软件版本：
- en: '**JVM version**: As of this writing, Java 8 (Oracle JDK, OpenJDK, Zulu) has
    been released as the latest stable production-ready version. It is not only stable,
    it also has better performance in several areas (especially concurrency) than
    the earlier versions. If you have a choice, choose Java 8 over the older versions
    of Java.'
  id: totrans-944
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**JVM 版本**：截至本文撰写时，Java 8（Oracle JDK，OpenJDK，Zulu）已发布为最新的稳定生产就绪版本。它不仅稳定，而且在多个领域（特别是并发）的性能也比早期版本更好。如果你有选择，请选择
    Java 8 而不是 Java 的旧版本。'
- en: '**Clojure version**: As of this writing, Clojure 1.7.0 is the latest stable
    version that has several performance improvements over the older versions. There
    are also new features (transducers, volatile) that can make your code perform
    better. Choose Clojure 1.7 over the older versions unless you have no choice.'
  id: totrans-945
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Clojure 版本**：截至本文撰写时，Clojure 1.7.0 是最新的稳定版本，它在性能上比旧版本有多个改进。还有一些新特性（transducers，volatile）可以使你的代码性能更好。除非你别无选择，否则请选择
    Clojure 1.7 而不是旧版本。'
- en: Leiningen project.clj configuration
  id: totrans-946
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Leiningen project.clj 配置
- en: As of version 2.5.1, the default Leiningen template (`lein new foo`, `lein new
    app foo`) needs few tweaks to make the project amenable to performance. Ensure
    your Leiningen `project.clj` file has the following entries, as appropriate.
  id: totrans-947
  prefs: []
  type: TYPE_NORMAL
  zh: 截至 2.5.1 版本，默认的 Leiningen 模板（`lein new foo`，`lein new app foo`）需要一些调整以使项目适应性能。确保你的
    Leiningen `project.clj` 文件包含以下条目，根据需要。
- en: Enable reflection warning
  id: totrans-948
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 启用反射警告
- en: 'One of the most common pitfalls in Clojure programming is to inadvertently
    let the code resort to reflection. Recall that we discussed this in [Chapter 3](ch10.html
    "Chapter 3. Leaning on Java"), *Leaning on Java. Enabling*, reflection warning
    is quite easy, let''s fix it by adding the following entry to `project.clj`:'
  id: totrans-949
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Clojure 编程中最常见的陷阱之一是无意中让代码依赖反射。回想一下，我们在 [第 3 章](ch10.html "第 3 章。依赖 Java。启用")
    中讨论了这一点，*依赖 Java。启用* 反射警告非常简单，让我们通过在 `project.clj` 中添加以下条目来修复它：
- en: '[PRE102]'
  id: totrans-950
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: In the previous configuration, the first setting `*unchecked-math* :warn-on-boxed`
    works only in Clojure 1.7—it emits numeric boxing warnings. The second setting
    `*warn-on-reflection* true` works on earlier Clojure versions as well as Clojure
    1.7, and emits reflection warning messages in the code.
  id: totrans-951
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的配置中，第一个设置 `*unchecked-math* :warn-on-boxed` 只在 Clojure 1.7 中有效——它会发出数字装箱警告。第二个设置
    `*warn-on-reflection* true` 适用于更早的 Clojure 版本以及 Clojure 1.7，并在代码中发出反射警告信息。
- en: However, including these settings in `project.clj` may not be enough. Reflection
    warnings are emitted only when a namespace is loaded. You need to ensure that
    all namespaces are loaded in order to search for reflection warnings throughout
    the project. This can be done by writing tests that refer to all namespaces, or
    via scripts that do so.
  id: totrans-952
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，将这些设置包含在 `project.clj` 文件中可能还不够。只有当命名空间被加载时，才会发出反射警告。你需要确保所有命名空间都被加载，以便在整个项目中搜索反射警告。这可以通过编写引用所有命名空间的测试或通过执行此类操作的脚本来实现。
- en: Enable optimized JVM options when benchmarking
  id: totrans-953
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在基准测试时启用优化 JVM 选项
- en: 'In [Chapter 4](ch11.html "Chapter 4. Host Performance"), *Host Performance*
    we discussed that Leiningen enables tiered compilation by default, which provides
    low startup time at the cost of poor JIT compiler optimization. The default setting
    is quite misleading for performance benchmarking, so you should enable JVM options
    that are representative of what you would use in production:'
  id: totrans-954
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第 4 章](ch11.html "第 4 章。主机性能") *主机性能* 中，我们讨论了 Leiningen 默认启用分层编译，这以牺牲 JIT
    编译器的优化为代价提供了较低的启动时间。默认设置对于性能基准测试来说相当具有误导性，因此你应该启用代表你在生产中使用的 JVM 选项：
- en: '[PRE103]'
  id: totrans-955
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'For example, the previous setting defines a Leiningen profile that overrides
    the default JVM options to configure a `server` Java runtime with 2 GB of fixed-size
    heap space. It also sets test paths to a directory `perf-test`. Now you can run
    performance tests as follows:'
  id: totrans-956
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，之前的设置定义了一个 Leiningen 配置文件，该配置文件覆盖了默认 JVM 选项，以配置具有 2 GB 固定大小的堆空间的 `server`
    Java 运行时。它还将测试路径设置为目录 `perf-test`。现在你可以按照以下方式运行性能测试：
- en: '[PRE104]'
  id: totrans-957
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: If your project has performance test suites that require different JVM options,
    you should define multiple profiles for running tests, as appropriate.
  id: totrans-958
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的项目有需要不同 JVM 选项的性能测试套件，你应该为运行测试定义多个配置文件。
- en: Distinguish between initialization and runtime
  id: totrans-959
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 区分初始化和运行时
- en: Most non-trivial projects need a lot of context to be set up before they can
    function. Examples of such contexts could be app configuration, in-memory state,
    I/O resources, thread pools, caches, and so on. While many projects start with
    ad hoc configuration and initialization, eventually projects need to isolate the
    initialization phase from runtime. The purpose of this distinction is not only
    to sanitize the organization of code, but also to pre-compute as much as possible
    once before the runtime can take over to repeatedly respond to demands. This distinction
    also allows the initialization phase to easily (and conditionally, based on configuration)
    instrument the initialized code for performance logging and monitoring.
  id: totrans-960
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数非平凡项目在它们能够运行之前都需要设置大量的上下文。这些上下文的例子可能包括应用程序配置、内存状态、I/O资源、线程池、缓存等等。虽然许多项目从临时的配置和初始化开始，但最终项目需要将初始化阶段与运行时分离。这种区分的目的不仅是为了净化代码的组织结构，而且是为了在运行时接管之前尽可能多地预先计算。这种区分还允许初始化阶段轻松（并且根据配置条件）为初始化的代码进行性能日志记录和监控。
- en: Non-trivial programs are usually divided into layers, such as business logic,
    caching, messaging, database access, and so on. Each layer has a dependency relationship
    with one or more of the other layers. It is feasible to carry out the isolation
    of the initialization phase by writing code using first principles, and many projects
    actually do that. However, there are a few libraries that simplify this process
    by letting you declare the dependency relationship between layers. **Component**
    ([https://github.com/stuartsierra/component](https://github.com/stuartsierra/component))
    and **Prismatic Graph** ([https://github.com/Prismatic/plumbing](https://github.com/Prismatic/plumbing))
    are notable examples of such libraries.
  id: totrans-961
  prefs: []
  type: TYPE_NORMAL
  zh: 非平凡程序通常被划分为层，例如业务逻辑、缓存、消息传递、数据库访问等等。每一层都与一个或多个其他层有依赖关系。通过使用第一性原理编写代码，可以实施初始化阶段的隔离，许多项目实际上就是这样做的。然而，有一些库通过允许你声明层之间的依赖关系来简化这个过程。**Component**
    ([https://github.com/stuartsierra/component](https://github.com/stuartsierra/component))
    和 **Prismatic Graph** ([https://github.com/Prismatic/plumbing](https://github.com/Prismatic/plumbing))
    是这类库的显著例子。
- en: 'The Component library is well documented. It may not be easily apparent how
    to use Prismatic Graph for dependency resolution; following is a contrived example
    for illustration:'
  id: totrans-962
  prefs: []
  type: TYPE_NORMAL
  zh: 组件库的文档非常完善。可能不太容易明显地看出如何使用Prismatic Graph进行依赖关系解析；以下是一个为了说明而构造的示例：
- en: '[PRE105]'
  id: totrans-963
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: This example merely shows the construction of a layer dependency graph, but
    often you may need different construction scope and order for testing. In that
    case you may define different graphs and resolve them, as and when appropriate.
    If you need teardown logic for testing, you can add extra `fnk` entries for each
    teardown step and use those for teardown.
  id: totrans-964
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子仅仅展示了层依赖图的构建，但通常你可能需要不同的构建范围和顺序来进行测试。在这种情况下，你可以定义不同的图并在适当的时候解决它们。如果你需要测试的拆解逻辑，可以为每个拆解步骤添加额外的
    `fnk` 条目，并使用这些条目进行拆解。
- en: Identifying performance bottlenecks
  id: totrans-965
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别性能瓶颈
- en: We discussed in previous chapters that random performance tuning of code rarely
    works, because we may not be tuning in the right place. It is crucial to find
    the performance bottlenecks before we can tune those areas in the code. Upon finding
    the bottleneck, we can experiment with alternate solutions around it. In this
    section we will look into finding the bottlenecks.
  id: totrans-966
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面章节中讨论过，随机调整代码的性能很少有效，因为我们可能没有在正确的位置进行调整。在我们可以调整代码中的这些区域之前，找到性能瓶颈至关重要。找到瓶颈后，我们可以围绕它进行替代解决方案的实验。在本节中，我们将探讨如何找到瓶颈。
- en: Latency bottlenecks in Clojure code
  id: totrans-967
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Clojure代码中的延迟瓶颈
- en: Latency is the starting, and the most obvious, metric to drill-down in order
    to find bottlenecks. For Clojure code, we observed in [Chapter 6](ch13.html "Chapter 6. Measuring
    Performance"), *Measuring Performance* that code profiling tools can help us find
    the areas of bottleneck. Profilers are, of course, very useful. Once you discover
    hotspots via profilers, you may find ways to tune those for latency to a certain
    extent.
  id: totrans-968
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟是深入挖掘以找到瓶颈的最基本、最明显的指标。对于Clojure代码，我们在[第6章](ch13.html "第6章。测量性能")中观察到，代码分析工具可以帮助我们找到瓶颈区域。当然，分析器非常有用。一旦通过分析器发现热点，你可能会找到一些方法来在一定程度上调整这些热点的延迟。
- en: 'Most profilers work on aggregates, a batch of runs, ranking the hotspots in
    code by resources consumed. However, often the opportunity to tune latency lies
    in the long tail that may not be highlighted by the profilers. In such circumstances,
    we may employ a direct drill-down technique. Let''s see how to carry out such
    drill-down using **Espejito** ([https://github.com/kumarshantanu/espejito](https://github.com/kumarshantanu/espejito)),
    a Clojure library for measuring latency (as of version 0.1.0) across measurement
    points in single-threaded execution paths. There are two parts of using **Espejito**,
    both requiring change to your code—one to wrap the code being measured, and the
    other to report the collected measurement data. The following code illustrates
    a contrived E-commerce use case of adding an item to a cart:'
  id: totrans-969
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数分析器都在聚合上工作，一批运行，按资源消耗对代码中的热点进行排名。然而，调整延迟的机会往往在于长尾，这可能不会被分析器突出显示。在这种情况下，我们可能需要采用直接钻取技术。让我们看看如何使用
    **Espejito** ([https://github.com/kumarshantanu/espejito](https://github.com/kumarshantanu/espejito))
    进行此类钻取，这是一个用于在单线程执行路径中的测量点测量延迟的 Clojure 库（截至版本 0.1.0）。使用 **Espejito** 有两个部分，都需要修改您的代码——一个用于包装要测量的代码，另一个用于报告收集到的测量数据。以下代码演示了一个虚构的电子商务用例，即向购物车添加商品：
- en: '[PRE106]'
  id: totrans-970
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'Reporting a call is required to be made only once at the outermost (top-level)
    layer of the code. Measurement calls can be made at any number of places in the
    call path. Be careful not to put measurement calls inside tight loops, which may
    shoot memory consumption up. When this execution path is triggered, the functionality
    works as usual, while the latencies are measured and recorded alongside transparently
    in memory. The `e/report` call prints a table of recorded metrics. An example
    output (edited to fit) would be:'
  id: totrans-971
  prefs: []
  type: TYPE_NORMAL
  zh: 报告调用只需要在代码的最外层（顶级）层进行一次。测量调用可以在调用路径中的任何位置进行。请注意，不要在紧密循环中放置测量调用，这可能会使内存消耗激增。当此执行路径被触发时，功能按常规工作，同时延迟被透明地测量和记录在内存中。`e/report`
    调用会打印出记录的指标表。一个示例输出（编辑以适应）可能如下所示：
- en: '[PRE107]'
  id: totrans-972
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: Here we can observe that the database call is the most expensive (individual
    latency), followed by the web layer. Our tuning preference may be guided by the
    order of expensiveness of the measurement points.
  id: totrans-973
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以观察到数据库调用是最昂贵的（单个延迟），其次是网络层。我们的调整偏好可能由测量点的昂贵程度顺序来指导。
- en: Measure only when it is hot
  id: totrans-974
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 只在热时进行测量
- en: 'One important aspect we did not cover in the drill-down measurement is whether
    the environment is ready for measurement. The `e/report` call is invoked unconditionally
    every time, which would not only have its own overhead (table printing), but the
    JVM may not be warmed up and the JIT compiler may not have kicked in to correctly
    report the latencies. To ensure that we report only meaningful latencies, let''s
    trigger the `e/report` call on an example condition:'
  id: totrans-975
  prefs: []
  type: TYPE_NORMAL
  zh: 在钻取测量中，我们没有涵盖的一个重要方面是环境是否已准备好进行测量。`e/report` 调用每次都会无条件地调用，这不仅会有自己的开销（打印表），而且
    JVM 可能还没有预热，JIT 编译器可能还没有启动以正确报告延迟。为了确保我们只报告有意义的延迟，让我们在以下示例条件下触发 `e/report` 调用：
- en: '[PRE108]'
  id: totrans-976
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'Now, let''s assume it is a **Ring**-based ([https://github.com/ring-clojure/ring](https://github.com/ring-clojure/ring))
    web app and you want to trigger the reporting only when the web request contains
    a parameter `report` with a value `true`. In that case, your call might look like
    the following:'
  id: totrans-977
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设它是一个基于 **Ring** ([https://github.com/ring-clojure/ring](https://github.com/ring-clojure/ring))
    的 Web 应用程序，并且您只想在 Web 请求包含参数 `report` 且值为 `true` 时触发报告。在这种情况下，您的调用可能如下所示：
- en: '[PRE109]'
  id: totrans-978
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: Condition-based invocation expects the JVM to be up across several calls, so
    it may not work with command-line apps.
  id: totrans-979
  prefs: []
  type: TYPE_NORMAL
  zh: 基于条件的调用期望 JVM 在多个调用中保持运行，因此它可能不适用于命令行应用程序。
- en: This technique can also be used in performance tests, where non-reporting calls
    may be made during a certain warm-up period, followed by a reporting call that
    provides its own reporter function instead of `e/print-table`. You may even write
    a sampling reporter function that aggregates the samples over a duration and finally
    reports the latency metrics. Not only for performance testing, you can use this
    for latency monitoring where the reporter function logs the metrics instead of
    printing a table, or sends the latency breakup to a metrics aggregation system.
  id: totrans-980
  prefs: []
  type: TYPE_NORMAL
  zh: 此技术也可以用于性能测试，在某个预热期间可能进行非报告调用，然后进行报告调用，该调用提供自己的报告函数而不是`e/print-table`。您甚至可以编写一个采样报告函数，该函数在一段时间内汇总样本，并最终报告延迟指标。不仅限于性能测试，您还可以使用此方法进行延迟监控，其中报告函数记录指标而不是打印表格，或将延迟分解发送到指标聚合系统。
- en: Garbage collection bottlenecks
  id: totrans-981
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 垃圾回收瓶颈
- en: 'Since Clojure runs on the JVM, one has to be aware of the GC behavior in the
    application. You can print out the GC details at runtime by specifying the respective
    JVM options in `project.clj` or on the Java command-line:'
  id: totrans-982
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Clojure运行在JVM上，因此必须了解应用程序中的GC行为。您可以通过在`project.clj`或Java命令行中指定相应的JVM选项来在运行时打印GC详细信息：
- en: '[PRE110]'
  id: totrans-983
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'This causes a detailed summary of GC events to be printed as the application
    runs. To capture the output in a file, you can specify the following parameter:'
  id: totrans-984
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在应用程序运行时打印GC事件的详细摘要。为了将输出捕获到文件中，您可以指定以下参数：
- en: '[PRE111]'
  id: totrans-985
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'It is also useful to see the time between and during full GC events:'
  id: totrans-986
  prefs: []
  type: TYPE_NORMAL
  zh: 看到完全GC事件之间和期间的时间也很有用：
- en: '[PRE112]'
  id: totrans-987
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'The other useful options to troubleshoot GC are as follows:'
  id: totrans-988
  prefs: []
  type: TYPE_NORMAL
  zh: 解决GC问题的其他有用选项如下：
- en: '`-XX:+HeapDumpOnOutOfMemoryError`'
  id: totrans-989
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-XX:+HeapDumpOnOutOfMemoryError`'
- en: '`-XX:+PrintTenuringDistribution`'
  id: totrans-990
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-XX:+PrintTenuringDistribution`'
- en: '`-XX:+PrintHeapAtGC`'
  id: totrans-991
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-XX:+PrintHeapAtGC`'
- en: The output of the previous options may help you identify GC bottlenecks that
    you can try to fix by choosing the right garbage collector, other generational
    heap options, and code changes. For easy viewing of GC logs, you may like to use
    GUI tools such as **GCViewer** ([https://github.com/chewiebug/GCViewer](https://github.com/chewiebug/GCViewer))
    for this purpose.
  id: totrans-992
  prefs: []
  type: TYPE_NORMAL
  zh: 之前选项的输出可以帮助您识别可以尝试通过选择合适的垃圾回收器、其他代际堆选项和代码更改来修复的GC瓶颈。为了方便查看GC日志，您可能喜欢使用GUI工具，如**GCViewer**
    ([https://github.com/chewiebug/GCViewer](https://github.com/chewiebug/GCViewer))来实现此目的。
- en: Threads waiting at GC safepoint
  id: totrans-993
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 等待在GC安全点的线程
- en: 'When there is a long tight loop (without any I/O operation) in the code, the
    thread executing it cannot be brought to safepoint if GC happens when the loop
    ends or goes out of memory (for example, fails to allocate). This may have a disastrous
    effect of stalling other critical threads during GC. You can identify this category
    of bottleneck by enabling safepoint logs using the following JVM option:'
  id: totrans-994
  prefs: []
  type: TYPE_NORMAL
  zh: 当代码中存在一个长时间紧循环（没有任何I/O操作）时，如果在循环结束时或内存不足时发生GC，执行该循环的线程无法达到安全点（例如，无法分配）。这可能会在GC期间对其他关键线程产生灾难性的影响。您可以通过启用以下JVM选项来识别此类瓶颈：
- en: '[PRE113]'
  id: totrans-995
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: The safepoint logs emitted by the previous option may help you identify the
    impact of a tight-loop thread on other threads during GC.
  id: totrans-996
  prefs: []
  type: TYPE_NORMAL
  zh: 之前选项发出的安全点日志可以帮助您识别在GC期间紧循环线程对其他线程的影响。
- en: Using jstat to probe GC details
  id: totrans-997
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用jstat探测GC细节
- en: 'The Oracle JDK (also OpenJDK, Azul''s Zulu) comes with a utility called `jstat`
    that can be handy to inspect GC details. You can find details on this utility
    at [https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstat.html](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstat.html)
    —the following examples show how to use it:'
  id: totrans-998
  prefs: []
  type: TYPE_NORMAL
  zh: Oracle JDK（也包括OpenJDK、Azul的Zulu）附带一个名为`jstat`的实用工具，可以方便地检查GC细节。您可以在[https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstat.html](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstat.html)上找到有关此实用工具的详细信息——以下示例显示了如何使用它：
- en: '[PRE114]'
  id: totrans-999
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: The first command mentioned previously monitors object allocations and freeing
    in various heap generations, together with other GC statistics, one in every 10
    seconds. The second command also prints the reason for GC, along with other details.
  id: totrans-1000
  prefs: []
  type: TYPE_NORMAL
  zh: 之前提到的第一个命令监控了各种堆代中的对象分配和释放，以及其他GC统计信息，每10秒输出一次。第二个命令也会打印GC的原因，以及其他详细信息。
- en: Inspecting generated bytecode for Clojure source
  id: totrans-1001
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查Clojure源生成的字节码
- en: We discussed in [Chapter 3](ch10.html "Chapter 3. Leaning on Java"), *Leaning
    on Java* how to see the generated equivalent Java code for any Clojure code. Sometimes,
    there may not be a direct correlation between the generated bytecode and Java,
    which is when inspecting the generated bytecode is very useful. Of course, it
    requires the reader to know at least a bit about the JVM instruction set ([http://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html](http://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html)).
    This tool can allow you to very effectively analyze the cost of the generated
    bytecode instructions.
  id: totrans-1002
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第3章](ch10.html "第3章。依赖Java")中讨论了*依赖Java*，介绍了如何查看任何Clojure代码生成的等效Java代码。有时，生成的字节码与Java之间可能没有直接关联，这时检查生成的字节码就非常有用。当然，这要求读者至少对JVM指令集([http://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html](http://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html))有一定的了解。这个工具可以让你非常有效地分析生成的字节码指令的成本。
- en: 'The project **no.disassemble** ([https://github.com/gtrak/no.disassemble](https://github.com/gtrak/no.disassemble))
    is a very useful tool to discover the generated bytecode. Include it in your `project.clj`
    file as a Leiningen plugin:'
  id: totrans-1003
  prefs: []
  type: TYPE_NORMAL
  zh: 项目**no.disassemble**([https://github.com/gtrak/no.disassemble](https://github.com/gtrak/no.disassemble))是一个非常有用的工具，可以用来发现生成的字节码。将其包含在`project.clj`文件中作为Leiningen插件：
- en: '[PRE115]'
  id: totrans-1004
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'Then, at the REPL, you can inspect the generated bytecodes one by one:'
  id: totrans-1005
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在REPL中，你可以逐个检查生成的字节码：
- en: '[PRE116]'
  id: totrans-1006
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: The previous snippet prints out the bytecode of the Clojure expression entered
    there.
  id: totrans-1007
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的代码片段输出了在那里输入的Clojure表达式的字节码。
- en: Throughput bottlenecks
  id: totrans-1008
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 吞吐量瓶颈
- en: The throughput bottlenecks usually arise from shared resources, which could
    be CPU, cache, memory, mutexes and locks, GC, disk, and other I/O devices. Each
    of these resources has a different way to find utilization, saturation, and load
    level. This also heavily depends on the operating system in use, as it manages
    the resources. Delving into the OS-specific ways of determining those factors
    is beyond the scope of this text. However, we will look at profiling some of these
    for bottlenecks in the next section.
  id: totrans-1009
  prefs: []
  type: TYPE_NORMAL
  zh: 吞吐量瓶颈通常源于共享资源，这些资源可能是CPU、缓存、内存、互斥锁、GC、磁盘和其他I/O设备。每种资源都有不同的方法来查找利用率、饱和度和负载水平。这也很大程度上取决于所使用的操作系统，因为它管理这些资源。深入探讨特定于操作系统的确定这些因素的方法超出了本文的范围。然而，我们将在下一节中查看一些这些资源的分析，以确定瓶颈。
- en: The net effect of throughput shows up as an inverse relationship with latency.
    This is natural as per Little's law—as we will see in the next chapter. We covered
    throughput testing and latency testing under concurrency in [Chapter 6](ch13.html
    "Chapter 6. Measuring Performance"), *Measuring Performance*. This should be roughly
    a good indicator of the throughput trend.
  id: totrans-1010
  prefs: []
  type: TYPE_NORMAL
  zh: 吞吐量的净效应表现为与延迟的倒数关系。根据Little定律，这是自然的——我们将在下一章中看到。在[第6章](ch13.html "第6章。测量性能")*测量性能*中，我们讨论了并发下的吞吐量测试和延迟测试。这应该是一个大致的吞吐量趋势的良好指标。
- en: Profiling code with VisualVM
  id: totrans-1011
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用VisualVM分析代码
- en: 'The Oracle JDK (also OpenJDK) comes with a powerful profiler called **VisualVM**;
    the distribution that comes with the JDK is known as Java VisualVM and can be
    invoked using the binary executable:'
  id: totrans-1012
  prefs: []
  type: TYPE_NORMAL
  zh: Oracle JDK（也称为OpenJDK）附带了一个强大的分析器，称为**VisualVM**；与JDK一起分发的版本被称为Java VisualVM，可以通过二进制可执行文件来调用：
- en: '[PRE117]'
  id: totrans-1013
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: This launches the GUI profiler app where you can connect to running instances
    of the JVM. The profiler has powerful features ([https://visualvm.java.net/features.html](https://visualvm.java.net/features.html))
    that can be useful for finding various bottlenecks in code. Besides analyzing
    heap dump and thread dump, VisualVM can interactively graph CPU and heap consumption,
    and thread status in near real time. It also has sampling and tracing profilers
    for both CPU and memory.
  id: totrans-1014
  prefs: []
  type: TYPE_NORMAL
  zh: 这将启动GUI分析器应用程序，你可以连接到正在运行的JVM实例。分析器具有强大的功能([https://visualvm.java.net/features.html](https://visualvm.java.net/features.html))，这些功能对于查找代码中的各种瓶颈非常有用。除了分析堆转储和线程转储外，VisualVM还可以实时交互式地绘制CPU和堆消耗，以及线程状态。它还具有CPU和内存的采样和跟踪分析器。
- en: The Monitor tab
  id: totrans-1015
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控标签页
- en: 'The **Monitor** tab has a graphical overview of the runtime, including CPU,
    heap, threads and loaded classes:'
  id: totrans-1016
  prefs: []
  type: TYPE_NORMAL
  zh: '**监控**标签页显示了运行时的图形概览，包括CPU、堆、线程和加载的类：'
- en: '![The Monitor tab](img/3642_07_01.jpg)'
  id: totrans-1017
  prefs: []
  type: TYPE_IMG
  zh: '![监控标签页](img/3642_07_01.jpg)'
- en: This tab is useful for "at a glance" information, leaving further drill-down
    for other tabs.
  id: totrans-1018
  prefs: []
  type: TYPE_NORMAL
  zh: 此标签页用于提供“一目了然”的信息，将更深入的挖掘留给其他标签页。
- en: The Threads tab
  id: totrans-1019
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线程标签页
- en: 'In the following screenshot, the **Threads** tab shows the status of all threads:'
  id: totrans-1020
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的屏幕截图中，**线程**标签页显示了所有线程的状态：
- en: '![The Threads tab](img/3642_07_02.jpg)'
  id: totrans-1021
  prefs: []
  type: TYPE_IMG
  zh: '![线程选项卡](img/3642_07_02.jpg)'
- en: 'It is very useful to find out if any threads are undergoing contention, entering
    deadlock, are underutilized, or they are taking up more CPU. Especially in concurrent
    apps with in-memory state, and in apps that use limited I/O resources (such as
    connection pools, or network calls to other hosts) shared by threads, this feature
    provides a great insight if you set the thread names:'
  id: totrans-1022
  prefs: []
  type: TYPE_NORMAL
  zh: 查找是否有任何线程正在竞争、进入死锁、利用率低或占用更多CPU是非常有用的。特别是在具有内存状态的并发应用程序中，以及在由线程共享的有限I/O资源（如连接池或对其他主机的网络调用）的应用程序中，如果您设置了线程名，此功能提供了极大的洞察力。
- en: 'Notice the threads named **citius-RollingStore-store-1** through **citius-RollingStore-store
    - 4**. In an ideal no-contention scenario, those threads would have a green **Running**
    status. See the legend at the bottom right of the image, which explains thread
    state:'
  id: totrans-1023
  prefs: []
  type: TYPE_NORMAL
  zh: 注意名为**citius-RollingStore-store-1**至**citius-RollingStore-store-4**的线程。在理想的无竞争场景中，这些线程将具有绿色的**运行**状态。请参阅图像右下角的图例，它解释了线程状态：
- en: '**Running**: A thread is running, which is the ideal condition.'
  id: totrans-1024
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**运行**：一个线程正在运行，这是理想的状态。'
- en: '**Sleeping**: A thread has yielded control temporarily.'
  id: totrans-1025
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**睡眠**：一个线程暂时放弃了控制权。'
- en: '**Wait**: A thread is waiting for notification in a critical section. `Object.wait()`
    was called, and is now waiting for `Object.notify()` or `Object.notifyAll()` to
    wake it up.'
  id: totrans-1026
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**等待**：一个线程正在临界区等待通知。调用了`Object.wait()`，现在正在等待`Object.notify()`或`Object.notifyAll()`将其唤醒。'
- en: '**Park**: A thread is parked on a permit (binary semaphore) waiting for some
    condition. Usually seen with concurrent blocking calls in the `java.util.concurrent`
    API.'
  id: totrans-1027
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**挂起**：一个线程挂载在许可（二进制信号量）上，等待某些条件。通常在`java.util.concurrent` API中的并发阻塞调用中看到。'
- en: '**Monitor**: A thread has reached object monitor waiting for some lock, perhaps
    waiting to enter or exit a critical section.'
  id: totrans-1028
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监视器**：一个线程已达到对象监视器，正在等待某些锁，可能是等待进入或退出临界区。'
- en: You can install the *Threads Inspector* plugin for details on threads of interest.
    To inspect thread dumps from the command line you can use the `jstack` or `kill
    -3` commands.
  id: totrans-1029
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以为感兴趣的线程安装“线程检查器”插件以获取详细信息。要从命令行检查线程转储，您可以使用`jstack`或`kill -3`命令。
- en: The Sampler tab
  id: totrans-1030
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在“采样器”选项卡
- en: The **Sampler** tab is the lightweight sampling profiler tab that can sample
    both CPU and memory consumption. You can easily find hotspots in code that may
    benefit from tuning. However, sampler profiling is limited by sampling period
    and frequency, inability to detect inlined code, and so on. It is a good general
    indicator of the bottlenecks and looks similar to the screenshots we saw in [Chapter
    6](ch13.html "Chapter 6. Measuring Performance"), *Measuring Performance*. You
    can profile either CPU or memory at a time.
  id: totrans-1031
  prefs: []
  type: TYPE_NORMAL
  zh: “采样器”选项卡是轻量级的采样分析器选项卡，可以采样CPU和内存消耗。您可以轻松地找到代码中的热点，这些热点可能受益于调整。然而，采样分析受采样周期和频率的限制，无法检测内联代码等。它是瓶颈的良好一般指标，看起来与我们看到的[第6章](ch13.html
    "第6章。测量性能")中的截图相似，*测量性能*。您一次可以分析CPU或内存。
- en: The **CPU** tab displays both the overall CPU time distribution and per-thread
    CPU consumption. You can take a thread dump while sampling is in progress and
    analyze the dump. There are several VisualVM plugins available for more analysis.
  id: totrans-1032
  prefs: []
  type: TYPE_NORMAL
  zh: “CPU”选项卡显示整体CPU时间分布和每个线程的CPU消耗。在采样进行时，您可以获取线程转储并分析转储。有几个VisualVM插件可用于进一步分析。
- en: The **Memory** tab displays heap histogram metrics with distribution and instance
    count of objects. It also shows a PermGen histogram and per thread allocation
    data. It is a very good idea and highly recommended to set thread names in your
    project so that it is easy to locate those names in such tools. In this tab, you
    can force a GC, take a heap dump for analysis, and view memory metrics data in
    several ways.
  id: totrans-1033
  prefs: []
  type: TYPE_NORMAL
  zh: “内存”选项卡显示堆直方图指标，包括对象的分布和实例计数。它还显示PermGen直方图和每个线程的分配数据。在您的项目中设置线程名是一个非常好的主意，并且强烈推荐这样做，这样就可以轻松地在这些工具中定位这些名称。在此选项卡中，您可以强制进行GC、为分析创建堆转储，并以多种方式查看内存指标数据。
- en: Setting the thread name
  id: totrans-1034
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置线程名
- en: 'Setting a thread name in Clojure is quite straightforward using Java interop:'
  id: totrans-1035
  prefs: []
  type: TYPE_NORMAL
  zh: 在Clojure中设置线程名使用Java互操作非常简单：
- en: '[PRE118]'
  id: totrans-1036
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'However, since threads often transcend several contexts, in most cases you
    should do so in a limited scope as follows:'
  id: totrans-1037
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于线程通常跨越多个上下文，在大多数情况下，您应该像以下这样在有限的范围内进行：
- en: '[PRE119]'
  id: totrans-1038
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'Now you can use this macro to execute any body of code with a specified thread
    name:'
  id: totrans-1039
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以使用此宏来执行任何具有指定线程名的代码体：
- en: '[PRE120]'
  id: totrans-1040
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: This style of setting a thread name makes sure that the original name is restored
    before leaving the thread-local scope. If your code has various sections and you
    are setting a different thread name for each section, you can detect which code
    sections are causing contention by looking at the name when any contention appears
    on profiling and monitoring tools.
  id: totrans-1041
  prefs: []
  type: TYPE_NORMAL
  zh: 这种设置线程名称的风格确保在离开线程局部作用域之前恢复原始名称。如果你的代码有多个部分，并且你为每个部分设置不同的线程名称，你可以在分析监控工具上出现任何竞争时通过查看名称来检测哪些代码部分导致了竞争。
- en: The Profiler tab
  id: totrans-1042
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析器标签页
- en: The **Profiler** tab lets you instrument the running code in the JVM, and profile
    both CPU and memory consumption. This option adds a larger overhead than the **Sampler**
    tab, and poses a different trade off in terms of JIT compilation, inlining, and
    accuracy. This tab does not have as much diversity in visualization as the **Sampler**
    tab. The main difference this tab has with the **Sampler** tab is it changes the
    bytecode of the running code for accurate measurement. When you choose CPU profiling,
    it starts instrumenting the code for CPU profiling. If you switch from CPU to
    memory profiling, it re-instruments the running code for memory profiling, and
    re-instruments every time you want a different profiling. One downside of such
    instrumentation is that it may massively slow down everything if your code is
    deployed in application containers, such as Tomcat.
  id: totrans-1043
  prefs: []
  type: TYPE_NORMAL
  zh: '**分析器**标签页允许你在 JVM 中对运行中的代码进行检测，并分析 CPU 和内存消耗。这个选项比 **采样器** 标签页增加了更大的开销，并且在
    JIT 编译、内联和准确性方面提出了不同的权衡。与 **采样器** 标签页相比，这个标签页在可视化方面的多样性较少。这个标签页与 **采样器** 标签页的主要区别在于它会改变运行中代码的字节码以进行准确测量。当你选择
    CPU 分析时，它开始对代码进行 CPU 分析的检测。如果你从 CPU 切换到内存分析，它会重新对运行中的代码进行内存分析的检测，并且每次你想要进行不同的分析时都会重新检测。这种检测的一个缺点是，如果你的代码部署在应用程序容器中，如
    Tomcat，它可能会大幅减慢一切。'
- en: While you can get most of the common CPU bottleneck information from **Sampler**,
    you may need the **Profiler** to investigate hotspots already discovered by **Sampler**
    and other profiling techniques. You can selectively profile and drill-down only
    the known bottlenecks using the instrumenting profiler, thereby restricting its
    ill-effects to only small parts of the code.
  id: totrans-1044
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你可以从 **采样器** 获取大多数常见的 CPU 瓶颈信息，但你可能需要 **分析器** 来调查 **采样器** 和其他分析技术已经发现的热点。你可以使用检测分析器有选择性地分析并深入已知瓶颈，从而将其不良影响限制在代码的小部分。
- en: The Visual GC tab
  id: totrans-1045
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Visual GC 标签页
- en: The **Visual GC** is a VisualVM plugin that visually depicts the GC status in
    near real time.
  id: totrans-1046
  prefs: []
  type: TYPE_NORMAL
  zh: '**Visual GC** 是一个 VisualVM 插件，可以近乎实时地以图形方式展示垃圾回收（GC）的状态。'
- en: '![The Visual GC tab](img/3642_07_03.jpg)'
  id: totrans-1047
  prefs: []
  type: TYPE_IMG
  zh: '![Visual GC 标签页](img/3642_07_03.jpg)'
- en: If your application uses a lot of memory and potentially has GC bottlenecks,
    this plugin may be very useful for various troubleshooting purposes.
  id: totrans-1048
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的应用程序使用大量内存并且可能存在 GC 瓶颈，这个插件可能对各种故障排除目的非常有用。
- en: The Alternate profilers
  id: totrans-1049
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 替代分析器
- en: 'Besides VisualVM, there are several third-party profilers and performance-monitoring
    tools for the Java platform. Among open source tools, Prometheus ([http://prometheus.io/](http://prometheus.io/))
    and Moskito ([http://www.moskito.org/](http://www.moskito.org/)) are relatively
    popular. A non-exhaustive list of Open Source performance tools is here: [http://java-source.net/open-source/profilers](http://java-source.net/open-source/profilers)'
  id: totrans-1050
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 VisualVM 之外，还有几个针对 Java 平台的第三方分析器和性能监控工具。在开源工具中，Prometheus ([http://prometheus.io/](http://prometheus.io/))
    和 Moskito ([http://www.moskito.org/](http://www.moskito.org/)) 相对流行。开源性能工具的不完全列表在这里：[http://java-source.net/open-source/profilers](http://java-source.net/open-source/profilers)
- en: There are several commercial proprietary profilers that you may want to know
    about. The YourKit ([https://www.yourkit.com/](https://www.yourkit.com/)) Java
    profiler is probably the most notable profiler that many people have found much
    success with for profiling Clojure code. There are also other profiling tools
    for the JVM, such as JProfiler ([https://www.ej-technologies.com/products/jprofiler/overview.html](https://www.ej-technologies.com/products/jprofiler/overview.html)),
    which is a desktop-based profiler and web-based hosted solutions such as New Relic
    ([http://newrelic.com/](http://newrelic.com/)) and AppDynamics ([https://www.appdynamics.com/](https://www.appdynamics.com/)).
  id: totrans-1051
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个商业专有分析器你可能想了解一下。YourKit ([https://www.yourkit.com/](https://www.yourkit.com/))
    Java分析器可能是许多人发现对分析Clojure代码非常成功的最著名分析器。还有其他针对JVM的分析工具，如JProfiler ([https://www.ej-technologies.com/products/jprofiler/overview.html](https://www.ej-technologies.com/products/jprofiler/overview.html))，这是一个基于桌面的分析器，以及基于网络的托管解决方案，如New
    Relic ([http://newrelic.com/](http://newrelic.com/)) 和AppDynamics ([https://www.appdynamics.com/](https://www.appdynamics.com/))。
- en: Performance tuning
  id: totrans-1052
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能调整
- en: Once we get insight into the code via testing and profiling results, we need
    to analyze the bottlenecks worth considering for optimization. A better approach
    is to find the most under-performing portion and optimize it, thereby eliminating
    the weakest link. We discussed performance aspects of hardware and JVM/Clojure
    in previous chapters. Optimization and tuning requires rethinking the design and
    code in light of those aspects, and then refactoring for performance objectives.
  id: totrans-1053
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦通过测试和性能分析结果对代码有了深入了解，我们就需要分析值得考虑优化的瓶颈。更好的方法是找到表现最差的片段并对其进行优化，从而消除最薄弱的环节。我们在前面的章节中讨论了硬件和JVM/Clojure的性能方面。优化和调整需要根据这些方面重新思考设计和代码，然后为了性能目标进行重构。
- en: Once we establish the performance bottlenecks, we have to pinpoint the root
    cause and experiment with improvisations, one step at a time, to see what works.
    Tuning for performance is an iterative process that is backed by measurement,
    monitoring and experimentation.
  id: totrans-1054
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了性能瓶颈，我们必须找出根本原因，并逐步尝试改进，以查看哪些有效。性能调整是一个基于测量、监控和实验的迭代过程。
- en: Tuning Clojure code
  id: totrans-1055
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整Clojure代码
- en: Identifying the nature of the performance bottleneck helps a lot in order to
    experiment with the right aspects of the code. The key is to determine the origin
    of cost and whether the cost is reasonable.
  id: totrans-1056
  prefs: []
  type: TYPE_NORMAL
  zh: 识别性能瓶颈的本质对于在代码的正确方面进行实验非常有帮助。关键是确定成本的来源以及成本是否合理。
- en: CPU/cache bound
  id: totrans-1057
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CPU/缓存绑定
- en: As we noted in the beginning of this chapter, setting up a project with the
    right JVM options and project settings informs us of reflection and boxing, the
    common sources of CPU-bound performance issues after poor design and algorithm
    choice. As a general rule, we have to see whether we are doing unnecessary or
    suboptimal operations, especially inside loops. For example, transducers are amenable
    to better performance than lazy sequences in CPU-bound operations.
  id: totrans-1058
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章开头所指出的，设置具有正确JVM选项和项目设置的项目使我们了解反射和装箱，这是在设计和算法选择不佳后CPU性能问题的常见来源。一般来说，我们必须看看我们是否在进行不必要的或次优的操作，尤其是在循环内部。例如，transducers在CPU密集型操作中比懒序列更适合更好的性能。
- en: While public functions are recommended to work with immutable data structures,
    the implementation details can afford to use transients and arrays when performance
    is necessary. Records are a great alternative to maps, where appropriate, due
    to type hints and tight field layout in the former. Operations on primitive data
    types is faster (hence recommended) than their boxed equivalents.
  id: totrans-1059
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然建议公共函数使用不可变数据结构，但在性能必要时，实现细节可以使用transients和arrays。在适当的情况下，记录是map的绝佳替代品，因为前者有类型提示和紧凑的字段布局。对原始数据类型的操作比它们的包装类型更快（因此推荐）。
- en: In tight loops, besides transients and arrays you may prefer loop-recur with
    unchecked math for performance. You may also like to avoid using multi-methods
    and dynamic vars in tight loops, rather than pass arguments around. Using Java
    and macros may be the last resort, but still an option if there is such a need
    for performance.
  id: totrans-1060
  prefs: []
  type: TYPE_NORMAL
  zh: 在紧密循环中，除了transients和arrays，你可能更喜欢使用带有未检查数学的loop-recur以提高性能。你也可能喜欢避免在紧密循环中使用多方法和动态变量，而不是传递参数。使用Java和宏可能是最后的手段，但在需要性能的情况下仍然是一个选项。
- en: Memory bound
  id: totrans-1061
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内存绑定
- en: Allocating less memory in code is always going to reduce memory-related performance
    issues. Optimization of memory-bound code is not only about reducing memory consumption,
    but it is also about memory layout and utilizing the CPU and cache well. We have
    to see whether we are using the data types that fit well in CPU registers and
    cache lines. For cache and memory-bound code, we have to know whether there are
    cache misses and the reason—often the data might be too large to fit in a cache
    line. For memory-bound code we have to care about data locality, whether the code
    is hitting the interconnect too often, and whether memory representation of data
    can be slimmed down.
  id: totrans-1062
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中分配更少的内存总是能减少与内存相关的性能问题。优化内存密集型代码不仅关乎减少内存消耗，还关乎内存布局以及如何有效地利用CPU和缓存。我们必须检查我们是否使用了适合CPU寄存器和缓存行的数据类型。对于缓存和内存密集型代码，我们必须了解是否存在缓存未命中以及原因——通常数据可能太大，无法适应缓存行。对于内存密集型代码，我们必须关注数据局部性，代码是否过于频繁地访问互连，以及数据在内存中的表示是否可以简化。
- en: Multi-threaded
  id: totrans-1063
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多线程
- en: Shared resources with side effects are the main source of contention and performance
    bottlenecks in multi-threaded code. As we saw in the *Profiling VisualVM code*
    section in this chapter, profiling the threads better informs us about the bottlenecks.
    The best way to improve performance of multi-threaded code is to reduce contention.
    The easy way to reduce contention is to increase the resources and reduce concurrency,
    though only optimal levels of resources and concurrency would be good for performance.
    While designing for concurrency, append only, single writer, and shared nothing
    approaches work well.
  id: totrans-1064
  prefs: []
  type: TYPE_NORMAL
  zh: 具有副作用共享资源是多线程代码中竞争和性能瓶颈的主要来源。正如我们在本章的“*VisualVM代码分析*”部分所看到的，更好地分析线程可以让我们更清楚地了解瓶颈。提高多线程代码性能的最好方法是减少竞争。减少竞争的一个简单方法是增加资源并减少并发性，尽管只有最优的资源水平和并发性对性能才是有益的。在设计并发时，仅追加、单写者和无共享数据方法都表现得很好。
- en: Another way to reduce contention may be to exploit thread-local queueing of
    data until resources are available. This technique is similar to what Clojure
    agents use, though it is an involved technique. [Chapter 5](ch12.html "Chapter 5. Concurrency"),
    *Concurrency* covers agents in some detail. I would encourage you to study the
    agents source code for better understanding. When using CPU-bound resources (for
    example `java.util.concurrent.atomic.AtomicLong`) you may use the contention-striping
    technique used by some Java 8 classes (such as `java.util.concurrent.atomic.LongAdder`,
    which also balances between memory consumption and contention striping across
    processors.) This technique is also quite involved and generic contention-striping
    solutions may have to trade off read consistency to allow fast updates.
  id: totrans-1065
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种减少竞争的方法可能是利用线程局部队列直到资源可用。这种技术与Clojure代理所使用的技术类似，尽管它是一个复杂的技术。[第5章](ch12.html
    "第5章。并发") *并发* 对代理进行了详细说明。我鼓励您研究代理源代码以更好地理解。当使用CPU密集型资源（例如`java.util.concurrent.atomic.AtomicLong`）时，您可以使用一些Java
    8类（如`java.util.concurrent.atomic.LongAdder`，它也在处理器之间平衡内存消耗和竞争分割）使用的竞争分割技术。这种技术也很复杂，通用的竞争分割解决方案可能需要牺牲读一致性以允许快速更新。
- en: I/O bound
  id: totrans-1066
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I/O密集型
- en: I/O-bound tasks could be limited by bandwidth or IOPS/latency. Any I/O bottleneck
    usually manifests in chatty I/O calls or unconstrained data serialization. Restricting
    I/O to only minimum required data is a common opportunity to minimize serialization
    and reduce latency. I/O operations can often be batched for higher throughput,
    for example *SpyMemcached* library employs an asynchronous batched operation for
    high throughput.
  id: totrans-1067
  prefs: []
  type: TYPE_NORMAL
  zh: I/O密集型任务可能受到带宽或IOPS/延迟的限制。任何I/O瓶颈通常表现为频繁的I/O调用或未受约束的数据序列化。将I/O限制在仅所需的最小数据上是一种常见的最小化序列化和减少延迟的机会。I/O操作通常可以批量处理以提高吞吐量，例如*SpyMemcached*库使用异步批量操作以实现高吞吐量。
- en: I/O-bound bottlenecks are often coupled with multi-threaded scenarios. When
    the I/O calls are synchronous (for example, the JDBC API), one naturally has to
    depend upon multiple threads working on a bounded resource pool. Asynchronous
    I/O can relieve our threads from blocking, letting the threads do other useful
    work until the I/O response arrives. In synchronous I/O, we pay the cost of having
    threads (each allocated with memory) block on I/O calls while the kernel schedules
    them.
  id: totrans-1068
  prefs: []
  type: TYPE_NORMAL
  zh: I/O瓶颈通常与多线程场景相关联。当I/O调用是同步的（例如，JDBC API），自然需要依赖多个线程在有限资源池上工作。异步I/O可以缓解线程的阻塞，让线程在I/O响应到达之前做其他有用的工作。在同步I/O中，我们付出了线程（每个线程分配了内存）在I/O调用上阻塞的成本，而内核则安排这些调用。
- en: JVM tuning
  id: totrans-1069
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: JVM调整
- en: Often Clojure applications might inherit bloat from Clojure/Java libraries or
    frameworks, which cause poor performance. Hunting down unnecessary abstractions
    and unnecessary layers of code may bring decent performance gains. Reasoning about
    the performance of dependency libraries/frameworks before inclusion in a project
    is a good approach.
  id: totrans-1070
  prefs: []
  type: TYPE_NORMAL
  zh: 常常Clojure应用程序可能会从Clojure/Java库或框架中继承膨胀，这会导致性能不佳。追踪不必要的抽象和不必要的代码层可能会带来可观的性能提升。在将依赖库/框架包含到项目中之前，考虑这些库/框架的性能是一个好的方法。
- en: The JIT compiler, garbage collector and safepoint (in Oracle HotSpot JVM) have
    a significant impact on the performance of applications. We discussed the JIT
    compiler and garbage collector in [Chapter 4](ch11.html "Chapter 4. Host Performance"),
    *Host Performance*. When the HotSpot JVM reaches a point when it cannot carry
    out concurrent, incremental GC anymore, it needs to suspend the JVM safely in
    order to carry out a full GC. It is also called the stop-the-world GC pause that
    may run up to several minutes while the JVM appears frozen.
  id: totrans-1071
  prefs: []
  type: TYPE_NORMAL
  zh: JIT编译器、垃圾回收器和安全点（在Oracle HotSpot JVM中）对应用程序的性能有重大影响。我们在[第4章](ch11.html "第4章。主机性能")*主机性能*中讨论了JIT编译器和垃圾回收器。当HotSpot
    JVM达到无法再执行并发增量GC的点时，它需要安全地挂起JVM以执行完全GC。这也被称为停止世界的GC暂停，可能持续几分钟，而JVM看起来是冻结的。
- en: The Oracle and OpenJDK JVMs accept many command-line options when invoked, to
    tune and monitor the way components in the JVM behave. Tuning GC is common among
    people who want to extract optimum performance from the JVM.
  id: totrans-1072
  prefs: []
  type: TYPE_NORMAL
  zh: Oracle和OpenJDK JVM在调用时接受许多命令行选项，以调整和监控JVM中组件的行为。对于想要从JVM中提取最佳性能的人来说，调整GC是很常见的。
- en: 'You may like to experiment with the following JVM options (Oracle JVM or OpenJDK)
    for performance:'
  id: totrans-1073
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能想尝试以下JVM选项（Oracle JVM或OpenJDK）以提升性能：
- en: '| JVM option | Description |'
  id: totrans-1074
  prefs: []
  type: TYPE_TB
  zh: '| JVM选项 | 描述 |'
- en: '| --- | --- |'
  id: totrans-1075
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `-XX:+AggressiveOpts` | Aggressive options that enable compressed heap pointers
    |'
  id: totrans-1076
  prefs: []
  type: TYPE_TB
  zh: '| `-XX:+AggressiveOpts` | 启用压缩堆指针的激进选项 |'
- en: '| `-server` | Server class JIT thresholds (use -client for GUI apps) |'
  id: totrans-1077
  prefs: []
  type: TYPE_TB
  zh: '| `-server` | 服务器类JIT阈值（用于GUI应用程序请使用-client） |'
- en: '| `-XX:+UseParNewGC` | Use Parallel GC |'
  id: totrans-1078
  prefs: []
  type: TYPE_TB
  zh: '| `-XX:+UseParNewGC` | 使用并行GC |'
- en: '| `-Xms3g` | Specify min heap size (keep it less on desktop apps) |'
  id: totrans-1079
  prefs: []
  type: TYPE_TB
  zh: '| `-Xms3g` | 指定最小堆大小（在桌面应用程序上保持较小） |'
- en: '| `-Xmx3g` | Specify max heap size (keep min/max same on servers) |'
  id: totrans-1080
  prefs: []
  type: TYPE_TB
  zh: '| `-Xmx3g` | 指定最大堆大小（在服务器上保持最小/最大相同） |'
- en: '| `-XX:+UseLargePages` | Reduce Translation-Lookaside Buffer misses (if OS
    supports), see [http://www.oracle.com/technetwork/java/javase/tech/largememory-jsp-137182.html](http://www.oracle.com/technetwork/java/javase/tech/largememory-jsp-137182.html)
    for details |'
  id: totrans-1081
  prefs: []
  type: TYPE_TB
  zh: '| `-XX:+UseLargePages` | 减少转换查找缓冲区丢失（如果操作系统支持），有关详细信息请参阅[http://www.oracle.com/technetwork/java/javase/tech/largememory-jsp-137182.html](http://www.oracle.com/technetwork/java/javase/tech/largememory-jsp-137182.html)
    |'
- en: 'On the Java 6 HotSpot JVM, the **Concurrent Mark and Sweep** (**CMS**) garbage
    collector is well regarded for its GC performance. On the Java 7 and Java 8 HotSpot
    JVM, the default GC is a parallel collector (for better throughput), whereas at
    the time of writing this, there is a proposal to use the G1 collector (for lower
    pauses) by default in the upcoming Java 9\. Note that the JVM GC can be tuned
    for different objectives, hence the same exact configuration for one application
    may not work well for another. Refer to the documents Oracle published for tuning
    the JVM at the following links:'
  id: totrans-1082
  prefs: []
  type: TYPE_NORMAL
  zh: 在Java 6 HotSpot JVM上，**并发标记清除**（**CMS**）垃圾回收器因其GC性能而备受好评。在Java 7和Java 8 HotSpot
    JVM上，默认的GC是一个并行收集器（以提高吞吐量），而撰写本文时，有一个提议在即将到来的Java 9中默认使用G1收集器（以降低暂停时间）。请注意，JVM
    GC可以根据不同的目标进行调整，因此同一应用程序的配置可能对另一个应用程序不起作用。请参阅Oracle发布的以下链接中的文档，了解如何调整JVM：
- en: '[http://www.oracle.com/technetwork/java/tuning-139912.html](http://www.oracle.com/technetwork/java/tuning-139912.html)'
  id: totrans-1083
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.oracle.com/technetwork/java/tuning-139912.html](http://www.oracle.com/technetwork/java/tuning-139912.html)'
- en: '[https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/](https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/)'
  id: totrans-1084
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/](https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/)'
- en: Back pressure
  id: totrans-1085
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 背压
- en: It is not uncommon to see applications behaving poorly under load. Typically,
    the application server simply appears unresponsive, which is often a combined
    result of high resource utilization, GC pressure, more threads that lead to busier
    thread scheduling, and cache misses. If the capacity of a system is known, the
    solution is to apply **back pressure** by denying services after the capacity
    is reached. Note that back pressure cannot be applied optimally until the system
    is load-tested for optimum capacity. The capacity threshold that triggers back
    pressure may or may not be directly associated with individual services, but rather
    can be defined as load criteria.
  id: totrans-1086
  prefs: []
  type: TYPE_NORMAL
  zh: 在负载下看到应用程序表现不佳并不罕见。通常，应用程序服务器简单地看起来无响应，这通常是高资源利用率、GC压力、更多线程导致更繁忙的线程调度和缓存未命中等多种因素的综合结果。如果已知系统的容量，解决方案是在达到容量后拒绝服务以应用**背压**。请注意，只有在系统经过负载测试以确定最佳容量后，才能最优地应用背压。触发背压的容量阈值可能与单个服务直接相关，也可能不直接相关，而是可以定义为负载标准。
- en: Summary
  id: totrans-1087
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: It is worth reiterating that performance optimization begins with learning about
    how the underlying system works, and measuring the performance of systems we build
    under representative hardware and load. The chief component of performance optimization
    is identifying the bottlenecks using various kinds of measurements and profiling.
    Thereafter, we can apply experiments to tune the performance of code and measure/profile
    once again to verify. The tuning mechanism varies depending on the type of bottleneck.
  id: totrans-1088
  prefs: []
  type: TYPE_NORMAL
  zh: 值得重申的是，性能优化始于了解底层系统的工作原理，并在代表性的硬件和负载下测量我们构建的系统的性能。性能优化的主要组成部分是使用各种类型的测量和剖析来识别瓶颈。之后，我们可以应用实验来调整代码的性能，并再次进行测量/剖析以验证。调整机制取决于瓶颈的类型。
- en: In the next chapter, we will see how to address performance concerns when building
    applications. Our focus will be on the several common patterns that impact performance.
  id: totrans-1089
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到如何在构建应用程序时解决性能问题。我们的重点将是影响性能的几个常见模式。
- en: Chapter 8. Application Performance
  id: totrans-1090
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 应用性能
- en: The earliest computing devices were built to perform automatic computations
    and, as computers grew in power, they became increasingly popular because of how
    much and how fast they could compute. Even today, this essence lives on in our
    anticipation that computers can execute our business calculations faster than
    before by means of the applications we run on them.
  id: totrans-1091
  prefs: []
  type: TYPE_NORMAL
  zh: 最早的计算设备是为了执行自动计算而建造的，随着计算机性能的提升，它们越来越受欢迎，因为它们能够进行大量且快速的运算。即使今天，这种本质仍然体现在我们期待通过在计算机上运行的应用程序来使计算机比以前更快地执行我们的商业计算。
- en: 'Compared to performance analysis and optimization at a smaller component level,
    as we saw in previous chapters, it takes a holistic approach to improve performance
    at the application level. The higher-level concerns, such as serving a certain
    number of users in a day, or handling an identified quantum of load through a
    multi-layered system, requires us to think about how the components fit together
    and how the load is designed to flow through it. In this chapter, we will discuss
    such high-level concerns. Like the previous chapter, by and large this chapter
    applies to applications written in any JVM language, but with a focus on Clojure.
    In this chapter, we will discuss general performance techniques that apply to
    all layers of the code:'
  id: totrans-1092
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们在前几章中看到的较小组件级别的性能分析和优化相比，它需要一种整体的方法来提高应用层的性能。更高层次的关注，如每天服务一定数量的用户，或者通过多层系统处理已识别的负载量，需要我们思考组件如何配合以及负载是如何设计通过它们的。在本章中，我们将讨论这些高层次的关注。与上一章类似，总体而言，本章适用于任何JVM语言编写的应用程序，但重点在于Clojure。在本章中，我们将讨论适用于代码所有层的通用性能技术：
- en: Choosing libraries
  id: totrans-1093
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择库
- en: Logging
  id: totrans-1094
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录日志
- en: Data sizing
  id: totrans-1095
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据大小
- en: Resource pooling
  id: totrans-1096
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 资源池化
- en: Fetch and compute in advance
  id: totrans-1097
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提前获取和计算
- en: Staging and batching
  id: totrans-1098
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阶段化和批量处理
- en: Little's law
  id: totrans-1099
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利特尔定律
- en: Choosing libraries
  id: totrans-1100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择库
- en: Most non-trivial applications depend a great deal on third-party libraries for
    various functionality, such as logging, serving web requests, connecting to databases,
    writing to message queues, and so on. Many of these libraries not only carry out
    parts of critical business functionality but also appear in the performance-sensitive
    areas of our code, impacting the overall performance. It is imperative that we
    choose libraries wisely (with respect to features versus performance trade off)
    after due performance analysis.
  id: totrans-1101
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数非平凡应用程序在很大程度上依赖于第三方库来实现各种功能，例如日志记录、处理网络请求、连接到数据库、写入消息队列等。许多这些库不仅执行关键业务功能的一部分，而且出现在性能敏感的代码区域，影响整体性能。在充分进行性能分析后，我们明智地选择库（在功能与性能权衡方面）是至关重要的。
- en: The crucial factor in choosing libraries is not identifying which library to
    use, rather it is having a performance model of our applications and having the
    use cases benchmarked under representative load. Only benchmarks can tell us whether
    the performance is problematic or acceptable. If the performance is below expectation,
    a drill-down profiling can show us whether a third-party library is causing the
    performance issue. In [Chapter 6](ch13.html "Chapter 6. Measuring Performance"),
    *Measuring Performance* and [Chapter 7](ch14.html "Chapter 7. Performance Optimization"),
    *Performance Optimization* we discussed how to measure performance and identify
    bottlenecks. You can evaluate multiple libraries for performance-sensitive use
    cases and choose what suits.
  id: totrans-1102
  prefs: []
  type: TYPE_NORMAL
  zh: 选择库的关键因素不是确定使用哪个库，而是拥有我们应用程序的性能模型，并在代表性负载下对用例进行基准测试。只有基准测试才能告诉我们性能是否存在问题或可接受。如果性能低于预期，深入分析可以显示第三方库是否导致了性能问题。在[第6章](ch13.html
    "第6章。性能测量") *性能测量* 和 [第7章](ch14.html "第7章。性能优化") *性能优化* 中，我们讨论了如何测量性能和识别瓶颈。您可以为性能敏感的用例评估多个库，并选择适合的库。
- en: Libraries often improve (or occasionally lose) performance with new releases,
    so measurement and profiling (comparative, across versions) should be an ongoing
    practice for the development and maintenance lifecycle of our applications. Another
    factor to note is that libraries may show different performance characteristics
    based on the use case, load, and the benchmark. The devil is in the benchmark
    details. Be sure that your benchmarks are as close as possible to the representative
    scenario for your application.
  id: totrans-1103
  prefs: []
  type: TYPE_NORMAL
  zh: 库通常在新版本中提高（或偶尔降低）性能，因此测量和配置文件（比较，跨版本）应该是我们应用程序的开发和维护生命周期中的持续实践。另一个需要注意的因素是，库可能根据用例、负载和基准表现出不同的性能特征。魔鬼在于基准细节。确保您的基准测试尽可能接近您应用程序的代表性场景。
- en: Making a choice via benchmarks
  id: totrans-1104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过基准测试进行选择
- en: Let's take a brief look at a few general use cases where performance of third-party
    libraries are exposed via benchmarks.
  id: totrans-1105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要看看一些通用用例，在这些用例中，第三方库的性能通过基准测试暴露出来。
- en: Web servers
  id: totrans-1106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网络服务器
- en: 'Web servers are typically subject to quite a bit of performance benchmarking
    due to their generic nature and scope. One such benchmark for Clojure web servers
    exists here:'
  id: totrans-1107
  prefs: []
  type: TYPE_NORMAL
  zh: 由于网络服务器具有通用性和广泛的应用范围，它们通常会受到大量的性能基准测试。Clojure网络服务器的一个基准测试示例如下：
- en: '[https://github.com/ptaoussanis/clojure-web-server-benchmarks](https://github.com/ptaoussanis/clojure-web-server-benchmarks)'
  id: totrans-1108
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/ptaoussanis/clojure-web-server-benchmarks](https://github.com/ptaoussanis/clojure-web-server-benchmarks)'
- en: Web servers are complex pieces of software and they may exhibit different characteristics
    under various conditions. As you will notice, the performance numbers vary based
    on keep-alive versus non-keep-alive modes and request volume—at the time of writing,
    Immutant-2 came out better in keep-alive mode but fared poorly in the non-keep-alive
    benchmark. In production, people often front their application servers with reverse
    proxy servers, for example Nginx or HAProxy, which make keep-alive connections
    to application servers.
  id: totrans-1109
  prefs: []
  type: TYPE_NORMAL
  zh: 网络服务器是复杂的软件组件，它们可能在各种条件下表现出不同的特性。如您所注意到的，性能数字根据长连接与短连接模式以及请求量而变化——在撰写本文时，Immutant-2在长连接模式下表现较好，但在短连接基准测试中表现不佳。在生产环境中，人们通常使用反向代理服务器（例如Nginx或HAProxy）作为应用程序服务器的前端，这些代理服务器与应用程序服务器建立长连接。
- en: Web routing libraries
  id: totrans-1110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网络路由库
- en: 'There are several web routing libraries for Clojure, as listed here:'
  id: totrans-1111
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure有多个网络路由库，如下所示：
- en: '[https://github.com/juxt/bidi#comparison-with-other-routing-libraries](https://github.com/juxt/bidi#comparison-with-other-routing-libraries)'
  id: totrans-1112
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/juxt/bidi#comparison-with-other-routing-libraries](https://github.com/juxt/bidi#comparison-with-other-routing-libraries)'
- en: 'The same document also shows a performance benchmark with **Compojure** as
    the baseline, in which (at the time of writing) Compojure turns out to be performing
    better than **Bidi**. However, another benchmark compares Compojure, **Clout**
    (the library that Compojure internally uses), and **CalfPath** routing here:'
  id: totrans-1113
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的文档还显示了一个以 **Compojure** 为基准的性能基准测试，在撰写本文时，Compojure 的表现优于 **Bidi**。然而，另一个基准测试比较了
    Compojure、**Clout**（Compojure 内部使用的库）和 **CalfPath** 路由：
- en: '[https://github.com/kumarshantanu/calfpath#development](https://github.com/kumarshantanu/calfpath#development)'
  id: totrans-1114
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/kumarshantanu/calfpath#development](https://github.com/kumarshantanu/calfpath#development)'
- en: In this benchmark, as of this writing, Clout performs better than Compojure,
    and CalfPath outperforms Clout. However, you should be aware of any caveats in
    the faster libraries.
  id: totrans-1115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个基准测试中，截至撰写本文时，Clout 的表现优于 Compojure，而 CalfPath 的表现优于 Clout。然而，你应该注意快速库中的任何注意事项。
- en: Data serialization
  id: totrans-1116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据序列化
- en: 'There are several ways to serialize data in Clojure, for example EDN and Fressian.
    Nippy is another serialization library with benchmarks to demonstrate how well
    it performs over EDN and Fressian:'
  id: totrans-1117
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Clojure 中有几种序列化数据的方法，例如 EDN 和 Fressian。Nippy 是另一个序列化库，它包含基准测试来展示它在 EDN 和 Fressian
    上的性能：
- en: '[https://github.com/ptaoussanis/nippy#performance](https://github.com/ptaoussanis/nippy#performance)'
  id: totrans-1118
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/ptaoussanis/nippy#performance](https://github.com/ptaoussanis/nippy#performance)'
- en: We covered Nippy in [Chapter 2](ch09.html "Chapter 2. Clojure Abstractions"),
    *Clojure Abstractions* to show how it uses transients to speed up its internal
    computations. Even within Nippy, there are several flavors of serialization that
    have different features/performance trade-offs.
  id: totrans-1119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 [第 2 章](ch09.html "第 2 章。Clojure 抽象") *Clojure 抽象* 中介绍了 Nippy，以展示它如何使用瞬态来加速其内部计算。即使在
    Nippy 中，也有几种序列化方式，它们具有不同的特性/性能权衡。
- en: JSON serialization
  id: totrans-1120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: JSON 序列化
- en: 'Parsing and generating JSON is a very common use case in RESTful services and
    web applications. The Clojure contrib library clojure/data.json ([https://github.com/clojure/data.json](https://github.com/clojure/data.json))
    provides this functionality. However, many people have found out that the Cheshire
    library [https://github.com/dakrone/cheshire](https://github.com/dakrone/cheshire)
    performs much better than the former. The included benchmarks in Cheshire can
    be run using the following command:'
  id: totrans-1121
  prefs: []
  type: TYPE_NORMAL
  zh: 解析和生成 JSON 是 RESTful 服务和 Web 应用程序中非常常见的用例。Clojure contrib 库 clojure/data.json
    ([https://github.com/clojure/data.json](https://github.com/clojure/data.json))
    提供了这项功能。然而，许多人发现 Cheshire 库 [https://github.com/dakrone/cheshire](https://github.com/dakrone/cheshire)
    的性能比前者要好得多。Cheshire 包含的基准测试可以通过以下命令运行：
- en: '[PRE121]'
  id: totrans-1122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: Cheshire internally uses the Jackson Java library [https://github.com/FasterXML/jackson](https://github.com/FasterXML/jackson),
    which is known for its good performance.
  id: totrans-1123
  prefs: []
  type: TYPE_NORMAL
  zh: Cheshire 内部使用 Jackson Java 库 [https://github.com/FasterXML/jackson](https://github.com/FasterXML/jackson)，该库以其良好的性能而闻名。
- en: JDBC
  id: totrans-1124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: JDBC
- en: 'JDBC access is another very common use case among applications using relational
    databases. The Clojure contrib library `clojure/java.jdbc` [https://github.com/clojure/java.jdbc](https://github.com/clojure/java.jdbc)
    provides a Clojure JDBC API. Asphalt [https://github.com/kumarshantanu/asphalt](https://github.com/kumarshantanu/asphalt)
    is an alternative JDBC library where the comparative benchmarks can be run as
    follows:'
  id: totrans-1125
  prefs: []
  type: TYPE_NORMAL
  zh: JDBC 访问是使用关系型数据库的应用程序中另一个非常常见的用例。Clojure contrib 库 `clojure/java.jdbc` [https://github.com/clojure/java.jdbc](https://github.com/clojure/java.jdbc)
    提供了 Clojure JDBC API。Asphalt [https://github.com/kumarshantanu/asphalt](https://github.com/kumarshantanu/asphalt)
    是一个替代的 JDBC 库，其中比较基准测试可以按照以下方式运行：
- en: '[PRE122]'
  id: totrans-1126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: As of this writing, Asphalt outperforms `clojure/java.jdbc` by several micro
    seconds, which may be useful in low-latency applications. However, note that JDBC
    performance is usually dominated by SQL queries/joins, database latency, connection
    pool parameters, and so on. We will discuss more about JDBC in later sections.
  id: totrans-1127
  prefs: []
  type: TYPE_NORMAL
  zh: 截至撰写本文时，Asphalt 的性能优于 `clojure/java.jdbc` 几微秒，这在低延迟应用中可能很有用。然而，请注意，JDBC 性能通常受
    SQL 查询/连接、数据库延迟、连接池参数等因素的影响。我们将在后面的章节中讨论更多关于 JDBC 的内容。
- en: Logging
  id: totrans-1128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 记录
- en: 'Logging is a prevalent activity that almost all non-trivial applications do.
    Logging calls are quite frequent, hence it is important to make sure our logging
    configuration is tuned well for performance. If you are not familiar with logging
    systems (especially on the JVM), you may want to take some time to get familiar
    with those first. We will cover the use of `clojure/tools.logging`, **SLF4J**
    and **LogBack** libraries (as a combination) for logging, and look into how to
    make them perform well:'
  id: totrans-1129
  prefs: []
  type: TYPE_NORMAL
  zh: 记录日志是一种普遍的活动，几乎所有非平凡的应用程序都会进行。日志调用非常频繁，因此确保我们的日志配置针对性能进行了优化非常重要。如果您对日志系统（尤其是在
    JVM 上）不熟悉，您可能需要花些时间先熟悉这些内容。我们将介绍如何使用 `clojure/tools.logging`、**SLF4J** 和 **LogBack**
    库（作为一个组合）进行日志记录，并探讨如何使它们表现良好：
- en: Clojure/tools.logging [https://github.com/clojure/tools.logging](https://github.com/clojure/tools.logging)
  id: totrans-1130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Clojure/tools.logging [https://github.com/clojure/tools.logging](https://github.com/clojure/tools.logging)
- en: 'SLF4J: [http://www.slf4j.org/](http://www.slf4j.org/)'
  id: totrans-1131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'SLF4J: [http://www.slf4j.org/](http://www.slf4j.org/)'
- en: 'LogBack: [http://logback.qos.ch/](http://logback.qos.ch/)'
  id: totrans-1132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'LogBack: [http://logback.qos.ch/](http://logback.qos.ch/)'
- en: Why SLF4J/LogBack?
  id: totrans-1133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么选择 SLF4J/LogBack？
- en: Besides SLF4J/LogBack, there are several logging libraries to choose from in
    the Clojure application, for example Timbre, Log4j and java.util.logging. While
    there is nothing wrong with these libraries, we are often constrained into choosing
    something that covers most other third-party libraries (also including Java libraries)
    in our applications for logging purposes. SLF4J is a Java logger facade that detects
    any available implementation (LogBack, Log4j, and so on) —we choose LogBack simply
    because it performs well and is highly configurable. The library clojure/tools.logging
    provides a Clojure logging API that detects SLF4J, Log4j or java.util.logging
    (in that order) in the classpath and uses whichever implementation is found first.
  id: totrans-1134
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 SLF4J/LogBack 之外，Clojure 应用程序中还有几个日志库可供选择，例如 Timbre、Log4j 和 java.util.logging。虽然这些库没有问题，但我们通常被迫选择一个可以覆盖我们应用程序中大多数其他第三方库（包括
    Java 库）的库用于日志记录。SLF4J 是一个 Java 日志门面，它可以检测任何可用的实现（LogBack、Log4j 等）——我们选择 LogBack
    只是因为它性能良好且高度可配置。库 clojure/tools.logging 提供了一个 Clojure 日志 API，它按顺序在类路径中检测 SLF4J、Log4j
    或 java.util.logging，并使用找到的第一个实现。
- en: The setup
  id: totrans-1135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置
- en: Let's walk through how to set up a logging system for your application using
    LogBack, SLF4J and `clojure/tools.logging` for a project built using Leiningen.
  id: totrans-1136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过使用 LogBack、SLF4J 和 `clojure/tools.logging` 为使用 Leiningen 构建的项目设置日志系统来逐步说明。
- en: Dependencies
  id: totrans-1137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 依赖项
- en: 'Your `project.clj` file should have the LogBack, SLF4J and `clojure/tools.logging`
    dependencies under the `:dependencies` key:'
  id: totrans-1138
  prefs: []
  type: TYPE_NORMAL
  zh: 您的 `project.clj` 文件应该在 `:dependencies` 键下包含 LogBack、SLF4J 和 `clojure/tools.logging`
    依赖项：
- en: '[PRE123]'
  id: totrans-1139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: The previously mentioned versions are current and work as of the time of writing.
    You may want to use updated versions, if available.
  id: totrans-1140
  prefs: []
  type: TYPE_NORMAL
  zh: 之前提到的版本是当前的，并且在写作时是有效的。如果您有更新的版本，您可能想使用它们。
- en: The logback configuration file
  id: totrans-1141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LogBack 配置文件
- en: 'You need to create a `logback.xml` file in the `resources` directory:'
  id: totrans-1142
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要在 `resources` 目录中创建一个 `logback.xml` 文件：
- en: '[PRE124]'
  id: totrans-1143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: The previous `logback.xml` file is simple on purpose (for illustration) and
    has just enough configuration to get you started with logging using LogBack.
  id: totrans-1144
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的 `logback.xml` 文件故意很简单（用于说明），只包含足够的配置来让您开始使用 LogBack 进行日志记录。
- en: Optimization
  id: totrans-1145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优化
- en: The optimization points are highlighted in the `logback.xml` file we saw earlier
    in this section. We set the `immediateFlush` attribute to `false` such that the
    messages are buffered before flushing to the appender. We also wrapped the regular
    file appender with an asynchronous appender and edited the `queueSize` and `discardingThreshold`
    attributes, which gets us much better results than the default.
  id: totrans-1146
  prefs: []
  type: TYPE_NORMAL
  zh: 优化点在我们在本节前面看到的 `logback.xml` 文件中被突出显示。我们将 `immediateFlush` 属性设置为 `false`，这样消息在刷新到追加器之前会被缓冲。我们还用异步追加器包装了常规文件追加器，并编辑了
    `queueSize` 和 `discardingThreshold` 属性，这比默认设置带来了更好的结果。
- en: Unless optimized, logging configurations are usually a common source of suboptimal
    performance in many applications. Usually, the performance problems show up only
    at high load when the log volume is very high. The optimizations discussed previously
    are only a few of the many possible optimizations that one can experiment with.
    The chapters in LogBack documentation, such as **encoders** ([http://logback.qos.ch/manual/encoders.html](http://logback.qos.ch/manual/encoders.html)),
    **appenders** ([http://logback.qos.ch/manual/appenders.html](http://logback.qos.ch/manual/appenders.html))
    and **configuration** ([http://logback.qos.ch/manual/configuration.html](http://logback.qos.ch/manual/configuration.html))
    have useful **information**. There are also tips [http://blog.takipi.com/how-to-instantly-improve-your-java-logging-with-7-logback-tweaks/](http://blog.takipi.com/how-to-instantly-improve-your-java-logging-with-7-logback-tweaks/)
    on the Internet that may provide useful pointers.
  id: totrans-1147
  prefs: []
  type: TYPE_NORMAL
  zh: 除非进行优化，否则日志配置通常是许多应用程序性能不佳的常见原因。通常，性能问题只有在高负载且日志量非常大时才会显现。之前讨论的优化只是众多可能的优化中的一部分。在LogBack文档中，例如**编码器**([http://logback.qos.ch/manual/encoders.html](http://logback.qos.ch/manual/encoders.html))、**追加器**([http://logback.qos.ch/manual/appenders.html](http://logback.qos.ch/manual/appenders.html))和**配置**([http://logback.qos.ch/manual/configuration.html](http://logback.qos.ch/manual/configuration.html))部分提供了有用的**信息**。互联网上也有关于如何通过7个Logback调整来即时提高Java日志性能的技巧[http://blog.takipi.com/how-to-instantly-improve-your-java-logging-with-7-logback-tweaks/](http://blog.takipi.com/how-to-instantly-improve-your-java-logging-with-7-logback-tweaks/)，可能提供有用的指导。
- en: Data sizing
  id: totrans-1148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据大小
- en: The cost of abstractions in terms of the data size plays an important role.
    For example, whether or not a data element can fit into a processor cache line
    depends directly upon its size. On a Linux system, we can find out the cache line
    size and other parameters by inspecting the values in the files under the `/sys/devices/system/cpu/cpu0/cache/`
    directory. Refer to [Chapter 4](ch11.html "Chapter 4. Host Performance"), *Host
    Performance*, where we discussed how to compute the size of primitives, objects,
    and data elements.
  id: totrans-1149
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据大小方面，抽象的成本起着重要作用。例如，一个数据元素是否可以适应处理器缓存行直接取决于其大小。在Linux系统中，我们可以通过检查`/sys/devices/system/cpu/cpu0/cache/`目录下的文件值来找出缓存行大小和其他参数。参考第4章[Chapter
    4](ch11.html "Chapter 4. Host Performance")，*主机性能*，其中我们讨论了如何计算原语、对象和数据元素的大小。
- en: 'Another concern we generally find with data sizing is how much data we hold
    at any time in the heap. As we noted in earlier chapters, GC has direct consequences
    on the application performance. While processing data, often we do not really
    need all the data we hold on to. Consider the example of generating a summary
    report of sold items for a certain period (months) of time. After the subperiod
    (month-wise) summary data is computed, we do not need the item details anymore,
    hence it''s better to remove the unwanted data while we add the summaries. See
    the following example:'
  id: totrans-1150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在数据大小方面通常遇到的一个问题是，在任何时候我们在堆中保留多少数据。正如我们在前面的章节中提到的，垃圾收集（GC）对应用程序性能有直接影响。在处理数据时，我们通常并不真的需要我们持有的所有数据。以生成一定时期（如几个月）内售出商品的总结报告为例。在计算了子时期（按月）的总结数据后，我们不再需要项目详情，因此在我们添加总结的同时删除不需要的数据会更好。请看以下示例：
- en: '[PRE125]'
  id: totrans-1151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: Had we not used `select-keys` in the previous `summarize` function, it would
    have returned a map with extra :`summary` data along with all other existing keys
    in the map. Now, such a thing is often combined with lazy sequences, so for this
    scheme to work it is important not to hold onto the head of the lazy sequence.
    Recall that in [Chapter 2](ch09.html "Chapter 2. Clojure Abstractions"), *Clojure
    Abstractions* we discussed the perils of holding onto the head of a lazy sequence.
  id: totrans-1152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在之前的`summarize`函数中没有使用`select-keys`，它将返回一个包含额外`:summary`数据和地图中所有其他现有键的映射。现在，这种事情通常与懒序列结合使用，因此对于这个方案能够工作，重要的是不要保留懒序列的头部。回想一下，在第2章[Chapter
    2](ch09.html "Chapter 2. Clojure Abstractions")，*Clojure 抽象*中，我们讨论了保留懒序列头部所带来的风险。
- en: Reduced serialization
  id: totrans-1153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 减少序列化
- en: We discussed in earlier chapters that serialization over an I/O channel is a
    common source of latency. The perils of over-serialization cannot be overstated.
    Whether we read or write data from a data source over an I/O channel, all of that
    data needs to be prepared, encoded, serialized, de-serialized, and parsed before
    being worked upon. The less data that is involved, the better it is for every
    step in order to lower the overhead. Where there is no I/O involved (such as in-process
    communication), it generally makes no sense to serialize.
  id: totrans-1154
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们讨论了通过I/O通道进行序列化是延迟的常见来源。过度序列化的危险不容忽视。无论我们是通过I/O通道从数据源读取还是写入数据，所有这些数据都需要准备、编码、序列化、反序列化和解析，然后才能进行处理。涉及的数据越少，对每一步来说越好，以便降低开销。在没有I/O操作的情况下（例如进程内通信），通常没有必要进行序列化。
- en: A common example of over-serialization is when working with SQL databases. Often,
    there are common SQL query functions that fetch all columns of a table or a relation—they
    are called by various functions that implement business logic. Fetching data that
    we do not need is wasteful and detrimental to performance for the same reason
    that we discussed in the previous paragraph. While it may seem more work to write
    one SQL statement and one database-query function for each use case, it pays off
    with better performance. Code that uses NoSQL databases is also subject to this
    anti-pattern—we have to take care to fetch only what we need even though it may
    lead to additional code.
  id: totrans-1155
  prefs: []
  type: TYPE_NORMAL
  zh: 当与SQL数据库一起工作时，过度序列化的一个常见例子是。通常，有一些常见的SQL查询函数可以检索表或关系的所有列——它们被各种实现业务逻辑的函数调用。检索我们不需要的数据是浪费的，并且与上一段中讨论的原因一样，对性能有害。虽然为每个用例编写一个SQL语句和一个数据库查询函数可能看起来工作量更大，但这样做会带来更好的性能。使用NoSQL数据库的代码也容易受到这种反模式的影响——我们必须小心只获取我们需要的，即使这可能导致额外的代码。
- en: There's a pitfall to be aware of when reducing serialization. Often, some information
    needs to be inferred in the absence of serialized data. In such cases, where some
    of the serialization is dropped so that we can infer other information, we must
    compare the cost of inference versus the serialization overhead. The comparison
    may not necessarily be only per operation, but rather on the whole, such that
    we can consider the resources we can allocate in order to achieve capacities for
    various parts of our systems.
  id: totrans-1156
  prefs: []
  type: TYPE_NORMAL
  zh: 在减少序列化时，有一个需要注意的陷阱。通常，在没有序列化数据的情况下，需要推断一些信息。在这种情况下，如果我们删除了一些序列化以便推断其他信息，我们必须比较推断成本与序列化开销。这种比较可能不一定只针对每个操作，而可能是整体上的，这样我们就可以考虑我们可以分配的资源，以便为我们的系统各个部分实现能力。
- en: Chunking to reduce memory pressure
  id: totrans-1157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分块以减少内存压力
- en: What happens when we slurp a text file regardless of its size? The contents
    of the entire file will sit in the JVM heap. If the file is larger than the JVM
    heap capacity, the JVM will terminate, throwing `OutOfMemoryError`. If the file
    is large, but not enough to force the JVM into OOM error, it leaves relatively
    less JVM heap space for other operations to continue in the application. Similar
    situations take place when we carry out any operation disregarding the JVM heap
    capacity. Fortunately, this can be fixed by reading data in chunks and processing
    them before reading more. In [Chapter 3](ch10.html "Chapter 3. Leaning on Java"),
    *Leaning on Java*, we briefly discussed memory mapped buffers, which is another
    complementary solution that you may like to explore.
  id: totrans-1158
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们不管文件大小如何就吞噬一个文本文件时，会发生什么？整个文件的内容将驻留在JVM堆中。如果文件大于JVM堆容量，JVM将终止，抛出`OutOfMemoryError`。如果文件很大，但不足以迫使JVM进入OOM错误，它将为其他操作在应用程序中继续执行留下相对较少的JVM堆空间。当我们执行任何不考虑JVM堆容量的操作时，也会发生类似的情况。幸运的是，可以通过分块读取数据并在读取更多之前进行处理来解决这个问题。在[第3章](ch10.html
    "第3章。依赖Java")《依赖Java》中，我们简要讨论了内存映射缓冲区，这是另一种你可能想探索的补充解决方案。
- en: Sizing for file/network operations
  id: totrans-1159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文件和网络操作的大小调整
- en: Let's take the example of a data ingestion process where a semi-automated job
    uploads large **Comma Separated File (CSV)** files via **File Transfer Protocol
    (FTP)** to a file server, and another automated job (written in Clojure) runs
    periodically to detect the arrival of files via a Network File System (NFS). After
    detecting a new file, the Clojure program processes the file, updates the result
    in a database, and archives the file. The program detects and processes several
    files concurrently. The size of the CSV files is not known in advance, but the
    format is predefined.
  id: totrans-1160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个数据摄取过程为例，其中半自动作业通过**文件传输协议（FTP**）将大型**逗号分隔文件（CSV**）上传到文件服务器，另一个自动作业（用Clojure编写）定期运行以通过网络文件系统（NFS）检测文件的到达。检测到新文件后，Clojure程序处理文件，更新数据库中的结果，并归档文件。程序并发检测和处理多个文件。CSV文件的大小事先未知，但格式是预定义的。
- en: 'As per the previous description, one potential problem is, since there could
    be multiple files being processed concurrently, how do we distribute the JVM heap
    among the concurrent file-processing jobs? Another issue at hand could be that
    the operating system imposes a limit on how many files could be open at a time;
    on Unix-like systems you can use the `ulimit` command to extend the limit. We
    cannot arbitrarily slurp the CSV file contents—we must limit each job to a certain
    amount of memory, and also limit the number of jobs that can run concurrently.
    At the same time, we cannot read a very small number of rows from a file at a
    time because this may impact performance:'
  id: totrans-1161
  prefs: []
  type: TYPE_NORMAL
  zh: 根据之前的描述，一个潜在的问题是，由于可能存在多个并发处理的文件，我们如何分配JVM堆给并发文件处理作业？另一个问题是操作系统对一次可以打开的文件数量有限制；在类Unix系统中，你可以使用`ulimit`命令来扩展限制。我们不能随意地读取CSV文件的内容——我们必须限制每个作业的内存量，并限制可以并发运行的作业数量。同时，我们也不能一次只读取文件中的一小部分行，因为这可能会影响性能：
- en: '[PRE126]'
  id: totrans-1162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: Fortunately, we can specify the buffer size when reading from a file (or even
    from a network stream) so as to tune the memory usage and performance as appropriate.
    In the previous code example, we explicitly set the buffer size of the reader
    to facilitate the same.
  id: totrans-1163
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们在从文件（或甚至从网络流）读取时可以指定缓冲区大小，以便根据需要调整内存使用和性能。在之前的代码示例中，我们明确设置了读取器的缓冲区大小以方便这样做。
- en: Sizing for JDBC query results
  id: totrans-1164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: JDBC查询结果的大小
- en: 'Java''s interface standard for SQL databases, JDBC (which is technically not
    an acronym), supports *fetch size* for fetching query results via JDBC drivers.
    The default fetch size depends on the JDBC driver. Most of the JDBC drivers keep
    a low default value to avoid high memory usage and for internal performance optimization
    reasons. A notable exception to this norm is the MySQL JDBC driver that completely
    fetches and stores all rows in memory by default:'
  id: totrans-1165
  prefs: []
  type: TYPE_NORMAL
  zh: Java的SQL数据库接口标准JDBC（技术上不是一个缩写），支持通过JDBC驱动程序获取查询结果的**获取大小**。默认获取大小取决于JDBC驱动程序。大多数JDBC驱动程序保持一个较低的默认值，以避免高内存使用和内部性能优化原因。一个值得注意的例外是MySQL
    JDBC驱动程序，它默认完全获取并存储所有行在内存中：
- en: '[PRE127]'
  id: totrans-1166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: When using the Clojure contrib library `java.jdbc` ([https://github.com/clojure/java.jdbc](https://github.com/clojure/java.jdbc)
    as of version 0.3.7), the fetch size can be set while preparing a statement as
    shown in the previous example. Note that the fetch size does not guarantee proportional
    latency; however, it can be used safely for memory sizing. We must test any performance-impacting
    latency changes due to fetch size at different loads and use cases for the particular
    database and JDBC driver. Another important factor to note is that the benefit
    of `:fetch-size` can be useful only if the query result set is consumed incrementally
    and lazily—if a function extracts all rows from a result set to create a vector,
    then the benefit of `:fetch-size` is nullified from a memory conservation point
    of view. Besides fetch size, we can also pass the `:max-rows` argument to limit
    the maximum rows to be returned by a query—however, this implies that the extra
    rows will be truncated from the result, and not whether the database will internally
    limit the number of rows to realize.
  id: totrans-1167
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用Clojure contrib库`java.jdbc`（[https://github.com/clojure/java.jdbc](https://github.com/clojure/java.jdbc)
    0.3.7版本）时，可以在准备语句时设置获取大小，如前例所示。请注意，获取大小并不能保证成比例的延迟；然而，它可以安全地用于内存大小调整。我们必须测试由于获取大小在不同负载和使用情况下对特定数据库和JDBC驱动程序的性能影响。另一个需要注意的重要因素是，`:fetch-size`的好处只有在查询结果集是增量且惰性消费的情况下才有用——如果函数从结果集中提取所有行以创建一个向量，那么从内存节省的角度来看，`:fetch-size`的好处就消失了。除了获取大小之外，我们还可以传递`:max-rows`参数来限制查询返回的最大行数——然而，这意味着额外的行将从结果中截断，而不是数据库是否内部限制行数以实现这一点。
- en: Resource pooling
  id: totrans-1168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源池
- en: There are several types of resources on the JVM that are rather expensive to
    initialize. Examples are HTTP connections, execution threads, JDBC connections,
    and so on. The Java API recognizes such resources and has built-in support for
    creating a pool of some of those resources, such that the consumer code borrows
    a resource from a pool when required and at the end of the job simply returns
    it to the pool. Java's thread pools (discussed in [Chapter 5](ch12.html "Chapter 5. Concurrency"),
    *Concurrency*) and JDBC data sources are prominent examples. The idea is to preserve
    the initialized objects for reuse. Even though Java does not support pooling of
    a resource type directly, one can always create a pool abstraction around custom
    expensive resources. Note that the pooling technique is common in I/O activities,
    but can be equally applicable to non-I/O purposes where initialization cost is
    high.
  id: totrans-1169
  prefs: []
  type: TYPE_NORMAL
  zh: 在JVM上，有一些资源类型初始化成本较高。例如，HTTP连接、执行线程、JDBC连接等。Java API识别这些资源，并内置了对创建某些资源池的支持，这样当消费者代码需要时可以从池中借用资源，并在工作结束时简单地将它返回到池中。Java的线程池（在第5章“并发”中讨论）和JDBC数据源是突出的例子。其理念是保留已初始化的对象以供重用。尽管Java不支持直接对资源类型进行池化，但总可以在自定义昂贵资源周围创建一个池抽象。请注意，池化技术在I/O活动中很常见，但也可以同样适用于初始化成本高的非I/O目的。
- en: JDBC resource pooling
  id: totrans-1170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: JDBC资源池
- en: Java supports the obtaining of JDBC connections via the `javax.sql.DataSource`
    interface, which can be pooled. A JDBC connection pool implements this interface.
    Typically, a JDBC connection pool is implemented by third-party libraries or a
    JDBC driver itself. Generally, very few JDBC drivers implement a connection pool,
    so Open Source third-party JDBC resource pooling libraries such as Apache DBCP,
    c3p0, BoneCP, HikariCP, and so on are popular. They also support validation queries
    for eviction of stale connections that might result from network timeouts and
    firewalls, and guard against connection leaks. Apache DBCP and HikariCP are accessible
    from Clojure via their respective Clojure wrapper libraries Clj-DBCP ([https://github.com/kumarshantanu/clj-dbcp](https://github.com/kumarshantanu/clj-dbcp))
    and HikariCP ([https://github.com/tomekw/hikari-cp](https://github.com/tomekw/hikari-cp)),
    and there are Clojure examples describing how to construct C3P0 and BoneCP pools
    ([http://clojure-doc.org/articles/ecosystem/java_jdbc/connection_pooling.html](http://clojure-doc.org/articles/ecosystem/java_jdbc/connection_pooling.html)).
  id: totrans-1171
  prefs: []
  type: TYPE_NORMAL
  zh: Java支持通过`javax.sql.DataSource`接口获取JDBC连接，该接口可以池化。JDBC连接池实现了此接口。通常，JDBC连接池由第三方库或JDBC驱动程序本身实现。一般来说，很少有JDBC驱动程序实现连接池，因此开源的第三方JDBC资源池库，如Apache
    DBCP、c3p0、BoneCP、HikariCP等，非常受欢迎。它们还支持验证查询，用于驱逐可能由网络超时和防火墙引起的陈旧连接，并防止连接泄漏。Apache
    DBCP和HikariCP可以通过各自的Clojure包装库Clj-DBCP ([https://github.com/kumarshantanu/clj-dbcp](https://github.com/kumarshantanu/clj-dbcp))
    和 HikariCP ([https://github.com/tomekw/hikari-cp](https://github.com/tomekw/hikari-cp))
    从Clojure访问，并且有一些Clojure示例描述了如何构建C3P0和BoneCP池 ([http://clojure-doc.org/articles/ecosystem/java_jdbc/connection_pooling.html](http://clojure-doc.org/articles/ecosystem/java_jdbc/connection_pooling.html))。
- en: Connections are not the only JDBC resources that need to be pooled. Every time
    we create a new JDBC prepared statement, depending on the JDBC driver implementation,
    often the entire statement template is sent to the database server in order to
    obtain a reference to the prepared statement. As the database servers are generally
    deployed on separate hardware, there may be network latency involved. Hence, the
    pooling of prepared statements is a very desirable property of JDBC resource pooling
    libraries. Apache DBCP, C3P0, and BoneCP all support statement pooling, and the
    Clj-DBCP wrapper enables the pooling of prepared statements out-of-the-box for
    better performance. HikariCP has the opinion that statement pooling, nowadays,
    is already done internally by JDBC drivers, hence explicit pooling is not required.
    I would strongly advise running your benchmarks with the connection pooling libraries
    to determine whether or not it really works for your JDBC driver and application.
  id: totrans-1172
  prefs: []
  type: TYPE_NORMAL
  zh: 连接不是唯一需要池化的JDBC资源。每次我们创建一个新的JDBC预编译语句时，根据JDBC驱动程序的实现，通常整个语句模板都会发送到数据库服务器以获取预编译语句的引用。由于数据库服务器通常部署在不同的硬件上，可能存在网络延迟。因此，预编译语句的池化是JDBC资源池库的一个非常理想特性。Apache
    DBCP、C3P0和BoneCP都支持语句池化，Clj-DBCP包装器可以开箱即用地实现预编译语句的池化，以获得更好的性能。HikariCP认为，如今，语句池化已经由JDBC驱动程序内部完成，因此不需要显式池化。我强烈建议您使用连接池库进行基准测试，以确定它是否真的适用于您的JDBC驱动程序和应用程序。
- en: I/O batching and throttling
  id: totrans-1173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: I/O批量处理和节流
- en: It is well known that chatty I/O calls generally lead to poor performance. In
    general, the solution is to batch together several messages and send them in one
    payload. In databases and network calls, batching is a common and useful technique
    to improve throughput. On the other hand, large batch sizes may actually harm
    throughput as they tend to incur memory overhead, and components may not be ready
    to handle a large batch at once. Hence, sizing the batches and throttling are
    just as important as batching. I would strongly advise conducting your own tests
    to determine the optimum batch size under representative load.
  id: totrans-1174
  prefs: []
  type: TYPE_NORMAL
  zh: 众所周知，频繁的I/O调用通常会导致性能不佳。一般来说，解决方案是将几条消息批量在一起，然后一次性发送。在数据库和网络调用中，批量处理是一种常见且有效的技术，可以提高吞吐量。另一方面，较大的批量大小实际上可能会损害吞吐量，因为它们往往会增加内存开销，并且组件可能无法一次性处理大量批量。因此，确定批量大小和节流与批量处理一样重要。我强烈建议您进行自己的测试，以确定在代表性负载下的最佳批量大小。
- en: JDBC batch operations
  id: totrans-1175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: JDBC批量操作
- en: 'JDBC has long had batch-update support in its API, which includes the `INSERT`,
    `UPDATE`, `DELETE` statements. The Clojure contrib library `java.jdbc` supports
    JDBC batch operations via its own API, as we can see as follows:'
  id: totrans-1176
  prefs: []
  type: TYPE_NORMAL
  zh: JDBC长期以来在其API中支持批量更新操作，包括`INSERT`、`UPDATE`、`DELETE`语句。Clojure contrib库`java.jdbc`通过其自己的API支持JDBC批量操作，如下所示：
- en: '[PRE128]'
  id: totrans-1177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: Besides batch-update support, we can also batch JDBC queries. One of the common
    techniques is to use the SQL `WHERE` clause to avoid the `N+1` selects issue.
    The `N+1` issue indicates the situation when we execute one query in another child
    table for every row in a rowset from a master table. A similar technique can be
    used to combine several similar queries on the same table into just one, and segregate
    the data in the program afterwards.
  id: totrans-1178
  prefs: []
  type: TYPE_NORMAL
  zh: 除了批量更新支持外，我们还可以批量执行JDBC查询。一种常见的技术是使用SQL `WHERE`子句来避免`N+1`选择问题。`N+1`问题表示当我们对主表的一个行集中的每一行在从表中执行一个查询时的情况。可以采用类似的技术将同一表上的几个相似查询合并为一个，然后在程序中分离数据。
- en: 'Consider the following example that uses clojure.java.jdbc 0.3.7 and the MySQL
    database:'
  id: totrans-1179
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下使用clojure.java.jdbc 0.3.7和MySQL数据库的示例：
- en: '[PRE129]'
  id: totrans-1180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: 'In the previous example there are two tables: `orders` and `items`. The first
    snippet reads all order IDs from the `orders` table, and then iterates through
    them to query corresponding entries in the `items` table in a loop. This is the
    `N+1` selects performance anti-pattern you should keep an eye on. The second snippet
    avoids `N+1` selects by issuing a single SQL query, but may not perform very well
    unless the column `fk_order_id` is indexed.'
  id: totrans-1181
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，有两个表：`orders`和`items`。第一个片段从`orders`表中读取所有订单ID，然后通过循环查询`items`表中的相应条目。这是你应该注意的`N+1`选择性能反模式。第二个片段通过发出单个SQL查询来避免`N+1`选择，但除非列`fk_order_id`被索引，否则可能不会表现得很出色。
- en: Batch support at API level
  id: totrans-1182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在API级别支持批量操作
- en: When designing any service, it is very useful to provide an API for batch operations.
    This builds flexibility in the API such that batch sizing and throttling can be
    controlled in a fine-grained manner. Not surprisingly, it is also an effective
    recipe for building high-performance services. A common overhead we encounter
    when implementing batch operations is the identification of each item in the batch
    and their correlation across requests and responses. The problem becomes more
    prominent when requests are asynchronous.
  id: totrans-1183
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计任何服务时，提供一个用于批量操作的API非常有用。这为API构建了灵活性，使得批量大小和节流可以以细粒度方式控制。不出所料，这也是构建高性能服务的一个有效方法。在实现批量操作时，我们遇到的一个常见开销是识别批量中的每个项以及它们在请求和响应之间的关联。当请求是异步的，这个问题变得更加突出。
- en: The solution to the item identification issue is resolved either by assigning
    a canonical or global ID to each item in the request (batch), or by assigning
    every request (batch) a unique ID and each item in the request an ID that is local
    to the batch.
  id: totrans-1184
  prefs: []
  type: TYPE_NORMAL
  zh: 解决项标识问题的方案是通过为请求（批量）中的每个项分配一个规范ID或全局ID，或者为每个请求（批量）分配一个唯一的ID，并为请求中的每个项分配一个在批量中是局部的ID。
- en: 'The choice of the exact solution usually depends on the implementation details.
    When requests are synchronous, you can do away with identification of each request
    item (see the Facebook API for reference: [http://developers.facebook.com/docs/reference/api/batch/](http://developers.facebook.com/docs/reference/api/batch/))
    where the items in response follow the same order as in the request. However,
    in asynchronous requests, items may have to be tracked via status-check call or
    callbacks. The desired tracking granularity typically guides the appropriate item
    identification strategy.'
  id: totrans-1185
  prefs: []
  type: TYPE_NORMAL
  zh: 确切解决方案的选择通常取决于实现细节。当请求是同步的，你可以省去对每个请求项的标识（参考Facebook API：[http://developers.facebook.com/docs/reference/api/batch/](http://developers.facebook.com/docs/reference/api/batch/)，其中响应中的项遵循与请求相同的顺序）。然而，在异步请求中，可能需要通过状态检查调用或回调来跟踪项。通常，所需的跟踪粒度指导着适当的项标识策略。
- en: For example, if we have a batch API for order processing, every order would
    have a unique Order-ID that can be used in subsequent status-check calls. In another
    example, let's say there is a batch API for creating API keys for **Internet of
    Things** (**IoT**) devices—here, the API keys are not known beforehand, but they
    can be generated and returned in a synchronous response. However, if this has
    to be an asynchronous batch API, the service should respond with a batch request
    ID that can be used later to find the status of the request. In a batch response
    for the request ID, the server can include request item IDs (for example device
    IDs, which may be unique for the client but not unique across all clients) with
    their respective status.
  id: totrans-1186
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们有一个用于订单处理的批量API，每个订单都会有一个唯一的订单ID，可以在后续的状态检查调用中使用。在另一个例子中，假设有一个用于创建物联网（**IoT**）设备API密钥的批量API——在这里，API密钥事先并不知道，但它们可以在同步响应中生成和返回。然而，如果这必须是一个异步批量API，服务应该响应一个批量请求ID，稍后可以使用该ID来查找请求的状态。在请求ID的批量响应中，服务器可以包括请求项目ID（例如设备ID，对于客户端可能是唯一的，但不是所有客户端都是唯一的）及其相应的状态。
- en: Throttling requests to services
  id: totrans-1187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制对服务的请求
- en: As every service can handle only a certain capacity, the rate at which we send
    requests to a service is important. The expectations about the service behavior
    are generally in terms of both throughput and latency. This requires us to send
    requests at a specified rate, as a rate lower than that may lead to under-utilization
    of the service, and a higher rate may overload the service or result in failure,
    thus leading to client-side under-utilization.
  id: totrans-1188
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个服务只能处理一定的容量，因此我们向服务发送请求的速率很重要。对服务行为的期望通常涉及吞吐量和延迟两个方面。这要求我们以指定的速率发送请求，因为低于该速率可能会导致服务利用率不足，而高于该速率可能会使服务过载或导致失败，从而引起客户端利用率不足。
- en: Let's say a third-party service can accept 100 requests per second. However,
    we may not know how robustly the service is implemented. Though sometimes it is
    not exactly specified, sending 100 requests at once (within 20ms, let's say) during
    each second may lead to lower throughput than expected. Evenly distributing the
    requests across the one-second duration, for example sending one request every
    10ms (1000ms / 100 = 10ms), may increase the chance of attaining the optimum throughput.
  id: totrans-1189
  prefs: []
  type: TYPE_NORMAL
  zh: 假设第三方服务每秒可以接受100个请求。然而，我们可能不知道该服务的实现有多稳健。尽管有时并没有明确指定，但在每秒内一次性发送100个请求（例如在20毫秒内），可能会低于预期的吞吐量。例如，将请求均匀地分布在1秒的时间内，例如每10毫秒发送一个请求（1000毫秒
    / 100 = 10毫秒），可能会增加达到最佳吞吐量的机会。
- en: For throttling, **Token bucket** ([https://en.wikipedia.org/wiki/Token_bucket](https://en.wikipedia.org/wiki/Token_bucket))
    and **Leaky bucket** ([https://en.wikipedia.org/wiki/Leaky_bucket](https://en.wikipedia.org/wiki/Leaky_bucket))
    algorithms can be useful. Throttling at a very fine-grained level requires that
    we buffer the items so that we can maintain a uniform rate. Buffering consumes
    memory and often requires ordering; queues (covered in [Chapter 5](ch12.html "Chapter 5. Concurrency"),
    *Concurrency*), pipeline and persistent storage usually serve that purpose well.
    Again, buffering and queuing may be subject to back pressure due to system constraints.
    We will discuss pipelines, back pressure and buffering in a later section in this
    chapter.
  id: totrans-1190
  prefs: []
  type: TYPE_NORMAL
  zh: 对于限制，**令牌桶** ([https://zh.wikipedia.org/wiki/Token_bucket](https://zh.wikipedia.org/wiki/Token_bucket))
    和 **漏桶** ([https://zh.wikipedia.org/wiki/Leaky_bucket](https://zh.wikipedia.org/wiki/Leaky_bucket))
    算法可能很有用。在非常细粒度的级别上进行限制需要我们缓冲项目，以便我们可以保持均匀的速率。缓冲会消耗内存，并且通常需要排序；队列（在第5章中介绍，*并发*），管道和持久存储通常很好地服务于这个目的。再次强调，由于系统限制，缓冲和排队可能会受到背压的影响。我们将在本章后面的部分讨论管道、背压和缓冲。
- en: Precomputing and caching
  id: totrans-1191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预计算和缓存
- en: While processing data, we usually come across instances where few common computation
    steps precede several kinds of subsequent steps. That is to say, some amount of
    computation is common and the remaining is different. For high-latency common
    computations (I/O to access the data and memory/CPU to process it), it makes a
    lot of sense to compute them once and store in digest form, such that the subsequent
    steps can simply use the digest data and proceed from that point onward, thus
    resulting in reduced overall latency. This is also known as staging of semi-computed
    data and is a common technique to optimize processing of non-trivial data.
  id: totrans-1192
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理数据时，我们通常会遇到一些情况，其中一些常见的计算步骤先于几种后续步骤。也就是说，一部分计算是通用的，而剩余的是不同的。对于高延迟的通用计算（如I/O访问数据以及内存/CPU处理它），将它们一次性计算并存储为摘要形式是非常有意义的，这样后续步骤就可以简单地使用摘要数据并从该点继续进行，从而降低整体延迟。这也被称为半计算数据的分阶段处理，是优化非平凡数据处理的一种常见技术。
- en: Clojure has decent support for caching. The built-in `clojure.core/memoize`
    function performs basic caching of computed results with no flexibility in using
    specific caching strategies and pluggable backends. The Clojure contrib library
    `core.memoize` offsets the lack of flexibility in `memoize` by providing several
    configuration options. Interestingly, the features in `core.memoize` are also
    useful as a separate caching library, so the common portion is factored out as
    a Clojure contrib library called `core.cache` on top of which `core.memoize` is
    implemented.
  id: totrans-1193
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure对缓存有良好的支持。内置的`clojure.core/memoize`函数执行基本的计算结果缓存，但在使用特定的缓存策略和可插拔后端方面没有灵活性。Clojure
    contrib库`core.memoize`通过提供几个配置选项来弥补`memoize`缺乏灵活性的不足。有趣的是，`core.memoize`中的功能也作为单独的缓存库很有用，因此公共部分被提取出来作为一个名为`core.cache`的Clojure
    contrib库，`core.memoize`是在其上实现的。
- en: As many applications are deployed on multiple servers for availability, scaling
    and maintenance reasons, they need distributed caching that is fast and space
    efficient. The open source memcached project is a popular in-memory, distributed
    key-value/object store that can act as a caching server for web applications.
    It hashes the keys to identify the server to store the value on, and has no out-of-the-box
    replication or persistence. It is used to cache database query results, computation
    results, and so on. For Clojure, there is a memcached client library called SpyGlass
    ([https://github.com/clojurewerkz/spyglass](https://github.com/clojurewerkz/spyglass)).
    Of course, memcached is not limited to just web applications; it can be used for
    other purposes too.
  id: totrans-1194
  prefs: []
  type: TYPE_NORMAL
  zh: 由于许多应用程序出于可用性、扩展性和维护的原因部署在多个服务器上，它们需要快速且空间高效的分布式缓存。开源的memcached项目是一个流行的内存分布式键值/对象存储，可以作为Web应用的缓存服务器。它通过散列键来识别存储值的服务器，并且没有现成的复制或持久化功能。它用于缓存数据库查询结果、计算结果等。对于Clojure，有一个名为SpyGlass的memcached客户端库（[https://github.com/clojurewerkz/spyglass](https://github.com/clojurewerkz/spyglass)）。当然，memcached不仅限于Web应用；它也可以用于其他目的。
- en: Concurrent pipelines
  id: totrans-1195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发管道
- en: Imagine a situation where we have to carry out jobs at a certain throughput,
    such that each job includes the same sequence of differently sized I/O task (task
    A), a memory-bound task (task B) and, again, an I/O task (task C). A naïve approach
    would be to create a thread pool and run each job off it, but soon we realize
    that this is not optimum because we cannot ascertain the utilization of each I/O
    resource due to unpredictability of the threads being scheduled by the OS. We
    also observe that even though several concurrent jobs have similar I/O tasks,
    we are unable to batch them in our first approach.
  id: totrans-1196
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下这样的情况，我们必须以一定的吞吐量执行工作，每个工作包括相同序列的不同大小的I/O任务（任务A），一个内存受限的任务（任务B），以及再次，一个I/O任务（任务C）。一个简单的方法是创建一个线程池并在其上运行每个工作，但很快我们会意识到这不是最佳方案，因为我们无法确定每个I/O资源的利用率，因为操作系统调度线程的不确定性。我们还观察到，尽管几个并发的工作有相似的I/O任务，但我们无法在我们的第一种方法中批量处理它们。
- en: As the next iteration, we split each job in stages (A, B, C), such that each
    stage corresponds to one task. Since the tasks are well known, we create one thread
    pool (of appropriate size) per stage and execute tasks in them. The result of
    task A is required by task B, and B's result is required by task C—we enable this
    communication via queues. Now, we can tune the thread pool size for each stage,
    batch the I/O tasks, and throttle them for an optimum throughput. This kind of
    an arrangement is a concurrent pipeline. Some readers may find this feebly resembling
    the actor model or **Staged Event Driven Architecture** (**SEDA**) model, which
    are more refined models for this kind of approach. Recall that we discussed several
    kinds of in-process queues in [Chapter 5](ch12.html "Chapter 5. Concurrency"),
    *Concurrency*.
  id: totrans-1197
  prefs: []
  type: TYPE_NORMAL
  zh: 作为下一个迭代，我们将每个作业分成阶段（A、B、C），使得每个阶段对应一个任务。由于任务都是已知的，我们为每个阶段创建一个适当大小的线程池并执行其中的任务。任务
    A 的结果需要由任务 B 使用，B 的结果需要由任务 C 使用——我们通过队列启用这种通信。现在，我们可以调整每个阶段的线程池大小，批量处理 I/O 任务，并调整它们以实现最佳吞吐量。这种安排是一种并发管道。一些读者可能会觉得这种安排与演员模型或**阶段事件驱动架构**（**SEDA**）模型有微弱的相似之处，这些是针对此类方法更精细的模型。回想一下，我们在[第
    5 章](ch12.html "第 5 章。并发")*并发*中讨论了几种进程内队列。
- en: Distributed pipelines
  id: totrans-1198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式管道
- en: With this approach, it is possible to scale out the job execution to multiple
    hosts in a cluster using network queues, thereby offloading memory consumption,
    durability, and delivery to the queue infrastructure. For example, in a given
    scenario there could be several nodes in a cluster, all of them running the same
    code and exchanging messages (requests and intermediate result data) via network
    queues.
  id: totrans-1199
  prefs: []
  type: TYPE_NORMAL
  zh: 采用这种方法，可以使用网络队列将作业执行扩展到集群中的多个主机，从而减轻内存消耗、持久性和交付到队列基础设施的负担。例如，在特定场景中，集群中可能有多个节点，它们都在运行相同的代码，并通过网络队列交换消息（请求和中间结果数据）。
- en: 'The following diagram depicts how a simple invoice-generation system might
    be connected to network queues:'
  id: totrans-1200
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图示展示了简单的发票生成系统如何连接到网络队列：
- en: '![Distributed pipelines](img/3642_08_03.jpg)'
  id: totrans-1201
  prefs: []
  type: TYPE_IMG
  zh: '![分布式管道](img/3642_08_03.jpg)'
- en: RabbitMQ, HornetQ, ActiveMQ, Kestrel and Kafka are some well-known Open Source
    queue systems. Once in a while, the jobs may require distributed state and coordination.
    The Avout ([http://avout.io/](http://avout.io/)) project implements the distributed
    version of Clojure's atom and ref, which can be used for this purpose. Tesser
    ([https://github.com/aphyr/tesser](https://github.com/aphyr/tesser)) is another
    library for local and distributed parallelism using Clojure. The Storm ([http://storm-project.net/](http://storm-project.net/))
    and Onyx ([http://www.onyxplatform.org/](http://www.onyxplatform.org/)) projects
    are distributed, real-time stream processing systems implemented using Clojure.
  id: totrans-1202
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ、HornetQ、ActiveMQ、Kestrel 和 Kafka 是一些知名的开放式队列系统。偶尔，工作可能需要分布式状态和协调。Avout
    ([http://avout.io/](http://avout.io/)) 项目实现了 Clojure 的原子和 ref 的分布式版本，可用于此目的。Tesser
    ([https://github.com/aphyr/tesser](https://github.com/aphyr/tesser)) 是另一个用于本地和分布式并行的
    Clojure 库。Storm ([http://storm-project.net/](http://storm-project.net/)) 和 Onyx
    ([http://www.onyxplatform.org/](http://www.onyxplatform.org/)) 项目是使用 Clojure 实现的分布式、实时流处理系统。
- en: Applying back pressure
  id: totrans-1203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用背压
- en: We discussed back pressure briefly in the last chapter. Without back pressure
    we cannot build a reasonable load-tolerant system with predictable stability and
    performance. In this section, we will see how to apply back pressure in different
    scenarios in an application. At a fundamental level, we should have a threshold
    of a maximum number of concurrent jobs in the system and, based on that threshold,
    we should reject new requests above a certain arrival rate. The rejected messages
    may either be retried by the client or ignored if there is no control over the
    client. When applying back pressure to user-facing services, it may be useful
    to detect system load and deny auxiliary services first in order to conserve capacity
    and degrade gracefully in the face of high load.
  id: totrans-1204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一个章节中简要讨论了背压。没有背压，我们无法构建一个具有可预测稳定性和性能的合理负载容忍系统。在本节中，我们将看到如何在应用程序的不同场景中应用背压。在基本层面上，我们应该有一个系统最大并发作业数的阈值，并根据该阈值，拒绝超过一定到达率的新的请求。被拒绝的消息可能由客户端重试，如果没有对客户端的控制，则可能被忽略。在应用背压到面向用户的服务时，检测系统负载并首先拒绝辅助服务可能是有用的，以保存容量并在高负载面前优雅降级。
- en: Thread pool queues
  id: totrans-1205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线程池队列
- en: 'JVM thread pools are backed by queues, which means that when we submit a job
    into a thread pool that already has the maximum jobs running, the new job lands
    in the queue. The queue is by default an unbounded queue, which is not suitable
    for applying back pressure. So, we have to create the thread pool backed by a
    bounded queue:'
  id: totrans-1206
  prefs: []
  type: TYPE_NORMAL
  zh: JVM线程池由队列支持，这意味着当我们向已经运行最大作业的线程池提交作业时，新作业将进入队列。默认情况下，队列是无界的，这不适合应用背压。因此，我们必须创建由有界队列支持的线程池：
- en: '[PRE130]'
  id: totrans-1207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: Now, on this pool, whenever there is an attempt to add more jobs than the capacity
    of the queue, it will throw an exception. The caller should treat the exception
    as a buffer-full condition and wait until the buffer has idle capacity again by
    periodically pooling the `java.util.concurrent.BlockingQueue.remainingCapacity()`
    method.
  id: totrans-1208
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在这个线程池中，每当尝试添加的作业数量超过队列容量时，它将抛出一个异常。调用者应将异常视为缓冲区满的条件，并通过定期调用`java.util.concurrent.BlockingQueue.remainingCapacity()`方法等待直到缓冲区再次有空闲容量。
- en: Servlet containers such as Tomcat and Jetty
  id: totrans-1209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Servlet容器，如Tomcat和Jetty
- en: In the synchronous **Tomcat** and **Jetty** versions, each HTTP request is given
    a dedicated thread from a common thread pool that a user can configure. The number
    of simultaneous requests being served is limited by the thread pool size. A common
    way to control the arrival rate is to set the thread pool size of the server.
    The **Ring** library uses an embedded jetty server by default in development mode.
    The embedded Jetty adapter (in Ring) can be programmatically configured with a
    thread pool size.
  id: totrans-1210
  prefs: []
  type: TYPE_NORMAL
  zh: 在同步的**Tomcat**和**Jetty**版本中，每个HTTP请求都会从用户可以配置的公共线程池中分配一个专用线程。正在服务的并发请求数量受线程池大小的限制。控制到达率的一种常见方法是为服务器设置线程池大小。在开发模式下，**Ring**库默认使用嵌入的Jetty服务器。在Ring中，可以通过编程方式配置嵌入的Jetty适配器的线程池大小。
- en: In the asynchronous (Async Servlet 3.0) versions of Tomcat and Jetty beside
    the thread pool size, it is also possible to specify the timeout for processing
    each request. However, note that the thread pool size does not limit the number
    of requests in asynchronous versions in the way it does on synchronous versions.
    The request processing is transferred to an ExecutorService (thread pool), which
    may buffer requests until a thread is available. This buffering behavior is tricky
    because this may cause system overload—you can override the default behavior by
    defining your own thread pool instead of using the servlet container's thread
    pool to return a HTTP error at a certain threshold of waiting requests.
  id: totrans-1211
  prefs: []
  type: TYPE_NORMAL
  zh: 在Tomcat和Jetty的异步（Async Servlet 3.0）版本中，除了线程池大小外，还可以指定处理每个请求的超时时间。然而，请注意，线程池大小在异步版本中限制请求数量的方式与同步版本不同。请求处理被转移到ExecutorService（线程池），它可能会缓冲请求，直到有可用的线程。这种缓冲行为很棘手，因为这可能会导致系统过载——你可以通过定义自己的线程池来覆盖默认行为，而不是使用servlet容器的线程池，在等待请求达到一定阈值时返回HTTP错误。
- en: HTTP Kit
  id: totrans-1212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HTTP Kit
- en: '**HTTP Kit** ([http://http-kit.org/](http://http-kit.org/)) is a high-performance
    asynchronous (based on Java NIO implementation) web server for Clojure. It has
    built-in support for applying back pressure to new requests via a specified queue
    length. As of HTTP Kit 2.1.19, see the following snippet:'
  id: totrans-1213
  prefs: []
  type: TYPE_NORMAL
  zh: '**HTTP Kit** ([http://http-kit.org/](http://http-kit.org/)) 是一个高性能的异步（基于Java
    NIO实现）Web服务器，用于Clojure。它内置了对通过指定队列长度应用背压的新请求的支持。截至HTTP Kit 2.1.19，请看以下代码片段：'
- en: '[PRE131]'
  id: totrans-1214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: In the previous snippet, the worker thread pool size is 32 and the max queue
    length is specified as 600\. When not specified, 20480 is the default maximum
    queue length for applying back pressure.
  id: totrans-1215
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，工作线程池的大小是32，最大队列长度指定为600。如果没有指定，默认的最大队列长度为20480，用于应用背压。
- en: Aleph
  id: totrans-1216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Aleph
- en: 'Aleph ([http://aleph.io/](http://aleph.io/)) is another high-performance asynchronous
    web server based on the Java Netty ([http://netty.io/](http://netty.io/)) library,
    which in turn is based on Java NIO. Aleph extends Netty with its own primitives
    compatible with Netty. The worker thread pool in Aleph is specified via an option,
    as we can see in the following snippet as of Aleph 0.4.0:'
  id: totrans-1217
  prefs: []
  type: TYPE_NORMAL
  zh: Aleph ([http://aleph.io/](http://aleph.io/)) 是另一个基于Java Netty ([http://netty.io/](http://netty.io/))库的高性能异步Web服务器，而Java
    Netty又是基于Java NIO的。Aleph通过自己的与Netty兼容的原语扩展了Netty。在Aleph中，工作线程池的大小通过一个选项指定，如下面的代码片段所示（截至Aleph
    0.4.0）：
- en: '[PRE132]'
  id: totrans-1218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: Here, `tpool` refers to a bounded thread pool as discussed in the subsection
    *Thread pool queues*. By default, Aleph uses a dynamic thread pool capped at maximum
    512 threads aimed at 90 percent system utilization via the **Dirigiste** ([https://github.com/ztellman/dirigiste](https://github.com/ztellman/dirigiste))
    library.
  id: totrans-1219
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`tpool` 指的是在子节 *线程池队列* 中讨论的有界线程池。默认情况下，Aleph 使用一个动态线程池，最大限制为 512 个线程，通过
    **Dirigiste** ([https://github.com/ztellman/dirigiste](https://github.com/ztellman/dirigiste))
    库实现，旨在达到 90% 的系统利用率。
- en: Back pressure not only involves enqueuing a limited number of jobs, but slows
    down the processing rate of a job when the peer is slow. Aleph deals with per-request
    back pressure (for example, when streaming response data) by "not accepting data
    until it runs out of memory" — it falls back to blocking instead of dropping data,
    or raising exceptions and closing connections
  id: totrans-1220
  prefs: []
  type: TYPE_NORMAL
  zh: 反压不仅涉及入队有限数量的作业，当对等方速度较慢时，还会减慢作业的处理速度。Aleph 通过“在内存耗尽之前不接受数据”来处理每个请求的反压（例如，在流式传输响应数据时）——它回退到阻塞而不是丢弃数据，或者引发异常并关闭连接。
- en: Performance and queueing theory
  id: totrans-1221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能和排队理论
- en: If we observe the performance benchmark numbers across a number of runs, even
    though the hardware, loads and OS remain the same, the numbers are rarely exactly
    the same. The difference between each run may be as much as -8 percent to 8 percent
    for no apparent reason. This may seem surprising, but the deep-rooted reason is
    that the performances of computer systems are *stochastic* by nature. There are
    many small factors in a computer system that make performance unpredictable at
    any given point of time. At best, the performance variations can be explained
    by a series of probabilities over random variables.
  id: totrans-1222
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们观察多次运行中的性能基准数字，即使硬件、负载和操作系统保持不变，这些数字也很少完全相同。每次运行之间的差异可能高达 -8% 到 8%，原因不明。这可能会让人感到惊讶，但深层次的原因是计算机系统的性能本质上具有随机性。计算机系统中存在许多小因素，使得在任何给定时间点的性能难以预测。在最好的情况下，性能变化可以通过一系列随机变量的概率来解释。
- en: The basic premise is that each subsystem is more or less like a queue where
    requests await their turn to be served. The CPU has an instruction queue with
    unpredictable fetch/decode/branch-predict timings, the memory access again depends
    on cache hit ratio and whether it needs to be dispatched via the interconnect,
    and the I/O subsystem works using interrupts that may again depend on mechanical
    factors of the I/O device. The OS schedules threads that wait while not executing.
    The software built on the top of all this basically waits in various queues to
    get the job done.
  id: totrans-1223
  prefs: []
  type: TYPE_NORMAL
  zh: 基本前提是每个子系统或多或少像是一个队列，其中请求等待它们的轮次来提供服务。CPU 有一个指令队列，其取指/解码/分支预测的时序不可预测，内存访问再次取决于缓存命中率以及是否需要通过互连进行调度，而
    I/O 子系统使用中断来工作，这些中断可能又依赖于 I/O 设备的机械因素。操作系统调度等待而不执行线程。构建在所有这些之上的软件基本上在各个队列中等待以完成任务。
- en: Little's law
  id: totrans-1224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Little's 定律
- en: 'Little''s law states that, over steady state, the following holds true:'
  id: totrans-1225
  prefs: []
  type: TYPE_NORMAL
  zh: Little's 定律指出，在稳态下，以下情况成立：
- en: '![Little''s law](img/3642_08_01.jpg)![Little''s law](img/3642_08_02.jpg)'
  id: totrans-1226
  prefs: []
  type: TYPE_IMG
  zh: '![Little''s 定律](img/3642_08_01.jpg)![Little''s 定律](img/3642_08_02.jpg)'
- en: This is a rather important law that gives us insight into the system capacity
    as it is independent of other factors. For an example, if the average time to
    satisfy a request is 200 ms and the service rate is about 70 per second, then
    the mean number of requests being served is *70 req/second x 0.2 second = 14 requests*.
  id: totrans-1227
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个相当重要的定律，它使我们能够了解系统容量，因为它独立于其他因素。例如，如果满足请求的平均时间是 200 毫秒，而服务率约为每秒 70 次，那么正在服务的请求的平均数量是
    *70 请求/秒 x 0.2 秒 = 14 请求*。
- en: Note that Little's law does not talk about spikes in request arrival rate or
    spikes in latency (due to GC and/or other bottlenecks) or system behavior in response
    to these factors. When the arrival rate spikes at one point, your system must
    have enough resources to handle the number of concurrent tasks required to serve
    the requests. We can infer here that Little's law is helpful to measure and tune
    average system behavior over a duration, but we cannot plan capacity based solely
    on this.
  id: totrans-1228
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，Little's 定律并没有讨论请求到达率或延迟（由于 GC 和/或其他瓶颈）的峰值，或者系统对这些因素的响应行为。当到达率在某一点出现峰值时，您的系统必须拥有足够的资源来处理服务请求所需的并发任务数量。我们可以推断出，Little's
    定律有助于测量和调整平均系统行为，但仅凭这一点无法规划容量。
- en: Performance tuning with respect to Little's law
  id: totrans-1229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于 Little's 定律的性能调整
- en: In order to maintain good throughput, we should strive to maintain an upper
    limit on the total number of tasks in the system. Since there can be many kinds
    of tasks in a system and lot of tasks can happily co-exist in the absence of bottlenecks,
    a better way to say it is to ensure that the system utilization and bottlenecks
    remain in limit.
  id: totrans-1230
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持良好的吞吐量，我们应该努力保持系统中总任务数的上限。由于系统中可能有多种任务，并且许多任务在没有瓶颈的情况下可以愉快地共存，所以更好的说法是确保系统利用率和瓶颈保持在限制之内。
- en: Often, the arrival rate may not be within the control of a system. For such
    scenarios, the only option is to minimize the latency as much as possible and
    deny new requests after a certain threshold of total jobs in the system. You may
    be able to know the right threshold only through performance and load tests. If
    you can control the arrival rate, you can throttle the arrival (based on performance
    and load tests) so as to maintain a steady flow.
  id: totrans-1231
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，系统的到达率可能无法完全控制。对于这种情况，唯一的选择是尽可能减少延迟，并在系统中总作业量达到一定阈值后拒绝新的请求。你可能只能通过性能和负载测试来了解正确的阈值。如果你可以控制到达率，你可以根据性能和负载测试来调节到达速率（即节流），以保持稳定的流量。
- en: Summary
  id: totrans-1232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Designing an application for performance should be based on the use cases and
    patterns of anticipated system load and behavior. Measuring performance is extremely
    important to guide optimization in the process. Fortunately, there are several
    well-known optimization patterns to tap into, such as resource pooling, data sizing,
    pre-fetch and pre-compute, staging, batching, and so on. As it turns out, application
    performance is not only a function of the use cases and patterns—the system as
    a whole is a continuous stochastic turn of events that can be assessed statistically
    and is guided by probability. Clojure is a fun language to do high-performance
    programming. This book prescribes many pointers and practices for performance,
    but there is no mantra that can solve everything. The devil is in the details.
    Know the idioms and patterns, experiment to see what works for your applications,
    and know which rules you can bend for performance.
  id: totrans-1233
  prefs: []
  type: TYPE_NORMAL
  zh: 为了性能而设计应用程序应基于预期的系统负载和使用案例的模式。在优化过程中，衡量性能至关重要。幸运的是，有一些著名的优化模式可以利用，例如资源池、数据大小、预取和预计算、分阶段、批量处理等。实际上，应用程序的性能不仅取决于使用案例和模式——整个系统是一个连续的随机事件，可以通过统计方法进行评估，并由概率指导。Clojure是一种进行高性能编程的有趣语言。这本书提供了许多关于性能的指针和实践，但没有一个咒语可以解决所有问题。魔鬼藏在细节中。了解惯用和模式，通过实验看看哪些适用于你的应用程序，并了解哪些规则你可以为了性能而弯曲。
