- en: Chapter 7. Logging and Monitoring Microservices
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章 微服务的日志记录和监控
- en: One of the biggest challenges due to the very distributed nature of Internet-scale
    microservices deployment is the logging and monitoring of individual microservices.
    It is difficult to trace end-to-end transactions by correlating logs emitted by
    different microservices. As with monolithic applications, there is no single pane
    of glass to monitor microservices.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 由于互联网规模微服务部署的分布式特性，最大的挑战之一是对单个微服务进行日志记录和监控。通过相关不同微服务发出的日志来跟踪端到端事务是困难的。与单片应用程序一样，没有单一的监控窗格来监视微服务。
- en: This chapter will cover the necessity and importance of logging and monitoring
    in microservice deployments. This chapter will further examine the challenges
    and solutions to address logging and monitoring with a number of potential architectures
    and technologies.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍微服务部署中日志记录和监控的必要性和重要性。本章还将进一步探讨解决日志记录和监控的挑战和解决方案，涉及多种潜在的架构和技术。
- en: 'By the end of this chapter, you will learn about:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章结束时，您将了解以下内容：
- en: The different options, tools, and technologies for log management
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志管理的不同选项、工具和技术
- en: The use of Spring Cloud Sleuth in tracing microservices
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在跟踪微服务中使用Spring Cloud Sleuth
- en: The different tools for end-to-end monitoring of microservices
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务端到端监控的不同工具
- en: The use of Spring Cloud Hystrix and Turbine for circuit monitoring
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spring Cloud Hystrix和Turbine进行电路监控
- en: The use of data lakes in enabling business data analysis
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数据湖来实现业务数据分析
- en: Reviewing the microservice capability model
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 审查微服务能力模型
- en: 'In this chapter, we will explore the following microservice capabilities from
    the microservices capability model discussed in [Chapter 3](ch03.html "Chapter 3. Applying
    Microservices Concepts"), *Applying Microservices Concepts*:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将从[第3章](ch03.html "第3章 应用微服务概念")中讨论的微服务能力模型中探讨以下微服务能力：
- en: '**Central Log Management**'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中央日志管理**'
- en: '**Monitoring and Dashboards**'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控和仪表板**'
- en: '**Dependency Management** (part of Monitoring and Dashboards)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**依赖管理**（监控和仪表板的一部分）'
- en: '**Data Lake**'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据湖**'
- en: '![Reviewing the microservice capability model](img/B05447_07_01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![审查微服务能力模型](img/B05447_07_01.jpg)'
- en: Understanding log management challenges
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解日志管理的挑战
- en: Logs are nothing but streams of events coming from a running process. For traditional
    JEE applications, a number of frameworks and libraries are available to log. Java
    Logging (JUL) is an option off the shelf from Java itself. Log4j, Logback, and
    SLF4J are some of the other popular logging frameworks available. These frameworks
    support both UDP as well as TCP protocols for logging. Applications send log entries
    to the console or to the filesystem. File recycling techniques are generally employed
    to avoid logs filling up all the disk space.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 日志只是来自运行进程的事件流。对于传统的JEE应用程序，有许多框架和库可用于日志记录。Java Logging（JUL）是Java本身提供的一个选项。Log4j、Logback和SLF4J是其他一些流行的日志记录框架。这些框架支持UDP和TCP协议进行日志记录。应用程序将日志条目发送到控制台或文件系统。通常采用文件回收技术来避免日志填满所有磁盘空间。
- en: One of the best practices of log handling is to switch off most of the log entries
    in production due to the high cost of disk IOs. Not only do disk IOs slow down
    the application, but they can also severely impact scalability. Writing logs into
    the disk also requires high disk capacity. An out-of-disk-space scenario can bring
    down the application. Logging frameworks provide options to control logging at
    runtime to restrict what is to be printed and what not. Most of these frameworks
    provide fine-grained control over the logging controls. They also provide options
    to change these configurations at runtime.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 日志处理的最佳实践之一是在生产环境中关闭大部分日志条目，因为磁盘IO的成本很高。磁盘IO不仅会减慢应用程序的速度，还会严重影响可伸缩性。将日志写入磁盘还需要高磁盘容量。磁盘空间不足的情况可能导致应用程序崩溃。日志框架提供了在运行时控制日志以限制打印内容的选项。这些框架大多提供对日志控制的细粒度控制。它们还提供在运行时更改这些配置的选项。
- en: On the other hand, logs may contain important information and have high value
    if properly analyzed. Therefore, restricting log entries essentially limits our
    ability to understand the application's behavior.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果适当分析，日志可能包含重要信息并具有很高的价值。因此，限制日志条目基本上限制了我们理解应用程序行为的能力。
- en: When moved from traditional to cloud deployment, applications are no longer
    locked to a particular, predefined machine. Virtual machines and containers are
    not hardwired with an application. The machines used for deployment can change
    from time to time. Moreover, containers such as Docker are ephemeral. This essentially
    means that one cannot rely on the persistent state of the disk. Logs written to
    the disk are lost once the container is stopped and restarted. Therefore, we cannot
    rely on the local machine's disk to write log files.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 从传统部署到云部署后，应用程序不再锁定到特定的预定义机器。虚拟机和容器不是与应用程序硬连接的。用于部署的机器可能会不时更改。此外，诸如Docker之类的容器是短暂的。这基本上意味着不能依赖磁盘的持久状态。一旦容器停止并重新启动，写入磁盘的日志就会丢失。因此，我们不能依赖本地机器的磁盘来写入日志文件。
- en: 'As we discussed in [Chapter 1](ch01.html "Chapter 1. Demystifying Microservices"),
    *Demystifying Microservices*, one of the principles of the Twelve-Factor app is
    to avoid routing or storing log files by the application itself. In the context
    of microservices, they will run on isolated physical or virtual machines, resulting
    in fragmented log files. In this case, it is almost impossible to trace end-to-end
    transactions that span multiple microservices:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第1章](ch01.html "第1章 解密微服务")中讨论的那样，*解密微服务*，十二要素应用程序的原则之一是避免应用程序自身路由或存储日志文件。在微服务的情况下，它们将在隔离的物理或虚拟机上运行，导致日志文件分散。在这种情况下，几乎不可能跟踪跨多个微服务的端到端事务：
- en: '![Understanding log management challenges](img/B05447_07_02.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![了解日志管理的挑战](img/B05447_07_02.jpg)'
- en: As shown in the diagram, each microservice emits logs to a local filesystem.
    In this case, microservice M1 calls M3\. These services write their logs to their
    own local filesystems. This makes it harder to correlate and understand the end-to-end
    transaction flow. Also, as shown in the diagram, there are two instances of M1
    and two instances of M2 running on two different machines. In this case, log aggregation
    at the service level is hard to achieve.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，每个微服务都会向本地文件系统发出日志。在这种情况下，微服务M1调用M3。这些服务将它们的日志写入自己的本地文件系统。这使得难以关联和理解端到端的事务流。此外，如图所示，有两个M1的实例和两个M2的实例在两台不同的机器上运行。在这种情况下，很难实现对服务级别的日志聚合。
- en: A centralized logging solution
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集中式日志解决方案
- en: 'In order to address the challenges stated earlier, traditional logging solutions
    require serious rethinking. The new logging solution, in addition to addressing
    the preceding challenges, is also expected to support the capabilities summarized
    here:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决前面提到的挑战，传统的日志解决方案需要认真重新思考。新的日志解决方案除了解决前面提到的挑战外，还应该支持以下总结的能力：
- en: The ability to collect all log messages and run analytics on top of the log
    messages
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够收集所有日志消息并对其进行分析
- en: The ability to correlate and track transactions end to end
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够关联和跟踪端到端的交易
- en: The ability to keep log information for longer time periods for trending and
    forecasting
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够保留日志信息以进行趋势分析和预测的更长时间段
- en: The ability to eliminate dependency on the local disk system
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消除对本地磁盘系统的依赖能力
- en: The ability to aggregate log information coming from multiple sources such as
    network devices, operating system, microservices, and so on
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够聚合来自多个来源的日志信息，如网络设备、操作系统、微服务等
- en: The solution to these problems is to centrally store and analyze all log messages,
    irrespective of the source of log. The fundamental principle employed in the new
    logging solution is to detach log storage and processing from service execution
    environments. Big data solutions are better suited to storing and processing large
    numbers of log messages more effectively than storing and processing them in microservice
    execution environments.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这些问题的方法是集中存储和分析所有日志消息，而不管日志的来源是什么。新日志解决方案采用的基本原则是将日志存储和处理与服务执行环境分离。与在微服务执行环境中存储和处理大量日志消息相比，大数据解决方案更适合存储和处理大量日志消息。
- en: 'In the centralized logging solution, log messages will be shipped from the
    execution environment to a central big data store. Log analysis and processing
    will be handled using big data solutions:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在集中式日志解决方案中，日志消息将从执行环境发货到中央大数据存储。日志分析和处理将使用大数据解决方案进行处理：
- en: '![A centralized logging solution](img/B05447_07_03.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![集中式日志解决方案](img/B05447_07_03.jpg)'
- en: 'As shown in the preceding logical diagram, there are a number of components
    in the centralized logging solution, as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的逻辑图所示，集中式日志解决方案中有许多组件，如下所示：
- en: '**Log streams**: These are streams of log messages coming out of source systems.
    The source system can be microservices, other applications, or even network devices.
    In typical Java-based systems, these are equivalent to streaming Log4j log messages.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志流：这些是源系统输出的日志消息流。源系统可以是微服务、其他应用程序，甚至是网络设备。在典型的基于Java的系统中，这相当于流式处理Log4j日志消息。
- en: '**Log shippers**: Log shippers are responsible for collecting the log messages
    coming from different sources or endpoints. The log shippers then send these messages
    to another set of endpoints, such as writing to a database, pushing to a dashboard,
    or sending it to stream-processing endpoint for further real-time processing.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志发货人：日志发货人负责收集来自不同来源或端点的日志消息。然后，日志发货人将这些消息发送到另一组端点，例如写入数据库，推送到仪表板，或将其发送到流处理端点进行进一步的实时处理。
- en: '**Log store**: A log store is the place where all log messages are stored for
    real-time analysis, trending, and so on. Typically, a log store is a NoSQL database,
    such as HDFS, capable of handling large data volumes.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志存储：日志存储是存储所有日志消息以进行实时分析、趋势分析等的地方。通常，日志存储是一个能够处理大数据量的NoSQL数据库，例如HDFS。
- en: '**Log stream processor**: The log stream processor is capable of analyzing
    real-time log events for quick decision making. A stream processor takes actions
    such as sending information to a dashboard, sending alerts, and so on. In the
    case of self-healing systems, stream processors can even take actions to correct
    the problems.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志流处理器：日志流处理器能够分析实时日志事件以进行快速决策。流处理器会采取行动，如向仪表板发送信息、发送警报等。在自愈系统的情况下，流处理器甚至可以采取行动来纠正问题。
- en: '**Log dashboard**: A dashboard is a single pane of glass used to display log
    analysis results such as graphs and charts. These dashboards are meant for the
    operational and management staff.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志仪表板：仪表板是用于显示日志分析结果的单一窗格，如图表和图形。这些仪表板是为运营和管理人员准备的。
- en: The benefit of this centralized approach is that there is no local I/O or blocking
    disk writes. It also does not use the local machine's disk space. This architecture
    is fundamentally similar to the lambda architecture for big data processing.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这种集中式方法的好处是没有本地I/O或阻塞磁盘写入。它也不使用本地机器的磁盘空间。这种架构在根本上类似于大数据处理的Lambda架构。
- en: Note
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: To read more on the Lambda architecture, go to [http://lambda-architecture.net](http://lambda-architecture.net).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于Lambda架构的信息，请访问[http://lambda-architecture.net](http://lambda-architecture.net)。
- en: It is important to have in each log message a context, message, and correlation
    ID. The context typically has the timestamp, IP address, user information, process
    details (such as service, class, and functions), log type, classification, and
    so on. The message will be plain and simple free text information. The correlation
    ID is used to establish the link between service calls so that calls spanning
    microservices can be traced.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 每条日志消息中都需要有上下文、消息和关联ID。上下文通常包括时间戳、IP地址、用户信息、进程详细信息（如服务、类和函数）、日志类型、分类等。消息将是简单的自由文本信息。关联ID用于建立服务调用之间的链接，以便跨微服务的调用可以被追踪。
- en: The selection of logging solutions
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志解决方案的选择
- en: There are a number of options available to implement a centralized logging solution.
    These solutions use different approaches, architectures, and technologies. It
    is important to understand the capabilities required and select the right solution
    that meets the needs.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种选择可用于实现集中式日志记录解决方案。这些解决方案使用不同的方法、架构和技术。重要的是要了解所需的功能，并选择满足需求的正确解决方案。
- en: Cloud services
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 云服务
- en: There are a number of cloud logging services available, such as the SaaS solution.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多云日志服务可用，例如SaaS解决方案。
- en: Loggly is one of the most popular cloud-based logging services. Spring Boot
    microservices can use Loggly's Log4j and Logback appenders to directly stream
    log messages into the Loggly service.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Loggly是最受欢迎的基于云的日志服务之一。Spring Boot微服务可以使用Loggly的Log4j和Logback appender直接将日志消息流式传输到Loggly服务中。
- en: If the application or service is deployed in AWS, AWS CloudTrail can be integrated
    with Loggly for log analysis.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果应用程序或服务部署在AWS上，AWS CloudTrail可以与Loggly集成进行日志分析。
- en: Papertrial, Logsene, Sumo Logic, Google Cloud Logging, and Logentries are examples
    of other cloud-based logging solutions.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Papertrial、Logsene、Sumo Logic、Google Cloud Logging和Logentries是其他基于云的日志解决方案的例子。
- en: The cloud logging services take away the overhead of managing complex infrastructures
    and large storage solutions by providing them as simple-to-integrate services.
    However, latency is one of the key factors to be considered when selecting cloud
    logging as a service.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 云日志服务通过提供简单易集成的服务，消除了管理复杂基础设施和大型存储解决方案的开销。然而，在选择云日志服务时，延迟是需要考虑的关键因素之一。
- en: Off-the-shelf solutions
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现成的解决方案
- en: There are many purpose-built tools to provide end-to-end log management capabilities
    that are installable locally in an on-premises data center or in the cloud.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多专门设计的工具，可以在本地数据中心或云中安装，提供端到端的日志管理功能。
- en: Graylog is one of the popular open source log management solutions. Graylog
    uses Elasticsearch for log storage and MongoDB as a metadata store. Graylog also
    uses GELF libraries for Log4j log streaming.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Graylog是流行的开源日志管理解决方案之一。Graylog使用Elasticsearch进行日志存储，使用MongoDB作为元数据存储。Graylog还使用GELF库进行Log4j日志流式传输。
- en: Splunk is one of the popular commercial tools available for log management and
    analysis. Splunk uses the log file shipping approach, compared to log streaming
    used by other solutions to collect logs.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Splunk是一种流行的商业工具，用于日志管理和分析。与其他解决方案使用日志流式传输相比，Splunk使用日志文件传输方法来收集日志。
- en: Best-of-breed integration
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最佳集成
- en: The last approach is to pick and choose best-of-breed components and build a
    custom logging solution.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一种方法是选择最佳的组件并构建自定义的日志解决方案。
- en: Log shippers
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 日志收集器
- en: There are log shippers that can be combined with other tools to build an end-to-end
    log management solution. The capabilities differ between different log shipping
    tools.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些日志收集器可以与其他工具结合使用，构建端到端的日志管理解决方案。不同的日志收集工具之间的功能有所不同。
- en: Logstash is a powerful data pipeline tool that can be used to collect and ship
    log files. Logstash acts as a broker that provides a mechanism to accept streaming
    data from different sources and sync them to different destinations. Log4j and
    Logback appenders can also be used to send log messages directly from Spring Boot
    microservices to Logstash. The other end of Logstash is connected to Elasticsearch,
    HDFS, or any other database.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Logstash是一个强大的数据管道工具，可用于收集和传输日志文件。Logstash充当代理，提供一种接受来自不同来源的流数据并将其同步到不同目的地的机制。Log4j和Logback
    appender也可以用于将日志消息直接从Spring Boot微服务发送到Logstash。Logstash的另一端连接到Elasticsearch、HDFS或任何其他数据库。
- en: Fluentd is another tool that is very similar to Logstash, as is Logspout, but
    the latter is more appropriate in a Docker container-based environment.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd是另一个与Logstash非常相似的工具，Logspout也是如此，但后者更适合基于Docker容器的环境。
- en: Log stream processors
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 日志流处理器
- en: Stream-processing technologies are optionally used to process log streams on
    the fly. For example, if a 404 error is continuously occurring as a response to
    a particular service call, it means there is something wrong with the service.
    Such situations have to be handled as soon as possible. Stream processors are
    pretty handy in such cases as they are capable of reacting to certain streams
    of events that a traditional reactive analysis can't.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 流处理技术可选择用于即时处理日志流。例如，如果404错误持续作为对特定服务调用的响应发生，这意味着服务出现了问题。这种情况必须尽快处理。在这种情况下，流处理器非常有用，因为它们能够对传统的反应式分析无法处理的某些事件流做出反应。
- en: A typical architecture used for stream processing is a combination of Flume
    and Kafka together with either Storm or Spark Streaming. Log4j has Flume appenders,
    which are useful to collect log messages. These messages are pushed into distributed
    Kafka message queues. The stream processors collect data from Kafka and process
    them on the fly before sending it to Elasticsearch and other log stores.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 用于流处理的典型架构是将Flume和Kafka与Storm或Spark Streaming结合在一起。Log4j具有Flume appender，用于收集日志消息。这些消息被推送到分布式Kafka消息队列中。流处理器从Kafka收集数据，并在发送到Elasticsearch和其他日志存储之前即时处理它们。
- en: Spring Cloud Stream, Spring Cloud Stream Modules, and Spring Cloud Data Flow
    can also be used to build the log stream processing.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream、Spring Cloud Stream模块和Spring Cloud Data Flow也可用于构建日志流处理。
- en: Log storage
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 日志存储
- en: Real-time log messages are typically stored in Elasticsearch. Elasticsearch
    allows clients to query based on text-based indexes. Apart from Elasticsearch,
    HDFS is also commonly used to store archived log messages. MongoDB or Cassandra
    is used to store summary data, such as monthly aggregated transaction counts.
    Offline log processing can be done using Hadoop's MapReduce programs.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 实时日志消息通常存储在Elasticsearch中。Elasticsearch允许客户端基于文本索引进行查询。除了Elasticsearch，HDFS也常用于存储归档的日志消息。MongoDB或Cassandra用于存储月度聚合交易计数等摘要数据。离线日志处理可以使用Hadoop的MapReduce程序来完成。
- en: Dashboards
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 仪表板
- en: The last piece required in the central logging solution is a dashboard. The
    most commonly used dashboard for log analysis is Kibana on top of an Elasticsearch
    data store. Graphite and Grafana are also used to display log analysis reports.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 中央日志解决方案所需的最后一部分是仪表板。用于日志分析的最常用的仪表板是基于Elasticsearch数据存储的Kibana。Graphite和Grafana也用于显示日志分析报告。
- en: A custom logging implementation
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自定义日志实现
- en: The tools mentioned before can be leveraged to build a custom end-to-end logging
    solution. The most commonly used architecture for custom log management is a combination
    of Logstash, Elasticsearch, and Kibana, also known as the ELK stack.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 之前提到的工具可以用来构建自定义端到端的日志解决方案。自定义日志管理最常用的架构是Logstash、Elasticsearch和Kibana的组合，也称为ELK堆栈。
- en: Note
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The full source code of this chapter is available under the `Chapter 7` project
    in the code files. Copy `chapter5.configserver`, `chapter5.eurekaserver`, `chapter5.search`,
    `chapter5.search-apigateway`, and `chapter5.website` into a new STS workspace
    and rename them `chapter7.*`.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的完整源代码可在代码文件的“第7章”项目下找到。将“chapter5.configserver”、“chapter5.eurekaserver”、“chapter5.search”、“chapter5.search-apigateway”和“chapter5.website”复制到一个新的STS工作空间中，并将它们重命名为“chapter7.*”。
- en: 'The following diagram shows the log monitoring flow:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了日志监控流程：
- en: '![A custom logging implementation](img/B05447_07_04.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![自定义日志实现](img/B05447_07_04.jpg)'
- en: In this section, a simple implementation of a custom logging solution using
    the ELK stack will be examined.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，将研究使用ELK堆栈的自定义日志解决方案的简单实现。
- en: 'Follow these steps to implement the ELK stack for logging:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤实现用于日志记录的ELK堆栈：
- en: Download and install Elasticsearch, Kibana, and Logstash from [https://www.elastic.co](https://www.elastic.co).
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[https://www.elastic.co](https://www.elastic.co)下载并安装Elasticsearch、Kibana和Logstash。
- en: 'Update the Search microservice (`chapter7.search`). Review and ensure that
    there are some log statements in the Search microservice. The log statements are
    nothing special but simple log statements using `slf4j`, as follows:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新Search微服务（chapter7.search）。审查并确保Search微服务中有一些日志语句。日志语句并不特别，只是使用“slf4j”进行简单的日志记录。
- en: '[PRE0]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Add the `logstash` dependency to integrate `logback` to Logstash in the Search
    service''s `pom.xml` file, as follows:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Search服务的“pom.xml”文件中添加“logstash”依赖项，以将“logback”集成到Logstash中，如下所示：
- en: '[PRE1]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Also, downgrade the `logback` version to be compatible with Spring 1.3.5.RELEASE
    via the following line:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，通过以下行将“logback”版本降级以与Spring 1.3.5.RELEASE兼容：
- en: '[PRE2]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Override the default Logback configuration. This can be done by adding a new
    `logback.xml` file under `src/main/resources`, as follows:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 覆盖默认的Logback配置。可以通过在“src/main/resources”下添加一个新的“logback.xml”文件来完成，如下所示：
- en: '[PRE3]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The preceding configuration overrides the default Logback configuration by adding
    a new TCP socket `appender`, which streams all the log messages to a Logstash
    service, which is listening on port `4560`. It is important to add an encoder,
    as mentioned in the previous configuration.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的配置通过添加一个新的TCP套接字“appender”来覆盖默认的Logback配置，该套接字将所有日志消息流式传输到在端口“4560”上监听的Logstash服务。重要的是要添加一个编码器，如前面的配置中所述。
- en: 'Create a configuration as shown in the following code and store it in a `logstash.conf`
    file. The location of this file is irrelevant as it will be passed as an argument
    when starting Logstash. This configuration will take input from the socket listening
    on `4560` and send the output to Elasticsearch running on `9200`. The `stdout`
    is optional and is set to debug:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建如下代码所示的配置，并将其存储在“logstash.conf”文件中。该文件的位置不重要，因为在启动Logstash时将作为参数传递。此配置将从在“4560”端口上监听的套接字接收输入，并将输出发送到在“9200”端口上运行的Elasticsearch。
    “stdout”是可选的，并设置为debug：
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Run Logstash, Elasticsearch, and Kibana from their respective installation
    folders, as follows:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从各自的安装文件夹运行Logstash、Elasticsearch和Kibana，如下所示：
- en: '[PRE5]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Run the Search microservice. This will invoke the unit test cases and result
    in printing the log statements mentioned before.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行Search微服务。这将调用单元测试用例，并导致打印前面提到的日志语句。
- en: Go to a browser and access Kibana, at `http://localhost:5601`.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到浏览器，访问Kibana，网址为“http://localhost:5601”。
- en: Go to **Settings** | **Configure an index pattern**, as shown here:![A custom
    logging implementation](img/B05447_07_05.jpg)
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到“Settings” | “Configure an index pattern”，如下所示：![自定义日志实现](img/B05447_07_05.jpg)
- en: Go to the **Discover** menu to see the logs. If everything is successful, we
    will see the Kibana screenshot as follows. Note that the log messages are displayed
    in the Kibana screen.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到“Discover”菜单查看日志。如果一切顺利，我们将看到Kibana截图如下。请注意，日志消息显示在Kibana屏幕上。
- en: 'Kibana provides out-of-the-box features to build summary charts and graphs
    using log messages:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Kibana提供了开箱即用的功能，可以使用日志消息构建摘要图表和图形：
- en: '![A custom logging implementation](img/B05447_07_06.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![自定义日志实现](img/B05447_07_06.jpg)'
- en: Distributed tracing with Spring Cloud Sleuth
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Spring Cloud Sleuth进行分布式跟踪
- en: The previous section addressed microservices' distributed and fragmented logging
    issue by centralizing the log data. With the central logging solution, we can
    have all the logs in a central storage. However, it is still almost impossible
    to trace end-to-end transactions. In order to do end-to-end tracking, transactions
    spanning microservices need to have a correlation ID.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节通过集中日志数据解决了微服务的分布式和碎片化日志问题。通过集中的日志解决方案，我们可以将所有日志存储在一个中央位置。然而，要跟踪端到端的事务仍然几乎是不可能的。为了进行端到端跟踪，跨越微服务的事务需要有一个相关ID。
- en: Twitter's Zipkin, Cloudera's HTrace, and Google's Dapper systems are examples
    of distributed tracing systems. Spring Cloud provides a wrapper component on top
    of these using the Spring Cloud Sleuth library.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter的Zipkin、Cloudera的HTrace和Google的Dapper系统是分布式跟踪系统的例子。Spring Cloud使用Spring
    Cloud Sleuth库在这些系统之上提供了一个包装组件。
- en: 'Distributed tracing works with the concepts of **span** and **trace**. The
    span is a unit of work; for example, calling a service is identified by a 64-bit
    span ID. A set of spans form a tree-like structure is called a trace. Using the
    trace ID, the call can be tracked end to end:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式跟踪使用**跨度**和**跟踪**的概念。跨度是一个工作单元；例如，调用一个服务由一个64位的跨度ID标识。一组跨度形成一个类似树状结构的跟踪。使用跟踪ID，可以跟踪端到端的调用：
- en: '![Distributed tracing with Spring Cloud Sleuth](img/B05447_07_07.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![使用Spring Cloud Sleuth进行分布式跟踪](img/B05447_07_07.jpg)'
- en: As shown in the diagram, **Microservice 1** calls **Microservice 2**, and **Microservice
    2** calls **Microservice 3**. In this case, as shown in the diagram, the same
    trace ID is passed across all microservices, which can be used to track transactions
    end to end.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，**微服务1**调用**微服务2**，**微服务2**调用**微服务3**。在这种情况下，如图所示，相同的跟踪ID在所有微服务之间传递，可以用来跟踪端到端的事务。
- en: In order to demonstrate this, we will use the Search API Gateway and Search
    microservices. A new endpoint has to be added in Search API Gateway (`chapter7.search-apigateway`)
    that internally calls the Search service to return data. Without the trace ID,
    it is almost impossible to trace or link calls coming from the Website to Search
    API Gateway to Search microservice. In this case, it only involves two to three
    services, whereas in a complex environment, there could be many interdependent
    services.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示这一点，我们将使用搜索API网关和搜索微服务。必须在搜索API网关（`chapter7.search-apigateway`）中添加一个新的端点，该端点在内部调用搜索服务以返回数据。如果没有跟踪ID，几乎不可能追踪或链接来自网站到搜索API网关到搜索微服务的调用。在这种情况下，只涉及两到三个服务，而在复杂的环境中，可能有许多相互依赖的服务。
- en: 'Follow these steps to create the example using Sleuth:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤使用Sleuth创建示例：
- en: 'Update Search and Search API Gateway. Before this, the Sleuth dependency needs
    to be added to the respective POM files, which can be done via the following code:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新搜索和搜索API网关。在此之前，需要将Sleuth依赖项添加到各自的POM文件中，可以通过以下代码完成：
- en: '[PRE6]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the case of building a new service, select **Sleuth** and **Web**, as shown
    here:![Distributed tracing with Spring Cloud Sleuth](img/B05447_07_08.jpg)
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在构建新服务的情况下，选择**Sleuth**和**Web**，如下所示：![使用Spring Cloud Sleuth进行分布式跟踪](img/B05447_07_08.jpg)
- en: Add the Logstash dependency to the Search service as well as the Logback configuration,
    as in the previous example.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在搜索服务以及Logback配置中添加Logstash依赖，如前面的示例所示。
- en: 'The next step is to add two more properties in the Logback configuration, as
    follows:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来是在Logback配置中添加两个属性：
- en: '[PRE7]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The first property is the name of the application. The names given in this
    are the service IDs: `search-service` and `search-apigateway` in Search and Search
    API Gateway, respectively. The second property is an optional pattern used to
    print the console log messages with a trace ID and span ID. The preceding change
    needs to be applied to both the services.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个属性是应用程序的名称。在这里给出的名称是服务ID：在搜索和搜索API网关中分别是`search-service`和`search-apigateway`。第二个属性是一个可选的模式，用于打印带有跟踪ID和跨度ID的控制台日志消息。前面的改变需要应用到两个服务中。
- en: 'Add the following piece of code to advise Sleuth when to start a new span ID
    in the Spring Boot Application class. In this case, `AlwaysSampler` is used to
    indicate that the span ID has to be created every time a call hits the service.
    This change needs to be applied in both the services:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Spring Boot应用程序类中添加以下代码片段，以指示Sleuth何时开始一个新的跨度ID。在这种情况下，使用`AlwaysSampler`表示每次调用服务时都必须创建跨度ID。这个改变需要应用在两个服务中：
- en: '[PRE8]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Add a new endpoint to Search API Gateway, which will call the Search service
    as follows. This is to demonstrate the propagation of the trace ID across multiple
    microservices. This new method in the gateway returns the operating hub of the
    airport by calling the Search service, as follows:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在搜索API网关中添加一个新的端点，该端点将调用搜索服务，如下所示。这是为了演示跟踪ID在多个微服务之间的传播。网关中的这个新方法通过调用搜索服务返回机场的操作中心，如下所示：
- en: '[PRE9]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Add another endpoint in the Search service, as follows:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在搜索服务中添加另一个端点，如下所示：
- en: '[PRE10]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Once added, run both the services. Hit the gateway's new hub on the gateway
    (`/hubongw`) endpoint using a browser ( `http://localhost:8095/hubongw`).
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加后，运行两个服务。使用浏览器（`http://localhost:8095/hubongw`）在网关的新中心（`/hubongw`）端点上进行访问。
- en: As mentioned earlier, the Search API Gateway service is running on `8095` and
    the Search service is running on `8090`.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，搜索API网关服务运行在`8095`上，搜索服务运行在`8090`上。
- en: 'Look at the console logs to see the trace ID and span IDs printed. The first
    print is from Search API Gateway, and the second one came from the Search service.
    Note that the trace IDs are the same in both the cases, as follows:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看控制台日志以查看打印的跟踪ID和跨度ID。第一个打印来自搜索API网关，第二个来自搜索服务。请注意，在这两种情况下，跟踪ID都是相同的，如下所示：
- en: '[PRE11]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Open the Kibana console and search for the trace ID using this trace ID printed
    in the console. In this case, it is `8a7e278f-7b2b-43e3-a45c-69d3ca66d663`. As
    shown in the following screenshot, with a trace ID, one can trace service calls
    that span multiple services:![Distributed tracing with Spring Cloud Sleuth](img/B05447_07_09.jpg)
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Kibana 控制台并使用控制台中打印的跟踪 ID 搜索跟踪 ID。在这种情况下，它是 `8a7e278f-7b2b-43e3-a45c-69d3ca66d663`。如下面的截图所示，使用跟踪
    ID，可以跟踪跨多个服务的服务调用:![使用Spring Cloud Sleuth进行分布式跟踪](img/B05447_07_09.jpg)
- en: Monitoring microservices
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控微服务
- en: Microservices are truly distributed systems with a fluid deployment topology.
    Without sophisticated monitoring in place, operations teams may run into trouble
    managing large-scale microservices. Traditional monolithic application deployments
    are limited to a number of known services, instances, machines, and so on. This
    is easier to manage compared to the large number of microservices instances potentially
    running across different machines. To add more complication, these services dynamically
    change their topologies. A centralized logging capability only addresses part
    of the issue. It is important for operations teams to understand the runtime deployment
    topology and also the behavior of the systems. This demands more than a centralized
    logging can offer.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务是真正的分布式系统，具有流动的部署拓扑。如果没有复杂的监控系统，运维团队可能会在管理大规模微服务时遇到麻烦。传统的单片应用部署仅限于已知服务、实例、机器等。这比可能在不同机器上运行的大量微服务实例更容易管理。更复杂的是，这些服务会动态改变其拓扑。集中式日志记录能力只解决了问题的一部分。运维团队了解运行时部署拓扑和系统行为至关重要。这需要比集中式日志记录更多的东西。
- en: In general application, monitoring is more a collection of metrics, aggregation,
    and their validation against certain baseline values. If there is a service-level
    breach, then monitoring tools generate alerts and send them to administrators.
    With hundreds and thousands of interconnected microservices, traditional monitoring
    does not really offer true value. The one-size-fits-all approach to monitoring
    or monitoring everything with a single pane of glass is not easy to achieve in
    large-scale microservices.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 一般应用程序监控更多是一组指标、聚合和它们对某些基线值的验证。如果有服务级别的违规，监控工具会生成警报并将其发送给管理员。对于数百甚至数千个相互连接的微服务，传统的监控实际上并没有真正提供真正的价值。在大规模微服务中实现一刀切的监控或使用单一视图监控所有东西并不容易实现。
- en: One of the main objectives of microservice monitoring is to understand the behavior
    of the system from a user experience point of view. This will ensure that the
    end-to-end behavior is consistent and is in line with what is expected by the
    users.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务监控的主要目标之一是从用户体验的角度了解系统的行为。这将确保端到端的行为是一致的，并符合用户的预期。
- en: Monitoring challenges
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控挑战
- en: Similar to the fragmented logging issue, the key challenge in monitoring microservices
    is that there are many moving parts in a microservice ecosystem.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 与分散的日志记录问题类似，监控微服务的关键挑战在于微服务生态系统中有许多移动部分。
- en: 'The typical issues are summarized here:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '典型问题总结如下:'
- en: The statistics and metrics are fragmented across many services, instances, and
    machines.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计数据和指标分散在许多服务、实例和机器中。
- en: Heterogeneous technologies may be used to implement microservices, which makes
    things even more complex. A single monitoring tool may not give all the required
    monitoring options.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能会使用异构技术来实现微服务，这使得事情变得更加复杂。单一的监控工具可能无法提供所有所需的监控选项。
- en: Microservices deployment topologies are dynamic, making it impossible to preconfigure
    servers, instances, and monitoring parameters.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务部署拓扑是动态的，无法预先配置服务器、实例和监控参数。
- en: 'Many of the traditional monitoring tools are good to monitor monolithic applications
    but fall short in monitoring large-scale, distributed, interlinked microservice
    systems. Many of the traditional monitoring systems are agent-based preinstall
    agents on the target machines or application instances. This poses two challenges:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '许多传统监控工具适用于监控单片应用程序，但在监控大规模、分布式、相互关联的微服务系统方面表现不佳。许多传统监控系统是基于代理的，需要在目标机器或应用程序实例上预先安装代理。这带来了两个挑战:'
- en: If the agents require deep integration with the services or operating systems,
    then this will be hard to manage in a dynamic environment
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果代理需要与服务或操作系统进行深度集成，那么在动态环境中将很难管理。
- en: If these tools impose overheads when monitoring or instrumenting the application,
    it may lead to performance issues
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果这些工具在监控或为应用程序进行仪器化时增加了开销，可能会导致性能问题
- en: Many traditional tools need baseline metrics. Such systems work with preset
    rules, such as if the CPU utilization goes above 60% and remains at this level
    for 2 minutes, then an alert should be sent to the administrator. It is extremely
    hard to preconfigure these values in large, Internet-scale deployments.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 许多传统工具需要基线指标。这些系统使用预设规则，例如如果 CPU 利用率超过 60% 并保持在这个水平 2 分钟，那么应该向管理员发送警报。在大规模的互联网部署中，预先配置这些值非常困难。
- en: 'New-generation monitoring applications learn the application''s behavior by
    themselves and set automatic threshold values. This frees up administrators from
    doing this mundane task. Automated baselines are sometimes more accurate than
    human forecasts:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '新一代的监控应用程序通过自学习应用程序的行为并设置自动阈值值。这使管理员免于进行这种乏味的任务。自动基线有时比人类预测更准确:'
- en: '![Monitoring challenges](img/B05447_07_10.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![监控挑战](img/B05447_07_10.jpg)'
- en: 'As shown in the diagram, the key areas of microservices monitoring are:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '如图所示，微服务监控的关键领域包括:'
- en: '**Metrics sources and data collectors**: Metrics collection at the source is
    done either by the server pushing metrics information to a central collector or
    by embedding lightweight agents to collect information. Data collectors collect
    monitoring metrics from different sources, such as network, physical machines,
    containers, software components, applications, and so on. The challenge is to
    collect this data using autodiscovery mechanisms instead of static configurations.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指标来源和数据收集器**：在源头进行指标收集，可以通过服务器将指标信息推送到中央收集器，也可以通过嵌入轻量级代理来收集信息。数据收集器从不同来源收集监控指标，如网络、物理机器、容器、软件组件、应用程序等。挑战在于使用自动发现机制而不是静态配置来收集这些数据。'
- en: This is done by either running agents on the source machines, streaming data
    from the sources, or polling at regular intervals.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过在源机器上运行代理、从源头流式传输数据或定期轮询来完成。
- en: '**Aggregation and correlation of metrics**: Aggregation capability is required
    for aggregating metrics collected from different sources, such as user transaction,
    service, infrastructure, network, and so on. Aggregation can be challenging as
    it requires some level of understanding of the application''s behavior, such as
    service dependencies, service grouping, and so on. In many cases, these are automatically
    formulated based on the metadata provided by the sources.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指标的聚合和关联**：需要聚合能力来聚合从不同来源收集的指标，如用户交易、服务、基础设施、网络等。聚合可能具有挑战性，因为它需要一定程度上理解应用程序的行为，如服务依赖关系、服务分组等。在许多情况下，这些是根据来源提供的元数据自动制定的。'
- en: Generally, this is done by an intermediary that accept the metrics.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这是由一个中间人接受指标来完成的。
- en: '**Processing metrics and actionable insights**: Once data is aggregated, the
    next step is to do the measurement. Measurements are typically done using set
    thresholds. In the new-generation monitoring systems, these thresholds are automatically
    discovered. Monitoring tools then analyze the data and provide actionable insights.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理指标和可操作见解**：一旦数据被聚合，下一步就是进行测量。通常使用设定的阈值进行测量。在新一代监控系统中，这些阈值是自动发现的。监控工具然后分析数据并提供可操作的见解。'
- en: These tools may use big data and stream analytics solutions.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具可能使用大数据和流分析解决方案。
- en: '**Alerting, actions, and dashboards**: As soon as issues are detected, they
    have to be notified to the relevant people or systems. Unlike traditional systems,
    the microservices monitoring systems should be capable of taking actions on a
    real-time basis. Proactive monitoring is essential to achieving self-healing.
    Dashboards are used to display SLAs, KPIs, and so on.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**警报、操作和仪表板**：一旦发现问题，就必须通知相关人员或系统。与传统系统不同，微服务监控系统应能够实时采取行动。积极的监控对于实现自愈至关重要。仪表板用于显示SLA、KPI等。'
- en: Dashboards and alerting tools are capable of handling these requirements.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表板和警报工具能够满足这些要求。
- en: 'Microservice monitoring is typically done with three approaches. A combination
    of these is really required for effective monitoring:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务监控通常有三种方法。实际上，需要结合这些方法才能有效监控：
- en: '**Application performance monitoring** (**APM**): This is more of a traditional
    approach to system metrics collection, processing, alerting, and dashboard rendering.
    These are more from the system''s point of view. Application topology discovery
    and visualization are new capabilities implemented by many of the APM tools. The
    capabilities vary between different APM providers.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用性能监控**（**APM**）：这更多地是一种传统的系统指标收集、处理、警报和仪表板呈现的方法。这些更多来自系统的角度。应用拓扑发现和可视化是许多APM工具实施的新功能。不同APM提供商之间的能力有所不同。'
- en: '**Synthetic monitoring**: This is a technique that is used to monitor the system''s
    behavior using end-to-end transactions with a number of test scenarios in a production
    or production-like environment. Data is collected to validate the system''s behavior
    and potential hotspots. Synthetic monitoring helps understand the system dependencies
    as well.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合成监控**：这是一种技术，用于使用在生产环境或类似生产环境中的多个测试场景进行端到端交易来监控系统的行为。收集数据以验证系统的行为和潜在热点。合成监控还有助于了解系统的依赖关系。'
- en: '**Real user monitoring** (**RUM**) or **user experience monitoring**: This
    is typically a browser-based software that records real user statistics, such
    as response time, availability, and service levels. With microservices, with more
    frequent release cycle and dynamic topology, user experience monitoring is more
    important.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时用户监控**（**RUM**）或**用户体验监控**：这通常是一个基于浏览器的软件，记录真实用户的统计数据，如响应时间、可用性和服务水平。对于微服务，由于发布周期更频繁、拓扑结构更动态，用户体验监控更为重要。'
- en: Monitoring tools
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控工具
- en: There are many tools available to monitor microservices. There are also overlaps
    between many of these tools. The selection of monitoring tools really depends
    upon the ecosystem that needs to be monitored. In most cases, more than one tool
    is required to monitor the overall microservice ecosystem.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多工具可用于监控微服务。许多工具之间也存在重叠。监控工具的选择实际上取决于需要监控的生态系统。在大多数情况下，需要多个工具来监控整个微服务生态系统。
- en: 'The objective of this section is to familiarize ourselves with a number of
    common microservices-friendly monitoring tools:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目标是让我们熟悉一些常见的微服务友好的监控工具：
- en: AppDynamics, Dynatrace, and New Relic are top commercial vendors in the APM
    space, as per Gartner Magic Quadrant 2015\. These tools are microservice friendly
    and support microservice monitoring effectively in a single console. Ruxit, Datadog,
    and Dataloop are other commercial offerings that are purpose-built for distributed
    systems that are essentially microservices friendly. Multiple monitoring tools
    can feed data to Datadog using plugins.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AppDynamics、Dynatrace和New Relic是Gartner Magic Quadrant 2015年APM领域的顶级商业供应商。这些工具对微服务友好，可以在单个控制台中有效支持微服务监控。Ruxit、Datadog和Dataloop是其他专为基本上友好的分布式系统而构建的商业产品。多个监控工具可以使用插件向Datadog提供数据。
- en: Cloud vendors come with their own monitoring tools, but in many cases, these
    monitoring tools alone may not be sufficient for large-scale microservice monitoring.
    For instance, AWS uses CloudWatch and Google Cloud Platform uses Cloud Monitoring
    to collect information from various sources.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云供应商都有自己的监控工具，但在许多情况下，这些监控工具本身可能不足以进行大规模微服务监控。例如，AWS使用CloudWatch，Google Cloud
    Platform使用Cloud Monitoring来收集来自各种来源的信息。
- en: Some of the data collecting libraries, such as Zabbix, statd, collectd, jmxtrans,
    and so on operate at a lower level in collecting runtime statistics, metrics,
    gauges, and counters. Typically, this information is fed into data collectors
    and processors such as Riemann, Datadog, and Librato, or dashboards such as Graphite.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些数据收集库，如Zabbix、statd、collectd、jmxtrans等，以较低的级别收集运行时统计数据、指标、量规和计数。通常，这些信息被馈送到数据收集器和处理器，如Riemann、Datadog和Librato，或者仪表板，如Graphite。
- en: Spring Boot Actuator is one of the good vehicles to collect microservices metrics,
    gauges, and counters, as we discussed in [Chapter 2](ch02.html "Chapter 2. Building
    Microservices with Spring Boot"), *Building Microservices with Spring Boot*. Netflix
    Servo, a metric collector similar to Actuator, and the QBit and Dropwizard metrics
    also fall in the same category of metric collectors. All these metrics collectors
    need an aggregator and dashboard to facilitate full-sized monitoring.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spring Boot Actuator是收集微服务指标、量规和计数的好工具，正如我们在《使用Spring Boot构建微服务》的第2章中讨论的那样。Netflix
    Servo是一种类似于Actuator的度量收集器，QBit和Dropwizard度量也属于同一类度量收集器。所有这些度量收集器都需要聚合器和仪表板来促进全尺寸监控。
- en: Monitoring through logging is popular but a less effective approach in microservices
    monitoring. In this approach, as discussed in the previous section, log messages
    are shipped from various sources, such as microservices, containers, networks,
    and so on to a central location. Then, we can use the logs files to trace transactions,
    identify hotspots, and so on. Loggly, ELK, Splunk, and Trace are candidates in
    this space.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过日志进行监控是一种流行但不太有效的微服务监控方法。在这种方法中，正如在前一节中讨论的那样，日志消息从各种来源（如微服务、容器、网络等）传送到一个中央位置。然后，我们可以使用日志文件来跟踪交易、识别热点等。Loggly、ELK、Splunk和Trace是这一领域的候选者。
- en: Sensu is a popular choice for microservice monitoring from the open source community.
    Weave Scope is another tool, primarily targeting containerized deployments. Spigo
    is one of the purpose-built microservices monitoring systems closely aligned with
    the Netflix stack.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sensu是开源社区中用于微服务监控的流行选择。Weave Scope是另一个工具，主要针对容器化部署。Spigo是一个专为微服务监控系统，与Netflix堆栈紧密结合。
- en: Pingdom, New Relic Synthetics, Runscope, Catchpoint, and so on provide options
    for synthetic transaction monitoring and user experience monitoring on live systems.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pingdom、New Relic Synthetics、Runscope、Catchpoint等提供了在实时系统上进行合成交易监控和用户体验监控的选项。
- en: Circonus is classified more as a DevOps monitoring tool but can also do microservices
    monitoring. Nagios is a popular open source monitoring tool but falls more into
    the traditional monitoring system.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Circonus更多地被归类为DevOps监控工具，但也可以进行微服务监控。Nagios是一种流行的开源监控工具，但更多地属于传统的监控系统。
- en: Prometheus provides a time series database and visualization GUI useful in building
    custom monitoring tools.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prometheus提供了一个时间序列数据库和可视化GUI，可用于构建自定义监控工具。
- en: Monitoring microservice dependencies
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控微服务的依赖关系
- en: 'When there are a large number of microservices with dependencies, it is important
    to have a monitoring tool that can show the dependencies among microservices.
    It is not a scalable approach to statically configure and manage these dependencies.
    There are many tools that are useful in monitoring microservice dependencies,
    as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 当有大量具有依赖关系的微服务时，重要的是要有一个监控工具，可以显示微服务之间的依赖关系。静态配置和管理这些依赖关系并不是一种可扩展的方法。有许多有用的工具可以监控微服务的依赖关系，如下所示：
- en: Mentoring tools such as AppDynamics, Dynatrace, and New Relic can draw dependencies
    among microservices. End-to-end transaction monitoring can also trace transaction
    dependencies. Other monitoring tools, such as Spigo, are also useful for microservices
    dependency management.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像AppDynamics、Dynatrace和New Relic这样的监控工具可以绘制微服务之间的依赖关系。端到端事务监控也可以跟踪事务依赖关系。其他监控工具，如Spigo，也对微服务依赖管理很有用。
- en: CMDB tools such as Device42 or purpose-built tools such as Accordance are useful
    in managing the dependency of microservices. **Veritas Risk Advisor** (**VRA**)
    is also useful for infrastructure discovery.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CMDB工具，如Device42或专门的工具，如Accordance，对于管理微服务的依赖关系非常有用。Veritas Risk Advisor（VRA）也对基础设施发现非常有用。
- en: A custom implementation with a Graph database, such as Neo4j, is also useful.
    In this case, a microservice has to preconfigure its direct and indirect dependencies.
    At the startup of the service, it publishes and cross-checks its dependencies
    with a Neo4j database.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用图形数据库（如Neo4j）进行自定义实现也是有用的。在这种情况下，微服务必须预先配置其直接和间接的依赖关系。在服务启动时，它会发布并与Neo4j数据库交叉检查其依赖关系。
- en: Spring Cloud Hystrix for fault-tolerant microservices
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Spring Cloud Hystrix用于容错微服务
- en: This section will explore Spring Cloud Hystrix as a library for a fault-tolerant
    and latency-tolerant microservice implementation. Hystrix is based on the *fail
    fast* and *rapid recovery* principles. If there is an issue with a service, Hystrix
    helps isolate it. It helps to recover quickly by falling back to another preconfigured
    fallback service. Hystrix is another battle-tested library from Netflix. Hystrix
    is based on the circuit breaker pattern.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将探讨Spring Cloud Hystrix作为一种容错和延迟容忍微服务实现的库。Hystrix基于*失败快速*和*快速恢复*原则。如果服务出现问题，Hystrix有助于隔离它。它通过回退到另一个预先配置的回退服务来快速恢复。Hystrix是Netflix的另一个经过实战检验的库。Hystrix基于断路器模式。
- en: Note
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Read more about the circuit breaker pattern at [https://msdn.microsoft.com/en-us/library/dn589784.aspx](https://msdn.microsoft.com/en-us/library/dn589784.aspx).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在[https://msdn.microsoft.com/en-us/library/dn589784.aspx](https://msdn.microsoft.com/en-us/library/dn589784.aspx)上阅读有关断路器模式的更多信息。
- en: 'In this section, we will build a circuit breaker with Spring Cloud Hystrix.
    Perform the following steps to change the Search API Gateway service to integrate
    it with Hystrix:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用Spring Cloud Hystrix构建一个断路器。执行以下步骤来更改Search API Gateway服务，以将其与Hystrix集成：
- en: Update the Search API Gateway service. Add the Hystrix dependency to the service.
    If developing from scratch, select the following libraries:![Spring Cloud Hystrix
    for fault-tolerant microservices](img/B05447_07_11.jpg)
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新Search API Gateway服务。为服务添加Hystrix依赖项。如果从头开始开发，请选择以下库：![Spring Cloud Hystrix
    for fault-tolerant microservices](img/B05447_07_11.jpg)
- en: In the Spring Boot Application class, add `@EnableCircuitBreaker`. This command
    will tell Spring Cloud Hystrix to enable a circuit breaker for this application.
    It also exposes the `/hystrix.stream` endpoint for metrics collection.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Spring Boot应用程序类中，添加`@EnableCircuitBreaker`。这个命令将告诉Spring Cloud Hystrix为这个应用程序启用断路器。它还公开了用于指标收集的`/hystrix.stream`端点。
- en: 'Add a component class to the Search API Gateway service with a method; in this
    case, this is `getHub` annotated with `@HystrixCommand`. This tells Spring that
    this method is prone to failure. Spring Cloud libraries wrap these methods to
    handle fault tolerance and latency tolerance by enabling circuit breaker. The
    Hystrix command typically follows with a fallback method. In case of failure,
    Hystrix automatically enables the fallback method mentioned and diverts traffic
    to the fallback method. As shown in the following code, in this case, `getHub`
    will fall back to `getDefaultHub`:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为Search API Gateway服务添加一个组件类，其中包含一个方法；在这种情况下，这是用`@HystrixCommand`注释的`getHub`。这告诉Spring这个方法容易失败。Spring
    Cloud库包装这些方法以处理容错和延迟容忍，通过启用断路器。Hystrix命令通常跟随一个回退方法。在失败的情况下，Hystrix会自动启用提到的回退方法，并将流量转移到回退方法。如下面的代码所示，在这种情况下，`getHub`将回退到`getDefaultHub`：
- en: '[PRE12]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The `getHub` method of `SearchAPIGatewayController` calls the `getHub` method
    of `SearchAPIGatewayComponent`, as follows:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`SearchAPIGatewayController`的`getHub`方法调用`SearchAPIGatewayComponent`的`getHub`方法，如下所示：'
- en: '[PRE13]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The last part of this exercise is to build a Hystrix Dashboard. For this, build
    another Spring Boot application. Include Hystrix, Hystrix Dashboard, and Actuator
    when building this application.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个练习的最后一部分是构建一个Hystrix仪表板。为此，构建另一个Spring Boot应用程序。在构建此应用程序时，包括Hystrix、Hystrix仪表板和执行器。
- en: In the Spring Boot Application class, add the `@EnableHystrixDashboard` annotation.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Spring Boot应用程序类中，添加`@EnableHystrixDashboard`注释。
- en: Start the Search service, Search API Gateway, and Hystrix Dashboard applications.
    Point the browser to the Hystrix Dashboard application's URL. In this example,
    the Hystrix Dashboard is started on port `9999`. So, open the URL `http://localhost:9999/hystrix`.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动Search服务、Search API Gateway和Hystrix仪表板应用程序。将浏览器指向Hystrix仪表板应用程序的URL。在本例中，Hystrix仪表板在端口`9999`上启动。因此，打开URL`http://localhost:9999/hystrix`。
- en: A screen similar to the following screenshot will be displayed. In the Hystrix
    Dashboard, enter the URL of the service to be monitored.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将显示类似于以下屏幕截图的屏幕。在Hystrix仪表板中，输入要监视的服务的URL。
- en: 'In this case, Search API Gateway is running on port `8095`. Hence, the `hystrix.stream`
    URL will be `http://localhost:8095/hytrix.stream`, as shown:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，Search API Gateway正在端口`8095`上运行。因此，`hystrix.stream`的URL将是`http://localhost:8095/hytrix.stream`，如下所示：
- en: '![Spring Cloud Hystrix for fault-tolerant microservices](img/B05447_07_12.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![Spring Cloud Hystrix for fault-tolerant microservices](img/B05447_07_12.jpg)'
- en: The Hystrix Dashboard will be displayed as follows:![Spring Cloud Hystrix for
    fault-tolerant microservices](img/B05447_07_13.jpg)
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hystrix仪表板将显示如下：![Spring Cloud Hystrix for fault-tolerant microservices](img/B05447_07_13.jpg)
- en: Tip
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Note that at least one transaction has to be executed to see the display. This
    can be done by hitting `http://localhost:8095/hubongw`.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，至少必须执行一个事务才能看到显示。这可以通过访问`http://localhost:8095/hubongw`来实现。
- en: Create a failure scenario by shutting down the Search service. Note that the
    fallback method will be called when hitting the URL `http://localhost:8095/hubongw`.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过关闭Search服务创建一个故障场景。请注意，当访问URL`http://localhost:8095/hubongw`时，将调用回退方法。
- en: If there are continuous failures, then the circuit status will be changed to
    open. This can be done by hitting the preceding URL a number of times. In the
    open state, the original service will no longer be checked. The Hystrix Dashboard
    will show the status of the circuit as **Open**, as shown in the following screenshot.
    Once a circuit is opened, periodically, the system will check for the original
    service status for recovery. When the original service is back, the circuit breaker
    will fall back to the original service and the status will be set to **Closed**:![Spring
    Cloud Hystrix for fault-tolerant microservices](img/B05447_07_14.jpg)
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果连续失败，则断路器状态将更改为打开。这可以通过多次访问上述URL来实现。在打开状态下，原始服务将不再被检查。Hystrix仪表板将显示断路器的状态为**打开**，如下面的屏幕截图所示。一旦断路器打开，系统将定期检查原始服务的状态以进行恢复。当原始服务恢复时，断路器将恢复到原始服务，并且状态将设置为**关闭**：![Spring
    Cloud Hystrix for fault-tolerant microservices](img/B05447_07_14.jpg)
- en: Note
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: To know the meaning of each of these parameters, visit the Hystrix wiki at [https://github.com/Netflix/Hystrix/wiki/Dashboard](https://github.com/Netflix/Hystrix/wiki/Dashboard).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解每个参数的含义，请访问Hystrix wiki [https://github.com/Netflix/Hystrix/wiki/Dashboard](https://github.com/Netflix/Hystrix/wiki/Dashboard)。
- en: Aggregating Hystrix streams with Turbine
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Turbine聚合Hystrix流
- en: In the previous example, the `/hystrix.stream` endpoint of our microservice
    was given in the Hystrix Dashboard. The Hystrix Dashboard can only monitor one
    microservice at a time. If there are many microservices, then the Hystrix Dashboard
    pointing to the service has to be changed every time we switch the microservices
    to monitor. Looking into one instance at a time is tedious, especially when there
    are many instances of a microservice or multiple microservices.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个示例中，我们的微服务的`/hystrix.stream`端点在Hystrix仪表板中给出。Hystrix仪表板一次只能监视一个微服务。如果有许多微服务，则Hystrix仪表板指向的服务必须每次切换要监视的微服务时更改。一次只查看一个实例是很繁琐的，特别是当有多个微服务实例或多个微服务时。
- en: 'We have to have a mechanism to aggregate data coming from multiple `/hystrix.stream`
    instances and consolidate it into a single dashboard view. Turbine does exactly
    the same thing. Turbine is another server that collects Hystrix streams from multiple
    instances and consolidates them into one `/turbine.stream` instance. Now, the
    Hystrix Dashboard can point to `/turbine.stream` to get the consolidated information:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须有一种机制来聚合来自多个`/hystrix.stream`实例的数据，并将其合并成单个仪表板视图。Turbine正是这样做的。Turbine是另一个服务器，它从多个实例收集Hystrix流，并将它们合并成一个`/turbine.stream`实例。现在，Hystrix仪表板可以指向`/turbine.stream`以获取合并信息：
- en: '![Aggregating Hystrix streams with Turbine](img/B05447_07_15.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![使用Turbine聚合Hystrix流](img/B05447_07_15.jpg)'
- en: Tip
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'Turbine currently works only with different hostnames. Each instance has to
    be run on separate hosts. If you are testing multiple services locally on the
    same host, then update the host file (`/etc/hosts`) to simulate multiple hosts.
    Once done, `bootstrap.properties` has to be configured as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: Turbine目前仅适用于不同的主机名。每个实例必须在单独的主机上运行。如果您在同一主机上本地测试多个服务，则更新主机文件（`/etc/hosts`）以模拟多个主机。完成后，必须配置`bootstrap.properties`如下：
- en: '[PRE14]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This example showcases how to use Turbine to monitor circuit breakers across
    multiple instances and services. We will use the Search service and Search API
    Gateway in this example. Turbine internally uses Eureka to resolve service IDs
    that are configured for monitoring.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例展示了如何使用Turbine监视多个实例和服务之间的断路器。在此示例中，我们将使用搜索服务和搜索API网关。Turbine内部使用Eureka来解析配置用于监视的服务ID。
- en: 'Perform the following steps to build and execute this example:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤来构建和执行此示例：
- en: The Turbine server can be created as just another Spring Boot application using
    Spring Boot Starter. Select Turbine to include the Turbine libraries.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Turbine服务器可以作为另一个Spring Boot应用程序创建，使用Spring Boot Starter选择Turbine以包括Turbine库。
- en: 'Once the application is created, add `@EnableTurbine` to the main Spring Boot
    Application class. In this example, both Turbine and Hystrix Dashboard are configured
    to be run on the same Spring Boot application. This is possible by adding the
    following annotations to the newly created Turbine application:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建应用程序后，在主Spring Boot应用程序类中添加`@EnableTurbine`。在此示例中，Turbine和Hystrix仪表板都配置为在同一个Spring
    Boot应用程序上运行。通过向新创建的Turbine应用程序添加以下注释，可以实现这一点：
- en: '[PRE15]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Add the following configuration to the `.yaml` or property file to point to
    the instances that we are interested in monitoring:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下配置添加到`.yaml`或属性文件中，以指向我们感兴趣监视的实例：
- en: '[PRE16]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The preceding configuration instructs the Turbine server to look up the Eureka
    server to resolve the `search-service` and `search-apigateway` services. The `search-service`
    and `search-apigateways` service IDs are used to register services with Eureka.
    Turbine uses these names to resolve the actual service host and port by checking
    with the Eureka server. It will then use this information to read `/hystrix.stream`
    from each of these instances. Turbine will then read all the individual Hystrix
    streams, aggregate all of them, and expose them under the Turbine server's `/turbine.stream`
    URL.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上述配置指示Turbine服务器查找Eureka服务器以解析`search-service`和`search-apigateway`服务。`search-service`和`search-apigateways`服务ID用于向Eureka注册服务。Turbine使用这些名称通过与Eureka服务器检查来解析实际的服务主机和端口。然后，它将使用此信息从每个实例中读取`/hystrix.stream`。Turbine然后读取所有单独的Hystrix流，将它们聚合，并在Turbine服务器的`/turbine.stream`
    URL下公开它们。
- en: 'The cluster name expression is pointing to the default cluster as there is
    no explicit cluster configuration done in this example. If the clusters are manually
    configured, then the following configuration has to be used:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集群名称表达式指向默认集群，因为在此示例中没有进行显式集群配置。如果手动配置了集群，则必须使用以下配置：
- en: '[PRE17]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Change the Search service''s `SearchComponent` to add another circuit breaker,
    as follows:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将搜索服务的`SearchComponent`更改为添加另一个断路器，如下所示：
- en: '[PRE18]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Also, add `@EnableCircuitBreaker` to the main Application class in the Search
    service.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，在搜索服务的主应用程序类中添加`@EnableCircuitBreaker`。
- en: 'Add the following configuration to `bootstrap.properties` of the Search service.
    This is required because all the services are running on the same host:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下配置添加到搜索服务的`bootstrap.properties`中。这是因为所有服务都在同一主机上运行：
- en: '[PRE19]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Similarly, add the following in `bootstrap.properties` of the Search API Gateway
    service. This is to make sure that both the services use different hostnames:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，在搜索API网关服务的`bootstrap.properties`中添加以下内容。这是为了确保两个服务使用不同的主机名：
- en: '[PRE20]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In this example, we will run two instances of `search-apigateway`: one on `localdomain1:8095`
    and another one on `localdomain2:8096`. We will also run one instance of `search-service`
    on `localdomain1:8090`.'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此示例中，我们将运行两个`search-apigateway`实例：一个在`localdomain1:8095`上，另一个在`localdomain2:8096`上。我们还将在`localdomain1:8090`上运行一个`search-service`实例。
- en: 'Run the microservices with command-line overrides to manage different host
    addresses, as follows:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用命令行覆盖运行微服务以管理不同的主机地址，如下所示：
- en: '[PRE21]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Open Hystrix Dashboard by pointing the browser to `http://localhost:9090/hystrix`.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将浏览器指向`http://localhost:9090/hystrix`来打开Hystrix仪表板。
- en: Instead of giving `/hystrix.stream`, this time, we will point to `/turbine.stream`.
    In this example, the Turbine stream is running on `9090`. Hence, the URL to be
    given in the Hystrix Dashboard is `http://localhost:9090/turbine.stream`.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与其给出`/hystrix.stream`，这次我们将指向`/turbine.stream`。在这个例子中，Turbine流正在`9090`上运行。因此，在Hystrix仪表板中要给出的URL是`http://localhost:9090/turbine.stream`。
- en: 'Fire a few transactions by opening a browser window and hitting the following
    two URLs: `http://localhost:8095/hubongw` and `http://localhost:8096/hubongw`.'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过打开浏览器窗口并访问以下两个URL来触发一些事务：`http://localhost:8095/hubongw`和`http://localhost:8096/hubongw`。
- en: Once this is done, the dashboard page will show the **getHub** service.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，仪表板页面将显示**getHub**服务。
- en: Run `chapter7.website`. Execute the search transaction using the website `http://localhost:8001`.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`chapter7.website`。使用网站`http://localhost:8001`执行搜索事务。
- en: 'After executing the preceding search, the dashboard page will show **search-service**
    as well. This is shown in the following screenshot:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行前面的搜索之后，仪表板页面将显示**search-service**。如下截图所示：
- en: '![Aggregating Hystrix streams with Turbine](img/B05447_07_16.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![使用Turbine聚合Hystrix流](img/B05447_07_16.jpg)'
- en: As we can see in the dashboard, **search-service** is coming from the Search
    microservice, and **getHub** is coming from Search API Gateway. As we have two
    instances of Search API Gateway, **getHub** is coming from two hosts, indicated
    by **Hosts 2**.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在仪表板中所看到的，**search-service**来自Search微服务，而**getHub**来自Search API网关。由于我们有两个Search
    API网关的实例，**getHub**来自两个主机，由**Hosts 2**表示。
- en: Data analysis using data lakes
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用数据湖进行数据分析
- en: Similarly to the scenario of fragmented logs and monitoring, fragmented data
    is another challenge in the microservice architecture. Fragmented data poses challenges
    in data analytics. This data may be used for simple business event monitoring,
    data auditing, or even deriving business intelligence out of the data.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 与分段日志和监控的情景类似，分段数据是微服务架构中的另一个挑战。分段数据在数据分析中带来了挑战。这些数据可能用于简单的业务事件监控、数据审计，甚至从数据中推导出业务智能。
- en: A data lake or data hub is an ideal solution to handling such scenarios. An
    event-sourced architecture pattern is generally used to share the state and state
    changes as events with an external data store. When there is a state change, microservices
    publish the state change as events. Interested parties may subscribe to these
    events and process them based on their requirements. A central event store may
    also subscribe to these events and store them in a big data store for further
    analysis.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 数据湖或数据中心是处理这种情况的理想解决方案。事件源架构模式通常用于将状态和状态变化作为事件与外部数据存储共享。当状态发生变化时，微服务将状态变化作为事件发布。感兴趣的各方可以订阅这些事件，并根据自己的需求进行处理。中央事件存储也可以订阅这些事件，并将它们存储在大数据存储中进行进一步分析。
- en: 'One of the commonly followed architectures for such data handling is shown
    in the following diagram:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 常用的数据处理架构如下图所示：
- en: '![Data analysis using data lakes](img/B05447_07_17.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![使用数据湖进行数据分析](img/B05447_07_17.jpg)'
- en: State change events generated from the microservice—in our case, the **Search**,
    **Booking**, and **Check-In** events—are pushed to a distributed high-performance
    messaging system, such as Kafka. A data ingestion service, such as Flume, can
    subscribe to these events and update them to an HDFS cluster. In some cases, these
    messages will be processed in real time by Spark Streaming. To handle heterogeneous
    sources of events, Flume can also be used between event sources and Kafka.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 从微服务生成的状态变化事件——在我们的案例中是**Search**、**Booking**和**Check-In**事件——被推送到分布式高性能消息系统，如Kafka。数据摄取服务，如Flume，可以订阅这些事件并将其更新到HDFS集群中。在某些情况下，这些消息将通过Spark
    Streaming实时处理。为了处理事件的异构来源，Flume也可以在事件源和Kafka之间使用。
- en: Spring Cloud Streams, Spring Cloud Streams modules, and Spring Data Flow are
    also useful as alternatives for high-velocity data ingestion.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Streams、Spring Cloud Streams模块和Spring Data Flow也是用于高速数据摄取的替代方案。
- en: Summary
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned about the challenges around logging and monitoring
    when dealing with Internet-scale microservices.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解了处理互联网规模微服务时日志记录和监控所面临的挑战。
- en: We explored the various solutions for centralized logging. You also learned
    about how to implement a custom centralized logging using Elasticsearch, Logstash,
    and Kibana (ELK). In order to understand distributed tracing, we upgraded BrownField
    microservices using Spring Cloud Sleuth.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探讨了集中式日志记录的各种解决方案。您还了解了如何使用Elasticsearch、Logstash和Kibana（ELK）实现自定义集中式日志记录。为了理解分布式跟踪，我们使用Spring
    Cloud Sleuth升级了BrownField微服务。
- en: In the second half of this chapter, we went deeper into the capabilities required
    for microservices monitoring solutions and different approaches to monitoring.
    Subsequently, we examined a number of tools available for microservices monitoring.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的后半部分，我们深入探讨了微服务监控解决方案所需的能力以及监控的不同方法。随后，我们检查了一些可用于微服务监控的工具。
- en: The BrownField microservices are further enhanced with Spring Cloud Hystrix
    and Turbine to monitor latencies and failures in inter-service communications.
    The examples also demonstrated how to use the circuit breaker pattern to fall
    back to another service in case of failures.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 通过Spring Cloud Hystrix和Turbine进一步增强了BrownField微服务，以监控服务间通信的延迟和故障。示例还演示了如何使用断路器模式在发生故障时回退到另一个服务。
- en: Finally, we also touched upon the importance of data lakes and how to integrate
    a data lake architecture in a microservice context.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们还提到了数据湖的重要性以及如何在微服务环境中集成数据湖架构。
- en: Microservice management is another important challenge we need to tackle when
    dealing with large-scale microservice deployments. The next chapter will explore
    how containers can help in simplifying microservice management.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务管理是我们在处理大规模微服务部署时需要解决的另一个重要挑战。下一章将探讨容器如何帮助简化微服务管理。
