- en: Benchmarking Your Application
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基准测试您的应用程序
- en: In the previous chapters, we saw how to develop a Java EE application to ensure
    it could scale later using multiple threads, asynchronous handling, pooled resources,
    and so on. We also saw how to get metrics on the performance and resource (CPU,
    memory) usage of your application and optimize the performance thanks to JVM or
    container tuning, as well as more aggressive techniques such as adding caching
    to your application.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们看到了如何开发一个Java EE应用程序，以确保它可以通过多线程、异步处理、资源池化等方式进行扩展。我们还看到了如何获取应用程序的性能和资源（CPU、内存）使用指标，并通过JVM或容器调优以及更激进的技巧，如向应用程序添加缓存来优化性能。
- en: At this point, you should be able to work on the performance. However it does
    not mean you are safe to get surprises when going into production. The main reason
    is that the work we talked about previously is rarely done in an environment close
    enough to the production or final environment the application will be deployed
    to.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你应该能够着手处理性能问题。然而，这并不意味着你在进入生产环境时就不会遇到惊喜。主要原因是我们之前讨论的工作很少在足够接近生产或最终部署环境的环境中完成。
- en: To avoid these surprises, benchmarks can (or should) be organized, but it is
    not as easy as taking all we previously learned and putting it all together. It,
    most of the time, requires more preparation that you should be aware of, if you
    don't want to lose precious time when you go to production.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这些惊喜，可以（或应该）组织基准测试，但这并不像把之前学到的所有东西都放在一起那么简单。大多数时候，这需要更多的准备，如果你不想在生产时浪费宝贵的时间，你应该意识到这一点。
- en: 'In this chapter, you will prepare a benchmark, going through the following
    points:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将准备一个基准测试，包括以下要点：
- en: What a benchmark is
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基准测试是什么
- en: Preparing a benchmark
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备基准测试
- en: Iterating during a benchmark
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基准测试期间的迭代
- en: What to do after a benchmark
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基准测试之后要做什么
- en: Benchmarking – validating your application against your SLA
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基准测试——验证您的应用程序是否符合服务等级协议（SLA）
- en: Benchmarks often enter into play when you have a **Service Level Agreement**
    (**SLA**) to respect. The SLA can be more or less explicit. Typically, you may
    have a very blurry definition of your SLA, such as *the application must provide
    good user experience*, or you may have them in a very precise manner in a contract,
    such as *the application must support Black Friday weekend and 10 million users
    a day, and each user action must be executed in less than one second*. There are
    even some standards to describe the SLA, such as the **Web Service Level Agreement**
    (**WSLA**) to define how to measure and expose your SLA.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试通常在您需要遵守**服务水平协议（SLA**）时发挥作用。SLA可能更明确或更不明确。通常，您可能对SLA有一个非常模糊的定义，例如“应用程序必须提供良好的用户体验”，或者您可能在合同中有非常精确的描述，例如“应用程序必须支持黑色星期五周末和每天1000万用户，并且每个用户操作必须在不到一秒内完成”。甚至还有一些标准来描述SLA，例如**Web服务等级协议（WSLA**）来定义如何衡量和公开您的SLA。
- en: In any case, if an SLA is identified, and even more so if you have some compensation
    in your contract if it is not met, it is very important to go through a benchmark
    phase in your project to make sure you increase your performance when going to
    production.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何情况下，如果确定了SLA，尤其是在合同中未达到SLA时有补偿的情况下，确保在项目中进行基准测试阶段以增加生产时的性能是非常重要的。
- en: The next and last chapter of the book will deal with the continuous evaluation
    of your performance and will help you to do it continuously and avoid this *phase* effect.
    Although, it is still common to have a dedicated phase because of the infrastructure
    constraints required by a benchmark, so we will consider it the case in this chapter.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 书本的下一章和最后一章将处理对性能的持续评估，并帮助你持续进行评估，避免这种*阶段*效应。尽管如此，由于基准测试所需的底层基础设施限制，仍然常见有一个专门阶段，因此在本章中我们将考虑这种情况。
- en: At this point, you know that you need to validate the performance of your application
    and your project manager, or you, has planned a benchmark. But what is this task
    about?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你知道你需要验证应用程序的性能，你的项目经理或你自己已经计划了基准测试。但这项任务具体是什么？
- en: Benchmark, benchmark, benchmark
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基准，基准，基准
- en: Working on performance is not uniform work. We saw that in the previous section;
    there are lots of tools doing that and each of them gives more or less information,
    but also has more or less impact on the actual performance. For instance, instrumenting
    all the code of the application to get metrics on all layers will make the application
    very slow, but the report very rich. On the contrary, instrumenting only some
    parts—such as the outbounds—will not impact the application that much, yet the
    report will give you only a very small set of data. This means that depending
    on the layer you work on, you will not use the same tools to ensure you have the
    right level of information.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在性能方面的工作并不均匀。我们在上一节中看到了这一点；有很多工具在做这件事，每个工具都会提供或多或少的信息，但也会对实际性能产生或多或少的影响。例如，对应用程序的所有代码进行仪器化以获取所有层级的指标会使应用程序非常慢，但报告非常丰富。相反，仅对某些部分——如出站部分——进行仪器化不会对应用程序产生太大影响，但报告只会给你一组非常小的数据。这意味着根据你工作的层级，你将不会使用相同的工具来确保你拥有正确的信息级别。
- en: 'Thus, we can distinguish multiple potential benchmark types:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以区分多种潜在的基准类型：
- en: 'The *algorithm benchmark*: You develop some code sections and want to validate
    the performance is correct or there is no bottleneck.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*算法基准*：你开发了一些代码部分，并希望验证性能是否正确或是否存在瓶颈。'
- en: 'The *layer benchmark*: You develop a layer—the persistence layer, front layer,
    and so on—and want to ensure the performance is correct before adding another
    layer or integrating it with another part of the application.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*层基准*：你开发一个层——持久化层、前端层等——并希望在添加另一个层或将其与其他应用程序部分集成之前确保性能是正确的。'
- en: 'The *sizing* benchmark: You get the figures of the application performance
    to identify the number of machines to use. This is directly related to horizontal
    scaling—this doesn''t work as smoothly as for a vertical one since the performance
    can''t be linear. Note that this is exactly the same kind of logic big data frameworks
    are based on to distribute their work.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*规模基准*：你得到应用程序性能的数字，以确定要使用的机器数量。这与水平扩展直接相关——这不像垂直扩展那样顺畅，因为性能不能是线性的。请注意，这正是大数据框架基于的逻辑，以分发它们的工作。'
- en: 'The *deliverable benchmark*: This is the benchmark validating that the application
    (delivery) and the performance of the final application matches expectations (SLA).'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可交付成果基准*：这是验证应用程序（交付）和最终应用程序的性能是否符合预期的基准（SLA）。'
- en: Of course, we can split the sort of benchmarks you can do into more precise
    categories, but these are the three you will encounter in most projects. Each
    kind of benchmark will use different tools and will have different preparation
    steps and output. However, each of them will validate criteria (one or more) against
    expectations.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们可以将你可以做的基准测试分成更精确的类别，但这些都是你在大多数项目中会遇到的三种。每种基准测试都会使用不同的工具，并且有不同的准备步骤和输出。然而，每一种都会将标准（一个或多个）与预期进行验证。
- en: 'In previous benchmarks, we can clearly split the criteria into two very high-level
    categories, but this split will have a huge impact on the way you drive your benchmark:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的基准测试中，我们可以清楚地将标准分为两个非常高级的类别，但这种划分将对你的基准测试驱动方式产生巨大影响：
- en: The *development benchmark*
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开发基准*'
- en: The *deliverable benchmark*
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可交付成果基准*'
- en: Even if a benchmark is done at delivery, by definition, this split means that
    the two first categories of benchmarks we identified are about validating the
    code is correctly done, and therefore it belongs to developer work in general,
    and it is rarely split from the development itself. The *layer benchmark* is generally
    done during multiple development iterations; it stays a development benchmark
    as it is still about validating an application internally, and not something exposed
    to the end user normally. The *deliverable* benchmark is about ensuring final
    performance is acceptable for the end user (or contract). It is therefore different
    from the previous categories of benchmarks because you need to have a deliverable
    complete enough to be tested.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 即使基准测试是在交付时进行的，根据定义，这种划分意味着我们确定的两个第一类基准测试是关于验证代码是否正确完成，因此它属于一般性的开发者工作，并且很少从开发本身中分离出来。*层基准*通常在多个开发迭代中进行；它仍然是一个开发基准，因为它仍然是在内部验证应用程序，而不是通常暴露给最终用户的东西。*可交付成果基准*是确保最终性能对最终用户（或合同）可接受。因此，它与之前的基准测试类别不同，因为你需要有一个足够完整的可交付成果来进行测试。
- en: In terms of implications, the fact you will work on a deliverable benchmark
    mainly means you will not be able to do it on *your machine*. What you want is
    to validate your performance against a contract, so you will need to validate
    the application on the machine it is installed on.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在影响方面，你将主要在可交付的基准测试上工作的事实意味着你将无法在自己的机器上完成它。你想要的是验证你的性能与合同，因此你需要在应用安装的机器上验证应用。
- en: At this point, it is important not to get confused between a benchmark to validate
    the SLA and a benchmark to size the infrastructure needed for the application.
    Both will almost look the same and are organized the same way. But in the case
    of a *sizing benchmark*, you will define an infrastructure (machine power, memory,
    and so on) and measure performance to then deduce how many machines you need if
    you horizontally scale. However, the *SLA benchmark* already assumes the infrastructure
    is fixed and then you just validate the performance to encounter the SLA. In practice,
    both are often done at the same time which leads to this confusion between both
    types of benchmarks. This mainly comes from the fact that developers or project
    managers have an idea of the infrastructure needed for an application, so the
    starting infrastructure for sizing is close to the target one, and then the game
    is only to validate the performance to match the expectations. Nonetheless, if
    you start a sizing benchmark then you will need another benchmark *phase* to validate
    the SLA, which can be seen as a second benchmark. Never forget the phase you are
    in; otherwise, you may change too many parameters at the same time and lose track
    of the current state of the application (it is crucial to be able to compare benchmark
    iterations, as we will see later).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，重要的是不要混淆用于验证SLA的基准测试和用于确定应用所需基础设施规模的基准测试。两者几乎看起来一样，并且以相同的方式组织。但在*规模基准测试*的情况下，你将定义一个基础设施（机器功率、内存等）并测量性能，然后推断如果你水平扩展需要多少台机器。然而，*SLA基准测试*已经假设基础设施是固定的，然后你只需验证性能以符合SLA。在实践中，两者通常同时进行，这导致了这两种类型基准测试之间的混淆。这主要源于开发者或项目经理对应用所需基础设施有一个想法，因此规模基准的起始基础设施接近目标基础设施，然后游戏就只是验证性能以符合期望。尽管如此，如果你开始规模基准测试，那么你将需要另一个基准测试*阶段*来验证SLA，这可以被视为第二个基准测试。永远不要忘记你所在的阶段；否则，你可能会同时改变太多参数，失去对当前应用状态的跟踪（如我们稍后所见，能够比较基准测试迭代至关重要）。
- en: Preparing your benchmark
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备你的基准测试
- en: Preparing a benchmark is probably the most important task you will have to do.
    In fact, if you miss it, it is guaranteed the benchmark will be a failure and
    useless. Even if tasks are not very complicated in general, they will not be done
    by themselves. So take your time to ensure they are done before the benchmark
    starts.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 准备基准测试可能是你将要做的最重要的任务。实际上，如果你错过了它，基准测试将注定是失败的，毫无用处。即使任务在总体上并不复杂，它们也不会自行完成。所以请花些时间确保在基准测试开始之前完成它们。
- en: Defining the benchmark criteria
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义基准测试标准
- en: A benchmark is always done to make sure we encounter a metric. Therefore, the
    first step of benchmark preparation is to *clearly* define this metric.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试总是进行以确保我们遇到一个指标。因此，基准准备的第一步是*明确*地定义这个指标。
- en: Defining a metric means clearly defining what is measured and how to measure
    it.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 定义一个指标意味着明确地定义要测量的内容和如何测量它。
- en: Defining the metric
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义指标
- en: Defining what is measured means to define the bounds of the measurement. In
    other words, when the metric starts and when the metric ends. This can sound simple
    to do, but don't forget we work in a multi-layer environment and that you can
    miss some layers if your monitoring is not well defined.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 定义要测量的内容意味着定义测量的范围。换句话说，当指标开始和结束时。这听起来可能很简单，但不要忘记我们在一个多层环境中工作，而且如果你的监控定义得不好，你可能会错过一些层。
- en: 'Here are some examples, based on our quote-manager application, where not defining
    the bounds of the metric well enough can lead to incorrectly validating the application:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些例子，基于我们的quote-manager应用，如果没有很好地定义指标的界限，可能会导致错误地验证应用：
- en: 'Measuring an endpoint execution duration with a CDI interceptor: You miss the
    JAX-RS layer'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用CDI拦截器测量端点执行持续时间：你错过了JAX-RS层
- en: 'Measuring an endpoint execution duration with a JAX-RS filter: You miss the
    servlet layer'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用JAX-RS过滤器测量端点执行持续时间：你错过了servlet层
- en: 'Measuring an endpoint execution duration with a servlet filter if the metric
    is the processing time of the request: You miss the container processing'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果度量标准是请求的处理时间，则使用servlet过滤器来测量端点执行持续时间：你会错过容器处理
- en: These examples are all server-side mistakes but illustrate the fact that being
    explicit about the metrics is not as trivial as it may seem, since the three mentioned
    solutions are easy and also very tempting ones.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这些例子都是服务器端错误，但说明了明确度量标准并不像看起来那么简单，因为提到的三种解决方案既简单又很有诱惑力。
- en: 'There is a case that is worse: the client side. When the metric is a client-side
    metric—often the case for an SLA, since in that case we generally don''t care
    about what the server does if it is fast for the clients—then the measurement
    definition is very important. The client case implies some infrastructure you
    don''t always control. Thus, ensuring the definition is well done will avoid ambiguities
    and potential disagreements with customers or reviewers of the benchmark. Here
    are some examples of different interpretations of the same metric:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种情况更糟：客户端。当度量标准是客户端度量标准——对于SLA来说通常是这种情况，因为在这种情况下，如果服务器对客户端来说运行得快，我们通常不关心服务器做了什么——那么度量定义就非常重要。客户端情况意味着一些你并不总是能控制的底层基础设施。因此，确保定义做得好将避免歧义和与基准测试的客户或审查者的潜在分歧。以下是一些对同一度量标准的不同解释的例子：
- en: The client execution time is measured from a client connected to the application
    server
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端执行时间是从一个连接到应用服务器的客户端测量的
- en: The client execution time is measured from a client connected to the load balancer
    in front of the application servers
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端执行时间是从一个连接到应用服务器前端的负载均衡器的客户端测量的
- en: The client execution time is measured from a client connected to an API gateway
    that redirects the call to a load balancer
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端执行时间是从一个连接到API网关的客户端测量的，该网关将调用重定向到负载均衡器
- en: The client execution time is measured from a client connected to a proxy in
    another **Wide Area Network** (**WAN**) that routes the request to an API gateway
    and so on
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端执行时间是从一个连接到另一个**广域网**（**WAN**）中的代理的客户端测量的，该代理将请求路由到API网关等等
- en: Each of these lines adds an infrastructure layer on top of the previous one,
    and thus, adds some latency for the client. They all measure the *client execution
    time*. This is why precisely defining the infrastructure, and moreover how the
    metric is designed, is very important, before starting to benchmark the application.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些每一行都在前一行的基础上增加了一个基础设施层，因此，为客户端增加了一些延迟。它们都测量*客户端执行时间*。这就是为什么在开始基准测试应用程序之前，精确地定义基础设施，以及更重要的是度量标准是如何设计的，非常重要。
- en: Defining acceptance criteria
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义接受标准
- en: Once you have a metric clearly defined, you need to define the criteria based
    on that metric that will make the benchmark validated or rejected—is your application
    fast enough to rephrase it at a high level?
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你明确了一个度量标准，你需要根据这个度量标准定义标准，这将使基准测试得到验证或被拒绝——你的应用程序是否足够快，以至于可以将其重新表述为高层次？
- en: Generally, it is a number that can be expressed as a time unit or percentage,
    depending on the metric. If the measure is lower (or higher) than this number
    then the benchmark is rejected.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这是一个可以根据度量标准表示为时间单位或百分比的数字。如果这个度量值低于（或高于）这个数字，那么基准值将被拒绝。
- en: 'Most of the time, the metric is not self-sufficient and needs some additional
    parameters to be able to define the acceptance criteria in a measurable way. Here
    are some common examples:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，度量标准不是自足的，需要一些额外的参数才能以可测量的方式定义接受标准。以下是一些常见的例子：
- en: The *client execution duration* must be under 1 second for *64 concurrent users*
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于*64个并发用户*，*客户端执行时间*必须低于1秒
- en: The *client latency* must be under 250 milliseconds when *128 messages per second* are
    received
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当每秒接收*128条消息*时，*客户端延迟*必须低于250毫秒
- en: The *insertion rate of the data into the database* must be higher than 1,500
    records per second for *two connections*
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据插入数据库的插入率*必须高于每秒*1,500条记录*，对于*两个连接*'
- en: In these examples, the bold expression is the metric we build our criteria on,
    and the italic one is another potential metric fixed in the context of the defined
    criteria (the underlined number).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些例子中，粗体表达的是我们建立标准的度量标准，而斜体的是在定义的标准上下文中固定的另一个潜在度量标准（下划线数字）。
- en: Of course, it is possible to use more than two metrics in the same criteria
    and even to make them all vary at the same time. However, this leads to complicated
    acceptance criteria, and it is generally always possible to rephrase them based
    on acceptance criteria that are using constants. Don't hesitate to rebuild a criteria
    database from the ones you get in inputs, to ensure they are easy to validate
    and measure. A very simple example of this sort of rephrasing can be represented
    by changing *the client execution duration must be under 1 second for a number
    of concurrent users between 1 and 64* into *the client execution duration must
    be under 1 second for 64 concurrent users*. This change is not strictly equivalent
    and you will need to validate the first statement, but the second phrase is easier
    to work with, in particular, if you need some tuning. It is worth using this simpler
    one to start work and to get a rough estimate of your metrics and then, once it
    passes, just validate the original one.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，可以在同一标准中使用超过两个指标，甚至让它们同时变化。然而，这会导致复杂的接受标准，并且通常总是可以根据使用常数的接受标准来重新表述它们。不要犹豫，从输入中重建一个标准数据库，以确保它们易于验证和测量。这种重新表述的一个非常简单的例子是将
    *客户端执行时间必须低于1秒，对于1到64个并发用户* 改为 *客户端执行时间必须低于1秒，对于64个并发用户*。这种改变并不严格等价，你需要验证第一个陈述，但第二个短语更容易处理，特别是如果你需要一些调整。使用这个更简单的版本开始工作，并对你的一些指标进行粗略估计，然后一旦通过，只需验证原始的即可。
- en: 'One criteria, which was not mentioned before, is the *time*. Generally, all
    criteria are defined for an *infinite* duration. This means you will need to make
    sure that once they are reached they are respected for *long enough* to assume
    it will not be degraded after some time. This is something to take into account
    when you prepare your tooling, as lots of factors can degrade the performance:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一个之前没有提到的标准是 *时间*。通常，所有标准都是为 *无限* 持续时间定义的。这意味着你需要确保一旦达到它们，它们将被尊重足够长的时间，以假设在一段时间后不会退化。这是在准备你的工具时需要考虑的事情，因为许多因素可能会降低性能：
- en: A database that slows down after a certain number of records are inserted
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在插入一定数量的记录后变慢的数据库
- en: A cache that is wrongly sized and starts being too big for its configuration
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个配置不当且开始变得比其配置太大的缓存
- en: A badly tuned memory, and so on
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个调优不当的内存，等等
- en: All these factors will not always prevent you from reaching your performance
    in a *short* period of time, but they will likely degrade the performance after
    some duration.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些因素并不总是能阻止你在 *短时间内* 达到你的性能，但它们很可能会在一段时间后降低性能。
- en: 'The idea here will be to ensure you can associate the acceptance criteria with
    some environment metrics, such as the memory behavior. For instance, you can associate
    the acceptance of your criteria with memory usage and/or a garbage collector profile,
    such as the following one:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的想法将是确保你可以将接受标准与某些环境指标相关联，例如内存行为。例如，你可以将你的标准接受与内存使用和/或垃圾收集器配置文件相关联，如下所示：
- en: '![](img/e3d7ce8f-72ae-4c05-b887-e43cf053d961.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e3d7ce8f-72ae-4c05-b887-e43cf053d961.jpg)'
- en: Assuming the *X* axis is the time and the *Y* axis the memory used, then this
    profile shows that the garbage collection is regular (almost each vertical line)
    and that the memory usage is bounded and regular since it doesn't go over the
    red line representing the maximum, even after a few cycles.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 假设 *X* 轴是时间，*Y* 轴是使用的内存，那么这个配置文件显示垃圾回收是规则的（几乎每一条垂直线），并且内存使用是有界和规则的，因为它没有超过代表最大值的红线，即使在经过几个周期之后也是如此。
- en: This sort of definition is rarely self-sufficient as it implicitly defines that
    this validation happens when the application has already reached the criteria
    we measure, and that *some time* has passed. Although, it is better than just
    measuring the criteria and not validating that the result is true for a long-running
    instance.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这种定义很少是自足的，因为它隐含地定义了这种验证发生在应用程序已经达到我们测量的标准，并且 *一些时间* 已经过去。尽管如此，这比仅仅测量标准而不验证长时间运行的实例的结果是否为真要好。
- en: Indeed, the best case is to be able to test the application for days, but it
    is generally costly and not doable. If you can't do it, using this kind of strategy
    and high-level validation is generally a good fallback.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，最好的情况是能够测试应用程序数天，但这通常成本高昂且不可行。如果你不能这样做，使用这种策略和高级验证通常是一个好的备选方案。
- en: Defining the scenario
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义场景
- en: Defining the scenario is linked to the criteria but removes the constant constraint.
    This allows you to define more complex cases where all metrics can vary at the
    same time.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 定义场景与标准相关联，但消除了恒定约束。这允许你定义更复杂的案例，其中所有指标可以同时变化。
- en: 'A common example is to make the user (client) number a variable moving with
    the time: *the response time will be constant from 5 users to 1,000 users with
    an increment of 5 users every 10 seconds*.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的例子是将用户（客户端）数量设为一个随时间移动的变量：*响应时间将从5个用户到1,000个用户保持恒定，每10秒增加5个用户*。
- en: A scenario is generally very close to the actual application usage but also
    harder to work on if you don't encounter it immediately because you are no longer
    running the application under a constant load. This is why they are seen more
    as validation checkpoints than work criteria.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一个场景通常非常接近实际应用程序的使用，但如果你没有立即遇到它，它也更难处理，因为你不再在恒定负载下运行应用程序。这就是为什么它们更多地被视为验证检查点而不是工作标准。
- en: Defining the environment
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义环境
- en: Once you know what you want to test, you will need to set up your application
    *somewhere* to be able to validate it and potentially optimize it.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你知道你想要测试什么，你需要在某个地方设置你的应用程序，以便能够验证它并可能优化它。
- en: It may sound obvious but, here, you have to be very strict on that point and
    benchmark your application in an environment comparable to your final environment.
    What does it mean? The same machine, same network setup, same load balancing strategy,
    same backends/databases, and so on.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来可能很显然，但在这里，你必须对此点非常严格，并在与最终环境相似的环境中基准测试你的应用程序。这意味着什么？相同的机器，相同的网络设置，相同的负载均衡策略，相同的后端/数据库，等等。
- en: Any part of the setup must match where you will run. Otherwise, when deploying
    in production, you may be surprised by some unexpected factors you should have
    seen coming and evaluated far before this final deployment. The best case is that
    the application is not functional, which is generally identified by some smoke
    tests done after the deployment. The worse case is that the application is functional,
    but its scalability or performance are affected by an unexpected factor. We rarely
    run performance tests in a production environment. Thus, limiting the potential
    error factors due to the environment is very important.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 设置的任何部分都必须与你的运行位置相匹配。否则，在生产环境中部署时，你可能会遇到一些你本应该提前看到并评估的意外因素。最好的情况是应用程序无法正常工作，这通常是通过部署后进行的某些烟雾测试来识别的。最坏的情况是应用程序可以正常工作，但其可扩展性或性能受到意外因素的影响。我们很少在生产环境中进行性能测试。因此，限制由于环境引起的潜在错误因素非常重要。
- en: The machines
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器
- en: Before installing any application, you need a machine. From what we just said,
    the machine must be close to the final one, but what does it mean in the machine's
    context?
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装任何应用程序之前，你需要一台机器。根据我们刚才所说的，这台机器必须接近最终版本，但在机器的背景下这意味着什么？
- en: 'The machine is often seen as its resources:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 机器通常被视为其资源：
- en: 'The CPU: The computing power the application can use'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU：应用程序可以使用的计算能力
- en: 'The memory: The space the application can use'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存：应用程序可以使用的空间
- en: 'The disk space: The local storage the application can rely upon'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 磁盘空间：应用程序可以依赖的本地存储
- en: Your first choice will be to pick the same CPU/memory/disk as the production
    machine. Yet make sure, before going this way, that the machine is not shared
    with other services (like another application), which can completely deserve the
    1-1 choice in terms of resources (CPU, memory, disk, ...) because the resources
    would be consumed by the other application. That is to say, if the application
    is sharing its resources with other software, you will need to find a way to either
    estimate the available resources for your application and limit them to this amount,
    or isolate both applications to guarantee each of them will have a well-defined
    set of resources.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 你的第一个选择将是选择与生产机器相同的CPU/内存/磁盘。然而，在采取这一步骤之前，请确保该机器没有被其他服务（如另一个应用程序）共享，因为这可能会在资源（CPU、内存、磁盘等）方面完全值得1-1的选择，因为资源将被其他应用程序消耗。也就是说，如果应用程序与其他软件共享资源，你需要找到一种方法来估计应用程序可用的资源并将它们限制在这个数量，或者隔离这两个应用程序以确保每个应用程序都将有一个定义良好的资源集。
- en: If you rely on Docker/Kubernetes for deployments, these recommendations apply
    as well, except they are no longer at *machine* level but *pod* level. Also, make
    sure your JVM is configured to support the pod (or container) settings that require
    some JVM tuning to use cgroup configuration instead of the whole machine setup—the
    Java default.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你依赖Docker/Kubernetes进行部署，这些建议同样适用，但它们不再是在*机器*级别，而是在*pod*级别。此外，确保你的JVM配置为支持pod（或容器）设置，这需要一些JVM调整来使用cgroup配置而不是整个机器设置——Java默认设置。
- en: The network
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络
- en: The network is, nowadays, a very important factor in a deployment. If your application
    is self-sufficient, it is not very crucial, but this is almost never the case.
    All applications have either an HTTP layer (through a UI or web services), a (remote)
    database, or are remotely connected to other applications. This is becoming even
    more crucial in a microservices architecture where some libraries are even designed
    to handle that part more specifically (with fallbacks, bulhead, and concurrency,
    as we saw in previous chapters).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，网络在部署中是一个非常重要的因素。如果你的应用是自给自足的，那么它并不是非常关键，但这种情况几乎从未发生过。所有应用要么有一个HTTP层（通过UI或Web服务），要么有一个（远程）数据库，或者远程连接到其他应用。在微服务架构中，这一点变得更加关键，因为一些库甚至被设计来更具体地处理这部分工作（包括回退、bulhead和并发，正如我们在前面的章节中看到的）。
- en: In this context, it is very important to be able to rely on a good network.
    In the same spirit as for the machine selection, you must choose a network comparable
    to the production network. Assuming the material is almost the same, this means
    that you will select networks with the same throughput, but this is not enough.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个背景下，能够依赖一个好的网络非常重要。与机器选择的精神相同，你必须选择一个与生产网络相当的网络。假设材料几乎相同，这意味着你将选择具有相同吞吐量的网络，但这还不够。
- en: 'When working with a network, there are two other criteria to take into account
    very quickly to avoid surprises:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当与网络一起工作时，还有两个其他标准需要迅速考虑，以避免意外：
- en: 'The *distance* between the machines/hosts: If remote services are *far* then
    the latency will be increased and the code relying on these services will be *slower*.
    Ensuring you benchmark in conditions close to the production ones—the same latency
    and response times—is very important to be able to rely on the figures you obtain.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器/主机之间的*距离*：如果远程服务*远*，那么延迟会增加，依赖于这些服务的代码将会*变慢*。确保你在接近生产环境的条件下进行基准测试——相同的延迟和响应时间——这对于能够依赖你获得的数字非常重要。
- en: 'The network usage: If the network is used a lot by other applications, the
    bandwidth available for your *new* application will be reduced, and the performance
    will be very quickly impacted. A common error in a benchmark is to have a network
    dedicated to the benchmark, whereas in production it is shared with some other
    applications. Ensuring you get a consistent setup here will avoid big surprises
    during your deployments.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络使用情况：如果其他应用大量使用网络，你的*新*应用可用的带宽将会减少，性能将会很快受到影响。基准测试中的一个常见错误是有一个专门用于基准测试的网络，而在生产中它与其他一些应用共享。确保你在这里有一个一致的设置，将避免在部署期间出现大的惊喜。
- en: Databases and remote services
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据库和远程服务
- en: If your application uses a remote service, which can be a classical **relational
    database management system** database (**RDBMS**), a NoSQL database, or another
    application, it is important to make sure you are benchmarking under realistic
    conditions. Concretely, if we take back our quote-manager application, which uses
    an RDBMS database, we should not test with local MySQL if our production database
    will be an Oracle instance. The idea is to get as close to the reality as possible—the
    latency our production environment will get.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的应用使用远程服务，这可能是一个经典的**关系型数据库管理系统**数据库（**RDBMS**），一个NoSQL数据库，或者另一个应用，确保你在现实条件下进行基准测试非常重要。具体来说，如果我们回到我们的quote-manager应用，它使用RDBMS数据库，我们不应该使用本地MySQL进行测试，如果我们的生产数据库将是Oracle实例。我们的想法是尽可能接近现实——生产环境将获得的延迟。
- en: In some cases you (or your company) will own the other services/databases and
    can tune them to make them scale more. But in some other cases, you use external
    services you can't optimize, such as CBOE and Yahoo! Finance, in the quote-manager
    application. In any case, it will always be saner to come to the other node (service/database)
    manager to ask to make it faster. Realizing you are slow in production because
    you don't have the same setup as during the benchmark will slow you down and impact
    you more.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，你（或你的公司）可能拥有其他服务/数据库，并且可以调整它们以提高其可扩展性。但在其他情况下，你使用外部服务，这些服务无法优化，例如在quote-manager应用程序中使用CBOE和Yahoo!
    Finance。在任何情况下，总是更明智地去找其他节点（服务/数据库）的管理员，请求使其更快。意识到在生产环境中因为你的设置与基准测试时不同而导致运行缓慢，这会减慢你的速度并对你产生更大的影响。
- en: This doesn't mean that *mocking* an external service is stupid. It can be very
    handy during the optimization phase of your own application, since it will make
    the external service interaction as fast as is potentially feasible. However,
    you must ensure you remove the mock when doing your *validation* benchmark.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不意味着*模拟*外部服务是愚蠢的。在优化你自己的应用程序的阶段，它可能非常有用，因为它可以使外部服务交互尽可能快。然而，你必须确保在执行*验证*基准测试时移除模拟。
- en: If you enable the application to be configured to use mocks or fast alternative
    systems, don't forget to write a log message (in the INFO or WARNING levels) during
    startup to ensure you can find this information later. It can save you a lot of
    time and avoid you re-running a benchmark because you are not sure of the *actual*
    running setup.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使应用程序能够配置为使用模拟或快速替代系统，不要忘记在启动时写入一条日志消息（INFO或WARNING级别），以确保你可以在以后找到这些信息。它可以节省你很多时间，并避免你因为不确定实际的运行设置而重新运行基准测试。它可以帮助你避免*实际*运行设置与基准测试设置不一致导致的问题。
- en: During the benchmark, in particular the tuning phase, you will likely configure
    your pools (connection pools). Thus, it is important to ensure you can rely on
    the database (or service) scalability. The goal is to avoid successfully passing
    a benchmark with a pool of 1,024 connections and realizing you can only use 20
    connections in production (20 being the maximum number of connections your database
    accepts).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在基准测试期间，特别是在调整阶段，你可能会配置你的池（连接池）。因此，确保你可以依赖数据库（或服务）的可扩展性是很重要的。目标是避免在拥有1,024个连接的池中成功通过基准测试，然后意识到在生产环境中你只能使用20个连接（20是数据库接受的连接数上限）。
- en: More than the database/service type, more than the version, more than the environment
    (OS, machine), you need to make sure the configuration of the database is copied
    from the production instance (or, if you are in the tuning phase, that the final
    configuration you used can be copied to the production instance).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅仅是要考虑数据库/服务类型，不仅仅是版本，不仅仅是环境（操作系统、机器），你需要确保数据库的配置是从生产实例复制过来的（或者，如果你处于调整阶段，确保你使用的最终配置可以被复制到生产实例）。
- en: The server
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务器
- en: 'We are talking about a Java EE application—but it could be generalized to any
    application if we talk about *packaging—*so we deploy the application into a server.
    Even embedded applications are packaging (*bundling*) a server in their deliverable.
    As with all the previous points, it is important to align it with the target system:
    the production environment.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在讨论一个Java EE应用程序——但如果谈论到*打包*，它可以推广到任何应用程序。因此，我们将应用程序部署到服务器中。即使是嵌入式应用程序，在其交付物中也打包（捆绑）了一个服务器。与所有先前的点一样，与目标系统（生产环境）保持一致是很重要的。
- en: Concretely, it means that you shouldn't test against a WildFly server if your
    production environment is using Apache TomEE or GlassFish.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，这意味着如果你的生产环境使用Apache TomEE或GlassFish，你不应该针对WildFly服务器进行测试。
- en: A server is not far from your application if we talk about the way it is developed
    and packaged. This means that it embeds several libraries selected by the server
    vendor. The direct implication is that a server version embeds several library
    versions. Since Java EE is between ~15 and ~30 specifications, it is at least
    as important as libraries packed together. Because it is software and you can't
    avoid some changes between versions—particularly during the early stages of a
    new specification—you should try to ensure you are using not only the same server
    as in production but also the same version.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们谈论的是开发和打包的方式，服务器离您的应用程序并不远。这意味着它嵌入了几种由服务器供应商选择的库。直接的含义是服务器版本嵌入了几种库版本。由于Java
    EE介于15到30个规范之间，它至少与打包在一起的库一样重要。因为它是软件，您无法避免版本之间的某些变化——尤其是在新规范早期阶段——因此，您应该尝试确保您不仅使用与生产环境中相同的服务器，而且使用相同的版本。
- en: This statement should be extended to all the code that is *outside* of your
    application. It can include your JDBC drivers, directly deployed in the container,
    or even some infrastructure/operation team services.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这个声明应该扩展到您应用程序之外的所有代码。它可以包括您的JDBC驱动程序，直接部署在容器中，甚至是一些基础设施/运营团队服务。
- en: Once you have picked your server, you need to ensure you use a setup (configuration)
    close enough to the production one. This includes the logging configuration you
    will need (typically, if you use a log aggregator, you may need a specific log
    format) and the resources deployed to it. If you auto-deploy resources from an
    infrastructure service, ensure you deploy them all to have the same thread usage,
    network usage (if it implies remote resources, such as JMS), and so on.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您选择了服务器，您需要确保您使用一个与生产环境尽可能接近的设置（配置）。这包括您需要的日志配置（通常，如果您使用日志聚合器，您可能需要一个特定的日志格式）以及部署到其上的资源。如果您从基础设施服务自动部署资源，确保您将它们全部部署以具有相同的线程使用率、网络使用率（如果它涉及远程资源，如JMS）等等。
- en: Finally (and linked to machine selection), ensure the setup is consistent with
    the production one. If you log on a **Solid State Drive** (**SSD**) disk in production,
    ensure you log on an SSD during your benchmark.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 最后（并且与机器选择相关），确保设置与生产环境一致。如果您在生产环境中登录到**固态硬盘**（**SSD**）磁盘，确保在基准测试期间登录到SSD。
- en: Automatize your scenarios
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动化您的场景
- en: Once you have your scenarios, you can just describe them and manually execute
    them for simple ones you can script or code directly without much effort. But
    most of the time, you will need to automate them. This is typically the case for
    load testing scenarios. The advantage of automating them is that you can run them
    on demand (*in one click*), and thus, it is easy to test and retest them without
    a huge investment.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有了场景，您只需描述它们，并手动执行它们，对于简单的场景，您可以轻松地编写脚本或代码。但大多数时候，您需要自动化它们。自动化它们的优点是可以按需运行（一键点击），因此，测试和重新测试它们很容易，而不需要大量投资。
- en: There are several tools to automate the scenarios, and they mainly depend on
    the scenario you need to test. We will go through some mainstream ones you can
    use if you don't know where to start.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种工具可以自动化场景，它们主要取决于您需要测试的场景。我们将介绍一些您可以使用的主流工具，如果您不知道从哪里开始的话。
- en: JMeter
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: JMeter
- en: 'Apache JMeter ([http://jmeter.apache.org/](http://jmeter.apache.org/)) is a
    historical solution to load test an application. It supports several modes and
    is fully written in Java, which makes it easy to integrate and use for most Java
    developers. It supports main *connections* used by applications:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Apache JMeter ([http://jmeter.apache.org/](http://jmeter.apache.org/)) 是一个历史悠久的解决方案，用于负载测试应用程序。它支持多种模式，并且完全用Java编写，这使得它对大多数Java开发者来说易于集成和使用。它支持应用程序使用的**主要连接**：
- en: HTTP/HTTPS, SOAP/REST for JavaEE, NodeJs, and so on
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP/HTTPS，SOAP/REST for JavaEE，NodeJs等等
- en: FTP
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FTP
- en: JDBC
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JDBC
- en: LDAP
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LDAP
- en: JMS
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JMS
- en: Mail
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 邮件
- en: TCP and so on
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TCP等等
- en: What is immediately interesting for you is that you will be able to test your
    Java EE application but also your other backends, and thus can compare the performance
    (of the database and application, for instance) to potentially be able to report
    that the database is the bottleneck.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 对您来说最有趣的是，您将能够测试您的Java EE应用程序，以及其他后端，从而可以比较（例如数据库和应用程序的性能），以便有可能报告数据库是瓶颈。
- en: 'It provides a nice UI, which looks like this:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 它提供了一个很好的用户界面，看起来像这样：
- en: '![](img/d124e64e-8f7a-44c2-bb2f-da11c842251d.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d124e64e-8f7a-44c2-bb2f-da11c842251d.png)'
- en: This interface is designed for building your test plans (scenarios); it allows
    you to create it without any configuration or deep knowledge of the tool. If you
    start the software from a command line, you will even have a warning message saying
    not to use it for actual load testing and to use the **command line interface**
    (**CLI**) for real runs.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这个界面是为了构建你的测试计划（场景）而设计的；它允许你无需任何配置或对工具的深入了解即可创建它。如果你从命令行启动软件，你甚至会有一个警告消息说不要用它进行实际的负载测试，而应该使用**命令行界面**（CLI）进行实际运行。
- en: 'Then, once you have started JMeter, you will build a *Test Plan* composed of
    steps. It will allow you to configure the threads and the way the number of *clients* is
    defined, add some assertions (validations of the output) to the scenario, and
    reuse variables between steps (for instance, a first step can get an OAuth2 token
    used to authenticate the next request or even handle the warm-up of your testing).
    In the elements you can add to the plan, there are some reports allowing you to
    get the figures you expect as output from a benchmark, such as the percentage
    of error, the min/max duration, the throughput, KB/sec, and so on:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，一旦你启动了JMeter，你将构建一个由步骤组成的**测试计划**。它将允许你配置线程和定义客户端数量的方式，向场景添加一些断言（输出验证），并在步骤之间重用变量（例如，第一步可以获取用于验证下一个请求的OAuth2令牌，甚至处理测试的预热）。你可以在计划中添加的元素中，有一些报告允许你获取你期望从基准测试中得到的输出数据，例如错误百分比、最小/最大持续时间、吞吐量、KB/秒等：
- en: '![](img/016d88b5-0a47-4a0a-b33c-383b7aef4c5b.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/016d88b5-0a47-4a0a-b33c-383b7aef4c5b.png)'
- en: This screenshot represents the *aggregated report* of JMeter which contains
    statistics about the plan execution—or a subpart of it. What is interesting here
    is the error rate (100% in the previous example) which allows you also to validate
    that the execution was *good enough,* that is, there were not too many errors
    saying we didn't test anything.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这张截图代表了JMeter的**聚合报告**，其中包含了关于计划执行或其子部分的统计数据。这里有趣的是错误率（前一个例子中的100%），这还允许你验证执行是否足够好，也就是说，没有太多错误表明我们没有测试任何东西。
- en: Once your plan is defined, you can save it in a `.jmx` file (JMeter default
    extension), which will allow you to replay it. At that point, you should be able
    to *locally* test your scenario (changing the URL of the plan a bit to adjust
    it to your local instance), but you can't yet test a cluster.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的计划定义好了，你可以将其保存为`.jmx`文件（JMeter默认扩展名），这将允许你重新播放它。到那时，你应该能够*本地*测试你的场景（稍微改变计划的URL以调整到你的本地实例），但你还不能测试集群。
- en: 'Finally, for real load testing, you will need to use the *remote testing* solution
    of JMeter. It will allow you to orchestrate multiple client nodes (often called
    *injectors* since they will *inject* requests into the system). The big advantages
    are:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，对于实际的负载测试，你需要使用JMeter的**远程测试**解决方案。它将允许你编排多个客户端节点（通常称为*注入器*，因为它们将向系统中*注入*请求）。主要优势是：
- en: You don't rely on your local machine anymore
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你不再依赖于你的本地机器了
- en: You control which networks are used by the client (it can be the same as the
    server or not)
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以控制客户端使用哪些网络（它可以与服务器相同，也可以不同）
- en: You can horizontally scale, using *N* client machines instead of one
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使用*N*个客户端机器进行水平扩展，而不是一个
- en: The last point is very important because of the network usage. When doing HTTP
    requests, you will use the machine network, and one of the most limiting criteria
    will be the number of clients per nodes. The more clients you have, the slower
    they will globally be as they add noise for other clients. That is to say, before
    launching a full run, make sure to size your injector correctly to establish how
    many clients you can use per injector node, without being limited by the infrastructure.
    You will rarely have tons of clients for a single machine in a real deployment.
    Thus, it is acceptable to have only one or two clients per machine, in some cases.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一点非常重要，因为涉及到网络使用。在进行HTTP请求时，你将使用机器网络，其中一个最限制性的标准将是每个节点的客户端数量。客户端越多，它们在全球范围内就会越慢，因为它们为其他客户端添加了噪声。也就是说，在启动完整运行之前，确保正确地调整注入器的大小，以确定每个注入器节点可以使用的客户端数量，而不会受到基础设施的限制。在实际部署中，你很少会为单个机器拥有大量的客户端。因此，在某些情况下，每台机器只有一个或两个客户端是可以接受的。
- en: If you want to download JMeter, you can go to its download page ([http://jmeter.apache.org/download_jmeter.cgi](http://jmeter.apache.org/download_jmeter.cgi))
    on the Apache website.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要下载JMeter，你可以访问Apache网站上的下载页面（[http://jmeter.apache.org/download_jmeter.cgi](http://jmeter.apache.org/download_jmeter.cgi)）。
- en: Gatling
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Gatling
- en: Gatling ([https://gatling.io/](https://gatling.io/)) is an alternative to JMeter.
    You will find the same features as in JMeter (of course, there are some differences,
    but we will not list them here). The main difference is that you script your scenarios instead
    of configuring them, either in an XML file, or visually in a nice UI.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Gatling ([https://gatling.io/](https://gatling.io/))是JMeter的替代品。你将找到与JMeter相同的功能（当然，有一些差异，但这里我们不会列出它们）。主要区别在于你通过脚本编写场景，而不是配置它们，无论是XML文件还是通过一个漂亮的UI进行可视化配置。
- en: The scripting is based on a **Domain Specific Language** (**DSL**) and relies
    on the Scala language. This can sound like a **blocker** for a Java developer,
    since Scala is not very friendly if you have never done any Scala development.
    However, it is the strength of Gatling compared to JMeter; it is an Akka-Netty-based
    load testing solution. This means it is coded with technologies trying to be lock-free
    in their own backbone and enabling the injector code to scale. JMeter was known
    to be self-limiting in the way it was designed if you were requesting it to scale
    to too many users. In reality, this is not a huge limitation since, as we saw
    in the previous section, you will often also scale in terms of infrastructure
    to test your application reliably. Yet, it is interesting in development and in
    some highly scaling applications as you will not need so many machines to reach
    the same level of scalability of the injector.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本基于**领域特定语言**（**DSL**）并且依赖于Scala语言。这可能会让Java开发者感到**阻碍**，因为如果你从未进行过任何Scala开发，Scala可能不太友好。然而，这是Gatling相对于JMeter的优势；它是一个基于Akka-Netty的负载测试解决方案。这意味着它是用试图在自身核心中实现无锁技术的技术编写的，并使注入器代码可扩展。如果你要求JMeter扩展到太多用户，它被认为在设计上会自我限制。实际上，这并不是一个很大的限制，因为我们之前看到的那样，你通常会从基础设施的角度进行扩展以可靠地测试你的应用程序。然而，在开发和一些高度扩展的应用程序中，这很有趣，因为你不需要那么多机器就能达到注入器相同的可扩展性水平。
- en: This is often a point we forget during a benchmark, and this is why it is important
    to prepare it before; to ensure the injector does not throttle the benchmark.
    Otherwise, you are testing the client/injector instead of the server/application.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常是我们进行基准测试时容易忘记的点，这就是为什么在测试之前准备它很重要的原因；以确保注入器不会限制基准测试。否则，你测试的是客户端/注入器而不是服务器/应用程序。
- en: 'Just to give you an idea, here is a simple Gatling script:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 只是为了给你一个概念，这里是一个简单的Gatling脚本：
- en: '[PRE0]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This simple script defines a scenario named `QuotesScenario`*.* It will request
    our `findAll` quote endpoint.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的脚本定义了一个名为`QuotesScenario`的场景。它将请求我们的`findAll`报价端点。
- en: 'If you put this script in `$GATLING_HOME/user-files/simulations/packt/QuotesSimulation.scala`,
    be careful, as Scala uses the concept of packages as in Java, so you need the
    right nested folder compared to the `simulations` folder. Then you can run `$GATLING_HOME/bin/gatling.sh`,
    which will scan and compile the files inside the previous folder to find the simulations
    and ask you to select the one you want to launch:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将此脚本放在`$GATLING_HOME/user-files/simulations/packt/QuotesSimulation.scala`，请注意，Scala使用与Java中相同的包的概念，因此你需要与`simulations`文件夹相比正确的嵌套文件夹。然后你可以运行`$GATLING_HOME/bin/gatling.sh`，它将扫描并编译之前文件夹内的文件以找到模拟，并要求你选择要启动的模拟：
- en: '[PRE1]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `computerdatabase` simulations are the default ones; our simulation is the
    last one. Once selected, Gatling requests some metadata about the simulation,
    such as its `id`and `description`.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`computerdatabase`模拟是默认的；我们的模拟是最后一个。一旦选择，Gatling将请求有关模拟的一些元数据，例如其`id`和`description`。'
- en: The first time you launch Gatling, the startup can be lengthy as it will compile
    the simulation—there are some samples with the default distribution.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次启动Gatling时，启动可能会比较长，因为它将编译模拟——有一些默认分布的示例。
- en: 'When the simulation runs, you will get some progress in the console (whereas
    with JMeter, you were able to get it in the UI for your tests and see the reports
    in real time):'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 当模拟运行时，你将在控制台中看到一些进度（而与JMeter相比，你可以在测试的UI中获取它并实时查看报告）：
- en: '[PRE2]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: These small reports show the progress of the test. We can identify that we are
    at 84% of the simulation we configured, representing the 54/64 requests (users)
    we requested and that 50 seconds has elapsed already.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这些小报告显示了测试的进度。我们可以确定我们配置的模拟已经完成了84%，代表了54/64个请求（用户），并且已经过去了50秒。
- en: 'Once the test is finished, a small report is generated in the console:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦测试完成，控制台会生成一个小报告：
- en: '[PRE3]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This report contains the statistics about the execution and the response time
    distribution.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这个报告包含了关于执行和响应时间分布的统计数据。
- en: 'Finally, Gatling generates an HTML report (by default). Its location is logged
    at the very end of the program, just before it exits. You can open it with any
    browser and here is what it looks like:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Gatling会生成一个HTML报告（默认情况下）。它的位置记录在程序末尾，就在它退出之前。你可以用任何浏览器打开它，看起来是这样的：
- en: '![](img/35dc2f5e-70b5-48d1-a37f-e52a97f32304.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/35dc2f5e-70b5-48d1-a37f-e52a97f32304.png)'
- en: 'Back on the report, we find the statistics (on the left, in orange) and some
    detailed indicators in the center of the page. Between them, you have the number
    of requests, the response time distribution (allowing you to see if the response
    time is in an acceptable range or if the response time is constant enough for
    your target users), and so on. You can see, in the previous screenshot, that there
    are two tabs: GLOBAL and DETAILS. The DETAILS tab has this small menu on the left
    (with quotes on our screenshot), allowing you to drill down the details, per step,
    of the simulation/scenario. The quotes references the name we gave to the `http`
    request we defined in our simulation.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 回到报告中，我们在页面中心找到了统计数据（在左侧，橙色显示）和一些详细指标。它们之间包括请求数量、响应时间分布（允许你查看响应时间是否在可接受范围内，或者响应时间是否足够稳定以满足目标用户），等等。你可以在之前的屏幕截图中看到有两个标签页：全局和详情。详情标签页左侧有一个小菜单（在我们的屏幕截图中带有引号），允许你按步骤深入到模拟/场景的细节。引号引用的是我们在模拟中定义的`http`请求的名称。
- en: Gatling has a lot more features and ways to compose scenarios, and since it
    is code, it is also quite flexible. This is not the topic of the book, but don't
    hesitate to have a deeper look.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Gatling有很多更多功能和组合场景的方式，由于它是代码，所以也非常灵活。这不是本书的主题，但不要犹豫，深入了解一下。
- en: Again, don't forget the injector machines (the machines where you put the processes
    simulating the clients, that is, the Gatling process here) may not be powerful
    enough or may have not enough bandwidth to scale very highly. For that reason,
    you will need to distribute your injectors across several machines to reach the
    right amount of users in general.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，不要忘记注入器机器（放置模拟客户端进程的机器，即这里的Gatling进程）可能不够强大，或者带宽不足，无法进行高度扩展。因此，你需要将注入器分布在几台机器上，以在一般情况下达到正确的用户数量。
- en: Gatling, like JMeter, supports this mode even if it requires more work. The
    procedure is explained on their website ([https://gatling.io/docs/2.3/cookbook/scaling_out/](https://gatling.io/docs/2.3/cookbook/scaling_out/)),
    but at a high level you will run the simulation on several nodes then grab all
    their outputs and aggregate them post-execution.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Gatling像JMeter一样支持这种模式，即使它需要更多的工作。该过程在他们的网站上解释（[https://gatling.io/docs/2.3/cookbook/scaling_out/](https://gatling.io/docs/2.3/cookbook/scaling_out/))，但在高层次上，你将在多个节点上运行模拟，然后收集它们的输出并在执行后进行汇总。
- en: Other tools
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他工具
- en: There are many other tools you can use to define your scenarios; even some DIY
    solutions can be used. In all cases, you should ensure it scales well enough to
    not limit your benchmark since you want to test your application and not your
    benchmark tooling.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用许多其他工具来定义你的场景；甚至一些DIY解决方案也可以使用。在所有情况下，你应该确保它足够扩展，以免限制你的基准测试，因为你想要测试的是你的应用程序，而不是基准测试工具。
- en: Ensuring you have support
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确保你有支持
- en: 'When you start benchmarking, you will probably encounter some issues, such
    as:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始基准测试时，你可能会遇到一些问题，例如：
- en: A network setup not correctly done
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络设置没有正确完成
- en: A bug in a framework/a library/your application/the injector
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 框架/库/你的应用程序/注入器的bug
- en: A remote service or database not absorbing enough load, and so on
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 远程服务或数据库没有吸收足够的负载，等等
- en: In all potential cases you may encounter—given any *brick* of your software
    can have an issue—you should be able to have somebody you can call to help you
    fix the issue, or at least evaluate it quickly. This is particularly crucial if
    part of the benchmark costs *some* money (if you are renting some machines, consulting,
    and so on). The idea here is to be able to get rid of any blocker as fast as possible
    to not waste time on details.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有可能遇到的情况中——假设你的软件中的任何**砖块**都可能有问题——你应该能够找到可以求助的人来帮助你修复问题，或者至少快速评估它。这尤其重要，如果基准测试的一部分需要**一些**费用（如果你在租用一些机器、咨询等）。这里的想法是尽可能快地消除任何阻碍，不要在细节上浪费时间。
- en: Time boxing your optimization benchmark
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将你的优化基准测试时间框起来
- en: An evaluation benchmark is time boxed by design; you run the benchmark and report
    the figures. Although, an optimization benchmark is more blurry. Concretely, you
    can spend a whole year optimizing a simple web service just because of the layers
    it uses and all the small tuning options you can test, from the network configuration,
    through the JVM memory, to the caching solutions.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 评估基准是按设计划分时间段的；你运行基准测试并报告数据。尽管如此，优化基准则更为模糊。具体来说，你可能会因为一个简单的网络服务所使用的层以及所有可以测试的小调整选项（从网络配置，通过JVM内存，到缓存解决方案）而花费整整一年时间进行优化。
- en: Thus, it is crucial before starting to benchmark an application and optimizing
    it to define how long you will spend benchmarking your application. It can also
    be linked to a renting period and may require an estimation phase to work with
    the operation and development teams. But if you don't do it, the risk is that
    you will spend a lot of time on the details and not make the best of the benchmark.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在开始基准测试和优化应用程序之前，定义你将花费多少时间进行基准测试是非常重要的。这也可以与租赁期相关联，可能需要与运营和开发团队一起进行估算阶段。但如果你不这样做，风险是你会在细节上花费大量时间，而没有充分利用基准测试。
- en: Even if it is a high-level approximation, the Pareto principle can be used here
    to try to optimize the benchmark time. Concretely, try to do 20% of the optimization,
    which will give you 80% of the boost for your application. Then, if you have time,
    you can work on the remaining 20%.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 即使这是一个高级近似，帕累托原则也可以用来尝试优化基准测试时间。具体来说，尝试进行20%的优化，这将为你提供80%的应用程序提升。然后，如果你有时间，你可以继续优化剩余的20%。
- en: Installing and resetting procedures
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装和重置程序
- en: It may sound obvious, but before starting the benchmark, you must know how to
    properly install your application and inter connect it with other systems (databases,
    other applications, and so on). This part should be written down in a document
    to make sure it is easy to find when needed, and that it has been tested at least
    once before the benchmark.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然听起来可能很明显，但在开始基准测试之前，你必须知道如何正确安装你的应用程序，并将其与其他系统（数据库、其他应用程序等）相互连接。这部分应该写成文档，以确保在需要时容易找到，并且至少在基准测试之前测试过一次。
- en: The part we forget more often is the reset part, and it would be ideal if this
    part is automatized as well in the scenarios. This is mainly about ensuring each
    execution is repeatable, and executions are comparable.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常忘记的部分是重置部分，如果在场景中这部分也能自动化，那就太理想了。这主要是确保每个执行都是可重复的，并且执行结果可以比较。
- en: Benchmark iterations
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基准测试迭代
- en: In the previous section, we prepared all we needed to start a benchmark in an
    efficient way. Now we need to see how we will work during the benchmark.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们为以高效的方式开始基准测试准备了所有需要的东西。现在我们需要看看在基准测试期间我们将如何工作。
- en: The first important thing is to establish that we only deal with optimization
    iterations here and not evaluation ones, which are straightforward—you run the
    scenarios and gather the reports.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 第一件重要的事情是确立我们在这里只处理优化迭代，而不是评估迭代，后者是直接的——你运行场景并收集报告。
- en: Iterating
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迭代
- en: It is probably natural, but you will iterate with your optimizations. This means
    that you will run the same test again and again to measure the result of a change—for
    instance, increasing the pool size.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是自然的，但你会对你的优化进行迭代。这意味着你会反复运行相同的测试来衡量变化的结果——例如，增加池大小。
- en: 'The direct implication of such a work structure is that you need to prepare
    yourself to store lots of reports in an organized way. There are many solutions
    for that and it mainly depends on the tools you are used to relying on. But at
    a very high level, you need to, at least, store:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这种工作结构的直接影响是，你需要准备好以有组织的方式存储大量的报告。有许多解决方案，这主要取决于你习惯使用的工具。但至少在非常高的层面上，你需要存储：
- en: The benchmark report.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基准测试报告。
- en: The benchmark date (to be able to sort them, it is often useful to replay the
    iterations done afterwards).
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基准测试日期（为了能够排序，通常在之后重放迭代是有用的）。
- en: The benchmark configuration (you can store the full configuration or just write
    it in a file, named `CHANGES.txt`, for instance, where you list what you changed
    from the previous run). Note that it is important here to include the changes
    of external systems—such as databases—since they can directly impact your performance.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基准测试配置（你可以存储完整的配置，或者将其写入一个文件，例如命名为`CHANGES.txt`的文件，其中列出你从上次运行中更改了什么）。请注意，在这里包括外部系统（如数据库）的更改是很重要的，因为它们可以直接影响你的性能。
- en: In terms of storage, you can just use a `benchmark`folder on your hard drive
    and create a folder per iteration containing the previous information. The folder
    name can contain the date. A common pattern is `<iteration number>_<date>_<short
    description>`, for instance `001_2017-11-14_increasing-pool-size`. Using a number
    (padded with *0)* will allow you to use your operating system sorting to sort
    the folder. The date gives you another entry point—when somebody tells you *yesterday,
    it was working better*, for instance. Finally, the small description allows you
    to more easily identify the reports to compare them.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在存储方面，您只需在您的硬盘上使用一个`benchmark`文件夹，并为每个迭代创建一个包含先前信息的文件夹。文件夹名称可以包含日期。一个常见的模式是`<迭代编号>_<日期>_<简短描述>`，例如`001_2017-11-14_increasing-pool-size`。使用数字（用*0*填充）将允许您使用操作系统的排序来排序文件夹。日期为您提供另一个切入点——当有人告诉您“昨天，它运行得更好”，例如。最后，简短描述使您更容易识别报告以进行比较。
- en: It is not mandatory, but if you have a small tool (like a script or a small
    Java program) parsing the reports and configuration to store them in an index,
    you can more easily find the data and you will get a more powerful search. In
    the same way, if you already did the work to parse the data, you can easily implement
    a small `diff` tool to compare two reports, which will allow you to show the configuration
    changes and the impact on the performance—the reports. Generally, the reports
    are visual. Thus, being able to merge two reports allows you to compare them more
    efficiently (visually) than using two windows.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是强制性的，但如果您有一个小工具（如脚本或小型Java程序）解析报告和配置并将它们存储在索引中，您可以更容易地找到数据，并且您将获得更强大的搜索功能。同样，如果您已经完成了解析数据的工作，您可以轻松实现一个小型的`diff`工具来比较两个报告，这将允许您显示配置更改和对性能——报告的影响。通常，报告是可视的。因此，能够合并两个报告可以使您比使用两个窗口更有效地（视觉上）进行比较。
- en: Changing a single setting at a time
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一次只更改一个设置
- en: While you are tuning the application, it is important to identify if a setting
    is the factor enhancing the performance or not, and thus identify it as important
    or not.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 当您调整应用程序时，重要的是要确定一个设置是否是增强性能的因素，并据此将其视为重要或不重要。
- en: If you change multiple settings for a single run, you will not be able to say
    which setting triggered a change, or you can even neutralize a good setting by
    using another bad one and missing an optimization factor.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在单次运行中更改多个设置，您将无法确定哪个设置触发了变化，或者您甚至可能通过使用另一个不良设置来抵消一个良好的设置，从而错过一个优化因素。
- en: Resist the temptation to change everything at the same time, and try to keep
    a *scientific* approach, changing a single setting at a time.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 抵制同时更改一切的诱惑，并尝试保持一种*科学*的方法，一次只更改一个设置。
- en: Resetting any state between runs
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在每次运行之间重置任何状态
- en: We saw, in the previous section, that you must prepare as much data as the production
    database will work with, but also don't forget to reset the database state between
    each run.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们看到了您必须准备与生产数据库可以处理的数据一样多的数据，但同时也不要忘记在每次运行之间重置数据库状态。
- en: If you don't do it, the risk is you will slow down the execution between each
    run and make the optimizations you do completely invisible. This is because databases
    have a sort of size limit (quite huge), but while you benchmark, you will generally
    insert a lot of data very quickly so it wouldn't be surprising to reach that limit.
    Once you reach this size limit, the database is less efficient and performance
    degrades. To ensure you can compare the runs and validate some tuning options,
    you must run in the same conditions. So, you should ensure the database has the
    same data between each run.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不这样做，风险是您将在每次运行之间减慢执行速度，并使您所做的优化完全不可见。这是因为数据库有一种大小限制（相当大），但在您进行基准测试时，您通常会非常快速地插入大量数据，因此达到这个限制并不令人惊讶。一旦达到这个大小限制，数据库效率降低，性能下降。为了确保您可以在相同条件下运行，以便比较运行并验证一些调整选项，您必须确保数据库在每次运行之间具有相同的数据。所以，您应该确保数据库在每次运行之间具有相同的数据。
- en: This explanation used the database as the main illustration because it is the
    most common pitfall, but it is true for any part of your system.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这个解释使用了数据库作为主要说明，因为它是最常见的陷阱，但它适用于您系统的任何部分。
- en: Warming up your system
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预热您的系统
- en: 'Another crucial step to doing a benchmark is to not measure the data on a *cold* system.
    The reason is that a Java EE application generally intends to be long-running
    software; for that reason, it is common to have a *hot* system which already got
    optimizations after having ran during weeks or hours. These optimizations can
    be in action:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 进行基准测试的另一个关键步骤是不要在**冷**系统上测量数据。原因是Java EE应用程序通常旨在是长期运行的软件；因此，通常会有一个已经运行了数周或数小时并进行了优化的**热**系统。这些优化可以生效：
- en: 'The **JVM** **Just-In-Time** (**JIT**) compilation: This will optimize some
    common code paths. You can also investigate the `-XX:-TieredCompilation` option
    of the JVM to *pre-compile* the code, but you can encounter some issues with it
    on some servers.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**JVM** **即时**（**JIT**）编译：这将优化一些常见的代码路径。你还可以调查JVM的`-XX:-TieredCompilation`选项来**预编译**代码，但你在一些服务器上可能会遇到一些问题。'
- en: You can use some caching and therefore the application will be faster once the
    cache has all the data you test.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使用一些缓存，因此一旦缓存包含了所有你测试的数据，应用程序将会更快。
- en: If you use some external system you may need to do some expensive connections
    you will reuse later on (SSL connections are slow, secured connections are slow,
    and so on).
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你使用了一些外部系统，你可能需要进行一些你之后会重复使用的昂贵连接（SSL连接很慢，安全连接很慢等等）。
- en: Having some warm-up iterations before the actual measures start is very important
    to hide all these initializations and just measure the *final* performance of
    your application.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际测量开始之前进行一些预热迭代非常重要，这样可以隐藏所有这些初始化，并仅测量应用程序的**最终**性能。
- en: After your benchmark
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基准测试之后
- en: Once you have done your benchmark, you should have a *database* of your runs
    (the folder we talked about earlier with the reports, configuration, and so on).
    Now, to ensure you did the benchmark for a reason, there are few actions you should
    take.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你完成了基准测试，你应该有一个包含你运行情况的数据库（我们之前提到的包含报告、配置等的文件夹）。现在，为了确保你进行基准测试有明确的原因，有一些行动你应该采取。
- en: In this section, we assume that you will do these steps after the benchmark,
    but you can do them during the benchmark itself. It is presented this way because
    it is something you can do *offline*, and if you have some costs associated with
    the benchmark, these are tasks you can postpone easily.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们假设你将在基准测试之后执行这些步骤，但你也可以在基准测试本身进行。这样呈现是因为这是一些你可以**离线**执行的任务，如果你有一些与基准测试相关的成本，这些是可以轻易推迟的任务。
- en: Writing a report
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写报告
- en: Normally, at this point, you have collected all the data corresponding to the
    hard work you did during the benchmark. It is quite important to aggregate this
    in a report. The report will mainly explain the investigation (why you changed
    some settings and so on) and expose the results of the runs.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在这个阶段，你已经收集了基准测试期间你付出的辛勤劳动所对应的所有数据。将这些数据汇总到报告中非常重要。报告将主要解释调查（为什么你更改了一些设置等等）并展示运行结果。
- en: You can, of course, ignore the useless runs (no significant change in the performance),
    but it is always interesting to integrate the ones corresponding to a performance
    boost or degradation.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你可以忽略那些无用的运行（性能没有显著变化），但将那些对应于性能提升或下降的运行整合进来总是很有趣的。
- en: The last part of the report should explain how to properly configure the server
    for production. It can be done inline in the report or point to another document
    such as a reference guide if it is about a product or a white book for an application.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '报告的最后部分应该解释如何正确配置服务器以供生产使用。这可以在报告中直接完成，或者指向另一个文档，如产品参考指南或应用程序的白皮书。 '
- en: 'Here is a high-level structure for a report:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个报告的高级结构：
- en: 'Application description: What the application does.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序描述：应用程序做什么。
- en: 'Metrics: If you have some not so obvious or specific metrics, explain them
    here (before the next part).'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指标：如果你有一些不太明显或具体的指标，请在这里解释它们（在下一部分之前）。
- en: 'Scenarios: What your test did.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 场景：你的测试做了什么。
- en: 'Infrastructure/environment: How you deployed machines and external systems,
    how you set up the monitoring, and so on.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础设施/环境：你如何部署机器和外部系统，你如何设置监控等等。
- en: 'Injection: How you stimulated the application (you can explain that you had
    *N* JMeter nodes, for instance).'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注入：你如何刺激应用程序（例如，你可以解释你有*N*个JMeter节点）。
- en: 'Runs: All the relevant iterations you did and their results.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行情况：你进行的所有相关迭代及其结果。
- en: 'Conclusions: What do you keep from the benchmark? Which configuration should
    be used? You can also mention some tests you didn''t get time to run.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结论：你从基准测试中保留了什么？应该使用哪种配置？你还可以提及一些你没有时间运行测试。
- en: Updating your default configurations
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新你的默认配置
- en: Even if, as shown in the previous section, the *final* configuration is part
    of the report, it will not prevent you from propagating all the good practices
    you deduced from the benchmark in the code base. The goal is to reduce the mandatory
    configuration.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 即使，如前所述，最终的配置是报告的一部分，它也不会阻止你将基准测试中得出的所有良好实践传播到代码库中。目标是减少强制配置。
- en: For instance, if you identified that you need a timeout of 1 second instead
    of the default 30 seconds to have a good performance, updating your defaults to
    1 second directly in the code base will avoid having a bad performance if the
    configuration is forgotten. This part is a trade-off between default usability
    and performance, but generally you can still enhance the default user/operation
    team experience by doing it.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你发现你需要1秒的超时时间而不是默认的30秒才能获得良好的性能，直接在代码库中将默认值更新为1秒将避免在配置被遗忘时出现不良性能。这部分是默认可用性和性能之间的权衡，但通常你仍然可以通过这样做来提高默认用户/操作团队的经验。
- en: If you have some provisioning recipes or a Dockerfile, don't forget to update
    them as well, if relevant.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有某些配置脚本或Dockerfile，不要忘记如果相关的话也更新它们。
- en: Reviewing the conclusions
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 审查结论
- en: Depending on your conclusions, you may need to cross-check, with developers
    or other members, that the outcome of the benchmark is valid.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的结论，你可能需要与开发人员或其他成员交叉检查基准测试的结果是否有效。
- en: 'For instance, if you deduced on our quote-manager that you needed to cache
    the quotes, then you may desire to validate:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你在我们的报价管理器中推断出你需要缓存报价，那么你可能希望验证：
- en: If it is OK to cache them business-wise (you can check it with your product
    owner or manager)
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果从业务角度来看可以缓存它们（你可以与你的产品负责人或经理核实）。
- en: How long you can cache them for, as you will probably want some updates on the
    prices at some point
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以缓存它们多长时间，因为你可能希望在某个时候更新价格
- en: Another common example is to validate that you can bypass or change the way
    you secured some part of the application because the security layer was too slow
    (switching from OAuth2 to HTTP signature, or some authentication mechanism to
    network security, for instance).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的例子是验证你是否可以绕过或更改保护应用程序某些部分的方式，因为安全层太慢（例如，从OAuth2切换到HTTP签名，或某种认证机制到网络安全）。
- en: Once the conclusions are validated, you can also extract the part of the report
    related to the original SLA and make them validated by your customers, or the
    people you report to.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦结论得到验证，你还可以提取与原始SLA相关的报告部分，并让您的客户或您所报告的人进行验证。
- en: Enriching your project backlog
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 丰富你的项目待办事项
- en: In some cases, you may have identified some issues in the code. They may or
    may not impact the performance, but in any case you need to create corresponding
    tasks to fix them upstream.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，你可能在代码中发现了某些问题。它们可能或可能不会影响性能，但无论如何，你需要创建相应的任务来修复它们。
- en: If you used some hotfix or patch during the benchmark, don't forget to mention
    it and reference it inside the report to let people track whether it is actually
    fixed or not. Note that it can also be related to external libraries or containers
    and not only your application.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在基准测试期间使用了某些热修复或补丁，别忘了在报告中提及并引用它们，以便让人们跟踪是否真正修复了这些问题。请注意，这可能与外部库或容器有关，而不仅仅是你的应用程序。
- en: The more you work across teams, the more this phase is important. Otherwise,
    you get a report where the SLA is reached, and a product is never able to respect
    that because the enhancements are never integrated into the mainstream source
    code.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 你在跨团队工作得越多，这个阶段就越重要。否则，你会得到一份报告，其中SLA得到了满足，但产品永远无法遵守，因为增强功能从未整合到主流源代码中。
- en: Summary
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we saw that a benchmark is something you need to prepare before
    ensuring you can benefit the most from the benchmark time, and that it requires
    some organization. We also saw that to be useful you need to extract, from the
    work done, the conclusions it implies. This is really a scientific procedure—but
    an easy one—and you need to respect it if you want to optimize your time.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解到基准是在确保你能最大限度地从基准时间中获益之前需要准备的东西，并且它需要一些组织工作。我们还看到，为了有用，你需要从已完成的工作中提取出它所蕴含的结论。这实际上是一个科学程序——但很容易——如果你想优化你的时间，你需要尊重它。
- en: The next and last chapter will go one step further and look at how to reduce
    the distance between the development and the benchmark to reach a continuous performance
    evaluation, making your benchmark no longer harmful, since everything is already
    prepared and under control.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章和最后一章将进一步深入探讨如何缩短开发和基准之间的距离，以达到持续的绩效评估，使你的基准不再有害，因为一切都已经准备就绪并且处于控制之下。
