- en: Message-Driven Microservices
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消息驱动的微服务
- en: We have already discussed many features around microservice-based architecture
    provided by Spring Cloud. However, we have always been considering synchronous,
    RESTful-based inter-service communication. As you probably remember from [Chapter
    1](33ddbb93-e658-4d91-97f5-06d6167ef89e.xhtml), *Introduction to Microservices*,
    there are some other popular communication styles, such as publish/subscribe or
    asynchronous, event-driven point-to-point messaging. In this chapter, I would
    like to introduce a different approach to microservices than that presented in
    previous chapters. We will talk in more detail about how you can work with Spring
    Cloud Stream in order to build message-driven microservices.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了围绕由Spring Cloud提供的微服务架构的许多特性。然而，我们一直都在考虑基于同步、RESTful的跨服务通信。正如您可能从[第1章](33ddbb93-e658-4d91-97f5-06d6167ef89e.xhtml)，《微服务简介》中记忆的那样，还有一些其他流行的通信方式，如发布/订阅或异步、事件驱动的点对点消息传递。在本章中，我想介绍一种与前几章中介绍的微服务不同的方法。我们将更详细地讨论如何使用Spring
    Cloud Stream来构建消息驱动的微服务。
- en: 'Topics we will cover in this chapter include:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将覆盖的主题包括：
- en: The main terms and concepts related to Spring Cloud Stream
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与Spring Cloud Stream相关的术语和概念
- en: Using RabbitMQ and Apache Kafka message brokers as binders
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用RabbitMQ和Apache Kafka消息代理作为绑定器
- en: The Spring Cloud Stream programming model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spring Cloud Stream编程模型
- en: Advanced configurations of binding, producers, and consumers
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绑定、生产者和消费者的高级配置
- en: Implementation of scaling, grouping, and partitioning mechanisms
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现缩放、分组和分区机制
- en: Multiple binder support
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持多个绑定器
- en: Learning about Spring Cloud Stream
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习Spring Cloud Stream
- en: Spring Cloud Stream is built on top of Spring Boot. It allows us to create standalone,
    production-grade Spring applications and uses Spring Integration that helps in
    implementing communication with message brokers. Every application created with
    Spring Cloud Stream integrates with other microservices through input and output
    channels. Those channels are connected to external message brokers via middleware-specific
    binder implementations. There are two built-in binder implementations available—Kafka
    and Rabbit MQ.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream是建立在Spring Boot之上的。它允许我们创建独立的、生产级别的Spring应用程序，并使用Spring Integration来实现与消息代理的通信。使用Spring
    Cloud Stream创建的每个应用程序通过输入和输出通道与其他微服务集成。这些通道通过特定于中间件的绑定器实现与外部消息代理的连接。内置的绑定器实现有两个——Kafka和Rabbit
    MQ。
- en: Spring Integration extends the Spring programming model to support the well-known
    **Enterprise Integration Patterns** (**EIP**). EIP defines a number of components
    that are typically used for orchestration in distributed systems. You have probably
    heard about patterns such as message channels, routers, aggregators, or endpoints.
    A primary goal of the Spring Integration framework is to provide a simple model
    for building Spring applications based on EIP. If you are interested in more details
    about EIP, please refer to the website at [http://www.enterpriseintegrationpatterns.com/patterns/messaging/toc.html](http://www.enterpriseintegrationpatterns.com/patterns/messaging/toc.html).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Integration将Spring编程模型扩展以支持著名的**企业集成模式**（**EIP**）。EIP定义了一系列通常用于分布式系统中的编排的组件。您可能已经听说过诸如消息通道、路由器、聚合器或端点之类的模式。Spring
    Integration框架的主要目标是提供一个简单的模型，用于构建基于EIP的Spring应用程序。如果您对EIP的更多细节感兴趣，请访问[http://www.enterpriseintegrationpatterns.com/patterns/messaging/toc.html](http://www.enterpriseintegrationpatterns.com/patterns/messaging/toc.html)网站。
- en: Building a messaging system
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建消息系统
- en: 'I think that the most suitable way to introduce main Spring Cloud Stream features
    is through the sample microservices-based system. We will lightly modify an architecture
    of the system that has been discussed in the previous chapters. Let me provide
    a short recall of that architecture. Our system is responsible for processing
    orders. It consists of four independent microservices. The `order-service` microservice
    first communicates with `product-service` in order to collect the details of the
    selected products, and then with `customer-service` to retrieve information about
    the customer and his accounts. Now, the orders sent to `order-service` will be
    processed asynchronously. There is still an exposed RESTful HTTP API endpoint
    for submitting new orders by the clients, but they are not processed by the application.
    It only saves new orders, sends it to a message broker, and then responds to the
    client that the order has been approved for processing. The main goal of the currently
    discussed example is to show a point-to-point communication, so the messages would
    be received by only one application, `account-service`. Here''s a diagram that
    illustrates the sample system architecture:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为介绍 Spring Cloud Stream 的主要特性的最适合方式是通过一个基于微服务的示例系统。我们将轻微修改一下在前几章中讨论过的系统架构。让我回顾一下那个架构。我们的系统负责处理订单。它由四个独立的微服务组成。`order-service`
    微服务首先与 `product-service` 通信，以收集所选产品的详细信息，然后与 `customer-service` 通信，以获取有关客户和他的账户的信息。现在，发送到
    `order-service` 的订单将被异步处理。仍然有一个暴露的 RESTful HTTP API 端点，用于客户端提交新订单，但它们不被应用程序处理。它只保存新订单，将其发送到消息代理，然后向客户端回应订单已被批准处理。目前讨论的示例的主要目标是展示点对点通信，所以消息只会被一个应用程序，`account-service`
    接收。以下是说明示例系统架构的图表：
- en: '![](img/6d470d32-4e38-49ef-a0b8-56cc3408ded5.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6d470d32-4e38-49ef-a0b8-56cc3408ded5.png)'
- en: After receiving a new message, `account-service` calls the method exposed by
    `product-service` in order to find out its price. It withdraws money from the
    account and then sends back the response to `order-service` with the current order
    status. That message is also sent through the message broker. The `order-service`
    microservice receives the message and updates the order status. If the external
    client would like to check the current status order, it may call the endpoint
    exposing the `find` method with the order details. The sample application's source
    code is available on GitHub ([https://github.com/piomin/sample-spring-cloud-messaging.git](https://github.com/piomin/sample-spring-cloud-messaging.git)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在接收到新消息后，`account-service` 调用 `product-service` 暴露的方法，以找出其价格。它从账户中提取资金，然后将当前订单状态的响应发送回
    `order-service`。该消息也是通过消息代理发送的。`order-service` 微服务接收到消息并更新订单状态。如果外部客户想要检查当前订单状态，它可以通过调用暴露
    `find` 方法的端点来提供订单详情。示例应用程序的源代码可以在 GitHub 上找到（[https://github.com/piomin/sample-spring-cloud-messaging.git](https://github.com/piomin/sample-spring-cloud-messaging.git)）。
- en: Enabling Spring Cloud Stream
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启用 Spring Cloud Stream
- en: 'The recommended way to include Spring Cloud Stream in the project is with a
    dependency management system. Spring Cloud Stream has an independent release trains
    management in relation to the whole Spring Cloud framework. However, if we have
    declared `spring-cloud-dependencies` in the `Edgware.RELEASE` version in the `dependencyManagement`
    section, we wouldn''t have to declare anything else in `pom.xml`. If you prefer
    to use only the Spring Cloud Stream project, you should define the following section:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Spring Cloud Stream 包含在项目中的推荐方法是使用依赖管理系统。Spring Cloud Stream 在整个 Spring Cloud
    框架方面有独立的发布列车管理。然而，如果我们已经在 `dependencyManagement` 部分声明了 `Edgware.RELEASE` 版本的 `spring-cloud-dependencies`，我们不必在
    `pom.xml` 中声明其他内容。如果您更喜欢只使用 Spring Cloud Stream 项目，您应该定义以下部分：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The next step is to add `spring-cloud-stream` to the project dependencies.
    I also recommend you include at least the `spring-cloud-sleuth` library to provide
    sending messaging with the same `traceId` as the source request incoming to `order-service`
    via the Zuul gateway:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是向项目依赖中添加 `spring-cloud-stream`。我还建议您至少包含 `spring-cloud-sleuth` 库，以提供与通过
    Zuul 网关传入 `order-service` 的源请求相同的 `traceId` 发送消息：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To enable connectivity to a message broker for your application, annotate the
    main class with `@EnableBinding`. The `@EnableBinding` annotation takes one or
    more interfaces as parameters. You may choose between three interfaces provided
    by Spring Cloud Stream:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使应用程序能够连接到消息代理，请用`@EnableBinding`注解标记主类。`@EnableBinding`注解需要一个或多个接口作为参数。您可以选择Spring
    Cloud Stream提供的三个接口之一：
- en: '`Sink`: This is used for marking a service that receives messages from the
    inbound channel.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Sink`：这用于标记接收来自入站通道消息的服务。'
- en: '`Source`: This is used for sending messages to the outbound channel.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Source`：用于向出站通道发送消息。'
- en: '`Processor`: This can be used in case you need both an inbound channel and
    an outbound channel, as it extends the `Source` and `Sink` interfaces. Because
    `order-service` sends messages, as well as receives them, its main class has been
    annotated with `@EnableBinding(Processor.class)`.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Processor`：如果您需要入站通道和出站通道，可以使用它，因为它扩展了`Source`和`Sink`接口。因为`order-service`发送消息，以及接收消息，所以它的主类被用`@EnableBinding(Processor.class)`注解标记。'
- en: 'Here''s the main class of `order-service` that enables Spring Cloud Stream
    binding:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`order-service`的`main`类，它启用了Spring Cloud Stream绑定：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Declaring and binding channels
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 声明和绑定通道
- en: 'Thanks to the use of Spring Integration, the application is independent from
    a message broker implementation included in the project. Spring Cloud Stream automatically
    detects and uses a binder found on the classpath. It means we may choose different
    types of middleware, and use it with the same code. All the middleware-specific
    settings can be overridden through external configuration properties in the form
    supported by Spring Boot, such as application arguments, environment variables,
    or just the `application.yml` file. As I have mentioned before, Spring Cloud Stream
    provides binder implementations for Kafka and Rabbit MQ. To include support for
    Kafka, you add the following dependency to the project:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 得益于Spring Integration的使用，应用程序与项目中包含的消息代理实现是独立的。Spring Cloud Stream会自动检测并使用类路径中找到的绑定器。这意味着我们可以选择不同类型的中间件，并用相同的代码使用它。所有中间件特定的设置都可以通过Spring
    Boot支持的格式（如应用程序参数、环境变量，或仅仅是`application.yml`文件）的外部配置属性来覆盖。正如我之前提到的，Spring Cloud
    Stream为Kafka和Rabbit MQ提供了绑定器实现。要包括对Kafka的支持，您需要将以下依赖项添加到项目中：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Personally, I prefer RabbitMQ, but in this chapter, we will create a sample
    for both RabbitMQ and Kafka. Since we have already discussed RabbitMQ''s features,
    I''ll begin with the samples based on RabbitMQ:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 个人而言，我更喜欢RabbitMQ，但在这章节，我们将为RabbitMQ和Kafka都创建一个示例。因为我们已经讨论过RabbitMQ的功能，我将从基于RabbitMQ的示例开始：
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'After enabling Spring Cloud Stream and including the binder implementation,
    we may create senders and listeners. Let''s begin with the producer responsible
    for sending new order messages to the broker. This is implemented by `OrderSender`
    in `order-service`, which uses the `Output` bean for sending messages:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在启用Spring Cloud Stream并包括绑定器实现之后，我们可以创建发送者和监听者。让我们从负责将新订单消息发送到代理的生产者开始。这通过`order-service`中的`OrderSender`实现，它使用`Output`bean来发送消息：
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'That bean is called by the controller, which exposes the HTTP method that allows
    submitting new orders:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这个bean被控制器调用，控制器暴露了一个允许提交新订单的HTTP方法：
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The message with information about the order has been sent to message broker.
    Now, it should be received by `account-service`. To make this happen, we have
    to declare the receiver, which is listening for messages incoming to the queue
    created on the message broker. To receive the message with the order data, we
    just have to annotate the method that takes the `Order` object as a parameter
    with `@StreamListener`:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 包含关于订单信息的消息已经发送到消息代理。现在，它应该被`account-service`接收。使这成为可能，我们必须声明接收者，它正在监听来自消息代理上创建的队列的消息。为了接收带有订单数据的消息，我们只需用`@StreamListener`注解来标记接受`Order`对象作为参数的方法：
- en: '[PRE7]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now you may launch the sample applications. But, there is one important detail
    that has not yet been mentioned. Both those applications try to connect with RabbitMQ
    running on localhost, and both of them treat the same exchanges as an input or
    output. It is a problem, since `order-service` sends the message to the output
    exchange, while `account-service` listens for messages incoming to its input exchange.
    These are different exchanges, but first things first. Let's begin with running
    a message broker.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以启动示例应用程序了。但是，还有一个重要细节尚未提到。这两个应用程序都尝试连接到运行在localhost上的RabbitMQ，并且它们都将相同的交换机作为输入或输出。这是一个问题，因为`order-service`将消息发送到输出交换机，而`account-service`监听其输入交换机传入的消息。这些是不同的交换机，但首先事情要一件一件来做。让我们先从运行一个消息代理开始。
- en: Customizing connectivity with the RabbitMQ broker
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用RabbitMQ代理自定义连接
- en: 'We have already started the RabbitMQ broker using its Docker image in the previous
    chapters, so it is worth reminding ourselves of that command. It starts a standalone
    Docker container with RabbitMQ, available under port `5672`, and its UI web console,
    available under port `15672`:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们已经使用RabbitMQ的Docker镜像启动了RabbitMQ代理，因此值得提醒这个命令。它启动了一个带有RabbitMQ的独立Docker容器，端口为`5672`，以及其UI网页控制台，端口为`15672`：
- en: '[PRE8]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The default RabbitMQ address should be overridden with the `spring.rabbit.*`
    properties inside the `application.yml` file:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的RabbitMQ地址应该在`application.yml`文件中使用`spring.rabbit.*`属性进行覆盖：
- en: '[PRE9]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'By default, Spring Cloud Stream creates a topic exchange for communication.
    This type of exchange better suits the publish/subscribe interaction model. We
    may override it with the `exchangeType` property, as in the fragment of `application.yml`,
    as shown here:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Spring Cloud Stream 为通信创建了一个主题交换机。这种类型的交换机更适合发布/订阅交互模型。我们可以使用`exchangeType`属性来覆盖它，如`application.yml`的片段所示：
- en: '[PRE10]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The same configuration settings should be provided for both `order-service`
    and `account-service`. You don''t have to create any exchange manually. If it
    does not exist, it is automatically created by the application during startup.
    Otherwise, the application just binds to that exchange. By default, it creates
    exchanges with names input for the `@Input` channel, and output for the `@Output`
    channel. These names may be overridden with the `spring.cloud.stream.bindings.output.destination`
    and `spring.cloud.stream.bindings.input.destination` properties, where input and
    output are the names of the channels. This configuration option is not just a
    nice addition to the Spring Cloud Stream features, but the key setting used for
    correlating the input and output destinations in inter-service communication.
    The explanation for why that happens is very simple. In our example, `order-service`
    is the message source application, so it sends messages to the output channel.
    Then, on the other hand, `account-service` listens for incoming messages on the
    input channel. If the `order-service` output channel and `account-service` input
    channel do not refer to the same destination on the broker, the communication
    between them would fail. In conclusion, I decided to use a destination with the
    names `orders-out` and `orders-in`, and I have provided the following configuration
    for `order-service`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的配置设置应该提供给`order-service`和`account-service`。您不需要手动创建任何交换机。如果不存在，应用程序在启动时会自动创建。否则，应用程序只是绑定到该交换机。默认情况下，它为`@Input`通道创建名为input的交换机，为`@Output`通道创建名为output的交换机。这些名称可以通过`spring.cloud.stream.bindings.output.destination`和`spring.cloud.stream.bindings.input.destination`属性进行覆盖，其中input和output是通道的名称。这个配置选项不仅仅是Spring
    Cloud Stream功能的一个很好的补充，而且是用于跨服务通信中关联输入和输出目的地的一个关键设置。解释为什么会出现这种情况非常简单。在我们的示例中，`order-service`是消息源应用程序，因此它将消息发送到输出通道。另一方面，`account-service`监听输入通道传入的消息。如果`order-service`输出通道和`account-service`输入通道不指向代理上的相同目的地，它们之间的通信将失败。总之，我决定使用名为`orders-out`和`orders-in`的目标，并为`order-service`提供了以下配置：
- en: '[PRE11]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The similar configuration settings for `account-service` are reversed:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`account-service`，类似的配置设置是反向的：
- en: '[PRE12]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'After both applications start up, you may easily check out the list of exchanges
    declared on the RabbitMQ broker using its web management console, available at `http://192.168.99.100:15672`
    (`quest`/`guest`). The following the implicitly created exchanges, and you may
    see our two destinations created for the test purpose:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 两个应用程序启动后，您可以通过访问 `http://192.168.99.100:15672`（`quest`/`guest`）的RabbitMQ代理的Web管理控制台，轻松查看声明的交换机列表。以下是为测试目的创建的两个目的地：
- en: '![](img/972692ab-4ae9-4f45-ab16-7987f69b003a.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/972692ab-4ae9-4f45-ab16-7987f69b003a.png)'
- en: By default, Spring Cloud Stream provides one input and one output message channel.
    We may imagine a situation where our system would need more than one destination
    for each type of message channel. Let's move back to the sample system architecture
    for a moment, and consider the situation where every order is asynchronously processed
    by two other microservices. Until now, only `account-service` has been listening
    for incoming events from `order-service`. In the current sample, `product-service`
    would be the receiver of incoming orders. Its main goal in that scenario is to
    manage the number of available products and decrease them on the basis of order
    details. It requires us to define two input and output message channels inside
    `order-service`, because we still have point-to-point communication based on a
    direct RabbitMQ exchange, where each message may be processed by exactly one consumer.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Spring Cloud Stream 提供了一个输入消息通道和一个输出消息通道。我们可以想象一种情况，我们的系统需要为每种类型的消息通道设置多个目的地。让我们回到示例系统架构中一会儿，考虑每个订单都由两个其他微服务异步处理的情况。到目前为止，只有
    `account-service` 在监听来自 `order-service` 的传入事件。在当前示例中，`product-service` 将是传入订单的接收者。在该场景中，其主要目标是管理可用产品的数量，并根据订单详情减少产品数量。它需要我们在
    `order-service` 内部定义两个输入和输出消息通道，因为基于直接RabbitMQ交换的点对点通信，每个消息可能由一个消费者处理。
- en: 'In that case, we should declare two interfaces with `@Input` and `@Output`
    methods. Every method has to return a `channel` object. Spring Cloud Stream provides
    two bindable message components—`MessageChannel` for an outbound communication,
    and its extension, `SubscribableChannel`, for an inbound communication. Here''s
    the interface definition for interaction with `product-service`. The analogous
    interface has been created for messaging with `account-service`:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们应该声明两个带有 `@Input` 和 `@Output` 方法的接口。每个方法都必须返回一个 `channel` 对象。Spring
    Cloud Stream 为出站通信提供了一个可绑定消息组件——`MessageChannel`，以及其扩展，`SubscribableChannel`，用于入站通信。以下是与
    `product-service` 交互的接口定义。已经为与 `account-service` 消息通信创建了类似接口：
- en: '[PRE13]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The next step is to activate the declared components for the application by
    annotating its main class with `@EnableBinding(value={AccountOrder.class, ProductOrder.class}`.
    Now, you may refer to these channels in the configuration properties using their
    names, for example, `spring.cloud.stream.bindings.productOrdersOut.destination=product-orders-in`.
    Each channel name may be customized by specifying a channel name when using the
    `@Input` and `@Output` annotations, as shown in the following example:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是通过对主类使用 `@EnableBinding(value={AccountOrder.class, ProductOrder.class})`
    注解来激活应用程序中声明的组件。现在，您可以使用它们的名称在配置属性中引用这些通道，例如，`spring.cloud.stream.bindings.productOrdersOut.destination=product-orders-in`。每个通道名称可以通过在使用
    `@Input` 和 `@Output` 注解时指定通道名称来自定义，如下例所示：
- en: '[PRE14]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Based on the custom interfaces declaration, Spring Cloud Stream will generate
    a bean that implements that interface. However, it still has to be accessed in
    the bean responsible for sending the message. In comparison with the previous
    sample, it would be more comfortable to inject bound channels directly. Here''s
    the current product order sender''s bean implementation. There is also a similar
    implementation of the bean, which sends messages to `account-service`:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 基于自定义接口的声明，Spring Cloud Stream 将生成实现该接口的bean。但是，它仍然必须在负责发送消息的bean中被访问。与之前的示例相比，直接注入绑定通道会更方便。以下是当前产品订单发送者的bean实现。还有一个类似的实现，用于向
    `account-service` 发送消息：
- en: '[PRE15]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Every message-channel custom interface should also be provided for the target
    service. The listener should be bound to the right message channel and the destination
    on the message broker:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 每个消息通道的自定义接口也应提供给目标服务。监听器应绑定到消息代理上的正确消息通道和目的地：
- en: '[PRE16]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Integration with other Spring Cloud projects
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与其他Spring Cloud项目的集成
- en: 'You have probably noticed that the sample system mixes different styles of
    inter-service communication. There are some microservices that use typical RESTful
    HTTP API, and some others that use the message broker. There are also no objections
    to mixing different styles of communication inside a single application. You may,
    for example, include `spring-cloud-starter-feign` to the project with Spring Cloud
    Stream, and enable it with the `@EnableFeignClients` annotation. In our sample
    system, those two different styles of communication combine `account-service`,
    which integrates with `order-service` via the message broker, and with `product-service`
    through the REST API. Here''s the Feign client''s `product-service` implementation
    inside the `account-service` module:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，示例系统混合了不同的服务间通信风格。有些微服务使用典型的RESTful HTTP API，而其他的则使用消息代理。也没有反对在单个应用程序中混合不同的通信风格。例如，你可以将`spring-cloud-starter-feign`添加到带有Spring
    Cloud Stream的项目中，并用`@EnableFeignClients`注解启用它。在我们的示例系统中，这两种不同的通信风格结合了`account-service`，它通过消息代理与`order-service`集成，并通过REST
    API与`product-service`通信。以下是`account-service`模块中`product-service`的Feign客户端实现：
- en: '[PRE17]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: There is other good news. Thanks to Spring Cloud Sleuth, all the messages exchanged
    during a single request incoming to the system via a gateway have the same `traceId`.
    Whether it is synchronous REST communication, or asynchronous messaging, you may
    easily track and correlate the logs between microservices using standard log files,
    or log aggregator tools such as Elastic Stack.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他好消息。得益于Spring Cloud Sleuth，通过网关进入系统的一个单一请求期间交换的所有消息都有相同的`traceId`。无论是同步的REST通信，还是异步的消息传递，你都可以很容易地使用标准日志文件，或像Elastic
    Stack这样的日志聚合工具，在微服务之间跟踪和关联日志。
- en: 'I think now is a good time to run and test our sample system. First, we have
    to build the whole project with the `mvn clean install` command. To access the
    code sample with two microservices listening for messages on two different exchanges,
    you should switch to the `advanced` branch ([https://github.com/piomin/sample-spring-cloud-messaging/tree/advanced](https://github.com/piomin/sample-spring-cloud-messaging/tree/advanced)).
    You should launch all the applications available there—gateway, discovery, and
    the three microservices (`account-service`, `order-service`, `product-service`).
    The currently discussed case assumes we have also started RabbitMQ, Logstash,
    Elasticsearch, and Kibana using its Docker container. For detailed instructions
    on how to run Elastic Stack locally using Docker images, refer to [Chapter 9](a84b38a5-4a2f-4e4b-a7fe-6396a2864021.xhtml),
    *Distributed Logging and Tracing*. The following diagram shows the architecture
    of the system in detail:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为现在是一个运行和测试我们的示例系统的好时机。首先，我们必须使用`mvn clean install`命令构建整个项目。要访问包含两个微服务，分别在两个不同的交换机上监听消息的代码示例，你应该切换到`advanced`分支([https://github.com/piomin/sample-spring-cloud-messaging/tree/advanced](https://github.com/piomin/sample-spring-cloud-messaging/tree/advanced)).
    你应该启动那里所有的应用程序——网关、发现以及三个微服务(`account-service`, `order-service`, `product-service`)。目前讨论的案例假设我们已经使用Docker容器启动了RabbitMQ、Logstash、Elasticsearch和Kibana。关于如何使用Docker镜像在本地运行Elastic
    Stack的详细说明，请参考[第9章](a84b38a5-4a2f-4e4b-a7fe-6396a2864021.xhtml)，*分布式日志和跟踪*。下面的图表详细显示了系统的架构：
- en: '![](img/1a3ef3e9-bd8e-45fb-8b75-b8050e1e4560.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1a3ef3e9-bd8e-45fb-8b75-b8050e1e4560.png)'
- en: 'After running all the required applications and tools, we may proceed to the
    tests. Here''s the sample request, which can be sent to the `order-service` via
    the API gateway:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行所有必要的应用程序和工具后，我们可以进行测试。以下是可以通过API网关发送到`order-service`的示例请求：
- en: '[PRE18]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'When I run the test for the first time with the applications configured following
    the description in the previous sections, it doesn''t work. I can understand that
    some of you may be confused a little, because generally it was tested on the default
    settings. To make it run properly, I also have to add the following property in
    `application.yml`: `spring.cloud.stream.rabbit.bindings.output.producer.routingKeyExpression:
    ''"#"''`. It sets the default producer''s routing key to conform with the exchange''s
    routing key automatically created during the application boot. In the following
    screenshot, you may see one of the output exchange definitions:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '当我第一次运行测试时，按照前几节的描述配置应用程序，它不起作用。我可以理解，你们中的一些人可能会有些困惑，因为通常它是用默认设置进行测试的。为了使其正常运行，我还需要在`application.yml`中添加以下属性：`spring.cloud.stream.rabbit.bindings.output.producer.routingKeyExpression:
    ''"#"''`. 它将默认生产者的路由键设置为自动在应用程序启动期间创建的交换机路由键，以符合输出交换定义。在下面的屏幕截图中，你可以看到输出交换定义之一：'
- en: '![](img/d568e23a-9c65-4fb4-beb0-483c8755debb.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d568e23a-9c65-4fb4-beb0-483c8755debb.png)'
- en: 'After the modification described previously, the test should be concluded successfully.
    The logs printed by the microservices are correlated with each other by `traceId`.
    I modified the default Sleuth logging format in `logback-spring.xml` a little,
    and that''s how it is configured now—`%d{HH:mm:ss.SSS} %-5level [%X{X-B3-TraceId:-},%X{X-B3-SpanId:-}]
    %msg%n`. After sending the test request `order-service` test request, log the
    following information:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面描述的修改之后，测试应该成功完成。微服务打印的日志通过 `traceId` 相互关联。我在 `logback-spring.xml` 中稍微修改了默认的
    Sleuth 日志格式，现在它是这样配置的——`%d{HH:mm:ss.SSS} %-5level [%X{X-B3-TraceId:-},%X{X-B3-SpanId:-}]
    %msg%n`。在发送 `order-service` 测试请求后，记录以下信息：
- en: '[PRE19]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'As you can see, `account-service` also uses the same logging format and prints
    the same `traceId` as `order-service`:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，`account-service` 也使用相同的日志格式，并打印出与 `order-service` 相同的 `traceId`：
- en: '[PRE20]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'All the logs generated during the single transaction can be aggregated using
    Elastic Stack. You may filter the entries by the `X-B3-TraceId` field, for example,
    `9da1e5c83094390d`:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在单个事务期间生成的所有日志可以使用 Elastic Stack 进行聚合。例如，您可以根据 `X-B3-TraceId` 字段过滤条目，例如 `9da1e5c83094390d`：
- en: '![](img/a2061976-3bb0-4367-ba21-2b8b76e7e2b4.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a2061976-3bb0-4367-ba21-2b8b76e7e2b4.png)'
- en: The publish/subscribe model
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发布/订阅模型
- en: The main motivation for creating a Spring Cloud Stream project is, in fact,
    support for a persistent publish/subscribe model. In the previous sections, we
    have discussed point-to-point communication between microservices, which is just
    an additional feature. However, the programming model is still the same, irrespective
    of whether we decided to use a point-to-point or publish/subscribe model.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 Spring Cloud Stream 项目的主要动机实际上是为了支持持久的发布/订阅模型。在前面的部分，我们已经讨论了微服务之间的点对点通信，这只是额外的特性。然而，无论我们决定使用点对点还是发布/订阅模型，编程模型都是相同的。
- en: In publish/subscribe communication, the data is broadcast through shared topics.
    It reduces the complexity of both the producer and the consumer, and allows new
    applications to be easily added to the existing topology without any changes in
    flow. This can be clearly seen in the last-presented sample of the system, where
    we decided to add the second application that has consumed events produced by
    the source microservice. In comparison to the initial architecture, we had to
    define custom message channels dedicated for each of the target applications.
    With direct communication through queues, the message can be consumed by only
    one application instance, so as such, the solution was necessary. The uses of
    the publish/subscribe model simplify that architecture.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在发布/订阅通信中，数据通过共享主题进行广播。它简化了生产者和消费者的复杂性，并且允许在没有更改流程的情况下，轻松地向现有拓扑添加新应用程序。这一点在前面展示的系统示例中可以明显看到，我们决定向由源微服务生成的事件添加第二个应用程序。与初始架构相比，我们不得不为每个目标应用程序定义自定义消息通道。通过队列进行直接通信，消息只能被一个应用程序实例消费，因此，这种解决方案是必要的。发布/订阅模型的使用简化了架构。
- en: Running a sample system
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行示例系统
- en: 'The development of the sample application is simpler for the publish/subscribe
    model than for point-to-point communication. We don''t have to override any default
    message channels to enable interaction with more than one receiver. In comparison
    with the initial sample that has illustrated messaging to a single target application
    (`account-service`), we only need to modify configuration settings a little. Because
    Spring Cloud Stream, by default, binds to the topic, we don''t have to override
    `exchangeType` for the input message channel. As you may see in the configuration
    fragment that follows, we still use point-to-point communication when sending
    the response to `order-service`. If we really think about it, that makes sense.
    The  `order-service` microservice sends the message that has to be received by
    both `account-service` and `product-service`, while the response from them is
    addressed only to `order-service`:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 对于发布/订阅模型，示例应用程序的开发比点对点通信要简单。我们不需要重写任何默认消息通道以实现与多个接收者的交互。与最初示例相比，我们只需要稍改配置设置。因为
    Spring Cloud Stream 默认绑定到主题，所以我们不需要重写输入消息通道的 `exchangeType`。如您在下面的配置片段中所见，我们仍然在使用点对点通信发送对
    `order-service` 的响应。如果我们仔细想想，这是有道理的。`order-service` 微服务发送的消息必须被 `account-service`
    和 `product-service` 接收，而它们的响应只针对 `order-service`：
- en: '[PRE21]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The logic of the main processing method of `product-service` is really simple.
    It just has to find all the `productIds` from the received order, change the number
    of stored products for every one of them, and then send the response to `order-service`:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 产品-服务的主要处理方法的逻辑非常简单。它只需要从接收到的订单中找到所有的`productIds`，为每一个它们改变存储产品的数量，然后将响应发送给`order-service`：
- en: '[PRE22]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: To access the current sample, you just have to switch to the  `publish_subscribe` branch,
    available at [https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe](https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe).
    Then, you should build the parent project and run all the services as for the
    previous sample. If you would like to test it all works fine until you have only
    one running instance of `account-service` and `product-service`. Let's discuss
    that problem.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问当前示例，您只需切换到`publish_subscribe`分支，可在[https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe](https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe)找到。然后，您应该构建父项目并像前一个示例一样运行所有服务。如果您想测试，直到您只有一个运行的`account-service`和`product-service`实例，所有都正常工作。让我们来讨论那个问题。
- en: Scaling and grouping
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展和分组
- en: When talking about microservice-based architecture, scalability is always presented
    as one of its main advantages. The ability to scale up the system by creating
    multiple instances of a given application is very important. When doing this,
    different instances of an application are placed in a competing consumer relationship,
    where only one of the instances is expected to handle a given message. For point-to-point
    communication, it is not a problem, but in a publish-subscribe model, where the
    message is consumed by all the receivers, it may be a challenge.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈论基于微服务的架构时，可扩展性总是作为其主要优点之一被提出。通过创建给定应用程序的多个实例来扩展系统的能力非常重要。这样做时，应用程序的不同实例被放置在竞争性消费者关系中，其中只有一个实例预期处理给定消息。对于点对点通信，这不是问题，但在发布-订阅模型中，消息被所有接收者消费，这可能是一个挑战。
- en: Running multiple instances
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行多个实例
- en: Availability for scaling up the number of microservice's instances is one of
    the main concepts around Spring Cloud Stream. However, there is no magic behind
    this idea. Running multiple instances of an application is very easy with Spring
    Cloud Stream. One of the reasons for this is native support from message brokers,
    which is designed to handle many consumers and huge amounts of traffic.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于扩展微服务实例的数量，Spring Cloud Stream的可用性是围绕其主要概念之一。然而，这个想法背后并没有魔法。使用Spring Cloud
    Stream运行应用程序的多个实例非常容易。其中一个原因是消息代理的原生支持，它被设计用来处理许多消费者和大量流量。
- en: 'In our case, all the messaging microservices also expose the RESTful HTTP API,
    so first, we have to customize the server port per instance. We have performed
    such operations before. We may also consider setting two Spring Cloud Stream properties,
    `spring.cloud.stream.instanceCount` and `spring.cloud.stream.instanceIndex`. Thanks
    to them, every instance of the microservice is able to receive information about
    how many other examples of the same application are started and what is its own
    instance index. The correct configuration of these properties is required only
    if you would like to enable the partitioning feature. I''ll talk about this mechanism
    more in a moment. Now, let''s take a look at the configuration settings of the
    scaled-up applications. Both `account-service` and `product-service` define two
    profiles for the purpose of running multiple instances of the application. We
    have customized there an HTTP port of the server, number, and an index of the
    instance:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，所有的消息微服务也都暴露了RESTful HTTP API，因此首先我们必须为每个实例定制服务器端口。我们之前已经进行了这样的操作。我们还可以考虑设置两个Spring
    Cloud Stream属性，`spring.cloud.stream.instanceCount`和`spring.cloud.stream.instanceIndex`。得益于它们，每个微服务实例都能够接收到关于有多少其他相同应用程序的实例被启动以及它自己的实例索引的信息。只有在您想要启用分区特性时，才需要正确配置这些属性。我稍后会详细讲解这个机制。现在，让我们来看看扩展应用程序的配置设置。`account-service`和`product-service`都为运行应用程序的多个实例定义了两个配置文件。我们在那里定制了服务器的HTTP端口、数量和实例索引：
- en: '[PRE23]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: After building the parent project, you may run two instances of the application.
    Each of them is initialized with properties assigned to the right profile passed
    during startup, for example, `java -jar --spring.profiles.active=instance1 target/account-service-1.0-SNAPSHOT.jar`.
    If you send a test request to the `order-service` endpoint `POST /`, the new order
    would be forwarded to the RabbitMQ topic exchange in order to be received by both
    the `account-service` and `product-service`, which are connected to that exchange.
    The problem is that the message is received by all the instances of each service,
    which is not exactly what we wanted to achieve. Here, a grouping mechanism comes
    with help.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 构建父项目后，您可以运行应用程序的两个实例。每个实例在启动时都分配有属性，例如，`java -jar --spring.profiles.active=instance1
    target/account-service-1.0-SNAPSHOT.jar`。如果您向`order-service`端点`POST /`发送测试请求，新订单将被转发到RabbitMQ主题交换，以便被连接到该交换的`account-service`和`product-service`接收。问题在于，消息被每个服务的所有实例接收，这并不是我们想要实现的效果。在这里，分组机制提供了帮助。
- en: Consumer groups
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消费者组
- en: Our purpose is clear. We have many microservices that consume messages from
    the same topic. Different instances of an application are placed in a competing
    consumer relationship, but only one of them should handle a given message. Spring
    Cloud Stream introduces the concept of a consumer group that models this behavior.
    To activate such a behavior, we should set a property called `spring.cloud.stream.bindings.<channelName>.group`,
    with a group name. After setting it, all groups that subscribe to a given destination
    receive a copy of the published data, but only one member of each group receives
    and handles a message from that destination. In our case, there are two groups.
    First, for all the `account-service` instances with a name account, and second,
    for a `product-service` with a name product.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标很明确。我们有多个微服务消费同一个主题的消息。应用程序的不同实例处于竞争性消费者关系中，但只有一个实例应该处理给定的消息。Spring Cloud
    Stream引入了消费者组的概念来模拟这种行为。要激活这种行为，我们应该设置一个名为`spring.cloud.stream.bindings.<channelName>.group`的属性，并指定一个组名。设置后，所有订阅给定目的地的组都会接收到发布的数据副本，但每个组中只有一个成员会从那个目的地接收并处理消息。在我们这个案例中，有两个组。首先，为所有`account-service`实例命名account，其次，为名为product的`product-service`。
- en: 'Here''s the current binding configuration for `account-service`. The `orders-in`
    destination is a queue created for direct communication with `order-service`,
    so only `orders-out` is grouped by service name. An analogous configuration has
    been prepared for `product-service`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`account-service`当前的绑定配置。`orders-in`目的地是为与`order-service`直接通信而创建的队列，所以只有`orders-out`按服务名称分组。为`product-service`准备了类似的配置：
- en: '[PRE24]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The first difference is visible in the names of queues automatically created
    for the RabbitMQ exchange. Now, it is not a randomly generated name, such as `orders-in.anonymous.qNxjzDq5Qra-yqHLUv50PQ`,
    but a determined string consisting of the destination and group name. The following
    screenshot shows all the queues currently existing on RabbitMQ:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个区别体现在为RabbitMQ交换自动创建的队列的名称上。现在，它不是一个随机生成的名称，如`orders-in.anonymous.qNxjzDq5Qra-yqHLUv50PQ`，而是一个由目的地和组名组成的确定字符串。下面的屏幕截图显示了目前在RabbitMQ上存在的所有队列：
- en: '![](img/ea66ddab-9c35-40be-9bb6-9b858aa41305.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ea66ddab-9c35-40be-9bb6-9b858aa41305.png)'
- en: You may perform the retest by yourself to verify if the message is received
    by only one application in the same group. However, you have no confidence which
    instance would handle the incoming message. In order to determine this, you can
    use a partitioning mechanism.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以自行重新测试以验证消息是否仅被同一组中的一个应用程序接收。然而，您无法确定哪个实例会处理传入的消息。为了确定这一点，您可以使用分区机制。
- en: Partitioning
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分区
- en: Spring Cloud Stream provides support for partitioning data between multiple
    instances of an application. In the typical use case, the destination is viewed
    as being divided into different partitions. Each producer, when sending messages
    received by multiple consumer instances, ensures that data is identified by configured
    fields to force processing by the same consumer instance.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream为应用程序的多个实例之间的数据分区提供了支持。在典型用例中，目的地被视为被分成不同的分区。每个生产者，在向多个消费者实例发送消息时，确保数据通过配置的字段来标识，以强制由同一个消费者实例处理。
- en: 'To enable the partitioning feature for your application, you have to define
    the `partitionKeyExpression` or `partitionKeyExtractorClass` properties, and `partitionCount`
    in the producer configuration settings. Here''s the sample configuration that
    may be provided for your application:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为了启用您应用程序的分区功能，您必须在生产者配置设置中定义`partitionKeyExpression`或`partitionKeyExtractorClass`属性，以及`partitionCount`。以下是为您的应用程序可能提供的示例配置：
- en: '[PRE25]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Partitioning mechanisms also require setting of the `spring.cloud.stream.instanceCount`
    and `spring.cloud.stream.instanceIndex` properties on the consumer side. It also
    has to be explicitly enabled with the `spring.cloud.stream.bindings.input.consumer.partitioned`
    property set to `true`. The instance index is responsible for identifying the
    unique partition from which a particular instance receives data. Generally, `partitionCount`
    on the producer side and `instanceCount` on the consumer side should be equal.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 分区机制还需要在消费者侧设置`spring.cloud.stream.instanceCount`和`spring.cloud.stream.instanceIndex`属性。它还需要通过将`spring.cloud.stream.bindings.input.consumer.partitioned`属性设置为`true`来显式启用。实例索引负责识别特定实例从哪个唯一分区接收数据。通常，生产者侧的`partitionCount`和消费者侧的`instanceCount`应该相等。
- en: Let me familiarize you with the partitioning mechanism provided by Spring Cloud
    Stream. First, it calculates a partition key based on `partitionKeyExpression`,
    which is evaluated against the outbound message or implementation of the `PartitionKeyExtractorStrategy`
    interface, which defines the algorithm for extracting the key for the message.
    Once the message key is calculated, the target partition is determined as a value
    between zero and `partitionCount - 1`. The default calculation formula is `key.hashCode()
    % partitionCount`. It can be customized with the `partitionSelectorExpression`
    property, or by creating an implementation of the `org.springframework.cloud.stream.binder.PartitionSelectorStrategy`
    interface. The calculated key is matched with `instanceIndex` on the consumer
    side.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我来向您介绍由Spring Cloud Stream提供的分区机制。首先，它根据`partitionKeyExpression`计算分区键，该表达式针对出站消息或实现`PartitionKeyExtractorStrategy`接口的实现进行评估，该接口定义了提取消息键的算法。一旦计算出消息键，目标分区就被确定为零到`partitionCount
    - 1`之间的一个值。默认的计算公式是`key.hashCode() % partitionCount`。可以通过设置`partitionSelectorExpression`属性，或通过实现`org.springframework.cloud.stream.binder.PartitionSelectorStrategy`接口来定制它。计算出的键与消费者侧的`instanceIndex`相匹配。
- en: 'I think that the main concept around partitioning has been explained. Let''s
    proceed to the sample. Here''s the current configuration of the input channel
    for `product-service` (the same as with the account group name set for `account-service`):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为分区的主要概念已经解释清楚了。接下来让我们看一个示例。以下是`product-service`的输入通道当前的配置（与`account-service`设置账户组名相同）：
- en: '[PRE26]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We have two running instances of each microservice that consumes data from the
    topic exchange. There are also two partitions set for the producer within `order-service`.
    The message key is calculated based on the `customerId` field from the `Order`
    object. The partition with index `0` is dedicated for orders having an even number
    in the `customerId` field, while the partition with index `1` is for odd numbers
    in the `customerId` field.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们每个从主题交换中消费数据的微服务中，都有两个运行实例。在`order-service`内部也为生产者设置了两个分区。消息键是基于`Order`对象中的`customerId`字段计算得出的。索引为`0`的分区专门用于`customerId`字段中偶数的订单，而索引为`1`的分区则用于奇数。
- en: 'In fact, RabbitMQ does not have native support for partitioning. It is interesting
    how Spring Cloud Stream implements the partitioning process with RabbitMQ. Here''s
    a screenshot that illustrates the list of bindings for exchanges created in RabbitMQ.
    As you may see, there are two routing keys that have been defined for the exchange—`orders-out-0`
    and `orders-out-1`:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，RabbitMQ并没有对分区提供原生支持。有趣的是，Spring Cloud Stream是如何使用RabbitMQ实现分区过程的。下面是一张说明在RabbitMQ中创建的交换器绑定的列表的屏幕截图。正如你所看到的，为交换器定义了两个路由键——`orders-out-0`和`orders-out-1`：
- en: '![](img/e699f2a7-dbb7-46fd-bb9d-3b1952b257c6.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e699f2a7-dbb7-46fd-bb9d-3b1952b257c6.png)'
- en: 'If you send an order with `customerId` equal to 1 in a JSON message, for example,
    `{"customerId": 1,"productIds": [4],"status": "NEW"}`, it would always be processed
    by an instance with `instanceIndex=1`. It may be checked out in the application
    logs or by using the RabbitMQ web console. Here''s a diagram with the message
    rates for each queue, where the message with `customerId=1` has been sent several
    times:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '例如，如果你在一个JSON消息中发送一个`customerId`等于1的订单，例如`{"customerId": 1,"productIds": [4],"status":
    "NEW"}`，它总是会由`instanceIndex=1`的实例处理。可以通过应用程序日志或使用RabbitMQ网页控制台进行检查。下面是一个每个队列的消息率的图表，其中`customerId=1`的消息已经发送了几次：'
- en: '![](img/683097cd-7210-4c3b-973c-bea138878ac4.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/683097cd-7210-4c3b-973c-bea138878ac4.png)'
- en: Configuration options
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置选项
- en: Spring Cloud Stream configuration settings may be overridden using any mechanism
    supported by Spring Boot, such as application arguments, environment variables,
    and YAML or property files. It defines a number of generic configuration options that
    may be applied to all binders. However, there are also some additional properties specific
    for a particular message broker used by the application.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream的配置设置可以通过Spring Boot支持的任何机制进行覆盖，例如应用程序参数、环境变量以及YAML或属性文件。它定义了一系列通用的配置选项，可以应用于所有绑定器。然而，还有一些特定于应用程序使用的消息代理的其他属性。
- en: Spring Cloud Stream properties
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spring Cloud Stream属性
- en: 'The current group of properties applies to the whole Spring Cloud Stream application.
    All the following properties are prefixed with  `spring.cloud.stream`:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当前组的属性适用于整个Spring Cloud Stream应用程序。以下所有属性都带有`spring.cloud.stream`前缀：
- en: '| Name | Default value | Description |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 默认值 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `instanceCount` | `1` | The number of running instances of an application.
    For more details, refer to the *Scaling and grouping* section. |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| `instanceCount` | `1` | 应用程序正在运行的实例数量。有关详细信息，请参阅*扩展和分组*部分。 |'
- en: '| `instanceIndex` | `0` | The index of the instance of the application. For
    more details, also refer to the *Scaling and grouping* section. |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| `instanceIndex` | `0` | 应用程序的实例索引。有关详细信息，请参阅*扩展和分组*部分。 |'
- en: '| `dynamicDestinations` | - | A list of destinations that can be bound dynamically.
    |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| `dynamicDestinations` | - | 可以动态绑定的目的地列表。 |'
- en: '| `defaultBinder` | - | The default binder in case there are multiple binders
    defined. For more details, also refer to the *Multiple binders* section. |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| `defaultBinder` | - | 如果有多个绑定器定义，则使用的默认绑定器。有关详细信息，请参阅*多个绑定器*部分。 |'
- en: '| `overrideCloudConnectors` | `false` | This is used only if the cloud is active
    and Spring Cloud Connectors is found on the classpath. When it is set to `true`, binders
    completely ignore the bound services and rely on the `spring.rabbitmq.*` or `spring.kafka.*` Spring
    Boot properties. |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| `overrideCloudConnectors` | `false` | 仅当云处于活动状态且Spring Cloud Connectors在类路径上时才使用。当设置为`true`时，绑定器完全忽略已绑定的服务，并依赖于`spring.rabbitmq.*`或`spring.kafka.*`的Spring
    Boot属性。 |'
- en: Binding properties
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绑定属性
- en: 'The next group of properties is related to a message channel. In Spring Cloud
    nomenclature, these are binding properties. They may be assigned only to a consumer,
    a producer, or to both simultaneously. Here is a list of the properties, along
    with their default value and a description:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 下一组属性与消息通道有关。在Spring Cloud命名法中，这些是绑定属性。它们只能分配给消费者、生产者，或同时分配给两者。以下是这些属性及其默认值和描述：
- en: '| Name | Default value | Description |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 默认值 | 描述 |'
- en: '| `destination` | - | The target destination name on the broker configured
    for the message channel. It can be specified as a comma-separated list of destinations
    if the channel is used by only one consumer. |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| `destination` | - | 配置为消息通道的消息代理的目标目的地名称。如果通道只被一个消费者使用，它可以被指定为以逗号分隔的目的地列表。
    |'
- en: '| `group` | `null` | The consumer group of the channel. See the *Scaling and
    grouping* section for more details. |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| `group` | `null` | 通道的消费者组。有关详细信息，请参阅*扩展和分组*部分。 |'
- en: '| `contentType` | `null` | The content type of messages exchanged via a given
    channel. We may set it, for example, to `application/json`. Then all the objects
    sent from that application would be automatically converted to a JSON string.
    |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| `contentType` | `null` | 给定通道上交换消息的内容类型。例如，我们可以将其设置为`application/json`。然后，从该应用程序发送的所有对象都会自动转换为JSON字符串。
    |'
- en: '| `binder` | `null` | The default binder used by the channel. See the *Multiple
    binders* section for more details. |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| `binder` | `null` | 通道使用的默认绑定器。有关详细信息，请参阅*多个绑定器*部分。 |'
- en: The consumer
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消费者
- en: 'The following list of properties is available for input bindings only, and
    must be prefixed with `spring.cloud.stream.bindings.<channelName>.consumer`. I''ll
    indicate just the most important of them:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的属性列表仅适用于输入绑定，并且必须以`spring.cloud.stream.bindings.<channelName>.consumer`为前缀。我将只指示其中最重要的几个：
- en: '| **Name** | **Default value** | **Description** |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **默认值** | **描述** |'
- en: '| --- | --- | --- |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `concurrency` | `1` | Number of consumers per single input channel |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| `concurrency` | `1` | 每个单一输入通道的消费者数量 |'
- en: '| `partitioned` | `false` | It enables receiving data from a partitioned producer
    |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| `partitioned` | `false` | 它使能够从分区生产者接收数据 |'
- en: '| `headerMode` | `embeddedHeaders` | If it is set to `raw`, header parsing
    on input is disabled |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| `headerMode` | `embeddedHeaders` | 如果设置为`raw`，则禁用输入上的头部解析 |'
- en: '| `maxAttempts` | `3` | Number of retries if message processing fails. Setting
    this option to `1` disables the retry mechanism |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| `maxAttempts` | `3` | 如果消息处理失败，则重试的次数。将此选项设置为`1`将禁用重试机制 |'
- en: The producer
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产者
- en: 'The following binding properties are available for output bindings only, and
    must be prefixed with `spring.cloud.stream.bindings.<channelName>.producer`. I''ll
    also indicate only the most important of them:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的属性绑定仅适用于输出绑定，并且必须以`spring.cloud.stream.bindings.<channelName>.producer`为前缀。我也会只指示其中最重要的几个：
- en: '| **Name** | **Default value** | **Description** |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **默认值** | **描述** |'
- en: '| `requiredGroups` | - | A comma-separated list of groups that must be created
    on the message broker |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| `requiredGroups` | - | 必须在与消息代理上创建的分隔的组列表 |'
- en: '| `headerMode` | `embeddedHeaders` | If it is set to `raw`, header parsing
    on input is disabled |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| `headerMode` | `embeddedHeaders` | 如果设置为`raw`，则禁用输入上的头部解析 |'
- en: '| `useNativeEncoding` | `false` | If it is set to `true`, the outbound message
    is serialized directly by the client library |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| `useNativeEncoding` | `false` | 如果设置为`true`，则出站消息由客户端库直接序列化 |'
- en: '| `errorChannelEnabled` | `false` | If it is set to `true`, failure messages
    are sent to the error channel for the destination |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| `errorChannelEnabled` | `false` | 如果设置为`true`，则将失败消息发送到目的地的错误通道 |'
- en: The advanced programming model
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级编程模型
- en: The basics around the Spring Cloud Stream programming model have been presented
    together with samples of point-to-point and publish/subscribe communication. Let's
    discuss some more advanced example features.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream编程模型的基础知识已经介绍过了，还包括点对点和发布/订阅通信的示例。让我们讨论一些更高级的示例特性。
- en: Producing messages
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发送消息
- en: 'In all the samples presented in this chapter, we have sent orders through RESTful
    API for testing purposes. However, we may easily create some test data by defining
    the message source inside the application. Here''s a bean that generates one message
    per second using `@Poller` and sends it to the output channel:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中 presented的所有示例中，我们通过RESTful API发送订单以进行测试。然而，我们很容易通过在应用程序内部定义消息源来创建一些测试数据。下面是一个使用`@Poller`每秒生成一条消息并将其发送到输出通道的bean：
- en: '[PRE27]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Transformation
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转换
- en: 'As you probably remember, `account-service` and `product-service` have been
    receiving events from `order-service` and then sending back the response message.
    We have created the `OrderSender` bean, which was responsible for preparing the
    response payload and sending it to the output channel. It turns out that the implementation
    may be simpler if we return the response object in method and annotate it with
    `@SentTo`:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您可能记得的，`account-service`和`product-service`一直在从`order-service`接收事件，然后发送回响应消息。我们创建了`OrderSender`bean，它负责准备响应载荷并将其发送到输出通道。结果是，如果我们在方法中返回响应对象并将其注解为`@SentTo`，则实现可能更简单：
- en: '[PRE28]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We can even imagine such an implementation, such as the following, without
    using `@StreamListener`. The transformer pattern is responsible for changing the
    object''s form. In that case, it modifies two `order` fields—`status` and `price`:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至可以想象这样一个实现，比如下面的实现，而不使用`@StreamListener`。变换器模式负责改变对象的形式。在这种情况下，它修改了两个`order`字段—`status`和`price`：
- en: '[PRE29]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Consuming messages conditionally
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 条件性地接收消息
- en: 'Assuming we would like to treat messages incoming to the same message channel
    differently, we may use conditional dispatching. Spring Cloud Stream supports
    dispatching messages to multiple `@StreamListener` methods registered on an input
    channel, based on a condition. That condition is a **Spring Expression Language**
    (**SpEL**) expression defined in the `condition` attribute of the `@StreamListener`
    annotation:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们希望对同一消息通道传入的消息进行不同的处理，我们可以使用条件分发。Spring Cloud Stream支持根据条件将消息分发到输入通道上注册的多个`@StreamListener`方法。这个条件是一个**Spring表达式语言**（**SpEL**）表达式，定义在`@StreamListener`注解的`condition`属性中：
- en: '[PRE30]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Here''s the sample implementation that defines two methods annotated with `@StreamListener`
    that listen on the same topic. One of them is dedicated only for messages incoming
    from `account-service`, while the second is dedicated only for `product-service`.
    The incoming message is dispatched, based on its header with the `processor` name:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个定义了两个注有`@StreamListener`注解的方法的示例，它们监听同一个主题。其中一个只处理来自`account-service`的消息，而第二个只处理`product-service`的消息。传入的消息根据其头部的`processor`名称进行分发：
- en: '[PRE31]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Using Apache Kafka
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Apache Kafka
- en: I have mentioned Apache Kafka a couple of times when discussing Spring Cloud
    integration with message brokers. However, until now, we haven't run any samples
    based on that platform. The fact is that RabbitMQ tends to be the preferred choice
    when working with Spring Cloud projects, but Kafka is also worthy of our attention.
    One of its advantages over RabbitMQ is native support for partitioning, which
    is one of the most important features of Spring Cloud Stream.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论Spring Cloud与消息代理的集成时，我提到了Apache Kafka几次。然而，到目前为止，我们还没有基于该平台运行任何示例。事实上，当与Spring
    Cloud项目一起使用时，RabbitMQ往往是最受欢迎的选择，但Kafka也值得我们关注。它相对于RabbitMQ的一个优势是对分区的大力支持，这是Spring
    Cloud Stream最重要的特性之一。
- en: Kafka is not a typical message broker. It is rather a distributed streaming
    platform. Its main feature is to allow you to publish and subscribe to streams
    of records. It is especially useful for real-time streaming applications that
    transform or react to streams of data. It is usually run as a cluster consisting
    of one or more servers, and stores streams of records in topics.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka不是一个典型的消息代理。它更像是一个分布式流处理平台。它的主要特性是允许您发布和订阅记录流。它特别适用于实时流应用程序，这些应用程序转换或对数据流做出反应。它通常作为由一个或多个服务器组成的集群运行，并将记录流存储在主题中。
- en: Running Kafka
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行Kafka
- en: 'Unfortunately, there is no official Docker image with Apache Kafka. However,
    we may use one that is unofficial, for example, that shared by Spotify. In comparison
    to other available Kafka docker images, this one runs both Zookeeper and Kafka
    in the same container. Here''s the Docker command that launches Kafka and exposes
    it on port `9092`. Zookeeper is also available outside on port `2181`:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，没有官方的Apache Kafka Docker镜像。然而，我们可以使用一个非官方的镜像，例如Spotify共享的镜像。与其他可用的Kafka
    Docker镜像相比，这个镜像在同一个容器中同时运行Zookeeper和Kafka。以下是启动Kafka并将其暴露在端口`9092`上的Docker命令。Zookeeper也外部可访问端口`2181`：
- en: '[PRE32]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Customizing application settings
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定制应用程序设置
- en: To enable Apache Kafka for the application, include the `spring-cloud-starter-stream-kafka`
    starter to the dependencies. Our current sample is very similar to to the sample
    of publish/subscribe using with RabbitMQ publish/subscribe with grouping and partitioning
    presented in *The publish/subscribe model*, section. The only difference is in
    the dependencies and configuration settings.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要为应用程序启用Apache Kafka，请将`spring-cloud-starter-stream-kafka`启动器包括在依赖项中。我们当前的示例与在*发布/订阅模型*章节中介绍的RabbitMQ的发布/订阅、带分组和分区的示例非常相似。唯一的区别在于依赖项和配置设置。
- en: 'Spring Cloud Stream automatically detects and uses a binder found on the classpath.
    The connection settings may be overridden with `spring.kafka.*` properties. In
    our case, we just need to change the auto-configured Kafka client address to the
    Docker machine address `192.168.99.100`. The same modification should be performed
    for Zookeeper, which is used by the Kafka client:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream会自动检测并使用类路径中找到的绑定器。连接设置可以通过`spring.kafka.*`属性进行覆盖。在我们的案例中，我们只需要将自动配置的Kafka客户端地址更改为Docker机器的地址`192.168.99.100`。对于由Kafka客户端使用的Zookeeper也应进行相同的修改：
- en: '[PRE33]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'After starting discovery, gateway, and all the required instances of microservices,
    you can perform the same tests as for the previous samples. If everything is configured
    correctly, you should see the following fragment in the logs during your application
    boot. The result of the tests is exactly the same as for the sample based on RabbitMQ:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 启动发现、网关以及所有必需的微服务实例之后，您可以执行与之前示例相同的测试。如果配置正确，您在应用启动过程中在日志中应看到以下片段。测试结果与基于 RabbitMQ
    的示例完全相同：
- en: '[PRE34]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Kafka Streams API support
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持 Kafka Streams API
- en: 'Spring Cloud Stream Kafka provides a binder specially designed for Kafka Streams
    binding. With this binder, the application can leverage the Kafka Streams API.
    To enable such a feature for your application, include the following dependency
    to your project:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream Kafka 提供了一个专门为 Kafka Streams 绑定设计的绑定器。通过这个绑定器，应用程序可以利用 Kafka
    Streams API。为了为您的应用程序启用此功能，请在您的项目中包含以下依赖项：
- en: '[PRE35]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The Kafka Streams API provides high-level stream DSL. It may be accessed by
    declaring the `@StreamListener` method that takes the `KStream` interface as a
    parameter. KStream provides some useful methods for stream manipulation, well-known
    from other streaming APIs such as `map`, `flatMap`, `join`, or `filter`. There
    are also some other methods specific to Kafka Stream, such as `to(...)` (for sending
    streams to a topic) or `through(...)` (same as `to`, but also creates a new instance
    of `KStream` from the topic):'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka Streams API 提供了高级流 DSL。可以通过声明接收 `KStream` 接口作为参数的 `@StreamListener` 方法来访问它。KStream
    为流处理提供了些有用的方法，这些方法在其他流式 API 中也很知名，如 `map`、`flatMap`、`join` 或 `filter`。还有一些 Kafka
    Stream 特有的方法，例如 `to(...)`（用于将流发送到主题）或 `through(...)`（与 `to` 相同，但还会从主题创建一个新的 `KStream`
    实例）：
- en: '[PRE36]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Configuration properties
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置属性
- en: 'Some of the Spring Cloud configuration settings for Kafka have been presented
    before when discussing the implementation of the sample application. Here''s a
    table with the most important properties, which can be set for customizing the
    Apache Kafka binder. All these properties are prefixed by `spring.cloud.stream.kafka.binder`:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 一些 Spring Cloud 针对 Kafka 的配置设置在讨论示例应用程序实现时已经介绍过。下面是一个包含为自定义 Apache Kafka 绑定器设置的最重要属性的表格，所有这些属性都带有
    `spring.cloud.stream.kafka.binder` 前缀：
- en: '| Name | Default value | Description |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| Name | 默认值 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `brokers` | `localhost` | A comma-separated list of brokers with or without
    port information. |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| `brokers` | `localhost` | 带或不带端口信息的经纪人列表，以逗号分隔。 |'
- en: '| `defaultBrokerPort` | `9092` | It sets the default port if no port is defined
    using the `brokers` property. |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| `defaultBrokerPort` | `9092` | 如果没有使用`brokers`属性定义端口，则设置默认端口。 |'
- en: '| `zkNodes` | `localhost` | A comma-separated list of ZooKeeper nodes with
    or without port information. |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| `zkNodes` | `localhost` | 带或不带端口信息的 ZooKeeper 节点列表，以逗号分隔。 |'
- en: '| `defaultZkPort` | `2181` | It sets the default ZooKeeper port if no port
    is defined using the `zkNodes` property. |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| `defaultZkPort` | `2181` | 如果没有使用 `zkNodes` 属性定义端口，则设置默认 ZooKeeper 端口。 |'
- en: '| `configuration` | - | A Key/Value map of Kafka client properties. It applies
    to all the clients created by the binder. |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| `configuration` | - | Kafka 客户端属性的键/值映射。它适用于绑定器创建的所有客户端。 |'
- en: '| `headers` | - | The list of custom headers that will be forwarded by the
    binder. |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| `headers` | - | 将由绑定器传递的自定义头列表。 |'
- en: '| `autoCreateTopics` | `true` | If set to `true`, the binder creates new topics
    automatically. |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| `autoCreateTopics` | `true` | 如果设置为`true`，则绑定器会自动创建新主题。 |'
- en: '| `autoAddPartitions` | `false` | If set to `true`, the binder creates new
    partitions automatically. |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| `autoAddPartitions` | `false` | 如果设置为`true`，则绑定器会自动创建新的分区。 |'
- en: Multiple binders
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多个绑定器
- en: In Spring Cloud Stream nomenclature, the interface that may be implemented to
    provide connection to physical destinations at the external middleware is called
    **binder**. Currently, there are two available built-in binder implementations—Kafka
    and RabbitMQ. In case you would like to provide a custom binder library, the key
    interface that is an abstraction for a strategy for connecting inputs and outputs
    to external middleware is `Binder`, having two methods—`bindConsumer` and `bindProducer`.
    For more details, you may refer to the Spring Cloud Stream specifications.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Spring Cloud Stream 命名约定中，可以实现以提供对外部中间件的物理目的地连接的接口称为**绑定器**。目前，有两大内置绑定器实现——Kafka
    和 RabbitMQ。如果您想要提供一个自定义的绑定器库，关键的接口是一个将输入和输出连接到外部中间件的策略的抽象，称为 `Binder`，有两个方法——`bindConsumer`
    和 `bindProducer`。有关更多详细信息，请参考 Spring Cloud Stream 规范。
- en: 'The important thing for us is an ability to use multiple binders in a single
    application. You can even mix different implementations, for example, RabbitMQ
    with Kafka. Spring Cloud Stream relies on Spring Boot''s auto-configuration in
    the binding process. The implementation available on the classpath is used automatically.
    In case you would like to use both the default Binders, include the following
    dependencies to the project:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们来说重要的是，能够在单个应用程序中使用多个绑定器。你甚至可以混合不同的实现，例如，RabbitMQ和Kafka。Spring Cloud Stream在绑定过程中依赖于Spring
    Boot的自动配置。可用的实现自动使用。如果您想要同时使用默认的绑定器，请将以下依赖项包含在项目中：
- en: '[PRE37]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: If more than one binder has been found in the classpath, the application must
    detect which of them should be used for the particular channel binding. We may
    configure the default binder globally with the `spring.cloud.stream.defaultBinder`
    property, or individually per each channel with the `spring.cloud.stream.bindings.<channelName>.binder`
    property. Now, we go back for a moment to our sample to configure multiple binders
    there. We define RabbitMQ for direct communication between `account-service` and
    `order-service`, and Kafka for the publish/subscribe model between `order-service`
    and other microservices.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在类路径中找到了多个绑定器，应用程序必须检测出哪个应该用于特定的通道绑定。我们可以通过`spring.cloud.stream.defaultBinder`属性全局配置默认的绑定器，或者每个通道分别通过`spring.cloud.stream.bindings.<channelName>.binder`属性配置。现在，我们回到我们的示例中，在那里配置多个绑定器。我们为`account-service`和`order-service`之间的直接通信定义RabbitMQ，为`order-service`与其他微服务之间的发布/订阅模型定义Kafka。
- en: 'Here''s the equivalent configuration to that provided for `account-service`
    in the `publish_subscribe` branch ([https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe](https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe)),
    but based on two different binders:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在`publish_subscribe`分支中为`account-service`提供的等效配置([https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe](https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe)),但基于两种不同的绑定器：
- en: '[PRE38]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Summary
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: Spring Cloud Stream can be treated as a separate category in comparison to all
    the other Spring Cloud projects. It is often being associated with other projects,
    and which are currently strongly promoted by Pivotal Spring Cloud Data Flow. That
    is a toolkit for building data integration and real-time data processing pipelines.
    However, it is a huge subject and rather a topic of discussion for a separate
    book.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream与其他所有Spring Cloud项目相比可以被视为一个单独的类别。它经常与其他项目关联，而这些项目目前由Pivotal
    Spring Cloud Data Flow强烈推广。这是一个用于构建数据集成和实时数据处理管道的工具包。然而，这是一个庞大的主题，更是一个需要单独讨论的书本内容。
- en: More to the point, Spring Cloud Stream provides support for asynchronous messaging,
    which may be easily implemented using a Spring annotation style. I think that
    for some of you, that style of inter-service communication is not as obvious as
    the RESTful API model. Therefore, I have focused on showing you the examples of
    point-to-point and publish/subscribe communication using Spring Cloud Stream.
    I have also described the differences between those two styles of messaging.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，Spring Cloud Stream提供了异步消息传递的支持，这可以通过使用Spring注解风格轻松实现。我认为对于你们中的某些人来说，这种服务间通信的风格不如RESTful
    API模型明显。因此，我专注于向你们展示使用Spring Cloud Stream的点对点和发布/订阅通信的示例。我还描述了这两种消息传递风格之间的区别。
- en: The publish/subscribe model is nothing new, but thanks to Spring Cloud Stream,
    it may be easily included to the microservice-based system. Some of the key concepts,
    such as consumer groups or partitioning, have also been described in this chapter.
    After reading it, you should be able to implement microservices based on the messaging
    model, and integrate them with other Spring Cloud libraries in order to provide
    logging, tracing, or just deploying them as part of the existing, REST-based microservices
    system.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 发布/订阅模型并非新事物，但得益于Spring Cloud Stream，它可以轻松地包含在基于微服务的系统中。本章中还描述了一些关键概念，例如消费者组或分区。阅读后，你应该能够实现基于消息模型的微服务，并将它们与Spring
    Cloud库集成，以提供日志记录、跟踪，或者只是将它们作为现有REST-based微服务系统的一部分部署。
