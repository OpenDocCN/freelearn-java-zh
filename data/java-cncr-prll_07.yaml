- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Concurrency in Java for Machine Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java 在机器学习中的并发
- en: The landscape of **machine learning** (**ML**) is rapidly evolving, with the
    ability to process vast amounts of data efficiently and in real time becoming
    increasingly crucial. Java, with its robust concurrency framework, emerges as
    a powerful tool for developers navigating the complexities of ML applications.
    This chapter delves into the synergistic potential of Java’s concurrency mechanisms
    when applied to the unique challenges of ML, exploring how they can significantly
    enhance performance and scalability in ML workflows.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）的领域正在迅速发展，能够高效且实时处理大量数据的能力变得越来越关键。Java，凭借其强大的并发框架，成为开发者应对机器学习应用复杂性的强大工具。本章深入探讨了将
    Java 的并发机制应用于机器学习的独特挑战中的协同潜力，探讨了它们如何显著提高机器学习工作流程的性能和可扩展性。
- en: Throughout this chapter, we will provide a comprehensive understanding of Java’s
    concurrency tools and how they align with the computational demands of ML. We’ll
    explore practical examples and real-world case studies that illustrate the transformative
    impact of employing Java’s concurrent programming paradigms in ML applications.
    From leveraging parallel streams for efficient data preprocessing to utilizing
    thread pools for concurrent model training, we’ll showcase strategies to achieve
    scalable and efficient ML deployments.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将全面了解 Java 的并发工具及其与机器学习计算需求的对齐方式。我们将探讨实际示例和现实世界的案例研究，说明在机器学习应用程序中采用 Java
    的并发编程范式对变革性影响的实例。从利用并行流进行高效的数据预处理到利用线程池进行并发模型训练，我们将展示实现可扩展和高效机器学习部署的策略。
- en: Furthermore, we’ll discuss best practices for thread management and reducing
    synchronization overhead, ensuring optimal performance and maintainability of
    ML systems built with Java. We’ll also explore the exciting intersection of Java
    concurrency and generative AI, inspiring you to push the boundaries of what’s
    possible in this emerging field.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将讨论线程管理的最佳实践和减少同步开销，以确保使用 Java 构建的机器学习系统的最佳性能和可维护性。我们还将探索 Java 并发与生成式 AI
    的激动人心的交汇点，激发您在这个新兴领域探索可能性的边界。
- en: By the end of this chapter, you’ll be equipped with the knowledge and skills
    needed to harness the power of Java’s concurrency in your ML projects. Whether
    you’re a seasoned Java developer venturing into the world of ML or an ML practitioner
    looking to leverage Java’s concurrency features, this chapter will provide you
    with insights and practical guidance to build faster, scalable, and more efficient
    ML applications.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将具备利用 Java 并发能力在您的机器学习项目中发挥其力量的知识和技能。无论您是进入机器学习世界的资深 Java 开发者，还是希望利用
    Java 并发特性的机器学习从业者，本章将为您提供见解和实践指导，以构建更快、可扩展和更高效的机器学习应用程序。
- en: So, let’s dive in and unlock the potential of Java’s concurrency in the realm
    of ML!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们深入探讨并解锁 Java 在机器学习领域的并发潜力！
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You’ll need to have the following software and dependencies set up in your
    development environment:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要在您的开发环境中设置以下软件和依赖项：
- en: '`8` or later'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`8` 或更高版本'
- en: Apache Maven for dependency management
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Maven 用于依赖管理
- en: An IDE of your choice (e.g., IntelliJ IDEA or Eclipse)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您选择的 IDE（例如，IntelliJ IDEA 或 Eclipse）
- en: 'For detailed instructions on setting up **Deeplearning4j** (**DL4J**) dependencies
    in your Java project, please refer to the official DL4J documentation:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 关于在您的 Java 项目中设置 **Deeplearning4j** (**DL4J**) 依赖的详细说明，请参阅官方 DL4J 文档：
- en: '[https://deeplearning4j.konduit.ai/](https://deeplearning4j.konduit.ai/)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://deeplearning4j.konduit.ai/](https://deeplearning4j.konduit.ai/)'
- en: 'The code in this chapter can be found on GitHub:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的代码可以在 GitHub 上找到：
- en: '[https://github.com/PacktPublishing/Java-Concurrency-and-Parallelism](https://github.com/PacktPublishing/Java-Concurrency-and-Parallelism)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Java-Concurrency-and-Parallelism](https://github.com/PacktPublishing/Java-Concurrency-and-Parallelism)'
- en: An overview of ML computational demands and Java concurrency alignment
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习计算需求和 Java 并发对齐概述
- en: ML tasks often involve processing massive datasets and performing complex computations,
    which can be highly time-consuming. Java’s concurrency mechanisms enable the execution
    of multiple parts of these tasks in parallel, significantly speeding up the process
    and improving the efficiency of resource utilization.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习任务通常涉及处理大量数据集和执行复杂的计算，这可能非常耗时。Java 的并发机制允许并行执行这些任务的多个部分，显著加快了过程并提高了资源利用效率。
- en: Imagine working on a cutting-edge ML project that deals with terabytes of data
    and intricate models. The data preprocessing alone could take days, not to mention
    the time needed for training and inference. However, by leveraging Java’s concurrency
    tools, such as threads, executors, and futures, you can harness the power of parallelism
    at various stages of your ML workflow, tackling these challenges head-on and achieving
    results faster than ever before.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你正在从事一个处理TB级数据和复杂模型的尖端ML项目。仅数据预处理就可能需要几天时间，更不用说训练和推理所需的时间。然而，通过利用Java的并发工具，如线程、执行器和未来，你可以在ML工作流程的各个阶段利用并行处理的力量，直面这些挑战，并以前所未有的速度实现结果。
- en: The intersection of Java concurrency and ML demands
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Java并发与ML需求的交汇
- en: The intersection of Java concurrency mechanisms and the computational demands
    of modern ML applications presents a promising frontier. ML models, especially
    those involving large datasets and deep learning, require significant resources
    for data preprocessing, training, and inference. By leveraging Java’s multithreading
    capabilities, parallel processing, and distributed computing frameworks, ML practitioners
    can tackle the growing complexity and scale of ML tasks. This synergy between
    Java concurrency and ML enables optimized resource utilization, accelerated model
    development, and high-performance solutions that keep pace with the increasing
    sophistication of ML algorithms and the relentless growth of data.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Java并发机制与现代ML应用计算需求的交汇处是一个有前景的前沿。ML模型，尤其是涉及大量数据集和深度学习的模型，在数据预处理、训练和推理方面需要大量的资源。通过利用Java的多线程能力、并行处理和分布式计算框架，ML从业者可以应对ML任务日益增长复杂性和规模。Java并发与ML之间的这种协同作用，使得资源利用优化、模型开发加速以及与ML算法日益复杂化和数据无休止增长保持同步的高性能解决方案成为可能。
- en: Parallel processing – the key to efficient ML workflows
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行处理——高效ML工作流程的关键
- en: The secret to efficient ML workflows lies in **parallel processing** – the ability
    to execute multiple tasks simultaneously. Java’s concurrency features allow you
    to parallelize various stages of your ML pipeline, from data preprocessing to
    model training and inference.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 高效ML工作流程的秘密在于**并行处理**——同时执行多个任务的能力。Java的并发特性允许你并行化ML管道的各个阶段，从数据预处理到模型训练和推理。
- en: For instance, by dividing the tasks of data cleaning, feature extraction, and
    normalization among multiple threads, you can significantly reduce the time spent
    on data preprocessing. Similarly, model training can be parallelized by distributing
    the workload across multiple cores or nodes, making the most of your computational
    resources.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，通过将数据清洗、特征提取和归一化的任务分配给多个线程，你可以显著减少数据预处理所需的时间。同样，通过在多个核心或节点之间分配工作负载，模型训练也可以并行化，充分利用你的计算资源。
- en: Handling big data with ease
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 轻松处理大数据
- en: In the era of big data, ML models often require processing massive datasets
    that can be challenging to handle efficiently. Java’s Fork/Join framework provides
    a powerful solution to this problem by enabling a divide-and-conquer approach.
    This framework allows you to split large datasets into smaller, more manageable
    subsets that can be processed in parallel across multiple cores or nodes.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在大数据时代，ML模型通常需要处理大量数据集，这可能对高效处理构成挑战。Java的Fork/Join框架通过实现分而治之的方法，为解决这个问题提供了一个强大的解决方案。这个框架允许你将大型数据集拆分成更小、更易于管理的子集，这些子集可以在多个核心或节点上并行处理。
- en: With Java’s data parallelism capabilities, handling terabytes of data becomes
    as manageable as processing kilobytes, unlocking new possibilities for ML applications.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 利用Java的数据并行能力，处理TB级数据变得和处理KB级数据一样容易，为ML应用解锁了新的可能性。
- en: An overview of key ML techniques
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关键ML技术的概述
- en: To understand how Java’s concurrency features can benefit ML workflows, let’s
    explore some prominent ML techniques and their computational demands.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解Java的并发特性如何使ML工作流程受益，让我们探讨一些突出的ML技术和它们的计算需求。
- en: Neural networks
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 神经网络
- en: '**Neural networks** are essential components in many ML applications. They
    consist of layers of interconnected artificial neurons that process information
    and learn from data. The training process involves adjusting the weights of connections
    between neurons based on the difference between predicted and actual outputs.
    This process is typically done using algorithms such as backpropagation and gradient
    descent.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**神经网络**是许多机器学习应用中的基本组件。它们由多层相互连接的人工神经元组成，处理信息和从数据中学习。训练过程涉及根据预测输出和实际输出之间的差异调整神经元之间连接的权重。这个过程通常使用反向传播和梯度下降等算法来完成。'
- en: Java’s concurrency features can significantly speed up neural network training
    by parallelizing data preprocessing and model updates. This is especially beneficial
    for large datasets. Once trained, neural networks can be used for making predictions
    on new data, and Java’s concurrency features enable parallel inference on multiple
    data points, enhancing the efficiency of real-time applications.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Java的并发特性可以通过并行化数据预处理和模型更新来显著加快神经网络训练速度。这对于大型数据集特别有益。一旦训练完成，神经网络可以用于对新数据进行预测，而Java的并发特性使得对多个数据点进行并行推理成为可能，从而提高了实时应用的效率。
- en: 'For further study, you can explore these resources:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于进一步的学习，你可以探索以下资源：
- en: '*Wikipedia’s Neural Network Overview* ([https://en.wikipedia.org/wiki/Neural_network](https://en.wikipedia.org/wiki/Neural_network))
    provides a comprehensive introduction to both biological and artificial neural
    networks, covering their structure, function, and applications'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*维基百科的神经网络概述*（[https://en.wikipedia.org/wiki/Neural_network](https://en.wikipedia.org/wiki/Neural_network)）提供了关于生物和人工神经网络的全面介绍，包括它们的结构、功能和应用'
- en: '*Artificial Neural Networks* ([https://www.analyticsvidhya.com/blog/2024/04/decoding-neural-networks/](https://www.analyticsvidhya.com/blog/2024/04/decoding-neural-networks/))
    offers detailed explanations of how neural networks work, including concepts such
    as forward propagation, backpropagation, and the differences between shallow and
    deep neural networks'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*人工神经网络*（[https://www.analyticsvidhya.com/blog/2024/04/decoding-neural-networks/](https://www.analyticsvidhya.com/blog/2024/04/decoding-neural-networks/））提供了关于神经网络如何工作的详细解释，包括前向传播、反向传播以及浅层和深层神经网络之间的区别等概念'
- en: These resources will give you a deeper understanding of neural networks and
    their applications in various fields.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这些资源将帮助你更深入地了解神经网络及其在各个领域的应用。
- en: Convolutional neural networks
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: '**Convolutional neural networks** (**CNNs**) are a specialized type of neural
    network designed to handle grid-like data, such as images and videos. They are
    particularly effective for tasks such as image recognition, object detection,
    and segmentation. CNNs are composed of several types of layers:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积神经网络**（**CNNs**）是一种专门设计的神经网络，用于处理网格状数据，例如图像和视频。它们在图像识别、目标检测和分割等任务中特别有效。CNNs由几种类型的层组成：'
- en: '**Convolutional layers**: These layers apply convolution operations to the
    input data using filters or kernels, which help in detecting various features
    such as edges, textures, and shapes.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层**：这些层使用过滤器或核对输入数据进行卷积操作，有助于检测各种特征，如边缘、纹理和形状。'
- en: '**Pooling layers**: These layers perform downsampling operations, reducing
    the dimensionality of the data and thereby reducing computational load. Common
    types include max pooling and average pooling.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**池化层**：这些层执行下采样操作，降低数据的维度，从而减少计算负载。常见的类型包括最大池化和平均池化。'
- en: '**Fully connected layers**: After several convolutional and pooling layers,
    the final few layers are fully connected, similar to traditional neural networks,
    to produce the output.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全连接层**：在多个卷积和池化层之后，最后的几层是全连接的，类似于传统的神经网络，以产生输出。'
- en: Java’s concurrency features can be effectively utilized to parallelize the training
    and inference processes of CNNs. This involves distributing the data preprocessing
    tasks and model computations across multiple threads or cores, leading to faster
    execution times and improved performance, especially when handling large datasets.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Java的并发特性可以有效地用于并行化CNNs的训练和推理过程。这涉及到将数据预处理任务和模型计算分配到多个线程或核心，从而缩短执行时间并提高性能，尤其是在处理大型数据集时。
- en: 'For further study, you can explore these resources:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 对于进一步的学习，你可以探索以下资源：
- en: '`Wikipedia’s Convolutional Neural Network Overview` provides a comprehensive
    introduction to CNNs, explaining their structure, function, and applications in
    detail'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`维基百科的卷积神经网络概述`提供了对CNN的全面介绍，详细解释了其结构、功能和在各领域的应用'
- en: Analytics Vidhya’s `CNN Tutorial` offers an intuitive guide to understanding
    how CNNs work, with practical examples and explanations of key concepts
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Analytics Vidhya的`CNN教程`提供了一个直观的指南，用于理解卷积神经网络（CNN）的工作原理，包括实际示例和关键概念的解释
- en: These resources will provide you with a deeper understanding of CNNs and their
    applications in various fields.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些资源将为您提供对卷积神经网络及其在各领域应用的更深入理解。
- en: Other relevant ML techniques
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他相关的机器学习技术
- en: 'Here’s a brief overview of other commonly used ML techniques, along with their
    relevance to Java concurrency:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是对其他常用机器学习技术的简要概述，以及它们与Java并发的相关性：
- en: '**Support vector machines** (**SVMs**): These are powerful tools for classification
    tasks. They can benefit from parallel processing during training data preparation
    and model fitting. More information can be found at [https://scikit-learn.org/stable/modules/svm.html](https://scikit-learn.org/stable/modules/svm.html).'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持向量机**（**SVMs**）：这些是强大的分类任务工具。在训练数据准备和模型拟合过程中，它们可以从并行处理中受益。更多信息可以在[https://scikit-learn.org/stable/modules/svm.html](https://scikit-learn.org/stable/modules/svm.html)找到。'
- en: '**Decision trees**: These are tree-like structures used for classification
    and regression. Java concurrency can be used for faster data splitting and decision
    tree construction during training. More information can be found at [https://en.wikipedia.org/wiki/Decision_tree](https://en.wikipedia.org/wiki/Decision_tree).'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策树**：这些是用于分类和回归的树状结构。在训练过程中，可以使用Java并发来加速数据分割和决策树构建。更多信息可以在[https://en.wikipedia.org/wiki/Decision_tree](https://en.wikipedia.org/wiki/Decision_tree)找到。'
- en: '**Random forests**: These are ensembles of decision trees, improving accuracy
    and robustness. Java concurrency can be leveraged for parallel training of individual
    decision trees. More information can be found at [https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机森林**：这些是决策树的集成，提高了准确性和鲁棒性。Java并发可以用于并行训练单个决策树。更多信息可以在[https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)找到。'
- en: These are just a few examples. Many other ML techniques can benefit from Java
    concurrency in various aspects of their workflows.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是几个例子。许多其他机器学习技术可以从Java并发在其工作流程的各个方面受益。
- en: The intersection of Java’s concurrency mechanisms and the computational demands
    of ML presents a powerful opportunity for developers to create efficient, scalable,
    and innovative ML applications. By leveraging parallel processing, handling big
    data with ease, and understanding the synergy between Java’s concurrency features
    and various ML techniques, you can embark on a journey where the potential of
    ML is unleashed, and the future of data-driven solutions is shaped.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Java的并发机制与机器学习的计算需求交汇，为开发者提供了创建高效、可扩展和创新的机器学习应用的有力机会。通过利用并行处理、轻松处理大数据以及理解Java并发特性与各种机器学习技术之间的协同作用，您可以开始一段旅程，在那里机器学习的潜力得到释放，数据驱动解决方案的未来得以塑造。
- en: Case studies – real-world applications of Java concurrency in ML
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 案例研究——Java并发在机器学习（ML）中的实际应用
- en: The power of Java concurrency in enhancing ML workflows is best demonstrated
    through real-world applications. These case studies not only showcase the practical
    implementation but also highlight the transformative impact on performance and
    scalability. Next, we explore notable examples where Java’s concurrency mechanisms
    have been leveraged to address complex ML challenges, complete with code demos
    to illustrate key concepts.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Java并发在增强机器学习工作流程中的力量最好通过实际应用来展示。这些案例研究不仅展示了实际实施，还突出了对性能和可扩展性的变革性影响。接下来，我们将探讨一些引人注目的例子，其中Java的并发机制被用来解决复杂的机器学习挑战，并附有代码演示来阐述关键概念。
- en: Case study 1 – Large-scale image processing for facial recognition
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 案例研究1——大规模图像处理用于人脸识别
- en: A leading security company aimed to improve the efficiency of its facial recognition
    system, tasked with processing millions of images daily. The challenge was to
    enhance the throughput of image preprocessing and feature extraction phases, which
    are critical for accurate recognition.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一家领先的安全公司旨在提高其面部识别系统的效率，该系统每天需要处理数百万张图像。挑战在于提高图像预处理和特征提取阶段的吞吐量，这对于准确识别至关重要。
- en: Solution
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 解决方案
- en: By employing Java’s Fork/Join framework, the company parallelized the image
    processing workflow. This allowed for recursive task division, where each subtask
    processed a portion of the image dataset concurrently, significantly speeding
    up the feature extraction process.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通过采用 Java 的 Fork/Join 框架，公司并行化了图像处理工作流程。这允许递归任务分解，其中每个子任务并行处理图像数据集的一部分，显著加快了特征提取过程。
- en: 'Here is the code snippet:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是代码片段：
- en: '[PRE0]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The provided code demonstrates the implementation of a task-based parallel
    processing approach using Java’s Fork/Join framework for extracting features from
    a batch of images. Here’s a description of the code:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 提供的代码展示了使用 Java 的 Fork/Join 框架实现基于任务的并行处理方法，用于从图像批次中提取特征。以下是代码的描述：
- en: The `ImageFeatureExtractionTask` class extends `RecursiveTask<Void>`, indicating
    that it represents a task that can be divided into smaller subtasks and executed
    in parallel.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ImageFeatureExtractionTask` 类扩展了 `RecursiveTask<Void>`，表明它代表一个可以分解成更小的子任务并并行执行的任务。'
- en: The class has a constructor that takes a list of `Image` objects called `imageBatch`,
    representing the batch of images to process.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该类有一个构造函数，它接受一个名为 `imageBatch` 的 `Image` 对象列表，表示要处理的图像批次。
- en: The `compute()` method is the main entry point for the task. It checks whether
    the size of the `imageBatch` constructor exceeds a defined `THRESHOLD` value.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`compute()` 方法是任务的入口点。它检查 `imageBatch` 构造函数的大小是否超过定义的 `THRESHOLD` 值。'
- en: If the `imageBatch` size is above the `THRESHOLD` value, the task divides itself
    into smaller subtasks using the `createSubtasks()` method. It creates two new
    `ImageFeatureExtractionTask` instances, each responsible for processing half of
    the `imageBatch`.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 `imageBatch` 的大小超过 `THRESHOLD` 值，任务将使用 `createSubtasks()` 方法将其自身分割成更小的子任务。它创建了两个新的
    `ImageFeatureExtractionTask` 实例，每个实例负责处理 `imageBatch` 的一半。
- en: The subtasks are then forked (executed asynchronously) using the `fork()` method,
    allowing them to run concurrently.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后使用 `fork()` 方法异步执行子任务，允许它们并发运行。
- en: If the `imageBatch` size is below the `THRESHOLD` value, the task directly processes
    the entire batch using the `processBatch()` method, which is assumed to perform
    the actual feature extraction on the images.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 `imageBatch` 的大小低于 `THRESHOLD` 值，任务将直接使用 `processBatch()` 方法处理整个批次，该方法假定在图像上执行实际的特征提取。
- en: The `createSubtasks()` method is responsible for dividing `imageBatch` into
    two equal parts and creating new `ImageFeatureExtractionTask` instances for each
    half. These subtasks are added to a list and returned.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`createSubtasks()` 方法负责将 `imageBatch` 分割成两个相等的部分，并为每个部分创建新的 `ImageFeatureExtractionTask`
    实例。这些子任务被添加到列表中并返回。'
- en: The `processBatch()` method is a placeholder for the actual feature extraction
    logic, which is not implemented in the provided code.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`processBatch()` 方法是实际特征提取逻辑的占位符，在提供的代码中未实现。'
- en: This code showcases a divide-and-conquer approach using the Fork/Join framework,
    where a large batch of images is recursively divided into smaller subtasks until
    a threshold is reached. Each subtask processes a portion of the images independently,
    allowing for parallel execution and potentially improving the overall performance
    of the feature extraction process.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码展示了使用 Fork/Join 框架的分割征服方法，其中大量图像批次递归地分割成更小的子任务，直到达到阈值。每个子任务独立处理图像的一部分，允许并行执行，并可能提高特征提取过程的整体性能。
- en: Case study 2 – Real-time data processing for financial fraud detection
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 案例研究 2 – 用于金融欺诈检测的实时数据处理
- en: A financial services firm needed to enhance its fraud detection system, which
    analyzes vast streams of transactional data in real time. The goal was to minimize
    detection latency while handling peak load efficiently.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一家金融服务公司需要增强其欺诈检测系统，该系统实时分析大量交易数据。目标是尽量减少检测延迟，同时高效地处理峰值负载。
- en: Solution
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 解决方案
- en: Utilizing Java’s executors and futures, the firm implemented an asynchronous
    processing model. Each transaction was processed in a separate thread, allowing
    for concurrent analysis of incoming data streams.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 利用Java的执行器和未来对象，公司实现了一个异步处理模型。每个交易都在一个单独的线程中处理，允许并发分析传入的数据流。
- en: 'Here’s a simplified code example highlighting the use of executors and futures
    for concurrent transaction processing:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个简化的代码示例，突出了使用执行器和未来对象进行并发交易处理的使用：
- en: '[PRE1]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The `Transaction` class, which is used in the code example, represents a financial
    transaction. It encapsulates the relevant information about a transaction, such
    as the transaction ID, amount, timestamp, and other necessary details. Here’s
    a simple definition of the `Transaction` class:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码示例中使用的`Transaction`类表示一笔金融交易。它封装了关于交易的相关信息，如交易ID、金额、时间戳和其他必要细节。以下是`Transaction`类的一个简单定义：
- en: '[PRE2]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here’s a description of the code:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是对代码的描述：
- en: The `FraudDetectionSystem` class represents the fraud detection system. It utilizes
    an `ExecutorService` to manage a thread pool for concurrent transaction processing.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FraudDetectionSystem`类表示欺诈检测系统。它使用`ExecutorService`来管理线程池以进行并发交易处理。'
- en: The `analyzeTransaction()` method submits a task to the `ExecutorService` to
    perform fraud detection analysis on a transaction. It returns a `Future<Boolean>`
    representing the asynchronous result of the analysis.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`analyzeTransaction()`方法将任务提交给`ExecutorService`以对交易执行欺诈检测分析。它返回一个表示分析异步结果的`Future<Boolean>`。'
- en: The `shutdown()` method is used to gracefully shut down the `ExecutorService`
    when it is no longer needed.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当不再需要`ExecutorService`时，使用`shutdown()`方法来优雅地关闭它。
- en: The `Transaction` class represents a financial transaction, containing relevant
    data fields such as the transaction ID and amount. Additional fields can be added
    based on the specific requirements of the fraud detection system.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Transaction`类表示一笔金融交易，包含相关的数据字段，如交易ID和金额。根据欺诈检测系统的具体要求，可以添加额外的字段。'
- en: 'To use `FraudDetectionSystem`, you can create an instance with the desired
    number of threads and submit transactions for analysis:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`FraudDetectionSystem`，你可以创建一个具有所需线程数的实例，并提交交易进行分析：
- en: '[PRE3]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This code creates a `FraudDetectionSystem` instance with a thread pool of 10
    threads, creates a sample `Transaction` object, and submits it for asynchronous
    analysis using the `analyzeTransaction()` method. The method returns a `Future<Boolean>`
    representing the future result of the analysis.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码创建了一个具有10个线程的线程池的`FraudDetectionSystem`实例，创建了一个示例`Transaction`对象，并使用`analyzeTransaction()`方法提交它进行异步分析。该方法返回一个表示分析未来结果的`Future<Boolean>`。
- en: These case studies underscore the vital role of Java concurrency in addressing
    the scalability and performance challenges inherent in ML workflows. By parallelizing
    tasks and employing asynchronous processing, organizations can achieve remarkable
    improvements in efficiency and responsiveness, paving the way for innovation and
    advancement in ML applications.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这些案例研究强调了Java并发在解决机器学习工作流程中固有的可扩展性和性能挑战中的关键作用。通过并行化任务和采用异步处理，组织可以实现显著的效率和工作响应性提升，为机器学习应用的创新和进步铺平道路。
- en: Java’s tools for parallel processing in ML workflows
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java在机器学习工作流程中的并行处理工具
- en: Parallel processing has become a cornerstone for ML workflows, enabling the
    handling of complex computations and large datasets with increased efficiency.
    Java, with its robust ecosystem, offers a variety of libraries and frameworks
    designed to support and enhance ML development through parallel processing. This
    section explores the pivotal role of these tools, with a focus on DL4J for neural
    networks and Java’s concurrency utilities for data processing.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 并行处理已成为机器学习工作流程的基石，它通过提高效率来处理复杂的计算和大数据集。Java凭借其强大的生态系统，提供了各种库和框架，旨在通过并行处理支持并增强机器学习开发。本节探讨了这些工具的关键作用，重点关注DL4J神经网络和Java的并发工具用于数据处理。
- en: DL4J – pioneering neural networks in Java
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DL4J – Java中的神经网络的先驱
- en: DL4J is a powerful open source library for building and training neural networks
    in Java. It provides a high-level API for defining and configuring neural network
    architectures, making it easier for Java developers to incorporate deep learning
    into their applications.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: DL4J是一个强大的开源库，用于在Java中构建和训练神经网络。它提供了一个高级API来定义和配置神经网络架构，使得Java开发者更容易将深度学习集成到他们的应用程序中。
- en: One of the key advantages of DL4J is its ability to leverage Java’s concurrency
    features for efficient training of neural networks. DL4J is designed to take advantage
    of parallel processing and distributed computing, allowing it to handle large-scale
    datasets and complex network architectures.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: DL4J的一个关键优势是它能够利用Java的并发特性来高效地训练神经网络。DL4J旨在利用并行处理和分布式计算，使其能够处理大规模数据集和复杂网络架构。
- en: 'DL4J achieves efficient training through several concurrency techniques:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: DL4J通过几种并发技术实现高效训练：
- en: '**Parallel processing**: DL4J can distribute the training workload across multiple
    threads or cores, enabling parallel processing of data and model updates. This
    is particularly useful when training on large datasets or when using complex network
    architectures.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并行处理**：DL4J可以将训练工作负载分配到多个线程或核心，从而实现数据和模型更新的并行处理。这在处理大型数据集或使用复杂网络架构时特别有用。'
- en: '**Distributed training**: DL4J supports distributed training across multiple
    machines or nodes in a cluster. By leveraging frameworks such as Apache Spark
    or Hadoop, DL4J can scale out the training process to handle massive datasets
    and accelerate training times.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式训练**：DL4J支持跨集群中的多台机器或节点进行分布式训练。通过利用Apache Spark或Hadoop等框架，DL4J可以将训练过程扩展以处理大规模数据集并加速训练时间。'
- en: '**GPU acceleration**: DL4J seamlessly integrates with popular GPU libraries
    such as CUDA and cuDNN, allowing it to utilize the parallel processing power of
    GPUs for faster training. This can significantly speed up the training process,
    especially for computationally intensive tasks such as image recognition or **natural
    language** **processing** (**NLP**).'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPU加速**：DL4J与流行的GPU库（如CUDA和cuDNN）无缝集成，使其能够利用GPU的并行处理能力以实现更快的训练。这可以显著加快训练过程，尤其是在处理计算密集型任务（如图像识别或**自然语言处理**（NLP））时。'
- en: '**Asynchronous model updates**: DL4J employs asynchronous model updates, where
    multiple threads can simultaneously update the model parameters without strict
    synchronization. This approach reduces the overhead of synchronization and allows
    for more efficient utilization of computational resources.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异步模型更新**：DL4J采用异步模型更新，其中多个线程可以同时更新模型参数而无需严格的同步。这种方法减少了同步的开销，并允许更有效地利用计算资源。'
- en: By leveraging these concurrency techniques, DL4J enables Java developers to
    build and train neural networks efficiently, even when dealing with large-scale
    datasets and complex architectures. The library abstracts away many of the low-level
    details of concurrency and distributed computing, providing a high-level API that
    focuses on defining and training neural networks.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用这些并发技术，DL4J使Java开发者能够高效地构建和训练神经网络，即使是在处理大规模数据集和复杂架构的情况下。该库抽象了许多并发和分布式计算的底层细节，提供了一个高级API，专注于定义和训练神经网络。
- en: 'To get started with DL4J, let’s take a look at a code snippet that demonstrates
    how to create and train a simple feedforward neural network for classification
    using the Iris dataset:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用DL4J，让我们看看一个代码片段，它演示了如何使用Iris数据集创建和训练一个简单的前馈神经网络进行分类：
- en: '[PRE4]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To compile and run this code, make sure you have the following dependencies
    in your project’s `pom.xml` file:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要编译和运行此代码，请确保你的项目`pom.xml`文件中包含以下依赖项：
- en: '[PRE5]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This code demonstrates a complete workflow for building, training, and evaluating
    a neural network for classifying the Iris dataset using DL4J. It involves configuring
    a neural network, training it on the dataset, evaluating its performance, and
    saving the model for future use.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码演示了使用DL4J构建、训练和评估用于分类Iris数据集的神经网络的完整工作流程。它包括配置神经网络、在数据集上训练它、评估其性能以及保存模型以供将来使用。
- en: 'Here is the code description:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是代码描述：
- en: '`IrisDataSetIterator` is a utility class (likely custom-built or provided by
    DL4J) to load the famous Iris flower dataset and iterate over it in batches. The
    dataset consists of 150 samples, with each sample having 4 features (sepal length,
    sepal width, petal length, and petal width) and a label indicating the species.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IrisDataSetIterator`是一个实用类（可能是自定义构建或由DL4J提供），用于加载著名的Iris花数据集并以批处理方式遍历它。该数据集包含150个样本，每个样本有4个特征（花瓣长度、花瓣宽度、花萼长度和花萼宽度）以及一个表示物种的标签。'
- en: '`NeuralNetConfiguration.Builder ()` sets up the network’s architecture and
    training parameters:'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NeuralNetConfiguration.Builder()`设置网络的架构和训练参数：'
- en: '`updater(new Adam(0.01))`: Uses the Adam optimization algorithm for efficient
    learning, with a learning rate of `0.01`.'
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`updater(new Adam(0.01))`: 使用 Adam 优化算法进行高效学习，学习率为 `0.01`。'
- en: '`list()`: Indicates we’re creating a multilayer (feedforward) neural network.'
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`list()`: 表示我们正在创建一个多层（前馈）神经网络。'
- en: '`layer(new DenseLayer...)`: Adds a hidden layer with 10 neurons, using the
    `layer(new OutputLayer...)`: Adds the output layer with three neurons (one for
    each iris species) and the `1` and are suitable for classification tasks. The
    loss function is set to `NEGATIVELOGLIKELIHOOD`, which is a standard choice for
    multi-class classification.'
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer(new DenseLayer...)`: 添加一个包含 10 个神经元的隐藏层，使用 `layer(new OutputLayer...)`:
    添加一个包含三个神经元（每个用于一种鸢尾花物种）的输出层，`1` 和是适合分类任务的。损失函数设置为 `NEGATIVELOGLIKELIHOOD`，这是多类分类的标准选择。'
- en: '`MultiLayerNetwork model = new MultiLayerNetwork(conf)`: Creates the network
    based on the configuration.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MultiLayerNetwork model = new MultiLayerNetwork(conf)`: 根据配置创建网络。'
- en: '`model.init()`: Initializes the network’s parameters (weights and biases).'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model.init()`: 初始化网络的参数（权重和偏差）。'
- en: '`model.setListeners(new ScoreIterationListener(10))`: Attaches a listener to
    print the score every 10 iterations during training. This helps you monitor progress.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model.setListeners(new ScoreIterationListener(10))`: 在训练过程中每 10 次迭代时附加一个监听器来打印分数。这有助于你监控进度。'
- en: '`model.fit(irisIter)`: Trains the model on the Iris dataset. The model learns
    to adjust its internal parameters to minimize the loss function and accurately
    predict iris species.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model.fit(irisIter)`: 在 Iris 数据集上训练模型。模型学会调整其内部参数以最小化损失函数并准确预测鸢尾花物种。'
- en: '`Evaluation eval = model.evaluate(irisIter)`: Evaluates the model’s performance
    on the Iris dataset (or a separate test set if you had one).*   `System.out.println(eval.stats())`:
    Prints out a comprehensive evaluation report, including accuracy, precision, recall,
    F1 score, and so on.*   `ModelSerializer.writeModel(model, new File("iris-model.zip"),
    true)`: Saves the trained model in a `.zip` file. This allows you to reuse it
    for predictions later without retraining.*   The `iris-model.zip` file encapsulates
    both the learned parameters (weights and biases) of the trained ML model, crucial
    for accurate predictions, and the model’s configuration, including its architecture,
    layer types, activation functions, and hyperparameters. This comprehensive storage
    mechanism ensures the model can be seamlessly reloaded and employed for future
    predictions, eliminating the need for retraining.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Evaluation eval = model.evaluate(irisIter)`: 在 Iris 数据集（或如果你有一个单独的测试集的话）上评估模型的性能。*   `System.out.println(eval.stats())`:
    打印出一份全面的评估报告，包括准确率、精确度、召回率、F1 分数等。*   `ModelSerializer.writeModel(model, new File("iris-model.zip"),
    true)`: 将训练好的模型保存为 `.zip` 文件。这允许你在以后进行预测时重用它，而无需重新训练。*   `iris-model.zip` 文件封装了训练好的机器学习模型的所学参数（权重和偏差），这对于准确预测至关重要，以及模型的配置，包括其架构、层类型、激活函数和超参数。这种全面的存储机制确保模型可以无缝重新加载并用于未来的预测，消除了重新训练的需求。'
- en: This standard Java class can be executed directly from an IDE, packaged as a
    JAR file using `mvn clean package`, and can be run with Java JAR or deployed to
    a cloud platform.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这个标准的 Java 类可以直接从 IDE 中执行，使用 `mvn clean package` 打包成 JAR 文件，并可以使用 Java JAR 运行或部署到云平台。
- en: Prior to commencing model training, it’s advisable to preprocess the input data.
    Standardizing or normalizing the features can significantly enhance the model’s
    performance. Additionally, experimenting with various hyperparameters such as
    learning rates, layer sizes, and activation functions is crucial for discovering
    the optimal configuration. Implementing regularization techniques, such as dropout
    or L2 regularization, helps prevent overfitting. Finally, utilizing cross-validation
    provides a more accurate evaluation of the model’s effectiveness on new, unseen
    data.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始模型训练之前，建议对输入数据进行预处理。标准化或归一化特征可以显著提高模型的表现。此外，尝试各种超参数，如学习率、层大小和激活函数，对于发现最佳配置至关重要。实现正则化技术，如
    dropout 或 L2 正则化，有助于防止过拟合。最后，利用交叉验证可以更准确地评估模型在新的、未见过的数据上的有效性。
- en: This example provides a starting point for creating and training a basic neural
    network using DL4J. For more detailed information, refer to the `DL4J documentation`.
    This comprehensive resource provides in-depth explanations, tutorials, and guidelines
    for configuring and working with neural networks using the DL4J framework. You
    can explore various sections of the documentation to gain a deeper understanding
    of the available features and best practices.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 本例提供了一个使用 DL4J 创建和训练基本神经网络的开端。对于更详细的信息，请参阅 `DL4J 文档`。这个综合资源提供了对使用 DL4J 框架配置和操作神经网络的深入解释、教程和指南。您可以探索文档的各个部分，以更深入地了解可用的功能和最佳实践。
- en: Java thread pools for concurrent data processing
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于并发数据处理的 Java 线程池
- en: Java’s built-in thread pools provide a convenient and efficient way to handle
    concurrent data processing in ML workflows. Thread pools allow developers to create
    a fixed number of worker threads that can execute tasks concurrently, optimizing
    resource utilization and minimizing the overhead of thread creation and destruction.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Java 的内置线程池为机器学习工作流程中的并发数据处理提供了一个方便且高效的方法。线程池允许开发者创建一定数量的工作线程，这些线程可以并发执行任务，优化资源利用并最小化线程创建和销毁的开销。
- en: In the context of ML, thread pools can be leveraged for various data processing
    tasks, such as data preprocessing, feature extraction, and model evaluation. By
    dividing the workload into smaller tasks and submitting them to a thread pool,
    developers can achieve parallel processing and significantly reduce the overall
    execution time.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习（ML）的背景下，线程池可以用于各种数据处理任务，例如数据预处理、特征提取和模型评估。通过将工作负载分解成更小的任务并将它们提交给线程池，开发者可以实现并行处理，从而显著减少整体执行时间。
- en: Java’s concurrency API, particularly the `ExecutorService` interface and `ForkJoinPool`
    classes, provide high-level abstractions for managing thread pools. `ExecutorService`
    allows developers to submit tasks to a thread pool and retrieve the results asynchronously
    using `Future` objects. `ForkJoinPool`, on the other hand, is specifically designed
    for divide-and-conquer algorithms, where a large task is recursively divided into
    smaller subtasks until a certain threshold is reached.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Java 的并发 API，特别是 `ExecutorService` 接口和 `ForkJoinPool` 类，为管理线程池提供了高级抽象。`ExecutorService`
    允许开发者将任务提交到线程池，并使用 `Future` 对象异步检索结果。另一方面，`ForkJoinPool` 是专门为分治算法设计的，其中一个大任务被递归地分解成更小的子任务，直到达到某个阈值。
- en: Let’s consider a practical example of using Java thread pools for parallel feature
    extraction in an ML workflow. Suppose we have a large dataset of images, and we
    want to extract features from each image using a pre-trained CNN model. CNNs are
    a type of deep learning neural network particularly well-suited for analyzing
    images and videos. We can leverage a thread pool to process multiple images concurrently,
    improving the overall performance.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个使用 Java 线程池在机器学习工作流程中进行并行特征提取的实际例子。假设我们有一个包含大量图像的大型数据集，我们希望使用预训练的 CNN
    模型从每个图像中提取特征。CNN 是一种特别适合分析图像和视频的深度学习神经网络。我们可以利用线程池来并发处理多个图像，从而提高整体性能。
- en: 'Here is the code snippet:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是代码片段：
- en: '[PRE6]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In this code snippet, we define three classes:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码片段中，我们定义了三个类：
- en: The `CNNModel` class contains an `extractFeatures(Image image)` method that,
    in a real scenario, would implement the logic for extracting features from an
    image. Here, it returns a dummy array of floats representing extracted features
    for demonstration purposes.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CNNModel` 类包含一个 `extractFeatures(Image image)` 方法，在真实场景中，该方法将实现从图像中提取特征的逻辑。在这里，它返回一个代表提取特征的虚拟浮点数数组，用于演示目的。'
- en: The `Image` class serves as a placeholder representing an image. In practice,
    this class would include properties and methods relevant to handling image data.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Image` 类作为一个占位符，代表一个图像。在实际应用中，这个类将包括处理图像数据相关的属性和方法。'
- en: 'The `ImageFeatureExtractor` class is designed to manage the concurrent feature
    extraction process:'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ImageFeatureExtractor` 类被设计用来管理并发特征提取过程：'
- en: '`Constructor`: Accepts the number of threads (`numThreads`) and an instance
    of `CNNModel`. It initializes `ExecutorService` with a fixed thread pool size
    based on `numThreads`, which controls the concurrency level of the feature extraction
    process.'
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`构造函数`：接受线程数（`numThreads`）和 `CNNModel` 的一个实例。它使用基于 `numThreads` 的固定线程池大小初始化
    `ExecutorService`，这控制了特征提取过程的并发级别。'
- en: '`extractFeatures(List<Image> images)`: Takes a list of `Image` objects and
    uses the executor service to submit feature extraction tasks concurrently for
    each image. Each task calls the `extractFeatures()` method of the `CNNModel` on
    a separate thread. The method collects the futures returned by these tasks into
    a list and waits for all futures to complete. It then retrieves the extracted
    features from each future and compiles them into a list of float arrays.'
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`extractFeatures(List<Image> images)`: 接受一个 `Image` 对象列表，并使用执行器服务并发提交每个图像的特征提取任务。每个任务在单独的线程上调用
    `CNNModel` 的 `extractFeatures()` 方法。该方法收集这些任务返回的未来对象并将它们收集到一个列表中，等待所有未来对象完成。然后从每个未来对象中检索提取的特征并将它们编译成一个浮点数数组的列表。'
- en: '`shutdown()`: Shuts down the executor service, stopping any further task submissions
    and allowing the application to terminate cleanly.'
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shutdown()`: 关闭执行器服务，停止任何进一步的任务提交，并允许应用程序干净地终止。'
- en: This approach demonstrates the efficient handling of potentially CPU-intensive
    feature extraction tasks by distributing them across multiple threads, thus leveraging
    modern multi-core processors to speed up the processing of large sets of images.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法展示了通过将任务分配到多个线程来高效处理可能占用 CPU 资源的特性提取任务，从而利用现代的多核处理器加速大量图像的处理。
- en: Practical examples – utilizing Java’s parallel streams for feature extraction
    and data normalization
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实际示例 - 利用 Java 的并行流进行特征提取和数据归一化
- en: Let’s dive into some practical examples of utilizing Java’s parallel streams
    for feature extraction and data normalization in the context of ML workflows.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨一些在机器学习（ML）工作流程中利用 Java 的并行流进行特征提取和数据归一化的实际示例。
- en: Example 1 – Feature extraction using parallel streams
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 示例 1 - 使用并行流进行特征提取
- en: Suppose we have a dataset of text documents, and we want to extract features
    from these documents using the **Term Frequency-Inverse Document Frequency** (**TF-IDF**)
    technique. We can leverage Java’s parallel streams to process the documents concurrently
    and calculate the TF-IDF scores efficiently.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个文本文档数据集，我们想使用 **词频-逆文档频率**（**TF-IDF**）技术从这些文档中提取特征。我们可以利用 Java 的并行流并发处理文档并高效计算
    TF-IDF 分数。
- en: 'Here is the `Document` class, which represents a document with textual content:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是表示包含文本内容的文档的 `Document` 类：
- en: '[PRE7]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here is the `FeatureExtractor` class, which processes a list of documents to
    extract TF-IDF features for each document:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是处理文档列表以提取每个文档的 TF-IDF 特征的 `FeatureExtractor` 类：
- en: '[PRE8]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here’s the code breakdown:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是代码分解：
- en: The `FeatureExtractor` class extracts TF-IDF features from a list of `Document`
    objects using parallel streams
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FeatureExtractor` 类使用并行流从 `Document` 对象列表中提取 TF-IDF 特征'
- en: 'The `extractTfIdfFeatures()` method does the following:'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`extractTfIdfFeatures()` 方法执行以下操作：'
- en: Processes the documents concurrently using `parallelStream()`
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `parallelStream()` 并发处理文档
- en: Calculates the TF-IDF scores for each word in each document
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为每个文档中的每个单词计算 TF-IDF 分数
- en: Returns the results as a list of `Double[]` arrays
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 返回结果作为 `Double[]` 数组的列表
- en: 'The `calculateTermFrequency()` and `calculateInverseDocumentFrequency()` methods
    are helper methods:'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`calculateTermFrequency()` 和 `calculateInverseDocumentFrequency()` 方法是辅助方法：'
- en: '`calculateTermFrequency()` computes the term frequency of a word in a document'
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`calculateTermFrequency()` 计算文档中单词的词频'
- en: '`calculateInverseDocumentFrequency()` computes the inverse document frequency
    of a word'
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`calculateInverseDocumentFrequency()` 计算单词的逆文档频率'
- en: The `Document` class represents a document with its content
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Document` 类表示包含其内容的文档'
- en: Parallel streams are utilized to efficiently parallelize the feature extraction
    process
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行流被用来有效地并行化特征提取过程
- en: Multi-core processors are leveraged to speed up the computation of TF-IDF scores
    for large datasets
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用多核处理器加速大型数据集 TF-IDF 分数的计算
- en: Integrating this feature extraction code into a larger ML pipeline is straightforward.
    You can use the `FeatureExtractor` class as a preprocessing step before feeding
    the data into your ML model.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 将此特征提取代码集成到更大的机器学习（ML）管道中很简单。您可以在将数据输入到您的 ML 模型之前，将 `FeatureExtractor` 类用作预处理步骤。
- en: 'Here’s an example of how you can integrate it into a pipeline:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何将其集成到管道中的一个示例：
- en: '[PRE9]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: By extracting the TF-IDF features using the `FeatureExtractor` class, you can
    obtain a numerical representation of the documents, which can be used as input
    features for various ML tasks such as document classification, clustering, or
    similarity analysis.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用 `FeatureExtractor` 类提取 TF-IDF 特征，你可以获得文档的数值表示，这可以用作各种机器学习任务的输入特征，例如文档分类、聚类或相似性分析。
- en: Example 2 – Data normalization using parallel streams
  id: totrans-157
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 示例 2 – 使用并行流进行数据归一化
- en: Data normalization is a common preprocessing step in ML to scale the features
    to a common range. Let’s say we have a dataset of numerical features, and we want
    to normalize each feature using the min-max scaling technique. We can utilize
    parallel streams to normalize the features concurrently.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 数据归一化是机器学习中的常见预处理步骤，用于将特征缩放到一个公共范围。假设我们有一个数值特征的数据集，我们希望使用最小-最大缩放技术对每个特征进行归一化。我们可以利用并行流来并发地归一化特征。
- en: 'Here is the code snippet:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是代码片段：
- en: '[PRE10]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The main components of the `DataNormalizer` class are as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataNormalizer` 类的主要组件如下：'
- en: The `normalizeData()` method uses `IntStream.range(0, numFeatures).parallel()`
    to process each feature concurrently
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`normalizeData()` 方法使用 `IntStream.range(0, numFeatures).parallel()` 并发处理每个特征'
- en: 'For each feature, the `mapToObj()` operation is applied to perform the following
    steps:'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个特征，应用 `mapToObj()` 操作执行以下步骤：
- en: Retrieve the feature values using the `getFeatureValues()` method
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `getFeatureValues()` 方法检索特征值
- en: Calculate the minimum and maximum values of the feature using `Arrays.stream(featureValues).min()`
    and `Arrays.stream(featureValues).max()`, respectively
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `Arrays.stream(featureValues).min()` 和 `Arrays.stream(featureValues).max()`
    分别计算特征的最低值和最高值。
- en: Normalize the feature values using the `normalize()` method, which applies the
    min-max scaling formula
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `normalize()` 方法归一化特征值，该方法应用最小-最大缩放公式。
- en: The normalized feature values are collected into a 2D array using `toArray(double[][]::new)`
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `toArray(double[][]::new)` 将归一化的特征值收集到一个二维数组中
- en: The `getFeatureValues()` and `normalize()` methods are helper methods used to
    retrieve the values of a specific feature and apply the min-max scaling formula,
    respectively
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getFeatureValues()` 和 `normalize()` 方法是辅助方法，分别用于检索特定特征的值并应用最小-最大缩放公式。'
- en: 'Integrating data normalization into an ML pipeline is crucial to ensure that
    all features are on a similar scale, which can improve the performance and convergence
    of many ML algorithms. Here’s an example of how you can use the `DataNormalizer`
    class in a pipeline:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据归一化集成到机器学习管道中对于确保所有特征处于相似尺度至关重要，这可以提高许多机器学习算法的性能和收敛性。以下是如何在管道中使用 `DataNormalizer`
    类的示例：
- en: '[PRE11]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: By normalizing the raw data using the `DataNormalizer` class, you ensure that
    all features are scaled to a common range, typically between `0` and `1`. This
    preprocessing step can significantly improve the performance and stability of
    many ML algorithms, especially those based on gradient descent optimization.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用 `DataNormalizer` 类对原始数据进行归一化，你可以确保所有特征都缩放到一个公共范围，通常是 `0` 到 `1` 之间。这个预处理步骤可以显著提高许多机器学习算法的性能和稳定性，尤其是基于梯度下降优化的算法。
- en: These examples demonstrate how you can easily integrate the `FeatureExtractor`
    and `DataNormalizer` classes into a larger ML pipeline. By using these classes
    as preprocessing steps, you can efficiently perform feature extraction and data
    normalization in parallel, leveraging the power of Java’s parallel streams. The
    resulting features and normalized data can then be used as input for subsequent
    steps in your ML pipeline, such as model training, evaluation, and prediction.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例演示了如何轻松地将 `FeatureExtractor` 和 `DataNormalizer` 类集成到更大的机器学习管道中。通过将这些类用作预处理步骤，你可以有效地并行执行特征提取和数据归一化，利用
    Java 并行流的力量。然后，可以将生成的特征和归一化数据用作机器学习管道后续步骤的输入，例如模型训练、评估和预测。
- en: As we conclude this section, we have explored a variety of Java tools that significantly
    enhance the parallel processing capabilities essential for modern ML workflows.
    Utilizing Java’s robust parallel streams, executors, and the Fork/Join framework,
    we’ve seen how to tackle complex, data-intensive tasks more efficiently. These
    tools not only facilitate faster data processing and model training but also enable
    scalable ML deployments capable of handling the increasing size and complexity
    of datasets.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节结束时，我们探讨了各种Java工具，这些工具显著增强了现代机器学习工作流程所需的并行处理能力。通过利用Java强大的并行流、执行器和Fork/Join框架，我们看到了如何更有效地处理复杂、数据密集型任务。这些工具不仅促进了更快的数据处理和模型训练，还使可扩展的机器学习部署成为可能，能够处理数据集的日益增长和复杂性。
- en: Understanding and implementing these concurrency tools is crucial because they
    allow ML practitioners to optimize computational resources, thereby reducing execution
    times and improving application performance. This knowledge ensures that your
    ML solutions can keep pace with the demands of ever-growing data volumes and complexity.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 理解和实现这些并发工具至关重要，因为它们允许机器学习从业者优化计算资源，从而减少执行时间并提高应用程序性能。这种知识确保了您的机器学习解决方案能够跟上不断增长的数据量和复杂性的需求。
- en: Next, we will transition from the foundational concepts and practical applications
    of Java’s concurrency tools to a discussion on achieving scalable ML deployments
    using Java’s concurrency APIs. In this upcoming section, we’ll delve deeper into
    strategic implementations that enhance the scalability and efficiency of ML systems
    using these powerful concurrency tools.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将从Java并发工具的基础概念和实际应用转向讨论如何使用Java的并发API实现可扩展的机器学习部署。在即将到来的章节中，我们将深入探讨战略实施，这些实施利用这些强大的并发工具增强了机器学习系统的可扩展性和效率。
- en: Achieving scalable ML deployments using Java’s concurrency APIs
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Java的并发API实现可扩展的机器学习部署
- en: Before delving into the specific strategies for leveraging Java’s concurrency
    APIs in ML deployments, it’s essential to understand the critical role these APIs
    play in the modern ML landscape. ML tasks often require processing vast amounts
    of data and performing complex computations that can be highly time-consuming.
    Java’s concurrency APIs enable the execution of multiple parts of these tasks
    in parallel, significantly speeding up the process and improving the efficiency
    of resource utilization. This capability is indispensable for scaling ML deployments,
    allowing them to handle larger datasets and more sophisticated models without
    compromising performance.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨如何利用Java的并发API在机器学习部署中发挥具体策略之前，理解这些API在现代机器学习领域中的关键作用至关重要。机器学习任务通常需要处理大量数据并执行可能非常耗时的复杂计算。Java的并发API允许并行执行这些任务的多个部分，从而显著加快处理速度并提高资源利用效率。这种能力对于扩展机器学习部署至关重要，使得它们能够处理更大的数据集和更复杂的模型，而不会影响性能。
- en: 'To achieve scalable ML deployments using Java’s concurrency APIs, we can consider
    the following strategies and techniques:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Java的并发API实现可扩展的机器学习部署，我们可以考虑以下策略和技术：
- en: '**Data preprocessing**: Leverage parallelism to preprocess large datasets efficiently.
    Utilize Java’s parallel streams or custom thread pools to distribute data preprocessing
    tasks across multiple threads.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据预处理**：利用并行性高效地预处理大量数据集。利用Java的并行流或自定义线程池将数据预处理任务分配到多个线程。'
- en: '**Feature extraction**: Employ concurrent techniques to extract features from
    raw data in parallel. Utilize Java’s concurrency APIs to parallelize feature extraction
    tasks, enabling faster processing of high-dimensional data.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征提取**：采用并发技术并行地从原始数据中提取特征。利用Java的并发API并行化特征提取任务，从而实现高维数据的快速处理。'
- en: '**Model training**: Implement concurrent model training approaches to accelerate
    the learning process. Utilize multithreading or distributed computing frameworks
    to train models in parallel, leveraging the available computational resources.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型训练**：实施并发模型训练方法以加速学习过程。利用多线程或分布式计算框架并行训练模型，利用可用的计算资源。'
- en: '**Model evaluation**: Perform model evaluation and validation concurrently
    to speed up the assessment process. Utilize Java’s concurrency primitives to parallelize
    evaluation tasks, such as cross-validation or hyperparameter tuning.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型评估**：并行执行模型评估和验证以加快评估过程。利用Java的并发原语并行化评估任务，如交叉验证或超参数调整。'
- en: '**Pipeline parallelism**: Implement a pipeline where different stages of the
    ML model training (e.g., data loading, preprocessing, and training) can be executed
    in parallel. Each stage of the pipeline can run concurrently on separate threads,
    reducing overall processing time.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道并行性**：实现一个管道，其中机器学习模型训练的不同阶段（例如，数据加载、预处理和训练）可以并行执行。管道的每个阶段可以在单独的线程上并发运行，从而减少整体处理时间。'
- en: Best practices for thread management and reducing synchronization overhead
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线程管理最佳实践和减少同步开销
- en: When dealing with Java concurrency, effective thread management and reducing
    synchronization overhead are crucial for optimizing performance and maintaining
    robust application behavior.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理Java并发时，有效的线程管理和减少同步开销对于优化性能和保持稳健的应用行为至关重要。
- en: 'Here are some best practices that can help achieve these objectives:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些最佳实践，可以帮助实现这些目标：
- en: '`java.util.concurrent` package such as `ConcurrentHashMap`, `Semaphore`, and
    `ReentrantLock`, which offer extended capabilities and better performance compared
    to traditional synchronized methods and blocks.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`java.util.concurrent`包，如`ConcurrentHashMap`、`Semaphore`和`ReentrantLock`，它们提供了比传统同步方法和块更好的扩展功能和性能。'
- en: '`ConcurrentHashMap` instead of `Collections.synchronizedMap(new HashMap<...>())`.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`ConcurrentHashMap`而不是`Collections.synchronizedMap(new HashMap<...>())`。
- en: '`ReadWriteLock` can offer better throughput by allowing multiple threads to
    read the data concurrently while still ensuring mutual exclusion during writes.*   **Optimize**
    **task granularity**:'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ReadWriteLock`可以通过允许多个线程并发读取数据，同时在写入时确保互斥性，从而提供更好的吞吐量。*   **优化** **任务粒度**：'
- en: '**Balance granularity and overhead**: Too fine a granularity can lead to higher
    overhead in terms of context switching and scheduling. Conversely, too coarse
    a granularity might lead to underutilization of CPU resources. Strike a balance
    based on the task and system capabilities.'
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平衡粒度和开销**：过细的粒度可能导致上下文切换和调度的开销增加。相反，过粗的粒度可能导致CPU资源利用率不足。根据任务和系统能力进行平衡。'
- en: '**Use partitioning strategies**: In cases such as batch processing or data-parallel
    algorithms, partition the data into chunks that can be processed independently
    and concurrently, but are large enough to ensure that the overhead of thread management
    is justified by the performance gain.*   `CompletableFuture` can help avoid blocking
    threads, allowing them to perform other tasks or to be returned to the thread
    pool, reducing the need for synchronization and the number of threads required.*   **Employ
    event-driven architectures**: In scenarios such as I/O operations, use event-driven,
    non-blocking APIs to free up threads from waiting for operations to complete,
    thus enhancing scalability and reducing the need for synchronization.*   `Executors`
    factory methods to create thread pools that match your application’s specific
    needs.*   **Avoid thread leakage**: Ensure that threads are properly returned
    to the pool after task completion. Watch out for tasks that can block indefinitely
    or hang, which can exhaust the thread pool.*   **Monitor and tune performance**:
    Regular monitoring and tuning based on actual system performance and throughput
    can help in optimally configuring thread pools and concurrency settings.*   **Consider
    new concurrency features** **in Java**:'
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用分区策略**：在批量处理或数据并行算法等情况下，将数据分成可以独立和并发处理的数据块，但数据块足够大，以确保线程管理的开销由性能提升所证明是合理的。*   `CompletableFuture`可以帮助避免阻塞线程，使它们能够执行其他任务或返回到线程池，减少同步的需求和所需线程的数量。*   **采用事件驱动架构**：在I/O操作等场景中，使用事件驱动、非阻塞API来释放线程等待操作完成的等待，从而提高可伸缩性并减少同步的需求。*   `Executors`工厂方法用于创建符合您应用程序特定需求的线程池。*   **避免线程泄漏**：确保任务完成后线程被正确地返回到池中。注意那些可能无限期阻塞或挂起的任务，这可能会耗尽线程池。*   **监控和调整性能**：根据实际系统性能和吞吐量进行定期监控和调整，有助于在最佳配置线程池和并发设置。*   **考虑Java中的新并发特性**：'
- en: '**Project Loom**: Stay informed about upcoming features such as Project Loom,
    which aims to introduce lightweight concurrency constructs such as fibers, offering
    a potential reduction in overhead compared to traditional threads.'
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Project Loom**：关注即将推出的功能，如Project Loom，它旨在引入轻量级并发构造，如fibers，与传统的线程相比，可能减少开销。'
- en: Implementing these best practices allows for more efficient thread management,
    reduces the risks of deadlock and contention, and improves the overall scalability
    and responsiveness of Java applications in concurrent execution environments.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 实施这些最佳实践可以更有效地管理线程，降低死锁和竞争的风险，并提高Java应用程序在并发执行环境中的整体可扩展性和响应性。
- en: As we leverage Java’s concurrency features to optimize ML deployments and implement
    best practices for efficient thread management, we stand at the forefront of a
    new era in AI development. In the next section, we will explore the exciting possibilities
    that arise when combining Java’s robustness and scalability with the cutting-edge
    field of generative AI, opening up a world of opportunities for creating intelligent,
    creative, and interactive applications.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们利用Java的并发功能来优化机器学习部署并实施最佳线程管理实践，我们站在AI开发新时代的前沿。在下一节中，我们将探讨将Java的稳健性和可扩展性与生成式AI这一前沿领域相结合所带来的激动人心的可能性，为创建智能、创造性和交互式应用程序开辟了一个新的世界。
- en: Generative AI and Java – a new frontier
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式AI与Java – 一个新的前沿
- en: Generative AI encompasses a set of technologies that enable machines to understand
    and generate content with minimal human intervention. This can include generating
    text, images, music, and other forms of media. The field is primarily dominated
    by ML and deep learning models.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI涵盖一系列技术，这些技术使机器能够在最小的人为干预下理解和生成内容。这可以包括生成文本、图像、音乐和其他形式的媒体。该领域主要由机器学习和深度学习模型主导。
- en: 'Generative AI includes these key areas:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI包括以下关键领域：
- en: '**Generative models**: These are models that can generate new data instances
    that resemble the training data. Examples include **generative adversarial networks**
    (**GANs**), **variational autoencoders** (**VAEs**), and Transformer-based models
    such as **Generative Pre-trained Transformer** (**GPT**) and DALL-E.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成模型**：这些模型可以生成与训练数据相似的新数据实例。例如，**生成对抗网络（GANs**）、**变分自编码器（VAEs**）以及基于Transformer的模型，如**生成预训练Transformer（GPT**）和DALL-E。'
- en: '**Deep learning**: Most generative AI models are based on deep learning techniques
    that use neural networks with many layers. These models are trained using a large
    amount of data to generate new content.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度学习**：大多数生成式AI模型基于深度学习技术，这些技术使用多层神经网络。这些模型通过大量数据训练，以生成新的内容。'
- en: '**NLP**: This is a pivotal area within AI that deals with the interaction between
    computers and humans through natural language. The field has seen a transformative
    impact through generative AI models, which can write texts, create summaries,
    translate languages, and more.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自然语言处理（NLP）**：这是AI中的一个关键领域，涉及计算机与人类通过自然语言进行交互。该领域通过生成式AI模型产生了变革性的影响，这些模型可以撰写文本、创建摘要、翻译语言等。'
- en: For Java developers, understanding and incorporating generative AI concepts
    can open up new possibilities in software development.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Java开发者来说，理解和采用生成式AI概念可以在软件开发中开辟新的可能性。
- en: 'Some of the key areas where generative AI can be applied in Java development
    include the following:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI在Java开发中可以应用的几个关键领域包括以下内容：
- en: '**Integration in Java applications**: Java developers can integrate generative
    AI models into their applications to enhance features such as chatbots, content
    generation, and customer interactions. Libraries such as *DL4J* or the *TensorFlow*
    Java API make it easier to implement these AI capabilities in a Java environment.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在Java应用程序中集成**：Java开发者可以将生成式AI模型集成到他们的应用程序中，以增强聊天机器人、内容生成和客户交互等功能。例如，*DL4J*库或*TensorFlow*
    Java API等库使得在Java环境中实现这些AI功能变得更加容易。'
- en: '**Automation and enhancement**: Generative AI can automate repetitive coding
    tasks, generate code snippets, and provide documentation, thereby increasing productivity.
    Tools such as *GitHub Copilot* are paving the way, and Java developers can benefit
    significantly from these advancements.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动化和增强**：生成式AI可以自动化重复的编码任务，生成代码片段，并提供文档，从而提高生产力。例如，*GitHub Copilot*这样的工具正在开辟道路，Java开发者可以从这些进步中受益良多。'
- en: '**Custom model training**: While Java is not traditionally known for its AI
    capabilities, frameworks such as *DL4J* allow developers to train their custom
    models directly within Java. This can be particularly useful for businesses that
    operate on Java-heavy infrastructure and want to integrate AI without switching
    to Python.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自定义模型训练**: 虽然Java传统上并不以AI能力著称，但如*DL4J*这样的框架允许开发者直接在Java中训练自定义模型。这对于那些在Java密集型基础设施上运营且希望集成AI而不切换到Python的企业来说尤其有用。'
- en: '**Big data and AI**: Java continues to be a strong player in big data technologies
    (such as *Apache Hadoop* and *Apache Spark*). Integrating AI into these ecosystems
    can enhance data processing capabilities, making predictive analytics and data-driven
    decision-making more efficient.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大数据与AI**: Java在大数据技术（如*Apache Hadoop*和*Apache Spark*）中继续扮演着重要角色。将这些生态系统与AI集成可以增强数据处理能力，使预测分析和数据驱动的决策更加高效。'
- en: As AI continues to evolve, its integration into Java environments is expected
    to grow, bringing new capabilities and transforming how traditional systems are
    developed and maintained. For Java developers, this represents a new frontier
    that holds immense potential for innovation and enhanced application functionalities.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 随着AI的不断发展，其与Java环境的集成预计将增长，带来新的功能，并改变传统系统的开发和维护方式。对于Java开发者来说，这代表了一个充满创新和增强应用功能潜力的新领域。
- en: Leveraging Java’s concurrency model for efficient generative AI model training
    and inference
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用Java的并发模型进行高效的生成式AI模型训练和推理
- en: When training and deploying generative AI models, handling massive datasets
    and computationally intensive tasks efficiently is crucial. Java’s concurrency
    model can be a powerful tool to optimize these processes, especially in environments
    where Java is already an integral part of the infrastructure.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练和部署生成式AI模型时，高效处理大量数据集和计算密集型任务至关重要。Java的并发模型可以是一个强大的工具来优化这些流程，尤其是在Java已经是基础设施重要部分的环境中。
- en: Let us explore how Java’s concurrency features can be utilized for enhancing
    generative AI model training and inference.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索Java的并发特性如何被用于增强生成式AI模型训练和推理。
- en: Parallel data processing – using the Stream API
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 并行数据处理 – 使用Stream API
- en: For AI, particularly during data preprocessing, parallel streams can be used
    to perform operations such as filtering, mapping, and sorting concurrently, reducing
    the time needed for preparing datasets for training.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 对于AI，尤其是在数据预处理期间，可以使用并行流来并行执行过滤、映射和排序等操作，从而减少准备训练数据集所需的时间。
- en: 'Here is an example:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个例子：
- en: '[PRE12]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The code snippet uses *parallel stream* processing to preprocess a list of `Data`
    objects concurrently. It creates a parallel stream from `dataList`, applies the
    `preprocess` method to each object, and collects the preprocessed objects into
    a new list, which replaces the original `dataList`. This approach can potentially
    improve performance when dealing with large datasets by utilizing multiple threads
    for concurrent execution.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 代码片段使用*并行流*处理来并行预处理`Data`对象列表。它从`dataList`创建一个并行流，对每个对象应用`preprocess`方法，并将预处理后的对象收集到一个新列表中，该列表替换了原始的`dataList`。这种方法通过利用多个线程进行并发执行，在处理大型数据集时可能提高性能。
- en: Concurrent model training – ExecutorService for asynchronous execution
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 并行模型训练 – 使用ExecutorService进行异步执行
- en: You can use `ExecutorService` to manage a pool of threads and submit training
    tasks concurrently. This is particularly useful when training multiple models
    or performing cross-validation, as these tasks are inherently parallelizable.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`ExecutorService`来管理线程池并提交并行训练任务。当训练多个模型或执行交叉验证时，这特别有用，因为这些任务本质上是可并行化的。
- en: 'Here is a code example:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个代码示例：
- en: '[PRE13]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The code uses `ExecutorService` with a fixed thread pool of `10` to execute
    model training tasks concurrently. It iterates over a list of models, submitting
    each training task to `ExecutorService` using `submit()`. The `shutdown()` method
    is called to initiate the shutdown of `ExecutorService`, and `awaitTermination()`
    is used to wait for all tasks to be completed or until a specified timeout is
    reached. This approach allows for Concurrent model training parallel execution
    of model training tasks, potentially improving performance when dealing with multiple
    models or computationally intensive training.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 代码使用具有固定线程池 `10` 的 `ExecutorService` 来并发执行模型训练任务。它遍历模型列表，使用 `submit()` 方法将每个训练任务提交给
    `ExecutorService`。调用 `shutdown()` 方法来启动 `ExecutorService` 的关闭，并使用 `awaitTermination()`
    等待所有任务完成或达到指定的超时时间。这种方法允许并发模型训练并行执行模型训练任务，在处理多个模型或计算密集型训练时可能提高性能。
- en: Efficient asynchronous inference
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高效的异步推理
- en: '`CompletableFuture` provides a non-blocking way to handle operations, which
    can be used to improve the response time of AI inference tasks. This is crucial
    in production environments to serve predictions quickly under high load.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '`CompletableFuture` 提供了一种非阻塞的方式来处理操作，这可以用于提高人工智能推理任务的响应时间。这在生产环境中至关重要，以便在高负载下快速提供预测。'
- en: 'Here is a code snippet:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个代码片段：
- en: '[PRE14]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The code uses `CompletableFuture` for asynchronous inference in AI systems.
    It creates a `CompletableFuture` that represents an asynchronous prediction computation
    using `supplyAsync`, which takes a `(model.predict(input))` supplier function
    and an `Executor`. The code continues executing other tasks while the prediction
    is computed asynchronously. Once the prediction is complete, a callback registered
    with `thenAccept()` is invoked to handle the prediction result. This non-blocking
    approach improves response times in production environments under high load.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 代码使用 `CompletableFuture` 在人工智能系统中进行异步推理。它创建一个 `CompletableFuture`，该 `CompletableFuture`
    使用 `supplyAsync` 表示异步预测计算，该函数接受一个 `(model.predict(input))` 供应函数和一个 `Executor`。代码在预测异步计算的同时继续执行其他任务。一旦预测完成，使用
    `thenAccept()` 注册的回调被调用以处理预测结果。这种非阻塞方法在负载高的情况下提高了生产环境中的响应时间。
- en: Reducing synchronization overhead – lock-free algorithms and data structures
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 减少同步开销 - 无锁算法和数据结构
- en: Utilize concurrent data structures such as `ConcurrentHashMap` and atomic classes
    such as `AtomicInteger` to minimize the need for explicit synchronization. This
    reduces overhead and can enhance performance when multiple threads interact with
    shared resources during AI tasks.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 利用 `ConcurrentHashMap` 和 `AtomicInteger` 等并发数据结构和原子类来最小化显式同步的需求。这减少了开销，并在多个线程在人工智能任务期间交互共享资源时可以增强性能。
- en: 'Here is an example:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个示例：
- en: '[PRE15]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The code uses `ConcurrentHashMap` to reduce synchronization overhead in AI tasks.
    `ConcurrentHashMap` is a thread-safe map that allows multiple threads to read
    and write simultaneously without explicit synchronization. The code attempts to
    add a new entry to `modelCache` using `putIfAbsent()`, which ensures that only
    one thread loads the model for a given `modelName`, while subsequent threads retrieve
    the existing model from the cache. By using thread-safe concurrent data structures,
    the code minimizes synchronization overhead and improves performance in multithreaded
    AI systems.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 代码使用 `ConcurrentHashMap` 来减少人工智能任务中的同步开销。`ConcurrentHashMap` 是一个线程安全的映射，允许多个线程同时读取和写入，而无需显式同步。代码尝试使用
    `putIfAbsent()` 方法向 `modelCache` 添加新条目，这确保了只有单个线程为给定的 `modelName` 加载模型，而后续线程则从缓存中检索现有模型。通过使用线程安全的并发数据结构，代码最小化了同步开销，并在多线程人工智能系统中提高了性能。
- en: Case study – Java-based generative AI project illustrating concurrent data generation
    and processing
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 案例研究 - 基于Java的生成人工智能项目，展示并发数据生成和处理
- en: This case study outlines a hypothetical Java-based project that leverages the
    Java concurrency model to facilitate generative AI in concurrent data generation
    and processing. The project involves a generative model that creates synthetic
    data for training an ML model in a situation where real data is scarce or sensitive.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 本案例研究概述了一个基于 Java 的假设项目，该项目利用 Java 并发模型来促进并发数据生成和处理中的生成人工智能。该项目涉及一个生成模型，该模型在真实数据稀缺或敏感的情况下为训练机器学习模型创建合成数据。
- en: The objective is to generate synthetic data that mirrors real-world data characteristics
    and use this data to train a predictive model efficiently.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是生成反映真实世界数据特性的合成数据，并使用这些数据高效地训练预测模型。
- en: It includes the following key components.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 它包括以下关键组件。
- en: Data generation module
  id: totrans-235
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据生成模块
- en: This uses a GAN implemented in DL4J. The GAN learns from a limited dataset to
    produce new, synthetic data points.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这使用了在 DL4J 中实现的 GAN。GAN 从有限的数据集中学习，以生成新的、合成的数据点。
- en: The code is designed to produce synthetic data points using a GAN. GANs are
    a type of neural network architecture where two models (a generator and a discriminator)
    are trained simultaneously. The generator tries to produce data that is indistinguishable
    from real data, while the discriminator attempts to differentiate between real
    and generated data. In practical applications, once the generator is sufficiently
    trained, it can be used to generate new data points that mimic the characteristics
    of the original dataset.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 代码被设计用来使用生成对抗网络（GAN）生成合成数据点。GAN 是一种神经网络架构，其中有两个模型（生成器和判别器）同时训练。生成器试图生成与真实数据不可区分的数据，而判别器试图区分真实数据和生成数据。在实际应用中，一旦生成器得到充分训练，就可以用来生成新的数据点，这些数据点模仿原始数据集的特征。
- en: 'Here is the code snippet:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是代码片段：
- en: '[PRE16]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Here’s a breakdown of what each part of the code does:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是代码每个部分功能的分解：
- en: '`ForkJoinPool` is instantiated with a parallelism level of `4`, indicating
    that the pool will use four threads. This pool is designed to efficiently handle
    a large number of tasks by dividing them into smaller parts, processing them in
    parallel, and combining the results. The purpose here is to utilize multiple cores
    of the processor to enhance the performance of data-intensive tasks.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ForkJoinPool` 以 `4` 个并行级别实例化，表示该池将使用四个线程。这个池被设计为通过将任务分成更小的部分，并行处理它们并合并结果来高效地处理大量任务。这里的目的是利用处理器的多个核心来提高数据密集型任务的性能。'
- en: 'The `customThreadPool.submit(…)` method submits a task to `ForkJoinPool`. The
    task is specified as a lambda expression that generates a list of synthetic data
    points. Inside the lambda, we see the following:'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`customThreadPool.submit(…)` 方法将一个任务提交给 `ForkJoinPool`。该任务指定为一个 lambda 表达式，用于生成一系列合成数据点。在
    lambda 表达式中，我们可以看到以下内容：'
- en: '`IntStream.rangeClosed(1, 1000)`: This generates a sequential stream of integers
    from 1 to 1,000, where each integer represents an individual task of generating
    a data point.'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IntStream.rangeClosed(1, 1000)`：这生成一个从 1 到 1,000 的整数序列流，其中每个整数代表生成一个数据点的单个任务。'
- en: '`.parallel()`: This method converts the sequential stream into a parallel stream.
    When a stream is parallel, the operations on the stream (such as mapping and collecting)
    are performed in parallel across multiple threads.'
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.parallel()`：这个方法将顺序流转换为并行流。当一个流是并行的，流上的操作（如映射和收集）将在多个线程上并行执行。'
- en: '`.mapToObj(i -> g.generate())`: For each integer in the stream (from `1` to
    `1000`), the `mapToObj` function calls the `generate()` method on an instance
    of a generator, `g`. This method is assumed to be responsible for creating a new
    synthetic data point. The result is a stream of `DataPoint` objects.'
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.mapToObj(i -> g.generate())`：对于流中的每个整数（从 `1` 到 `1000`），`mapToObj` 函数在生成器实例
    `g` 上调用 `generate()` 方法。这个方法被假设为负责创建一个新的合成数据点。结果是 `DataPoint` 对象的流。'
- en: '`.collect(Collectors.toList())`: This terminal operation collects the results
    from the parallel stream into `List<DataPoint>`. The collection process is designed
    to handle the parallel stream correctly, aggregating the results from multiple
    threads into a single list.'
  id: totrans-246
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.collect(Collectors.toList())`：这个终端操作将并行流中的结果收集到 `List<DataPoint>` 中。收集过程被设计为正确处理并行流，将多个线程的结果聚合到一个列表中。'
- en: Since `submit()` returns a future, calling `get()` on this future blocks the
    current thread until all the synthetic data generation tasks are complete and
    the list is fully populated. The result is that `syntheticData` will hold all
    the generated data points after this line executes.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于 `submit()` 返回一个 future，在这个 future 上调用 `get()` 将阻塞当前线程，直到所有合成数据生成任务完成并且列表完全填充。结果是，`syntheticData`
    将在执行此行之后包含所有生成的数据点。
- en: By utilizing `ForkJoinPool`, this code efficiently manages the workload across
    multiple processor cores, reducing the time required to generate a large dataset
    of synthetic data. This approach is particularly advantageous in scenarios where
    quick generation of large volumes of data is crucial, such as in training ML models
    where data augmentation is required to improve model robustness.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用 `ForkJoinPool`，此代码有效地管理了多个处理器核心之间的工作负载，减少了生成大量合成数据所需的时间。这种方法在需要快速生成大量数据的情况下特别有利，例如在训练需要数据增强以提高模型鲁棒性的机器学习模型时。
- en: Data processing module
  id: totrans-249
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据处理模块
- en: This applies various preprocessing techniques to both real and synthetic data
    to prepare it for training. Tasks such as normalization, scaling, and augmentation
    are applied to enhance the synthetic data.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这对真实和合成数据应用各种预处理技术，以准备训练。如归一化、缩放和增强等任务应用于增强合成数据。
- en: The use of parallel streams is particularly advantageous for processing large
    datasets where the computational load can be distributed across multiple cores
    of a machine, thereby reducing the overall processing time. This is essential
    in ML projects where preprocessing can often become a bottleneck due to the volume
    and complexity of the data.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 并行流的使用在处理大型数据集时特别有利，因为计算负载可以分布到机器的多个核心上，从而减少整体处理时间。这在机器学习项目中至关重要，因为在这些项目中，由于数据的体积和复杂性，预处理往往成为瓶颈。
- en: 'Here is a code snippet:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个代码片段：
- en: '[PRE17]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This is the code breakdown:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码分解：
- en: '`syntheticData`, which is the source of the data to be processed. The `ProcessedData`
    type suggests that the list will hold processed versions of the original data.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`syntheticData` 是要处理的数据的来源。`ProcessedData` 类型表明列表将包含原始数据的处理版本。'
- en: '`.parallelStream()` method creates a parallel stream from the `syntheticData`
    list. This allows the processing to be divided across multiple processor cores
    if available, potentially speeding up the operation.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.parallelStream()` 方法从 `syntheticData` 列表中创建一个并行流。如果可用，这允许处理在多个处理器核心之间划分，从而可能加快操作速度。'
- en: '`.map(data -> preprocess(data))` section applies a transformation to each element
    in the stream:'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.map(data -> preprocess(data))` 部分对流中的每个元素应用转换：'
- en: Each element (referred to as `data`) is passed into the `preprocess()` function.
    The `preprocess()` function (not shown in the snippet) is responsible for modifying
    or transforming the data in some way. The output of the `preprocess()` function
    becomes the new element in the resulting stream.
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个元素（称为 `data`）都传递到 `preprocess()` 函数中。`preprocess()` 函数（在代码片段中未显示）负责以某种方式修改或转换数据。`preprocess()`
    函数的输出成为结果流中的新元素。
- en: '`.collect(Collectors.toList())` gathers the processed elements from the stream
    and places them into a new `List<ProcessedData>` called `processedData`.'
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.collect(Collectors.toList())` 从流中收集处理后的元素并将它们放入一个新的 `List<ProcessedData>`
    中，称为 `processedData`。'
- en: This code snippet efficiently takes a list of data, applies preprocessing steps
    in parallel, and collects the results into a new list of processed data.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码片段有效地处理数据列表，并行应用预处理步骤，并将结果收集到一个新的处理数据列表中。
- en: Model training module
  id: totrans-261
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型训练模块
- en: The model training module leverages the power of DL4J to train a predictive
    model on processed data. To accelerate training, it breaks down the dataset into
    batches, allowing the model to be trained on multiple batches simultaneously using
    `ExecutorService`. Further efficiency is gained by employing `CompletableFuture`
    to update the model asynchronously after processing each batch; this prevents
    the main training process from being stalled.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练模块利用DL4J的强大功能在处理后的数据上训练预测模型。为了加速训练，它将数据集分解成批次，允许使用 `ExecutorService` 同时在多个批次上训练模型。通过在处理每个批次后异步更新模型，采用
    `CompletableFuture` 进一步提高了效率；这防止了主训练过程停滞。
- en: 'Here is a code snippet:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个代码片段：
- en: '[PRE18]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This is an explanation of the key components:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关键组件的解释：
- en: '`trainModel(List<DataPoint> batch)`: This function defines the core model training
    logic within the DL4J framework. It accepts a batch of data and returns a partially
    trained model.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trainModel(List<DataPoint> batch)`: 这个函数在DL4J框架内定义了核心模型训练逻辑。它接受一个数据批次并返回一个部分训练好的模型。'
- en: '`ExecutorService executorService = Executors.newFixedThreadPool(10)`: A thread
    pool of 10 threads is created, allowing simultaneous training on up to 10 data
    batches for improved efficiency.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ExecutorService executorService = Executors.newFixedThreadPool(10)`: 创建了一个包含10个线程的线程池，允许同时训练多达10个数据批次，以提高效率。'
- en: '`List<Future<Model>> futures = new ArrayList<>(); ... futures.add(future);`:
    This code snippet stores references to the asynchronous model training tasks.
    Each `Future<Model>` object represents a model being trained on a specific batch.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`List<Future<Model>> futures = new ArrayList<>(); ... futures.add(future);`：此代码片段存储了对异步模型训练任务的引用。每个`Future<Model>`对象代表在特定批次上训练的模型。'
- en: '`List<Model> models = futures.stream()...`: This line extracts the trained
    models from the futures list once they are ready.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`List<Model> models = futures.stream()...`：此行在准备就绪后从futures列表中提取训练好的模型。'
- en: '`executorService.shutdown();`: This signals the completion of the training
    process and releases resources associated with the thread pool.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`executorService.shutdown();`：这表示训练过程的完成并释放与线程池相关的资源。'
- en: This project demonstrates a well-structured approach to addressing the challenges
    of data scarcity in ML. By leveraging a GAN for synthetic data generation, coupled
    with efficient concurrent processing and a robust DL4J-based training module,
    it provides a scalable solution for training predictive models in real-world scenarios.
    The use of Java’s concurrency features ensures optimal performance and resource
    utilization throughout the pipeline.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目展示了应对机器学习中数据稀缺挑战的良好结构化方法。通过利用生成对抗网络（GAN）进行合成数据生成，结合高效的并发处理和基于DL4J的强大训练模块，它为在现实场景中训练预测模型提供了一个可扩展的解决方案。Java的并发功能确保了在整个流程中性能和资源利用的最优化。
- en: Summary
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter offered an in-depth exploration of harnessing Java’s concurrency
    mechanisms to significantly enhance ML processes. By facilitating the simultaneous
    execution of multiple operations, Java effectively shortens the durations required
    for data preprocessing and model training, which are critical bottlenecks in ML
    workflows. The chapter presented practical examples and case studies that demonstrate
    how Java’s concurrency capabilities can be applied to real-world ML applications.
    These examples vividly showcased the substantial improvements in performance and
    scalability that could be achieved.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 本章深入探讨了利用Java的并发机制来显著提高机器学习过程。通过促进多个操作的并行执行，Java有效地缩短了数据预处理和模型训练所需的时间，这些是机器学习工作流程中的关键瓶颈。本章提供了实际示例和案例研究，展示了Java的并发能力如何应用于现实世界的机器学习应用。这些示例生动地展示了在性能和可扩展性方面可以实现的重大改进。
- en: Furthermore, the chapter outlined specific strategies, such as utilizing parallel
    streams and custom thread pools, to optimize large-scale data processing and perform
    complex computations efficiently. This discussion is crucial for developers aiming
    to enhance the scalability and performance of ML systems. Additionally, the text
    provided a detailed list of necessary tools and dependencies, accompanied by illustrative
    code examples. These resources are designed to assist developers in effectively
    integrating Java concurrency strategies into their ML projects.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，本章概述了特定的策略，例如利用并行流和自定义线程池，以优化大规模数据处理并高效执行复杂计算。对于旨在提高机器学习系统可扩展性和性能的开发者来说，这一讨论至关重要。此外，文本还提供了详细的工具和依赖项列表，并配有说明性代码示例。这些资源旨在帮助开发者在他们的机器学习项目中有效地集成Java并发策略。
- en: The narrative also encouraged forward-thinking by suggesting the exploration
    of innovative applications at the intersection of Java concurrency and generative
    AI. This guidance opens up new possibilities for advancing technology using Java’s
    robust features.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 叙述还通过建议探索Java并发和生成式AI交叉领域的创新应用来鼓励前瞻性思考。此指导为使用Java的强大功能推进技术进步开辟了新的可能性。
- en: In the upcoming chapter, ([*Chapter 8*](B20937_08.xhtml#_idTextAnchor206), *Microservices
    in the Cloud and Java’s Concurrency*), the discussion transitions to the application
    of Java’s concurrency tools within microservices architectures. This chapter aims
    to further unpack how these capabilities can enhance scalability and responsiveness
    in cloud environments, pushing the boundaries of what can be achieved with Java
    in modern software development.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在即将到来的章节中，([*第8章*](B20937_08.xhtml#_idTextAnchor206)，*云中的微服务和Java的并发*），讨论转向了在微服务架构中应用Java的并发工具。本章旨在进一步阐述这些功能如何增强云环境中的可扩展性和响应性，推动Java在现代软件开发中所能实现的目标边界。
- en: Questions
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is the primary benefit of integrating Java’s concurrency mechanisms into
    ML workflows?
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将Java的并发机制集成到机器学习工作流程中的主要好处是什么？
- en: To increase the programming complexity
  id: totrans-279
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了增加编程复杂性
- en: To enhance data security
  id: totrans-280
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以提高数据安全性
- en: To optimize computational efficiency
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以优化计算效率
- en: To simplify code documentation
  id: totrans-282
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 简化代码文档
- en: Which Java tool is highlighted as crucial for processing large datasets in ML
    projects quickly?
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个Java工具被强调为在机器学习项目中快速处理大数据集的关键？
- en: '**Java Database** **Connectivity** (**JDBC**)'
  id: totrans-284
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Java数据库** **连接** （**JDBC**）'
- en: '**Java Virtual** **Machine** (**JVM**)'
  id: totrans-285
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Java虚拟** **机** （**JVM**）'
- en: Parallel Streams
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 并行流
- en: JavaFX
  id: totrans-287
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: JavaFX
- en: What role do custom thread pools play in Java concurrency for ML?
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Java并发中，自定义线程池在机器学习（ML）中扮演什么角色？
- en: They decrease the performance of ML models.
  id: totrans-289
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们降低了机器学习模型的性能。
- en: They are used to manage database transactions only.
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们仅用于管理数据库事务。
- en: They improve scalability and manage large-scale computations.
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们提高了可扩展性并管理大规模计算。
- en: They simplify the user interface design.
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们简化了用户界面设计。
- en: Which of the following is a suggested application of Java’s concurrency in ML
    as discussed in this chapter?
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪项是本章讨论中建议的Java并发在机器学习（ML）中的应用？
- en: To handle multiple user interfaces simultaneously
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同时处理多个用户界面
- en: To perform data preprocessing and model training more efficiently
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更高效地执行数据预处理和模型训练
- en: To replace Python in scientific computing
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用作科学计算的Python替代品
- en: To manage client-server architecture only
  id: totrans-297
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅用于管理客户端-服务器架构
- en: What future direction does this chapter encourage exploring with Java concurrency?
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这章鼓励使用Java并发探索哪些未来的方向？
- en: Decreasing the reliance on multithreading
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 减少对多线程的依赖
- en: Combining Java concurrency with generative AI
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将Java并发与生成式人工智能相结合
- en: Phasing out older Java libraries
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 废弃旧的Java库
- en: Focusing exclusively on single-threaded applications
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 专注于单线程应用程序
