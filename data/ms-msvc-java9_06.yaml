- en: Reactive Microservices
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 响应式微服务
- en: In this chapter, we'll implement reactive microservices using Spring Boot, Spring
    Stream, Apache Kafka, and Apache Avro. We'll make use of the existing Booking
    microservice to implement the message producer, or in other words, generate the
    event. We'll also create a new microservice (Billing) for consuming the messages
    produced by the updated Booking microservice, or we can say, for consuming the
    event generated by the Booking microservice. We'll also discuss the tradeoffs
    between REST-based microservice and event-based microservice.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用Spring Boot、Spring Stream、Apache Kafka和Apache Avro来实现响应式微服务。我们将利用现有的Booking微服务来实现消息生产者，或者说，生成事件。我们还将创建一个新的微服务（Billing），用于消费由更新的Booking微服务产生的消息，或者说，用于消费由Booking微服务生成的事件。我们还将讨论REST-based微服务和事件-based微服务之间的权衡。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: An overview of the reactive microservice architecture
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应式微服务架构概述
- en: Producing an event
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成事件
- en: Consuming the event
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消费事件
- en: An overview of the reactive microservice architecture
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 响应式微服务架构概述
- en: So far, the microservices we have developed are based on REST. We have used
    REST for both internal (inter-microservice, where one microservice communicates
    with another microservice in the same system) and external (through the public
    API) communication. At present, REST fits best for the public API. Are there other
    alternatives for inter-microservices communication? Is it the best approach to
    implement the REST for inter-microservices communication? We'll discuss all this
    in this section.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们所开发的微服务是基于REST的。我们使用REST进行内部（微服务之间的通信，其中一个微服务与同一系统中的另一个微服务进行通信）和外部（通过公共API）通信。目前，REST最适合公共API。对于微服务之间的通信，还有其他选择吗？实现REST用于微服务之间通信的最佳方法是什么？我们将在本节中讨论所有这些问题。
- en: You can build microservices that are purely asynchronous. You can build microservice-based
    systems that would communicate based on events. There is a tradeoff between REST
    and event-based microservices. REST provides synchronous communication, whereas
    reactive microservices are based on asynchronous communication (asynchronous message
    passing).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以构建完全是异步的微服务。你可以构建基于微服务的系统，这种系统将基于事件进行通信。REST和基于事件 的微服务之间有一个权衡。REST提供同步通信，而响应式微服务则基于异步通信（异步消息传递）。
- en: We can use asynchronous communication for inter-microservice communication.
    Based on the requirement and functionality, we can choose REST or asynchronous
    message passing. Consider the example case of a user placing an order, which makes
    a very good case for implementing reactive microservices. On successful order
    placement, the inventory service would recalculate the available items; account
    service would maintain the transaction, correspondence service would send the
    messages (SMS, emails, and so on) to all involved users such as a customer and
    a supplier. In this case, more than one microservice may perform distinct operations
    (inventory, accounts, messaging, and so on) based on an operation (order placement)
    performed in one microservice. Now, just think if all these communications were
    synchronous. Instead, reactive communication, with asynchronous message passing,
    provides efficient use of hardware resources, non-blocking, low latency, and high
    throughput operations.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以为微服务之间的通信使用异步通信。根据需求和功能，我们可以选择REST或异步消息传递。考虑一个用户下订单的示例案例，这对于实现响应式微服务来说是一个非常好的案例。在成功下单后，库存服务将重新计算可用商品；账户服务将维护交易；通信服务将向所有涉及的用户（如客户和供应商）发送消息（短信、电子邮件等）。在这种情况下，一个微服务可能会根据另一个微服务执行的操作（下单）执行不同的操作（库存、账户、消息传递等）。现在，想想如果所有的这些通信都是同步的。相反，通过异步消息传递实现的响应式通信，提供了硬件资源的高效利用、非阻塞、低延迟和高吞吐量操作。
- en: We can primarily divide the microservice implementations into two groups—REST-based
    microservices and event-based/message-driven microservices. Reactive microservices
    are event-based.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将微服务实现主要分为两组——REST-based微服务和事件-based/消息驱动的微服务。响应式微服务是基于事件的。
- en: '![](img/42dd3919-b165-4b8a-b0d2-ec2cf4aacd8b.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/42dd3919-b165-4b8a-b0d2-ec2cf4aacd8b.png)'
- en: Reactive manifesto
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 响应式宣言
- en: Reactive microservices are based on the Reactive Manifesto ([https://www.reactivemanifesto.org/](https://www.reactivemanifesto.org/)).
    The Reactive Manifesto comprises of four principles, which we will now discuss.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '- 响应式微服务基于响应式宣言（[https://www.reactivemanifesto.org/](https://www.reactivemanifesto.org/)）。响应式宣言包括四个原则，我们现在将讨论这些原则。'
- en: Responsive
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '- 响应性'
- en: Responsiveness is the characteristic of serving a request in a timely manner.
    It is measured by the latency. The producer should provide the response in time
    and the consumer should receive the response in time. A failure in the chain of
    operations performed for a request should not cause a delay in response or failure.
    Therefore, it is very important for availability of services.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '- 响应性是及时服务请求的特征。它由延迟来衡量。生产者应及时提供响应，消费者应及时接收响应。对于请求执行的操作链中的故障，不应导致响应延迟或失败。因此，这对于服务的可用性非常重要。'
- en: Resilient
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '- 弹性'
- en: A resilient system is a robust system. The resilient principle is in line with
    the responsive principle. A microservice, despite failures, should provide the
    response, and if one instance of the microservice gets down, the request should
    be served by another node of the same microservice. A resilient microservice system
    is capable of handling all kinds of failures. All services should be monitored
    for detecting failures and all failures should be handled. We have used the service
    discovery eureka for monitoring and Hystrix for circuit breaker pattern implementation
    in the last chapter.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '- 一个有弹性的系统也是一个健壮的系统。弹性原则与响应性原则相一致。微服务在遇到故障时，仍应提供响应，如果微服务的某个实例宕机，请求应由同一微服务的另一个节点处理。一个有弹性的微服务系统能够处理各种故障。所有服务都应受到监控，以检测故障，并且所有故障都应得到处理。我们在上一章使用了服务发现Eureka进行监控和Hystrix实现断路器模式。'
- en: Elastic
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '- 弹性'
- en: A reactive system is elastic if it reacts to the load by utilizing the hardware
    and other resources optimally. It can bring up new instances of a microservice
    or microservices if the demand increases and vice versa. On special sales days,
    such as Black Friday, Christmas, Diwali, and so on, a reactive shopping application
    would instantiate a greater number of microservice nodes in order to share the
    load of increased requests. On normal days, the shopping application may not require
    a bigger number of resources than on average, hence it can reduce the number of
    nodes. Therefore, for effectively using the hardware, a reactive system should
    be elastic in nature.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '- 一个反应式的系统如果通过利用硬件和其他资源来对负载做出反应，那么它是弹性的。如果需求增加，它可以实例化微服务或微服务的新实例，反之亦然。在特别的销售日，如黑色星期五、圣诞节、排灯节等，反应式的购物应用会实例化更多的微服务节点，以分担增加请求的负载。在正常日子，购物应用可能不需要比平均更多的资源，因此它可以减少节点的数量。因此，为了有效地使用硬件，反应式系统应该是弹性的。'
- en: Message driven
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '- 消息驱动'
- en: A reactive system would sit idle if it has nothing to do; it would not use the
    resources unnecessarily if it was not supposed to do anything. An event or a message
    may make a reactive microservice active and then start working (reacting) on the
    received event/message (request). Ideally, communication should be asynchronous
    and non-blocking by nature. A reactive system uses messages for communication—asynchronous
    message passing. In this chapter, we'll use the Apache Kafka for messaging.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '- 如果反应式系统没有事情可做，它就会闲置；如果它本无任务，它就不会无用地使用资源。一个事件或消息可以使反应式微服务变得活跃，并开始处理（反应）接收到的该事件/消息（请求）。理想情况下，通信应该是异步和非阻塞的。反应式系统通过消息进行通信——异步消息传递。在本章中，我们将使用Apache
    Kafka进行消息传递。'
- en: Ideally, a reactive programming language is the best way to implement the reactive
    microservices. A reactive programming language provides asynchronous and non-blocking
    calls. Java could also be used for developing the reactive microservices with
    the use of Java streaming feature. Kafka would be used for messaging with Kafka's
    Java libraries and plugins. We have already implemented service discovery and
    registry service (Eureka Server-monitoring), the proxy server (Zuul) with Eureka
    for elasticity, and Hystrix with Eureka for Circuit Breaker (resilient and responsive).
    In the next section, we will implement the message-driven microservices.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，反应式编程语言是实现反应式微服务的最佳方式。反应式编程语言提供异步和非阻塞调用。Java也可以利用Java流功能来开发反应式微服务。Kafka将使用Kafka的Java库和插件进行消息传递。我们已经实现了服务发现和注册服务（Eureka
    Server-监控），利用Eureka实现弹性代理服务器（Zuul），以及利用Eureka和Hystrix实现断路器（弹性响应）。在下一节中，我们将实现基于消息的微服务。
- en: Implementing reactive microservices
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现反应式微服务
- en: Reactive microservice performs operations in response to events. We'll make
    changes in our code to produce and consume events for our sample implementation.
    Although we'll create a single event, a microservice can have multiple producers
    or consumer events. Also, a microservice can have both producer and consumer events.
    We'll make use of the existing functionality in the Booking microservice that
    creates the new booking (`POST /v1/booking`). This will be our event source and
    would make use of Apache Kafka for sending this event. Other microservices can
    consume this event by listening to the event. On successful booking call, the
    Booking microservice will produce the Kafka topic (event) `amp.bookingOrdered`.
    We'll create a new microservice Billing (in the same way in which we created the
    other microservices like Booking) for consuming this event (`amp.bookingOrdered`).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 反应式微服务响应事件执行操作。我们将修改我们的代码以产生和消费我们示例实现的事件。虽然我们将创建一个单一事件，但微服务可以有多个生产者或消费者事件。此外，微服务可以同时具有生产者和消费者事件。我们将利用Booking微服务中现有的功能来创建新预订（`POST
    /v1/booking`）。这将作为我们的事件源，并使用Apache Kafka发送此事件。其他微服务可以通过监听此事件来消费该事件。在成功预订调用后，Booking微服务将产生Kafka主题（事件）`amp.bookingOrdered`。我们将创建一个与创建其他微服务（如Booking）相同方式的新微服务Billing，用于消费此事件（`amp.bookingOrdered`）。
- en: Producing an event
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 产生事件
- en: An object would be sent to Kafka once an event is produced. Similarly, Kafka
    would send this produced object to all listeners (microservices). In short, the
    produced object travels over the network. Therefore, we need serialization support
    for these objects. We'll make use of Apache Avro for data serialization. It defines
    the data structure (schema) in the JSON format and also provides a plugin for
    both Maven and Gradle to generate Java classes using JSON schema. Avro works well
    with Kafka because both Avro and Kafka are Apache products and align well with
    each other for integration.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦产生事件，对象就会被发送到Kafka。同样，Kafka会将这个产生的对象发送给所有监听器（微服务）。简而言之，产生的对象通过网络传输。因此，我们需要为这些对象提供序列化支持。我们将使用Apache
    Avro进行数据序列化。它定义了以JSON格式表示的数据结构（架构），并为Maven和Gradle提供了一个插件，使用JSON架构生成Java类。Avro与Kafka配合很好，因为Avro和Kafka都是Apache产品，彼此之间集成非常紧密。
- en: Let's start with defining the schema that represents the object sent over the
    network when a new booking is created. As shared earlier for producing the event,
    we'll make use of the existing Booking microservice. We'll create the Avro schema
    file `bookingOrder.avro` in `src/main/resources/avro` directory in Booking microservice.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先定义一个代表创建新预订时通过网络发送的对象的架构。正如之前提到的用于产生事件的Booking微服务，我们将在Booking微服务的`src/main/resources/avro`目录中创建Avro架构文件`bookingOrder.avro`。
- en: 'The `bookingOrder.avro` file will look something like this:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`bookingOrder.avro`文件看起来像这样：'
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here, `namespace` represents the package `type` which is `record` represents
    the class, `name` represents the name of the class, and `fields` represent the
    properties of the class. When we generate the Java class using this schema, it
    would create the new Java class `BookingOrder.java` in the `com.packtpub.mmj.booking.domain.valueobject.avro
    package`, with all properties defined in `fields`.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`namespace`代表包`type`，`record`代表类，`name`代表类名，而`fields`代表类的属性。当我们使用此架构生成Java类时，它将在`com.packtpub.mmj.booking.domain.valueobject.avro`包中创建新的Java类`BookingOrder.java`，`fields`中定义的所有属性都将包含在这个类中。
- en: In `fields` too, we have `name` and `type` that represent the name and type
    of the property. For all fields, we have used the input `type` as `string`. You
    could also use other primitive types such as `boolean`, `int`, and `double`. Also,
    you can use complex types such as `record` (used in the preceding code snippet),
    `enum`, `array`, and `map`. The `default` type represents the default value of
    the property.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在`fields`中，也有`name`和`type`，它们表示属性的名称和类型。对于所有字段，我们都使用了输入`type`作为`string`。您还可以使用其他基本类型，如`boolean`、`int`和`double`。此外，您可以使用复杂类型，如`record`（在上面的代码片段中使用）、`enum`、`array`和`map`。`default`类型表示属性的默认值。
- en: 'The preceding schema would be used to generate the Java code. We''ll make use
    of the `avro-maven-plugin` to generate the Java source files from the preceding
    Avro schema. We''ll add this plugin in the plugins section of the child `pom`
    files (service''s `pom.xml`):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的模式将用于生成Java代码。我们将使用`avro-maven-plugin`从前面的Avro模式生成Java源文件。我们将在此插件的子`pom`文件（服务的`pom.xml`）的插件部分添加此插件：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can see that in the `configuration` section, `sourceDirectory` and `outputDirectory`
    are configured. Therefore, when we run `mvn package`, it would create the `BookingOrder.java`
    file in the `com.packtpub.mmj.booking.domain.valueobject.avro` package located
    inside the configured `outputDirectory`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，在`configuration`部分，已经配置了`sourceDirectory`和`outputDirectory`。因此，当我们运行`mvn
    package`时，它将在配置的`outputDirectory`内部的`com.packtpub.mmj.booking.domain.valueobject.avro`包中创建`BookingOrder.java`文件。
- en: Now that our Avro schema and the generated Java source is available to us, we'll
    add Maven dependencies that are required for producing the event.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在既然我们的Avro模式和生成的Java源代码已经可用，我们将添加生成事件所需的Maven依赖项。
- en: 'Adding dependency in the Booking microservice `pom.xml` file:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在Booking微服务`pom.xml`文件中添加依赖项：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here, we have added the three main dependencies: `avro`, `spring-cloud-stream`,
    and `kafka-clients`. Also, we have added stream integration with Kafka (`spring-cloud-starter-stream-kafka`)
    and stream support schema (`spring-cloud-stream-schema`).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们添加了三个主要依赖项：`avro`、`spring-cloud-stream`和`kafka-clients`。此外，我们还添加了与Kafka的流集成（`spring-cloud-starter-stream-kafka`）和流支持模式（`spring-cloud-stream-schema`）。
- en: Now, since our dependencies are in place, we can start writing producer implementation.
    Booking microservice would send the `amp.bookingOrdered` event to the Kafka stream.
    We'll declare the message channel for this purpose. It can be done either using
    `Source.OUTPUT` with the `@InboundChannelAdapter` annotation or by declaring the
    Java interface. We'll use the interface approach because it is easier to understand
    and correlate.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，既然我们的依赖项已经就位，我们可以开始编写生产者实现。Booking微服务将发送`amp.bookingOrdered`事件到Kafka流。我们将声明为此目的的消息通道。可以通过使用`Source.OUTPUT`与`@InboundChannelAdapter`注解，或者通过声明Java接口来完成。我们将使用接口方法，因为这更容易理解且有关联。
- en: We'll create the `BookingMessageChannels.java` message channel in the `com.packtpub.mmj.booking.domain.service.message`
    package. Here, we can add all the message channels that are required. Since we
    are using the single event for sample implementation, we have to just declare
    the `bookingOrderOutput`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在`com.packtpub.mmj.booking.domain.service.message`包中创建`BookingMessageChannels.java`消息通道。在这里，我们可以添加所有必需的消息通道。由于我们使用单事件样本实现，我们只需声明`bookingOrderOutput`。
- en: 'The `BookingMessageChannels.java` file will look something like this:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`BookingMessageChannels.java`文件将看起来像这样：'
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here, we have just defined the name of the message channel, `bookingOrderOutput`,
    using the `@Output annotation`. We also need to configure this message channel
    in `application.yaml`. We''ll use this name to define the Kafka topic in the `application.yaml`
    file:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们只是使用`@Output`注解定义了消息通道的名称，`bookingOrderOutput`。我们还需要在`application.yaml`中配置此消息通道。我们将在`application.yaml`文件中使用此名称定义Kafka主题：
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, the Kafka topic name `amp.bookingOrdered` is given that is bound to the
    `bookingOrderOutput` message channel. (Kafka topic name could be any string. We
    prefix `amp` to denote asynchronous message passing; you can use Kafka topic name
    with or without prefix.)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，给出了Kafka主题名称`amp.bookingOrdered`，它与`bookingOrderOutput`消息通道绑定。（Kafka主题名称可以是任何字符串。我们添加`amp`前缀以表示异步消息传递；您可以使用带或不带前缀的Kafka主题名称。）
- en: We also need a message converter that would send the `BookingOrder` object to
    Kafka. For this purpose, we'll create an `@Bean` annotation that would return
    the Spring `MessageConverter` in the Booking service main class.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要一个消息转换器，用于将`BookingOrder`对象发送到Kafka。为此，我们将在Booking服务的主类中创建一个`@Bean`注解，以返回Spring的`MessageConverter`。
- en: 'The `@Bean` annotation in `BookingApp.class` file will look something like
    this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`BookingApp.class`文件中的`@Bean`注解看起来像这样：'
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: You may add more beans based on required schemas for respective schemas. We
    have not yet configured the Kafka server in `application.yaml`, which is set to
    `localhost`. Let's do it.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以根据所需的模式添加更多的豆子。我们还没有在`application.yaml`中配置Kafka服务器，默认为`localhost`。让我们来做这件事。
- en: 'Configuring the Kafka server in the `application.yaml` file:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在`application.yaml`文件中配置Kafka服务器：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, we have configured `localhost` for both `zkNodes` and `brokers`; you can
    change it to the host where Kafka is hosted.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们为`zkNodes`和`brokers`都配置了`localhost`；您可以将其更改为托管Kafka的主机。
- en: We are ready for sending the `amp.bookingOrdered` Kafka topic to the Kafka server.
    For simplicity, we'll directly add a `produceBookingOrderEvent` method that takes
    the `Booking` class as a parameter in the `BookingServiceImpl.java` class (you
    need to add the same method signature in `BookingService.java`). Let's see the
    code first.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好将`amp.bookingOrdered` Kafka主题发送到Kafka服务器。为了简单起见，我们将在`BookingServiceImpl.java`类中直接添加一个`produceBookingOrderEvent`方法，该方法接受`Booking`类作为参数（您需要在`BookingService.java`中添加相同的签名方法）。让我们先看看代码。
- en: 'The `BookingServiceImpl.java` file is as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`BookingServiceImpl.java`文件如下：'
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here, we have declared the `bookingMessageChannel` object that is autowired
    using the `setter` method. The Spring cloud stream annotation `@EnableBinding`
    binds the `bookingOrderOutput` message channel declared in the `BookingMessageChannels`
    class.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们声明了`bookingMessageChannel`对象，该对象通过`setter`方法进行自动注入。Spring Cloud Stream注解`@EnableBinding`将`bookingOrderOutput`消息通道绑定在`BookingMessageChannels`类中声明的`bookingOrderOutput`消息通道。
- en: The `produceBookingOrderEvent` method is added, which takes the `booking` object.
    Inside the `produceBookingOrderEvent` method, the `BookingOrder` object properties
    are set using the `booking` object. Then the message is built using the `bookingOrder`
    object. At the end, the message is sent to Kafka using `bookingMessageChannels`.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 添加了`produceBookingOrderEvent`方法，该方法接受`booking`对象。在`produceBookingOrderEvent`方法内部，使用`booking`对象设置`BookingOrder`对象属性。然后使用`bookingOrder`对象构建消息。最后，通过`bookingMessageChannels`将消息发送到Kafka。
- en: The `produceBookingOrderEvent` method is called after the booking is successfully
    persisted in DB.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`produceBookingOrderEvent`方法在预约成功保存在数据库后调用。'
- en: 'To test this functionality, you can run the Booking microservice with the following
    command:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试这个功能，您可以使用以下命令运行Booking微服务：
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Ensure that the Kafka and Zookeeper applications are running properly on hosts
    and ports defined in the `application.yaml` file for performing successful testing.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 确保Kafka和Zookeeper应用程序在`application.yaml`文件中定义的主机和端口上正确运行，以进行成功的测试。
- en: 'Then, fire a post request (`http://<host>:<port>/v1/booking`) for a booking
    through any REST client with the following payload:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过任何REST客户端向`http://<host>:<port>/v1/booking`发送一个预约的POST请求，并带有以下载荷：
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'It would produce the `amp.bookingOrdered` Kafka topic (event) as shown in following
    logs published on the Booking microservice console:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 它将产生`amp.bookingOrdered` Kafka主题（事件），如下所示，在Booking微服务控制台上发布日志：
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Similarly, the Kafka console would display the following message that confirms
    that the message is received successfully by Kafka:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，Kafka控制台将显示以下消息，确认消息已成功由Kafka接收：
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We can now move to code the consumer of the previously generated event.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以移动到编写之前生成的事件的消费者代码。
- en: Consuming the event
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消费事件
- en: First, we'll add the new module `billing-service` in the parent `pom.xml` file
    and create the Billing microservice the way other microservices are created in
    [Chapter 5](b1f93b4e-3475-4d8a-8c9f-697b0fd4410c.xhtml), *Deployment and Testing*.
    Most of the reactive code we have written for the Booking microservice will be
    reused for a Billing microservice, such as Avro schema and `pom.xml` entries.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将在父级`pom.xml`文件中添加新模块`billing-service`，并以与其他微服务相同的方式创建Billing微服务[第5章](b1f93b4e-3475-4d8a-8c9f-697b0fd4410c.xhtml)，*部署和测试*。我们为Booking微服务编写的几乎所有反应式代码都将被Billing微服务重用，例如Avro模式和`pom.xml`条目。
- en: We'll add the Avro schema in Billing microservice in same way we have added
    it in Booking microservice. Since schema namespace (package name) would be the
    same `booking` package in Billing microservice, we need to add value `com.packtpub.mmj.booking`
    in the `scanBasePackages` property of `@SpringBootApplication` annotation in `BillingApp.java`.
    It would allow the spring context to scan booking package also.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在账单微服务中以与预订微服务相同的方式添加Avro模式。由于账单微服务的模式命名空间（包名）将是相同的`booking`包，我们需要在`@SpringBootApplication`注解的`scanBasePackages`属性中添加值`com.packtpub.mmj.booking`。这将允许spring上下文也扫描预订包。
- en: We'll add following dependencies in the Billing microservice `pom.xml`, which
    is the same as we have added in Booking microservice.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在账单微服务的`pom.xml`中添加以下依赖项，这与我们在预订微服务中添加的依赖项相同。
- en: 'The `pom.xml` file for Billing microservice is as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 账单微服务的`pom.xml`文件如下：
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: You can refer to the booking service dependency paragraph for the reason behind
    the addition of these dependencies.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考预订服务依赖段落，了解添加这些依赖的原因。
- en: 'Next, we''ll add the message channel in the Billing microservice, as shown
    here:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将向账单微服务中添加消息通道，如下所示：
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Here, we are adding the input message channel opposite to the message channel
    in the booking service where we have added the output message channel. Note that
    `bookingOrderInput` is an input message channel marked with the `@input` annotation.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们正在为预订服务中的输出消息通道添加一个输入消息通道的对端。请注意`bookingOrderInput`是一个带有`@input`注解的输入消息通道。
- en: 'Next, we want to configure the `bookingOrderInput` channel to the Kafka topic
    `amp.BookingOrdered`. We''ll modify the `application.yaml` for this purpose:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们想要将`bookingOrderInput`通道配置为Kafka主题`amp.BookingOrdered`。为此，我们将修改`application.yaml`：
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Here, the Kafka topic is added to the `bookingOrderInput` channel using the
    destination property. We''ll also configure Kafka in the Billing microservice
    (`application.yaml`) the way we have configured it in the Booking microservice:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，通过目标属性将Kafka主题添加到`bookingOrderInput`通道。我们还将按照在预订微服务中配置的方式在账单微服务（`application.yaml`）中配置Kafka：
- en: '[PRE15]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now, we'll add the event listener that would listen to the stream bound to the
    `bookingOrderInput` message channel using the `@StreamListener` annotation available
    in the Spring Cloud Steam library.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将添加一个事件监听器，该监听器将监听与`bookingOrderInput`消息通道绑定的流，使用Spring Cloud Steam库中可用的`@StreamListener`注解。
- en: 'The `EventListener.java` file is as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`EventListener.java`文件如下：'
- en: '[PRE16]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Here, you can also add other event listeners. For example, we'll simply log
    the received object. You may add an additional functionality based on the requirement;
    you can even produce a new event again for further processing if required. For
    example, you can produce the event to a restaurant for which a new booking is
    requested, and so on, through a service that manages restaurant communication.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，您还可以添加其他事件监听器。例如，我们只需记录接收到的对象。根据需求，您可以添加一个额外的功能；如果需要，您甚至可以再次产生一个新事件以进行进一步处理。例如，您可以将事件产生到一家餐厅，该餐厅有一个新的预订请求，等等，通过一个管理餐厅通信的服务。
- en: 'Finally, we can enable the binding of the `bookingOrderInput` message channel
    to stream using the `@EnableBinding` annotation of the Spring Cloud Stream library
    and create the bean of the `EventListener` class created in `BillingApp.java`
    (the main class of the `billing-service` module) as shown here:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用Spring Cloud Stream库的`@EnableBinding`注解启用`bookingOrderInput`消息通道与流的绑定，并在`BillingApp.java`（`billing-service`模块的主类）中创建`EventListener`类的bean，如下所示：
- en: 'The `BillingApp.java` will look something like this:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`BillingApp.java`可能看起来像这样：'
- en: '[PRE17]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, you can start the Billing microservice and raise a new `POST/v1/booking`
    REST call. You can find the received object in the Billing microservice log, as
    shown here:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以启动账单微服务并发起一个新的`POST/v1/booking` REST调用。您可以在账单微服务的日志中找到接收到的对象，如下所示：
- en: '[PRE18]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: References
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'The following links will give you more information:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 以下链接将为您提供更多信息：
- en: '**Apache Kafka**: [https://kafka.apache.org/](https://kafka.apache.org/)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Kafka**: [https://kafka.apache.org/](https://kafka.apache.org/)'
- en: '**Apache Avro**: [https://avro.apache.org/](https://avro.apache.org/)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Avro**: [https://avro.apache.org/](https://avro.apache.org/)'
- en: '**Avro Specs**: [https://avro.apache.org/docs/current/spec.html](https://avro.apache.org/docs/current/spec.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Avro规范**: [https://avro.apache.org/docs/current/spec.html](https://avro.apache.org/docs/current/spec.html)'
- en: '**Spring Cloud Stream**: [https://cloud.spring.io/spring-cloud-stream/](https://cloud.spring.io/spring-cloud-stream/)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spring Cloud Stream**: [https://cloud.spring.io/spring-cloud-stream/](https://cloud.spring.io/spring-cloud-stream/)'
- en: Summary
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned about reactive microservices or event-based microservices.
    These services work on messages/events rather than REST calls over HTTP. They
    provide asynchronous communication among services, which provide non-blocking
    communication and allow better usage of resources and failure handling.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了关于响应式微服务或基于事件的微服务。这些服务基于消息/事件工作，而不是基于HTTP的REST调用。它们提供了服务之间的异步通信，这种通信是非阻塞的，并且允许更好地利用资源和处理失败。
- en: We have made use of Apache Avro and Apache Kafka with Spring Cloud Stream libraries
    for implementing the reactive microservices. We have added the code in the existing
    `booking-service` module for producing the `amp.bookingOrdered` messages under
    the Kafka topic and added new module `billing-service` for consuming the same
    event.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了Apache Avro和Apache Kafka与Spring Cloud Stream库来实现响应式微服务。我们在现有的`booking-service`模块中添加了代码，用于在Kafka主题下生产`amp.bookingOrdered`消息，并添加了新的模块`billing-service`来消费同一个事件。
- en: You may want to add a new event for producers and consumers. You can add multiple
    consumers for an event or create a chain of events as exercise.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想要为生产者和消费者添加一个新事件。你可以为一个事件添加多个消费者，或者创建一个事件链作为练习。
- en: In the next chapter, you will learn to secure the microservices with respect
    to authentication and authorization. We will also explore the other aspects of
    microservice securities.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习如何根据认证和授权来保护微服务。我们还将探讨微服务安全的其他方面。
