- en: Build a Breast Cancer Prognosis Pipeline with the Power of Spark and Scala
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用 Spark 和 Scala 的力量构建乳腺癌预后流程
- en: Breast cancer is the leading cause of death among women each year, leaving others
    in various stages of the disease. Lately, **machine learning** (**ML**) has shown
    great promise for physicians and researchers working towards better outcomes and
    lowering the cost of treatment. With that in mind, the **Wisconsin Breast Cancer** **Da****ta
    Set** represents a combination of suitable features that are useful enough to
    generate ML models, models that are able to predict a future diagnostic outcome
    by learning from predetermined or historical breast mass tissue sample data.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 乳腺癌是每年女性死亡的主要原因，使其他人处于各种疾病阶段。最近，**机器学习**（**ML**）在医生和研究人员追求更好的结果和降低治疗成本方面显示出巨大的潜力。考虑到这一点，**威斯康星乳腺癌**
    **数据集**代表了一系列适合的特征，这些特征足以生成机器学习模型，这些模型能够通过学习预先确定的或历史乳腺癌组织样本数据来预测未来的诊断结果。
- en: 'Here is  the dataset we refer to:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们所参考的数据集：
- en: 'UCI Machine Learning Repository: Breast Cancer Wisconsin (Original) Data Set'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UCI 机器学习仓库：乳腺癌威斯康星（原始）数据集
- en: 'UCI Machine Learning Repository: Breast Cancer Wisconsin (Diagnostic) Data
    Set'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UCI 机器学习仓库：乳腺癌威斯康星（诊断）数据集
- en: Accessed July 13, 2018
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问日期：2018年7月13日
- en: Website URL: [https://archive.ics.uci.edu/ml/datasets/Breast Cancer Wisconsin
    (Original)](https://archive.ics.uci.edu/ml/datasets/Breast%20Cancer%20Wisconsin%20(Original))
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网站URL：[https://archive.ics.uci.edu/ml/datasets/Breast Cancer Wisconsin (Original)](https://archive.ics.uci.edu/ml/datasets/Breast%20Cancer%20Wisconsin%20(Original))
- en: In this chapter, we will be focusing on implementing and training a logistic
    regression multiclass classifier for making a prediction on whether a breast cancer
    mass is malignant or not. The Wisconsin Breast Cancer Data Set is a classification
    task.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将专注于实现和训练一个逻辑回归多类分类器，以预测乳腺癌肿块是否为恶性。威斯康星乳腺癌数据集是一个分类任务。
- en: The overarching learning objective of this chapter is to be able to implement
    a Scala solution that will predict cancer outcomes. Starting from the **UCI Machine
    Learning Repository** breast cancer dataset, we will lean on the Spark ML library's
    ML APIs and its supporting libraries to build a breast cancer prediction pipeline.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主要学习目标是能够实现一个 Scala 解决方案，该方案可以预测癌症结果。从 **UCI 机器学习仓库** 乳腺癌数据集开始，我们将依赖 Spark
    ML 库的 ML API 和其支持库来构建乳腺癌预测流程。
- en: 'The following list is a section-wise breakdown of individual learning outcomes
    for this chapter:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表是本章各个部分的学习成果的逐节分解：
- en: Breast cancer classification problem
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 乳腺癌分类问题
- en: Getting started
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始
- en: Random Forest breast cancer pipeline
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林乳腺癌流程
- en: LR breast cancer pipeline
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LR 乳腺癌流程
- en: Breast cancer classification problem
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 乳腺癌分类问题
- en: At the moment supervised learning is the most common class of ML problems in
    the business domain. In [Chapter 1](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml),
    *Predict the Class of a Flower from the Iris Dataset*, we approached the Iris
    classification task by employing a powerful supervised learning classification
    algorithm called **Random Forests**, which at its core depends on a categorical
    response variable. In this chapter, besides the Random Forest approach, we also
    turn to yet another intriguing yet popular classification technique, called **logistic
    regression**. Both approaches present a unique solution to the prediction problem
    of breast cancer prognosis, while an iterative learning process is a common denominator.
    The logistic regression technique occupies center stage in this chapter, taking
    precedence over Random Forests. However, both learn from a test dataset containing
    samples with predetermined measurements and compute a prediction on new, unseen
    data.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，监督学习是商业领域中最常见的机器学习问题类别。在 [第1章](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml)
    *从鸢尾花数据集预测花的类别* 中，我们通过采用一个强大的监督学习分类算法 **随机森林** 来处理鸢尾花分类任务，其核心依赖于一个分类响应变量。在本章中，除了随机森林方法之外，我们还转向另一种有趣且流行的分类技术，称为
    **逻辑回归**。这两种方法都为乳腺癌预后预测问题提供了一个独特的解决方案，而迭代学习过程是它们的共同点。本章中，逻辑回归技术占据中心舞台，优先于随机森林。然而，两者都是从包含预定测量值的样本测试数据集中学习，并在新的、未见过的数据上计算预测。
- en: Before we proceed further, a quick note on ML terminology. The literature in
    this rapidly expanding field is sometimes seen to be replete with terms from other
    overlapping fields, leading to differing perceptions, even though two apparently
    different terms refer to the same thing or are mostly equivalent in regard to
    semantics. Sometimes, two terms that are often used interchangeably in the literature
    might actually be quite different; for example, the terms **multivariate** and
    **multivariable** are two such terms. We will avoid using multivariable in this
    chapter. That said, let's take up the Wisconsin Breast Cancer Data Set and understand
    the terms around it, prior to problem formulation and implementation.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进一步进行之前，关于机器学习术语的简要说明。在这个快速发展的领域中，文献有时会看到充斥着来自其他重叠领域的术语，导致不同的看法，尽管两个显然不同的术语指的是同一件事或者从语义上大多是等效的。有时，文献中经常互换使用的两个术语实际上可能相当不同；例如，术语**多元**和**多变量**就是这样的术语。在本章中，我们将避免使用多变量。话虽如此，让我们来探讨威斯康星州乳腺癌数据集，并在问题制定和实现之前理解其周围的术语。
- en: First, we must download the dataset from the UCI Machine Learning Repository.
    It is available in the `ModernScalaProjects_Code` folder.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须从UCI机器学习仓库下载数据集。它位于`ModernScalaProjects_Code`文件夹中。
- en: Breast cancer dataset at a glance
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 威斯康星州乳腺癌数据集概览
- en: The Wisconsin Breast Cancer Data Set contains 699 rows of data. Each row corresponds
    to a single sample (the term **example** is sometimes used interchangeably with
    a **sample** in the ML literature) containing nine feature measurements of digitized
    images of a fine needle aspirate of a breast mass.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 威斯康星州乳腺癌数据集包含699行数据。每一行对应一个单独的样本（在机器学习文献中，术语**示例**有时与**样本**可以互换使用），包含九个特征测量，这些特征测量是乳腺肿块细针吸取的数字化图像。
- en: 'Before we dive into the details, here is a table listing the key characteristics
    of the 699 rows (instances) of the Wisconsin Breast Cancer Data Set:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入细节之前，这里有一个表格列出了威斯康星州乳腺癌数据集699行（实例）的关键特征：
- en: '![](img/ddc04472-19c3-40fa-a0f1-1f2111bf31e7.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ddc04472-19c3-40fa-a0f1-1f2111bf31e7.jpg)'
- en: Breast cancer dataset characteristics
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 乳腺癌数据集特征
- en: The preceding table lists nine cell nuclei attributes of the breast cancer dataset,
    where each attribute bears a single value. All of the nine cell nuclei attribute
    values are measurements that have been captured from digitized images of a certain
    sample. 699 of these breast cancer tissue samples, then, should constitute our
    ML experimental unit of 699 input vectors.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的表格列出了乳腺癌数据集的九个细胞核属性，其中每个属性只有一个值。这九个细胞核属性值都是从某个样本的数字化图像中捕获的测量值。因此，699个这样的乳腺癌组织样本应该构成我们的699个输入向量的机器学习实验单元。
- en: 'To reflect on what input vectors are, we invite readers to draw upon their
    previous experience with the Iris dataset supervised learning problem; this was
    a classification task characterized by two fundamental aspects:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了反思输入向量是什么，我们邀请读者回顾他们之前在Iris数据集监督学习问题上的经验；这是一个有两个基本方面的分类任务：
- en: An input vector
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个输入向量
- en: 'A response variable value `Y` with two possible outcomes for its input vector:'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个响应变量值`Y`，对于其输入向量有两个可能的结果：
- en: '`Y` is represented by the class column and is sometimes known as a supervisory
    signal.'
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Y`由类别列表示，有时被称为监督信号。'
- en: Two outcomes (for example, either heads or tails) implies more than one class
    label. An outcome represents a *classification*, as in a classification task.
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两种结果（例如，正面或反面）意味着多于一个的类别标签。一个结果代表一个**分类**，就像在分类任务中一样。
- en: 'The preceding two aspects are also shared by our breast cancer supervised learning
    problem—the task at hand. The following points describe the task at hand by offering
    more insight:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的两个方面也与我们面临的乳腺癌监督学习问题——当前任务——是共有的。以下各点通过提供更多见解来描述当前任务：
- en: It is a 699-input vector multiclass classification task. This task is characterized
    by historical (predetermined) categorical data and more than one dependent or
    outcome variable (or label).
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是一个699个输入向量的多类别分类任务。这个任务的特点是历史（预定）的类别数据和多个依赖或结果变量（或标签）。
- en: 'This task is performed on a dataset that has 699 observations/measurements
    (instances), where each observation row may be described further as follows:'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个任务是在一个包含699个观察/测量（实例）的数据集上执行的，其中每一行观察可能进一步描述如下：
- en: Each row is composed of 10 attributes; each of these attributes is a predictor
    variable (inputs, `X`), which are also known as input variables (`X`)
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每一行由10个属性组成；这些属性中的每一个都是预测变量（输入，`X`），它们也被称为输入变量（`X`）。
- en: Each of the 699 observations is historical or predetermined (with the exception
    of certain incomplete observations/rows), and represent (breast mass cell nuclei)
    characteristics of cell nuclei from a breast cancer tissue sample from a needle
    aspirate
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 699个观测值都是历史数据或预先确定的（除了某些不完整的观测值/行），它们代表了从针吸活检的乳腺癌组织样本中细胞核的特性（乳腺质量细胞核）。
- en: There are 10 characteristics of the aforementioned breast mass cell nuclei;
    these are just the breast's mass cell nuclei measurements
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上述乳腺质量细胞核有10个特性；这些只是乳腺质量细胞核的测量值。
- en: The classification task is also multidimensional, owing to the fact that 10
    (input) attribute values exist as feature parameters that are passed into `Model`
    to carry out a diagnosis classification on the so-called target class.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于存在10个（输入）属性值作为特征参数传递到`Model`以执行所谓的目标类诊断分类，因此分类任务也是多维的。
- en: Each instance (row) in the breast cancer dataset represents measurements (from
    digitized images) made on breast mass tissue samples.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 乳腺癌数据集中的每个实例（行）代表了在乳腺质量组织样本上进行的测量（来自数字化图像）。
- en: 'The goal of the classification task is as follows:'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类任务的目标如下：
- en: 'To identify (or classify) the diagnosis on a new breast cancer sample as belonging
    to either of two diagnoses: malignant (cancerous) or benign (non-cancerous).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别（或分类）新的乳腺癌样本的诊断，判断其属于两种诊断中的哪一种：恶性（癌性）或良性（非癌性）。
- en: To derive a predicted value for the response from the predictors by a process
    of learning (or fitting) a discrete number of targets or category labels (`Y`). The
    predicted value is a categorical response (outcome) variable (output `Y`), also
    known as a response or outcome variable (`Y`).
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过学习（或拟合）离散数量的目标或类别标签（`Y`）的过程，从预测变量中推导出响应的预测值。预测值是一个分类响应（结果）变量（输出`Y`），也称为响应或结果变量（`Y`）。
- en: To learn a predictive function also known as a model; this computes a predictor
    function that predetermines the feature measurements on 10 attributes that will
    be able to classify or identify, the type of diagnosis (benign or malignant).
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习一个预测函数，也称为模型；这个模型计算一个预测函数，预先确定10个属性上的特征测量值，这将能够对诊断类型（良性或恶性）进行分类或识别。
- en: 'In [Chapter 1](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml), *Predict the Class
    of a Flower from the Iris Dataset*, we used a supervised learning classification
    algorithm called Random Forests. In this chapter, we will employ what is known
    as the logistic regression classification technique (a Spark ML algorithm). This
    will be the heart of our predictive analysis classification pipeline. To sum this
    up, a high-level view of the breast cancer classification task can be compartmentalized
    as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml)《从鸢尾花数据集预测花的类别》中，我们使用了一种名为随机森林的有监督学习分类算法。在本章中，我们将采用被称为逻辑回归分类技术（Spark
    ML算法）。这将是我们的预测分析分类流程的核心。总结一下，乳腺癌分类任务的高层次视图可以概括如下：
- en: '**The classifier algorithm**: This involves the creation of a discriminant
    function or model function that discovers patterns, relationships, or interactions
    between several independent variables and one dependent variable (indexed by the
    model to a binary dummy variable) that is either a nominal or ordinal variable'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类算法**：这涉及到创建一个判别函数或模型函数，该函数发现几个独立变量和一个依赖变量（通过模型索引到一个二元虚拟变量）之间的模式、关系或交互，该依赖变量可以是名义变量或有序变量。'
- en: '**Predetermined features**: Measurements or observations that have been labeled
    malignant or otherwise'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预定的特征**：已被标记为恶性或其他情况的测量或观测值。'
- en: '** Predicted labels**: Labeling unseen data before arriving at a prediction
    on new, unseen data after a learning process'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测标签**：在学习过程之前对未见数据打标签，在学习过程之后对新未见数据进行预测。'
- en: The end goal of logistical regression is to produce a model that is as well
    fitted (trained) as possible and one that emits a prediction. A prediction, of
    course, is a variable of interest.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归的最终目标是生成一个尽可能拟合（训练）好的模型，并能够输出预测结果。当然，预测结果是一个感兴趣的变量。
- en: The next section is a prelude to a broader discussion on the application of
    the logistic regression statistical technique.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个部分是对逻辑回归统计技术应用的更广泛讨论的序言。
- en: Logistic regression algorithm
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归算法
- en: The **logistic regression** (**LR**) algorithm, which is employed when building
    a data pipeline in this chapter, is a fresh approach to making a prediction on
    whether a breast cancer mass is malignant or not.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 本章在构建数据管道时使用的**逻辑回归（LR**）算法是一种新颖的方法，用于预测乳腺癌肿块是否为恶性。
- en: 'At the outset, the key to understanding the LR algorithm boils down to this:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解LR算法的关键在于：
- en: '"if (categorical) feature x = …”, then it treats the label as an output that
    is something like this: “label =..”.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “如果（分类）特征x = …”，那么它将标签视为一个输出，类似于“标签 =..”。
- en: Speaking of categorical features, we may want to understand the relationship
    between two or more of them in the breast cancer dataset. In addition, we are
    also interested in building LR ML models as an efficient data inference to derive
    the concurrent effects of multiple categorical variables.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谈到分类特征，我们可能想了解乳腺癌数据集中两个或多个特征之间的关系。此外，我们还对构建LR机器学习模型感兴趣，作为高效的数据推理，以推导出多个分类变量的同时效应。
- en: In the next section, we will present you with a high-level overview of the LR
    technique.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将向您展示LR技术的概述。
- en: Salient characteristics of LR
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LR显著特点
- en: 'The following table lists the salient characteristics of LR:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格列出了LR的显著特点：
- en: '![](img/bf9cb42f-114d-4898-a245-e45c8ae6e1cf.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bf9cb42f-114d-4898-a245-e45c8ae6e1cf.png)'
- en: LR at a glance
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: LR速览
- en: The regression or classification model that we implement for the pipeline in
    this chapter is a specialized type of a generalized linear regression model called
    **binary logistic regression**.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们为管道实现的回归或分类模型是一种特殊的广义线性回归模型，称为**二元逻辑回归**。
- en: 'Before we talk about binary logistic regression, we will take a step back,
    refer back to [Chapter 1](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml), *Predict
    the Class of a Flower from the Iris Dataset*, and remind ourselves of the different
    types of variables. One such variable type is that of a response variable, a variable
    whose changes are explained by a so-called explanatory variable. An explanatory
    variable is plotted on the *x *axis of a scatter plot, whereas the response variable
    plotted on the *y* axis is dependent on the former. The following diagram is an
    example of a scatter plot that, though not directly relevant to this chapter,
    has some significance:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论二元逻辑回归之前，我们将回顾一下[第1章](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml)，*从鸢尾花数据集预测花的类别*，并提醒自己不同类型的变量。其中一种变量类型是响应变量，其变化由所谓的解释变量解释。解释变量在散点图的*x*轴上绘制，而绘制在*y*轴上的响应变量则依赖于前者。以下是一个散点图的示例，尽管它与此章节不直接相关，但具有一定的意义：
- en: '![](img/9ba8a82f-d08d-44a3-9cdd-1e93c471ebd2.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9ba8a82f-d08d-44a3-9cdd-1e93c471ebd2.jpg)'
- en: A scatter plot example
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图示例
- en: 'Going one step further, we get into the topic of linear regression. This type
    of prediction model takes a bunch of explanatory categorical values as hyperparameters
    that play a direct role in predicting expected response variable values. What
    are the odds of our response variable taking on a certain value? Those odds are
    represented in mathematical terms, which is a probability model that translates
    to a predictor function. A function like this does two things:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步深入，我们将探讨线性回归这一主题。这种预测模型将一组解释性分类值作为超参数，这些超参数在预测期望的响应变量值中起着直接作用。我们的响应变量取某个特定值的可能性有多大？这些可能性用数学术语表示，即一个概率模型，它转化为预测函数。这样的函数做两件事：
- en: Accepts more than one explanatory (or input) variable feature measurement
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接受多个解释性（或输入）变量特征测量
- en: Models the probabilities of response variables
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模拟响应变量的概率
- en: 'Before we apply all of this to our breast cancer dataset, we will cite a (fictitious)
    example of a mathematics program admission process from the Case Western Reserve
    University. This process can be described in terms of the following points:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们将所有这些应用到我们的乳腺癌数据集之前，我们将引用来自凯斯西储大学的一个（虚构的）数学程序招生过程的例子。这个过程可以用以下要点来描述：
- en: It is supposed to be a fair, nondiscriminatory process, one that admits students
    coming from various categories or groups to academic programs.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它应该是一个公平、非歧视的过程，允许来自各种类别或群体的学生进入学术项目。
- en: An admission process predictor model would predict the probability of the successful
    (or not) admission of a student, given that they belong to a certain gender, race,
    or economic background.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个录取过程预测模型将预测学生成功（或不成功）录取的概率，前提是他们属于某个性别、种族或经济背景。
- en: An important question to pose is what are the odds of student A being successfully
    admitted into this program? In other words, how do we come up with a `StudentAdmission`
    predictor function (model) that will predict the odds of the `admission status`
    response variable taking a specific value?
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个重要的问题是学生A成功进入这个项目的几率是什么？换句话说，我们如何提出一个`StudentAdmission`预测函数（模型），该模型将预测`admission
    status`响应变量取特定值的几率？
- en: The `StudentAdmission` model receives a group of explanatory variables. This
    group consists of independent variables representing some characteristics of the
    individual. These are multiple feature measurements. Some features can include
    gender, race, income group, and many more.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`StudentAdmission` 模型接收一组解释变量。这个组包括代表个人某些特征的独立变量。这些是多个特征测量。一些特征可以包括性别、种族、收入群体等等。'
- en: 'All that being said, we want to know how binary logistic regression finds its
    niche as an extension of the linear regression model approach. Two examples of
    usage are described as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些话，我们想知道二元逻辑回归如何作为线性回归模型方法的扩展找到其位置。以下描述了两个使用示例：
- en: Consider, for example, that a binary logistic regression model simply predicts
    whether an incident (an event) took place or not. A researcher with earthquake
    data is interested in analyzing whether an earthquake is bound to happen sometime
    in the future. This kind of response variable is **discrete**. In other words,
    it is noncontinuous, static, or a one-time limited occurrence.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，考虑一个二元逻辑回归模型仅仅预测一个事件（一个事件）是否发生。一个拥有地震数据的学者对分析未来某个时间是否会发生地震感兴趣。这种响应变量是**离散的**。换句话说，它是非连续的、静态的或一次性的有限发生。
- en: The university admission process could be modeled as a binary logistic regression
    model, one that involves more than one explanatory variable or course. This model
    will predict the odds (or probability) of the response variable (`admission status`)
    taking a certain value. Taking this a step further, the predicted discrete value
    in the student admission process is a value of either `0` or `1`.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大学录取过程可以建模为一个二元逻辑回归模型，该模型涉及多个解释变量或课程。该模型将预测响应变量（`admission status`）取特定值的几率（或概率）。更进一步，学生录取过程中的预测离散值是`0`或`1`的值。
- en: Next, we will list assumptions that will help us formulate a logistical regression
    task.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将列出有助于我们制定逻辑回归任务的假设。
- en: Binary logistic regression assumptions
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二元逻辑回归假设
- en: 'Here are some assumptions that are made for a binary logistic regression classification
    task:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些为二元逻辑回归分类任务所做的假设：
- en: The dependent variable should be dichotomous, representing mutually exclusive
    states. There is more than one independent predictor variable.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因变量应该是二元的，表示互斥的状态。存在多个自变量预测因子。
- en: Correlations between predictor variables are represented by the elements of
    a correlation matrix. They can be no higher than 0.9.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测变量之间的相关性由相关矩阵的元素表示。它们不能高于0.9。
- en: Outliers must be absent. Outlier presence or absence can be determined by transforming
    predictors into standardized statistical scores.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常值必须不存在。异常值的存在与否可以通过将预测因子转换为标准化的统计分数来确定。
- en: 'The only dataset that is relevant to us in this chapter is the breast cancer
    dataset. This is a classification task whose analysis solution will be a binary
    logistic regression. Before we get to that, we will present this as a much simpler
    dataset to illustrate the following:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，与我们相关的唯一数据集是乳腺癌数据集。这是一个分类任务，其分析解决方案将是二元逻辑回归。在我们到达那里之前，我们将将其作为一个更简单的数据集来展示以下内容：
- en: Independent variables
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自变量
- en: Dependent variables
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因变量
- en: Correlation matrix
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关系数矩阵
- en: In the next section, we will illustrate the bottom line of linear regression
    with a fictitious example from a survey on males and their luck with snagging
    the next date.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将通过一个关于男性和他们约会成功率的调查的虚构例子来说明线性回归的基本原理。
- en: A fictitious dataset and LR
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个虚构数据集和LR
- en: Here, we are going to present you with a fictitious dataset to merely present
    our case on LR so that it can be a candidate for our breast cancer dataset classification
    task.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将向您展示一个虚构的数据集，仅为了展示我们对逻辑回归案例的论述，以便它能够成为我们乳腺癌数据集分类任务的候选者。
- en: The following example lists data that has been created by a dating website about
    male singles. Listed in the table is a dependent variable that represents whether
    the guy was lucky, which means they were able to work up to a second date with
    the same person within a week after the first date.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例列出了约会网站创建的关于单身男性的数据。表中列出的一个因变量代表男士是否幸运，这意味着他们在第一次约会一周内能够与同一个人再次约会。
- en: 'There are two independent variables, and they are as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个自变量，它们如下：
- en: Did the guy attend a dating workshop to firm up his dating skills?
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 男士是否参加了约会工作坊来巩固他们的约会技巧？
- en: The second variable measures the guy's desperation on a desperation scale. The
    higher the score, the more desperate the guy is, with 100 being the most desperate.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个变量衡量的是男士在绝望尺度上的绝望程度。分数越高，男士越绝望，100分代表最绝望。
- en: 'The following dating survey table tabulates data pertaining to the dating logistical
    regression problem:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的约会调查表列出了与约会逻辑回归问题相关的数据：
- en: '![](img/7cf47e02-461d-4b78-9e7a-5711946ce0c3.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7cf47e02-461d-4b78-9e7a-5711946ce0c3.jpg)'
- en: Logistical regression example
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归示例
- en: An inspection of the dataset tells us that a little more than half of all single
    guys have had a second date in less than a week. This is assuming that the dating
    survey company does not possess any other background data on these singles and
    is applying the best techniques in this (fictitious) dating help industry.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 检查数据集告诉我们，超过一半的单身男士在不到一周的时间内有过第二次约会。这是假设约会调查公司没有这些单身人士的其他背景数据，并且在这个（虚构的）约会帮助行业中应用了最佳技术。
- en: 'Now, we want to know whether those in the **Workshop** group are more likely
    to have another date. Looking at the fourth column, **Cool**, greater coolness
    translates to a better chance of a second date:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们想知道**工作坊**组的人是否更有可能再次约会。查看第四列，**酷**，更高的酷度意味着有更好的第二次约会的可能性：
- en: '![](img/bf651e9a-b4df-4e18-bd02-f488fe9126b4.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/bf651e9a-b4df-4e18-bd02-f488fe9126b4.jpg)'
- en: Correlation coefficient table
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 相关系数表
- en: Looking at the table for  **Correlation Coefficients**, those men not in the **Workshop**
    were less likely to have another date and those with a higher **Cool** factor
    were more likely to have a second date.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 观察到**相关系数**表，那些不在**工作坊**的男士不太可能再次约会，而那些**酷**因子较高的男士更有可能再次约会。
- en: 'A logistical regression applied on this dataset would have the following:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个数据集上应用逻辑回归将具有以下特点：
- en: Response (dependent) variable: **Date**
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应（因）变量：**约会**
- en: 'Levels of measurement: **Mean** and **standard deviation**'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量水平：**平均值**和**标准差**
- en: 'Regression function: **Logistic** or **logit**'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归函数：**逻辑**或**logit**
- en: Total number of feature rows: **20**
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征行总数：**20**
- en: At this point, we have given you a better understanding of LR. We will wade
    deeper into this topic in the next section. We talked about response variables
    and correlation coefficients, otherwise known as dichotomous variables, and got
    a good handle on all of these. However, we have not yet formulated the LR model
    in mathematical terms. We want to know if using linear regression for building
    a model is appropriate for the breast cancer classification task. As it turns
    out, we will not be able to apply linear regression models to the task at hand.
    Why we turned to LR and not linear regression is one of the points of discussion
    in the next section.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经让您对逻辑回归有了更好的理解。我们将在下一节更深入地探讨这个话题。我们讨论了响应变量和相关性系数，也就是二元变量，并且对这些有了很好的把握。然而，我们还没有用数学术语制定逻辑回归模型。我们想知道使用线性回归来构建模型是否适合乳腺癌分类任务。结果证明，我们无法将线性回归模型应用于当前的任务。为什么我们转向逻辑回归而不是线性回归是下一节讨论的要点之一。
- en: LR as opposed to linear regression
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归与线性回归的区别
- en: 'Before choosing between logistic and linear regression methods, here are a
    few pointers that reiterate or restate what we talked about in this chapter and [Chapter
    1](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml), *Predict the Class of a Flower
    from the Iris Dataset*:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择逻辑回归和线性回归方法之前，这里有一些要点，它们重申或重述了我们在本章和[第一章](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml)，“从鸢尾花数据集预测花的类别”中讨论的内容：
- en: A data scientist working on their experimental data unit is seeking to build
    a model. Naturally, the follow-up question might be why are they interested in
    building an (ML) model?
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在他们的实验数据单元上工作的数据科学家正在寻求构建一个模型。自然而然地，接下来的问题可能是他们为什么对构建一个（机器学习）模型感兴趣？
- en: One answer to the previous question might be that the model helps discover patterns
    or the underlying relationship between the predictor (explanatory or independent)
    variables and their response counterparts.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于上一个问题的答案可能在于，该模型有助于发现预测变量（解释变量或独立变量）与其响应变量之间的模式或潜在关系。
- en: 'Speaking of response variables, response variables in a breast cancer dataset
    are categorical, as opposed to other ML classification tasks where the response
    variables are as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 谈到响应变量，乳腺癌数据集中的响应变量是分类的，与其他机器学习分类任务中的响应变量不同，后者如下：
- en: Continuous
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连续型
- en: Unbounded
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无界
- en: 'This brings us clarity, and with it the following working hypotheses:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们带来了清晰，并随之而来的是以下工作假设：
- en: The linear regression approach for our breast cancer classification task models
    may not work. After all, the response variable `Y` is neither continuous unbounded,
    or normally distributed. Before writing off the linear regression approach for
    our purposes, we will attempt such a formulation anyway, and in the process, shed
    more light on why LR is what we really want.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的乳腺癌分类任务，线性回归方法可能不起作用。毕竟，响应变量 `Y` 既不是连续的无界变量，也不是正态分布的。在我们将线性回归方法排除在我们的目的之前，我们仍然会尝试这样的公式，在这个过程中，我们可以更多地了解为什么线性回归（LR）是我们真正想要的。
- en: Formulation of a linear regression classification model
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归分类模型的公式化
- en: 'The basis for a mathematical formulation of a linear regression model may be
    broken down as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型的数学公式的依据可以分解如下：
- en: 'Left-hand side: The predicted variable.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 左侧：预测变量。
- en: 'Right-hand side represented by `y`: A linear construct that is made up of coefficients,
    a predictor (independent variable), and the arithmetic operators `+` for addition
    and `*` for multiplication.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 右侧表示为 `y`：由系数、预测变量（独立变量）和算术运算符 `+`（加法）和 `*`（乘法）组成的线性结构。
- en: Assuming there are four predictor variables, `PX1`, `PX2`, `PX3`, and `PX4`,
    each of these variables represents the so-called `X`.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设有四个预测变量，`PX1`、`PX2`、`PX3` 和 `PX4`，每个变量代表所谓的 `X`。
- en: 'At the outset, we could write an equation representing a linear regression
    model, as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在一开始，我们可以写出一个代表线性回归模型的方程，如下所示：
- en: '[PRE0]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'There is a catch! Our new linear regression model is characterized by response
    variables that are actually **non-dichotomous**. Well, we could put up a stand
    and say that it is still possible to come up with an improved version of this
    equation, which will represent a linear regression model with dichotomous response
    variables. It turns out that such an improved linear model will not work in actuality,
    for two reasons:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 但是有一个问题！我们新的线性回归模型的特点是响应变量实际上是**非二元的**。好吧，我们可以站出来声称，仍然有可能提出这个方程的改进版本，这将代表具有二元响应变量的线性回归模型。但实际上，这样的改进线性模型不会起作用，原因有两个：
- en: Our (dichotomous) response variables need to be arbitrarily assigned `0` and
    `1`. This is because we want to represent two mutually exclusive categorical states.
    Those states can be either benign or malignant, respectively.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的（二元）响应变量需要任意分配 `0` 和 `1`。这是因为我们想要表示两种相互排斥的分类状态。这些状态可以是良性的或恶性的，分别对应。
- en: The second reason has to do with the fact that because the response variable
    value `Y` is categorical, the predicted value is really the probability that this
    variable accepts a certain value, and not the value itself.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个原因与事实有关，即因为响应变量值 `Y` 是分类的，所以预测值实际上是这个变量接受某个值的概率，而不是这个值本身。
- en: At this point, our thought process appears to be decidedly in favor of at least
    a regression model with dichotomous response variables, as opposed to a linear
    regression model. How so?
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的思考过程似乎明显倾向于至少一个具有二元响应变量的回归模型，而不是线性回归模型。为什么会这样？
- en: It may be that the model we are looking to build is a function of probabilities,
    an LR equation, distinguished by a left-hand-side representation of a logit of
    `Y` rather than `Y` itself. The next section will weave the ideas presented here
    and build a mathematical formulation of the LR as an equation.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 可能我们想要构建的模型是概率的函数，一个逻辑回归方程，它区别于左侧表示为 `Y` 的对数而不是 `Y` 本身。下一节将结合这里提出的思想，构建逻辑回归的数学公式。
- en: Logit function as a mathematical equation
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对数函数作为数学方程
- en: Continuing on from where we left off in the previous section, this section is
    an attempt at translating those ideas and conclusions into a newer narrative.
    The goal of this section is to have a high-level mathematical formulation for
    LR.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 继续从上一节结束的地方讲起，本节试图将那些想法和结论转化为新的叙述。本节的目标是给出逻辑回归的高层次数学公式。
- en: However, with LR being a much more complicated case, we will formulate a simpler
    equation for what is known as a logit function, logit model, or logit odds.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于逻辑回归是一个更为复杂的案例，我们将为所谓的对数函数、对数模型或对数赔率制定一个更简单的方程。
- en: Without further ado, the logit function at a high level is expressed as `Logit(p)`
    and can be expanded to the mean logit of the odds of `Y`, rather than `Y` itself.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 不再赘述，对数函数在高级别上表示为 `Logit(p)`，可以扩展为赔率的均值对数，而不是 `Y` 本身。
- en: 'That said, here are a few mathematical concepts to help us understand and write
    a logit function:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，以下是一些数学概念，有助于我们理解和编写对数函数：
- en: '**Euler number**: Euler number (*e*) = 2.718228183'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**欧拉数**：欧拉数 (*e*) = 2.718228183'
- en: '**Natural logarithm**: If *e* can be raised to the power *y*, as in *e** ^y* = *x*,
    then the logarithm of *x* to the base *e* is *log[e]*(*x*) = *y*'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自然对数**：如果 *e* 可以被提升到 *y* 的幂，例如，*e**y* = *x*，那么 *x* 的以 *e* 为底的对数是 *log[e]*(*x*)
    = *y*'
- en: 'At this point, a formulation of the logit function becomes something like the
    following equation:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，对对数函数的表述类似于以下方程：
- en: '[PRE1]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Our newly-minted logit function is an equation based on the natural logarithm
    of the ratio of odds or probabilities. The logit function is a model, which is
    characterized by the following features:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们新制定的对数函数是基于赔率或概率比的自然对数的一个方程。对数函数是一个模型，其特征如下：
- en: In this logit function, `Ln[p/(1-p)]`, `p/(1-p)` is called the odds of our sample
    being labeled as benign. For example, `Ln[p/(1-p)]` is the natural logarithm or
    log-odds, or simply the logit as `Ln[p/(1-p)]` varying between drop down -∞ to
    +∞.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这个对数函数中，`Ln[p/(1-p)]`，`p/(1-p)` 被称为样本被标记为良性时的赔率。例如，`Ln[p/(1-p)]` 是自然对数或对数赔率，或者简单地说是对数，其值在
    -∞ 到 +∞ 之间变化。
- en: The logit function can be written as `fnLogistic(p) = ln(p/1-p)`, where `p`
    is between `0` and `1`, and where `0` and `1` are the maximum and minimum values
    plotted on the *x* axis, for example, `fnLogistic(0.9) = 2.197224577336`.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数函数可以表示为 `fnLogistic(p) = ln(p/1-p)`，其中 `p` 在 `0` 和 `1` 之间，而 `0` 和 `1` 是绘制在
    *x* 轴上的最大和最小值，例如，`fnLogistic(0.9) = 2.197224577336`。
- en: '`LR0`, `LR1`, `LR2`, and so on are known as model coefficients or correlation
    coefficients. These model coefficients relate to the predictor (explanatory) variable
    of the predicted (response) variable.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LR0`、`LR1`、`LR2` 等被称为模型系数或相关系数。这些模型系数与预测变量（解释变量）相关联，该变量与预测变量（响应变量）相关。'
- en: '`PX1`, `PX2`, and `PX3` are predictor variables.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PX1`、`PX2` 和 `PX3` 是预测变量。'
- en: The logit function is also a **link function**. It is a link function because
    it links the natural log of the probabilities on the left of the logit function
    to the linear equation made up of predictor variables and their respective coefficients.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数函数也是一个 **连接函数**。它之所以是连接函数，是因为它将位于对数函数左侧的概率的自然对数与由预测变量及其相应系数组成的线性方程联系起来。
- en: '`p` is said to be bounded between 0 and 1, which is the case here.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`p` 被说是在 0 和 1 之间有界，这里就是这种情况。'
- en: 'A typical logit function curve looks like this:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的对数函数曲线看起来像这样：
- en: '![](img/b835b690-a0ca-4189-9417-826d70661550.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b835b690-a0ca-4189-9417-826d70661550.jpg)'
- en: Logit model graph
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 对数模型图表
- en: At this point, we haven't discussed LR, which is a little more complicated than
    the logit model.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们还没有讨论逻辑回归，它比对数模型稍微复杂一些。
- en: 'An interpretation of the graph is as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 对图表的解释如下：
- en: 'The nonlinear graph will depict the following:'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非线性图表将描绘以下内容：
- en: '*x* axis: Logit values'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x* 轴：对数值'
- en: '*y* axis: Probabilities (or odds)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*y* 轴：概率（或赔率）'
- en: Looking at the graph, for a probability of **0**, the logit value is **0.5**
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察图表，对于概率为 **0** 的情况，对数值为 **0.5**
- en: To recap, we started with linear regression and then progressed to a discussion
    on the logit model. Understanding what the logit function is sets the stage for
    LR in the context of the breast cancer classification task.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下，我们开始于线性回归，然后转向对对数模型的讨论。理解对数几率函数是什么为在乳腺癌分类任务中逻辑回归的背景奠定了基础。
- en: LR function
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归函数
- en: We said before that LR is harder than the logit function. However, the LR formulation,
    as we shall see, is a good fit for this problem. We want to make a prediction
    on the fate of a sample being either benign or malignant. In other words, a prediction
    on a particular breast cancer tissue sample can only take one of two mutually
    exclusive values, based on feature measurements such as clump thickness, uniformity
    of cell size, and many more. Each of these feature measurements can be `X1`, `X2`,
    and `X3`, respectively.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前说过，逻辑回归比对数几率函数更难。然而，正如我们将要看到的，逻辑回归的公式非常适合这个问题。我们想要对样本是良性还是恶性的命运进行预测。换句话说，基于簇厚度、细胞大小均匀性等特征测量，特定的乳腺癌组织样本的预测只能取两个互斥值之一。每个这些特征测量可以分别表示为`X1`、`X2`和`X3`。
- en: This brings us to the beginning of a formulation of the LR function.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这将我们带到逻辑回归函数公式的开始。
- en: 'The core concept behind the LR function is the so-called inverse function,
    which is written down as:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归函数背后的核心概念是所谓的逆函数，其表示如下：
- en: '![](img/ca1342bb-fb83-4473-8ba0-5a38a02994ba.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ca1342bb-fb83-4473-8ba0-5a38a02994ba.png)'
- en: 'Here is a brief interpretation of the preceding equation:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是对前面方程的简要解释：
- en: '**p** in the preceding equation is simply a function of feature measurements
    of breast cancer samples represented by `X1`, `X2`, `X3`, and many more.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的方程中，**p**只是一个由`X1`、`X2`、`X3`以及更多表示的乳腺癌样本特征测量的函数。
- en: 'Rewriting **p** as `fLogistic(X1,X2,..)`, we have a complete function definition
    as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 将**p**重写为`fLogistic(X1,X2,..)`，我们得到了以下完整函数定义：
- en: '[PRE2]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: It turns out that the logit function we discussed earlier and our logistic regression
    function are inverses of each other.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，我们之前讨论的对数几率函数和我们的逻辑回归函数互为逆函数。
- en: 'Important points to remember about logistic regression are as follows:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 关于逻辑回归的重要要点如下：
- en: There is a dichotomous response variable representing the odds of an outcome
    occurring or not
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在一个表示结果发生或未发生的概率的二分响应变量
- en: 'A non-linear relationship between:'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以下是一个非线性关系：
- en: The categorical input (independent feature measurements) values plotted on the *x*
    axis. These are also known as predictor variables.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*x*轴上绘制的分类输入（独立特征测量）值。这些也被称为预测变量。
- en: The probabilities on the *y*-axis. These are predicted values.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*y*轴上的概率。这些是预测值。
- en: 'Very important: The coefficients `LR0`, `LR1`, and `LR2` are computed from
    our training dataset. Our training dataset has known or predetermined input measurements
    and output labels.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常重要：系数`LR0`、`LR1`和`LR2`是从我们的训练数据集中计算出来的。我们的训练数据集有已知或预定的输入测量和输出标签。
- en: At this point, we have what we need to switch focus to the Spark ML API for
    an implementation of the LR mathematical model that we just discussed.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经拥有了转向Spark ML API以实现我们刚才讨论的逻辑回归数学模型所需的全部内容。
- en: 'In the next section, we will build two data pipelines:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将构建两个数据管道：
- en: A pipeline using the Random Forests algorithm
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用随机森林算法的管道
- en: A pipeline using the LR method
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用逻辑回归方法的管道
- en: We are familiar with Random Forests from [Chapter 1, ](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml)*Predict
    the Class of a Flower from the Iris Dataset*. LR is a proven method that is backed
    by established statistical techniques that ML has found very handy for solving
    binary classification problems.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从[第1章，](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml)*从鸢尾花数据集预测花卉类别*中熟悉了随机森林。逻辑回归是一个经过验证的方法，它背后有成熟的统计技术，机器学习发现这些技术对于解决二元分类问题非常有用。
- en: The following *Getting started* section will get you started with the implementation
    process.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 以下*开始使用*部分将指导您开始实现过程。
- en: Getting started
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用
- en: 'The best way to get started is by understanding the bigger picture—gauging
    the magnitude of the work ahead of us. In this sense, we have identified two broad
    tasks:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 开始的最佳方式是理解更大的图景——评估我们面前工作的规模。在这种情况下，我们已经确定了两个广泛的任务：
- en: Setting up the prerequisite software.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置必备软件。
- en: 'Developing two pipelines, starting with data collection and building a workflow
    sequence that could end with predictions. Those pipelines are as follows:'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发两个流水线，从数据收集开始，构建一个可能以预测结束的工作流程序列。这些流水线如下：
- en: A Random Forests pipeline
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个随机森林流水线
- en: A logistical regression pipeline
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个逻辑回归流水线
- en: We will talk about setting up the prerequisite software in the next section.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中讨论设置先决软件。
- en: Setting up prerequisite software
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置先决软件
- en: First, please refer back to the *Setting up the prerequisite software* section
    in [Chapter 1](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml), *Predict the Class
    of a Flower from the Iris Dataset*, to review your existing infrastructure. If
    need be, you might want to install everything again. The chances of you having
    to substantively change anything are slim.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，请回顾[第1章](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml)中的*设置先决软件*部分，*从鸢尾花数据集预测花的类别*，以审查您现有的基础设施。如果需要，您可能需要重新安装所有内容。您需要实质性更改任何内容的可能性很小。
- en: 'However, here are the upgrades I recommend:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，以下是我推荐的升级：
- en: JDK upgrade to 1.8.0_172, if you have not already done so
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您还没有这样做，请将 JDK 升级到 1.8.0_172
- en: Scala from 2.11.12 to an early stable version of 2.12
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scala 从 2.11.12 升级到一个早期的稳定版本 2.12
- en: Spark 2.2 to 2.3 where 2.3, is a major release with numerous bug fixes, which
    is why hence it is recommended
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark 2.2 升级到 2.3，其中 2.3 是一个主要版本，包含许多错误修复，这也是为什么建议这样做的原因。
- en: At the time of writing this book, Java 9 and 10 don't appear to work with Spark.
    That might change. For the purposes of this chapter, your local Spark shell will
    be the development environment of choice.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时，Java 9 和 10 似乎与 Spark 不兼容。这可能会改变。为了本章的目的，您的本地 Spark shell 将是首选的开发环境。
- en: With the prerequisites out of the way, we are ready to jump right into developing
    pipelines. This journey starts in the *Implementation objectives* section.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在解决完先决条件后，我们准备好直接进入开发流水线。这次旅程从*实施目标*部分开始。
- en: Implementation objectives
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施目标
- en: 'We fulfilled our implementation objectives for [Chapter 1](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml),
    *Predict the Class of a Flower from the Iris Dataset*. In that chapter, early
    on, we developed the beginnings of a workflow process. This is depicted in the
    following diagram, which will help us frame the implementation objectives for
    this chapter as well:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经实现了[第1章](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml)的实施方案目标，*从鸢尾花数据集预测花的类别*。在该章的早期，我们开发了工作流程的初步过程。以下图表展示了这一点，它将帮助我们为本章制定实施方案目标：
- en: '![](img/1ae72d8d-a9ba-4d16-88f5-cebbd65d6a66.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1ae72d8d-a9ba-4d16-88f5-cebbd65d6a66.png)'
- en: Stages in a preliminary workflow
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 初步工作流程的阶段
- en: 'Since the current chapter also deals with a multiclass classification task
    like the one before it, the four boxes that are shown in the preceding diagram
    are our guide to setting up implementation objectives for this chapter. The broad
    high-level objectives are:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 由于当前章节也处理与之前类似的多类分类任务，因此前图中显示的四个框是我们为设置本章实施方案目标的指南。广泛的高级目标是：
- en: A **Data Collection** step followed by an **Exploratory Data Analysis** (**EDA**)
    step
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据收集**步骤之后是**探索性数据分析**(**EDA**)步骤'
- en: A **Data Cleaning**/**Preprocessing** step
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据清洗**/**预处理**步骤'
- en: Handing off data to an algorithm; there are models to be trained (fitted) and
    predictions to be generated
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据传递给算法；有模型需要训练（拟合）和预测需要生成
- en: 'This paves the way for a more complete list of implementation objectives, and
    they are:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这为更完整的实施方案目标列表铺平了道路，它们是：
- en: Getting the breast cancer dataset from the UCI Machine Learning Repository.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 UCI 机器学习库获取乳腺癌数据集。
- en: Deriving a dataframe for EDA.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为 EDA 提取数据框。
- en: Carrying out preliminary EDA in the Sandbox Zeppelin Notebook environment (or
    Spark shell), and running a statistical analysis.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在沙盒 Zeppelin 笔记本环境中进行初步的 EDA（探索性数据分析）操作，并在 Spark shell 中运行统计分析。
- en: 'Developing the pipeline incrementally in Zeppelin and porting the code into
    IntelliJ. What this means is the following:'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Zeppelin 中逐步开发流水线并将代码移植到 IntelliJ。这意味着以下内容：
- en: Creating a new Scala project in IntelliJ, or importing an existing empty project
    into IntelliJ, and creating Scala artifacts from code that was incrementally developed
    in the Notebook
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 IntelliJ 中创建一个新的 Scala 项目，或将现有的空项目导入 IntelliJ，并从笔记本中逐步开发出的代码创建 Scala 代码库
- en: Do not forget to wire up all the necessary dependencies in the `build` file
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要忘记在`build`文件中连接所有必要的依赖项
- en: 'Interpreting the results of the pipeline:'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释管道的结果：
- en: How well did the classifier perform?
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类器表现如何？
- en: How close are the predicted values to those in the original dataset?
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测值与原始数据集中的值有多接近？
- en: Now, we will start working on these implementations one by one, starting with
    getting the Wisconsin Breast Cancer Data Set from the UCI Machine Learning Repository.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将逐一开始工作，从从UCI机器学习仓库获取威斯康星乳腺癌数据集开始。
- en: Implementation objective 1 – getting the breast cancer dataset
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施目标1 – 获取乳腺癌数据集
- en: Head over to the UCI Machine Learning Repository website at [https://archive.ics.uci.edu/ml/datasets/bcw](https://archive.ics.uci.edu/ml/datasets/bcw)
    and download the `Data` folder by clicking on Data Folder. Extract this folder
    someplace convenient and copy `bcw.csv` into the root of your project folder,
    which we will call `Chapter2`. At this point, `Chapter2` will be empty.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 前往UCI机器学习仓库网站[https://archive.ics.uci.edu/ml/datasets/bcw](https://archive.ics.uci.edu/ml/datasets/bcw)，通过点击数据文件夹下载`Data`文件夹。将此文件夹提取到方便的位置，并将`bcw.csv`复制到项目文件夹的根目录，我们将称之为`Chapter2`。此时，`Chapter2`将是空的。
- en: 'You may refer back to the project overview for an in-depth description of the
    breast cancer dataset. We depict the contents of the `bcw.data` file here as follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考项目概述以深入了解乳腺癌数据集的描述。我们在此以如下方式描述`bcw.data`文件的内容：
- en: '![](img/6fc9f404-d847-4dfe-94a9-049f4b0af745.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6fc9f404-d847-4dfe-94a9-049f4b0af745.jpg)'
- en: A snapshot of the breast cancer dataset with 699 rows
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 包含699行的乳腺癌数据集快照
- en: The breast cancer dataset that we just downloaded is multivariate, meaning it
    includes a set of more than one independent variable. Before performing any EDA
    on it, we need to create an abstraction over the dataset, which we call a dataframe. How
    we create a dataframe as a prelude to EDA is the goal of the next section.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚下载的乳腺癌数据集是多元的，这意味着它包含一组超过一个的独立变量。在对其进行任何EDA之前，我们需要创建一个数据集的抽象，我们称之为dataframe。如何创建dataframe作为EDA的先导是下一节的目标。
- en: Implementation objective 2 – deriving a dataframe for EDA
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施目标2 – 为EDA推导dataframe
- en: We downloaded the Wisconsin Breast Cancer data file into the `Chapter2` folder
    and renamed it `bcw.csv`. The process of `DataFrame` creation starts with loading
    the data.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将威斯康星乳腺癌数据文件下载到`Chapter2`文件夹，并将其重命名为`bcw.csv`。`DataFrame`创建的过程从加载数据开始。
- en: 'We will invoke the `read` method on `SparkSession` as follows:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按照以下方式在`SparkSession`上调用`read`方法：
- en: '[PRE3]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `read` method that has been returned produces `DataFrameReader`. Because
    our dataset is a CSV file, we want to tell Spark about it by invoking the `format`
    method on `DataFrameReader` by passing in the `com.databricks.spark.csv` format
    specifier string:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的`read`方法产生`DataFrameReader`。由于我们的数据集是一个CSV文件，我们想通过在`DataFrameReader`上调用`format`方法并传入`com.databricks.spark.csv`格式指定符字符串来告诉Spark：
- en: '[PRE4]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'At this point, `DataFrameReader` needs an input data source option in the form
    of a key-value pair. Invoke the `option` method with two arguments, a key `"header"`
    of type string and its value `true` of type Boolean:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，`DataFrameReader`需要一个键值对形式的输入数据源选项。使用两个参数调用`option`方法，一个字符串类型的键`"header"`和其布尔类型的值`true`：
- en: '[PRE5]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, the code is invoking the `option` method again (on the `DataFrameReader)`
    with an argument called `inferSchema` and a `true` value. With the `inferSchema`
    method call, we want Spark to figure out the schema of our input data source and
    return our `DataFrameReader`:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，代码再次调用`option`方法（在`DataFrameReader`上），参数为名为`inferSchema`的参数和`true`值。通过调用`inferSchema`方法，我们希望Spark确定我们的输入数据源的架构，并返回我们的`DataFrameReader`：
- en: '[PRE6]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, load `bcw.csv` by invoking the `load` method and passing it to the path
    to the dataset file. External data sources such as our dataset require a path
    for Spark to be able to load the data so that `DataFrameReader` can process the
    file and return the `DataFrame`, as follows:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，通过调用`load`方法并将数据集文件的路径传递给它来加载`bcw.csv`。外部数据源，如我们的数据集，需要一个路径，以便Spark能够加载数据，这样`DataFrameReader`就可以处理文件并返回`DataFrame`，如下所示：
- en: '[PRE7]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We now have a breast cancer dataframe! This completes the *Implementation objective
    2 – deriving a dataframe for EDA* section. Our next step is to run a preliminary
    statistical analysis.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了乳腺癌dataframe！这完成了*实施目标2 – 为EDA推导dataframe*部分。我们的下一步是进行初步的统计分析。
- en: 'Finally, before we move on to the next step, here is a view of the dataframe:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在我们进行下一步之前，这里有一个dataframe的视图：
- en: '![](img/cd772ab5-cd71-410d-8bd1-748be5055d54.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cd772ab5-cd71-410d-8bd1-748be5055d54.jpg)'
- en: Dataframe with raw data
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据 DataFrame
- en: It looks like we have data in our `DataFrame`, which is now ready for EDA.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们的 `DataFrame` 中有数据，现在它已经准备好进行 EDA。
- en: Step 1 – conducting preliminary EDA
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一步 – 进行初步的 EDA
- en: At this point, we will perform a fairly simple statistical analysis on our dataset.
    This will provide us with useful, though preliminary, statistical insights such
    as mean, median, range, and standard deviation, to name a few.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们将对我们的数据集进行相当简单的统计分析。这将为我们提供一些有用的、初步的统计洞察，例如均值、中位数、范围和标准差等。
- en: 'To proceed with the preliminary EDA, let''s invoke the `describe` method with
    the required column names as parameters. This will give us a new `DataFrame` called
    `stats`. Invoking a `show` method on `stats` will produce a table of statistical
    results as follows:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行初步的 EDA，让我们使用所需的列名作为参数调用 `describe` 方法。这将给我们一个新的名为 `stats` 的 `DataFrame`。在
    `stats` 上调用 `show` 方法将生成如下统计结果表：
- en: '![](img/f92ee6f5-15cb-4485-b4d3-ac9030619620.jpg)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f92ee6f5-15cb-4485-b4d3-ac9030619620.jpg)'
- en: Statistical analysis
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 统计分析
- en: Although the output is ugly to look at and is mangled, we see statistical numbers
    such as the `count`, `mean`, standard deviation, minimum, and maximum. Yes, the
    dataset has 699 rows of continuous, discrete (or categorical) values.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管输出看起来很丑陋且混乱，但我们看到了统计数字，如 `count`、`mean`、标准差、最小值和最大值。是的，数据集有 699 行连续的、离散的（或分类的）值。
- en: Now that the preliminary exploratory data analysis is complete, we proceed to
    the next step, where we will load the dataset into Spark.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 现在初步的探索性数据分析已经完成，我们进入下一步，将数据集加载到 Spark 中。
- en: Step 2 – loading data and converting it to an RDD[String]
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二步 – 加载数据并将其转换为 RDD[String]
- en: 'In this step, we will load the data again, but in a slightly different manner.
    The goal of this phase of the data analysis is to produce a `DataFrame` where
    the data has been read into an `RDD[String]`. First, we will need a path to the
    dataset:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步中，我们将再次加载数据，但方式略有不同。这一阶段数据分析的目标是生成一个 `DataFrame`，其中数据已被读入 `RDD[String]`。首先，我们需要数据集的路径：
- en: '[PRE8]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We have just created `dataSetpath`. In the following code, we will pass the
    path to the dataset into the `textFile` method:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚创建了 `dataSetpath`。在下面的代码中，我们将数据集的路径传递给 `textFile` 方法：
- en: '[PRE9]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `textFile` method returned an `RDD[String]`. To check if data was loaded
    into the RDD, we need to invoke the `first` method on `firstRDD` to give us the `header`
    content. We will leave this as an exercise for the reader.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '`textFile` 方法返回了一个 `RDD[String]`。为了检查数据是否已加载到 RDD 中，我们需要在 `firstRDD` 上调用 `first`
    方法以获取 `header` 内容。我们将把这个作为练习留给读者。'
- en: 'Next, we want to know the number of partitions in our RDD:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们想知道我们的 RDD 中的分区数：
- en: '[PRE10]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `getNumPartitions` method returned the number of partitions in `firstRDD`. 
    Since an RDD allows us to work with data at a low level, we will continue to reorganize
    and massage this data as required.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '`getNumPartitions` 方法返回了 `firstRDD` 中的分区数。由于 RDD 允许我们在低级别上处理数据，我们将继续按照需要重新组织和调整这些数据。'
- en: In the next step, we want to inspect the RDD. We want to reorganize and repackage
    data into arrays.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一步中，我们想要检查 RDD。我们想要重新组织和包装数据到数组中。
- en: Step 3 – splitting the resilient distributed dataset and reorganizing individual
    rows into an array
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三步 – 分割弹性分布式数据集并将单个行重新组织为数组
- en: To split the dataset, we will start with the RDD partitions. It is helpful to
    think of an RDD partition in the following manner.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分割数据集，我们将从 RDD 分区开始。以以下方式思考 RDD 分区是有帮助的。
- en: Each partition can be visualized as one long string consisting of rows of data
    separated by `"\n"`. We want to break down this long string into its constituent
    string, by splitting them along the `"\n"` separator. Shortly, we will try a `flatMap`
    operation on our RDD, `firstRDD`. Each constituent string is a `Row` that represents
    a row in the original dataset.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 每个分区可以可视化为一个由 `"\n"` 分隔的行数据组成的长字符串。我们想要通过 `"\n"` 分隔符将这些长字符串分解为其组成部分字符串。简而言之，我们将在我们的
    RDD，`firstRDD` 上尝试一个 `flatMap` 操作。每个组成部分字符串是一个 `Row`，它代表原始数据集中的行。
- en: 'We will do `flatMap` and pass to it an anonymous function, which will be invoked
    on rows separated by a `"\n"` character, as follows:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对 `flatMap` 进行操作，并传递一个匿名函数，该函数将在由 `"\n"` 字符分隔的行上调用，如下所示：
- en: '[PRE11]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The preceding code does a `flatMap` flattening operation, resulting in the
    creation of a new `RDD[String]` that will hold all of these strings (each string
    is a row in our dataset). At this point, we will `split` (along the comma between
    individual characters of that row) a `String` producing an `RDD[Array[String]]`:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码执行了一个`flatMap`扁平化操作，结果创建了一个新的`RDD[String]`，它将包含所有这些字符串（每个字符串都是我们的数据集中的一行）。在这个阶段，我们将`split`（沿着该行中各个字符之间的逗号）一个`String`，生成一个`RDD[Array[String]]`：
- en: '[PRE12]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The `RDD[Array[String]]` naturally implies that the RDD contains more than one
    `Array[String]`. How many of these arrays are in this RDD?
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '`RDD[Array[String]]`自然意味着该RDD包含多个`Array[String]`。在这个RDD中有多少这样的数组？'
- en: '[PRE13]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Invoking `count` on our RDD returns an array count of `700`, which is what it
    should be.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的RDD上调用`count`返回了一个数组计数为`700`，这正是它应有的值。
- en: Step 4 – purging the dataset of rows containing question mark characters
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4步 – 清除包含问号字符的行
- en: Before we go any further, let's eyeball the raw dataset again. If you looked
    closely, you will notice that the dataset contains a `?` character in some places.
    Actually, this character starts appearing in some rows in the seventh column,
    starting on the 25^(th) row. The 25^(th) row, with the `?` character, is displayed
    in the following diagram. That them is a problem, which needs a solution.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，让我们再次查看原始数据集。如果你仔细观察，你会注意到数据集中某些地方包含`?`字符。实际上，这个字符从第七列开始出现在一些行的第25行。带有`?`字符的第25行在下面的图中显示。这是一个问题，需要解决方案。
- en: Sometimes, a visual inspection of the dataset can reveal the presence of extraneous
    characters.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，对数据集的视觉检查可以揭示存在多余的字符。
- en: 'The following is a snapshot of the Wisconsin Breast Cancer Data Set with the
    `?` character in the 25^(th) row and the sixth column:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是以`?`字符出现在第25行和第六列的威斯康星州乳腺癌数据集的快照：
- en: '![](img/fb958bd9-a451-4a2e-a353-2116ffe8bb41.jpg)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fb958bd9-a451-4a2e-a353-2116ffe8bb41.jpg)'
- en: Dataset showing ? characters
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 显示?字符的数据集
- en: 'Obviously, it is not just row 25^(th) that has a `?` character. There are likely
    other rows with the extraneous `?` character that needs to be purged. One solution
    appears to be to invoke a `filter` operation on our `rddArrayString`:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，不仅仅是第25行有`?`字符。可能还有其他行包含需要清除的多余的`?`字符。一个解决方案似乎是在我们的`rddArrayString`上调用一个`filter`操作：
- en: '[PRE14]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As evident from the preceding code, we just ran the `filter` operation, which
    returned a new `RDD[Array[String]` that we called `purgedRDD`. Naturally, we may
    want to count the number of rows left in the dataset that we believe are relevant
    for data analysis. That is the goal of the next section.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述代码所示，我们刚刚运行了`filter`操作，它返回了一个新的`RDD[Array[String]`，我们称之为`purgedRDD`。自然地，我们可能想要计算数据集中剩余的行数，我们认为这些行对于数据分析是相关的。这就是下一节的目标。
- en: Step 5 – running a count after purging the dataset of rows with questionable
    characters
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5步 – 清除数据集中有疑问字符的行后的计数
- en: 'We will now run `count` on our new `purgedRDD`:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将在新的`purgedRDD`上运行`count`：
- en: '[PRE15]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: So, in the preceding code, we invoked the `count` method on `purgedRDD`. Spark
    returned a value of `684`. Apparently, 16 rows contained `?` characters. After
    all, many datasets like this one need a preprocessing step or two. For now, we
    will proceed with the next steps in data analysis, secure in the knowledge that
    Spark will probably not report an error, especially at the point where we want
    a new two-column `DataFrame` containing a consolidated feature vector.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在先前的代码中，我们在`purgedRDD`上调用了`count`方法。Spark返回了一个值为`684`的结果。显然，有16行包含`?`字符。毕竟，许多像这样的数据集需要预处理步骤或两个。现在，我们将继续进行数据分析的下一步，因为我们知道Spark可能不会报告错误，尤其是在我们想要一个包含合并特征向量的新两列`DataFrame`的地方。
- en: In the next section, we are going to get rid of `header`.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将去除`header`。
- en: Step 6 – getting rid of header
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6步 – 去除header
- en: 'Each of the inner arrays shown earlier holds rows that represent feature measurements,
    and a row representing the dataset `header`. The following line of code converts
    our RDD into an `Array`, containing arrays that themselves contain rows as strings:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 之前显示的每个内部数组都包含表示特征测量的行和一个表示数据集`header`的行。以下代码行将我们的RDD转换为包含字符串行的数组：
- en: '[PRE16]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The `drop` method got rid of `header`. Next, we will move on and create a new
    `DataFrame`.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '`drop`方法去除了`header`。接下来，我们将继续创建一个新的`DataFrame`。'
- en: Step 7 – creating a two-column DataFrame
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7步 – 创建一个两列的DataFrame
- en: 'We are close. In this section, the goal is to create an input feature vector,
    and the steps are listed as follows:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经接近目标了。在本节中，目标是创建一个输入特征向量，步骤如下：
- en: Import the `Vectors` class.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `Vectors` 类。
- en: Inside the `map` operation on the `Array`, we will iterate over each row of
    our header-free dataset. Then, we transform each row in turn, operating on every
    single column containing predetermined cell nuclei measurements. These columns
    are converted to doubles by using the `dense` method.
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Array` 上的 `map` 操作中，我们将遍历我们的无头数据集的每一行。然后，我们依次转换每一行，对包含预定细胞核测量的每一列进行操作。这些列通过使用
    `dense` 方法被转换为双精度浮点数。
- en: 'The `map` operation processes the entire dataset and produces `featureVectorArray,`
    a structure of type `Array[(Input Feature Vector, String representing the Class)]`:'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`map` 操作处理整个数据集，并生成 `featureVectorArray`，这是一个类型为 `Array[(Input Feature Vector,
    String representing the Class)]` 的结构：'
- en: '[PRE17]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Okay, we created `featureVectorArray`, an `Array` consisting of a set of `(Vector,
    String)` tuples. This `Array` is now ready to be converted into `DataFrame`. That
    is the goal of the next section.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我们已经创建了 `featureVectorArray`，这是一个由一组 `(Vector, String)` 元组组成的 `Array`。现在这个
    `Array` 已经准备好被转换成 `DataFrame`。这就是下一节的目标。
- en: Step 8 – creating the final DataFrame
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8步 – 创建最终的 DataFrame
- en: 'The goal of this section is to create a final version of our analysis-ready
    `DataFrame`. The `createDataFrame` method available on `SparkSession` is suitable,
    and is shown as follows:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目标是创建一个最终的分析就绪 `DataFrame` 版本。`SparkSession` 上可用的 `createDataFrame` 方法是合适的，如下所示：
- en: '[PRE18]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As seen earlier, the new `DataFrame` has two columns, which are not very readable
    named `_1` and `_2`.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，新的 `DataFrame` 有两个列，它们的命名不是很可读，分别是 `_1` 和 `_2`。
- en: 'What we want is a renamed `DataFrame` with two readable columns as follows:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要的是一个重命名的 `DataFrame`，包含两个可读的列，如下所示：
- en: A feature vector column that is named `bc-diagnosis-label-column` and a target
    variable label column named `bc-indexed-category-column`.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个名为 `bc-diagnosis-label-column` 的特征向量列和一个名为 `bc-indexed-category-column` 的目标变量标签列。
- en: By the way, a target variable in ML terminology denotes what is being predicted.
    For example, it could be a `0` for benign or `1` for malignant. Since a target
    variable is associated with the output, it can also be termed an outcome or output
    variable. Defining a target variable is an integral part of the binary classification
    model creation step; a target variable in statistics terminology is the same as
    a response variable.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顺便说一下，在机器学习术语中，目标变量表示正在预测的内容。例如，它可以是良性为 `0` 或恶性为 `1`。由于目标变量与输出相关联，它也可以被称为结果或输出变量。定义目标变量是创建二元分类模型步骤的一个基本部分；在统计学术语中，目标变量与响应变量相同。
- en: 'To get a renamed `DataFrame`, we will transform it a little, and we will do
    this by creating two methods as follows:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 要得到一个重命名的 `DataFrame`，我们将对其进行一些转换，我们将通过创建以下两个方法来完成：
- en: '[PRE19]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In the following line of code, invoke the `toDF` method:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码行中，调用 `toDF` 方法：
- en: '[PRE20]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Invoking the `toDF` method creates a `DataFrame` with the desired column names.
    Invoking `show` on `dataFrame2` will result in the following display:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 `toDF` 方法创建一个具有所需列名的 `DataFrame`。在 `dataFrame2` 上调用 `show` 将导致以下显示：
- en: '[PRE21]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The preceding listing confirms that the `DataFrame` you wanted is what you
    got. In the next section, we will use this `DataFrame` to build a data pipeline
    with two algorithms:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 上述列表确认了您想要的 `DataFrame` 就是您得到的。在下一节中，我们将使用这个 `DataFrame` 来构建包含两个算法的数据管道：
- en: The Random Forest algorithm
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林算法
- en: LR
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LR
- en: We will build a Random Forest pipeline first.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将构建一个随机森林管道。
- en: Random Forest breast cancer pipeline
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林乳腺癌管道
- en: 'A good way to start this section off is to download the `Skeleton` SBT project
    archive file from the `ModernScalaProjects_Code` folder. Here is the structure
    of the `Skeleton` project:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 开始本节的一个好方法是下载 `ModernScalaProjects_Code` 文件夹中的 `Skeleton` SBT 项目存档文件。以下是 `Skeleton`
    项目的结构：
- en: '![](img/1d7e9856-8def-4c5a-b296-ce02f3458bec.jpg)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1d7e9856-8def-4c5a-b296-ce02f3458bec.jpg)'
- en: Project structure
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 项目结构
- en: Instructions to readers: Copy and paste the file into a folder of your choice
    before extracting it. Import this project into IntelliJ, drill down to the package
    `"com.packt.modern.chapter"`, and rename it `"com.packt.modern.chapter2"`. If
    you would rather choose a different name, choose something appropriate. The breast
    cancer pipeline project is already set up with `build.sbt`, `plugins.sbt`, and
    `build.properties`. You only need to make appropriate changes to the organization
    element in `build.sbt`. Once these changes are done, you are all set for development.
    For an explanation of dependency entries in `build.sbt`, please refer back to
    [Chapter 1](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml), *Predict the Class of
    a Flower from the Iris Dataset*. Unless we introduce new dependencies for this
    project, we will stick with the `build.sbt` that came bundled in the `Skeleton`
    project.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 读者指南：在提取之前，将文件复制并粘贴到您选择的文件夹中。将此项目导入IntelliJ，深入到包`"com.packt.modern.chapter"`，并将其重命名为`"com.packt.modern.chapter2"`。如果您想选择不同的名称，请选择一个合适的名称。乳腺癌管道项目已经设置了`build.sbt`、`plugins.sbt`和`build.properties`。您只需要在`build.sbt`中的组织元素中进行适当的更改。一旦完成这些更改，您就为开发做好了准备。有关`build.sbt`中依赖项的解释，请参阅[第1章](4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml)，*从鸢尾花数据集预测花的类别*。除非我们为这个项目引入新的依赖项，否则我们将坚持使用`Skeleton`项目中捆绑的`build.sbt`。
- en: All that being said, we will now start the implementation. The first step will
    be to create Scala code files in IntelliJ. Note that the complete code is available
    in your downloaded folder, `ModernScalaProjects_Code`.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，我们现在将开始实施。第一步将是创建IntelliJ中的Scala代码文件。请注意，完整的代码已包含在你下载的文件夹中，`ModernScalaProjects_Code`。
- en: Step 1 – creating an RDD and preprocessing the data
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1步 – 创建RDD并预处理数据
- en: Create a Scala file called `BreastCancerRfPipeline.scala` in the `com.packt.modern.chapter2` package.
    Up until now, we relied on `SparkSession` and `SparkContext`, which are what `spark-shell`
    gave us. We need to create our `SparkSession` now, which will give us `SparkContext`.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在`com.packt.modern.chapter2`包中创建一个名为`BreastCancerRfPipeline.scala`的Scala文件。到目前为止，我们依赖于`SparkSession`和`SparkContext`，这是`spark-shell`提供给我们的。现在我们需要创建我们的`SparkSession`，这将给我们`SparkContext`。
- en: 'In `BreastCancerRfPipeline.scala`, after the package statement, place the following
    import statements:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在`BreastCancerRfPipeline.scala`中，在包声明之后，放置以下导入语句：
- en: '[PRE22]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Create a `SparkSession` inside a trait, which we shall call `WisconsinWrapper`:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个名为`WisconsinWrapper`的特质中创建一个`SparkSession`：
- en: '[PRE23]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Just one `SparkSession` is made available to all classes extending from `WisconsinWrapper`.
    Create `val` to hold the `bcw.csv` file path:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 只有一个`SparkSession`被提供给所有继承自`WisconsinWrapper`的类。创建`val`来保存`bcw.csv`文件路径：
- en: '[PRE24]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Create a method to build the `DataFrame`. This method takes in the complete
    path to the breast cancer dataset as a `String` and returns `DataFrame`:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个构建`DataFrame`的方法。此方法接受乳腺癌数据集的完整路径作为`String`，并返回`DataFrame`：
- en: '[PRE25]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Import the `DataFrame` class by updating the previous `import` statement for
    `SparkSession`:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 通过更新之前的`import`语句来导入`DataFrame`类，针对`SparkSession`：
- en: '[PRE26]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Create a nested function inside `buildDataFrame` to process the raw dataset.
    Name this function `getRows`. The `getRows` function takes no parameters but returns
    `Array[(Vector, String)]`. The `textFile` method on the `SparkContext` variable
    processes `bcw.csv` into `RDD[String]`:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在`buildDataFrame`内部创建一个嵌套函数来处理原始数据集。将此函数命名为`getRows`。`getRows`函数不接受任何参数，但返回`Array[(Vector,
    String)]`。`SparkContext`变量的`textFile`方法将`bcw.csv`处理为`RDD[String]`：
- en: '[PRE27]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The resulting RDD contains two partitions. Each partition, in turn, contains
    rows of strings separated by a newline character, `"\n"`. Each row in the RDD
    represents its original counterpart in the raw data.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 结果RDD包含两个分区。每个分区依次包含由换行符`"\n"`分隔的字符串行。RDD中的每一行代表其在原始数据中的原始对应项。
- en: In the next step, we will preprocess this RDD; this entails creating a single
    consolidated input `features` column out of the original four feature columns.
    We start this process by invoking `flatMap` and passing a function block to it.
    After successive transformations, which are listed in the following code, we should
    be able to create an array of type `Array[(org.apache.spark.ml.linalg.Vector,
    String)]`.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一步中，我们将预处理这个RDD；这包括从原始的四个特征列中创建一个单一的合并输入`features`列。我们通过调用`flatMap`并传递一个函数块来开始这个过程。在后续的转换之后，这些转换在下面的代码中列出，我们应该能够创建一个类型为`Array[(org.apache.spark.ml.linalg.Vector,
    String)]`的数组。
- en: '`Vector`, in this case, represents a row of feature measurements. The Scala
    code to give us `Array[(org.apache.spark.ml.linalg.Vector, String)]` is as follows:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '`Vector`在这种情况下代表特征测量的行。Scala代码以给我们`Array[(org.apache.spark.ml.linalg.Vector,
    String)]`如下：'
- en: '[PRE28]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Next, drop the `header` column, but not before performing a `collect` that
    returns an `Array[Array[String]]`:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，删除`header`列，但在执行返回`Array[Array[String]]`的`collect`操作之前：
- en: '[PRE29]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The `header` column is now eliminated. We will now import the `Vectors` class:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '`header`列现在已被删除。我们现在将导入`Vectors`类：'
- en: '[PRE30]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, transform the `Array[Array[String]]` into `Array[(Vector, String)]`:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将`Array[Array[String]]`转换为`Array[(Vector, String)]`：
- en: '[PRE31]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now, we will invoke the `createDataFrame` method with a parameter called `getRows`.
    This returns a `DataFrame` with `featureVector` and `speciesLabel` (for example,
    `bcw-Setos`):'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用名为`getRows`的参数调用`createDataFrame`方法。这将返回一个包含`featureVector`和`speciesLabel`（例如，`bcw-Setos`）的`DataFrame`：
- en: '[PRE32]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The new `DataFrame` contains two rows:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 新的`DataFrame`包含两行：
- en: A column named `bcw-features-column`
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个名为`bcw-features-column`的列
- en: A column named `bcw-species-label-column`
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个名为`bcw-species-label-column`的列
- en: We need to index `species-label-column` by converting the `"bcw-Setosa"`, `"bcw-Virginica"`,
    and `"bcw-Versicolor"` strings into doubles. We will use a `StringIndexer` to
    do that.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要通过将`"bcw-Setosa"`、`"bcw-Virginica"`和`"bcw-Versicolor"`字符串转换为double来索引`species-label-column`。我们将使用`StringIndexer`来完成此操作。
- en: Now, create a file called `bcwPipeline.scala`.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，创建一个名为`bcwPipeline.scala`的文件。
- en: 'Create an object called `bcwPipeline` that extends our `bcwWrapper` trait:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为`bcwPipeline`的对象，它扩展了我们的`bcwWrapper`特质：
- en: '[PRE33]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Import the `StringIndexer` algorithm class:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 导入`StringIndexer`算法类：
- en: '[PRE34]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now, create a `StringIndexer` algorithm instance. `StringIndexer` will map `species-label-column`
    to an indexed learned column:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，创建一个`StringIndexer`算法实例。`StringIndexer`将`species-label-column`映射到一个索引学习列：
- en: '[PRE35]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The indexer transforms the `bcw` type column into a column of type double. This
    is an example where a categorical variable is disguised as a quantitative variable.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 索引器将`bcw`类型列转换为double类型的列。这是一个将分类变量伪装成定量变量的例子。
- en: Step 2 – creating training and test data
  id: totrans-342
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2步 – 创建训练和测试数据
- en: 'Now, let''s split our dataset in two by providing a random seed:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，通过提供一个随机种子来将我们的数据集分成两部分：
- en: '[PRE36]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The new `splitDataset` contains two datasets:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 新的`splitDataset`包含两个数据集：
- en: 'The training `Dataset` is a dataset containing `Array[(Vector, bcw-species-label-column:
    String)]`'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '训练`Dataset`是一个包含`Array[(Vector, bcw-species-label-column: String)]`的数据集'
- en: 'The test `Dataset` is a dataset containing `Array[(Vector, bcw-species-label-column:
    String)]`'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '测试`Dataset`是一个包含`Array[(Vector, bcw-species-label-column: String)]`的数据集'
- en: 'Confirm that the new `Dataset` is of size `2`:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 确认新的`Dataset`大小为`2`：
- en: '[PRE37]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Assign the training `Dataset` to the `trainSet` variable:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 将训练`Dataset`分配给`trainSet`变量：
- en: '[PRE38]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Assign the testing `Dataset` to the `testSet` variable:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 将测试`Dataset`分配给`testSet`变量：
- en: '[PRE39]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Now, we will see how to create a Random Forest classifier.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将看到如何创建一个随机森林分类器。
- en: 'Create a classifier and pass into it hyperparameters. We will set the following
    parameters first:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个分类器并将其超参数传递给它。我们首先设置以下参数：
- en: A `"features"` column name
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个名为`"features"`的列名
- en: An indexed `"label"` column name
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个索引的`"label"`列名
- en: The number of features to be considered per split (we have 150 observations
    and four features) that will make our `max_features 2`
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每次分割要考虑的特征数量（我们有150个观测值和四个特征），这将使我们的`max_features`为`2`
- en: 'Since `bcw` is a classification problem, the `''sqrt''` setting for `featureSubsetStrategy`
    is what we need. In addition, we will pass in other parameters such as impurity,
    the number of trees to train, and many more, as follows:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`bcw`是一个分类问题，因此`featureSubsetStrategy`的`'sqrt'`设置是我们需要的。此外，我们还将传递其他参数，如杂质、要训练的树的数量等，如下所示：
- en: Impurity settings—values can be gini and entropy
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杂质设置—值可以是gini和entropy
- en: Number of trees to train (since the number of trees is greater than 1, we set
    the tree maximum depth, which is a number equal to the number of nodes)
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要训练的树的数量（由于树的数量大于1，我们设置树的最大深度，这是一个等于节点数量的数字）
- en: The required minimum number of feature measurements (sampled observations),
    also known as the minimum instances per node
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所需的最小特征测量数（样本观测值），也称为每个节点的最小实例数
- en: This time, we will employ an exhaustive grid search-based model selection process,
    based on combinations of parameters, where parameter value ranges are specified.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们将采用基于参数组合的穷举网格搜索模型选择过程，其中指定了参数值范围。
- en: 'Create a `randomForestClassifier` instance. Set the features and `featureSubsetStrategy`:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个 `randomForestClassifier` 实例。设置特征和 `featureSubsetStrategy`：
- en: '[PRE40]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Start building a `Pipeline` that has two stages, an `indexer` and a `Classifier`:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 开始构建一个有两个阶段的 `Pipeline`，一个 `indexer` 和一个 `Classifier`：
- en: '[PRE41]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Next, set the hyperparameter `num_trees` (number of trees) on the classifier
    to `15`, a `Max_Depth` parameter, and an impurity with two possible values of
    gini and entropy. Then, build a parameter grid with all three hyperparameters.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将分类器上的超参数 `num_trees`（树的数量）设置为 `15`，一个 `Max_Depth` 参数，以及具有两个可能值 gini 和 entropy
    的不纯度。然后，构建一个包含所有三个超参数的参数网格。
- en: Step 3 – training the Random Forest classifier
  id: totrans-369
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 3 步 – 训练随机森林分类器
- en: 'Next, we will split our existing training set (the one used to train the model)
    into two:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将现有的训练集（用于训练模型的那个）分成两部分：
- en: '**Validation set**: This is a subset of the training dataset which is used
    to get a preliminary estimate of the effectiveness of the level of skillfulness
    attained by the model.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证集**：这是训练数据集的一个子集，用于获取模型达到的技能水平的初步估计。'
- en: '**Training set**: A training set is that percentage of dataset that the model
    learns from. This learning process is called training the model. Also because
    the model learns from this data, the data is said fit the model.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练集**：训练集是模型从中学习的那个数据集百分比。这个过程被称为训练模型。也因为模型从这些数据中学习，所以这些数据被称为拟合模型。'
- en: 'We can accomplish a split by creating an instance of the `TrainValidationSplit`
    algorithm:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过创建 `TrainValidationSplit` 算法的实例来完成分割：
- en: '[PRE42]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: On this variable, set a seed, set `EstimatorParamMaps,` set the `Estimator`
    with `bcwPipeline,` and finally set the training ratio to `0.8`.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个变量上设置种子，设置 `EstimatorParamMaps`，设置 `Estimator` 为 `bcwPipeline`，最后将训练比例设置为
    `0.8`。
- en: Finally, do a fit and transform with our training `Dataset` and testing `Dataset`.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用我们的训练 `Dataset` 和测试 `Dataset` 进行拟合和转换。
- en: Great! Now, the classifier is trained. In the next step, we will apply this
    classifier to the testing data.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！现在，分类器已经训练完成。在下一步中，我们将把这个分类器应用到测试数据上。
- en: Step 4 – applying the classifier to the test data
  id: totrans-378
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 4 步 – 将分类器应用于测试数据
- en: 'The purpose of our validation set is to be able to make a choice between models.
    We want an evaluation metric as well as hyperparameter tuning. Now, we will create
    an instance of a validation estimator called `TrainValidationSplit`, which will
    split the training set into a validation set and a training set as follows:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 我们验证集的目的是能够在模型之间做出选择。我们希望有一个评估指标以及超参数调整。现在，我们将创建一个名为 `TrainValidationSplit`
    的验证估计实例，该实例将训练集分割为验证集和训练集，如下所示：
- en: '[PRE43]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Next, we will fit this estimator over the training dataset to produce a model
    and a transformer that we will use to transform our testing dataset. Finally,
    we will perform validation for hyperparameter tuning by applying an evaluator
    for a metric.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将这个估计器拟合到训练数据集上，以生成一个模型和一个转换器，我们将使用它们来转换我们的测试数据集。最后，我们将通过应用一个用于指标的评估器来执行超参数调整的验证。
- en: 'The new `ValidatedTestResults DataFrame` should contain the following columns,
    including three newly generated columns—`rawPrediction`, `probability`, and `prediction`,
    and some additional ones:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 新的 `ValidatedTestResults DataFrame` 应包含以下列，包括三个新生成的列—`rawPrediction`、`probability`
    和 `prediction` 以及一些额外的列：
- en: '`bcw-features-column`'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bcw-features-column`'
- en: '`bcw-species-column`'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bcw-species-column`'
- en: '`label`'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`label`'
- en: '`rawPrediction`'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rawPrediction`'
- en: '`probability`'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`probability`'
- en: '`prediction`'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prediction`'
- en: 'Next, let''s generate a new dataset. Invoke the `select` method on the `validatedTestResults` dataset
    and pass the column expressions for `prediction` and `label` into it:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们生成一个新的数据集。在 `validatedTestResults` 数据集上调用 `select` 方法，并将 `prediction`
    和 `label` 的列表达式传递给它：
- en: '[PRE44]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: We will revisit these test results towards the close of this chapter, where
    we will be evaluating the classifier. At that point, we will explain how to interpret
    these results and how they tie into the main goal of this chapter predicting the
    class of a breast cancer mass diagnosis.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章末尾回顾这些测试结果，届时我们将评估分类器。到那时，我们将解释如何解释这些结果以及它们如何与本章的主要目标预测乳腺癌肿块诊断的分类联系起来。
- en: Step 5 – evaluating the classifier
  id: totrans-392
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 5 步 – 评估分类器
- en: 'In this section, we will evaluate the accuracy of the mode output results on
    the test result. Evaluation starts by creating an instance of `MulticlassEvaluator`:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将评估模型输出结果在测试结果上的准确性。评估从创建 `MulticlassEvaluator` 的实例开始：
- en: '[PRE45]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Now, on `MulticlassEvaluationEvaluator`, we set the following:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在 `MulticlassEvaluationEvaluator` 上，我们设置以下内容：
- en: The `"label"` column
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “label”列
- en: A metric name
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指标名称
- en: The prediction column `label`
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测列 `label`
- en: Next, we invoke the `evaluate` method with the `validatedTestResults` dataset.
    Note the accuracy of the model output results for the testing dataset from the
    `modelOutputAccuracy` variable. The other metric of note to evaluate is how close
    the predicted label value in the `predicted` column is to the actual label value
    in the (indexed) `"label"` column.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用 `validatedTestResults` 数据集调用 `evaluate` 方法。注意从 `modelOutputAccuracy`
    变量中获取测试数据集的模型输出结果的准确率。另一个值得评估的指标是预测列中预测的标签值与（索引的）“label”列中实际标签值之间的接近程度。
- en: 'Next, we want to extract the metrics:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们想要提取指标：
- en: '[PRE46]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '`MulticlassMetrics` includes two computed metrics that we extract by giving
    a reading of the `accuracy` and `weightedMetrics` variables.'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '`MulticlassMetrics` 包含两个通过读取 `accuracy` 和 `weightedMetrics` 变量计算出的指标。'
- en: Step 6 – running the pipeline as an SBT application
  id: totrans-403
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 6 步 – 将管道作为 SBT 应用程序运行
- en: 'At the root of your project folder, issue the `sbt console` command, and in
    the Scala shell, import the `bcwPipeline` object and then invoke the `main` method
    of `bcwPipeline` with the `bcw` argument:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的项目文件夹根目录下，运行 `sbt console` 命令，然后在 Scala shell 中导入 `bcwPipeline` 对象，然后使用 `bcw`
    参数调用 `bcwPipeline` 的 `main` 方法：
- en: '[PRE47]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The classifier reported on two metrics:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器报告了两个指标：
- en: Accuracy
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率
- en: Weighted precision
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加权精确率
- en: In the next section, we will package the application.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将打包应用程序。
- en: Step 7 – packaging the application
  id: totrans-410
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 7 步 – 打包应用程序
- en: 'In the root folder of your SBT application, we want to generate an Uber JAR.
    We will run the following command:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的 SBT 应用程序的根目录下，我们想要生成一个 Uber JAR。我们将运行以下命令：
- en: '[PRE48]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'This command generates an Uber JAR file, which can then be easily deployed
    into `[local]` in standalone deploy mode:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令生成一个 Uber JAR 文件，然后可以轻松地以独立部署模式部署到 `[本地]`：
- en: '![](img/d350f370-8839-476f-8510-b638736fe56f.jpg)'
  id: totrans-414
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d350f370-8839-476f-8510-b638736fe56f.jpg)'
- en: The application JAR file
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序 JAR 文件
- en: The pipeline JAR file is available under the target folder. In the next section,
    we will deploy the application into Spark.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 管道 JAR 文件位于目标文件夹下。在下一节中，我们将部署应用程序到 Spark。
- en: Step 8 – deploying the pipeline app into Spark local
  id: totrans-417
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 8 步 – 将管道应用程序部署到 Spark 本地
- en: 'At the root of the application folder, issue the `spark-submit` command with
    the class and JAR file path arguments, respectively. If everything went well,
    the application will do the following:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序文件夹根目录下，运行带有类和 JAR 文件路径参数的 `spark-submit` 命令。如果一切顺利，应用程序将执行以下操作：
- en: Load up the data.
  id: totrans-419
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据。
- en: Performs EDA.
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行 EDA。
- en: Create training, test, and validation datasets.
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练、测试和验证数据集。
- en: Create a Random Forest classifier model.
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个随机森林分类器模型。
- en: Train the model.
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型。
- en: Test the accuracy of the model, which is the most important part of the ML classification
    task.
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试模型的准确率，这是机器学习分类任务最重要的部分。
- en: 'To accomplish step 6, we apply our trained Random Forest classifier model to
    the test dataset, which is data that has not been seen by the model yet:'
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了完成第 6 步，我们将我们的训练好的随机森林分类器模型应用于测试数据集，这是模型尚未见过的数据：
- en: Unseen data could be likened to new data that the classifier needs to predict
    on
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未见数据可以类比为分类器需要预测的新数据。
- en: Our goal at the beginning of this was to classify the diagnosis of a breast
    cancer mass that is exemplified by specific features in the test dataset
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在开始时的目标是根据测试数据集中特定特征对乳腺癌肿块进行分类。
- en: Applying the model to the test dataset results in a prediction of the diagnosis.
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型应用于测试数据集会导致诊断预测。
- en: The pipeline runs an evaluation process, which is all about checking the model
    reports the correct diagnosis.
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 管道运行一个评估过程，这完全是检查模型是否报告了正确的诊断。
- en: Lastly, pipeline reports back on how important a certain feature of the breast
    cancer dataset turned out to be in relation to the others. As a matter of fact,
    it turns out that a certain feature is more important than others in carrying
    out the classification task.
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，管道会报告某个特征在乳腺癌数据集中相对于其他特征的重要性。事实上，某个特征在执行分类任务时比其他特征更重要。
- en: The preceding summary listing concludes the Random Forests section and brings
    us to the beginning of a brand new section on the topic of creating a logistic
    regression pipeline.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 上述总结列表结束了随机森林部分，并带我们来到了关于创建逻辑回归管道的新章节的开始。
- en: LR breast cancer pipeline
  id: totrans-432
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LR 乳腺癌管道
- en: 'Before getting down to the implementation of a logistic regression pipeline,
    refer back to the earlier table in section *Breast cancer dataset at a glance *where
    nine breast cancer tissue sample characteristics (features) are listed, along
    with one class column. To recap, those characteristics or features are listed
    as follows for context:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始实施逻辑回归管道之前，请参考第*乳腺癌数据集概览*部分中较早的表格，其中列出了九个乳腺癌组织样本特征（特征），以及一个类别列。为了回顾，以下特征或特征如下列出，以供参考：
- en: '**c****lump_thickness**'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**c****lump_thickness**'
- en: '**size_uniformity**'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**size_uniformity**'
- en: '**shape_uniformity**'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**shape_uniformity**'
- en: '**marginal_adhesion**'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**marginal_adhesion**'
- en: '**epithelial_size**'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**epithelial_size**'
- en: '**bare_nucleoli**'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**bare_nucleoli**'
- en: '**bland_chromatin**'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**bland_chromatin**'
- en: '**normal_nucleoli**'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**normal_nucleoli**'
- en: '**mitoses**'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**mitoses**'
- en: 'Now, let''s get down to a high-level formulation of the logistic regression
    approach in terms of what it is meant to achieve. The following diagram represents
    the elements of such a formulation at a high level:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们从逻辑回归方法的高级公式开始，说明其预期达到的目标。以下图表代表了这个公式的要素，从高级层面来看：
- en: '![](img/ba37e64b-0234-427d-bfa4-589093753c8a.png)'
  id: totrans-444
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ba37e64b-0234-427d-bfa4-589093753c8a.png)'
- en: Breast cancer classification formulation
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 乳腺癌分类公式
- en: 'The preceding diagram represents a high-level formulation of a logistic classifier
    pipeline that we are aware needs to be translated into an implementation in Spark
    and Scala. Here are a few helpful points to get you started:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表代表了一个逻辑分类器管道的高级公式，我们知道需要将其转换为Spark和Scala中的实现。以下是一些有助于您开始的有用提示：
- en: What are some interesting attributes that we can choose to come up with predictions?
    Attributes or features are like `if` statements and the predicted label is the
    answer. For example, if it looks like a fish, is 100 feet long, and is a mammal,
    it must be a whale. We must identify those `if` statements or attributes with
    the express purpose of making predictions. Of course, a prediction must classify
    a tissue sample as either malignant or benign.
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以选择哪些有趣的属性来进行预测？属性或特征就像`if`语句，预测的标签就是答案。例如，如果它看起来像鱼，长100英尺，而且是哺乳动物，那么它一定是一只鲸鱼。我们必须识别那些`if`语句或属性，目的是进行预测。当然，预测必须将组织样本分类为恶性或良性。
- en: Create a classifier model with LR.
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LR创建一个分类器模型。
- en: There is our class column in the breast cancer dataset, which represents the
    label. This column holds known (or predetermined) label values that `"label"`
    each feature measurement row with either malignant or benign.
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在乳腺癌数据集中，我们有我们的类别列，它代表标签。该列包含已知（或预先确定的）标签值，用“标签”将每个特征测量行标记为恶性或良性。
- en: Thus, the entire dataset, an experimental unit of known labels for known measurements,
    is said to be labeled either malignant or benign.
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，整个数据集，一个已知标签的已知测量的实验单元，被标记为恶性或良性。
- en: In the next section, we will lay out our implementation objectives, what our
    implementation goals will be, and how we plan on implementing them.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将阐述我们的实施目标，我们的实施目标将是什么，以及我们计划如何实施它们。
- en: Implementation objectives
  id: totrans-452
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施目标
- en: 'We will kickstart this section by listing the following implementation objectives:'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从这个部分开始，列出以下实施目标：
- en: '**Implementation objective 1**: Depicting what we believe are fundamental pipeline
    building blocks, rough workflow stages in the actual pipeline, and where each
    block is visualized as being connected to the next, implying flow of data and
    the transformation of data. A state of connection implies a set of workflow stages
    placed in a sequence.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实施目标1**：描绘我们认为的基本管道构建块，实际管道中的粗略工作流程阶段，以及每个块如何被可视化地连接到下一个块，这暗示了数据流和数据转换。连接状态意味着一系列工作流程阶段按顺序排列。'
- en: '**Implementation objective 2**: Core building blocks of the pipeline.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实施目标2**：管道的核心构建块。'
- en: '**Implementation objective 3**: Spark ML Workflow for the breast cancer classification
    task.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实施目标3**：乳腺癌分类任务的Spark ML工作流程。'
- en: '**Implementation objective 4**: Developing two pipeline stages and assigning
    an indexer and logit model to each of these stages.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实施目标4**：开发两个管道阶段，并将索引器和logit模型分配给每个阶段。'
- en: '**Implementation objective 5**: Evaluating the binary classifier''s performance.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实施目标5**：评估二元分类器的性能。'
- en: Next, we get on with implementation objectives 1 and 2.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们继续实施目标1和2。
- en: Implementation objectives 1 and 2
  id: totrans-460
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施目标1和2
- en: The following diagram depicts a **DataFrame** block that progresses through
    a transformation process into the **FeatureVector creation** block. A **Feature
    Vector** and an unindexed label (not shown in the following diagram for simplicity)
    make up a new (transformed) **DataFrame**. The **FeatureVector creation** block
    (or stage) is a precursor to **Classifier Model **creation. The last block is
    a **Prediction** stage where predictions are generated.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图展示了从**DataFrame**块通过转换过程进入**特征向量创建**块。一个**特征向量**和一个未索引的标签（为了简单起见，在下面的图中未显示）组成一个新的（转换后的）**DataFrame**。**特征向量创建**块（或阶段）是**分类模型**创建的前奏。最后一个块是**预测**阶段，其中生成预测。
- en: 'This is a succinct description of what is to be implemented in the code later:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对稍后代码中要实现的内容的简要描述：
- en: '![](img/c1d596f3-8a93-4aed-8902-3a1aae9420db.png)'
  id: totrans-463
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c1d596f3-8a93-4aed-8902-3a1aae9420db.png)'
- en: Core building blocks of the pipeline
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 管道的核心构建块
- en: 'The preceding diagram makes no mention of splitting the `DataFrame[Feature
    Vector and Label]` into two parts:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图没有提到将 `DataFrame[特征向量和标签]` 分成两部分：
- en: A training dataset
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据集
- en: A testing dataset, which is input data on which the model is fitted (trained)
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试数据集，这是模型拟合（训练）的输入数据
- en: These two datasets are represented by a **training** block and a **testing**
    block in the diagram in the next section instead. Implementation objectives 1
    and 2 were laid out in this section. Implementation objective 3 is laid out in
    the topic that follows.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 这些两个数据集在下一节的图中表示为**训练**块和**测试**块。实施目标 1 和 2 在本节中概述。实施目标 3 在接下来的主题中概述。
- en: Implementation objective 3 – Spark ML workflow for the breast cancer classification
    task
  id: totrans-469
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施目标 3 – Spark ML 工作流程用于乳腺癌分类任务
- en: We will start working on implementation objective 3\. This forms the basis for
    our logistic regression pipeline. This pipeline is divided into two functional
    areas—a training block depicted in the diagram as training, and a testing block
    depicted as testing.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将开始实施目标 3。这构成了我们逻辑回归管道的基础。这个管道分为两个功能区域——图中表示为训练的训练块，以及表示为测试的测试块。
- en: 'We filled out the **training** block with four pipeline stages, which are as
    follows:'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在**训练**块中填充了四个管道阶段，如下所示：
- en: '**Loading Data**'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加载数据**'
- en: '**Feature Extraction**'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征提取**'
- en: '**Model Fitting (Training)**'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型拟合（训练**）'
- en: '**Evaluation**'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估**'
- en: 'Likewise, the testing block has four stages of its own:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，测试块也有它自己的四个阶段：
- en: '**Loading Data**'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加载数据**'
- en: '**Feature Extraction**'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征提取**'
- en: '**Prediction**'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测**'
- en: '**Evaluation**'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估**'
- en: 'The two blocks don''t appear to be all that different. However, there is more
    to it than meets the eye. We will now lay out a new ML workflow diagram in terms
    of the training, testing, and Spark ML components, as follows:'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个块看起来并没有太大的不同。然而，其中还有更多。我们现在将根据训练、测试和 Spark ML 组件，展示一个新的机器学习工作流程图，如下所示：
- en: '![](img/b05ece70-273c-4948-b0be-4dc9a9f6dcad.png)'
  id: totrans-482
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b05ece70-273c-4948-b0be-4dc9a9f6dcad.png)'
- en: Spark ML workflow for the breast cancer classification task
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML 工作流程用于乳腺癌分类任务
- en: An arrow from the training block to the testing block indicates a data transformation
    workflow starting in the training block and proceeding into the testing block.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 从训练块到测试块的箭头表示从训练块开始的数据转换工作流程，并继续到测试块。
- en: Our preceding ML workflow diagram is a step forward. It is a precursor of sorts
    to the actual pipeline, whose implementation details will be laid out in *Implementation
    objective 4—coding steps for building the indexer and logit machine learning model *section.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前的机器学习工作流程图是一个进步。它是实际管道的某种前奏，其实施细节将在*实施目标 4—构建索引器和 logit 机器学习模型的编码步骤*部分中展开。
- en: 'At this point, we must note that the implementation critically depends on leveraging
    the following Spark ML API components:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们必须注意，实施关键依赖于利用以下 Spark ML API 组件：
- en: '**DataFrame**'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DataFrame**'
- en: '**Transformer**'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**转换器**'
- en: '**Estimator**'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**估计器**'
- en: '**Metrics Evaluator**'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**度量评估器**'
- en: Now, we have enough information to get to the next level that is *Implementation*
    *objective 4—coding steps for building the indexer and logit machine learning
    model* section where we will go through all the motions of building a two-stage
    pipeline.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了足够的信息进入下一个层次，即*实施目标 4—构建索引器和 logit 机器学习模型的编码步骤*部分，我们将逐步构建一个两阶段管道。
- en: Implementation objective 4 – coding steps for building the indexer and logit
    machine learning model
  id: totrans-492
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现目标 4 – 构建索引器和 logit 机器学习模型的编码步骤
- en: At the outset, fulfilling implementation objective 5 requires that we import
    the following. Create an empty Scala file in the following package and add the
    following imports in.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 在一开始，实现实现目标 5 需要导入以下内容。在以下包中创建一个空的 Scala 文件，并添加以下导入。
- en: 'After all the imports are in, create a new Scala object called `BreastCancerLrPipeline`
    and have this class extend from the `WisconsinWrapper` trait:'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有导入完成后，创建一个新的 Scala 对象 `BreastCancerLrPipeline`，并让这个类扩展 `WisconsinWrapper`
    特性：
- en: '[PRE49]'
  id: totrans-495
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The `WisconsinWrapper` trait contains code that creates a `SparkSession` for
    us. It also contains a method that takes in the dataset and creates a `DataFrame`
    from it. The imports also bring in the following, which is important for implementation
    tasks. For example, you will note that they are necessary for importing the Spark
    ML API for `LogisticRegression`, which is one of the algorithms used in binary
    classification. We needed APIs to compute binary classification metrics. That
    said, we will move on to the next task, where we talk more about our trait, `WisconsinWrapper`.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: '`WisconsinWrapper` 特性包含创建 `SparkSession` 的代码。它还包含一个接受数据集并从中创建 `DataFrame` 的方法。导入还带来了以下内容，这对于实现任务非常重要。例如，你会注意到它们对于导入
    Spark ML API 中的 `LogisticRegression` 是必要的，`LogisticRegression` 是二进制分类中使用的算法之一。我们需要计算二进制分类指标的
    API。因此，我们将继续进行下一个任务，我们将更多地讨论我们的特性 `WisconsinWrapper`。'
- en: Extending our pipeline object with the WisconsinWrapper trait
  id: totrans-497
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 WisconsinWrapper 特性扩展我们的管道对象
- en: '`WisconsionWrapper` contains a trait called `WisconsinWrapper`, which contains
    the following code components:'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '`WisconsionWrapper` 包含一个名为 `WisconsinWrapper` 的特性，其中包含以下代码组件：'
- en: A `SparkSession` called `lazy val`
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个名为 `lazy val` 的 `SparkSession`
- en: A `val` representing the path to the breast cancer dataset, `bcw.csv` (this
    file is available in the root of the project folder)
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个表示乳腺癌数据集路径的 `val`，`bcw.csv`（此文件位于项目文件夹的根目录下）
- en: A tuple holding string representations of columns for `"features"` and `"label"`
    in `DataFrame`, which we will create shortly
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含 `"features"` 和 `"label"` 列的字符串表示的元组，我们将很快创建它
- en: A method to build `DataFrame`. It takes in the fully qualified path to the dataset
    path with a method named `buildDataFrame()`
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个用于构建 `DataFrame` 的方法。它接受数据集路径的完整路径，并使用名为 `buildDataFrame()` 的方法
- en: 'The `Wrapper` trait is depicted as follows, and includes all four code components:'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: '`Wrapper` 特性如下所示，并包括所有四个代码组件：'
- en: '![](img/c98695e5-286d-43b8-8f5e-ee0be9ad2af2.jpg)'
  id: totrans-504
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c98695e5-286d-43b8-8f5e-ee0be9ad2af2.jpg)'
- en: WisconsinWrapper
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: WisconsinWrapper
- en: Readers may grab a copy of the `WisconsinWrapper` trait and paste this file
    into their SBT project. The SBT project is available under the `ModernScalaProjects_Code`
    folder.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 读者可以获取 `WisconsinWrapper` 特性的副本，并将其粘贴到他们的 SBT 项目中。SBT 项目位于 `ModernScalaProjects_Code`
    文件夹下。
- en: 'Now, create a declaration for `object BreastCancerLrPipeline` as follows:'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，创建一个名为 `object BreastCancerLrPipeline` 的声明，如下所示：
- en: '[PRE50]'
  id: totrans-508
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: We now have an empty `object` body, so we will add in an `import` for the `StringIndexer`.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个空的 `object` 主体，因此我们将添加一个 `import` 语句来导入 `StringIndexer`。
- en: Importing the StringIndexer algorithm and using it
  id: totrans-510
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导入 StringIndexer 算法并使用它
- en: 'We need the `StringIndexer` algorithm to index values in the `"label"` column.
    That is why `StringIndexer` is imported:'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要 `StringIndexer` 算法来索引 `"label"` 列中的值。这就是为什么需要导入 `StringIndexer` 的原因：
- en: '[PRE51]'
  id: totrans-512
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '`StringIndexer` is an algorithm that can take a list of hyperparameters. Two
    such parameters are set as follows:'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: '`StringIndexer` 是一个可以接受超参数列表的算法。以下设置了两个这样的参数：'
- en: '[PRE52]'
  id: totrans-514
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We have created an `indexer StringIndexer` algorithm instance. The next step
    will be to fit the model on a new generic `DataFrame` that we will build using
    the `buildDataFrame` method:'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经创建了一个 `indexer StringIndexer` 算法实例。下一步将是使用 `buildDataFrame` 方法在新的通用 `DataFrame`
    上拟合模型：
- en: '[PRE53]'
  id: totrans-516
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The resulting `StringIndexerModel` is transformed:'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的 `StringIndexerModel` 被转换：
- en: '[PRE54]'
  id: totrans-518
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The `show` method now displays the first `20` rows of the `DataFrame`:'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: '`show` 方法现在显示 `DataFrame` 的前 `20` 行：'
- en: '![](img/171ec8a6-1b46-42f3-8b6a-71398790669a.jpg)'
  id: totrans-520
  prefs: []
  type: TYPE_IMG
  zh: '![](img/171ec8a6-1b46-42f3-8b6a-71398790669a.jpg)'
- en: Result of the fit and transform of StringIndexer
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: StringIndexer 的 fit 和 transform 结果
- en: 'There is a reason for the `"features"` column to coexist with `"bcw-diagnoses-column"`.
    The `"features"` that are present in the feature vector are attributes that are
    closely tied to the diagnosis of a certain tissue sample. `"bcw-diagnoses-column"`
    represents the class column in the original dataset. This is a binary classification
    problem where the category cannot have a numerical measure, so we must artificially
    assign a value of either `0` or `1`. In this case, `2` and `4` are standing in
    for benign and malignant, respectively. The `"label"` column beside the `"features"`
    column bears two kinds of values:'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: '`"features"` 列与 `"bcw-diagnoses-column"` 并存是有原因的。存在于特征向量中的 `"features"` 是与特定组织样本的诊断紧密相关的属性。"`bcw-diagnoses-column`"
    代表原始数据集中的类别列。这是一个二元分类问题，其中类别不能有数值度量，因此我们必须人工分配 `0` 或 `1` 的值。在这种情况下，`2` 和 `4` 分别代表良性肿瘤和恶性肿瘤。位于
    `"features"` 列旁边的 `"label"` 列包含两种类型的值：'
- en: '`0.0`'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`0.0`'
- en: '`1.0`'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1.0`'
- en: The `StringIndexer` indexed values in the `"bcw-diagnoses-column"` from the
    original `DataFrame` are produced by the `buildDataFrame` method and are assigned
    values of `0.0` to `2.0` and `1.0` to `4.0`, respectively.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 从原始 `DataFrame` 的 `"bcw-diagnoses-column"` 中索引的值是由 `buildDataFrame` 方法产生的，分别分配了
    `0.0` 到 `2.0` 和 `1.0` 到 `4.0` 的值。
- en: Next, we will venture deeper into ML territory. As with any ML exercise, it
    is common to split a dataset into a training set and testing set. That is exactly
    what we will do in the next coding step.
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将深入探索机器学习（ML）领域。与任何机器学习练习一样，通常会将数据集分为训练集和测试集。这正是我们在下一个编码步骤中将要做的。
- en: Splitting the DataFrame into training and test datasets
  id: totrans-527
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 DataFrame 分割为训练集和测试集
- en: 'We will split our `DataFrame` in two:'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把我们的 `DataFrame` 分成两部分：
- en: Training set—75%
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练集—75%
- en: Testing set—25%
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试集—25%
- en: 'The training set is used to train (fit) the model, and the remaining 25% will
    be put to use for testing:'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集用于训练（拟合）模型，其余 25% 将用于测试：
- en: '[PRE55]'
  id: totrans-532
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: To verify that our split went well, we will run the `count` method on both the
    `trainDataFrame` and `testDataFrame` dataframes.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证我们的分割是否成功，我们将在 `trainDataFrame` 和 `testDataFrame` 数据帧上运行 `count` 方法。
- en: We will leave this as an exercise to the reader. Next, we will move on to creating
    a `LogisticRegression` classifier model and passing parameters into it.
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把这个作为练习留给读者。接下来，我们将继续创建一个 `LogisticRegression` 分类器模型并将其参数传递给它。
- en: Creating a LogisticRegression classifier and setting hyperparameters on it
  id: totrans-535
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 LogisticRegression 分类器并设置其超参数
- en: 'The `LogisticRegression` classifier can take hyperparameters, which we will
    set by using the appropriate setter methods from the `LogisticRegression` API.
    Since Spark ML has support for elastic net regularization, we will pass this as
    a parameter first. We also want two additional parameters:'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: '`LogisticRegression` 分类器可以接受超参数，我们将通过使用 `LogisticRegression` API 中的适当设置方法来设置这些超参数。由于
    Spark ML 支持弹性网络正则化，我们将首先传递此参数。我们还想添加两个额外的参数：'
- en: The `"features"` column
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"features"` 列'
- en: An indexed `"label"` column
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索引的 `"label"` 列
- en: '[PRE56]'
  id: totrans-539
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: What we just did was start the training process by creating an LR classifier
    model. We are now in a position to train our LR model on the training dataset
    by making an association between input feature measurements and their labeled
    output. To recap, we passed in a `"features"` column, a `"label"` column, and
    an elastic net coefficient.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚才所做的是通过创建一个 LR 分类器模型来启动训练过程。我们现在处于一个位置，可以通过将输入特征测量与它们的标记输出关联起来，在训练数据集上训练我们的
    LR 模型。为了回顾，我们传递了一个 `"features"` 列，一个 `"label"` 列和一个弹性网络系数。
- en: Next, we will execute our model with a transformation operation and testing
    dataset data.
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过转换操作和测试数据集数据执行我们的模型。
- en: Running the LR model on the test dataset
  id: totrans-542
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在测试数据集上运行 LR 模型
- en: 'We will now invoke the `transform` method on our `LogisticRegression` model:'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将对 `LogisticRegression` 模型调用 `transform` 方法：
- en: '[PRE57]'
  id: totrans-544
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The `transform` method invocation returns a new `DataFrame`. Not only that,
    that model transformation step resulted in three new columns:'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: '`transform` 方法调用返回一个新的 `DataFrame`。不仅如此，那个模型转换步骤还产生了三个新列：'
- en: '`rawPrediction`'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rawPrediction`'
- en: '`probability`'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`probability`'
- en: '`predictions`'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predictions`'
- en: 'Next, we will display the first `25` rows of this `DataFrame`:'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将显示这个 `DataFrame` 的前 `25` 行：
- en: '[PRE58]'
  id: totrans-550
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'See the following table to look at the displayed predictions, which were made
    by running our LR models on the test dataset:'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅以下表格，查看由我们在测试数据集上运行的 LR 模型生成的预测结果：
- en: '![](img/6fe43848-6883-416c-88bc-75e88bf3558f.jpg)'
  id: totrans-552
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6fe43848-6883-416c-88bc-75e88bf3558f.jpg)'
- en: Three new columns resulting from model transformation
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 模型转换产生的三个新列
- en: Spark's pipeline API provides us with the necessary tools to help us build a
    pipeline. A pipeline is a workflow and consists of a sequence of stages that we
    call pipeline stages. As we shall see later, each of these stages is executed
    in order.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 的管道 API 为我们提供了必要的工具，帮助我们构建管道。一个管道是一个工作流程，由一系列我们称之为管道阶段的阶段组成。正如我们稍后将看到的，这些阶段是按顺序执行的。
- en: 'That being said, we will now get on with the next order of business—creating
    a data pipeline with the following stages:'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，我们现在将继续进行下一项业务——创建一个包含以下阶段的 数据管道：
- en: A logit model
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个对数模型
- en: An indexer
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个索引器
- en: Building a breast cancer pipeline with two stages
  id: totrans-558
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用两个阶段构建乳腺癌管道
- en: 'Create the pipeline and add two stages to it as follows:'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 创建管道并添加两个阶段，如下所示：
- en: '[PRE59]'
  id: totrans-560
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Next, let''s do something with our pipeline. We can do the following things
    right away:'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们对我们的管道做一些事情。我们可以立即做以下事情：
- en: Train the pipeline with the training dataset
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用训练数据集训练管道
- en: 'Run a `transform` operation with the test set data on our derived `pipelineModel`:'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在我们的 `pipelineModel` 上对测试集数据进行 `transform` 操作：
- en: '[PRE60]'
  id: totrans-564
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Next, we will make predictions by running a `transform` operation on the `pipelineModel`
    with the testing dataset:'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过在 `pipelineModel` 上对测试数据集运行 `transform` 操作来进行预测：
- en: '[PRE61]'
  id: totrans-566
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The next step focuses on obtaining quantifiable measures. These are key performance
    indicators, metrics that with facts and figures assess how each one of our algorithms
    fared. How do they stack up with respect to one another? What graphical evaluation
    tools are available that help us assess the performance of a certain algorithm
    contributing to a particular binary classification? To understand what it takes
    to perform this evaluation, we might want to ask the following question first:
    how close is the predicted value of a certain breast cancer sample to a predetermined
    label?'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步的重点是获得可衡量的指标。这些是关键性能指标，是那些通过事实和数字评估我们每个算法表现如何的指标。它们彼此之间是如何排列的？有什么图形评估工具可以帮助我们评估对特定二分类有贡献的算法的性能？为了了解进行这种评估需要什么，我们可能首先想问以下问题：某个乳腺癌样本的预测值与预先设定的标签有多接近？
- en: Implementation objective 5 – evaluating the binary classifier's performance
  id: totrans-568
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施目标 5 – 评估二分类器的性能
- en: 'This section is all about obtaining evaluations, metrics, and supporting Spark
    ML APIs. In this section, we will go into depth on the importance of the evaluation
    step regarding quantifiable measures of effectiveness, as follows:'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 本节全部关于获取评估、指标和支持 Spark ML API。在本节中，我们将深入探讨评估步骤在衡量有效性可量化指标方面的重要性，如下所述：
- en: Our breast cancer classification task is a supervised learning classification
    problem. In such a problem, there's a so-called **true output**, and a classifier
    or ML model generated prediction output for each individual feature measurement
    or data point in our breast cancer dataset.
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的乳腺癌分类任务是一个监督学习分类问题。在这种问题中，有一个所谓的**真实输出**，以及一个分类器或机器学习模型为我们的乳腺癌数据集中的每个特征测量或数据点生成的预测输出。
- en: 'We have now turned our attention to evaluating the performance of our binary
    classification algorithm by deriving certain metrics. That said, the question
    is this: is pure accuracy enough to gauge the correctness of our classifier''s
    evaluation effort? Here, pure accuracy is trying to simply tell whether the prediction
    was correct or not. Okay, what is a better method? We can employ a binary classification
    evaluator to evaluate the correctness and hence have a measure of the performance
    regarding this kind of accuracy.'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们现在将注意力转向通过推导某些指标来评估我们的二分类算法的性能。那么，问题是这样的：纯准确率是否足够来衡量我们分类器评估努力的正确性？在这里，纯准确率试图简单地告诉预测是否正确。好吧，有什么更好的方法？我们可以使用二分类评估器来评估正确性，从而对这种准确性的性能有一个衡量标准。
- en: 'Circling back to the same topic of pure accuracy, the question to ask again
    is this: is this a good enough metric? It turns out that pure accuracy is not
    a great metric, because it does not take into account the type of error.'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回到纯准确性的同一主题，再次需要问的问题是：这是一个足够好的指标吗？结果证明，纯准确率不是一个很好的指标，因为它没有考虑到错误类型。
- en: For the aforementioned reason, we will derive better metrics, such as the **area
    under ROC curve** (**AUC**) and the **area under the precision recall curve**
    (**AUPCR**). We will employ Spark's `BinaryClassificationMetrics` to compute such
    metrics for us.
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于上述原因，我们将派生更好的指标，例如**ROC曲线下面积**（**AUC**）和**精确率召回率曲线下面积**（**AUPCR**）。我们将使用Spark的`BinaryClassificationMetrics`来计算这些指标。
- en: 'Next, we will get on with the implementation part of the metric derivation
    process. First, we will create a `BinaryClassificationEvaluator`. We will reiterate
    this evaluator and evaluate predictions with a kind of metric or score that we
    will call pure accuracy:'
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将继续实施指标派生过程的实现部分。首先，我们将创建一个`BinaryClassificationEvaluator`。我们将重复使用这个评估器，并使用一种我们称之为纯准确度的指标或分数来评估预测：
- en: '[PRE62]'
  id: totrans-575
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'We just computed a so-called pure accuracy score that we called `modelOutputAccuracy`
    in the preceding line of code. As an exercise, readers are invited to determine
    their pure accuracy score. The question they could pose is this: is this score
    useful? Is it a naive score?'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚计算了一个所谓的纯准确度分数，我们在上一行代码中将其称为`modelOutputAccuracy`。作为练习，读者被邀请确定他们的纯准确度分数。他们可能提出的问题是：这个分数有用吗？这是一个天真型的分数吗？
- en: 'With that accomplished, we will now turn our attention to the next task at
    hand, deriving a new dataframe by running a `select` operation on our predictions
    `DataFrame`:'
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 完成上述任务后，我们现在将注意力转向下一个任务，通过在我们的预测`DataFrame`上运行`select`操作来派生一个新的`DataFrame`：
- en: '[PRE63]'
  id: totrans-578
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'We are not done yet. We will convert our `"predictions"` and `"label" DataFrame`
    that we derived in the preceding code to an `RDD[Double, Double]`:'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有完成。我们将把在前面的代码中派生的`"predictions"`和`"label" DataFrame`转换为`RDD[Double, Double]`：
- en: '[PRE64]'
  id: totrans-580
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The RDD is now at hand. But why are we doing this? The answer is this: we talked
    about deriving better, meaningful, and not naive metric scores. We will now create
    a `BinaryClassificationMetrics` instance that we will call `classifierMetrics`:'
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 现在`RDD`已经准备好了。但我们为什么要这样做呢？答案是：我们讨论了派生更好、有意义且非天真型的指标分数。现在我们将创建一个名为`classifierMetrics`的`BinaryClassificationMetrics`实例：
- en: '[PRE65]'
  id: totrans-582
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '`BinaryClassificationMetrics` provides us with tools to derive meaningful evaluation
    metrics for our breast cancer binary classification task. At its core, binary
    classification is an ML approach to classifying new, unclassified, incoming data
    under either of two mutually exclusive categories. For example, our classifier
    classified a breast cancer sample as either benign or malignant, but not both,
    of course. More specifically, the breast cancer binary classifier pipeline predicted
    the probability of a target breast cancer sample belonging to one of two outcomes,
    either benign or malignant. This looks like a straightforward yes or no-type prediction.'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: '`BinaryClassificationMetrics`为我们提供了工具，以派生对我们乳腺癌二分类任务有意义的评估指标。在核心上，二分类是一种机器学习方法，用于将新的、未分类的、即将到来的数据分类到两个互斥的类别之一。例如，我们的分类器将乳腺癌样本分类为良性或恶性，但当然不是两者都是。更具体地说，乳腺癌二分类器管道预测目标乳腺癌样本属于两种结果之一，即良性或恶性。这看起来像是一种简单的是或否型预测。'
- en: Sure, our model performed and did the heavy lifting. However, we want to put
    its performance to the test. To do that, we need numeric metrics that, if properly
    thought through and computed, will tell us the model's performance story in ways
    that are meaningful.
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们的模型已经表现良好并完成了繁重的工作。然而，我们想要对其性能进行测试。为了做到这一点，我们需要数值指标，如果经过适当的思考和计算，这些指标将告诉我们模型的表现故事，并以有意义的方式呈现。
- en: 'What are those measures and when do they assume relevance? When an experimental
    analysis unit is balanced—the number of breast cancer samples like our breast
    cancer dataset—the following measures assume relevance:'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标是什么，它们在何时具有相关性？当一个实验分析单元平衡时——类似于我们的乳腺癌数据集的乳腺癌样本数量——以下指标将具有相关性：
- en: '**True Positive Rate** (**TPR**): This is a ratio of the **true positives**
    (abbreviated as **TPs**) in the predicted output to the **false negatives** (abbreviated
    as **FNs**). Mathematically, it is represented as follows: *TPR* = *TPs* / (*TPs*
    + *FNs*). TPR is known by the terms **Hit Rate**, **Recall**, or **Sensitivity**.'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真正例率**（**TPR**）：这是预测输出中**真正例**（简称为**TPs**）与**假阴性**（简称为**FNs**）的比率。数学上，它表示如下：*TPR*
    = *TPs* / (*TPs* + *FNs*）。TPR也被称为**命中率**、**召回率**或**灵敏度**。'
- en: '**False Positive Rate** (**FPR**): Mathematically, it is represented as *FPR*
    = *1* - (*TNs */ (*TNs *+ *FPs*), where **TNs** is a stand-in for **true negatives**
    and **FPs**, which is a stand-in for **false positives**.'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性率**(**FPR**)：数学上表示为*FPR* = *1* - (*TNs / (*TNs + *FPs*))，其中**TNs**代表**真阴性**，**FPs**代表**假阳性**。'
- en: 'Before we proceed any further, some explanations are in order for TPs, TNs,
    FNs, and FPs:'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在我们进一步进行之前，有必要对TPs、TNs、FNs和FPs进行一些解释：
- en: True positives point to those predictions that turn out to be truly malignant
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真阳性指的是那些最终证明为真正恶性的预测
- en: True negatives point to those predictions that turn out to be truly benign
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真阴性指的是那些最终证明为真正良性的预测
- en: False negatives point to those breast cancer samples that were wrongly labeled
    benign
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阴性指的是那些被错误标记为良性的乳腺癌样本
- en: False positives point to those breast cancer samples that were wrongly labeled
    malignant
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阳性指的是那些被错误标记为恶性的乳腺癌样本
- en: '**Receiver Operating Characteristic** (**ROC**) **curve**:The area under this
    curve is a measure of binary classification performance. This curve is a graphical
    plot of FPR on the *x* axis and TPR on the *y* axis. A typical plot is shown later.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**接收者操作特征**(**ROC**)曲线：此曲线下的面积是二分类性能的衡量指标。这是一个以*x*轴上的FPR和*y*轴上的TPR为图形的绘制。典型的曲线将在后面展示。'
- en: '**The area under the ****Precision-Recall (PR) curve**: This is a graphical
    plot of precision on the *y* axis and accuracy on the *x* axis. To plot the curve,
    we need computed (precision value, accuracy value) pairs. To compute these values,
    the following mathematical equations for accuracy and precision are applied as
    follows: Precision = *TPs* / (*TPs* + *FPs*); Accuracy = *TPs* / (*TPs* +*FNs*).
    The ROC curve is shown later, followed by the PR curve.'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Precision-Recall (PR)曲线下的面积**：这是以*y*轴上的精确率和*x*轴上的准确率为图形的绘制。为了绘制曲线，我们需要计算(precision
    value, accuracy value)对。为了计算这些值，应用以下数学方程式：精确率 = *TPs* / (*TPs* + *FPs*)；准确率 =
    *TPs* / (*TPs* + *FNs*)。ROC曲线将在后面展示，随后是PR曲线。'
- en: 'Both the ROC and PR curves represent binary classifier performance. How so?
    The area under the ROC curve becomes a measure of the binary classifier''s performance.
    If a curve plotted for a particular algorithm snakes higher up to the top-right
    reading from left to right (the greater area under it), it has a lower **false
    positive rate**, making it a better classifier than a curve for a different algorithm
    that has a higher **false positive rate**. This is useful, though not necessarily
    the best metric. A typical ROC curve is shown as follows:'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: ROC和PR曲线都代表二分类器的性能。为什么会这样？ROC曲线下的面积成为二分类器性能的衡量指标。如果一个特定算法的曲线从左到右向上弯曲更高（其下的面积更大），那么它具有更低的**假阳性率**，使其比具有更高**假阳性率**的另一个算法的曲线更好。这很有用，尽管不一定是最优指标。典型的ROC曲线如下所示：
- en: '![](img/12467032-121d-4dad-a2ae-233d01346a05.png)'
  id: totrans-596
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/12467032-121d-4dad-a2ae-233d01346a05.png)'
- en: A typical ROC curve
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的ROC曲线
- en: The next metric that is worth mentioning is the so-called precision-recall curve
    or PR curve for short. This curve involves the computation of two separate metrics,
    precision and recall.
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的下一个指标是所谓的精确率-召回率曲线，或简称PR曲线。此曲线涉及计算两个独立的指标，精确率和召回率。
- en: A PR curve is plotted with accuracy on the *x* axis and precision on the *y*
    axis. In this case, a particular algorithm fared better than others in its binary
    classification task if its curve snaked higher up towards the top-right. There
    are more TPs and considerably fewer FNs. This indicates a better classification.
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: PR曲线以准确率作为*x*轴，精确率作为*y*轴进行绘制。在这种情况下，如果一个特定算法的曲线向上弯曲更高，靠近右上角，那么它在二分类任务中的表现比其他算法更好。TPs更多，FNs相对较少。这表明分类效果更好。
- en: This completes our discussion on binary classifier metrics, and their computation
    marks an important milestone regarding the breast cancer data analysis initiative.
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了我们对二分类器指标及其计算的讨论，它们的计算标志着乳腺癌数据分析计划的一个重要里程碑。
- en: 'Indeed, if the logit model we built performed well, the area under the ROC
    discriminant curve should represent a meaningful measure of prediction performance:'
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，如果我们构建的对数模型表现良好，ROC判别曲线下的面积应该代表预测性能的有意义度量：
- en: '[PRE66]'
  id: totrans-602
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The metrics are ready. Here are the results. Running the pipeline should generate
    the following metrics:'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: 指标已准备好。以下是结果。运行管道应生成以下指标：
- en: '[PRE67]'
  id: totrans-604
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: That concludes our breast cancer classification task. In the previous section,
    on a Random Forests breast cancer pipeline, we showed you how to deploy your pipeline
    application into Spark. Likewise, in a similar fashion, we can deploy our logistic
    regression pipeline.
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们的乳腺癌分类任务。在上一个部分，关于随机森林乳腺癌管道，我们向您展示了如何将您的管道应用程序部署到Spark中。同样，以类似的方式，我们也可以部署我们的逻辑回归管道。
- en: Summary
  id: totrans-606
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned how to implement a binary classification task using
    two approaches such as, an ML pipeline using the Random Forest algorithm and an
    secondly using the logistic regression method.
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用两种方法实现二元分类任务，例如，使用随机森林算法的机器学习管道，其次是使用逻辑回归方法。
- en: Both pipelines combined several stages of data analysis into one workflow. In
    both pipelines, we calculated metrics to give us an estimate of how well our classifier
    performed. Early on in our data analysis task, we introduced a data preprocessing
    step to get rid of rows that were missing attribute values that were filled in
    by a placeholder, `?`. With 16 rows of unavailable attribute values eliminated
    and 683 rows with attribute values still available, we constructed a new `DataFrame`.
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个管道将数据分析的几个阶段合并到一个工作流程中。在这两个管道中，我们计算了指标，以估计我们的分类器表现得多好。在数据分析任务早期，我们引入了一个数据预处理步骤，以去除那些由占位符`?`填充的缺失属性值的行。通过消除16行不可用的属性值和683行仍有可用属性值的行，我们构建了一个新的`DataFrame`。
- en: In each pipeline, we also created training, training, and validation datasets,
    followed by a training phase where we fit the models on training data. As with
    every ML task, the classifier may learn by rotating the training set details,
    a preponderant phenomenon called overfitting. We got around this problem by arriving
    at a reduced but optimal number of attributes. We did this by fitting our classifier
    models with various combinations of attributes.
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个管道中，我们还创建了训练、训练和验证数据集，然后是训练阶段，其中我们在训练数据上拟合模型。与每个ML任务一样，分类器可能会通过旋转训练集细节来学习，这是一种称为过拟合的普遍现象。我们通过达到一个减少但最优的属性数量来解决这个问题。我们通过用各种属性组合拟合我们的分类器模型来实现这一点。
- en: In the next chapter, we will move our development efforts away from a local
    `spark-shell`. This time, we will take advantage of a Zeppelin Notebook running
    inside a **Hortonworks Development Platform** (**HDP**) Sandbox Virtual Machine.
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将把我们的开发工作从本地的`spark-shell`转移到其他地方。这次，我们将利用运行在**Hortonworks开发平台**（**HDP**）沙盒虚拟机内的Zeppelin
    Notebook。
- en: To conclude this chapter, we will move on to the last section where we pose
    a set of questions to the reader.
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 为了结束本章，我们将进入最后一节，在那里我们将向读者提出一系列问题。
- en: Questions
  id: totrans-612
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'We will now list a set of questions to test your knowledge of what you have
    learned so far:'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将列出一系列问题，以测试你对所学知识的掌握程度：
- en: What do you understand by logistical regression? Why is it important?
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你如何理解逻辑回归？为什么它很重要？
- en: How does logistical regression differ from linear regression?
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归与线性回归有何不同？
- en: Name one powerful feature of `BinaryClassifier`.
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出`BinaryClassifier`的一个强大功能。
- en: What are the feature variables in relation to the breast cancer dataset?
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与乳腺癌数据集相关的特征变量是什么？
- en: The breast cancer dataset problem is a classification task that can be approached
    with other machine learning algorithms as well. Prominent among other techniques
    are **Support Vector Machine** (**SVM**), **k-nearest neighbor**, and **decision
    trees**. When you run the pipelines developed in this chapter, compare the time
    it took to build a model in each case and how many of the input rows of the dataset
    were classified correctly by each algorithm.
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: 乳腺癌数据集问题是一个可以通过其他机器学习算法来处理的分类任务。其中，最突出的技术包括**支持向量机**（**SVM**）、**k-最近邻**和**决策树**。当你运行本章开发的管道时，比较每种情况下构建模型所需的时间和每个算法正确分类的数据集输入行数。
- en: This concludes this chapter. The next chapter implements a new kind of pipeline,
    which is a stock prediction task pipeline. We shall see how we can use Spark to
    work on larger datasets. Stock price prediction is not an easy problem to solve.
    How we shall tackle this is the subject of the next chapter.
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了本章。下一章将实现一种新的管道，即股票预测任务管道。我们将看到如何使用Spark处理更大的数据集。股票价格预测不是一个容易解决的问题。我们将如何应对，这是下一章的主题。
