- en: Chapter 7. Architecting for Performance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章. 为性能而架构
- en: 'We have come a long way in our exploration of Scala and various techniques
    to write performant code. In this final chapter, we look at more open-ended topics.
    The final topics are largely applicable beyond Scala and the JVM. We dive into
    various tools and practices to improve the architecture and the design of an application.
    In this chapter, we explore the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索Scala和各种编写高性能代码的技术方面，我们已经取得了长足的进步。在本章的最后，我们探讨了一些更开放的话题。最后的话题在很大程度上适用于Scala和JVM之外。我们深入研究了各种工具和实践，以提高应用程序的架构和设计。在本章中，我们探讨了以下主题：
- en: Conflict-free replicated data types (CRDTs)
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无冲突复制数据类型（CRDTs）
- en: Throughput and latency impact of queueing
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 队列的吞吐量和延迟影响
- en: The Free monad
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Free monad
- en: Distributed automated traders
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式自动化交易员
- en: 'Thanks to our hard work, MVT is thriving. The sales department is signing contracts
    like there is no tomorrow, and the sales bell is ringing from sunrise to sunset.
    The order book is able to handle more orders, and as a result of the increase
    in traffic, another product offered by MVT is incurring performance issues: the
    automated trading system. The automated trader receives orders from the order
    book and applies various trading strategies in real time to automatically place
    orders on behalf of the customers. As the order book is processing an order of
    magnitude of more trade orders, the automated trading system is unable to keep
    up, and, therefore, cannot efficiently apply its strategies. Several big customers
    recently lost a lot of money due to bad decisions made by the algorithm and the
    high latency of execution. The engineering team needs to solve this performance
    issue. Alice, your technical lead, has tasked you with finding a solution and
    preventing the company from losing newly-acquired customers.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了我们的辛勤工作，MVT正在蓬勃发展。销售部门正在签订合同，仿佛明天就是世界末日，销售铃声从日出响到日落。订单簿能够处理更多的订单，由于流量的增加，MVT提供的另一产品出现了性能问题：自动化交易系统。自动化交易员从订单簿接收订单，并实时应用各种交易策略，代表客户自动下单。由于订单簿正在处理数量级的交易订单，自动化交易系统无法跟上，因此无法有效地应用其策略。最近，一些大客户由于算法决策失误和执行延迟高而损失了大量资金。工程团队需要解决这个性能问题。你的技术负责人Alice要求你找到解决方案，防止公司失去新获得的客户。
- en: In the previous chapter, we studied and took advantage of concurrency. We learned
    how to design code to leverage the power of multicore hardware. The automated
    trader is already optimized to run concurrent code and utilize all the CPU resources
    on the machine. The truth is, there is only so much one machine can handle, even
    with several cores. To scale the system and keep up with the traffic coming from
    the order book, we will have to start implementing a distributed system.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们研究了并发，并利用了并发。我们学习了如何设计代码以利用多核硬件的强大功能。自动化交易器已经优化以运行并发代码并利用机器上的所有CPU资源。事实是，即使是几个核心，一台机器也只能处理这么多。为了扩展系统并跟上订单簿带来的流量，我们不得不开始实施分布式系统。
- en: A glimpse into distributed architectures
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式架构的概览
- en: Distributed computing is a rich topic, and we cannot pretend to address it entirely
    in a single chapter. This short section gives a brief and incomplete description
    of distributed computing. We will try to give you an overview of the paradigm
    and point to some of the main benefits and challenges of distributed systems.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式计算是一个丰富的主题，我们无法假装在一章中完全解决它。本节提供了一个简短且不完整的分布式计算描述。我们将尝试为您概述这个范式，并指出分布式系统的一些主要优势和挑战。
- en: The idea behind distributed computing is to design a system involving several
    components, which runs on different machines and communicates with each other
    (for example, over a network) to achieve a task or provide a service. A distributed
    system can involve components of different natures, each component providing a
    specific service and participating in the realization of the task. For example,
    a web server can be deployed to receive HTTP requests. To service a request, the
    web server may communicate over the network to query an authentication service
    to validate credentials and a database server in order to store and retrieve data
    and complete the request. Together, the web server, the authentication service,
    and the database form a distributed system.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式计算背后的理念是设计一个涉及多个组件的系统，这些组件运行在不同的机器上，并通过彼此（例如，通过网络）进行通信以完成一个任务或提供一项服务。分布式系统可以涉及不同性质的组件，每个组件提供特定的服务并参与任务的实现。例如，可以将Web服务器部署来接收HTTP请求。为了处理请求，Web服务器可能通过网络查询认证服务以验证凭证，并查询数据库服务器以存储和检索数据并完成请求。Web服务器、认证服务和数据库共同构成了一个分布式系统。
- en: A distributed system can also involve several instances of the same component.
    These instances form a cluster of nodes, and they can be used to divide the work
    among them. This topology allows a system to scale out and support a higher load
    by adding more instances to the cluster. As an example, if a web server is able
    to handle 20,000 requests per second, it may be possible to run a cluster of three
    identical servers to handle 60,000 requests per second (assuming that your architecture
    allows your application to scale linearly). Distributed clusters also help achieve
    high availability. If one of the nodes crashes, the others are still up and able
    to fulfill requests while the crashed instance is restarted or recovers. As there
    is no single-point of failure, there is no interruption of service.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统也可能涉及相同组件的多个实例。这些实例形成一个节点集群，并且可以用来在他们之间分配工作。这种拓扑结构允许系统通过向集群添加更多实例来扩展并支持更高的负载。例如，如果一个Web服务器能够每秒处理20,000个请求，那么可能可以通过运行三个相同的Web服务器集群来处理每秒60,000个请求（假设您的架构允许您的应用程序线性扩展）。分布式集群还有助于实现高可用性。如果一个节点崩溃，其他节点仍然可以运行并能够满足请求，同时崩溃的实例正在重新启动或恢复。因为没有单点故障，所以没有服务中断。
- en: For all their benefits, distributed systems come with their drawbacks and challenges.
    The communication between components is subject to failure and network disruptions.
    The application needs to implement a retry mechanism and error handling, and then
    deal with lost messages. Another challenge is managing shared state. For example,
    if all the nodes use a single database server to save and retrieve information,
    the database has to implement some form of a locking mechanism to ensure that
    concurrent modifications do not collide. It is also possible that once the cluster
    node count grows sufficiently large, the database will not be able to serve them
    all efficiently and will become a bottleneck.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管分布式系统带来了诸多好处，但也伴随着其自身的缺点和挑战。组件之间的通信可能会出现故障和网络中断。应用程序需要实现重试机制和错误处理，并处理丢失的消息。另一个挑战是管理共享状态。例如，如果所有节点都使用单个数据库服务器来保存和检索信息，数据库必须实现某种形式的锁定机制来确保并发修改不会冲突。一旦集群节点数量足够大，数据库可能无法高效地为他们提供服务，并可能成为瓶颈。
- en: Now that you have been briefly introduced to distributed systems, we will go
    back to MVT. The team has decided to turn the automated trader into a distributed
    application to be able to scale the platform. You have been tasked with the design
    of the system. Time to go to the whiteboard.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经简要了解了分布式系统，我们将回到MVT。团队决定将自动化交易转变为分布式应用程序，以便能够扩展平台。您被分配了设计系统的任务。是时候去白板前了。
- en: The first attempt at a distributed automated trader
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 首次尝试分布式自动化交易
- en: 'Your first strategy is simple. You plan to deploy several instances of the
    automated trader to form a cluster of nodes. These nodes can share the work and
    handle each part of the incoming orders. A load balancer in front of the cluster
    can distribute the load evenly among the nodes. This new architecture helps scale
    out the automated trader. However, you are facing a common problem with distributed
    systems: the nodes have to share a common state to operate. To understand this
    requirement, we explore one of the features of the automated trader. To be able
    to use MVT''s automated trading system, customers have to open an account with
    MVT and provision it with enough money to cover their trades. This is used as
    a safety net by MVT to execute orders on behalf of its clients without running
    the risk of a customer being unable to honor their transactions. To ensure that
    the automated strategies do not overspend, the automated trader keeps track of
    the current balance of each customer and checks the balance of a customer before
    placing an automated order on their behalf.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您的第一个策略很简单。您计划部署几个自动化交易员的实例以形成一个节点集群。这些节点可以共享工作并处理进入订单的每个部分。集群前面的负载均衡器可以在节点之间均匀分配负载。这种新的架构有助于扩展自动化交易。然而，您面临着分布式系统的一个常见问题：节点必须共享一个公共状态才能运行。为了理解这个要求，我们探索自动化交易的一个功能。为了能够使用MVT的自动化交易系统，客户必须向MVT开设账户并为其提供足够的资金以覆盖他们的交易。这是MVT作为安全网执行其客户订单的一种方式，以免客户无法履行其交易的风险。为了确保自动化策略不会过度消费，自动化交易员跟踪每个客户的当前余额并在代表他们下单之前检查客户的余额。
- en: Your plan consists of deploying several instances of the automated trading system.
    Each instance receives a portion of the orders processed by the order book, runs
    a strategy and places matching order on behalf of a customer. Now that the system
    consists of several identical instances running in parallel, each instance can
    place orders on behalf of the same customer. To be able to perform the balance
    validation, they all need to be aware of the current balance of all customers.
    Customer balances become a shared state that has to be synchronized in the cluster.
    To solve this problem, you envision a balance monitor server deployed as an independent
    component and holding the state of each customer's balance. When a trade order
    is received by a node of the automated trading cluster, the node interrogates
    the balance monitor server to verify that a customer's account has enough funds
    to place an automated trade. Similarly, when a trade is executed, a node instructs the
    balance monitor server to update the balance of the customer.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 您的计划包括部署几个自动化交易系统的实例。每个实例接收订单簿处理的部分订单，运行策略并代表客户下单。现在系统由几个并行运行的相同实例组成，每个实例都可以代表同一客户下单。为了能够执行余额验证，它们都需要知道所有客户的当前余额。客户余额成为一个需要在集群中同步的共享状态。为了解决这个问题，您设想部署一个作为独立组件的余额监控服务器，并持有每个客户余额的状态。当一个交易订单被自动化交易集群的节点接收时，该节点会查询余额监控服务器以验证客户的账户是否有足够的资金进行自动化交易。同样，当交易执行时，一个节点会指示余额监控服务器更新客户的余额。
- en: '![The first attempt at a distributed automated trader](img/image_07_001.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![分布式自动化交易员的第一尝试](img/image_07_001.jpg)'
- en: The preceding diagram describes various interactions between the components
    of your architecture. **Automated Trader 1** receives an incoming trade and queries
    the balance monitor server to check whether the client has enough funds to perform
    a trade. The balance monitor server either authorizes or rejects the order. At
    the same time, **Automated Trader 3** sends an order that was previously approved
    by the balance monitor server and updates the client's balance.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图描述了您架构组件之间的各种交互。**自动化交易员1**接收一个进入的交易并查询余额监控服务器以检查客户端是否有足够的资金进行交易。余额监控服务器要么授权要么拒绝订单。同时，**自动化交易员3**发送一个之前由余额监控服务器批准的订单并更新客户端的余额。
- en: Note
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: You probably spotted a flaw in this design. It is possible to run into a race
    condition where two different instances of the automated trader may validate the
    balance of the same customer, receive an authorization from the **Balance Monitor
    Server**, place both trades in parallel and go over the limit of the client's
    account. This is comparable to a race condition that you can encounter with a
    concurrent system running on a single machine. In practice, the risk is low and
    is accepted by companies that are similar to MVT. The limit used to cut-off a
    client is usually set lower than the actual balance to account for this risk.
    Designing a platform to handle this case would increase the latency of the system
    because we would have to introduce more drastic synchronization across the nodes.
    This is a good example of business and technical domains working together to optimize
    the solution.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经发现了这个设计的缺陷。可能会遇到一个竞态条件，其中两个不同的自动化交易实例可能会验证同一客户的余额，从**余额监控服务器**接收授权，并行执行两笔交易并超过客户的账户限额。这类似于你在单台机器上运行的并发系统可能遇到的竞态条件。在实践中，这种风险很低，类似于MVT的公司可以接受这种风险。用于切断客户的限额通常设置得低于实际余额，以考虑到这种风险。设计一个处理这种情况的平台会增加系统的延迟，因为我们不得不在节点之间引入更多的剧烈同步。这是一个很好的例子，说明了商业和技术领域如何合作以优化解决方案。
- en: 'At the end of this design session, you take a short walk to clear your mind
    while drinking a bottle of carbonated water. As you return to the whiteboard,
    the crude reality hits you. Like a flat bottle of carbonated water, your idea
    has fizzled out. You realize that all these arrows linking rectangles are in reality
    messages that are traveling over the network. Currently, while a single automated
    trader relies on its internal state to execute strategies and place orders, this
    new design requires the automated trader to query an external system over the
    network and wait for the answer. This query happens on the critical path. This
    is another common issue with distributed systems: components with focused roles
    need to communicate with each other to accomplish their tasks. This communication
    comes at a cost. It involves serialization, I/O operations, and transfer over
    a network. You share your reflections with Alice, who confirms that this is a
    problem. The automated trader has to keep the internal latency as low as possible
    for its decisions to be relevant. After a short discussion, you agree that it
    would endanger performance for the automated trader to perform a remote call on
    the critical path. You are now left with the task of implementing a distributed
    system with components sharing a common state without communicating with each
    other on the critical path. This is where we can start talking about CRDTs.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个设计会议结束时，你走一小段路来清醒一下头脑，同时喝一瓶碳酸水。当你回到白板前，残酷的现实让你感到震惊。就像一个扁平的碳酸水瓶一样，你的想法已经消散了。你意识到，所有这些连接矩形的箭头实际上是在网络上传输的消息。目前，虽然单个自动化交易者依赖于其内部状态来执行策略和下订单，但这个新设计要求自动化交易者通过网络查询外部系统并等待答案。这个查询发生在关键路径上。这是分布式系统中的另一个常见问题：具有特定角色的组件需要相互通信以完成任务。这种通信是有成本的。它涉及到序列化、I/O操作和网络传输。你与爱丽丝分享你的反思，她确认这是一个问题。自动化交易者必须尽可能保持内部延迟低，以便其决策具有相关性。经过简短讨论后，你们同意在关键路径上对自动化交易者执行远程调用将危害性能。你现在面临着一个任务，即实现一个由共享公共状态的组件组成但不通过关键路径相互通信的分布式系统。这就是我们可以开始讨论CRDTs的地方。
- en: Introducing CRDTs
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入CRDTs
- en: '**CRDT** stands for **Conflict-free Replicated Data Types**. CRDTs were formally
    defined by Marc Shapiro and Nuno Preguiça in their paper, *Designing a commutative
    replicated data type* (refer to [https://hal.inria.fr/inria-00177693/document](https://hal.inria.fr/inria-00177693/document)).
    A CRDT is a data structure that is specifically designed to ensure eventual consistency
    across multiple components without the need for synchronization. Eventual consistency
    is a well-known concept in distributed system, which is not exclusive to CRDTs.
    This model guarantees that eventually, if a piece of data is no longer modified,
    all nodes in a cluster will end up with the same value for this piece of data.
    Nodes send each other update notifications to keep their state synchronized. The
    difference with strong consistency is that at a given time, some nodes may see
    a slightly outdated state until they receive the update notice:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**CRDT** 代表 **无冲突复杂数据类型**。CRDTs 由 Marc Shapiro 和 Nuno Preguiça 在他们的论文 *设计一个交换复杂数据类型*
    中正式定义（参见 [https://hal.inria.fr/inria-00177693/document](https://hal.inria.fr/inria-00177693/document)）。CRDT
    是一种专门设计的数据结构，旨在确保多个组件之间最终一致性，而无需同步。最终一致性是分布式系统中的一个知名概念，并不局限于 CRDTs。此模型保证最终，如果某个数据不再被修改，集群中的所有节点都将具有该数据的相同值。节点通过发送更新通知来保持其状态同步。与强一致性不同的是，在某个特定时间，一些节点可能看到稍微过时的状态，直到它们收到更新通知：'
- en: '![Introducing CRDTs](img/image_07_002.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![介绍CRDTs](img/image_07_002.jpg)'
- en: The preceding diagram shows an example of eventual consistency. All the nodes
    of the cluster hold the same piece of data (A = 0). Node 1 receives an update
    to set the value of A to 1\. After updating its internal state, it broadcasts
    the update to the rest of the cluster. The messages reach their targets at different
    instants, which means that until we reach step 4, A has a different value depending
    on the node. If a client queries node 4 for the value of A at step 3, they receive
    an older value as the change has not yet been reflected in node 4.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图示展示了最终一致性的一个例子。集群中的所有节点都持有相同的数据块（A = 0）。节点1收到更新以将A的值设置为1。在更新其内部状态后，它向集群的其他部分广播更新。消息在不同的时刻到达目标，这意味着直到我们达到第4步，A的值根据节点而异。如果客户端在第3步查询节点4的A的值，他们将收到较旧的价值，因为更改尚未反映在节点4上。
- en: 'A problem that may arise with eventual consistency is the resolution of conflicts.
    Imagine a simple example where nodes in a cluster share the state of an array
    of integers. The following table describes a sequence of events involving updating
    the state of this array:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最终一致性可能引发的问题之一是冲突的解决。想象一个简单的例子，集群中的节点共享一个整数数组的状态。以下表格描述了涉及更新该数组状态的连续事件序列：
- en: '| **Instant** | **Event** | **State change** |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| **即时** | **事件** | **状态变化** |'
- en: '| **T0** | Initialization of the cluster | Nodes 1 and 2 hold the same value
    for the array of integers: `[1,2,3]` |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| **T0** | 集群的初始化 | 节点1和2持有整数数组的相同值：`[1,2,3]` |'
- en: '| **T1** | Node 1 receives a request to update the value at index 1 from 2
    to 4 | Node 1 updates its internal state to `[1,4,3]` and sends an update message
    to node 2 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| **T1** | 节点1收到更新索引1的值的请求，从2更改为4 | 节点1将其内部状态更新为 `[1,4,3]` 并向节点2发送更新消息 |'
- en: '| **T2** | Node 2 receives a request to update the value at index 1 from 2
    to 5 | Node 2 updates its internal state to `[1,5,3]` and sends an update message
    to node 1 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| **T2** | 节点2收到更新索引1的值的请求，从2更改为5 | 节点2将其内部状态更新为 `[1,5,3]` 并向节点1发送更新消息 |'
- en: '| **T3** | Node 1 receives the update from node 2 | Node 1 needs to decide
    whether it should ignore or take into account the update message |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| **T3** | 节点1收到来自节点2的更新 | 节点1需要决定是否应该忽略或考虑更新消息 |'
- en: Our cluster now needs to resolve the conflict. Should node 1 update its state
    when receiving the update from node 2? If node 2 does the same, we end up with
    two nodes holding a different state. What about the other nodes? Some may receive
    the broadcast from node 2 before the one from node 1 and vice versa.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在需要解决冲突。节点1在收到来自节点2的更新时是否应该更新其状态？如果节点2也这样做，我们将有两个节点持有不同的状态。其他节点呢？一些节点可能先收到来自节点2的广播，然后是来自节点1的，反之亦然。
- en: Various strategies exist to deal with this problem. Some protocols use timestamps
    or vector clocks to determine which update was performed later in time and should
    take precedence. Others simply assume that the last writer wins. This is not a
    simple problem and CRDTs are designed to completely avoid conflicts altogether.
    Actually, CRDTs are defined to make conflicts mathematically impossible. To be
    defined as a CRDT, a data structure has to support only commutative updates. That
    is, regardless of the ordering in which the update operations are applied, the
    end state must always be the same. This is the secret of eventual consistency
    without merge conflict. When a system uses CRDTs, all the nodes can send each
    other update messages without a need for strict synchronization. The messages
    can be received in any order, and all the local states will converge to the same
    value eventually.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 存在多种策略来处理这个问题。一些协议使用时间戳或向量时钟来确定哪个更新是在时间上更晚执行的，应该具有优先权。其他协议简单地假设最后写入者获胜。这不是一个简单的问题，CRDTs旨在完全避免冲突。实际上，CRDTs被定义为使冲突在数学上成为不可能。要被定义为CRDT，数据结构必须仅支持交换性更新。也就是说，无论更新操作应用的顺序如何，最终状态必须始终相同。这是无合并冲突的最终一致性的秘密。当系统使用CRDTs时，所有节点都可以相互发送更新消息，而不需要严格的同步。消息可以以任何顺序接收，所有局部状态最终都会收敛到相同的值。
- en: '![Introducing CRDTs](img/image_07_003.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![介绍CRDTs](img/image_07_003.jpg)'
- en: In the preceding diagram, we see that node 3 and node 1 receive two different
    changes. They send this update information to all the other nodes. Note that we
    are not concerned with the order in which the updates are received by the other
    nodes. As the updates are commutative, their order has no impact on the final
    state that will be computed by each node. They are guaranteed to hold the same
    piece of data once all of them have received all the update broadcasts.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，我们看到节点3和节点1接收到了两个不同的更改。它们将这个更新信息发送给所有其他节点。请注意，我们并不关心其他节点接收更新的顺序。由于更新是交换的，它们的顺序对每个节点最终计算出的最终状态没有影响。一旦所有节点都接收到了所有的更新广播，它们将保证持有相同的数据。
- en: 'There exist two types of CRDT:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 存在两种类型的CRDT：
- en: Operation-based
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于操作的
- en: State-based
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于状态的
- en: 'They are equivalent in that it is always possible to define a state-based CRDT
    for each operation-based CRDT and vice-versa. However, their implementations differ
    and provide different guarantees in terms of error-recovery and performance. We
    define each type and consider its characteristics. As an example, we implement
    each version of the simplest CRDT: an increase-only counter.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 它们在这一点上是等效的，因为对于每个基于操作的CRDT，总是可以定义一个基于状态的CRDT，反之亦然。然而，它们的实现不同，在错误恢复和性能方面提供了不同的保证。我们定义每种类型并考虑其特性。作为一个例子，我们实现了最简单的CRDT版本：仅增加计数器。
- en: The state-based increase-only counter
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于状态的仅增加计数器
- en: 'With this model, when a CRDT receives an operation to perform from a client,
    it updates its state accordingly and sends an update message to all the other
    CRDTs in the cluster. This update message contains the full state of the CRDT.
    When the other CRDTs receive this message, they perform a merge of their state
    with the received new state. This merge operation has to guarantee that the end
    state will always be the same. It has to be commutative, associative, and idempotent.
    Let''s look at a possible implementation of this data type:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个模型，当CRDT从客户端接收到要执行的操作时，它会相应地更新其状态，并向集群中的所有其他CRDT发送更新消息。这个更新消息包含CRDT的完整状态。当其他CRDT接收到这个消息时，它们将它们的状态与接收到的新的状态合并。这个合并操作必须保证最终状态始终相同。它必须是交换的、结合的和幂等的。让我们看看这个数据类型的一个可能的实现：
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The `update` method can be used by clients to increase the value of the counter.
    This returns a new state-based counter containing an updated count, and it generates
    a `CounterState` object that can be sent to all the other CRDTs in the cluster.
    The `merge` is used to handle these `CounterState` messages and merge the new
    state of the other counters with the local state. A counter has a unique ID in
    the cluster. The internal state is composed of the local state (that is, `count`)
    and the states of all the other counters in the cluster. We keep these counters
    in a map that we update in the `merge` method when receiving state information
    from a different counter. Merging is a simple operation. We compare the incoming
    value with the one that we have in the map and keep the greatest one. This is
    to ensure that if we receive two update messages in the wrong order, we do not
    override the latest state (that is, the greatest number) with an older update
    message that was delayed.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端可以使用 `update` 方法来增加计数器的值。这会返回一个新的基于状态的计数器，包含更新的计数，并生成一个可以发送到集群中所有其他 CRDT
    的 `CounterState` 对象。`merge` 用于处理这些 `CounterState` 消息，并将其他计数器的新状态与本地状态合并。计数器在集群中有一个唯一的
    ID。内部状态由本地状态（即 `count`）和集群中所有其他计数器的状态组成。我们保持这些计数器在一个映射中，并在从不同的计数器接收状态信息时在 `merge`
    方法中更新这个映射。合并是一个简单的操作。我们比较传入的值与我们映射中的值，并保留最大的一个。这是为了确保如果我们收到两个更新消息的顺序错误，我们不会用延迟的较旧更新消息覆盖最新的状态（即最大的数字）。
- en: The operation-based increase-only counter
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于操作的仅增加计数器
- en: 'Operation-based CRDTs are similar to state-based CRDTs with the difference
    that update messages only contain a description of the operation that was just
    performed. These CRDTs do not send their full-state in an update message, but
    they are merely a copy of the operation that they just performed to update their
    own state. This ensures that all the other CRDTs in the cluster perform the same
    operation and maintain their state in sync. The updates can be received in a different
    order by each node of the cluster. To guarantee that the end state is the same
    for all the nodes, the updates have to be commutative. You can see an example
    of this data structure, as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 基于操作的 CRDT 与基于状态的 CRDT 类似，不同之处在于更新消息只包含刚刚执行的操作的描述。这些 CRDT 不在更新消息中发送它们的完整状态，但它们仅仅是它们刚刚执行以更新自己状态的操作的副本。这确保了集群中的所有其他
    CRDT 都执行相同的操作并保持它们的状态同步。更新消息可以按不同的顺序被集群的每个节点接收。为了保证所有节点的最终状态相同，更新必须是交换的。您可以在以下示例中看到这种数据结构：
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This implementation is shorter than the state-based example. The `update` method
    still returns an updated instance of the counter, and the `CounterUpdate` object
    that was applied. For an operation-based counter, it is enough to broadcast the
    operation that was applied. This update is received by the `merge` method of the
    other instances to apply the same operation to their own internal state. Note
    that `update` and `merge` are equivalent, `merge` is even implemented in terms
    of `update`. In this model, there is no need for a unique ID per counter.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此实现比基于状态的示例更短。`update` 方法仍然返回计数器的更新实例以及应用过的 `CounterUpdate` 对象。对于基于操作的计数器，只需广播应用过的操作即可。这个更新通过其他实例的
    `merge` 方法接收，以将相同的操作应用于它们自己的内部状态。请注意，`update` 和 `merge` 是等效的，`merge` 实际上是基于 `update`
    实现的。在这个模型中，每个计数器不需要唯一的 ID。
- en: Operation-based CRDTs use potentially smaller messages because they only send
    each discrete operation as opposed to their full internal state. In our example,
    the state-based update contains two integers, as opposed to only one for the operation-based
    update. Smaller messages can help reduce bandwidth usage and improve the throughput
    of your system. However, they are sensitive to communication failures. If an update
    message is lost during the transmission and does not reach a node, this node will
    be out of sync with the rest of the cluster with no way of recovering. If you
    decide to use operation-based CRDTs, you have to be able to trust your communication
    protocol and be confident that all update messages reach their destination and
    are properly processed. State-based CRDTs do not suffer from this issue because
    they always send their entire state in an update message. If a message is lost
    and does not reach a node, this node will only be out of sync until it receives
    the next update message. It is possible to make this model even more robust by
    implementing a periodic broadcast of the node's state, even when no updates are
    performed. This would force all nodes to regularly send their current state and
    ensure that the cluster is always eventually consistent.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 基于操作的CRDTs使用可能更小的消息，因为它们只发送每个离散操作，而不是它们的完整内部状态。在我们的例子中，基于状态的更新包含两个整数，而基于操作的更新只有一个。较小的消息可以帮助减少带宽使用并提高系统的吞吐量。然而，它们对通信故障敏感。如果在传输过程中更新消息丢失并且没有到达节点，这个节点将无法与集群的其他部分保持同步，并且无法恢复。如果您决定使用基于操作的CRDTs，您必须能够信任您的通信协议，并确信所有更新消息都到达了目的地并且得到了适当的处理。基于状态的CRDTs不受此问题的影响，因为它们总是在更新消息中发送整个状态。如果消息丢失并且没有到达节点，该节点将仅在收到下一个更新消息之前与集群不同步。通过实现节点的状态周期性广播，即使没有执行更新，也可以使此模型更加健壮。这将迫使所有节点定期发送其当前状态，并确保集群始终最终一致。
- en: CRDTs and automated traders
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CRDTs和自动化交易员
- en: Based on the requirements of our system, it seems that CRDTs are a good fit
    for our implementation. Each node can keep the current state of each customer's
    balance in memory as a counter, update it when placing orders, and broadcast update
    messages to the rest of the system. This broadcast can be done outside the critical
    path, and we do not have to worry about handling conflicts, as this is what CRDTs
    are designed for. Eventually, all nodes will have in memory the same value for
    each balance, and they will be able to locally check for trade authorization.
    The balance monitor server can be removed entirely.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们系统的需求，CRDTs似乎非常适合我们的实现。每个节点可以将每个客户的当前余额状态保存在内存中作为一个计数器，在下单时更新它，并将更新消息广播到系统的其余部分。这种广播可以在关键路径之外进行，我们不必担心处理冲突，因为这是CRDTs的设计目的。最终，所有节点都将内存中每个余额具有相同的值，并且它们将能够本地检查交易授权。余额监控服务器可以完全移除。
- en: 'To implement the state of the balance as a CRDT, we need a more sophisticated
    counter than the one we previously explored. The balance cannot be represented
    as an increase-only counter because, occasionally, orders are canceled and the
    system must credit the customer''s account. The counter has to be able to handle
    both increment and decrement operations. Luckily, such a counter exists. Let''s
    look at a simple implementation of a state-based counter:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 要将余额状态实现为CRDT，我们需要一个比我们之前探索的更复杂的计数器。余额不能表示为只增加的计数器，因为偶尔订单会被取消，系统必须向客户的账户进行信用。计数器必须能够处理增加和减少操作。幸运的是，这样的计数器存在。让我们看看基于状态的计数器的一个简单实现：
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The PN counter leverages our previous implementation of an increase-only counter
    to provide the decrement capability. To be able to represent a counter as a state-based
    CRDT, we need to keep track of the state of both increment and decrement operations.
    This is necessary to guarantee that we do not lose information if our update messages
    are received in the wrong order by other nodes.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: PN计数器利用我们之前实现的只增加的计数器来提供减少功能。为了能够将计数器表示为基于状态的CRDT，我们需要跟踪增加和减少操作的状态。这是必要的，以确保如果我们的更新消息以错误的顺序被其他节点接收，我们不会丢失信息。
- en: Tip
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Remember that the increase-only counter guarantees conflict resolution by assuming
    that the highest value of the counter is necessarily the most up-to-date. This
    invariant does not hold true for the PN counter.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，只增加的计数器通过假设计数器的最高值必然是最新的来保证冲突解决。这个不变量对于PN计数器不成立。
- en: 'This implementation shows you another interesting property of CRDTs: simple
    and basic structures can be composed to create more complex and feature-rich CRDTs.
    Should we proceed to demonstrate the implementation of an operation-based counter?
    As it turns out and we are sure you spotted this earlier, our previous increase-only
    counter already supports decrement operations. Applying a positive or a negative
    delta is handled by the operation-based counter.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这个实现展示了CRDTs的另一个有趣特性：简单和基本的结构可以组合起来创建更复杂和功能丰富的CRDTs。我们是否应该继续演示基于操作的计数器的实现？结果证明，并且我们确信你之前已经注意到了，我们之前的只增计数器已经支持减操作。应用正或负的delta由基于操作的计数器处理。
- en: When the balance is not enough
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当余额不足时
- en: You have finished the implementation of the proof-of-concept and call Alice
    to get some feedback. She spends a few minutes studying your new design and your
    code. "Looks good to me. Do not forget to synchronize the account blacklist as
    well." What is she talking about? "Checking the account balance is only one of
    the criteria to allow or block an automated trade. Other attributes of the client
    need to be taken into consideration. Today, the automated trader runs a trust
    algorithm in the background, and it calculates a score for each customer. If the
    score falls below a certain threshold, the account is blacklisted until the end
    of the trading day, and all automated orders are denied. I like your design, but
    you need to incorporate this blacklist into the new system." Faced with this new
    challenge, you think that the best solution would be to implement the blacklist
    as a CRDT as well, provided that it fits your current design.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经完成了概念验证的实现，并打电话给Alice获取一些反馈。她花了几分钟研究你的新设计和你的代码。“看起来不错。别忘了同步账户黑名单。”她在说什么？“检查账户余额只是允许或阻止自动化交易的一个标准之一。客户的其他属性也需要考虑。今天，自动化交易员在后台运行信任算法，并为每位客户计算一个分数。如果分数低于某个阈值，账户将被列入黑名单直到交易日结束，并且所有自动化订单都将被拒绝。我喜欢你的设计，但你需要将这个黑名单纳入到新系统中。”面对这个新的挑战，你认为最好的解决方案是将黑名单也实现为CRDT，前提是它适合你的当前设计。
- en: A new CRDT - the grow-only set
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个新的CRDT - 只增集合
- en: 'One CRDT is designed to handle our new use case. The grow-only set data type
    implements a set that only supports the addition of new elements without duplicates.
    We can implement the blacklist as a grow-only set. Each node can run its own trust
    algorithm and can decide whether a client should be blacklisted and denied automated
    trading for the rest of the day. At the end of the day, the system can clear the
    set. We display a possible implementation of a state-based grow-only set, as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一个CRDT被设计来处理我们的新用例。只增集合数据类型实现了一个只支持添加新元素而不重复的集合。我们可以将黑名单实现为只增集合。每个节点都可以运行自己的信任算法，并决定是否应该将客户端列入黑名单并拒绝当天剩余的自动化交易。在一天结束时，系统可以清除集合。以下是我们展示的一个基于状态的只增集合的可能实现：
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Our implementation supports adding an element by calling the `update` method.
    It returns a new instance of `StateBasedGSet` with an updated set, as well as
    a `GSetState` instance to be broadcast to the other nodes. This update contains
    the entire state of the counter, that is, the internal set. An operation-based
    implementation is trivial and left as an exercise for the reader (a possible solution
    is provided in the code repository). Similar to the increment-decrement counter
    explored earlier, it is possible to create a set that supports both adding and
    removing an element. There is one caveat though: as adding and removing an element
    are not commutative operations, one must take precedence on the other. In practice,
    a 2P-set can be created to support adding and removing items, but once removed,
    an element cannot be added again. The remove operation takes precedence and guarantees
    that the operations are commutative and can be handled without conflicts. A possible
    implementation is to combine two grow-only sets, one for adding elements, and
    the other to remove them. Again, we see the power of simple CRDTs that can be
    combined to create more powerful data types.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实现支持通过调用`update`方法添加元素。它返回一个带有更新集合的新`StateBasedGSet`实例，以及一个要广播到其他节点的`GSetState`实例。此更新包含计数器的整个状态，即内部集合。基于操作的实现是微不足道的，留给读者作为练习（代码库中提供了一个可能的解决方案）。类似于之前探索的增量-减量计数器，可以创建一个同时支持添加和删除元素的集合。但是有一个注意事项：由于添加和删除元素不是交换操作，必须优先考虑其中一个。在实践中，可以创建一个2P集合来支持添加和删除项目，但一旦删除，元素就不能再次添加。删除操作具有优先权，并保证操作是交换的，可以无冲突地处理。一个可能的实现是将两个仅增长的集合组合起来，一个用于添加元素，另一个用于删除它们。我们再次看到了简单CRDT的强大之处，这些CRDT可以组合起来创建更强大的数据类型。
- en: Free trading strategy performance improvements
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 免费交易策略性能改进
- en: You stare at your agile burn down chart and discover that you completed all
    your story points before the sprint ends tomorrow. You are excited to have delivered
    this week's features early, but you are left wondering whether or not you will
    have yet another discussion with the scrum master about estimation. Instead of
    spending mental energy on estimating, you instead return your attention to an
    issue that Dave raised. At a recent lunch together, Dave talked about how the
    company's trading strategies lose money when trading decisions are made based
    on stale information. Even several milliseconds can make the difference between
    extremely profitable trades and losses. His words piqued your interest to see
    if you can improve the performance of MVT's trading strategies.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 你盯着你的敏捷燃尽图，发现你将在明天冲刺结束时完成所有的故事点。你对本周提前交付功能感到兴奋，但你仍然想知道你是否还会与敏捷大师就估算进行另一场讨论。与其在估算上浪费精力，你不如将注意力转回到Dave提出的问题上。在最近的一次午餐中，Dave谈到了公司的交易策略在基于过时信息做出交易决策时亏损。即使是几毫秒的差距也可能在极其有利可图的交易和亏损之间产生差异。他的话激起了你的兴趣，想知道你是否能提高MVT交易策略的性能。
- en: 'MVT''s trading strategies are downstream consumers of the order book. The trading
    strategies listen for changes in the best bid and offer (BBO) in order to determine
    when to submit buy or sell orders. At lunch, Dave explained that tracking the
    BBO has historically proven to give the most signals for MVT''s trading strategies.
    The best bid refers to the bid with the highest price, and the best offer refers
    to the offer with the lowest price. When either side of the BBO changes due to
    a cancellation, execution, or new limit order, then a BBO update event is transmitted
    to downstream trading strategies. The model representing this event is `BboUpdated`,
    and it looks like the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: MVT的交易策略是订单簿的下游消费者。交易策略会监听最佳买入价和卖出价（BBO）的变化，以便确定何时提交买入或卖出订单。在午餐时，Dave解释说，历史上跟踪BBO已被证明为给MVT的交易策略提供最多的信号。最佳买入价指的是最高价格的买入价，最佳卖出价指的是最低价格的卖出价。当BBO的任一侧因取消、执行或新的限价订单而发生变化时，则将BBO更新事件传输到下游交易策略。表示此事件的模型是`BboUpdated`，其外观如下：
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: MVT deploys each trading strategy within its own JVM to ensure that failures
    do not affect other running strategies. When deployed, each trading strategy maintains
    BBO subscriptions for the set of tickers it trades.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: MVT在其自己的JVM中部署每个交易策略，以确保失败不会影响其他正在运行的策略。部署后，每个交易策略为其交易的股票集合维护BBO订阅。
- en: Having spent a significant amount of time working on the order book, you hope
    to find opportunities to apply your functional programming knowledge to yield
    better performance. During your lunch with Dave, you discovered that "better performance"
    has a slightly different meaning for trading strategy development than it does
    for other systems. You asked Dave, "If you could choose between an improvement
    in latency or throughput, which would you choose?" Dave sarcastically replied,
    "Why do I have to choose? I want both!" Afterwards, he went on to say, "Latency!
    Almost every time a trading strategy makes a decision using old BBO updates, we
    lose money. In fact, if we could, I would rather throw away old BBO updates. We
    only trade high-volume tickers, so we are pretty much guaranteed to see another
    BBO update immediately." As you start looking into the code base, you wonder whether
    you can utilize Dave's thinking to improve trading strategy performance.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在花费了大量时间处理订单簿之后，你希望找到机会将你的函数式编程知识应用于提高性能。在与Dave共进午餐时，你发现“更好的性能”在交易策略开发中的含义与其他系统略有不同。你问Dave，“如果你必须在延迟提升和吞吐量提升之间选择，你会选择哪一个？”Dave带着讽刺的口气回答，“为什么我必须选择？我想要两者都要！”之后，他继续说，“延迟！每次交易策略使用旧的BBO更新做出决策时，我们都会损失金钱。事实上，如果我们能的话，我宁愿丢弃旧的BBO更新。我们只交易高量级的股票，所以我们几乎可以保证立即看到另一个BBO更新。”当你开始研究代码库时，你开始思考是否可以利用Dave的想法来提高交易策略的性能。
- en: Benchmarking the trading strategy
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基准测试交易策略
- en: Recalling the lessons that you learned when working on the order book, your
    first step is to benchmark. You select one of MVT's production trading strategies
    and adapt the benchmark that you wrote to exercise the order book, `FinalLatencyBenchmark`,
    to send the `BboUpdated` events to the trading strategy. Originally, the benchmark
    focused on displaying the 99^(th) percentile latency and higher. As you know that
    latency is the most important factor in your performance investigation, you modify
    the benchmark to also emit the median and 75^(th) percentile latencies. This will
    give you a more holistic view into the latency of trading strategy performance.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾你在处理订单簿时学到的经验，你的第一步是进行基准测试。你选择MVT的一个生产交易策略，并将你为练习订单簿而编写的基准`FinalLatencyBenchmark`进行适配，以便将`BboUpdated`事件发送到交易策略。最初，基准测试主要关注显示99^(th)百分位延迟以及更高。正如你所知，延迟是你性能调查中最重要的因素，因此你修改了基准测试，使其也发出中位数和75^(th)百分位延迟。这将为你提供对交易策略性能延迟的更全面视角。
- en: Looking at the production metrics system, you see a time series trading volume
    chart for the system that you want to benchmark. It shows that it is a low-volume
    day, only about 4,000 BBO updated events per second. You dig through historical
    metrics to find the highest volume day in the last few weeks. The market has been
    volatile again, so a recent high-volume day is likely a good proxy for a high
    throughput rate to benchmark. About two weeks ago, there was a trading day with
    a sustained peak of 12,000 BBO updated events per second. You plan to begin benchmarking
    at the lower end of the spectrum with 4,000 events per second, ramping up to 12,000
    events per second to see how performance changes.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 查看生产指标系统，你看到的是你想要基准测试的系统的时间序列交易量图表。它显示这是一个低量级的日子，每秒大约有4,000个BBO更新事件。你挖掘历史指标以找到过去几周中最高量级的一天。市场再次波动，所以最近的高量级一天可能是衡量高吞吐率的良好代理。大约两周前，有一个交易日，每秒BBO更新事件量持续达到12,000。你计划从每秒4,000个事件的低端开始基准测试，逐步增加到每秒12,000个事件，以观察性能如何变化。
- en: 'The testing methodology is to measure latency for an equivalent number of events
    across throughput rates while ensuring a thorough test at each throughput level.
    To accomplish this goal, you multiply the higher throughput, 12,000 events per
    second, by 30 trials for a sum total of 360,000 events. At 4,000 events per second,
    running the benchmark for 90 trials produces the equivalent of 360,000 events.
    Running the benchmarks in a test environment replicating production gives the
    results displayed in the following table. The table abbreviates events per second
    as EPS:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 测试方法是在不同的吞吐量速率下测量等量事件的时间延迟，同时确保在每个吞吐量级别上进行彻底的测试。为了实现这一目标，你将12,000个事件每秒的较高吞吐量乘以30次试验，总共360,000个事件。在4,000个事件每秒的情况下，进行90次基准测试相当于360,000个事件。在模拟生产环境的测试环境中运行基准测试，得到以下表格中显示的结果。表格将每秒事件数缩写为EPS：
- en: '| **Percentile** | **4,000 EPS** | **12,000 EPS** |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| **百分位** | **4,000 EPS** | **12,000 EPS** |'
- en: '| 50^(th) (median) | 0.0 ms | 1,063.0 ms |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 第50百分位（中位数） | 0.0 ms | 1,063.0 ms |'
- en: '| 75^(th) | 0.0 ms | 1,527.0 ms |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 第75百分位 | 0.0 ms | 1,527.0 ms |'
- en: '| 99^(th) | 10.0 ms | 2,063.0 ms |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 第99百分位 | 10.0 ms | 2,063.0 ms |'
- en: '| 99.9^(th) | 22.0 ms | 2,079.0 ms |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 第99.9百分位 | 22.0 ms | 2,079.0 ms |'
- en: '| 100^(th) (maximum) | 36.0 ms | 2,079.0 ms |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 第100百分位（最大值） | 36.0 ms | 2,079.0 ms |'
- en: 'These results illustrate a startling contrast in performance. At 4,000 events
    per second, the trading strategy appears to perform well. 99% of events are responded
    to within 10 ms, and we observe that up to the 75^(th) percentile, the strategy
    is responding with miniscule delay. This suggests that on low-volume days, this
    trading strategy is able to decide on information quickly, which should bode well
    for profitability. Unfortunately, at 12,000 events per second, the performance
    is unacceptable. Having not yet looked at the code, you wonder whether you can
    spot any sudden changes in performance by sweeping several more throughputs. You
    try a binary search between 4,000 and 12,000 events per second and get the following
    results:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果展示了性能的惊人对比。在每秒4,000个事件时，交易策略看起来表现良好。99%的事件在10毫秒内得到响应，并且我们观察到，直到75百分位，策略的响应延迟极小。这表明在低交易量日，这种交易策略能够快速做出信息决策，这对盈利性应该是有利的。不幸的是，在每秒12,000个事件时，性能是不可接受的。由于尚未查看代码，你怀疑是否可以通过在4,000和12,000事件每秒之间进行多次吞吐量扫描来发现性能的突然变化。你尝试在4,000和12,000事件每秒之间进行二分搜索，并得到以下结果：
- en: '| **Percentile** | **9,000 EPS** | **10,000 EPS** | **11,000 EPS** | **11,500
    EPS** |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| **百分位** | **9,000 EPS** | **10,000 EPS** | **11,000 EPS** | **11,500 EPS**
    |'
- en: '| 50^(th) (median) | 0.0 ms | 4.0 ms | 41.0 ms | 487.0ms |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 第50百分位（中位数） | 0.0 ms | 4.0 ms | 41.0 ms | 487.0 ms |'
- en: '| 75^(th) | 5.0 ms | 9.0 ms | 66.0 ms | 715.0 ms |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 第75百分位 | 5.0 ms | 9.0 ms | 66.0 ms | 715.0 ms |'
- en: '| 99^(th) | 32.0 ms | 47.0 ms | 126.0 ms | 871.0 ms |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 第99百分位 | 32.0 ms | 47.0 ms | 126.0 ms | 871.0 ms |'
- en: '| 99.9^(th) | 58.0 ms | 58.0 ms | 135.0 ms | 895.0 ms |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 第99.9百分位 | 58.0 ms | 58.0 ms | 135.0 ms | 895.0 ms |'
- en: '| 100^(th) (maximum) | 67.0ms | 62.0 ms | 138.0 ms | 895.0 ms |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 第100百分位（最大值） | 67.0 ms | 62.0 ms | 138.0 ms | 895.0 ms |'
- en: You chose 9,000 events per second as a starting point because it divided evenly
    into the total event count, 360,000\. At this level of throughput, the strategy's
    profile is qualitatively closer to the 4,000 events per second profile. As results
    looked reasonable at this level, you increased the throughput approximately halfway
    between 9,000 and 12,000 events per second to the next level that divides evenly
    into 360,000\. At 10,000 events per second, we once again observe a profile that
    remains similar to the 4,000 events per second profile. There is a discernible
    increase in the median and 75^(th) percentile latencies, suggesting the strategy's
    performance is beginning to degrade. Next, you increase the throughput to the
    midpoint, 11,000 events per second. As you cannot run 32.72 trials, you instead
    round up to 33 trials for a total of 363,000 events. These results are qualitatively
    worse than the 4,000 events per second results by approximately an order of magnitude
    at each measured percentile. Admittedly, these are weak performance results, but
    does this profile closely resemble the profile at 12,000 events per second?
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你选择每秒9,000个事件作为起始点，因为它可以均匀地分成总事件数360,000个。在这个吞吐量级别上，策略的轮廓在定性上更接近每秒4,000个事件的轮廓。由于在这个级别上结果看起来合理，你将吞吐量增加到9,000和12,000事件每秒之间的中间值，以达到下一个可以均匀分成360,000的事件数的级别。在每秒10,000个事件时，我们再次观察到与每秒4,000个事件轮廓相似的轮廓。中位数和75百分位延迟的明显增加表明策略的性能开始下降。接下来，你将吞吐量增加到中间值，即每秒11,000个事件。由于你不能运行32.72次试验，你将试验次数向上取整到33次，总共363,000个事件。这些结果在各个测量的百分位上比每秒4,000个事件的结果差大约一个数量级。诚然，这些是弱性能结果，但这个轮廓是否与每秒12,000个事件的轮廓相似？
- en: 'You are now a bit alarmed because 11,000 events per second is approximately
    90% of the throughput at 12,000 events per second. Yet, the results do not display
    close to 90% similarity. If the trading strategy decreased linearly you would
    expect to see latencies approximating 90% of the latencies that were observed
    at 12,000 events per second. Unsatisfied with this performance profile, you try
    one more throughput, 11,500 events per second. At this throughput level, you run
    the benchmark for 31 trials, totaling 356,500 events. Increasing the throughput
    by approximately 5% resulted in an observed median latency that is roughly 11
    times greater and an observed 99^(th) percentile latency that is nearly six times
    greater. These results make it clear that the strategy''s runtime performance
    degrades exponentially. To better reason about the results, you quickly throw
    together the following bar graph:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在有点惊慌，因为每秒11,000个事件大约是每秒12,000个事件吞吐量的90%。然而，结果并没有显示出接近90%的相似性。如果交易策略线性下降，你预计会看到接近于在每秒12,000个事件时观察到的延迟的90%。对这个性能配置文件不满意，你尝试了另一个吞吐量，每秒11,500个事件。在这个吞吐量级别上，你进行了31次基准测试，总共356,500个事件。通过将吞吐量增加大约5%，观察到的中位延迟大约是原来的11倍，观察到的99^(th)百分位延迟几乎是原来的6倍。这些结果清楚地表明，策略的运行时性能呈指数下降。为了更好地理解结果，你迅速制作了以下条形图：
- en: '![Benchmarking the trading strategy](img/image_07_004.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![基准测试交易策略](img/image_07_004.jpg)'
- en: This bar graph visualizes the exponential decay in performance. Interestingly,
    we observe that all measured latency percentiles follow consistent patterns of
    decay, further substantiating the hypothesis that the strategy has exhausted its
    capacity to process requests. Before jumping into improving the trading strategy
    performance, you ponder, "How can I bound the exponential increases in latency?"
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这个条形图可视化了性能的指数衰减。有趣的是，我们观察到所有测量的延迟百分位数都遵循一致的衰减模式，进一步证实了该策略已耗尽其处理请求的能力的假设。在着手提高交易策略性能之前，你思考着，“我该如何限制延迟的指数增长？”
- en: Note
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Instead of seeing consistent decay across all measured latency percentiles,
    imagine that the median and 75^(th) percentiles remained qualitatively constant
    across all configured throughput levels. Does this profile suggest the same types
    of performance impediment as the scenario that we are working through? Take a
    moment to consider what could cause such a distribution to arise.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 与观察到所有测量延迟百分位数持续衰减的情况不同，想象一下中位数和75^(th)百分位数在所有配置的吞吐量级别上保持定性上的恒定。这个配置文件是否表明了与我们在处理的场景相同的性能障碍类型？花点时间考虑一下什么可能导致这种分布出现。
- en: The danger of unbounded queues
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无界队列的危险
- en: 'Benchmarking revealed a universal truth about performance tuning: unbounded
    queues kill performance. Here, we use the term queue to broadly mean a waiting
    line, instead of specifically focusing on the queue data structure. For example,
    this benchmark queues events to be transmitted at specific points in time in a
    `List`. In a production environment, this queue exists at multiple levels. The
    sender of the `BboUpdated` events likely queues events at the application-level,
    and subsequently, the network protocol (for example, TCP) may employ its own sets
    of queues to manage transmission to the consumer. When events are processed at
    a rate slower than they are produced, the system becomes unstable because the
    backlog of work always increases. Given infinite memory and zero response time
    guarantees, it is possible for an application to continue processing an ever-growing
    queue of items. However, in practice, when a system cannot stabilize itself by
    increasing its consumption rate to match or exceed the production rate, the system
    eventually spirals out of control. A system''s hardware resources are finite,
    and as a consumer falls behind, it will require increasing amounts of memory to
    cope with the growing backlog. Taken to an extreme, increasing memory requirements
    causes more frequent garbage collections, which in turn, further slow down consumption.
    This is a cyclical problem that will eventually exhaust memory resources, causing
    a system to crash.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试揭示了一个关于性能调优的普遍真理：无界队列会杀死性能。在这里，我们使用“队列”这个术语广泛地指代一个等待队列，而不是专门关注队列数据结构。例如，这个基准测试在`List`中排队事件，以便在特定的时间点进行传输。在生产环境中，这个队列存在于多个层级。`BboUpdated`事件的发送者可能在应用层排队事件，随后，网络协议（例如，TCP）可能会使用它自己的队列集来管理向消费者传输。当事件的处理速度慢于产生速度时，系统会变得不稳定，因为工作积压总是不断增加。假设有无限的内存和零响应时间保证，应用程序可以继续处理不断增长的队列项。然而，在实践中，当系统无法通过增加其消费速率以匹配或超过生产速率来自我稳定时，系统最终会失控。系统的硬件资源是有限的，随着消费者落后，它将需要越来越多的内存来应对不断增长的工作积压。如果内存需求增加到了极端，会导致垃圾回收更加频繁，这反过来又会进一步减慢消费速度。这是一个循环问题，最终会耗尽内存资源，导致系统崩溃。
- en: By inspecting the trading system code, you will discover that there is a queue
    for message processing within the trading system. This application-level queue
    is a `LinkedBlockingQueue` that separates the network I/O thread from the application
    thread. In the benchmark, the thread driving the benchmark adds events directly
    to the queue, simulating the behavior of a production network thread receiving
    events from the outside world. It is a common practice to group together logical
    parts of an application into separate thread pools in order to gain efficiencies
    by parallelizing processing work.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查交易系统代码，你会发现交易系统中存在一个用于消息处理的队列。这个应用层队列是一个`LinkedBlockingQueue`，它将网络I/O线程与应用线程分开。在基准测试中，驱动基准测试的线程直接将事件添加到队列中，模拟了生产网络线程从外部世界接收事件的行为。将应用程序的逻辑部分组合在一起，分别放入单独的线程池中，以通过并行化处理工作来提高效率，这是一种常见的做法。
- en: Note
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: When we previously explored concurrency with `Future` and `Task`, we indirectly
    worked with queues. The `ExecutorService` that receives submissions from `Future`
    and `Task` manages its workload by enqueuing tasks into a `BlockingQueue`. The
    factory methods that are provided in `Executors` do not allow the caller to provide
    a queue. If you explore the implementation of these factory methods you discover
    the kind and the size of `BlockingQueue` created.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们之前使用`Future`和`Task`探索并发时，我们间接地与队列一起工作。接收`Future`和`Task`提交的`ExecutorService`通过将任务入队到`BlockingQueue`来管理其工作负载。`Executors`中提供的工厂方法不允许调用者提供队列。如果你探索这些工厂方法的实现，你会发现创建的`BlockingQueue`的类型和大小。
- en: Adding a buffer between the network layer and the application layer typically
    bodes well for performance. A queue can enable an application to tolerate momentary
    consumption slowdowns and bursts of messages from a producer. However, as we have
    seen in our benchmarking, buffers are a double-edged sword. The default constructor
    for `LinkedBlockingQueue` is effectively unbounded, setting a limit that is equal
    to the maximum supported integer value. By buffering messages indefinitely when
    the rate of production is consistently higher than the consumption rate, the trading
    system's performance degrades to an unusable state.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络层和应用层之间添加缓冲通常对性能有益。队列可以使应用程序能够容忍来自生产者的暂时性消费减速和消息突发。然而，正如我们在基准测试中所看到的，缓冲是一把双刃剑。`LinkedBlockingQueue`的默认构造函数实际上是未限定的，设置了一个等于最大支持整数值的限制。当生产率持续高于消费率时，无限期地缓冲消息，交易系统的性能会下降到不可用的状态。
- en: Applying back pressure
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用反向压力
- en: What would happen if we instead chose to bound the queue that is receiving events
    to a smaller limit? When the production rate exceeds the consumption rate and
    the queue reaches capacity, one option is for the system to block until a spot
    is available in the queue. Blocking forces event production to halt, which describes
    a strategy for applying back pressure. In this context, pressure refers to the
    queue of events to be processed. The pressure manifests itself with increasing
    resource usage (for example, memory). By adopting a policy of blocking further
    production, the system is applying pressure back to the producer. Any queues that
    exist between the application-level consumer and the producer will also eventually
    reach capacity, forcing the producer to change its production rate in order to
    continue transmitting events.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们选择将接收事件的队列限制在一个更小的限制，会发生什么？当生产率超过消费率并且队列达到容量时，一个选项是系统阻塞，直到队列中有空位。阻塞迫使事件生产停止，这描述了应用反向压力的策略。在这个上下文中，压力指的是待处理的事件队列。压力通过不断增加的资源使用（例如，内存）表现出来。通过采用阻塞进一步生产的策略，系统将压力反馈给生产者。任何存在于应用级消费者和生产者之间的队列最终也会达到容量，迫使生产者改变其生产率以继续传输事件。
- en: 'To implement this back pressure policy, all queues must be bounded to a size
    that avoids excessive resource usage, and production into queues must block when
    full. This is straightforward to implement with implementations of the JDK-provided
    `BlockingQueue` interface. For example, the following snippet displays this strategy
    with `LinkedBlockingQueue`:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这种反向压力策略，所有队列都必须限制在一个大小，以避免过度使用资源，并且在队列满时必须阻塞生产。使用JDK提供的`BlockingQueue`接口的实现，这很容易实现。例如，以下片段使用`LinkedBlockingQueue`展示了这种策略：
- en: '[PRE5]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this snippet, we see construction of a `LinkedBlockingQueue` with a capacity
    limit of 1,000 messages. Based on knowledge of the production environment, you
    feel comfortable retaining up to 1,000 messages in-memory without exhausting memory
    resources. The second line in the snippet demonstrates a blocking operation to
    enqueue an element via `put`.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个片段中，我们看到构建了一个容量限制为1,000条消息的`LinkedBlockingQueue`。根据对生产环境的了解，你感到舒适地保留最多1,000条消息在内存中，而不会耗尽内存资源。片段中的第二行演示了通过`put`方法进行阻塞操作来入队一个元素。
- en: When applying back pressure, the choice in queue size is critical. To illustrate
    why, let's assume that we measured the maximum trading system processing latency
    to be 0.5 ms once a message is consumed from the event queue. At maximum, the
    total processing latency for an event is equal to 0.5 ms plus the time spent waiting
    to be processed. Consider the scenario where the queue has a size of 1,000 and
    999 events are queued when a new event arrives. In the worst case scenario, the
    new event waits 499.5 ms for the 999 other events that are already enqueued to
    be processed, plus 0.5 ms to be processed. Configuring a queue size of 1,000 yielded
    a maximum latency of 500 ms, showing that maximum latency is directly proportional
    to queue size.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用反向压力时，队列大小的选择至关重要。为了说明原因，让我们假设我们测量了最大交易系统处理延迟为0.5毫秒，一旦从事件队列中消费了一条消息。在最坏的情况下，一个事件的总处理延迟等于0.5毫秒加上等待处理的等待时间。考虑以下场景：当新事件到达时，队列大小为1,000，并且有999个事件已经排队。在最坏的情况下，新事件需要等待499.5毫秒，直到999个已经排队的其他事件被处理，再加上0.5毫秒来处理。配置队列大小为1,000产生了最大延迟500毫秒，这表明最大延迟与队列大小成正比。
- en: 'A more disciplined approach to sizing queues involves considering environment
    resources and understanding the maximum latency that is tolerated by the business.
    From informal discussions with Dave, we learned that even several milliseconds
    can make or break a trading strategy''s profitability. Until we have a moment
    to check in with him, let''s assume that 10 ms is the maximum delay the strategy
    can tolerate without risking significant trading losses. Using this information,
    we can calculate a queue size that ensures that the 10 ms latency limit is respected.
    In the previous example, we performed the following worst-case scenario arithmetic:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 一种更严谨的队列大小确定方法涉及考虑环境资源以及业务所能容忍的最大延迟。从与Dave的非正式讨论中，我们了解到，即使是几毫秒也可能决定交易策略的盈利能力。在我们有机会与他联系之前，让我们假设10毫秒是策略可以容忍的最大延迟，而不会造成重大的交易损失。使用这些信息，我们可以计算出确保10毫秒延迟限制得到遵守的队列大小。在先前的例子中，我们进行了以下最坏情况下的算术运算：
- en: '[PRE6]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can rearrange this formula to solve for queue size, as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以重新排列这个公式来求解队列大小，如下所示：
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'From this arithmetic, we substitute in known values to compute queue size,
    as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个算术中，我们代入已知值来计算队列大小，如下所示：
- en: '[PRE8]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The arithmetic suggests that we bound the queue size for twenty elements to
    ensure that in the worst case scenario an event can be enqueued and processed
    within 10 ms. To explore back pressure deeper, we encourage you to read the following
    blog post by Martin Thompson at [http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html](http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html).
    Martin is an authority on high-performance software development, and this particular
    blog post was an invaluable learning source for back pressure.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 算术表明，我们将队列大小限制为20个元素，以确保在最坏的情况下，一个事件可以在10毫秒内入队并处理。为了更深入地了解反压，我们鼓励您阅读马丁·汤普森在[http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html](http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html)上发表的以下博客文章。马丁是高性能软件开发方面的权威人士，这篇特定的博客文章是关于反压的宝贵学习资源。
- en: Applying load-control policies
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用负载控制策略
- en: Back pressure is a strategy that works well when the message producer respects
    consumers that operate at different rates and does not penalize slow consumers.
    Particularly when dealing with third-party systems, there are situations where
    applying back pressure to force the producer to slow down will not be well received.
    In these scenarios, we need to consider additional strategies that improve the
    capacity of our systems without requiring algorithmic improvements to our business
    logic.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 反压是一种策略，当消息生产者尊重以不同速率运行的消费者且不对慢速消费者进行惩罚时，这种策略效果很好。尤其是在处理第三方系统时，有时对生产者施加反压以迫使其减速可能不会得到良好的接受。在这些情况下，我们需要考虑额外的策略，以提高我们系统的容量，而无需对业务逻辑的算法进行改进。
- en: Note
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The authors have worked in the **real-time bidding** (**RTB**) space where a
    bidding system participates in auctions to bid on opportunities to display advertisements.
    In this industry, there is low tolerance for bidding systems that are unable to
    cope with the configured auction rate. Failure to respond to a high percentage
    of auctions with a bidding decision (either bid or no-bid) in a timely manner
    results in the bidding system being penalty-boxed. While in the penalty box, the
    bidding systems received a reduced auction rate. Bidding systems that remain in
    the penalty box for extended periods of time may be disallowed from participating
    in any auctions until their performance improves.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们在**实时竞价**（**RTB**）领域工作过，在这个领域，竞价系统参与拍卖，以竞标展示广告的机会。在这个行业中，对于无法应对配置的拍卖速率的竞价系统，容忍度很低。未能及时对高比例的拍卖做出竞价决定（无论是出价还是不出价），会导致竞价系统被罚入“小黑屋”。在“小黑屋”中，竞价系统会收到降低的拍卖速率。长时间留在“小黑屋”的竞价系统可能会被禁止参与任何拍卖，直到其性能改善。
- en: Let's revisit a scenario that we considered when describing back pressure to
    motivate our discussion. The precondition to apply back pressure is reaching the
    capacity of a queue. When a queue is filled, our first strategy blocks further
    additions until there is room available. Another option that we can investigate
    is to discard the event because the system is saturated. Discarding the event
    requires extra domain knowledge to understand the semantics of what it means to
    abruptly terminate processing. In the trading system domain, the trading strategy
    is only required to send back a response when a bid or an offer is made. The trading
    strategy is not required to send back a response when it does not decide to make
    either a bid or an offer. For the trading system domain, discarding an event simply
    means halting processing. In other domains, such as RTB, discarding an event implies
    halting processing and responding with a message indicating that there will not
    be a bid placed in this auction.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下我们在描述背压时考虑的场景，以激发我们的讨论。应用背压的前提是达到队列的容量。当队列满时，我们的第一种策略是阻止进一步的添加，直到有空间可用。我们可以调查的另一种选择是丢弃事件，因为系统已饱和。丢弃事件需要额外的领域知识来理解突然终止处理的意义。在交易系统领域，交易策略仅在收到出价或要约时才需要发送响应。当交易策略决定不进行出价或要约时，它不需要发送响应。对于交易系统领域，丢弃事件简单地意味着停止处理。在其他领域，例如实时竞价（RTB），丢弃事件意味着停止处理，并响应一条消息，表明不会在这个拍卖中放置出价。
- en: Additionally, it is relevant that that each event is a snapshot of the best
    bid and offer. In contrast to the snapshot, imagine if instead of `BboUpdated`,
    the trading strategy received discrete events for changes in the best bid and
    offer. This is analogous to the state-based versus operation-based CRDT operations
    that we explored. Discarding an event would mean having partial information until
    a subsequent event is received. In this scenario, it is important to work with
    domain experts and product owners to determine if and for how long operating with
    partial information is acceptable.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，值得注意的是，每个事件都是最佳出价和要约的快照。与快照相反，想象一下，如果交易策略收到最佳出价和要约变化的离散事件，而不是`BboUpdated`。这与我们所探讨的基于状态与基于操作的CRDT操作类似。丢弃事件意味着在接收到后续事件之前只能获得部分信息。在这种情况下，与领域专家和产品所有者合作，确定在何种情况下以及多长时间内使用部分信息是可接受的，这是非常重要的。
- en: 'Introducing load-control policies is another shift in thinking when working
    on high performance systems. Like the introduction of back pressure, this is another
    opportunity to reconsider assumptions that are made along the way to improve performance.
    Our lunchtime discussion with Dave provided great insight into a load-control
    policy that we can apply. Dave stated that he believes latent `BboUpdated` events
    cause more harm than good for trading strategy profitability. There are two assumptions
    we can challenge:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理高性能系统时引入负载控制策略是思维方式的另一种转变。就像引入背压一样，这也是重新考虑在提高性能过程中所做假设的另一个机会。我们与Dave的午餐讨论为我们提供了一个可以应用的负载控制策略的深刻见解。Dave表示，他认为潜在的`BboUpdated`事件对交易策略的盈利性弊大于利。我们可以挑战以下两个假设：
- en: All events must be processed
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有事件都必须被处理
- en: An event being processed must complete processing
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正在处理的事件必须完成处理
- en: We can challenge these assumptions because Dave also indicated that MVT trades
    only high-volume tickers. If a BBO update is discarded, Dave is confident that
    a new BBO update is sure to follow quickly. Let's take a deeper look at how these
    policies can be defined.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以挑战这些假设，因为Dave还指出MVT交易只涉及高成交量股票。如果丢弃BBO更新，Dave有信心新的BBO更新一定会很快跟上来。让我们更深入地看看这些策略如何定义。
- en: Rejecting work
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 拒绝工作
- en: Rejecting work is not about rejecting sprint tasks, sorry! When we discuss work
    in this context, the term refers to processing effort. In the case of the benchmarked
    trading system, the work in hand is processing a new `BboUpdated` event. Although
    we have not dived into the code yet, we do know from previous benchmarking work
    that there is a queue used to accept the `BboUpdated` events from the network
    for application-level processing. This queue is the entry point into the application,
    and it represents the first application-level opportunity to reject the event
    due to capacity constraints.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 拒绝工作并不是指拒绝冲刺任务，抱歉！在这个上下文中，当我们讨论工作时，这个术语指的是处理努力。在基准测试的交易系统中，当前的工作正在处理一个新的 `BboUpdated`
    事件。尽管我们还没有深入研究代码，但我们知道从之前的基准测试工作中，有一个队列用于从网络接受 `BboUpdated` 事件以进行应用级处理。这个队列是进入应用程序的入口点，它代表了由于容量限制而拒绝事件的第一个应用级机会。
- en: From our earlier domain investigation, we learned that to reject a request,
    it can simply be dropped on the floor without response. A trading strategy is
    only required to respond when it wishes to trade. This means that the policy of
    rejecting work can be implemented by dropping the request on the floor when the
    queue is at capacity.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们之前的领域研究中，我们了解到拒绝请求，只需简单地将其丢弃在地板上，无需响应。交易策略只有在希望交易时才需要响应。这意味着拒绝工作的策略可以通过在队列达到容量时将请求丢弃在地板上来实现。
- en: 'By inspecting the trading system source code, we see that the architecture
    is quite barebones. At start-up, a `LinkedBlockingQueue` is created to buffer
    the `BboUpdated` events, and a consumer thread is started to consume from the
    queue. The following snippet shows this logic:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查交易系统源代码，我们看到架构相当简单。在启动时，创建了一个 `LinkedBlockingQueue` 来缓冲 `BboUpdated` 事件，并启动了一个消费者线程从队列中消费。以下代码片段显示了此逻辑：
- en: '[PRE9]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As per our earlier work, we see that the work queue is sized with twenty elements
    to ensure a maximum processing latency of 10 ms. After the queue is instantiated,
    the consumer thread is created and started. The processing logic is omitted from
    this snippet, but we observe that the sole purpose of this thread is to consume
    events as they become available. The logic to add work to the queue is trivial.
    This snippet assumes a `MessageSentTimestamp` and a `BboUpdated` event are in
    lexical scope with the names, `ts` and `e`, respectively:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们之前的工作，我们看到工作队列的大小设置为二十个元素，以确保最大处理延迟为 10 毫秒。队列实例化后，创建并启动了消费者线程。此代码片段省略了处理逻辑，但我们观察到这个线程的唯一目的是消费可用的事件。将工作添加到队列的逻辑很简单。此代码片段假设
    `MessageSentTimestamp` 和 `BboUpdated` 事件分别在 `ts` 和 `e` 的名称中具有词法作用域：
- en: '[PRE10]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Our exploration of back pressure application indicated that `put` is a blocking
    call. As our intent is now to discard work,  `put` is no longer a viable strategy.
    Instead, we can make use of `offer`. As per the API documentation, `offer` returns
    a `boolean` value, indicating whether or not the element was added to the queue.
    When the queue is full, it returns false. These are exactly the semantics that
    we wish to enforce. We can modify this snippet accordingly:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对背压应用的探索表明，`put` 是一个阻塞调用。鉴于我们现在的意图是丢弃工作，`put` 已不再是可行的策略。相反，我们可以利用 `offer`。根据API文档，`offer`
    返回一个 `boolean` 值，指示元素是否被添加到队列中。当队列满时，它返回 false。这正是我们希望强制执行的语义。我们可以相应地修改此代码片段：
- en: '[PRE11]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Note
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The pattern matching in the preceding snippet provides a good entry point to
    introduce application metrics for introspection and transparency. For example,
    it is likely an interesting business metric to track how many events a trading
    system discards over time. This information may also be useful to the data science
    team for offline analysis in order to determine interesting patterns between discarded
    events and profitability. Whenever you encounter state changes, it is worth considering
    whether a metric should be recorded or whether an event should be emitted. Take
    a moment to consider state changes in your application. Are you making state changes
    available for introspection to nontechnical team members?
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个代码片段中的模式匹配为引入应用指标以进行内省和透明度提供了良好的切入点。例如，跟踪交易系统随时间丢弃的事件数量可能是一个有趣的业务指标。这些信息也可能对数据科学团队进行离线分析有用，以确定丢弃事件和盈利性之间的有趣模式。每当遇到状态变化时，都值得考虑是否应该记录指标或是否应该发出事件。花点时间考虑一下你应用程序中的状态变化。你是否让状态变化对非技术团队成员可内省？
- en: 'Performing a benchmark with 12,000 events per second and 30 trials, totaling
    360,000 events processed, yields the following result:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 以每秒 12,000 事件和 30 次试验进行基准测试，总共处理了 360,000 个事件，得到以下结果：
- en: '| **Metric** | **12,000 EPS with queue size = 20** |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| **指标** | **队列大小 = 20 的每秒 12,000 EPS** |'
- en: '| 50^(th) (median) latency | 0.0 ms |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 50^(th)（中位数）延迟 | 0.0 毫秒 |'
- en: '| 75^(th) latency | 0.0 ms |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 75^(th) 延迟 | 0.0 毫秒 |'
- en: '| 99^(th) latency | 3.0 ms |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 99^(th) 延迟 | 3.0 毫秒 |'
- en: '| 99.9^(th) latency | 11.0 ms |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 99.9^(th) 延迟 | 11.0 毫秒 |'
- en: '| 100^(th) (maximum) latency | 45.0 ms |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 100^(th)（最大）延迟 | 45.0 毫秒 |'
- en: '| Mean latency | 0.1 ms |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 平均延迟 | 0.1 毫秒 |'
- en: '| Events processed as percentage of total events | 31.49% |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 处理事件占总事件的比例 | 31.49% |'
- en: This table introduces two rows to record the observed mean latency and the percentage
    of events processed out of the 360,000 that are provided. This row is important
    because the system now rejects events, which is an example of trading throughput
    for latency improvements. The latency profile looks great in comparison to the
    first benchmarking attempt at 12,000 events per second. The maximum latency is
    four times larger than our desired maximum latency. This suggests that our performance
    model is optimistic. The higher maximum latency can be attributed to an unlucky
    garbage collection pause in combination with wrongly estimating the actual processing
    latency. Even so, the maximum latency is two orders of magnitude lower than the
    maximum latency that was observed during the first benchmarking trial. We also
    observe that 99.9% of requests have a latency less than or equal to 11 ms, which
    is within 10% of our stated maximum latency goal.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 此表引入了两行来记录观察到的平均延迟和处理的 360,000 个事件中的百分比。这一行很重要，因为系统现在拒绝事件，这是以延迟改进为代价提高交易吞吐量的一个例子。与每秒
    12,000 事件的第一次基准测试相比，延迟配置文件看起来非常好。最大延迟是我们的期望最大延迟的四倍。这表明我们的性能模型过于乐观。更高的最大延迟可以归因于不幸的垃圾回收暂停和错误估计实际处理延迟。即便如此，最大延迟比第一次基准测试观察到的最大延迟低两个数量级。我们还观察到，99.9%
    的请求的延迟小于或等于 11 毫秒，这在我们声明的最大延迟目标内 10%。
- en: 'While the latency profile looks excellent, the same cannot be said about the
    throughput. Due to our new load-control policy, only approximately 30% of the
    provided events were processed. When an event is processed, it is processed quickly,
    but unfortunately events are discarded two-thirds of the time. Another takeaway
    from performance tuning with load-control policies is that you will likely require
    multiple iterations to properly tune a policy for the right balance between trading
    throughput for latency and vice-versa. Reviewing the results of the benchmark,
    you note the mean observed latency is 0.1 ms. As a next step, you choose to calibrate
    the queue size according to the mean latency. By tuning according to the mean
    latency, you are implying that you are willing to introduce latency in exchange
    for improved throughput. Performing the arithmetic reveals the new queue size:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然延迟配置文件看起来很好，但吞吐量却不能这么说。由于我们新的负载控制策略，只有大约 30% 的事件被处理。当事件被处理时，处理速度很快，但不幸的是，三分之二的事件被丢弃。从性能调整和负载控制策略中得到的另一个教训是，你可能会需要多次迭代才能正确调整策略，以在吞吐量与延迟之间取得适当的平衡。回顾基准测试的结果，你注意到平均观察到的延迟是
    0.1 毫秒。作为下一步，你选择根据平均延迟校准队列大小。通过根据平均延迟进行调整，你暗示你愿意为了提高吞吐量而引入延迟。进行算术运算后，得到新的队列大小：
- en: '[PRE12]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'After re-running the benchmark with the new queue size, you observe the following
    results:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在重新运行带有新队列大小的基准测试后，你观察到了以下结果：
- en: '| **Metric** | **12,000 EPS with queue size = 100** |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| **指标** | **队列大小 = 100 的每秒 12,000 EPS** |'
- en: '| 50^(th) (median) latency | 3.0 ms |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 50^(th)（中位数）延迟 | 3.0 毫秒 |'
- en: '| 75^(th) latency | 5.0 ms |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 75^(th) 延迟 | 5.0 毫秒 |'
- en: '| 99^(th) latency | 19.0 ms |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 99^(th) 延迟 | 19.0 毫秒 |'
- en: '| 99.9^(th) latency | 43.0 ms |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 99.9^(th) 延迟 | 43.0 毫秒 |'
- en: '| 100^(th) (maximum) latency | 163.0 ms |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 100^(th)（最大）延迟 | 163.0 毫秒 |'
- en: '| Mean latency | 3.9 ms |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 平均延迟 | 3.9 毫秒 |'
- en: '| Events processed as percentage of total events | 92.69% |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 处理事件占总事件的比例 | 92.69% |'
- en: As expected, the latency profile lost ground when compared to the trial with
    a queue size of 20\. Except for the maximum latency, each percentile experienced
    at least a doubling in latency. The good news from this experiment is that the
    tail latencies did not experience exponential growth. The throughput picture is
    dramatically changed as well. We observe more than a doubling in throughput, yielding
    nearly 93% of all events processed. The mean latency is 39 times larger than the
    previously recorded 0.1 ms mean latency. For comparative purposes, the mean reflects
    the significant increase in median and 75^(th) percentile latencies.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，与队列大小为20的试验相比，延迟特征有所下降。除了最大延迟外，每个百分位数都至少经历了延迟的两倍增长。这个实验的好消息是尾部延迟没有经历指数增长。吞吐量图也发生了显著变化。我们观察到吞吐量增加了两倍以上，处理了所有事件的近93%。平均延迟是之前记录的0.1毫秒平均延迟的39倍。为了比较目的，平均数反映了中位数和75^(th)百分位数延迟的显著增加。
- en: 'As a final test, out of curiosity, you try doubling the throughput rate while
    retaining a queue size of 100 elements. Will the trading system crash and burn,
    will it process all the requests, or will it do something different? Running the
    benchmark produces the following results:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后的测试，出于好奇，你尝试将吞吐量率加倍，同时保持队列大小为100个元素。交易系统会崩溃吗，它会处理所有请求，还是会做些不同的事情？运行基准测试产生了以下结果：
- en: '| **Metric** | **24,000 EPS with queue size = 100** |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| **指标** | **24,000 EPS，队列大小 = 100** |'
- en: '| 50^(th) (median) latency | 7.0 ms |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 50^(th) (中位数)延迟 | 7.0 毫秒 |'
- en: '| 75^(th) latency | 8.0 ms |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 75^(th)延迟 | 8.0 毫秒 |'
- en: '| 99^(th) latency | 23.0 ms |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 99^(th)延迟 | 23.0 毫秒 |'
- en: '| 99.9^(th) latency | 55.0 ms |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 99.9^(th)延迟 | 55.0 毫秒 |'
- en: '| 100^(th) (maximum) latency | 72.0 ms |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 100^(th) (最大)延迟 | 72.0 毫秒 |'
- en: '| Mean latency | 8.4 ms |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 平均延迟 | 8.4 毫秒 |'
- en: '| Events processed as percentage of total events | 44.58% |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 处理事件占总事件的比例 | 44.58% |'
- en: The good news is that the trading system did not crash and burn. It withstood
    receiving double the throughput that previously caused second delays with a latency
    profile qualitatively similar to the same trial at 12,000 events per second. This
    suggests that the work rejection policy has made the trading system significantly
    more robust to high volumes of incoming events.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是交易系统没有崩溃。它承受了接收是之前导致第二次延迟的两倍吞吐量的压力，其延迟特征与每秒12,000个事件的相同试验质量相似。这表明拒绝工作策略使交易系统对高量级的事件输入具有显著更高的鲁棒性。
- en: The tradeoff for improved durability and acceptable processing latencies at
    higher volumes is lower throughput. These experiments revealed the value of bounding
    queue sizes, which we learned about when studying how to apply back pressure along
    with the value of rejecting work. After implementing the load-control policy and
    only tuning queue size, we are able to produce dramatically different results.
    There is definitely room for further analysis and tuning. Further analysis should
    involve product owners to weigh the throughput versus latency tradeoffs. It is
    important to remember that although the load control policy's implementation relies
    on knowledge of highly technical topics, the benefit should be measured in terms
    of business value.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在更高吞吐量下提高耐用性和可接受的延迟的权衡是降低吞吐量。这些实验揭示了限制队列大小的重要性，这是我们学习如何在应用背压的同时了解拒绝工作价值时学到的。在实施负载控制策略并仅调整队列大小后，我们能够产生显著不同的结果。肯定还有进一步分析和调整的空间。进一步的分析应涉及产品所有者，权衡吞吐量与延迟的权衡。重要的是要记住，尽管负载控制策略的实施依赖于对高度技术主题的了解，但其好处应以商业价值来衡量。
- en: Interrupting expensive processing
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 中断昂贵的处理
- en: A second idea that we can explore is to halt processing before it completes.
    This is a powerful technique to ensure processing cycles are not spent on work
    that is already stale. Consider a request that is taken from the queue and undergoes
    partial processing before being interrupted by a garbage collection cycle. If
    the garbage collection cycle takes more than a couple of milliseconds, the event
    is now stale and will likely harm trading strategy profitability. Worse, all subsequent
    events in the queue are also now more likely to be stale as well.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以探索的第二个想法是在处理完成之前停止处理。这是一种强大的技术，可以确保处理周期不会浪费在已经过时的工作上。考虑一个从队列中取出并经过部分处理但在垃圾回收周期中断的请求。如果垃圾回收周期超过几毫秒，该事件现在已过时，可能会损害交易策略的盈利能力。更糟糕的是，队列中的后续事件现在也更可能过时。
- en: 'To address this shortcoming, we can apply a technique that is analogous to
    rejecting work by imposing latency limits throughout processing. By carrying a
    timestamp that indicates when processing was started, it is possible to evaluate
    a computation''s latency at discrete points in time. Let''s consider a manufactured
    example to illustrate the idea. Consider the following processing pipeline, which
    runs arbitrary business logic for an event after journaling the event and updating
    metrics:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个不足，我们可以应用一种类似于通过在整个处理过程中施加延迟限制来拒绝工作的技术。通过携带一个表示处理开始时间的戳记，我们可以在不同的时间点评估计算的延迟。让我们考虑一个制造出的例子来说明这个想法。考虑以下处理流程，它在记录事件并更新指标后，为事件运行任意业务逻辑：
- en: '[PRE13]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'To avoid processing latent events, we may write logic similar to the following:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免处理潜伏事件，我们可能编写类似于以下逻辑的代码：
- en: '[PRE14]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this snippet, a `hasEventProcessingExpiryExpired` method is introduced to
    branch processing, which is based on time. The implementation of this method is
    omitted, but you can imagine that system time is queried and compared to a known
    and allowed processing duration (for example, 5 ms). While this approach accomplishes
    our goal of interrupting latent event processing, the code is now cluttered with
    multiple concerns. Even in this trivial example, it becomes more challenging to
    follow the sequence of processing steps.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个片段中，引入了一个`hasEventProcessingExpiryExpired`方法来分支处理，这是基于时间的。这个方法的实现被省略了，但你可以想象系统时间被查询并与已知和允许的处理持续时间（例如，5
    ms）进行比较。虽然这种方法实现了我们中断潜伏事件处理的目标，但代码现在被多个关注点所杂乱。即使在这样一个简单的例子中，也变得更加难以追踪处理步骤的顺序。
- en: The pain point with this code is that the business logic is intertwined with
    the cross-cutting concern of interrupting latent processing. One way to improve
    the readability of this code is to separate the description of what is being accomplished
    from how this description is executed. There is a construct in functional programming,
    known as the free monad that can help us do exactly this. Let's take a deeper
    look at the free monad to see how we can use it to improve the trading strategy's
    performance.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的痛点在于业务逻辑与中断潜伏处理的横切关注点交织在一起。提高代码可读性的一个方法是将所完成工作的描述与如何执行这种描述分开。在函数式编程中有一个结构，称为自由单子，可以帮助我们做到这一点。让我们更深入地了解自由单子，看看我们如何使用它来提高交易策略的性能。
- en: Free monads
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自由单子
- en: 'Monads and their mathematical underpinnings in the subject of category theory
    are dense subjects deserving a dedicated exploration. As your sprint ends tomorrow
    and you want to deliver improved trading strategy performance, we instead provide
    a practitioner''s perspective on free monads to show how you can use them to address
    a real-world problem. To demonstrate the power of applying free monads to our
    problem, we start by showing the end result and work backwards to develop an intuition
    about how free monads work. To begin, let''s consider the sequence of processing
    steps that are required for a trading strategy to process a `BboUpdated` event
    once picked up from the work queue:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在范畴论主题中，单子及其数学基础是密集的主题，值得专门探索。随着你的冲刺明天结束，你想要交付改进的交易策略性能，我们提供一个实践者的视角来展示你如何使用它们来解决现实世界的问题。为了展示将自由单子应用于我们问题的力量，我们首先展示最终结果，然后回溯以发展对自由单子如何工作的直觉。首先，让我们考虑交易策略从工作队列中选中`BboUpdated`事件后所需的处理步骤序列：
- en: '[PRE15]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'There are three steps that happen before the trading strategy makes a trading
    decision. If the trading decision is to submit a bid or an offer, the decision
    is sent to the exchange. `strategy` is an implementation of the `TradingStrategy`
    trait, which looks like the following:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在交易策略做出交易决策之前，有三个步骤发生。如果交易决策是提交一个出价或报价，决策将被发送到交易所。"strategy"是`TradingStrategy`特质的实现，其外观如下：
- en: '[PRE16]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Next, let's look at how we can translate this processing sequence into the free
    monad and also add in early termination logic.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看我们如何将这个处理序列转换为自由单子，并添加早期终止逻辑。
- en: Describing a program
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 描述一个程序
- en: 'To build our new version of the trading strategy pipeline, we use the Scalaz-provided
    free monad implementation, `scalaz.Free`. The end result of our efforts to use
    the free monad in conjunction with a domain-specific language (DSL) for simpler
    construction looks like the following:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建我们新的交易策略管道版本，我们使用 Scalaz 提供的自由单子实现 `scalaz.Free`。我们使用自由单子结合领域特定语言 (DSL)
    以简化构建的努力的结果如下所示：
- en: '[PRE17]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Recall that our first attempt at implementing short-circuiting logic involved
    a series of if-statements. Instead of if-statements, the free monad-based snippet
    shows that the processing pipeline can now be defined as a for-comprehension.
    This approach removes the branching statements, making it simpler to understand
    what is happening. Without seeing how the DSL is made, you likely can already
    infer what this pipeline will do. For example, you likely inferred that if `journalEvent`
    takes more than 10 ms to execute, then the processing is halted and neither `performPreTradeBalanceChecks`
    nor `MakeTradingDecision` will be invoked.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，我们第一次尝试实现短路逻辑涉及一系列的 if 语句。而不是 if 语句，基于自由单子的代码片段显示，处理管道现在可以被定义为 for-comprehension。这种方法消除了分支语句，使得理解正在发生的事情变得更加简单。在不看到
    DSL 如何构建的情况下，你很可能已经推断出这个管道将做什么。例如，你很可能推断出如果 `journalEvent` 执行时间超过 10 毫秒，则处理将停止，并且不会调用
    `performPreTradeBalanceChecks` 或 `MakeTradingDecision`。
- en: 'The construction of the pipeline is only one half of the story. Underlying
    the implementation of this for-comprehension is the free monad. Creating a free
    monad involves two parts:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 管道构建只是故事的一半。在这个 for-comprehension 的实现背后，是自由单子。创建一个自由单子涉及两个部分：
- en: Building a description of a program
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建程序描述
- en: Writing an interpreter to execute the description
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写解释器以执行描述
- en: The for-comprehension represents our description of a program. It is a description
    of how to process the `BboUpdated` events that also defines execution delay constraints.
    To execute this description, we must build an interpreter.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: for-comprehension 代表我们对程序的描述。它是对如何处理 `BboUpdated` 事件的描述，同时也定义了执行延迟约束。为了执行这个描述，我们必须构建一个解释器。
- en: Building an interpreter
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建解释器
- en: 'Our interpreter looks like the following:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的解释器如下所示：
- en: '[PRE18]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The `foldRun` method is a method that is provided by `Free` to execute the
    description of the program that we wrote. Analogous to the signature of `foldLeft`, `foldRun`
    accepts a value representing an initial state, a curried function that accepts
    the current state, and the next processing step from our processing pipeline.
    The next processing step is represented as an ADT named `Thunk` with the following
    members:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '`foldRun` 方法是 `Free` 提供的一个方法，用于执行我们编写的程序描述。类似于 `foldLeft` 的签名，`foldRun` 接受一个表示初始状态的值，一个接受当前状态的
    curried 函数，以及来自我们的处理管道的下一个处理步骤。下一个处理步骤由一个名为 `Thunk` 的 ADT 表示，具有以下成员：'
- en: '[PRE19]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The `Thunk` algebra defines the possible operations that can be transcribed
    into the free monad. The pipeline that we previously showed is constructed by
    composing together combinations of the `Thunk` members. This pipeline hides the
    construction behind the DSL to eliminate verbosity and to improve readability.
    The following table maps each processing step to its associated `Thunk`:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '`Thunk` 代数定义了可以转录到自由单子中的可能操作。我们之前展示的管道是通过组合 `Thunk` 成员的组合构建的。这个管道隐藏了 DSL 背后的构建，以消除冗余并提高可读性。以下表格将每个处理步骤映射到其关联的
    `Thunk`：'
- en: '| **Step DSL** | **Thunk** |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| **步骤 DSL** | **Thunk** |'
- en: '| `StartWith` | `StartProcessing` |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| `开始` | `开始处理` |'
- en: '| `Step` | `Timed` |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| `步骤` | `计时` |'
- en: '| `MakeTradingDecision` | `TradingDecision` |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| `做出交易决策` | `交易决策` |'
- en: Returning to the curried `foldRun` function, we see that the interpreter pattern
    matches to determine which `Thunk` is the next processing step. These pattern
    match statements are how the interpreter applies the behavior that is described
    by our program's description. `StartProcessing` and `Timed` use system time to
    determine which method to execute, based on the provided millisecond expiry (`LimitMs`). `StartProcessing`
    and `TradingDecision` require states from the outside world to support execution.
    For `StartProcessing`, the `BboUpdated` event from the work queue must be supplied,
    and for `TradingDecision`, a `Strategy` must be provided to yield a trading decision.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 回到柯里化的`foldRun`函数，我们看到解释器模式匹配以确定下一个处理步骤是哪个`Thunk`。这些模式匹配语句是解释器应用我们程序描述中描述的行为的方式。`StartProcessing`和`Timed`使用系统时间来确定根据提供的毫秒到期时间（`LimitMs`）执行哪个方法。`StartProcessing`和`TradingDecision`需要来自外部世界的状态来支持执行。对于`StartProcessing`，必须提供工作队列中的`BboUpdated`事件，而对于`TradingDecision`，必须提供一个`Strategy`以产生交易决策。
- en: The return value of `foldRun` is a tuple of the accumulated state, which is
    discarded in the snippet, and the return value of interpreting the free monad.
    The return value of executing the sequence of `Thunk`s that is defined by `pipeline`
    is `\/[BboProcessingFailure, Option[Either[Bid,Offer]]]`. The return value is
    a disjunction to account for failure scenarios, which can occur as part of the
    business logic or because the processing expiry expired. These failures are represented
    with an ADT of type `BboProcessingFailure`. The right side of the disjunction
    matches the return type of `TradingStrategy`, indicating that completing all steps
    in `pipeline` yields a trading decision. The final step is to fold over the trading
    decision to record processing latency when the pipeline was completed (that is,
    a `\/-` was returned) and to conditionally send the order to the exchange.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`foldRun`的返回值是一个累积状态的元组，该元组在片段中被丢弃，以及解释自由单子的返回值。由`pipeline`定义的`Thunk`序列的执行返回值是`\/[BboProcessingFailure,
    Option[Either[Bid,Offer]]]`。这个返回值是一个析取，以处理可能作为业务逻辑的一部分发生或因为处理到期时间已过期的失败场景。这些失败用类型为`BboProcessingFailure`的ADT表示。析取的右侧与`TradingStrategy`的返回类型匹配，表示完成`pipeline`中的所有步骤会产生一个交易决策。最后一步是对交易决策进行折叠，以记录当管道完成时的处理延迟（即返回了`\/-`），并条件性地向交易所发送订单。'
- en: At this juncture, the intuition that you should have developed is that we have
    separated the description of what we would like to have happen from how it happens.
    The free monad allows us to do this by first creating a description of our program,
    and then secondly, building an interpreter to execute the instructions that are
    provided by the description. As a concrete example, our program description in
    `pipeline` is not bogged down with providing a strategy for how to implement early
    termination. Instead, it only describes that certain steps in the processing sequence
    are subject to time constraints. The interpreter provided to `foldRun` enforces
    this constraint using system time. Having built a functioning version of the trading
    strategy pipeline, let's benchmark again to see what effect our changes had.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你应该已经形成的直觉是我们已经将我们希望发生的事情的描述与它如何发生的方式分离开来。自由单子允许我们通过首先创建我们程序的描述，然后其次构建一个解释器来执行由描述提供的指令来实现这一点。作为一个具体的例子，我们的`pipeline`程序描述并没有被如何实现早期终止的策略所拖累。相反，它只描述了处理序列中的某些步骤受到时间限制。提供给`foldRun`的解释器使用系统时间来强制执行这个限制。在构建了交易策略管道的运行版本之后，让我们再次进行基准测试，看看我们的变化产生了什么效果。
- en: Benchmarking the new trading strategy pipeline
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基准测试新的交易策略管道
- en: 'Running the benchmark at 12,000 and 24,000 events per second using the new
    trading strategy pipeline yields the following results. The results columns show
    two values per row. The value before the slash is the result from running with
    the new implementation that provides early termination. The value after the slash
    is the copied over result from running without the early termination for comparative
    purposes:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 使用新的交易策略管道以每秒12,000和24,000个事件运行基准测试，得到以下结果。结果列每行显示两个值。斜杠前的值是使用提供早期终止的新实现运行的结果。斜杠后的值是用于比较目的而复制的没有早期终止的运行结果：
- en: '| **Metric** | **12,000 EPS with queue size = 100** | **24,000 EPS with queue
    size = 100** |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| **指标** | **队列大小为100时的12,000 EPS** | **队列大小为100时的24,000 EPS** |'
- en: '| 50^(th) (median) latency | 1.0 ms / 3.0 ms | 6.0 ms / 7.0 ms |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| 第50百分位（中位数）延迟 | 1.0 ms / 3.0 ms | 6.0 ms / 7.0 ms |'
- en: '| 75^(th) latency | 3.0 ms / 5.0 ms | 7.0 ms / 8.0 ms |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| 75^(th) 延迟 | 3.0 ms / 5.0 ms | 7.0 ms / 8.0 ms |'
- en: '| 99^(th) latency | 7.0 ms / 19.0 ms | 8.0 ms / 23.0 ms |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| 99^(th) 延迟 | 7.0 ms / 19.0 ms | 8.0 ms / 23.0 ms |'
- en: '| 99.9^(th) latency | 10.0 ms / 44.0 ms | 16.0 ms / 55.0 ms |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 99.9^(th) 延迟 | 10.0 ms / 44.0 ms | 16.0 ms / 55.0 ms |'
- en: '| 100^(th) (maximum) latency | 197.0 ms / 163.0 ms | 26.0 ms / 72.0 ms |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 100^(th) (最大)延迟 | 197.0 ms / 163.0 ms | 26.0 ms / 72.0 ms |'
- en: '| Mean latency | 2.0 ms / 3.9 ms | 6.0 ms / 8.4 ms |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 平均延迟 | 2.0 ms / 3.9 ms | 6.0 ms / 8.4 ms |'
- en: '| Events processed as percentage of total events | 90.43% / 92.69% | 36.62%
    / 44.58% |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| 处理事件占总事件的比例 | 90.43% / 92.69% | 36.62% / 44.58% |'
- en: 'From a latency perspective, early termination appears to be a clear win. Excluding
    maximum latency, early termination yielded lower latencies at each percentile.
    For example, at 12,000 events per second, half of all requests are processed in
    one-third of the time, a mere millisecond, as compared to the median when processing
    is not interrupted. At 12,000 events per second, the observed maximum latency
    increases, which is likely indicative of garbage collection pauses after the early
    termination checks. There are two possible improvements to make to our implementation:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 从延迟角度来看，提前终止似乎是一个明显的胜利。排除最大延迟，提前终止在每个百分位上产生了更低的延迟。例如，在每秒12,000个事件的情况下，所有请求中有一半在一三分之一的时间内处理完成，仅用了1毫秒，而与处理未中断时的中位数相比。在每秒12,000个事件的情况下，观察到的最大延迟增加，这可能是提前终止检查后的垃圾回收暂停的指示。我们可以对我们的实现进行两项可能的改进：
- en: Check the processing duration after invoking `performPreTradeBalanceChecks`
    before the `TradingStrategy` is executed
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在执行`TradingStrategy`之前，调用`performPreTradeBalanceChecks`之前检查处理持续时间
- en: Check the processing duration after the trading decision is created
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在交易决策创建后检查处理持续时间
- en: In both scenarios, processing could be interrupted if the latency exceeds a
    threshold. It is straightforward to see that these two steps of the processing
    require attention to reduce the maximum latency because of the clear separation
    of concerns provided by our free monad implementation. Consider how much more
    challenging it would be to reason about execution with the pipeline and early
    termination logic intertwined.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，如果延迟超过阈值，处理可以被中断。很容易看出，由于我们的免费单子实现提供的明确关注点分离，这两个处理步骤需要关注以减少最大延迟。考虑一下，如果管道和提前终止逻辑交织在一起，推理执行会多么具有挑战性。
- en: From a throughput perspective, we see a reduction in throughput in both trials.
    The throughput drop arises from the latent events that are discarded. Here, we
    again see the tradeoff between throughput and latency. We sacrificed throughput
    for a better latency profile. Arguably, it is a worthy tradeoff because the higher
    throughput included stale events, which are more likely to yield trading losses.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 从吞吐量角度来看，我们在两次试验中都看到了吞吐量的下降。吞吐量下降是由于被丢弃的潜在事件引起的。在这里，我们再次看到了吞吐量和延迟之间的权衡。我们为了更好的延迟特性牺牲了吞吐量。可以说，这是一个值得的权衡，因为更高的吞吐量包括了过时的事件，这些事件更有可能产生交易损失。
- en: A Task interpreter
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个任务解释器
- en: Our efforts so far have yielded a significantly improved latency profile while
    sacrificing throughput. What if we could have the best of both worlds? An improved
    latency profile with higher throughput would be ideal but seems to be out of reach.
    One strategy for improved throughput is to introduce concurrency. Perhaps, we
    can make the trading strategy execution concurrent to take advantage of hardware
    with multiple cores. Before diving in, you ping Gary, your colleague who helped
    you discover the lineage of the order book implementations. You double-check with
    Gary to confirm that MVT strategies are thread-safe. He responds with a thumbs
    up emoji, which gives us the green light to parallelize execution of trading strategies.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们到目前为止的努力已经显著改善了延迟特性，而牺牲了吞吐量。如果我们能够两者兼得会怎样？一个改善了延迟特性且具有更高吞吐量的特性将是理想的，但似乎难以实现。提高吞吐量的一个策略是引入并发。也许，我们可以使交易策略执行并发，以利用具有多个核心的硬件。在深入之前，你联系了你的同事Gary，他帮助你发现了订单簿实现的血统。你与Gary再次确认MVT策略是线程安全的。他回应了一个点赞表情符号，这给了我们并行化交易策略执行的绿灯。
- en: 'In our exploration of the free monad thus far, we have seen the relationship
    between the program description and the interpreter. The program description,
    which is represented with the `Thunk` ADT, is agnostic to the interpreter. This
    statement represents the essence of the free monad and is best stated by Adam
    Warski in his excellent free monad blog post at [https://softwaremill.com/free-monads/](https://softwaremill.com/free-monads/).
    The semantics of the term "free" in free monad is that the monad is free to be
    interpreted in any way. We will see this idea in practice by demonstrating that
    we can transform our existing interpreter to a `Task` interpreter. To do this,
    we must map `Thunk` to `Task`. Scalaz provides a trait to express this mapping,
    called `NaturalTransformation`, with a type alias of `~>`. The following snippet
    shows how to map from `Thunk` to `Task` via a `NaturalTransformation`:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们迄今为止对自由单子的探索中，我们已经看到了程序描述与解释器之间的关系。程序描述，用`Thunk` ADT表示，对解释器是无关的。这个陈述代表了自由单子的本质，由Adam
    Warski在他的优秀的自由单子博客文章中最好地表述，见[https://softwaremill.com/free-monads/](https://softwaremill.com/free-monads/)。在自由单子中，“自由”这个术语的语义是单子可以自由地以任何方式被解释。我们将通过演示我们可以将现有的解释器转换为一个`Task`解释器来看到这个想法在实践中的应用。为此，我们必须将`Thunk`映射到`Task`。Scalaz提供了一个特性来表示这种映射，称为`NaturalTransformation`，其类型别名为`~>`。以下代码片段显示了如何通过`NaturalTransformation`将`Thunk`映射到`Task`：
- en: '[PRE20]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The trait defines one method to be implemented that is provided a `Thunk` and
    returns a `Task`. As with our previous interpreter within `foldRun`, the interpreter
    requires the same state to provide the `BboUpdated` event, `MessageSentTimestamp`,
    and `TradingStrategy`. We use pattern matching to handle the mapping of each ADT
    member. Note the usage of `Task.suspend`, which has the following signature:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 该特性定义了一种实现方法，该方法接受一个`Thunk`并返回一个`Task`。与我们在`foldRun`中的先前的解释器一样，解释器需要相同的状态来提供`BboUpdated`事件、`MessageSentTimestamp`和`TradingStrategy`。我们使用模式匹配来处理每个ADT成员的映射。注意`Task.suspend`的使用，它具有以下签名：
- en: '[PRE21]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In contrast to `Task.now`, `suspend` defers evaluation of the argument. This
    is necessary because the interpreter has the side-effect of checking the system
    clock when invoking `hasProcessingTimeExpired`. Using `suspend` defers the call
    to the system clock until the `Task` is run instead of executing at `Task` construction
    time.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 与`Task.now`不同，`suspend`将参数的评估推迟。这是必要的，因为解释器在调用`hasProcessingTimeExpired`时具有检查系统时钟的副作用。使用`suspend`将系统时钟的调用推迟到`Task`运行时，而不是在`Task`构造时执行。
- en: 'A second interesting implementation note is the usage of `Task.fork` when translating `TradingDecision`.
    Here is the introduction of concurrency to the trading strategy pipeline. With
    our transformation complete, the remaining step is to run the interpreter. Fortunately, `Free`
    provides a method analogous to `foldRun` that accepts a `NaturalTransformation`
    named `foldMap`. The following snippet shows how the existing `Thunk` pipeline
    can be executed using `Task`:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个有趣的实现注意事项是当转换`TradingDecision`时使用`Task.fork`。这是将并发引入交易策略管道的介绍。随着我们的转换完成，接下来的步骤是运行解释器。幸运的是，`Free`提供了一个类似于`foldRun`的方法，它接受一个名为`foldMap`的`NaturalTransformation`。以下代码片段显示了如何使用`Task`执行现有的`Thunk`管道：
- en: '[PRE22]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Invoking `foldMap` applies the transformation, yielding a `Task`. The `Task`
    is executed asynchronously via `unsafePerformAsync`. Let''s run a benchmark at
    24,000 events per second with our new implementation and compare the results against
    the `foldRun` interpreter:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 调用`foldMap`应用转换，产生一个`Task`。该`Task`通过`unsafePerformAsync`异步执行。让我们用我们的新实现以每秒24,000个事件的速度运行基准测试，并将结果与`foldRun`解释器进行比较：
- en: '| **Metric** | **24,000 EPS with queue size = 100** |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| **指标** | **队列大小为100时的24,000 EPS** |'
- en: '| 50^(th) (median) latency | 0.0 ms / 6.0 ms |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| 第50百分位（中位数）延迟 | 0.0 ms / 6.0 ms |'
- en: '| 75^(th) latency | 0.0 ms / 7.0 ms |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 第75百分位延迟 | 0.0 ms / 7.0 ms |'
- en: '| 99^(th) latency | 4.0 ms / 8.0 ms |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| 第99百分位延迟 | 4.0 ms / 8.0 ms |'
- en: '| 99.9^(th) latency | 13.0 ms / 16.0 ms |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 第99.9百分位延迟 | 13.0 ms / 16.0 ms |'
- en: '| 100^(th) (maximum) latency | 178.0 ms / 26.0 ms |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 第100百分位（最大值）延迟 | 178.0 ms / 26.0 ms |'
- en: '| Mean latency | 0.13 ms / 6.0 ms |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 平均延迟 | 0.13 ms / 6.0 ms |'
- en: '| Events processed as percentage of total events | 96.60 % / 36.62% |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 处理的事件占总事件的比例 | 96.60 % / 36.62% |'
- en: Running the `Task` interpreter on a computer with four cores yields a substantive
    difference in latency and performance. From a throughput perspective, nearly all
    events can be processed, in contrast to the 36% processing rate previously. The
    throughput improvement is indicative of the extra capacity gained by use of `Task.fork`,
    which is providing runtime parallelism. We also observe a significant reduction
    in lower percentile latencies, which can also be attributed to the use of `Task.fork`
    on a multicore machine. Interestingly, the higher percentile latencies remain
    quite similar. As we previously noted, this is because we are still not defending
    against latent events at the end of the processing pipeline. The takeaway from
    this benchmark is that judicious usage of `Task` yields double the throughput
    with an improved latency profile. This is an exciting result to have achieved
    by treating the trading strategy as a black box and only changing how the system
    interacts with the trading strategy.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在具有四个核心的计算机上运行`Task`解释器，在延迟和性能方面产生了实质性的差异。从吞吐量角度来看，几乎所有事件都可以被处理，与之前的36%处理率形成对比。吞吐量的提升表明，通过使用`Task.fork`获得了额外的容量，这提供了运行时并行性。我们还观察到低百分位延迟的显著减少，这也可以归因于在多核机器上使用`Task.fork`。有趣的是，高百分位延迟仍然相当相似。正如我们之前指出的，这是因为我们仍然没有在处理管道的末尾防御潜在事件。从这个基准测试中得到的启示是，合理使用`Task`可以在提高延迟特性的同时，将吞吐量提高一倍。这是一个通过将交易策略视为黑盒，并且只改变系统与交易策略交互的方式所取得的令人兴奋的结果。
- en: Exploring free monads further
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进一步探索免费单子
- en: Our exploration into free monads has deliberately avoided a deep dive into monads
    and instead focused on showing you the practical results from using this approach.
    With free monads, we have shown you that we can separate the description of a
    program from its execution. This allowed us to cleanly introduce logic to interrupt
    the processing of latent events. We also added concurrency to the processing pipeline
    without affecting its construction by writing a `Task` interpreter. The core business
    logic remains pure while retaining excellent runtime characteristics. Here, we
    see the salient point about the free monad. The description of our program is
    a value and the interpreter is responsible for handling side-effects.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对免费单子的探索故意避免了深入探讨单子，而是专注于展示使用这种方法带来的实际结果。使用免费单子，我们向你展示了我们可以将程序的描述与其执行分离。这使我们能够干净地引入逻辑来中断潜在事件的处理。我们还通过编写`Task`解释器来向处理管道中添加并发性，而不会影响其构建。核心业务逻辑保持纯净，同时保留了优秀的运行时特性。在这里，我们看到了免费单子的显著特点。我们程序的描述是一个值，而解释器负责处理副作用。
- en: At this point, you can see the benefits of applying this technique, but you
    are still in the dark about the underlying mechanisms. A full treatment of monads
    is beyond the scope of our exploration. By studying the source code that is associated
    with these examples and exploring other learning sources, you will gain a deeper
    understanding of how to apply this technique in your own systems. We recommend
    reading Adam Warski's aforementioned blog post in-depth and reviewing the presentation
    linked from another free monad example built by Ken Scrambler that is available
    at [https://github.com/kenbot/free](https://github.com/kenbot/free). To get a
    deeper understanding of monads, we encourage you to read, *Functional Programming
    in Scala* by Paul Chiusano and Rúnar Bjarnason.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你可以看到应用这项技术的益处，但你仍然对背后的机制一无所知。对单子（monads）的全面探讨超出了我们探索的范围。通过研究与这些示例相关的源代码，以及探索其他学习资源，你将更深入地理解如何在你的系统中应用这项技术。我们建议深入阅读Adam
    Warski之前提到的博客文章，并回顾从另一个由Ken Scrambler构建的免费单子示例中链接的演示，该示例可在[https://github.com/kenbot/free](https://github.com/kenbot/free)找到。为了更深入地理解单子，我们鼓励你阅读Paul
    Chiusano和Rúnar Bjarnason的《Scala函数式编程》。
- en: Summary
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we focused on high-performance system design in a more language-agnostic
    context. We introduced distributed architectures and explained how they can help
    scale a platform. We presented some of the challenges that such a paradigm involves,
    and we focused on solving the problem of shared state inside a cluster. We used
    CRDTs to implement efficient and performant synchronization among the nodes of
    a cluster. Using these data types, we were able to simplify our architecture and
    avoid creating a bottleneck by eliminating the need for a standalone service that
    is dedicated to storing the shared state. We also kept the latency low by avoiding
    remote calls on the critical path.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们关注了在更语言无关的上下文中进行的高性能系统设计。我们介绍了分布式架构，并解释了它们如何帮助扩展平台。我们提出了一些这种范式涉及到的挑战，并专注于解决集群内部共享状态的问题。我们使用CRDTs（冲突检测与修复类型）在集群的节点之间实现高效且性能良好的同步。使用这些数据类型，我们简化了我们的架构，并通过消除对存储共享状态的独立服务的需求来避免创建瓶颈。我们还通过避免在关键路径上进行远程调用，将延迟保持在较低水平。
- en: In the second part of this chapter, we analyzed how queues impact latency, and
    how we can apply load control policies to control latency. By benchmarking the
    trading strategy pipeline, we discovered the importance of applying back pressure
    and bounding queue sizes in order to reason about maximum latency. Unbounded queues
    will eventually lead to disastrous production performance. The formal name for
    the study of queues is a branch of mathematics known as queueing theory. Queueing
    theory, like monads, is a topic that deserves a more formal treatment. We focused
    on using empirical observations to drive improvements. Studying queueing theory
    will provide you with a stronger theoretical background and the ability to build
    models for system performance.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的第二部分，我们分析了队列如何影响延迟，以及我们如何应用负载控制策略来控制延迟。通过基准测试交易策略管道，我们发现应用背压和限制队列大小对于推理最大延迟的重要性。无界队列最终会导致灾难性的生产性能。队列研究的正式名称是数学的一个分支，称为排队论。排队论，就像单子一样，是一个值得更正式处理的话题。我们专注于使用经验观察来推动改进。研究排队论将为您提供更强的理论基础和构建系统性能模型的能力。
- en: We extended the policy of rejecting work to interrupting work that is taking
    too long. In doing so, we explored a new functional programming technique in the
    form of the free monad. The free monad allowed us to maintain clean business logic
    describing what the pipeline does without focusing on how the pipeline accomplishes
    its goals. This separation of concerns enabled us to also add concurrency to the
    pipeline without complicating the pipeline description. The principles that we
    discussed enable you to write high-throughput and low-latency systems that remain
    robust when the system is at capacity, while retaining an emphasis on functional
    design.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将拒绝工作的策略扩展到中断耗时过长的任务。在这样做的时候，我们探索了一种新的函数式编程技术，即自由单子。自由单子允许我们保持干净的业务逻辑，描述管道做什么，而不关注管道如何实现其目标。这种关注点的分离使我们能够在不复杂化管道描述的情况下向管道添加并发性。我们讨论的原则使您能够编写高吞吐量和低延迟的系统，当系统达到容量时，这些系统能够保持稳健，同时仍然强调函数式设计。
