- en: Container and Cloud Environments with Java EE
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java EE的容器和云环境
- en: The last years have shown a lot of interest in container as well as cloud technology.
    The vast majority of companies building software is at least considering migrating
    environments to these modern approaches. In all of my recent projects these technologies
    have been a point of discussion. Especially, introducing container orchestration
    technologies greatly affects the way how applications are run.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 过去几年，对容器以及云技术的兴趣很大。绝大多数构建软件的公司至少在考虑将这些环境迁移到这些现代方法。在我最近的所有项目中，这些技术都是讨论的焦点。特别是，引入容器编排技术极大地影响了应用程序的运行方式。
- en: What are the benefits of container technologies? And why should companies care
    about the cloud? It seems a lot of these concerns are used as buzzwords, as a
    *silver bullet* approach. This chapter will examine the motivations behind these
    technologies. We will also see if and how the Java EE platform is ready for this
    new world.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 容器技术的益处是什么？为什么公司应该关注云计算？似乎很多这些担忧都被用作流行语，作为一种*银弹*方法。本章将探讨这些技术背后的动机。我们还将看看Java
    EE平台是否为这个新世界做好了准备。
- en: 'This chapter will cover:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖：
- en: How infrastructure as code supports operations
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础设施即代码如何支持运营
- en: Container technologies and orchestration
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器技术和编排
- en: Why especially Java EE fits these technologies
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么Java EE特别适合这些技术
- en: Cloud platforms and their motivations
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云平台及其动机
- en: 12-factor, cloud native enterprise applications
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 12因素，云原生企业应用程序
- en: Motivations and goals
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动机与目标
- en: What are the motivations behind containers, container orchestration, and cloud
    environments? Why do we see such momentum in this area?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 容器、容器编排和云环境背后的动机是什么？为什么我们在这个领域看到如此强劲的动力？
- en: Traditionally, enterprise application deployment worked something like the following.
    Application developers implemented some business logic and built the application
    into a packaged artifact. This artifact was deployed manually on an application
    server that was managed manually as well. During deployment or reconfiguration
    of the server, the application usually faced a downtime.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，企业应用程序部署的工作方式如下。应用程序开发者实现了某些业务逻辑并将应用程序构建成一个打包的工件。这个工件被手动部署到由人工管理的应用程序服务器上。在服务器部署或重新配置期间，应用程序通常面临停机时间。
- en: Naturally, this approach is a rather high-risk process. Human, manual tasks
    are error-prone and are not guaranteed to be executed in the same manner each
    and every time. Humans are rather bad at executing automated, repetitive work.
    Processes such as installing application servers, operating systems and servers
    in general, require precise documentation, especially for future reproducibility.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，这种方法是一个相当高风险的过程。人工任务容易出错，并且不能保证每次都以相同的方式进行执行。人类在执行自动化、重复性工作方面相当糟糕。例如安装应用程序服务器、操作系统和服务器等过程，需要精确的文档，特别是为了未来的可重复性。
- en: In the past, tasks for operation teams typically were ordered using a ticket
    system and performed manually. By doing so, installation and configuration of
    servers held the risk of transforming the system into a non-reproducible state.
    Setting up a new environment identical to the current one required a lot of manual
    investigation.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去，操作团队的典型任务是使用票务系统进行订购并手动执行。这样做，服务器安装和配置的风险是将系统转变为不可重复的状态。设置一个与当前环境相同的新环境需要大量的手动调查。
- en: Operational tasks need to be automated and reproducible. Installing a new server,
    operating system or runtime should always execute in exactly the same manner.
    Automated processes not only speed up the execution but introduce transparency,
    revealing which precise steps have been executed. Reinstalling environments should
    produce exactly the same runtime including all configuration and setup as before.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 操作任务需要自动化和可重复。安装新的服务器、操作系统或运行时应该始终以完全相同的方式进行执行。自动化流程不仅加快了执行速度，还引入了透明度，揭示了哪些精确步骤已被执行。重新安装环境应该产生与之前完全相同的运行时，包括所有配置和设置。
- en: This also includes deployment and configuration of the application. Instead
    of manually building and shipping applications, Continuous Integration servers
    are in charge of building software in an automated, reliable, and reproducible
    way. CI servers act as *golden source of truth* for software builds. The artifacts
    produced there are deployed on all involved environments. A software artifact
    is built once, on the Continuous Integration server, and then verified in integration
    and end-to-end tests, until it ends up in production. The same application binary
    that is deployed to production is therefore reliably tested upfront.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这也包括应用程序的部署和配置。而不是手动构建和分发应用程序，持续集成服务器负责以自动化、可靠和可重复的方式构建软件。CI服务器作为软件构建的“黄金真相”来源。在那里产生的工件被部署到所有相关环境中。软件工件在持续集成服务器上构建一次，然后通过集成和端到端测试进行验证，直到最终进入生产环境。因此，部署到生产环境的同一应用程序二进制文件在部署前已经得到了可靠的测试。
- en: Another very important aspect is to be explicit in the software versions that
    are being used. This includes all used software dependencies, from the application
    server and Java runtime, down to the operating system and its binaries. Rebuilding
    or reinstalling software should result in exactly the same state each and every
    time. Software dependencies are a complex subject which comes with a lot of possibilities
    for potentials errors. Applications are tested to work properly on specific environments
    with specific configurations and dependencies. In order to guarantee that the
    application will work as expected, it is shipped in exactly that configuration
    that has been verified before.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个非常重要的方面是明确使用软件的版本。这包括所有使用的软件依赖项，从应用程序服务器和Java运行时，到操作系统及其二进制文件。重新构建或重新安装软件应每次都产生完全相同的状态。软件依赖项是一个复杂的话题，伴随着许多潜在错误的可能性。应用程序被测试以在具有特定配置和依赖项的特定环境中正常工作。为了确保应用程序按预期工作，它被以在之前已验证的配置中发货。
- en: This aspect also implies that test and staging environments which are used to
    verify the application's behavior should be as similar to production as possible.
    In theory this constraint sounds reasonable. From experience the used environments
    vary quite a lot from production in terms of software versions being used, network
    configuration, databases, external systems, number of server instances, and so
    on. In order to test applications properly these differences should be erased
    as much as possible. In section *Containers* we will see how container technology
    supports us here.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方面也意味着用于验证应用程序行为的测试和预演环境应尽可能接近生产环境。从理论上讲，这个限制听起来是合理的。从经验来看，所使用的环境在软件版本、网络配置、数据库、外部系统、服务器实例数量等方面与生产环境差异很大。为了正确测试应用程序，这些差异应尽可能消除。在“容器”部分，我们将看到容器技术如何在这里提供支持。
- en: Infrastructure as code
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础设施即代码
- en: A logical conclusion to enable reproducible environments is to make use of **infrastructure
    as code** (**IaC**). The idea is that all required steps, configuration, and versions
    are explicitly defined as code. These code definitions are directly used to configure
    the infrastructure. Infrastructure as code can be implemented in a procedural
    form, such as scripts, or in a declarative way. The latter approach specifies
    the desired target state and is executed using additional tooling. No matter which
    approach is preferred, the point is that the whole environment is specified as
    code, being executed in an automated, reliable, and reproducible way, always producing
    the same results.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现可重复的环境，一个合理的结论是利用**基础设施即代码**（**IaC**）。其理念是所有必需的步骤、配置和版本都明确地定义为代码。这些代码定义直接用于配置基础设施。基础设施即代码可以以程序形式实现，例如脚本，或者以声明方式实现。后一种方法指定了期望的目标状态，并使用额外的工具执行。无论哪种方法被优先考虑，关键是整个环境都作为代码指定，以自动化、可靠和可重复的方式执行，始终产生相同的结果。
- en: In any way, the approach implies that the manual steps are kept to a minimum.
    The easiest form of infrastructure as code are shell scripts. The scripts should
    be executed from soup to nuts without human involvement. The same holds true for
    all IaC solutions.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，这种方法意味着将手动步骤保持在最低限度。基础设施即代码最简单的形式是shell脚本。脚本应从头到尾执行，无需人工干预。所有IaC解决方案都适用同样的原则。
- en: Naturally the responsibility of installing and configuring environments moves
    from an operations team more toward developers. Since the development team sets
    certain requirements on the required runtime it makes sense for all engineering
    teams to work together. This is the idea behind the DevOps movement. In the past
    the mindset and method of operating too often was that application developers
    implemented software and literally passed the software and responsibilities toward
    operations - without further involvement on their side. Potential errors in production
    primarily concerned the operations team. This unfortunate process not only leads
    to tensions between engineering teams but ultimately lower quality. However, the
    overall goal should be to deliver high quality software that fulfills a purpose.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，安装和配置环境的责任从运维团队更多地转向了开发者。由于开发团队对所需的运行时设置了一定的要求，因此所有工程团队共同工作是合理的。这就是DevOps运动背后的理念。在过去，操作的心态和方法往往是在应用开发者实现了软件并直接将软件和责任传递给运维团队，而运维团队没有进一步的参与。生产中的潜在错误主要涉及运维团队。这个不幸的过程不仅导致了工程团队之间的紧张关系，而且最终降低了质量。然而，整体目标应该是交付高质量的软件，以满足其目的。
- en: This goal requires the accountability of application developers. By defining
    all required infrastructure, configuration, and software as code, all engineering
    teams naturally move together. DevOps aims toward accountability of the software
    team as a whole. Infrastructure as code is a prerequisite which increases reproducibility,
    automation, and ultimately software quality.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这个目标需要应用开发者的问责制。通过将所有必需的基础设施、配置和软件定义为代码，所有工程团队自然地协同工作。DevOps旨在实现整个软件团队的问责制。基础设施即代码是一个先决条件，它增加了可重复性、自动化，并最终提高了软件质量。
- en: In the topic *Containers* and *Container orchestration frameworks*, we will
    see how the presented technologies implement IaC.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在“容器”和“容器编排框架”这个主题中，我们将看到所展示的技术是如何实现基础设施即代码（IaC）的。
- en: Stability and production readiness
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稳定性和生产就绪性
- en: The practices of Continuous Delivery include what needs to be done in order
    to increase the quality and value of the software. This includes the stability
    of the application. Reconfiguring and redeploying software does not have to result
    in any downtime. New features and bugfixes do not have to be shipped exclusively
    during maintenance windows. Ideally the enterprise software can continuously improve
    and move forward.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 持续交付的实践包括为了提高软件的质量和价值需要做什么。这包括应用程序的稳定性。重新配置和重新部署软件不必导致任何停机时间。新特性和错误修复不必仅在维护窗口期间发布。理想情况下，企业软件可以持续改进并向前发展。
- en: 'A *zero downtime* approach involves a certain effort. In order to avoid an
    application being unavailable, at least one other instance of the software needs
    to be present at a time. A load balancer or proxy server upfront needs to direct
    the traffic to an available instance. *Blue-green* deployments make use this technique:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一种*零停机时间*的方法需要一定的努力。为了避免应用程序不可用，至少需要同时存在另一个软件实例。前端需要一个负载均衡器或代理服务器将流量引导到可用的实例。*蓝绿*部署利用了这种技术：
- en: '![](img/6e8d1123-39ac-485a-971c-22ecd5258517.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6e8d1123-39ac-485a-971c-22ecd5258517.png)'
- en: The application instances including their databases are replicated and proxied
    by a load balancer. The involved applications typically represent different software
    versions. Switching the traffic from the *blue* to the *green* path and vice versa
    instantly changes the version, without any downtime. Other forms of blue-green
    deployments can include scenarios of multiple application instances that are all
    configured to use the same database instance.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序实例及其数据库由负载均衡器进行复制和代理。涉及的应用程序通常代表不同的软件版本。从*蓝色*路径切换到*绿色*路径，反之亦然，可以立即更改版本，而无需任何停机时间。其他形式的蓝绿部署可以包括多个应用程序实例的场景，这些实例都配置为使用相同的数据库实例。
- en: This approach obviously does not have to be realized using some shiny new technology.
    We have seen blue-green deployments that enable zero-downtime in the past using
    home-grown solutions. However, modern technologies support these techniques increasing
    stability, quality, and production-readiness out of the box without much engineering
    effort required.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这种方法并不一定需要使用一些闪亮的新技术。我们过去看到过使用自建解决方案实现零停机时间的蓝绿部署。然而，现代技术支持这些技术，无需太多工程努力即可提高稳定性、质量和生产就绪性。
- en: Containers
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器
- en: The last years have shown a lot of interest in **Linux container** technology.
    Technically this approach is not that new. Linux operating systems such as **Solaris**
    supported containers a long time ago. However, **Docker** made a the breakthrough
    in this technology by providing features to build, manage and ship containers
    in a uniform way.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，对**Linux容器**技术的兴趣日益浓厚。从技术上讲，这种方法并不新颖。像**Solaris**这样的Linux操作系统很久以前就支持容器。然而，**Docker**通过提供以统一方式构建、管理和运输容器的功能，在这一技术上实现了突破。
- en: What is the difference between containers and **virtual machines** (**VMs**)
    and what makes containers that interesting?
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 容器和**虚拟机（VMs**）之间的区别是什么？是什么让容器如此有趣？
- en: Virtual machines act like a computer in a computer. They allow the runtime to
    be easily managed from the outside such as creating, starting, stopping, and distributing
    machines in a fast and ideally automated way. If new servers need to be setup,
    a blueprint, an image, of the required type can be deployed without installing
    software from scratch every time. Snapshots of running environments can be taken
    to easily backup the current state.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟机就像计算机中的计算机。它们允许从外部轻松管理运行时，例如快速且理想地以自动化的方式创建、启动、停止和分发机器。如果需要设置新的服务器，可以部署所需类型的蓝图或镜像，而无需每次从头开始安装软件。可以拍摄运行环境的快照以轻松备份当前状态。
- en: In many ways containers behave like virtual machines. They are separated from
    the host as well as other containers, run in their own network with their own
    file system and potentially own resources. The difference is that virtual machines
    run on a hardware abstraction layer, emulating a computer including operating
    system, whereas containers run directly in the host's kernel. Unlike other kernel
    processes, containers are separated from the rest of the system using operating
    system functionality. They manage their own file system. Therefore, containers
    behave like separate machines but with native performance without the overhead
    of an abstraction layer. The performance of virtual machines is naturally decreased
    by their abstraction. Whereas virtual machines provide full flexibility in choosing
    operating systems, containers will always run in the same kernel and therefore
    in the same version as the host operating system. Containers therefore do not
    ship their own Linux kernel and can be minimized to their required binaries.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多方面，容器表现得就像虚拟机。它们与主机以及其他容器分离，在自己的网络和文件系统中运行，并且可能拥有自己的资源。区别在于虚拟机在硬件抽象层上运行，模拟包括操作系统在内的计算机，而容器则直接在主机的内核中运行。与其它内核进程不同，容器通过操作系统功能与系统其他部分分离。它们管理自己的文件系统。因此，容器表现得像独立的机器，但具有原生性能，而没有抽象层的开销。虚拟机的性能自然会因抽象而降低。而虚拟机在操作系统选择上提供了完全的灵活性，容器则始终在相同的内核中运行，因此与宿主操作系统的版本相同。因此，容器不需要携带自己的Linux内核，可以最小化到所需的二进制文件。
- en: Container technologies such as Docker provide functionality to build, run, and
    distribute containers in a uniform way. Docker defines building container images
    as IaC which again enables automation, reliability, and reprocibility. Dockerfiles
    define all the steps that are required to install the application including its
    dependencies, for example, an application container and the Java runtime. Each
    step in the Dockerfile corresponds to a command that is executed at image build
    time. Once a container is started from an image it should contain everything which
    is required to fulfill its task.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 容器技术，如Docker，提供了一种统一的方式来构建、运行和分发容器。Docker将构建容器镜像定义为基础设施即代码（IaC），这再次实现了自动化、可靠性和可重复性。Dockerfile定义了安装应用程序及其依赖项（例如应用程序容器和Java运行时）所需的全部步骤。Dockerfile中的每一步都对应于在镜像构建时执行的命令。一旦从镜像启动容器，它应该包含完成其任务所需的一切。
- en: Containers usually contain a single Unix process which represents a running
    service, for example an application server, a web server, or a database. If an
    enterprise system consists of several running servers, they run in individual
    containers.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 容器通常包含一个Unix进程，代表一个运行中的服务，例如应用程序服务器、Web服务器或数据库。如果企业系统由多个运行中的服务器组成，它们将在各自的容器中运行。
- en: One of the biggest advantages of Docker containers is that they make use of
    a **copy-on-write** file system. Every build step, as well as every running container
    later on, operates on a layered file system, which does not change its layers
    but only adds new layers on top. Built images therefore comprise multiple layers.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 容器的最大优点之一是它们使用 **写时复制** 文件系统。每个构建步骤，以及之后的每个运行中的容器，都在一个分层文件系统上操作，该文件系统不会改变其层，而只是在上面添加新的层。因此，构建的镜像包含多个层。
- en: Containers that are created from images are always started with the same initial
    state. Running containers potentially modify files as new, temporary layers in
    the file system, which are discarded as soon as the containers are stopped. By
    default, Docker containers are therefore stateless runtime environments. This
    encourages the idea of reproducibility. Every persistent behavior needs to be
    defined explicitly.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从镜像创建的容器总是以相同的初始状态启动。运行中的容器可能会作为新的、临时的文件系统层修改文件，一旦容器停止，这些层就会被丢弃。因此，默认情况下，Docker
    容器是无状态的运行时环境。这鼓励了可重复性的想法。每个持久行为都需要明确定义。
- en: The multiple layers are beneficial when rebuilding and redistributing images.
    Docker caches intermediate layers and only rebuilds and retransmits what has been
    changed.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当重新构建和重新分发镜像时，多个层是有益的。Docker 缓存中间层，并且只重新构建和重新传输已更改的内容。
- en: For example, an image build may consist of multiple steps. System binaries are
    added first, then the Java runtime, an application server, and finally our application.
    When changes are made to the application and a new build is required, only the
    last step is re-executed; the previous steps are cached. The same is true for
    transmitting images over the wire. Only the layers that have been changed and
    that are not yet existent on the target registry, are actually retransmitted.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，镜像构建可能由多个步骤组成。首先添加系统二进制文件，然后是 Java 运行时，一个应用程序服务器，最后是我们的应用程序。当对应用程序进行更改并需要新的构建时，只需重新执行最后一步；之前的步骤被缓存。同样，对于通过网络传输镜像也是如此。只有已更改且在目标仓库中尚不存在的层才会实际重新传输。
- en: 'The following illustrates the layers of a Docker image and their individual
    distribution:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 以下说明了 Docker 镜像的层及其各自的分发：
- en: '![](img/b978dac1-a27b-435c-8c26-dfda3b4ad020.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b978dac1-a27b-435c-8c26-dfda3b4ad020.png)'
- en: Docker images are either built from scratch, that is from an empty starting
    point, or built upon an existing base image. There are tons of base images available,
    for all major Linux distributions containing package managers, for typical environment
    stacks as well as for Java-based images. Base images are a way to build upon a
    common ground and provide basic functionality for all resulting images. For example,
    it makes sense to use a base image including a Java runtime installation. If this
    image needs to be updated, for example, to fix security issues, all dependent
    images can be rebuilt and receive the new contents by updating the base image
    version. As said before, software builds need to be repeatable. Therefore we always
    need to specify explicit versions for software artifacts such as images.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 镜像要么从头开始构建，即从一个空起点开始，要么基于现有的基础镜像构建。有大量的基础镜像可供选择，包括所有主要的 Linux 发行版，包含包管理器，典型的环境栈以及基于
    Java 的镜像。基础镜像是一种在共同基础上构建的方式，并为所有生成的镜像提供基本功能。例如，使用包含 Java 运行时安装的基础镜像是有意义的。如果这个镜像需要更新，例如，为了修复安全问题，所有依赖的镜像都可以重新构建，并通过更新基础镜像版本来接收新内容。正如之前所说，软件构建需要可重复性。因此，我们总是需要为软件工件（如镜像）指定明确的版本。
- en: Containers that are started from previously built Docker images need access
    to these images. They are distributed using Docker registries such as the publicly
    available DockerHub or company-internal registries to distribute own images. Locally
    built images are pushed to these registries and retrieved on the environments
    that will start new containers later on.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 从先前构建的 Docker 镜像启动的容器需要访问这些镜像。这些镜像通过 Docker 仓库进行分发，例如公开可用的 DockerHub 或公司内部的镜像仓库来分发自己的镜像。本地构建的镜像被推送到这些仓库，并在稍后启动新容器的环境中检索。
- en: Java EE in the container
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器中的 Java EE
- en: As it turns out the approach of a layered file system matches Java EE's approach
    of separating the application from the runtime. Thin deployment artifacts only
    contain the actual business logic, the part which changes and which is rebuilt
    each and every time. These artifacts are deployed onto an enterprise container
    which does not change that often. Docker container images are built step-by-step,
    layer-by-layer. Building an enterprise application image includes an operating
    system base image, a Java runtime, an application server and finally the application.
    If only the application layer changes, only this step will have to be re-executed
    and retransmitted - all the other layers are touched only once and then cached.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，分层文件系统的方法与Java EE将应用程序与运行时分离的方法相匹配。轻量级部署工件仅包含实际的业务逻辑，这部分内容会发生变化，并且每次都需要重建。这些工件部署到一个企业容器上，这个容器不经常改变。Docker容器镜像是通过逐步、分层构建的。构建企业应用程序镜像包括操作系统基础镜像、Java运行时、应用程序服务器，最后是应用程序。如果只有应用程序层发生变化，那么只有这一步需要重新执行和重新传输
    - 其他所有层只接触一次然后缓存。
- en: Thin deployment artifacts leverage the advantages of layers since only a matter
    of kilobytes has to be rebuilt and redistributed, respectively. Therefore, zero-dependency
    applications is the advisable way of using containers.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 轻量级部署工件利用了层的优势，因为只需要重建和重新分配几KB的内容。因此，零依赖的应用程序是使用容器的推荐方式。
- en: As seen in the previous chapter, it makes sense to deploy one application per
    application server. Containers execute a single process which in this case is
    the application server containing the application. The application server therefore
    needs to run on a dedicated container that is included in the container as well.
    Both the application server and the application are added at image build time.
    Potential configuration, for example regarding datasources, pooling, or server
    modules, is also made during build time, usually by adding custom configuration
    files. Since the container is owned by the single application these components
    are configured without affecting anything else.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章所述，每个应用程序服务器部署一个应用程序是有意义的。容器执行单个进程，在这种情况下是包含应用程序的应用程序服务器。因此，应用程序服务器需要在容器中运行的专用容器上运行，这个容器也包含在容器中。应用程序服务器和应用程序都是在镜像构建时添加的。潜在的配置，例如关于数据源、连接池或服务器模块的配置，也是在构建时进行的，通常是通过添加自定义配置文件来实现的。由于容器属于单个应用程序，因此这些组件的配置不会影响其他任何东西。
- en: Once a container is started from the image it should already contain everything
    that is required to fulfill its job. The application as well as all required configuration
    must already be present. Therefore, applications are not deployed on a previously
    running container anymore but added during the image build time, to be present
    at container runtime. This is usually achieved by placing the deployment artifact
    into the container's auto-deployment directory. As soon as the configured application
    server starts, the application is deployed.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦从镜像启动容器，它应该已经包含完成其工作所需的一切。应用程序以及所有必需的配置必须已经存在。因此，应用程序不再部署到之前运行的容器上，而是在镜像构建时添加，以便在容器运行时存在。这通常是通过将部署工件放入容器的自动部署目录中实现的。一旦配置的应用程序服务器启动，应用程序就会被部署。
- en: The container image is built only once and then executed on all the environments.
    Following the idea of reproducible artifacts before, the same artifacts that run
    in production have to be tested upfront. Therefore the same Docker image that
    has been verified will be published to production.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 容器镜像只构建一次，然后在所有环境中执行。遵循之前可重复工件的想法，在生产中运行的同一样件必须事先进行测试。因此，经过验证的相同Docker镜像将被发布到生产环境中。
- en: But what if applications are configured differently in various environments?
    What if different external systems or databases need to be communicated with?
    In order to not interfere with several environments, at least the used database
    instances will differ. Applications shipped in containers are started from the
    same image but sometimes still need some variations.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果应用程序在不同的环境中配置不同怎么办？如果需要与不同的外部系统或数据库进行通信怎么办？为了不干扰多个环境，至少使用的数据库实例将不同。在容器中交付的应用程序是从相同的镜像启动的，但有时仍然需要一些变化。
- en: Docker offers the possibility of changing several aspects of running containers.
    This includes networking, adding volumes, that is, injecting files and directories
    that reside on the Docker host, or adding Unix environment variables. The environment
    differences are added by the container orchestration from outside of the container.
    The images are only built once for a specific version, used and potentially modified
    in different environments. This brings the big advantage that these configuration
    differences are not modeled into the application rather than managed from the
    outside. The same is true for networking and connecting applications and external
    systems, which we will see in the coming sections.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Docker提供了改变运行容器多个方面的可能性。这包括网络配置、添加卷，即注入位于Docker主机上的文件和目录，或添加Unix环境变量。环境差异由容器编排从容器外部添加。镜像只为特定版本构建一次，在不同环境中使用和可能修改。这带来了巨大的优势，即这些配置差异不是建模到应用程序中，而是从外部进行管理。这一点对于网络和连接应用程序以及外部系统也是如此，我们将在接下来的章节中看到。
- en: Linux containers, by the way, solve the business-politically motivated issue
    of shipping the application together with the implementation in a single package
    for the reason of flexibility. Since containers include the runtime and all dependencies
    required, including the Java runtime, the infrastructure only has to provide a
    Docker runtime. All used technology including the versions are the responsibility
    of the development team.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，Linux容器解决了由于灵活性原因，将应用程序及其实现打包在一起进行运输的商业和政治动机问题。由于容器包含了运行时以及所有必需的依赖项，包括Java运行时，因此基础设施只需提供Docker运行时即可。所有使用的技术及其版本都是开发团队的责任。
- en: The following code snippet shows the definition of a `Dockerfile` building an
    enterprise application `hello-cloud` onto a **WildFly** base image.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段展示了构建企业应用程序`hello-cloud`到**WildFly**基础镜像的`Dockerfile`定义。
- en: '[PRE0]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The `Dockerfile` specifies the `jboss/wildfly` base image in a specific version
    which already contains a Java 8 runtime and the WildFly application server. It
    resides in the application's project directory, pointing to the `hello-cloud.war`
    archive which was previously built by a Maven build. The WAR file is copied to
    WildFly's auto-deployment directory and will be available at that location at
    container runtime. The `jboss/wildfly` base image already specifies a run command,
    how to run the application server, which is inherited by the Dockerfile. Therefore
    it doesn't have to specify a command as well. After a Docker build the resulting
    image will contain everything from the `jboss/wildfly` base image including the
    *hello-cloud* application. This matches the same approach of installing a WildFly
    application server from scratch and adding the WAR file to the auto-deployment
    directory. When distributing the built image, only the added layer including the
    thin WAR file needs to be transmitted.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dockerfile`指定了特定版本的`jboss/wildfly`基础镜像，该镜像已经包含了Java 8运行时和WildFly应用程序服务器。它位于应用程序的项目目录中，指向之前由Maven构建的`hello-cloud.war`存档文件。WAR文件被复制到WildFly的自动部署目录，并在容器运行时在该位置可用。`jboss/wildfly`基础镜像已经指定了运行命令，即如何运行应用程序服务器，这由`Dockerfile`继承。因此，它不需要再指定命令。在Docker构建后，生成的镜像将包含从`jboss/wildfly`基础镜像中的一切，包括*hello-cloud*应用程序。这与从头开始安装WildFly应用程序服务器并将WAR文件添加到自动部署目录的方法相同。在分发构建的镜像时，只需传输包含薄WAR文件的附加层即可。'
- en: The deployment model of the Java EE platform fits the container world. Separating
    the application for the enterprise container leverage the use of copy-on-write
    file systems, minimizing the time spent on builds, distribution, or deployments.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Java EE平台的部署模型适合容器世界。将应用程序与企业容器分离利用了copy-on-write文件系统的使用，最小化了构建、分发或部署所花费的时间。
- en: Container orchestration frameworks
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器编排框架
- en: Let's go up one abstraction layer from containers. Containers include everything
    required to run specific services as stateless, self-contained artifacts. However,
    the containers need to be orchestrated to run in the correct network, being able
    to communicate with other services and being started with the correct configuration,
    if required. The straightforward approach is to develop home-grown scripts that
    run the required containers. However, in order to realize a more flexible solution
    that also enables production-readiness such as zero-downtime, the use of container
    orchestration frameworks is advisable.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从容器抽象层上升一级。容器包括运行特定服务所需的一切，作为无状态、自包含的工件。然而，容器需要被编排以在正确的网络中运行，能够与其他服务通信，并在需要时以正确的配置启动。直接的方法是开发自制的脚本以运行所需的容器。然而，为了实现更灵活的解决方案，同时也能实现生产就绪性，如零停机时间，建议使用容器编排框架。
- en: 'Container orchestration frameworks such as **Kubernetes**, **DC/OS** or **Docker
    Compose** are not only responsible to run containers, but to orchestrate, connect
    and configure them appropriately. The same motivations and principles apply that
    are true for container technologies as well: automation, reproducibility and IaC.
    Software engineers define the desired target state as code and let the orchestration
    tool reliably setup the environments as required.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如**Kubernetes**、**DC/OS**或**Docker Compose**之类的容器编排框架不仅负责运行容器，还要适当地编排、连接和配置它们。对于容器技术同样适用的动机和原则也适用：自动化、可重复性和基础设施即代码（IaC）。软件工程师将期望的目标状态定义为代码，并让编排工具可靠地设置所需的环境。
- en: Before going into a specific orchestration solution, let's have a closer look
    at the rough concepts.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究特定的编排解决方案之前，让我们更详细地看看这些基本概念。
- en: Orchestration frameworks enable us to connect multiple containers together.
    This usually involves service lookup using logic names via DNS. If multiple physical
    hosts are used, the framework resolves IP addresses over these nodes. Ideally
    an application running in a container just connects to an external system using
    a logical service name that is resolved by the container orchestration. For example,
    a car manufacturing application using the *vehicle* database connects using the
    `vehicle-db` hostname. This hostname is then resolved via DNS, depending on the
    environment which the application runs in. Connecting via logical names reduces
    the required configuration in the application code, since the configured connection
    is always the same. The orchestration just connects the desired instance.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 编排框架使我们能够将多个容器连接在一起。这通常涉及通过DNS使用逻辑名称进行服务查找。如果使用多个物理主机，框架将在这些节点上解析IP地址。理想情况下，运行在容器中的应用程序只需连接到外部系统，使用由容器编排解析的逻辑服务名称。例如，一个使用*vehicle*数据库的汽车制造应用程序通过`vehicle-db`主机名进行连接。然后，该主机名通过DNS解析，具体取决于应用程序运行的环境。通过逻辑名称连接可以减少应用程序代码中所需的配置，因为配置的连接始终相同。编排只是连接所需的实例。
- en: This is true for all offered systems. Applications, databases, and other servers
    are abstracted to logical service names which are accessed and resolved during
    runtime.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这适用于所有提供的系统。应用程序、数据库和其他服务器都被抽象为逻辑服务名称，这些名称在运行时被访问和解析。
- en: Configuring containers depending on their environment is another aspect that
    orchestration frameworks solve. In general it's advisable to reduce the required
    configuration in applications. However, there are cases where some configuration
    effort is required. It is the framework's responsibility to provide container
    configuration by dynamically injecting files or environment variables depending
    on the circumstances.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 根据其环境配置容器是编排框架解决的问题的另一个方面。一般来说，建议减少应用程序中所需的配置。然而，有些情况下可能需要一些配置工作。框架的责任是根据具体情况动态注入文件或环境变量，以提供容器配置。
- en: The production-readiness features that some of the container orchestration frameworks
    offer represent one of their biggest advantages. Ongoing development of an application
    triggers new project builds and result in new container image versions. The running
    containers need to be replaced by containers that are started from these new versions.
    In order to avoid downtime the container orchestration swaps the running containers
    using a zero-downtime deployment approach.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一些容器编排框架提供的生产就绪功能是它们最大的优势之一。应用程序的持续开发会触发新的项目构建，并导致新的容器镜像版本的产生。运行中的容器需要被从这些新版本启动的容器所替换。为了避免停机时间，容器编排使用零停机部署方法来交换运行中的容器。
- en: In the same way, container orchestration makes it possible to increase the workload
    by scaling up the number of container instances. In the past, certain applications
    ran on multiple instances simultaneously. If the number of instances needed to
    be increased, more application servers had to be provisioned. In a container world
    the same goal is achieved by simply starting more of the stateless application
    containers. The developers increase the configured number of container replicas;
    the orchestration framework implements this change by starting more container
    instances.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，容器编排使得通过扩展容器实例的数量来增加工作负载成为可能。在过去，某些应用程序同时运行在多个实例上。如果需要增加实例数量，就必须提供更多的应用程序服务器。在容器世界中，通过简单地启动更多的无状态应用程序容器来实现相同的目标。开发者增加配置的容器副本数；编排框架通过启动更多的容器实例来实现这一变化。
- en: In order to run containers in production some orchestration aspects have to
    be considered. Experience shows that some companies tend to build their own solutions
    rather than using de facto standard technology. However, container orchestration
    frameworks already solve these issues well and it is highly advisable to at least
    consider them.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在生产环境中运行容器，必须考虑一些编排方面的问题。经验表明，一些公司倾向于构建自己的解决方案，而不是使用既定标准技术。然而，容器编排框架已经很好地解决了这些问题，并且强烈建议至少考虑它们。
- en: Realizing container orchestration
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现容器编排
- en: We've now seen which challenges container orchestration framework tackle. This
    section will show you the core concepts of **Kubernetes**, a solution originally
    developed by Google to run their workloads. At the time of writing this book Kubernetes
    has a enormous momentum and is also the basis for other orchestration solutions
    such as **OpenShift** by RedHat. I chose this solution because of its popularity
    but also because I believe that it does the job of orchestration very well. However,
    the important point is less about comprehending the chosen technology rather than
    the motivations and concepts behind it.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经看到了容器编排框架所面临的挑战。本节将向您展示**Kubernetes**的核心概念，这是一个最初由Google开发来运行其工作负载的解决方案。在撰写本书时，Kubernetes具有巨大的动力，也是其他编排解决方案（如RedHat的**OpenShift**）的基础。我选择这个解决方案是因为它的普及，同时也因为我相信它非常擅长编排工作。然而，重要的点不在于理解所选技术，而在于其背后的动机和概念。
- en: Kubernetes runs and manages Linux containers in a cluster of nodes. The Kubernetes
    master node orchestrates the worker nodes which do the actual work, that is, to
    run the containers. The software engineers control the cluster using the API provided
    by the master node, via a web-based GUI or command-line tool.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes在节点集群中运行和管理Linux容器。Kubernetes主节点编排工作节点，这些节点执行实际工作，即运行容器。软件工程师通过主节点提供的API、基于Web的GUI或命令行工具来控制集群。
- en: The running cluster consists of so-called resources of a specific type. The
    core resource types of Kubernetes are **pods**, **deployments**, and **services**.
    A pod is an atomic workload unit, running one or more Linux container. This means
    the application runs in a pod.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 运行中的集群由特定类型的所谓资源组成。Kubernetes的核心资源类型是**pods**、**deployments**和**services**。一个pod是一个原子工作负载单元，运行一个或多个Linux容器。这意味着应用程序是在pod中运行的。
- en: The pods can be started and managed as standalone, single resources. However,
    it makes a lot of sense to not directly specify separate pods but to define a
    deployment, which encapsulates and manages running pods. Deployments enable the
    functionality that provide production-readiness such as upscaling and downscaling
    of pods or rolling updates. They are responsible for reliably running our applications
    in the specified versions.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Pod可以作为独立、单一的资源启动和管理。然而，不直接指定单独的Pod，而是定义一个部署，封装并管理运行中的Pod，这样做非常有意义。部署提供了生产就绪功能，如Pod的扩展和缩减或滚动更新。它们负责以指定版本可靠地运行我们的应用程序。
- en: A system defines services in order to connect to running applications from outside
    of the cluster or within other containers. The services provide the logical abstraction
    described in the last section that embraces a set of pods. All pods that run a
    specific application are abstracted by a single service which directs the traffic
    onto active pods. The combination of services routing to active pods and deployments
    managing the rolling update of versions enables zero-downtime deployments. Applications
    are always accessed using services which direct to corresponding pods.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 系统定义服务以便从集群外部或其他容器内连接到运行中的应用程序。服务提供了上一节中描述的逻辑抽象，它包含了一组Pod。所有运行特定应用程序的Pod都被单个服务抽象，该服务将流量导向活动Pod。服务路由到活动Pod的组合以及管理版本滚动更新的部署使得零停机部署成为可能。应用程序始终通过服务访问，这些服务指向相应的Pod。
- en: All core resources are unique within a Kubernetes **namespace**. Namespaces
    encapsulate aggregates of resources and can be used to model different environments.
    For example, services that point to external systems outside of the cluster can
    be configured differently in different namespaces. The applications that use the
    external systems always use the same logical service name which are directed to
    different endpoints.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 所有核心资源在Kubernetes **命名空间**内都是唯一的。命名空间封装资源聚合，并可用于建模不同的环境。例如，指向集群外部的系统中的服务可以在不同的命名空间中配置不同。使用外部系统的应用程序始终使用相同的逻辑服务名称，这些名称指向不同的端点。
- en: Kubernetes supports resources definition as IaC using JSON or YAML files. The
    YAML format is a human-readable data serialization format, a superset of JSON.
    It became the de facto standard within Kubernetes.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes支持使用JSON或YAML文件定义资源作为IaC。YAML格式是一种人类可读的数据序列化格式，是JSON的超集。它已成为Kubernetes中的事实标准。
- en: 'The following code snippet shows the definition of a service of the `hello-cloud`
    application:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段显示了`hello-cloud`应用程序服务的定义：
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The example specifies a service which directs traffic on port `8080` toward
    `hello-cloud` pods that are defined by the deployment.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 示例指定了一个服务，该服务将端口`8080`上的流量导向由部署定义的`hello-cloud`Pod。
- en: 'The following shows the `hello-cloud` deployment:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 以下展示了`hello-cloud`部署：
- en: '[PRE2]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The deployment specifies one pod from the given template with the provided Docker
    image. As soon as the deployment is created Kubernetes tries to satisfy the pod
    specifications by starting a container from the image and testing the container's
    health using the specified probes.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 部署指定了一个来自给定模板的Pod，并使用提供的Docker镜像。一旦部署创建，Kubernetes就会尝试通过从镜像启动容器并使用指定的探针测试容器的健康状态来满足Pod规范。
- en: The container image `docker.example.com/hello-cloud:1` includes the enterprise
    application which was built and distributed to a Docker registry earlier.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 容器镜像`docker.example.com/hello-cloud:1`包含了之前构建并分发到Docker注册表的商业应用程序。
- en: All these resource definitions are applied to the Kubernetes cluster by either
    using the web-based GUI or the CLI.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些资源定义都可以通过使用基于Web的GUI或CLI应用到Kubernetes集群。
- en: 'After creating both the deployment and the service, the *hello-cloud* application
    is accessible from within the cluster via the service. To be accessed from the
    outside of the cluster a route needs to be defined, for example using an **ingress**.
    Ingress resources route traffic to services using specific rules. The following
    shows an example ingress resource that makes the `hello-cloud` service available:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建部署和服务之后，*hello-cloud*应用程序可以通过服务在集群内部访问。要从集群外部访问，需要定义一个路由，例如使用**入口**。入口资源使用特定规则将流量路由到服务。以下是一个示例入口资源，它使`hello-cloud`服务可用：
- en: '[PRE3]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: These resources now specify the whole application, which is deployed onto a
    Kubernetes cluster, accessible from the outside and abstracted in a logical service
    inside of the cluster. If other applications need to communicate with the application,
    they can do so via the Kubernetes-internal, resolvable `hello-cloud` DNS hostname
    and port `8080`.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这些资源现在指定了整个应用，该应用部署到了 Kubernetes 集群中，可以从外部访问，并在集群内部以逻辑服务的形式抽象化。如果其他应用需要与应用通信，它们可以通过
    Kubernetes 内部的、可解析的 `hello-cloud` DNS 主机名和端口 `8080` 来实现。
- en: 'The following diagram shows an example setup of the *hello-cloud* application
    with a replica of three pods that runs in a Kubernetes cluster of two nodes:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了 *hello-cloud* 应用程序的一个示例设置，其中包含三个副本的 pod，这些 pod 在一个由两个节点组成的 Kubernetes
    集群中运行：
- en: '![](img/cb7873c2-fc69-4174-a05d-7ccd2a9bfaca.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/cb7873c2-fc69-4174-a05d-7ccd2a9bfaca.png)'
- en: 'Besides service lookup using logical names, some applications still need additional
    configuration. Therefore Kubernetes as well as other orchestration technology
    has the possibility of inserting files and environment variables into the container
    dynamically at runtime. The concept of **config maps**, key-value-based configuration
    is used for this. The contents of config maps can be made available as files,
    dynamically mounted into a container. The following defines an example config
    map, specifying the contents of a properties file:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用逻辑名称进行服务查找之外，一些应用程序仍然需要额外的配置。因此，Kubernetes 以及其他编排技术都有在运行时动态将文件和环境变量插入容器的可能性。为此，使用了基于键值对的
    **配置映射** 概念。配置映射的内容可以作为文件提供，动态挂载到容器中。以下定义了一个示例配置映射，指定了属性文件的内容：
- en: '[PRE4]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The config map is being used to mount the contents as files into containers.
    The config map''s keys will be used as file names, mounted into a directory, with
    the value representing the file contents. The pod definitions specify the usage
    of config maps mounted as volumes. The following shows the previous deployment
    definition of the *hello-cloud* application, using `hello-cloud-config` in a mounted
    volume:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 配置映射正在被用来将内容作为文件挂载到容器中。配置映射的键将被用作文件名，挂载到一个目录中，其值代表文件内容。pod 定义指定了挂载为卷的配置映射的使用。以下展示了
    *hello-cloud* 应用的先前部署定义，使用挂载卷中的 `hello-cloud-config`：
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The deployment defines a volume which references to the `hello-cloud-config`
    config map. The volume is mounted to the path `/opt/config` resulting in all key-value
    pairs of the config map being inserted as files in this directory. With the config
    map demonstrated previously this would result in a `application.properties` file
    containing the entries for keys `hello.greeting` and `hello.name`. The application
    expects that at runtime the file resides under this location.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 部署定义了一个卷，该卷引用了 `hello-cloud-config` 配置映射。该卷挂载到 `/opt/config` 路径，导致配置映射的所有键值对作为文件插入到这个目录中。使用前面演示的配置映射，这将导致一个包含
    `hello.greeting` 和 `hello.name` 键条目的 `application.properties` 文件。应用期望在运行时文件位于这个位置。
- en: 'Separate environments will specify different contents of the config maps, depending
    on the desired configuration values. Configuring applications using dynamic files
    is one approach. It is also possible to inject and override specific environment
    variables. The following code snippet demonstrates this example as well. This
    approach is advisable when the number of configuration values is limited:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的环境将指定不同的配置映射内容，这取决于所需的配置值。使用动态文件配置应用是一种方法。也有可能注入和覆盖特定的环境变量。以下代码片段也展示了这个例子。当配置值的数量有限时，这种方法是可取的：
- en: '[PRE6]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Applications need to configure credentials, used for example to authorize against
    external systems or as database accesses. These credentials are ideally configured
    in a different place than uncritical configuration values. Besides config maps,
    Kubernetes therefore also includes the concept of **secrets**. These are similar
    to config maps, also representing key-value pairs, but obfuscated for humans as
    Base64-encoded data. Secrets and their contents are typically not serialized as
    infrastructure as code since the credentials should not have unrestricted access.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 应用需要配置凭证，例如用于授权外部系统或作为数据库访问。这些凭证最好配置在不同于非关键配置值的地方。除了配置映射之外，Kubernetes 因此还包括了
    **机密** 的概念。这些与配置映射类似，也代表键值对，但对人类来说是 Base64 编码的数据。机密及其内容通常不会作为基础设施代码序列化，因为凭证不应拥有无限制的访问权限。
- en: 'A common practice is to make credentials accessible in containers using environment
    variables. The following code snippet shows how to include a value configured
    in secret `hello-cloud-secret` into the *hello-cloud* application:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的做法是使用环境变量在容器中使凭证可访问。以下代码片段展示了如何将秘密 `hello-cloud-secret` 中配置的值包含到 *hello-cloud*
    应用程序中：
- en: '[PRE7]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The environment variable `TOP_SECRET` is created from referencing the `topsecret`
    key in secret `hello-cloud-secret`. This environment variable is available at
    container runtime and can be used from the running process.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 环境变量 `TOP_SECRET` 是通过引用秘密 `hello-cloud-secret` 中的 `topsecret` 键创建的。这个环境变量在容器运行时可用，可以从运行进程中使用。
- en: Some applications packaged in containers cannot solely run as stateless applications.
    Databases are a typical example of this. Since containers are discarded after
    their processes have exited, the contents of their file system are also gone.
    Services such as databases need persistent state though. To solve this issue Kubernetes
    includes **persistent volumes**. As the name suggests these volumes are available
    beyond the life cycle of the pods. Persistent volumes dynamically make files and
    directories available which are used within the pod and retain after it has exited.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一些打包在容器中的应用程序不能仅作为无状态应用程序运行。数据库是这种情况的典型例子。由于容器在其进程退出后会被丢弃，因此它们的文件系统内容也会消失。像数据库这样的服务需要持久状态。为了解决这个问题，Kubernetes
    包括 **持久卷**。正如其名所示，这些卷在Pod的生命周期之外可用。持久卷动态提供在Pod中使用并在其退出后保留的文件和目录。
- en: Persistent volumes are backed by network attached storage or cloud storage offerings,
    depending on the cluster installation. They make it possible to run storage services
    such as databases in container orchestration clusters as well. However, as a general
    advise, persistent state in containers should be avoided.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 持久卷由网络附加存储或云存储服务提供支持，具体取决于集群安装。这使得在容器编排集群中运行数据库等存储服务也成为可能。然而，作为一般建议，容器中的持久状态应避免使用。
- en: The YAML IaC definitions are kept under version control in the application repository.
    The next chapter covers how to apply the file contents to a Kubernetes cluster
    as part of a Continuous Delivery pipeline.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: YAML IaC 定义保存在应用程序仓库的版本控制下。下一章将介绍如何将文件内容应用于Kubernetes集群，作为持续交付管道的一部分。
- en: Java EE in orchestrated containers
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java EE 在编排容器中
- en: The orchestration framework orchestrates and integrates enterprise applications
    in clustered environments. It takes a lot of work off the used application technology.
    Container orchestration also vastly simplifies how to configure applications and
    how to connect to external services. This section will showcase this.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 编排框架在集群环境中编排和集成企业应用程序。它大大减轻了使用应用程序技术的负担。容器编排也极大地简化了配置应用程序和连接外部服务的方式。本节将展示这一点。
- en: Connecting external services
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接外部服务
- en: 'Client controls require URLs to connect against in order to integrate external
    services. The URLs traditionally have been configured in files, which potentially
    differed in various environments. In an orchestrated environment the application
    can resolve external services using a logical name, via DNS. The following code
    snippet shows how to connect against the *cloud processor* application:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端控制需要连接以集成外部服务的URL。传统上，这些URL已在文件中配置，可能在各种环境中有所不同。在编排环境中，应用程序可以通过DNS使用逻辑名称解析外部服务。以下代码片段展示了如何连接到
    *cloud processor* 应用程序：
- en: '[PRE8]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The same holds true for other URLs, for example datasources definitions. The
    application server configuration can simply point to the name of the database
    service and use it to resolve the corresponding instance at runtime.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的情况也适用于其他URL，例如数据源定义。应用程序服务器配置可以简单地指向数据库服务的名称，并在运行时使用它解析相应的实例。
- en: Configuring orchestrated applications
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置编排应用程序
- en: 'Resolving services by logical names already eliminates a lot of configuration
    in the application. Since the same container image is being used in all environments,
    potentially different configuration needs to be inserted from the orchestration
    environment. As shown in the previous example, Kubernetes config maps tackle this
    situation. The *hello-cloud* application expects that at runtime a properties
    file will reside under `/opt/config/application.properties`. The project code
    will therefore access this location. The following demonstrates the integration
    of the properties file using a CDI producer:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 通过逻辑名称解析服务已经消除了应用程序中的大量配置。由于所有环境中都使用相同的容器镜像，可能需要从编排环境中插入不同的配置。如图中先例所示，Kubernetes配置映射处理这种情况。"hello-cloud"应用程序期望在运行时，属性文件位于`/opt/config/application.properties`下。因此，项目代码将访问此位置。以下演示了使用CDI生产者集成属性文件：
- en: '[PRE9]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The CDI producer is defined similarly to the configuration example shown previously:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: CDI生产者定义与之前展示的配置示例类似：
- en: '[PRE10]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The definition of the `@Config` qualifier is similar to the previous example
    in Chapter 3, *Implementing Modern Java Enterprise Applications*. The application
    loads the contents of the properties file into the properties map and produces
    the configured values using CDI. All managed beans can inject these values which
    emerge from the Kubernetes config map.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`@Config`限定符的定义与第三章中*实现现代Java企业应用程序*的先例类似。应用程序将属性文件的内容加载到属性映射中，并使用CDI生成配置值。所有受管理的Bean都可以注入这些值，这些值来自Kubernetes配置映射。'
- en: In order to realize secret configuration values, Kubernetes includes the concept
    of secrets as previously shown. A common practice is to make the contents of the
    secrets accessible in containers using environment variables.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现秘密配置值，Kubernetes包含了之前展示的秘密概念。一种常见的做法是使用环境变量在容器中使秘密内容可访问。
- en: Java applications use the `System.getenv()` method to access environment variables.
    This functionality is used for both secrets and config map values, respectively.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Java应用程序使用`System.getenv()`方法来访问环境变量。此功能分别用于秘密和配置映射值。
- en: The demonstrated approaches and examples enable an enterprise application to
    be deployed, managed, and configured in a container orchestration cluster. They
    are sufficient for the majority of use cases.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 展示的方法和示例使企业应用程序能够在容器编排集群中部署、管理和配置。它们对于大多数用例来说是足够的。
- en: 12-factor applications and Java EE
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12要素应用程序和Java EE
- en: As of writing this book, **12-factor** applications has emerged as a way of
    developing **Software as a Service** (**SaaS**) applications. The 12-factor application
    approach define 12 software development principles. The motivations behind these
    principles aim to minimize time and effort, avoid software erosion, and embrace
    Continuous Delivery and cloud platforms.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时，**12要素**应用程序已成为开发**软件即服务**（**SaaS**）应用程序的一种方式。12要素应用程序方法定义了12个软件开发原则。这些原则背后的动机旨在最小化时间和精力，避免软件侵蚀，并拥抱持续交付和云平台。
- en: In other words the 12-factors aim to to implement enterprise applications in
    a modern way. Some of the principles sound obvious to most engineers, while others
    seem to contradict the common practice of building enterprise applications.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，12要素旨在以现代方式实现企业应用程序。其中一些原则对大多数工程师来说很显然，而其他原则似乎与构建企业应用程序的常见做法相矛盾。
- en: 'The list of the 12-factors includes:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 12要素列表包括：
- en: I. Have one codebase tracked in revision control, many deploys
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: I. 使用版本控制跟踪一个代码库，进行多次部署
- en: II. Explicitly declare and isolate dependencies
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: II. 明确声明并隔离依赖项
- en: III. Store config in the environment
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: III. 在环境中存储配置
- en: IV. Treat backing services as attached resources
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IV. 将后端服务视为附加资源
- en: V. Strictly separate build and run stages
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: V. 严格分离构建和运行阶段
- en: VI. Execute the app as one or more stateless processes
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VI. 以一个或多个无状态进程执行应用程序
- en: VII. Export services via port binding
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VII. 通过端口绑定导出服务
- en: VIII. Scale out via the process model
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VIII. 通过进程模型进行扩展
- en: IX. Maximize robustness with fast startup and graceful shutdown
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IX. 通过快速启动和优雅关闭最大化鲁棒性
- en: X. Keep development, staging, and production as similar as possible
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: X. 尽可能使开发、测试和生产的相似性最大化
- en: XI. Treat logs as event streams
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XI. 将日志视为事件流
- en: XII. Run admin/management tasks as one-off processes
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XII. 将管理/管理任务作为一次性进程运行
- en: The following explains the motivations of each principle and its realization
    with Java EE.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 以下解释了每个原则的动机及其在Java EE中的实现。
- en: Have one codebase tracked in revision control, many deploys
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在版本控制中跟踪一个代码库，多个部署
- en: This principle sounds pretty obvious to software engineers, declaring that a
    software code should be kept under version control, a single repository, even
    for multiple *deploys*. Deploys relate to software instances, running on specific
    environments. Therefore the codebase of a single application is tracked in a single
    repository, not several codebases per application or vice versa, containing all
    specifications for potentially different environments.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这一原则对软件工程师来说听起来相当明显，即声明软件代码应保持在版本控制下，一个仓库，即使是对于多个*部署*。部署与软件实例相关，运行在特定的环境中。因此，单个应用程序的代码库在单个仓库中进行跟踪，而不是每个应用程序或相反，包含所有可能不同环境的规范。
- en: This principle leverages developer productivity since all information is found
    under one repository. It is indifferent to the chosen technology and therefore
    supported by Java EE applications, as well.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这一原则利用了开发者的生产力，因为所有信息都位于一个仓库下。它对选择的技术无关紧要，因此也支持Java EE应用程序。
- en: The repository should contain all source files that are required to build and
    run the enterprise application. Besides Java sources and configuration files,
    this includes infrastructure as code.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 仓库应包含构建和运行企业应用程序所需的所有源文件。除了Java源代码和配置文件外，还包括基础设施即代码。
- en: Explicitly declare and isolate dependencies
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 明确声明并隔离依赖
- en: Software dependencies and their versions that are required in order to run the
    application must be specified explicitly. This includes not only dependencies
    which the application is programmed against, for example third-party APIs, but
    also implicit dependencies on the Java runtime or operating system, respectively.
    Explicitly specifying the required versions leads to far less compatibility issues
    in production. A composition of software versions is sufficiently tested during
    the development workflow. Dependency versions that differ when rebuilding binaries
    introduce potential issues. It is therefore advisable to explicitly declare all
    software versions to reduce probability of error and enable reproducibility.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 运行应用程序所需的软件依赖及其版本必须明确指定。这不仅包括应用程序编程所依赖的依赖项，例如第三方API，还包括对Java运行时或操作系统的隐式依赖。明确指定所需的版本可以大大减少生产中的兼容性问题。在开发工作流程中，软件版本的组合已经足够测试。在重建二进制文件时版本不同会引入潜在问题。因此，建议明确声明所有软件版本以减少错误概率并实现可重复性。
- en: Container technology simplifies this principle by explicitly specifying all
    software installation steps. Versions of used base images should be explicitly
    declared, so that image rebuilds result in the same result. The Docker `latest`
    tag should therefore be avoided in favor of definite versions. All software installations
    specified in Dockerfiles should point to explicit versions as well. Docker rebuilds,
    with or without cache, should produce the same outcome.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 容器技术通过明确指定所有软件安装步骤简化了这一原则。应明确声明使用的基镜像的版本，以便镜像重建产生相同的结果。因此，应避免使用Docker的`latest`标签，而应使用确定的版本。Docker文件中指定的所有软件安装也应指向明确的版本。带有或没有缓存的Docker重建应产生相同的结果。
- en: Java applications specify their dependencies using build systems. The first
    chapter already covered what is necessary to enable reproducible builds using
    both Maven and Gradle. In Java EE applications these dependencies are ideally
    minimized to the Java EE API.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Java应用程序使用构建系统指定其依赖项。第一章已经介绍了使用Maven和Gradle实现可重复构建所必需的内容。在Java EE应用程序中，这些依赖项理想情况下应最小化到Java
    EE API。
- en: Whenever possible, it's advisable to specify explicit dependency versions, not
    just *latest* ones. Only software using explicit versions can be tested reliably.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在可能的情况下，建议指定明确的依赖版本，而不仅仅是*最新*版本。只有使用明确版本的软件才能可靠地进行测试。
- en: Isolating dependencies is a necessity for distributed development throughout
    the software team. Software artifacts should be accessible via well-defined processes,
    for example artifact repositories. Dependencies, which are added during the software
    build, no matter whether Java runtime installations, Java artifacts, or operating
    system components, need to be distributed from a central place. Repositories such
    as **Maven Central**, **DockerHub** or company-internal repositories enable this
    approach.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 将依赖项隔离是软件团队分布式开发的一个必要条件。软件工件应通过定义良好的流程，例如工件仓库，可被访问。在软件构建过程中添加的依赖项，无论是否为Java运行时安装、Java工件或操作系统组件，都需要从中央位置分发。例如，**Maven
    Central**、**DockerHub**或公司内部仓库都支持这种做法。
- en: Store config in the environment
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在环境中存储配置
- en: Application configuration, that differ for separate environments, such as databases,
    external systems, or credentials, need to be existent at runtime. This configuration
    should not be reflected in the source code but dynamically modifiable from outside
    of the application. This implies that configuration is retrieved via files, environment
    variables or other external concerns.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序配置，如数据库、外部系统或凭证等不同环境下的配置，需要在运行时存在。这种配置不应反映在源代码中，而应能够从应用程序外部动态修改。这意味着配置是通过文件、环境变量或其他外部因素检索的。
- en: Container technology and orchestration frameworks support these approaches as
    previously shown. Configuration for different environments, such as *test*, *staging*,
    and *production* is stored in Kubernetes config maps and dynamically used in pods
    in volumes or environment variables.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 容器技术和编排框架如前所述支持这些方法。不同环境，如**测试**、**预发布**和**生产**的配置存储在Kubernetes配置映射中，并在Pod的卷或环境变量中动态使用。
- en: The 12-factor principles state that an application "[...] stores config in environment
    variables". Environment variables are a straightforward way of inserting specific
    variations that is supported by all kinds of technology. However, if configuring
    the application involves a lot of individual configuration values, engineers may
    consider to use configuration files contained in container volumes, instead.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 12个因素原则指出，应用程序“ [...] 应在环境变量中存储配置”。环境变量是插入特定变体的一种直接方式，所有类型的技术都支持。然而，如果配置应用程序涉及大量单个配置值，工程师可能考虑使用容器卷中包含的配置文件。
- en: Treat backing services as attached resources
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将后端服务视为附加资源
- en: Databases and external systems that are accessed in the application are called
    *resources*. It should make no difference to the system where an external service
    or database is part of the application. The *resources* should be attached to
    the application in a loosely coupled way. External systems and databases should
    be able to be replaced by new instances without affecting the application.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序中访问的数据库和外部系统被称为**资源**。对于系统来说，一个外部服务或数据库是否是应用程序的一部分不应有任何区别。**资源**应以松散耦合的方式附加到应用程序上。外部系统和数据库应能够被新的实例替换，而不会影响应用程序。
- en: 'Applications abstract the accessed external system, first of all in the communication
    technology being used. Communication via HTTP or JDBC, for example, abstracts
    the implementations and enables systems to be replaced by others. By doing so,
    applications are only coupled to their contract: the communication protocol and
    defined schemas. JPA, JAX-RS, and JSON-B are examples that support this approach.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序抽象了访问的外部系统，首先是使用的通信技术。例如，通过HTTP或JDBC进行通信抽象了实现，并使系统能够被其他系统替换。通过这样做，应用程序仅与其合同耦合：通信协议和定义的模式。JPA、JAX-RS和JSON-B是支持此方法的示例。
- en: Container orchestration frameworks take this approach even further and abstract
    services into logic names. As shown previously applications can use service names
    as hostnames, resolved by DNS.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 容器编排框架将这种方法进一步发展，并将服务抽象为逻辑名称。如前所述，应用程序可以使用服务名称作为主机名，由DNS解析。
- en: In general, application developers should loosely couple systems together, ideally
    only depending on protocols and schemas. At a code level backing services are
    abstracted into own components, such as individual controls with clean interfaces.
    This minimizes changes if attached resources change.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，应用程序开发者应该将系统松散耦合在一起，理想情况下只依赖于协议和模式。在代码级别，后端服务被抽象为独立的组件，例如具有干净接口的单独控件。这样，如果附加资源发生变化，可以最小化更改。
- en: Strictly separate build and run stages
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 严格分离构建和运行阶段
- en: This principle advises to separate the application build, the deployment, and
    the run processes. This is a well-known approach to Java enterprise developers.
    Application binaries are built, deployed, and run in separate steps. Software
    or configuration changes happen in the source code or in the deployment step,
    respectively, and not directly in production. The deployment step brings application
    binaries and potential configuration together. Well-defined change and release
    management processes keep the integrity of the enterprise software.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 此原则建议将应用程序构建、部署和运行过程分开。这是Java企业开发者所熟知的方法。应用程序二进制文件在单独的步骤中构建、部署和运行。软件或配置更改分别在源代码或部署步骤中发生，而不是直接在生产环境中。部署步骤将应用程序二进制文件和潜在配置组合在一起。定义良好的变更和发布管理流程保持企业软件的完整性。
- en: For the vast majority of software projects, it is common practice to separate
    these steps and orchestrate stages in a Continuous Integration server. This is
    necessary to ensure reliability and reproducibility. [Chapter 6](599c6821-8971-4489-931c-9e11b5e23afd.xhtml),
    *Application Development Workflows* covers this topic in depth.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 对于绝大多数软件项目，将步骤分开并在持续集成服务器中编排阶段是常见的做法。这是确保可靠性和可重复性的必要条件。[第6章](599c6821-8971-4489-931c-9e11b5e23afd.xhtml)，*应用程序开发工作流程*深入探讨了这一主题。
- en: Execute the app as one or more stateless processes
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将应用程序作为单个或多个无状态进程执行
- en: Ideally, applications run as stateless processes where every use case is executed
    self-sufficiently, without affecting other running processes. Potential state
    is either stored in an attached resource such as a database or discarded. Session
    state that lives longer than a single request is therefore a violation of this
    principle. The challenge with traditional user session state is that it only resides
    in a local application instance and not accessible from other instances. The need
    for so-called *sticky sessions* on load balancers is an indicator for not having
    a stateless application.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，应用程序作为无状态进程运行，每个用例都是独立执行的，不会影响其他正在运行的进程。潜在状态要么存储在附加资源（如数据库）中，要么被丢弃。因此，比单个请求持续时间长的会话状态违反了这一原则。传统用户会话状态的挑战在于它仅存在于本地应用程序实例中，不可从其他实例访问。在负载均衡器上需要所谓的*粘性会话*是未拥有无状态应用程序的指标。
- en: A lot of modern technology supports this approach. Docker containers with their
    copy-on-write file system are an example. Stopped containers will be discarded
    and therefore all of their state is gone as well. Stateless EJBs are based on
    a similar motivation. However, instances of stateless session beans are pooled
    and reused, therefore developers need to ensure that no state retains after the
    business use case invocations.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 许多现代技术支持这种方法。例如，具有写时复制的文件系统的Docker容器。停止的容器将被丢弃，因此它们的所有状态也将消失。无状态EJBs基于类似动机。然而，无状态会话bean的实例是池化和重复使用的，因此开发人员需要确保在业务用例调用后没有状态保留。
- en: Enterprise applications should be able to be restarted from scratch without
    affecting their behavior. This also implies that applications share no state except
    via well-defined attached resources.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 企业应用程序应该能够在不影响其行为的情况下从头开始重新启动。这也意味着应用程序除了通过定义良好的附加资源外，不共享任何状态。
- en: Export services via port binding
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过端口绑定导出服务
- en: Web applications are traditionally deployed to a certain software stack. Java
    enterprise applications for examples are deployed to an enterprise or Servlet
    container whereas server-side scripting languages such as PHP run on top of a
    web server. The applications therefore depend on their immediate runtime.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: Web应用程序传统上部署到特定的软件堆栈。例如，Java企业应用程序部署到企业或Servlet容器，而服务器端脚本语言（如PHP）则在Web服务器上运行。因此，应用程序依赖于它们的即时运行时。
- en: This 12-factor principle advise to develop self-sufficient applications that
    expose their functionality via network ports. Since web-based enterprise applications
    will communicate via the network, binding services to ports is the way of least
    coupling.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 12因素原则建议开发自给自足的应用程序，通过网络端口公开其功能。由于基于Web的企业应用程序将通过网络进行通信，因此将服务绑定到端口是最低耦合的方式。
- en: Java EE applications that run in a container support this approach, only exporting
    a port which is used to communicate with the application. Containers only depend
    on the Linux kernel, the application runtime is therefore transparent. Container
    orchestration frameworks leverage this idea, connecting services to pods via logical
    names and ports, as shown in a previous example. Java EE supports the use of containers
    and therefore this principle as well.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器中运行的Java EE应用程序支持这种方法，仅导出一个用于与应用程序通信的端口。容器只依赖于Linux内核，因此应用程序运行时是透明的。容器编排框架利用这一想法，通过逻辑名称和端口将服务连接到Pod，如前一个示例所示。Java
    EE支持容器使用，因此也支持这一原则。
- en: Scale out via the process model
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过进程模型进行扩展
- en: Modern applications as well as their environments should enable scalability
    when the workload on them increases. Applications ideally are able to scale out
    horizontally, rather than just vertically. The difference is that scaling horizontally
    aims to adds more individual, self-contained nodes to the software whereas scaling
    vertically increases the resources on single nodes or processes. However, scaling
    vertically is limited, since resources on physical nodes cannot be increased infinitely.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现代应用程序及其环境应在工作负载增加时能够实现可伸缩性。理想情况下，应用程序能够水平扩展，而不仅仅是垂直扩展。区别在于，水平扩展旨在向软件中添加更多单独的、自包含的节点，而垂直扩展则是增加单个节点或进程的资源。然而，垂直扩展是有限的，因为物理节点上的资源不能无限增加。
- en: 12-factor applications describe the procedure of adding concurrency to the software
    with adding more self-contained, *shared-nothing* processes. Workloads should
    be distributable within several physical hosts, by increasing the number of processes.
    The processes represent the request or worker threads who handle the system's
    workload.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 12因素应用描述了通过添加更多自包含的、*无共享*进程来向软件中添加并发的程序。工作负载应在多个物理主机之间可分配，通过增加进程数量来实现。进程代表处理系统工作负载的请求或工作线程。
- en: This approach shows the necessity of implementing stateless application in a
    shared-nothing manner. Containers that run stateless Java enterprise applications
    enable the system to scale out. Kubernetes managed scalability in deployments
    via managing the number of replicas.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法显示了在无共享方式中实现无状态应用程序的必要性。运行无状态Java企业应用程序的容器使系统能够进行扩展。Kubernetes通过管理副本数量来管理部署中的可伸缩性。
- en: The bottleneck of enterprise applications, however, is typically not the application
    instances rather than central databases. Chapter 8, *Microservices and System
    Architecture* and Chapter 9, *Monitoring, Performance, and Logging* cover the
    topics of scalability in distributed systems as well as performance in Java EE
    projects in general.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，企业应用程序的瓶颈通常是应用程序实例而不是中央数据库。第8章《微服务与系统架构》和第9章《监控、性能和日志》涵盖了分布式系统中的可伸缩性和Java
    EE项目中的一般性能问题。
- en: Maximize robustness with fast startup and graceful shutdown
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过快速启动和优雅关闭最大化鲁棒性
- en: '[Chapter 4](f0a49441-e411-49c4-a4b6-c6193ba36094.xhtml), *Lightweight Java
    EE* already showed the necessity of fast turnarounds. This principle of 12-factor
    applications requires technology that enables velocity and elasticity. In order
    to rapidly scale up, the software should startup in a matter of seconds, making
    it possible to tackle a growing workload.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '[第4章](f0a49441-e411-49c4-a4b6-c6193ba36094.xhtml)，《轻量级Java EE》已经展示了快速迭代的重要性。12因素应用的原则要求能够实现速度和弹性的技术。为了快速扩展，软件应在几秒钟内启动，使其能够处理不断增长的工作负载。'
- en: Application shutdowns should gracefully finish in-flight requests and properly
    close all open connections and resources. Especially requests and transactions
    that are executed while the shutdown signal occurs should be finished properly
    not to maliciously abort client use cases. In a Unix process approach shutdown
    signals are sent as `SIGTERM` signals. Linux containers are stopped in the same
    way, giving the container process a chance to shutdown properly. When building
    container images, developers should pay attention that the process handles Unix
    signals properly, resulting in a graceful shutdown of the application server when
    it receives a `SIGTERM` signal.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序关闭应该优雅地完成正在进行的请求，并妥善关闭所有打开的连接和资源。特别是当关闭信号发生时执行的请求和事务应该被适当地完成，而不是恶意地终止客户端用例。在
    Unix 进程方法中，关闭信号以 `SIGTERM` 信号的形式发送。Linux 容器以相同的方式停止，给容器进程一个优雅关闭的机会。当构建容器镜像时，开发者应该注意进程正确处理
    Unix 信号，以便在接收到 `SIGTERM` 信号时，应用程序服务器能够优雅地关闭。
- en: Java EE supports both fast startups and graceful shutdowns. As shown previously,
    modern application servers start up and deploy applications in a matter of seconds.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Java EE 支持快速启动和优雅关闭。如前所述，现代应用服务器可以在几秒钟内启动和部署应用程序。
- en: 'Since the application servers manage beans, resources, pooling, and threading,
    they take care of closing the resources properly at JVM shutdown. The developers
    don''t need to take care of this aspect themselves. Beans that manage custom resources
    or handles that need to be closed, use pre-destroy methods to implemented proper
    closing. The following shows a client control using a JAX-RS client handle which
    is closed on server shutdown:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 由于应用服务器管理着豆类、资源、池化和线程，它们会在 JVM 关闭时妥善关闭资源。开发者不需要自己处理这一方面。管理自定义资源或需要关闭的处理程序，使用预销毁方法来实现适当的关闭。以下是一个使用
    JAX-RS 客户端处理程序的客户端控制示例，该处理程序在服务器关闭时被关闭：
- en: '[PRE11]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The platform guarantees that the pre-destroy methods of all managed beans are
    called once the application server shuts down.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 平台保证一旦应用服务器关闭，所有管理豆类的预销毁方法都会被调用一次。
- en: Keep development, staging, and production as similar as possible
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 尽可能保持开发、预发布和生产的相似性
- en: This 12-factor principle aims to minimize differences between environments.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这个12要素原则旨在最小化环境之间的差异。
- en: Enterprise applications traditionally have quite some differences between the
    environments of the development process. There are development environments, maybe
    several of them, such as local workstations or dedicated server environments and
    finally there is the production environment. These environments differ in regard
    of time when software artifacts in certain versions and configuration are deployed
    during the development process. The longer the time span of simultaneously having
    different versions in the set of environments the greater this difference becomes.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 企业应用程序在开发过程的各个环境之间通常存在相当大的差异。有开发环境，可能有几个，例如本地工作站或专用服务器环境，最后是生产环境。这些环境在开发过程中部署的软件工件版本和配置方面存在差异。在环境中同时拥有不同版本的时间跨度越长，这种差异就越大。
- en: There is also a difference in teams and people. Traditionally software developers
    maintain their own development environment while an operations team takes care
    of production. This introduces potential gaps in communication, processes, and
    used technology.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 团队和人员之间也存在差异。传统上，软件开发者维护自己的开发环境，而运维团队则负责生产环境。这引入了潜在的沟通、流程和使用的技术的差距。
- en: The technical difference between environments contains the biggest risk. Development
    or test environments that use different tools, technology, external services and
    configuration than production introduce the risk that these differences will lead
    to errors. Software is tested automatically on these environments before going
    to production. Every difference from production that is not tested can and eventually
    will introduce bugs that could have been prevented. The same is true for exchanging
    tools, backend services, or used stacks for lightweight alternatives in development
    or local environments.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 环境之间的技术差异包含最大的风险。与生产环境使用不同工具、技术、外部服务和配置的开发或测试环境，会引入这些差异可能导致错误的风险。软件在这些环境中自动测试，然后再部署到生产环境中。任何未测试的生产差异都可能并最终引入本可以预防的错误。对于在开发或本地环境中交换工具、后端服务或使用的堆栈以轻量级替代品也是同样的情况。
- en: It is therefore advisable to keep the environments as similar as possible. Especially,
    container technologies and orchestration frameworks highly support this approach.
    As we saw previously, differences in configuration, services, and technology are
    minimized or at least explicitly defined via the environment. Ideally, software
    landscapes are identical on development, test environments, staging, and production.
    If that is not possible, service abstractions as well as environment-managed configuration
    support to manage the differences.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，建议尽可能保持环境相似。特别是，容器技术和编排框架高度支持这种方法。正如我们之前看到的，配置、服务和技术的差异被最小化或至少通过环境明确定义。理想情况下，软件景观在开发、测试环境、预生产和生产环境中是相同的。如果不可能实现这一点，服务抽象以及环境管理的配置支持有助于管理差异。
- en: The difference in time and people is tackled by usage of Continuous Delivery,
    not just from a technical but also organizational point of view. The overall time
    to production should be as small as possible, enabling fast delivery of features
    and bug fixes. Implementing Continuous Delivery naturally moves teams and responsibilities
    together. The DevOps movement describes how all engineers are responsible for
    the overall software. This leads to a culture where all teams closely work together
    or merge into single teams of software engineers.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 通过持续交付的使用来处理时间和人员差异，这不仅从技术角度，也从组织角度出发。整体的生产时间应尽可能小，以便快速交付特性和错误修复。实施持续交付自然会推动团队和责任的整合。DevOps运动描述了所有工程师对整体软件的责任。这导致了一种文化，即所有团队都紧密合作或合并成单一的软件工程师团队。
- en: Treat logs as event streams
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将日志视为事件流
- en: Enterprise applications traditionally write logs to log files on disk. Some
    engineers argue that this information is one of the most important insights into
    the application. The software project usually includes configuration of the contents
    and format of these logfiles. However, storing log data in log files is first
    of all just an output format, usually having a single log event per line.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 企业应用程序传统上会将日志写入磁盘上的日志文件。一些工程师认为，这些信息是了解应用程序最重要的洞察之一。软件项目通常包括配置这些日志文件的内容和格式。然而，将日志数据存储在日志文件中首先只是一个输出格式，通常每行只有一个日志事件。
- en: This principle of 12-factor applications argues that logging should be treated
    as a stream of log events, that are emitted by the application. Applications should,
    however, not concern themselves with routing and storing the log file into specific
    output formats. Instead they log to the process' standard output. The standard
    out is captured and processed by the runtime environment.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 12因素应用原则认为，日志应该被视为由应用程序发出的日志事件流。然而，应用程序不应关心路由和将日志文件存储到特定输出格式。相反，它们将日志记录到进程的标准输出。标准输出被运行时环境捕获和处理。
- en: This approach is uncommon to most enterprise developers with all logging frameworks,
    output formats and tools being around. However, environments where a lot of services
    run in parallel need to capture and process log events externally anyway. Solutions
    such as **Elasticsearch**, **Logstash**, and **Kibana** have proven themselves
    well to process and comprehend complex situations with log events from several
    sources. Storing log events in log files not necessarily supports these approaches.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法对于大多数企业开发者来说并不常见，因为所有日志框架、输出格式和工具都存在。然而，在许多服务并行运行的环境中，仍然需要外部捕获和处理日志事件。例如，**Elasticsearch**、**Logstash**和**Kibana**等解决方案已经证明在处理和解析来自多个来源的日志事件复杂情况方面表现良好。将日志事件存储在日志文件中并不一定支持这些方法。
- en: Logging to the application's standard out not only simplifies development, since
    routing and storing is not a responsibility of the application anymore. It also
    reduces the need for external dependencies, such as logging frameworks. Zero-dependency
    applications support this approach. The environment such as a container orchestration
    framework takes care of capturing and routing the event stream. In Chapter 9,
    *Monitoring, Performance, and Logging*, we will cover the topic of logging, its
    necessity and shortcomings.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 将日志记录到应用程序的标准输出不仅简化了开发，因为路由和存储不再是应用程序的责任。它还减少了对外部依赖的需求，例如日志框架。零依赖应用程序支持这种方法。环境，如容器编排框架，负责捕获和路由事件流。在第9章“监控、性能和日志”中，我们将讨论日志、其必要性和不足之处。
- en: Run admin/management tasks as one-off processes
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将管理/管理任务作为一次性进程运行
- en: This principle describes that administrative or management tasks should be executed
    as separate short-lived processes. The technology ideally supports command execution
    in a shell that operates on the running environment.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这个原则描述了管理或管理任务应该作为独立的短暂进程来执行。理想的技术支持在运行环境中操作的shell中的命令执行。
- en: Although containers encapsulate Unix processes, they provide additional functionality
    to execute single commands or to open a remote shell into the container. Engineers
    can therefore execute the management and administration scripts provided by the
    Java EE application server. Still, in Java EE applications, the number of required
    administration and management tasks are limited. A Container runs the application
    server process, which auto-deploys the application; no further application life
    cycle management is required.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管容器封装了Unix进程，但它们提供了执行单个命令或打开远程shell到容器中的额外功能。因此，工程师可以执行Java EE应用服务器提供的管理和行政脚本。然而，在Java
    EE应用程序中，所需的管理和管理任务数量有限。容器运行应用程序服务器进程，该进程自动部署应用程序；不需要进一步的应用程序生命周期管理。
- en: Administrative tasks are usually required for debugging and troubleshooting
    purposes. Therefore containers and container orchestration frameworks offer possibilities
    to open remote shells into the containers or execute one-time commands. Apart
    from that, the Chapter 9, *Monitoring, Performance, and Logging* will show you
    what is necessary to gather further monitoring information about enterprise applications.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 管理任务通常用于调试和故障排除目的。因此，容器和容器编排框架提供了打开远程shell到容器或执行一次性命令的可能性。除此之外，第9章“监控、性能和日志”将向您展示收集有关企业应用程序的进一步监控信息所必需的内容。
- en: The motivations of the 12-factors are to develop stateless, scalable enterprise
    applications that embrace Continuous Delivery and modern environment platforms,
    optimize time and effort spent in development and try to avoid software erosion.
    12-factor application have a clean contract with their underlying system and ideally
    declarative infrastructure definitions.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 12要素的动机是开发无状态、可扩展的企业应用程序，这些应用程序采用持续交付和现代环境平台，优化开发中花费的时间和精力，并试图避免软件侵蚀。12要素应用程序与其底层系统有一个清晰的合同，并且理想情况下有声明性基础设施定义。
- en: Cloud, Cloud native, and their benefits
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云、云原生及其优势
- en: As of writing this book, there is a lot of interest in cloud platforms. We currently
    see big companies moving their IT infrastructure into cloud offerings. But what
    benefits does *the cloud* have to offer?.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时，对云平台有很大的兴趣。我们目前看到大型公司正在将他们的IT基础设施迁移到云服务中。但云平台究竟有哪些好处呢？
- en: First of all, we have to be aware that modern environments do not necessarily
    have to run on top of a cloud platform. All the benefits of container technology
    and container orchestration frameworks can equally be achieved using company-internal
    infrastructure. On premise installations of platforms such as Kubernetes or OpenShift
    at first provide the same advantages for software teams. In fact, one of the biggest
    benefits of container runtimes is to abstract the environment where the containers
    are running. Why are cloud platforms interesting for companies then?
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须意识到，现代环境不一定必须运行在云平台之上。容器技术和容器编排框架的所有好处都可以通过公司内部基础设施实现。最初，在本地安装Kubernetes或OpenShift等平台为软件开发团队提供相同的优势。事实上，容器运行时最大的好处之一是抽象容器运行的
    环境。那么，为什么云平台对公司来说很有趣呢？
- en: As mentioned in the beginning of this book, the software world is moving faster
    than ever. The key for companies to keep pace with the trends in their business
    is to embrace agility and velocity in terms of moving fast. The time to market
    of new products and features thereof need to be as short as possible. Moving in
    iterative steps, adapting to customers' needs and continuously improving software
    meets this demand. In order to realize this goal, IT infrastructure, as well as
    all other aspects of software engineering, needs to be fast and flexible. New
    environments should be setup via automated, reliable and reproducible processes.
    The same principles for continuous software delivery apply to server environments.
    Cloud platforms offer this possibility.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如本书开头所述，软件世界正在比以往任何时候都更快地发展。公司跟上其业务趋势的关键是拥抱敏捷和快速移动。新产品及其新特性的上市时间需要尽可能短。以迭代步骤进行，适应客户需求并持续改进软件满足这一需求。为了实现这一目标，IT基础设施以及软件工程的各个方面都需要快速和灵活。新环境应通过自动化、可靠和可重复的过程来设置。持续软件交付的相同原则也适用于服务器环境。云平台提供了这种可能性。
- en: 'Companies that want to embrace agility and to adapt to their customers'' demands
    need to ask themselves the question: *How long does it take to provision new environments?*
    This is the prerequisite of being able to adapt quickly. Provisioning whole new
    environments should be a matter of minutes, should not require overly complex
    processes and ideally no human intervention. As said before it is definitely possible
    to realize such approaches on premises. Cloud offerings, however, offer these
    benefits out of the box with sufficient, scalable resources. **Infrastructure
    as a Service** (**IaaS**) or **Platform as a Service** (**PaaS**) offerings take
    a lot of work off the hands of companies, enabling them to focus on building their
    products.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 想要拥抱敏捷并适应客户需求的公司需要问自己一个问题：*配置新环境需要多长时间？* 这是快速适应的前提。配置全新的环境应该是几分钟内的事情，不应该需要过于复杂的流程，理想情况下不需要人为干预。正如之前所说，在本地实现这样的方法是完全可能的。然而，云服务提供这些好处是现成的，拥有足够的、可扩展的资源。**基础设施即服务**（**IaaS**）或**平台即服务**（**PaaS**）提供的服务可以减轻公司的许多工作负担，使他们能够专注于构建自己的产品。
- en: Still, big companies are often skeptical when it comes to cloud services, especially
    in terms of data security. Interestingly, experience of projects shows that when
    comparing infrastructure environments down to earth, cloud platforms run by sophisticated
    enterprises offer more secure environments than most on premises. Cloud platform
    providers put a lot of time and effort into building proper solutions. Especially
    combining cloud platform offerings with orchestration solutions, such as Docker
    Compose, Kubernetes, or OpenShift hold a lot of potential.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，大型公司在面对云服务时往往持怀疑态度，尤其是在数据安全方面。有趣的是，项目经验表明，当将基础设施环境比较到实际层面时，由复杂企业运营的云平台提供的环境通常比大多数本地环境更安全。云平台提供商投入了大量时间和精力来构建适当的解决方案。特别是将云平台服务与编排解决方案相结合，如Docker
    Compose、Kubernetes或OpenShift，具有很大的潜力。
- en: Interestingly, one of the main arguments of companies to move their IT into
    the cloud is because of economic reasons. From experience, a lot of companies
    want to save costs by using cloud platforms. In fact, when taking the whole process
    of migrating and transforming environments, teams, technology, and most of all
    know-how, into account, on premises solutions are usually still cheaper. However,
    the main advantage of cloud offerings is flexibility and the ability to move fast.
    If an IT company maintains a well-orchestrated landscape, including automation,
    reliable and reproducible processes, it is advisable to keep, and continuously
    improve, this approach. That said, the question about modern environments is less
    about whether to use cloud platforms than about processes, team mindsets, and
    reasonable technology.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，公司将其IT迁移到云中的主要论点之一是出于经济原因。从经验来看，许多公司希望通过使用云平台来节省成本。实际上，当考虑到将整个迁移和转型过程，包括团队、技术和最重要的是专业知识，都纳入考量时，本地解决方案通常仍然更便宜。然而，云服务的主要优势在于灵活性和快速移动的能力。如果一个IT公司维护一个良好的协调景观，包括自动化、可靠和可重复的过程，那么保持并持续改进这种方法是明智的。话虽如此，关于现代环境的问题，与其说是关于是否使用云平台，不如说是关于流程、团队心态和合理的技术。
- en: Cloud native
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云原生
- en: Besides the interest in cloud technology there is a lot of interest in the term
    **cloud native** which describes applications that, besides following the 12-factors,
    have a strong relationship to cloud platforms. Cloud native and 12-factor applications
    are not synonymous; rather than cloud native includes the 12-factors, among other
    things.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对云技术的兴趣之外，对术语**云原生**也非常感兴趣，它描述了除了遵循12要素之外，与云平台有强烈关系的应用程序。云原生和12要素应用不是同义词；云原生包括12要素，以及其他一些内容。
- en: Cloud native applications are designed to run on cloud PaaS offerings with all
    their benefits and challenges, embrace container technology and elastic scalability.
    They are built with the claim to provide modern, scalable, stateless and resilient
    applications, manageable within modern orchestration environments. Unlike the
    term *native* suggests, applications that follow this approach do not necessarily
    have to be built as *green-field* projects that support cloud technology from
    day one.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生应用旨在在云PaaS服务上运行，利用其所有优势和挑战，拥抱容器技术和弹性可伸缩性。它们旨在提供现代、可扩展、无状态和具有弹性的应用程序，可在现代编排环境中进行管理。与术语*native*所暗示的相反，遵循此方法的应用程序不一定必须作为*green-field*项目来构建，从第一天起就支持云技术。
- en: 'Important aspects for cloud native applications beyond the 12-factors are monitoring
    and application health concerns, which can be summarized as telemetry. Telemetry
    for enterprise applications include responsiveness, monitoring, domain-specific
    insights, health checks, and debugging. As we have seen previously, container
    orchestration supports us at least with the last two concerns: health checks and
    debugging. Running applications are probed whether they are still alive and healthy.
    Debugging and troubleshooting is possible by evaluating the log event streams,
    connecting into the running containers or executing processes.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生应用除了12要素之外，重要的方面还包括监控和应用健康问题，这可以总结为遥测。企业应用的遥测包括响应性、监控、特定领域的洞察、健康检查和调试。正如我们之前所看到的，容器编排至少支持我们解决最后两个问题：健康检查和调试。运行中的应用程序会被探测，以确定它们是否仍然存活且健康。通过评估日志事件流、连接到运行中的容器或执行进程，可以进行调试和故障排除。
- en: Application monitoring need to be exposed by the running container. This requires
    a bit more effort from software developers. Domain-specific metrics need to be
    defined by the business experts first. It depends which metrics are interesting
    to business departments and will be exposed by the application. Technical metrics
    are gathered from the running application as well. Chapter 9, *Monitoring, Performance,
    and Logging* covers the topic of monitoring in regard to modern environments.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序监控需要由运行中的容器暴露出来。这需要软件开发人员付出更多努力。特定领域的指标需要由业务专家首先定义。这取决于哪些指标对业务部门感兴趣，并且将由应用程序暴露出来。技术指标也来自运行中的应用程序。第9章，*监控、性能和日志*，涵盖了关于现代环境中的监控主题。
- en: Another aspect that the 12-factors don't include are APIs and security thereof.
    SaaS applications communicate via exposed APIs that have to be made known to other
    teams of developers. The nature and structure of web services needs to be documented
    and agreed upon during development. This is especially the case when HTTP APIs
    don't implement Hypermedia. The applications need to know the nature and structure
    of exchanged information - ideally as early as possible in the development process.
    This also covers authentication and authorization. Application developers should
    be aware of security mechanisms they need to address before communicating to other
    services. In general it is not advisable to only think of security aspects after
    development. [Chapter 10](2c990001-2bf1-4ede-b2cd-f4939754b6df.xhtml), *Security*
    covers this topic concerning cloud environments and integration into Java EE applications.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 12要素不包括的另一个方面是API及其安全性。SaaS应用程序通过暴露的API进行通信，这些API必须为其他开发团队所知晓。Web服务的性质和结构需要在开发过程中进行文档化和协商。这在HTTP
    API没有实现超媒体的情况下尤其如此。应用程序需要了解交换信息的性质和结构——理想情况下，在开发过程的早期就应如此。这还包括身份验证和授权。应用程序开发人员应该意识到在与其他服务通信之前需要解决的网络安全机制。一般来说，在开发之后才考虑安全方面是不明智的。[第10章](2c990001-2bf1-4ede-b2cd-f4939754b6df.xhtml)，*安全*，涵盖了关于云环境和集成到Java
    EE应用程序中的这个主题。
- en: In order to build an umbrella for all technologies that embrace cloud platforms,
    the **Cloud Native Computing Foundation** was formed by several software vendors.
    It is part of the Linux Foundation, representing an foundation for cloud native
    Open Source Software. It contains technology that orchestrates, manages, monitors,
    traces or in some other way supports containerized **microservices** running in
    modern environments. As of writing this book, examples for technology projects
    being part of the Cloud Native Computing Foundation are **Kubernetes**, **Prometheus**,
    **OpenTracing**, or **containerd**.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 为了为所有拥抱云平台的技术构建一个伞状结构，几家软件供应商共同成立了**云原生计算基金会**。它是Linux基金会的一部分，代表云原生开源软件的基础。它包含技术，可以编排、管理、监控、跟踪或以其他方式支持在现代环境中运行的容器化**微服务**。截至撰写本书时，Cloud
    Native Computing Foundation的技术项目示例包括**Kubernetes**、**Prometheus**、**OpenTracing**或**containerd**。
- en: Summary
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Operational tasks need to be automated. Setting up application environments
    should always produce the same outcome, including installations, network, and
    configuration. Container technologies as well as infrastructure as code support
    this by defining, automating and distributing software installations and configuration.
    They fulfill the necessity of rebuilding software and systems in a fast and reproducible
    way.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 运营任务需要自动化。设置应用程序环境应始终产生相同的结果，包括安装、网络和配置。容器技术和基础设施即代码通过定义、自动化和分发软件安装和配置来支持这一点。它们满足了快速且可重复地重建软件和系统的必要性。
- en: Infrastructure as code definitions specify the required infrastructure together
    with all dependencies as part of the application code, kept under version control.
    This approach supports the ideas behind the DevOps movement. The responsibilities
    of not only defining the application but also its runtime with all requirements
    move different teams together. It should be a responsibility of all engineers
    to deliver quality software that serves a business purpose.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 基础设施即代码定义指定了所需的基础设施及其所有依赖项，作为应用程序代码的一部分，并保持在版本控制之下。这种方法支持DevOps运动背后的理念。不仅定义应用程序，还包括其运行时以及所有要求的责任，将不同的团队聚集在一起。所有工程师都应该有责任交付服务于商业目的的高质量软件。
- en: Container technologies such as Docker provides functionality to build, manage,
    and ship containers in a uniform way. Docker's copy-on-write layered file system
    enables us to minimize build and publishing times by only re-executing steps that
    have changed. Java EE zero-dependency applications encourage the use of container
    technology by separating the application logic from its implementation. The changing
    layer therefore only contains business code.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 容器技术，如Docker，提供了一种统一的方式来构建、管理和运输容器。Docker的写时复制层文件系统使我们能够通过仅重新执行已更改的步骤来最小化构建和发布时间。Java
    EE零依赖应用程序通过将应用程序逻辑与其实现分离，鼓励使用容器技术。因此，变化的层只包含业务代码。
- en: Container orchestration frameworks such as Kubernetes manage containers in their
    life cycle, network, and external configuration. They are responsible to lookup
    services, provide production readiness such as zero-downtime deployments and scale
    up and down application instances. Container orchestration supports infrastructure
    as code definitions, that contain the configuration of the whole runtime environment
    required by the application.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 容器编排框架，如Kubernetes，管理容器的生命周期、网络和外部配置。它们负责查找服务，提供生产就绪性，如零停机时间部署，以及扩展和缩减应用程序实例。容器编排支持基础设施即代码定义，这些定义包含应用程序所需的整个运行时环境的配置。
- en: The 12-factor and cloud native approaches aim to develop modern enterprise applications
    with minimal time and effort, avoiding software erosion, and supporting Continuous
    Delivery and cloud platforms. The 12-factor principles target software dependencies,
    configuration, dependent services, runtime environments, logging and administration
    processes. Similarly, cloud native applications aim to build enterprise software
    that works well on cloud platforms, supporting monitoring, resilience, application
    health, and security. Since these approaches are not bound to a specific technology,
    they are realizable using Java EE. We have seen the motivations why to follow
    these principles.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 12因子和云原生方法旨在以最短的时间和最小的努力开发现代企业应用，避免软件侵蚀，并支持持续交付和云平台。12因子原则针对软件依赖、配置、依赖服务、运行时环境、日志和行政流程。同样，云原生应用旨在构建在云平台上运行良好的企业软件，支持监控、弹性、应用健康和安全。由于这些方法不受特定技术的限制，它们可以使用Java
    EE实现。我们已经看到了遵循这些原则的动机。
- en: The following chapter will show you how to build productive application development
    workflows, that are based on container technologies.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将向您展示如何构建基于容器技术的生产力应用开发工作流程。
