- en: Chapter 6. Measuring Performance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章 测量性能
- en: 'Depending on the expected and actual performance, and the lack or presence
    of a measuring system, performance analysis and tuning can be a fairly elaborate
    process. Now we will discuss the analysis of performance characteristics and ways
    to measure and monitor them. In this chapter we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 根据预期的和实际性能，以及测量系统的缺乏或存在，性能分析和调整可能是一个相当复杂的过程。现在我们将讨论性能特性的分析以及测量和监控它们的方法。在本章中，我们将涵盖以下主题：
- en: Measuring performance and understanding the results
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量性能和理解结果
- en: What performance tests to carry out for different purposes
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据不同的目的进行性能测试
- en: Monitoring performance and obtaining metrics
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控性能和获取指标
- en: Profiling Clojure code to identify performance bottlenecks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析Clojure代码以识别性能瓶颈
- en: Performance measurement and statistics
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能测量和统计学
- en: Measuring performance is the stepping stone to performance analysis. As we noted
    earlier in this book, there are several performance parameters to be measured
    with respect to various scenarios. Clojure's built-in `time` macro is a tool to
    measure the amount of time elapsed while executing a body of code. Measuring performance
    factors is a much more involved process. The measured performance numbers may
    have linkages with each other that we need to analyze. It is a common practice
    to use statistical concepts to establish the linkage factors. We will discuss
    some basic statistical concepts in this section and use that to explain how the
    measured data gives us the bigger picture.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 测量性能是性能分析的基础。正如我们在这本书中之前提到的，我们需要根据各种场景测量几个性能参数。Clojure的内置`time`宏是一个测量执行代码体所花费时间的工具。测量性能因素是一个更为复杂的过程。测量的性能数字之间可能存在联系，我们需要分析这些联系。使用统计概念来建立联系因素是一种常见的做法。在本节中，我们将讨论一些基本的统计概念，并使用这些概念来解释测量的数据如何为我们提供更全面的视角。
- en: A tiny statistics terminology primer
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个小小的统计术语入门
- en: 'When we have a series of quantitative data, such as latency in milliseconds
    for the same operation (measured over a number of executions), we can observe
    a number of things. First, and the most obvious, are the minimum and maximum values
    in the data. Let''s take an example dataset to analyze further:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有一系列定量数据，例如相同操作的延迟（在多次执行中测量）时，我们可以观察到许多事情。首先，也是最明显的，是数据中的最小值和最大值。让我们用一个示例数据集来进一步分析：
- en: '| 23 | 19 | 21 | 24 | 26 | 20 | 22 | 21 | 25 | 168 | 23 | 20 | 29 | 172 | 22
    | 24 | 26 |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| 23 | 19 | 21 | 24 | 26 | 20 | 22 | 21 | 25 | 168 | 23 | 20 | 29 | 172 | 22
    | 24 | 26 |'
- en: Median, first quartile, third quartile
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 中位数，第一四分位数，第三四分位数
- en: 'We can see that the minimum latency here is 19 ms whereas the maximum latency
    is 172ms. We can also observe that the average latency here is about 40ms. Let''s
    sort this data in ascending order:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，这里的最低延迟是19毫秒，而最高延迟是172毫秒。我们还可以观察到，这里的平均延迟大约是40毫秒。让我们按升序排序这些数据：
- en: '| 19 | 20 | 20 | 21 | 21 | 22 | 22 | 23 | 23 | 24 | 24 | 25 | 26 | 26 | 29
    | 168 | 172 |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 19 | 20 | 20 | 21 | 21 | 22 | 22 | 23 | 23 | 24 | 24 | 25 | 26 | 26 | 29
    | 168 | 172 |'
- en: 'The center element of the previous dataset, that is the ninth element (value
    23), is considered the **median** of the dataset. It is noteworthy that the median
    is a better representative of the center of the data than the **average** or **mean**.
    The center element of the left half, that is the fifth element (value 21), is
    considered the **first quartile**. Similarly, the value in the center of the right
    half, that is the 13th element (value 26), is considered the **third quartile**
    of the dataset. The difference between the third quartile and the first quartile
    is called **Inter Quartile Range (IQR)**, which is 5 in this case. This can be
    illustrated with a **boxplot** , as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 之前数据集的中心元素，即第九个元素（值为23），被认为是数据集的**中位数**。值得注意的是，中位数比**平均数**或**均值**更能代表数据的中心。左半部分的中心元素，即第五个元素（值为21），被认为是**第一四分位数**。同样，右半部分的中心值，即第13个元素（值为26），被认为是数据集的**第三四分位数**。第三四分位数和第一四分位数之间的差值称为**四分位距（IQR）**，在本例中为5。这可以用以下**箱线图**来表示：
- en: '![Median, first quartile, third quartile](img/3642_06_01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![中位数，第一四分位数，第三四分位数](img/3642_06_01.jpg)'
- en: A boxplot highlights the first quartile, median and the third quartile of a
    dataset. As you can see, two "outlier" latency numbers (168 and 172) are unusually
    higher than the others. Median makes no representation of outliers in a dataset,
    whereas the mean does.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 箱线图突出了数据集的第一个四分位数、中位数和第三个四分位数。如图所示，两个“异常值”延迟数值（168和172）异常地高于其他数值。中位数在数据集中不表示异常值，而平均值则表示。
- en: '![Median, first quartile, third quartile](img/3642_06_02.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![中位数、第一个四分位数、第三个四分位数](img/3642_06_02.jpg)'
- en: A histogram (the diagram shown previously) is another way to display a dataset
    where we batch the data elements in **periods** and expose the **frequency** of
    such periods. A period contains the elements in a certain range. All periods in
    a histogram are generally the same size; however, it is not uncommon to omit certain
    periods when there is no data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图（前面显示的图表）是另一种显示数据集的方法，我们将数据元素分批处理在**时间段**内，并暴露这种时间段的**频率**。一个时间段包含一定范围内的元素。直方图中的所有时间段通常大小相同；然而，当没有数据时，省略某些时间段并不罕见。
- en: Percentile
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 百分位数
- en: A **percentile** is expressed with a parameter, such as 99 percentile, or 95
    percentile etc. A percentile is the value below which all the specified percentage
    of data elements exist. For example, 95 percentile means the value *N* among a
    dataset, such that 95 percent of elements in the dataset are below *N* in value.
    As a concrete example, 85 percentile from the dataset of latency numbers we discussed
    earlier in this section is 29, because out of 17 total elements, 14 (which is
    85 percent of 17) other elements in the dataset have a value below 29\. A quartile
    splits a dataset into chunks of 25 percent elements each. Therefore, the first
    quartile is actually 25 percentile, the median is 50 percentile, and the third
    quartile is 75 percentile.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 百分位数用参数表示，例如99百分位数，或95百分位数等。百分位数是指所有指定百分比的数值元素都存在的值。例如，95百分位数意味着数据集中值*N*，使得数据集中95%的元素值都低于*N*。作为一个具体的例子，本节前面讨论的延迟数值数据集中的85百分位数是29，因为在17个总元素中，有14个（即17的85%）其他元素在数据集中的值低于29。四分位数将数据集分成每个25%元素的块。因此，第一个四分位数实际上是25百分位数，中位数是50百分位数，第三个四分位数是75百分位数。
- en: Variance and standard deviation
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 方差和标准差
- en: 'The spread of the data, that is, how far away the data elements are from the
    center value, gives us further insight into the data. Consider the *i^(th)* deviation
    as the difference between the *i^(th)* dataset element value (in statistics terms,
    a "variable" value) and its mean; we can represent it as ![Variance and standard
    deviation](img/image006.jpg). We can express its "variance" and "standard deviation"
    as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的分布，即数据元素与中心值之间的距离，为我们提供了对数据的进一步了解。考虑第*i*个偏差作为第*i*个数据集元素值（在统计学中，称为“变量”值）与其平均值之间的差异；我们可以将其表示为![方差和标准差](img/image006.jpg)。我们可以将其“方差”和“标准差”表示如下：
- en: Variance = ![Variance and standard deviation](img/image008.jpg), standard deviation
    (σ) = ![Variance and standard deviation](img/image010.jpg) = ![Variance and standard
    deviation](img/image012.jpg)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 方差 = ![方差和标准差](img/image008.jpg)，标准差（σ）= ![方差和标准差](img/image010.jpg) = ![方差和标准差](img/image012.jpg)
- en: 'Standard deviation is shown as the Greek letter "sigma", or simply "s". Consider
    the following Clojure code to determine variance and standard deviation:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 标准差用希腊字母“sigma”表示，或简单地表示为“s”。考虑以下Clojure代码来确定方差和标准差：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You can use the Clojure-based platform Incanter ([http://incanter.org/](http://incanter.org/))
    for statistical computations. For example, you can find standard deviation using
    `(incanter.stats/sd tdata)` in Incanter.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用基于Clojure的平台Incanter ([http://incanter.org/](http://incanter.org/))进行统计分析。例如，您可以使用Incanter中的`(incanter.stats/sd
    tdata)`来找到标准差。
- en: The **empirical rule** states the relationship between the elements of a dataset
    and SD. It says that 68.3 percent of all elements in a dataset lie in the range
    of one (positive or negative) SD from the mean, 95.5 percent of all elements lie
    in two SDs from the mean, and 99.7 percent of all data elements lie in three SDs
    from the mean.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**经验法则**说明了数据集元素与标准差之间的关系。它说，数据集中68.3%的所有元素都位于平均值一个（正或负）标准差的范围内，95.5%的所有元素位于两个标准差范围内，99.7%的所有数据元素位于三个标准差范围内。'
- en: Looking at the latency dataset we started out with, one SD from the mean is
    ![Variance and standard deviation](img/image014.jpg)(![Variance and standard deviation](img/image016.jpg)
    range -9 to 89) containing 88 percent of all elements. Two SDs from the mean is
    ![Variance and standard deviation](img/image014.jpg) range -58 to 138) containing
    the same 88 percent of all elements. However, three SDs from the mean is(![Variance
    and standard deviation](img/image018.jpg)range -107 to 187) containing 100 percent
    of all elements. There is a mismatch between what the empirical rule states and
    the results we found, because the empirical rule applies generally to uniformly
    distributed datasets with a large number of elements.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 观察我们最初使用的延迟数据集，从平均值出发的一个标准差是![方差和标准差](img/image014.jpg)(![方差和标准差](img/image016.jpg)范围-9到89)，包含所有元素的88%。从平均值出发的两个标准差是![方差和标准差](img/image014.jpg)范围-58到138)，包含所有元素的88%。然而，从平均值出发的三个标准差是(![方差和标准差](img/image018.jpg)范围-107到187)，包含所有元素的100%。由于经验法则通常适用于具有大量元素的均匀分布数据集，因此经验法则所陈述的内容与我们的发现之间存在不匹配。
- en: Understanding Criterium output
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解Criterium输出
- en: 'In [Chapter 4](ch04.html "Chapter 4. Host Performance"), *Host Performance*,
    we introduced the Clojure library *Criterium* to measure the latency of Clojure
    expressions. A sample benchmarking result is as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](ch04.html "第4章。主机性能")“主机性能”中，我们介绍了Clojure库*Criterium*来测量Clojure表达式的延迟。以下是一个基准测试结果的示例：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We can see that the result has some familiar terms we discussed earlier in this
    section. A high mean and low standard deviation indicate that there is not a lot
    of variation in the execution times. Likewise, the lower (first) and upper (third)
    quartiles indicate that they are not too far away from the mean. This result implies
    that the body of code is more or less stable in terms of response time. Criterium
    repeats the execution many times to collect the latency numbers.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，结果中包含了一些我们在本节 earlier 讨论过的熟悉术语。高平均值和低标准差表明执行时间的变化不大。同样，下四分位数（第一四分位数）和上四分位数（第三四分位数）表明它们与平均值并不太远。这一结果意味着代码在响应时间方面相对稳定。Criterium重复执行多次以收集延迟数值。
- en: However, why does Criterium attempt to do a statistical analysis of the execution
    time? What would be amiss if we simply calculate the mean? It turns out that the
    response times of all executions are not always stable and there is often disparity
    in how the response time shows up. Only upon running sufficient times under correctly
    simulated load we can get complete data and other indicators about the latency.
    A statistical analysis gives insight into whether there is something wrong with
    the benchmark.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为什么Criterium试图对执行时间进行统计分析？如果我们简单地计算平均值，会有什么遗漏呢？结果发现，所有执行的响应时间并不总是稳定的，响应时间的显示往往存在差异。只有在正确模拟负载下运行足够的时间，我们才能获得关于延迟的完整数据和其它指标。统计分析有助于了解基准测试是否存在问题。
- en: Guided performance objectives
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指导性能目标
- en: We only briefly discussed performance objectives in [Chapter 1](ch01.html "Chapter 1. Performance
    by Design"), *Performance by Design* because that discussion needs a reference
    to statistical concepts. Let's say we identified the functional scenarios and
    the corresponding response time. Should response time remain fixed? Can we constrain
    throughput in order to prefer a stipulated response time?
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第1章](ch01.html "第1章。设计性能")“设计性能”中仅简要讨论了性能目标，因为该讨论需要参考统计概念。假设我们确定了功能场景和相应的响应时间。响应时间是否应该保持固定？我们能否通过限制吞吐量来优先考虑规定的响应时间？
- en: The performance objective should specify the worst-case response time, that
    is, maximum latency, the average response time and the maximum standard deviation.
    Similarly, the performance objective should also mention the worst-case throughput,
    maintenance window throughput, average throughput, and the maximum standard deviation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 性能目标应指定最坏情况的响应时间，即最大延迟、平均响应时间和最大标准差。同样，性能目标还应提及最坏情况的吞吐量、维护窗口吞吐量、平均吞吐量和最大标准差。
- en: Performance testing
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能测试
- en: Testing for performance requires us to know what we are going to test, how we
    want to test, and what environment to set up for the tests to execute. There are
    several pitfalls to be aware of, such as a lack of near-real hardware and resources
    of production use, similar OS and software environments, diversity of representative
    data for test cases, and so on. Lack of diversity in test inputs may lead to a
    monotonic branch prediction, hence introducing a "bias" in test results.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 对性能的测试要求我们知道我们要测试什么，我们希望如何测试，以及为测试执行而设置的环境。有几个需要注意的陷阱，例如缺乏接近真实硬件和生产使用的资源，类似的操作系统和软件环境，测试用例中代表性数据的多样性，等等。测试输入的多样性不足可能导致单调的分支预测，从而在测试结果中引入“偏差”。
- en: The test environment
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试环境
- en: Concerns about the test environment begin with the hardware representative of
    the production environment. Traditionally, the test environment hardware has been
    a scaled-down version of the production environment. The performance analysis
    done on non-representative hardware is almost certain to skew the results. Fortunately,
    in recent times, thanks to the commodity hardware and cloud systems, provisioning
    test environment hardware that is similar to the production environment is not
    too difficult.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对测试环境的担忧始于生产环境的硬件代表。传统上，测试环境硬件是生产环境的缩小版。在非代表性硬件上进行的性能分析几乎肯定会歪曲结果。幸运的是，近年来，得益于通用硬件和云系统，提供与生产环境相似的测试环境硬件并不太难。
- en: The network and storage bandwidth, operating system, and software used for performance
    testing should of course be the same as in production. What is also important
    is to have a "load" representative of the test scenarios. The load comes in different
    combinations including the concurrency of requests, the throughput and standard
    deviation of requests, the current population level in the database or in the
    message queue, CPU and heap usage, and so on. It is important to simulate a representative
    load.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 用于性能测试的网络和存储带宽、操作系统和软件应当然与生产环境相同。同样重要的是要有代表测试场景的“负载”。负载包括不同的组合，包括请求的并发性、请求的吞吐量和标准偏差、数据库或消息队列中的当前人口水平、CPU和堆使用情况等。模拟一个代表性负载是很重要的。
- en: Testing often requires quite some work on the part of the piece of code that
    carries out the test. Be sure to keep its overhead to a minimum so that it does
    not impact the benchmark results. Wherever possible, use a system other than the
    test target to generate requests.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 测试通常需要对执行测试的代码片段进行相当多的工作。务必将其开销保持在最低，以免影响基准测试结果。在可能的情况下，使用除测试目标以外的系统生成请求。
- en: What to test
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 要测试的内容
- en: Any implementation of a non-trivial system typically involves many hardware
    and software components. Performance testing a certain feature or a service in
    the entire system needs to account for the way it interacts with the various sub-systems.
    For example, a web service call may touch multiple layers such as the web server
    (request/response marshaling and unmarshaling), URI-based routing, service handler,
    application-database connector, the database layer, logger component, and so on.
    Testing only the service handler would be a terrible mistake, because that is
    not exactly the performance what the web client will experience. The performance
    test should test at the perimeter of a system to keep the results realistic, preferably
    with a third-party observer.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 任何非平凡系统的实现通常涉及许多硬件和软件组件。在整个系统中对某个功能或服务进行性能测试需要考虑它与各种子系统的交互方式。例如，一个Web服务调用可能会触及多个层次，如Web服务器（请求/响应打包和解包）、基于URI的路由、服务处理程序、应用程序-数据库连接器、数据库层、日志组件等。仅测试服务处理程序将是一个严重的错误，因为这并不是Web客户端将体验到的性能。性能测试应该在系统的外围进行，以保持结果的真实性，最好有第三方观察者。
- en: The performance objectives state the criteria for testing. It would be useful
    to test what is not required by the objective, especially when the tests are run
    concurrently. Running meaningful performance tests may require a certain level
    of isolation.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 性能目标陈述了测试的标准。测试不需要达到的目标内容是有用的，尤其是在测试并行运行时。运行有意义的性能测试可能需要一定程度的隔离。
- en: Measuring latency
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测量延迟
- en: The latency obtained by executing a body of code may vary slightly on each run.
    This necessitates that we execute the code many times and collect samples. The
    latency numbers may be impacted by the JVM warm-up time, garbage collection and
    the JIT compiler kicking in. So, the test and sample collection should ensure
    that these conditions do not impact the results. Criterium follows such methods
    to produce the results. When we test a very small piece of code this way, it is
    called a **Micro-benchmark**.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 执行一段代码所获得的延迟可能在每次运行时略有不同。这需要我们多次执行代码并收集样本。延迟数值可能会受到JVM预热时间、垃圾收集和JIT编译器启动的影响。因此，测试和样本收集应确保这些条件不会影响结果。Criterium遵循这种方法来产生结果。当我们以这种方式测试非常小的代码片段时，它被称为**微基准测试**。
- en: As the latency of some operations may vary during runs, it is important to collect
    all samples and segregate them into periods and frequencies turning up into a
    histogram. The maximum latency is an important metric when measuring latency—it
    indicates the worst-case latency. Besides the maximum, the 99 percentile and 95
    percentile latency numbers are also important to put things in perspective. It's
    important to actually collect the latency numbers instead of inferring them from
    standard deviation, as we noted earlier that the empirical rule works only for
    normal distributions without significant outliers.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于某些操作的延迟在运行期间可能会变化，因此收集所有样本并将它们按时间段和频率分离成直方图是很重要的。在测量延迟时，最大延迟是一个重要的指标——它表示最坏情况的延迟。除了最大值之外，99百分位和95百分位的延迟数值也很重要，以便从不同角度看待问题。实际上收集延迟数值比从标准差推断它们更重要，正如我们之前提到的，经验法则仅适用于没有显著异常值的高斯分布。
- en: The outliers are an important data point when measuring latency. A proportionately
    higher count of outliers indicates a possibility of degradation of service.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在测量延迟时，异常值是一个重要的数据点。异常值比例较高可能表明服务退化的可能性。
- en: Comparative latency measurement
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 比较延迟测量
- en: When evaluating libraries for use in projects, or when coming up with alternate
    solutions against some baseline, comparative latency benchmarks are useful to
    determine the performance trade-offs. We will inspect two comparative benchmarking
    tools based on Criterium, called Perforate and Citius. Both make it easy to run
    Criterium benchmarks grouped by context, and to easily view the benchmark results.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当评估用于项目的库或提出针对某些基线的替代解决方案时，比较延迟基准测试有助于确定性能权衡。我们将检查基于Criterium的两个比较基准测试工具，称为Perforate和Citius。两者都使得按上下文分组运行Criterium基准测试变得容易，并可以轻松查看基准测试结果。
- en: 'Perforate ([https://github.com/davidsantiago/perforate](https://github.com/davidsantiago/perforate))
    is a Leiningen plugin that lets one define goals; a goal (defined using `perforate.core/defgoal`)
    is a common task or context having one or more benchmarks. Each benchmark is defined
    using `perforate.core/defcase`. As of version 0.3.4, a sample benchmark code may
    look like the following code snippet:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Perforate ([https://github.com/davidsantiago/perforate](https://github.com/davidsantiago/perforate))
    是一个Leiningen插件，允许定义目标；目标（使用`perforate.core/defgoal`定义）是一个具有一个或多个基准测试的常见任务或上下文。每个基准测试使用`perforate.core/defcase`定义。截至0.3.4版本，一个示例基准测试代码可能看起来像以下代码片段：
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can declare the test environments in `project.clj` and provide the setup/cleanup
    code when defining the goal. Perforate provides ways to run the benchmarks from
    the command-line.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在`project.clj`中声明测试环境，并在定义目标时提供设置/清理代码。Perforate提供了从命令行运行基准测试的方法。
- en: Citius ([https://github.com/kumarshantanu/citius](https://github.com/kumarshantanu/citius))
    is a library that provides integration hooks for clojure.test and other forms
    of invocation. It imposes more rigid constraints than Perforate, and renders additional
    comparative information about the benchmarks. It presumes a fixed number of targets
    (cases) per test suite where there may be several goals.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Citius ([https://github.com/kumarshantanu/citius](https://github.com/kumarshantanu/citius))
    是一个库，它为clojure.test和其他调用形式提供集成钩子。它比Perforate施加更严格的约束，并提供了关于基准测试的额外比较信息。它假设每个测试套件中有一个固定的目标（案例）数量，其中可能有多个目标。
- en: 'As of version 0.2.1, a sample benchmark code may look like the following code
    snippet:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 截至0.2.1版本，一个示例基准测试代码可能看起来像以下代码片段：
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the previous example, the code runs the benchmarks, reports the comparative
    summary, and draws a bar chart image of the mean latencies.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个示例中，代码运行基准测试，报告比较总结，并绘制平均延迟的柱状图图像。
- en: Latency measurement under concurrency
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 并发下的延迟测量
- en: When we benchmark a piece of code with Criterium, it uses just a single thread
    to determine results. That gives us a fair output in terms of single-threaded
    result, but there are many benchmarking scenarios where single-threaded latency
    is far from what we need. Under concurrency, the latency often differs quite a
    bit from single-threaded latency. Especially when we deal with *stateful* objects
    (e.g. drawing a connection from a JDBC connection pool, updating shared in-memory
    state etc.), the latency is likely to vary in proportion with the contention.
    In such scenarios it is useful to find out the latency patterns of the code under
    various concurrency levels.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用 Criterium 基准测试一段代码时，它只使用一个线程来确定结果。这为我们提供了一个关于单线程结果的公平输出，但在许多基准测试场景中，单线程延迟与我们需要的相差甚远。在并发情况下，延迟通常与单线程延迟有很大差异。特别是当我们处理*有状态*对象（例如从
    JDBC 连接池中绘制连接、更新共享内存状态等）时，延迟很可能会随着竞争程度成比例变化。在这种情况下，了解代码在不同并发级别下的延迟模式是有用的。
- en: 'The Citius library we discussed in the previous sub-section supports tunable
    concurrency levels. Consider the following benchmark of implementations of shared
    counters:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前一小节中讨论的 Citius 库支持可调的并发级别。考虑以下共享计数器实现的基准测试：
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: When I ran this benchmark on a 4th generation quad-core Intel Core i7 processor
    (Mac OSX 10.10), the mean latency at concurrency level 04 was 38 to 42 times the
    value of the mean latency at concurrency level 01\. Since, in many cases, the
    JVM is used to run server-side applications, benchmarking under concurrency becomes
    all the more important.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当我在第四代四核英特尔酷睿 i7 处理器（Mac OSX 10.10）上运行这个基准测试时，在并发级别 04 的平均延迟是并发级别 01 的平均延迟的
    38 到 42 倍。由于在许多情况下 JVM 用于运行服务器端应用程序，因此在并发下的基准测试变得尤为重要。
- en: Measuring throughput
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测量吞吐量
- en: Throughput is expressed per unit of time. Coarse-grained throughput, that is,
    the throughput number collected over a long period of time, may hide the fact
    when the throughput is actually delivered in bursts instead of a uniform distribution.
    Granularity of the throughput test is subject to the nature of the operation.
    A batch process may process bursts of data, whereas a web service may deliver
    uniformly distributed throughput.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 吞吐量是以时间单位来表示的。粗粒度吞吐量，即在一个较长时期内收集的吞吐量数字，可能会隐藏这样一个事实：吞吐量实际上是在爆发式地而不是均匀分布地交付的。吞吐量测试的粒度取决于操作的性质。批量处理可能处理数据爆发，而网络服务可能提供均匀分布的吞吐量。
- en: Average throughput test
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 平均吞吐量测试
- en: 'Though Citius (as of version 0.2.1) shows extrapolated throughput (per second,
    per thread) in benchmark results, that throughput number may not represent the
    actual throughput very well for a variety of reasons. Let''s construct a simple
    throughput benchmark harness as follows, beginning with the helper functions:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管截至版本 0.2.1 的 Citius 在基准测试结果中显示了外推吞吐量（每秒，每线程），但由于各种原因，这个吞吐量数字可能并不能很好地代表实际的吞吐量。让我们构建一个简单的吞吐量基准测试
    harness，如下所示，从辅助函数开始：
- en: '[PRE5]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now that we have the helper functions defined, let''s see the benchmarking
    code:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了辅助函数，让我们看看基准测试代码：
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s now see how to test some code for throughput using the harness:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看如何使用 harness 测试代码的吞吐量：
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This harness provides only a simple throughput test. To inspect the throughput
    pattern you may want to bucket the throughput across rolling fixed-duration windows
    (e.g. per second throughput.) However, that topic is beyond the scope of this
    text, though we will touch upon it in the *Performance monitoring* section later
    in this chapter.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 harness 只提供了简单的吞吐量测试。为了检查吞吐量模式，你可能想要将吞吐量分配到滚动固定时间窗口中（例如每秒吞吐量）。然而，这个主题超出了本文的范围，尽管我们将在本章后面的*性能监控*部分中涉及到它。
- en: The load, stress, and endurance tests
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负载、压力和耐久性测试
- en: One of the characteristics of tests is each run only represents the slice of
    time it is executed through. Repeated runs establish their general behavior. But
    how many runs should be enough? There may be several anticipated load scenarios
    for an operation. So, there is a need to repeat the tests at various load scenarios.
    Simple test runs may not always exhibit the long-term behavior and response of
    the operation. Running the tests under varying high load for longer duration allows
    us to observe them for any odd behavior that may not show up in a short test cycle.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 测试的一个特点是每次运行只代表执行过程中的一个时间片段。重复运行可以建立它们的总体行为。但是，应该运行多少次才算足够呢？对于某个操作可能有几种预期的负载场景。因此，需要在各种负载场景下重复测试。简单的测试运行可能并不总是表现出操作的长期行为和响应。在较长的时间内以不同的高负载运行测试，可以让我们观察任何可能不会在短期测试周期中出现的异常行为。
- en: When we test an operation at a load far beyond its anticipated latency and throughput
    objectives, that is **stress testing**. The intent of a stress test is to ascertain
    a reasonable behavior exhibited by the operation beyond the maximum load it was
    developed for. Another way to observe the behavior of an operation is to see how
    it behaves when run for a very long duration, typically for several days or weeks.
    Such prolonged tests are called **endurance tests**. While a stress test checks
    the graceful behavior of the operation, an endurance test checks the consistent
    behavior of the operation over a long period.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在远超预期的延迟和吞吐量目标的负载下测试一个操作时，这就是**压力测试**。压力测试的目的是确定操作在超出其开发的最大负载时表现出的合理行为。观察操作行为的另一种方法是观察它在非常长时间运行时的表现，通常为几天或几周。这种长时间的测试被称为**耐久测试**。虽然压力测试检查操作的良好行为，但耐久测试检查操作在长时间内的稳定行为。
- en: There are several tools that may help with load and stress testing. Engulf ([http://engulf-project.org/](http://engulf-project.org/))
    is a distributed HTTP-based, load-generation tool written in Clojure. Apache JMeter
    and Grinder are Java-based load-generation tools. Grinder can be scripted using
    Clojure. Apache Bench is a load-testing tool for web systems. Tsung is an extensible,
    high-performance, load-testing tool written in Erlang.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种工具可以帮助进行负载和压力测试。Engulf ([http://engulf-project.org/](http://engulf-project.org/))
    是一个用Clojure编写的基于HTTP的分布式负载生成工具。Apache JMeter和Grinder是基于Java的负载生成工具。Grinder可以使用Clojure进行脚本化。Apache
    Bench是一个用于Web系统的负载测试工具。Tsung是一个用Erlang编写的可扩展、高性能的负载测试工具。
- en: Performance monitoring
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能监控
- en: During prolonged testing or after the application has gone to production, we
    need to monitor its performance to make sure the application continues to meet
    the performance objectives. There may be infrastructure or operational issues
    impacting the performance or availability of the application, or occasional spikes
    in latency or dips in throughput. Generally, monitoring alleviates such risk by
    generating a continuous feedback stream.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在长时间测试期间或应用上线后，我们需要监控其性能，以确保应用继续满足性能目标。可能存在影响应用性能或可用性的基础设施或运营问题，或者偶尔的延迟峰值或吞吐量下降。通常，监控通过生成持续的反馈流来减轻这种风险。
- en: Roughly there are three kinds of components used to build a monitoring stack.
    A **collector** sends the numbers from each host that needs to be monitored. The
    collector gets host information and the performance numbers and sends them to
    an **aggregator**. An aggregator receives the data sent by the collector and persists
    them until asked by a **visualizer** on behalf of the user.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 大概有三种组件用于构建监控堆栈。一个**收集器**将每个需要监控的主机上的数字发送出去。收集器获取主机信息和性能数字，并将它们发送到一个**聚合器**。聚合器接收收集器发送的数据，并在用户代表**可视化器**请求时持久化这些数据。
- en: The project **metrics-clojure** ([https://github.com/sjl/metrics-clojure](https://github.com/sjl/metrics-clojure))
    is a Clojure wrapper over the **Metrics** ([https://github.com/dropwizard/metrics](https://github.com/dropwizard/metrics))
    Java framework, which acts as a collector. **Statsd** is a well-known aggregator
    that does not persist data by itself but passes it on to a variety of servers.
    One of the popular visualizer projects is **Graphite** that stores the data as
    well as produces graphs for requested periods. There are several other alternatives
    to these, notably **Riemann** ([http://riemann.io/](http://riemann.io/)) that
    is written in Clojure and Ruby. Riemann is an event processing-based aggregator.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 项目 **metrics-clojure** ([https://github.com/sjl/metrics-clojure](https://github.com/sjl/metrics-clojure))
    是一个Clojure封装的 **Metrics** ([https://github.com/dropwizard/metrics](https://github.com/dropwizard/metrics))
    Java框架，它作为一个收集器。**Statsd** 是一个知名的聚合器，它本身不持久化数据，而是将数据传递给各种服务器。其中最受欢迎的可视化项目之一是 **Graphite**，它不仅存储数据，还为请求的时段生成图表。还有其他几种替代方案，特别是用Clojure和Ruby编写的
    **Riemann** ([http://riemann.io/](http://riemann.io/))，它是一个基于事件处理的聚合器。
- en: Monitoring through logs
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过日志进行监控
- en: One of the popular performance monitoring approaches that has emerged in recent
    times is via logs. The idea is simple—the application emits metrics data as logs,
    which are shipped from the individual machine to a central log aggregation service.
    Then, those metrics data are aggregated for each time window and further moved
    for archival and visualization.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来出现的一种流行的性能监控方法是通过对日志的监控。这个想法很简单——应用程序以日志的形式发出指标数据，这些数据从单个机器发送到中央日志聚合服务。然后，这些指标数据在每个时间窗口内进行聚合，并进一步移动以进行归档和可视化。
- en: 'As a high-level example of such a monitoring system, you may like to use **Logstash-forwarder**
    ([https://github.com/elastic/logstash-forwarder](https://github.com/elastic/logstash-forwarder))
    to grab the application logs from the local filesystem and ship to **Logstash**
    ([https://www.elastic.co/products/logstash](https://www.elastic.co/products/logstash)),
    where it forwards the metrics logs to **StatsD** ([https://github.com/etsy/statsd](https://github.com/etsy/statsd))
    for metrics aggregation or to Riemann ([http://riemann.io/](http://riemann.io/))
    for events analysis and monitoring alerts. StatsD and/or Riemann can forward the
    metrics data to Graphite ([http://graphite.wikidot.com/](http://graphite.wikidot.com/))
    for archival and graphing of the time-series metrics data. Often, people want
    to plug in a non-default time-series data store (such as **InfluxDB**: [https://influxdb.com/](https://influxdb.com/))
    or a visualization layer (such as **Grafana**: [http://grafana.org/](http://grafana.org/))
    with Graphite.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 作为此类监控系统的示例，你可能想使用 **Logstash-forwarder** ([https://github.com/elastic/logstash-forwarder](https://github.com/elastic/logstash-forwarder))
    从本地文件系统抓取应用程序日志并将其发送到 **Logstash** ([https://www.elastic.co/products/logstash](https://www.elastic.co/products/logstash))，在那里它将指标日志转发到
    **StatsD** ([https://github.com/etsy/statsd](https://github.com/etsy/statsd))
    进行指标聚合，或者转发到 **Riemann** ([http://riemann.io/](http://riemann.io/)) 进行事件分析和监控警报。StatsD
    和/或 Riemann 可以将指标数据转发到 Graphite ([http://graphite.wikidot.com/](http://graphite.wikidot.com/))
    进行归档和时间序列指标数据的图表化。通常，人们希望将非默认的时间序列数据存储（如 **InfluxDB**：[https://influxdb.com/](https://influxdb.com/))
    或可视化层（如 **Grafana**：[http://grafana.org/](http://grafana.org/)) 与 Graphite 连接起来。
- en: A detailed discussion on this topic is out of the scope of this text, but I
    think exploring this area would serve you well.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个话题的详细讨论超出了本文的范围，但我认为探索这个领域对你大有裨益。
- en: Ring (web) monitoring
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 环境监控（web监控）
- en: 'If you develop web software using Ring ([https://github.com/ring-clojure/ring](https://github.com/ring-clojure/ring))
    then you may find the Ring extension of the metrics-clojure library useful: [http://metrics-clojure.readthedocs.org/en/latest/ring.html](http://metrics-clojure.readthedocs.org/en/latest/ring.html)
    —this tracks a number of useful metrics that can be queried in JSON format and
    integrated with visualization via the web browser.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用 Ring ([https://github.com/ring-clojure/ring](https://github.com/ring-clojure/ring))
    开发Web软件，那么你可能觉得 metrics-clojure 库的 Ring 扩展很有用：[http://metrics-clojure.readthedocs.org/en/latest/ring.html](http://metrics-clojure.readthedocs.org/en/latest/ring.html)
    ——它跟踪了许多有用的指标，这些指标可以以JSON格式查询，并通过网络浏览器与可视化集成。
- en: To emit a continuous stream of metrics data from the web layer, **Server-Sent
    Events** (**SSE**) may be a good idea due to its low overhead. Both **http-kit**
    ([http://www.http-kit.org/](http://www.http-kit.org/)) and **Aleph** ([http://aleph.io/](http://aleph.io/)),
    which work with Ring, support SSE today.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 要从网络层发出连续的指标数据流，**服务器端事件** (**SSE**) 可能是一个好主意，因为它具有低开销。**http-kit** ([http://www.http-kit.org/](http://www.http-kit.org/))
    和 **Aleph** ([http://aleph.io/](http://aleph.io/))，它们与 Ring 一起工作，今天都支持 SSE。
- en: Introspection
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反省
- en: Both Oracle JDK and OpenJDK provide two GUI tools called **JConsole** (executable
    name `jconsole`) and **JVisualVM** (executable name `jvisualvm`) that we can use
    to introspect into running JVMs for instrumentation data. There are also some
    command-line tools ([http://docs.oracle.com/javase/8/docs/technotes/tools/](http://docs.oracle.com/javase/8/docs/technotes/tools/))
    in the JDK to peek into the inner details of the running JVMs.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Oracle JDK 和 OpenJDK 都提供了两个名为 **JConsole** (可执行名称 `jconsole`) 和 **JVisualVM**
    (可执行名称 `jvisualvm`) 的 GUI 工具，我们可以使用它们来反省正在运行的 JVM 以获取仪器化数据。JDK 中还有一些命令行工具 ([http://docs.oracle.com/javase/8/docs/technotes/tools/](http://docs.oracle.com/javase/8/docs/technotes/tools/))，可以窥探正在运行的
    JVM 的内部细节。
- en: A common way to introspect a running Clojure application is to have an **nREPL**
    ([https://github.com/clojure/tools.nrepl](https://github.com/clojure/tools.nrepl))
    service running so that we can connect to it later using an nREPL client. Interactive
    introspection over nREPL using the Emacs editor (embedded nREPL client) is popular
    among some, whereas others prefer to script an nREPL client to carry out tasks.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 反省一个正在运行的 Clojure 应用程序的一种常见方法是运行一个 **nREPL** ([https://github.com/clojure/tools.nrepl](https://github.com/clojure/tools.nrepl))
    服务，这样我们就可以稍后使用 nREPL 客户端连接到它。使用 Emacs 编辑器（内嵌 nREPL 客户端）进行 nREPL 的交互式反省在一些人中很受欢迎，而其他人则更喜欢编写
    nREPL 客户端脚本来执行任务。
- en: JVM instrumentation via JMX
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过 JMX 进行 JVM 仪器化
- en: The JVM has a built-in mechanism to introspect managed resources via the extensible
    **Java Management Extensions** (**JMX**) API. It provides a way for application
    maintainers to expose manageable resources as "MBeans". Clojure has an easy-to-use
    `contrib` library called `java.jmx` ([https://github.com/clojure/java.jmx](https://github.com/clojure/java.jmx))
    to access JMX. There is a decent amount of open source tooling for visualization
    of JVM instrumentation data via JMX, such as `jmxtrans` and `jmxetric`, which
    integrate with Ganglia and Graphite.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: JVM 通过可扩展的 **Java 管理扩展** (**JMX**) API 内置了一种反省管理资源的机制。它为应用程序维护者提供了一种将可管理资源作为“MBeans”公开的方法。Clojure
    有一个名为 `java.jmx` 的易于使用的 `contrib` 库 ([https://github.com/clojure/java.jmx](https://github.com/clojure/java.jmx))，用于访问
    JMX。有一些开源工具可用于通过 JMX 可视化 JVM 仪器化数据，例如 `jmxtrans` 和 `jmxetric`，它们与 Ganglia 和 Graphite
    集成。
- en: 'Getting quick memory stats of the JVM is pretty easy using Clojure:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Clojure 获取 JVM 的快速内存统计信息相当简单：
- en: '[PRE8]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Profiling
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析
- en: 'We briefly discussed profiler types in [Chapter 1](ch01.html "Chapter 1. Performance
    by Design"), *Performance by Design*. The JVisualVM tool we discussed with respect
    to introspection in the previous section is also a CPU and memory profiler that
    comes bundled with the JDK. Let''s see them in action— consider the following
    two Clojure functions that stress the CPU and memory respectively:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第1章](ch01.html "第1章。通过设计进行性能")中简要讨论了分析器类型，即“通过设计进行性能”。我们之前讨论的与反省相关的 JVisualVM
    工具也是一个 CPU 和内存分析器，它随 JDK 一起提供。让我们看看它们在实际中的应用——考虑以下两个 Clojure 函数，它们分别对 CPU 和内存进行压力测试：
- en: '[PRE9]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Using JVisualVM is pretty easy—open the Clojure JVM process from the left pane.
    It has sampler and regular profiler styles of profiling. Start profiling for CPU
    or memory use when the code is running and wait for it to collect enough data
    to plot on the screen.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 JVisualVM 非常简单——从左侧面板打开 Clojure JVM 进程。它具有采样和常规分析器风格的分析。当代码运行时，开始对 CPU 或内存使用进行分析，并等待收集足够的数据以在屏幕上绘制。
- en: '![Profiling](img/3642_06_03.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![分析](img/3642_06_03.jpg)'
- en: 'The following shows memory profiling in action:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 以下展示了内存分析的实际操作：
- en: '![Profiling](img/3642_06_04.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![分析](img/3642_06_04.jpg)'
- en: Note that JVisualVM is a very simple, entry-level profiler. There are several
    commercial JVM profilers on the market for sophisticated needs.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，JVisualVM 是一个非常简单、入门级的分析器。市场上有多款商业 JVM 分析器，用于满足复杂需求。
- en: OS and CPU/cache-level profiling
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作系统和 CPU/缓存级别分析
- en: Profiling only the JVM may not always tell the whole story. Getting down to
    OS and hardware-level profiling often provides better insight into what is going
    on with the application. On Unix-like operating systems, command-line tools such
    as `top`, `htop`, `perf`, `iota`, `netstat`, `vista`, `upstate`, `pidstat` etc
    can help. Profiling the CPU for cache misses and other information is a useful
    source to catch performance issues. Among open source tools for Linux, **Likwid**
    ([http://code.google.com/p/likwid/](http://code.google.com/p/likwid/) and [https://github.com/rrze-likwid/likwid](https://github.com/rrze-likwid/likwid))
    is small yet effective for Intel and AMD processors; **i7z** ([https://code.google.com/p/i7z/](https://code.google.com/p/i7z/)
    and [https://github.com/ajaiantilal/i7z](https://github.com/ajaiantilal/i7z))
    is specifically for Intel processors. There are also dedicated commercial tools
    such as **Intel VTune Analyzer** for more elaborate needs.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 仅对JVM进行性能分析可能并不总是能揭示全部情况。深入到操作系统和硬件级别的性能分析通常能更好地了解应用程序的情况。在类Unix操作系统中，如`top`、`htop`、`perf`、`iota`、`netstat`、`vista`、`upstate`、`pidstat`等命令行工具可以帮助。对CPU进行缓存缺失和其他信息的分析是捕捉性能问题的有用来源。在Linux的开源工具中，**Likwid**（[http://code.google.com/p/likwid/](http://code.google.com/p/likwid/)
    和 [https://github.com/rrze-likwid/likwid](https://github.com/rrze-likwid/likwid)）对于Intel和AMD处理器来说体积小但效果显著；**i7z**（[https://code.google.com/p/i7z/](https://code.google.com/p/i7z/)
    和 [https://github.com/ajaiantilal/i7z](https://github.com/ajaiantilal/i7z)）专门针对Intel处理器。还有针对更复杂需求的专用商业工具，如**Intel
    VTune Analyzer**。
- en: I/O profiling
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I/O性能分析
- en: Profiling I/O may require special tools too. Besides `iota` and `blktrace`,
    `ioping` ([https://code.google.com/p/ioping/](https://code.google.com/p/ioping/)
    and [https://github.com/koct9i/ioping](https://github.com/koct9i/ioping)) is useful
    to measure real-time I/O latency on Linux/Unix systems. The **vnStat** tool is
    useful to monitor and log network traffic on Linux. The IOPS of a storage device
    may not tell the whole truth unless it is accompanied by latency information for
    different operations, and how many reads and writes can simultaneously happen.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 分析I/O可能也需要特殊的工具。除了`iota`和`blktrace`之外，`ioping`（[https://code.google.com/p/ioping/](https://code.google.com/p/ioping/)
    和 [https://github.com/koct9i/ioping](https://github.com/koct9i/ioping)）对于测量Linux/Unix系统上的实时I/O延迟很有用。**vnStat**工具对于监控和记录Linux上的网络流量很有用。存储设备的IOPS可能无法完全反映真相，除非它伴随着不同操作的延迟信息，以及可以同时发生的读取和写入次数。
- en: In an I/O bound workload one has to look for the read and write IOPS over time
    and set a threshold to achieve optimum performance. The application should throttle
    the I/O access so that the threshold is not crossed.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在I/O密集型的工作负载中，必须随着时间的推移寻找读取和写入IOPS，并设置一个阈值以实现最佳性能。应用程序应限制I/O访问，以确保不超过阈值。
- en: Summary
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Delivering high-performance applications not only requires care for performance
    but also systematic effort to measure, test, monitor, and optimize the performance
    of various components and subsystems. These activities often require the right
    skill and experience. Sometimes, performance considerations may even bring system
    design and architecture back to the drawing board. Early structured steps taken
    to achieve performance go a long way to ensuring that the performance objectives
    are being continuously met.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 提供高性能应用程序不仅需要关注性能，还需要系统地测量、测试、监控和优化各种组件和子系统的性能。这些活动通常需要正确的技能和经验。有时，性能考虑甚至可能将系统设计和架构推回设计图板。早期采取的结构化步骤对于确保持续满足性能目标至关重要。
- en: In the next chapter, we will look into performance optimization tools and techniques.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨性能优化工具和技术。
