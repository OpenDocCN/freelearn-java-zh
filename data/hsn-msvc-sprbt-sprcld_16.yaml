- en: Understanding Distributed Tracing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解分布式追踪
- en: In this chapter, we will learn how to use distributed tracing to better understand
    how our microservices cooperate; for example, fulfilling a request sent to the
    external API. Being able to utilize distributed tracing is essential for being
    able to manage a system landscape of cooperating microservices. As already described
    in [Chapter 8](9878a36a-5760-41a4-a132-1a2387b61037.xhtml), *Introduction to Spring
    Cloud*, in reference to the *Spring Cloud Sleuth and Zipkin for distributed tracing* section,
    Spring Cloud Sleuth will be used to collect trace information, and Zipkin will
    be used for the storage and visualization of said trace information.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何使用分布式追踪更好地了解我们的微服务如何协作，例如，对外部API发送请求。能够利用分布式追踪对于能够管理相互协作的微服务系统架构至关重要。如已在[第8章](9878a36a-5760-41a4-a132-1a2387b61037.xhtml),
    *Spring Cloud简介*中提到的*Spring Cloud Sleuth和Zipkin进行分布式追踪*部分所述，Spring Cloud Sleuth将用于收集追踪信息，而Zipkin将用于存储和可视化所述追踪信息。
- en: 'In this chapter, we will learn about the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习以下主题：
- en: Introducing distributed tracing with Spring Cloud Sleuth and Zipkin
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spring Cloud Sleuth和Zipkin引入分布式追踪
- en: How to add distributed tracing to the source code
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将分布式追踪添加到源代码中
- en: 'How to perform distributed tracing:'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何进行分布式追踪：
- en: 'We will learn how to visualize trace information using Zipkin in relation to
    the following:'
  id: totrans-6
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将学习如何使用Zipkin可视化追踪信息，并与以下内容相关：
- en: Successful and unsuccessful API requests
  id: totrans-7
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成功和失败的API请求
- en: Synchronous and asynchronous processing of API requests
  id: totrans-8
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: API请求的同步和异步处理
- en: We will use both RabbitMQ and Kafka to send trace events from our microservices
    to the Zipkin server
  id: totrans-9
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将同时使用RabbitMQ和Kafka将微服务中的追踪事件发送到Zipkin服务器
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All commands described in this book are run on a MacBook Pro using macOS Mojave
    but should be straightforward to modify so that they can be run on another platform
    such as Linux or Windows.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中描述的所有命令都是在MacBook Pro上使用macOS Mojave运行的，但应该很容易修改，以便它们可以在其他平台（如Linux或Windows）上运行。
- en: No new tools need to be installed in this chapter.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中不需要安装任何新工具。
- en: The source code for this chapter can be found on GitHub at [https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter14](https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter14).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的源代码可以在GitHub上找到，地址为[https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter14](https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter14)。
- en: 'To be able to run the commands as described in the book, download the source
    code to a folder and set up an environment variable, `$BOOK_HOME`, that points
    to that folder. Some sample commands are as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够按照书中描述运行命令，将源代码下载到一个文件夹中，并设置一个环境变量`$BOOK_HOME`，使其指向该文件夹。一些示例命令如下：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The Java source code is written for Java 8 and tested on Java 12\. This chapter
    uses Spring Cloud 2.1.0, SR1 (also known as the **Greenwich** release), Spring
    Boot 2.1.4, and Spring 5.1.6, that is, the latest available version of the Spring
    components at the time of writing this chapter.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 该Java源代码是为Java 8编写的，并在Java 12上进行了测试。本章使用Spring Cloud 2.1.0, SR1（也称为**Greenwich**版本），Spring
    Boot 2.1.4和Spring 5.1.6，即在撰写本章时可用的Spring组件的最新版本。
- en: The base Docker image, `openjdk:12.0.2`, is used in all Dockerfiles.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 所有Dockerfile中均使用基础Docker镜像`openjdk:12.0.2`。
- en: All source code examples in this chapter come from the source code in `$BOOK_HOME/Chapter14` but
    are, in several cases, edited to remove non-relevant parts of the source code,
    such as comments and import and log statements.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的所有示例代码均来自`$BOOK_HOME/Chapter14`的源代码，但在许多情况下，为了删除源代码中不相关部分，例如注释和导入以及日志声明，对其进行了编辑。
- en: If you want to see the changes applied to the source code in this chapter, that
    is, see what it took to add distributed tracing using Spring Cloud Sleuth and
    Zipkin, you can compare it with the source code for [Chapter 13](23795d34-4068-4961-842d-989cde26b642.xhtml),
    *Improving Resilience Using Resilience4j*. You can use your favorite `diff` tool
    and compare the two folders – `$BOOK_HOME/Chapter13` and `$BOOK_HOME/Chapter14`.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想查看本章源代码所做的更改，即了解添加Spring Cloud Sleuth和Zipkin进行分布式追踪所需的内容，你可以将其与[第13章](23795d34-4068-4961-842d-989cde26b642.xhtml),
    *使用Resilience4j提高弹性*的源代码进行比较。你可以使用你喜欢的`diff`工具，比较两个文件夹——`$BOOK_HOME/Chapter13`和`$BOOK_HOME/Chapter14`。
- en: Introducing distributed tracing with Spring Cloud Sleuth and Zipkin
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spring Cloud Sleuth和Zipkin引入分布式跟踪。
- en: 'To recapitulate from [Chapter 8](9878a36a-5760-41a4-a132-1a2387b61037.xhtml), *Introduction
    to Spring Cloud*, in reference to the *Spring Cloud Sleuth and Zipkin for distributed
    tracing* section, the tracing information from a complete workflow is called a
    **trace** or a **trace** **tree**, and sub-parts of the tree, for example, the
    basic units of work, are called a **span**. Spans can consist of sub spans forming
    the trace tree. The Zipkin UI can visualize a trace tree and its spans as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾[第8章](9878a36a-5760-41a4-a132-1a2387b61037.xhtml)，*Spring Cloud简介*，在*分布式跟踪的Spring
    Cloud Sleuth和Zipkin*部分，整个工作流程的跟踪信息称为一个**跟踪**或一个**跟踪树**，树的子部分，例如工作基本单元，称为一个**跨度**。跨度可以包括子跨度，形成跟踪树。Zipkin
    UI可以如下可视化跟踪树和其跨度：
- en: '![](img/c486eb1c-6ecf-4f66-9783-fdecfe33f7dc.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c486eb1c-6ecf-4f66-9783-fdecfe33f7dc.png)'
- en: 'Spring Cloud Sleuth can send trace information to Zipkin either synchronously
    over HTTP, or asynchronously using a message broker such as RabbitMQ or Kafka.
    To avoid creating runtime dependencies on the Zipkin server from the microservices,
    it is preferable to send trace information to Zipkin asynchronously using either
    RabbitMQ or Kafka. This is illustrated in the following diagram:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Sleuth可以通过HTTP同步发送跟踪信息到Zipkin，或者使用RabbitMQ或Kafka等消息代理异步发送。为了避免在微服务中创建对Zipkin服务器的运行时依赖，最好使用RabbitMQ或Kafka异步发送跟踪信息到Zipkin。以下图表说明了这一点：
- en: '![](img/0006d41f-9f89-4f39-a1ca-8d3971451602.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0006d41f-9f89-4f39-a1ca-8d3971451602.png)'
- en: Zipkin comes with native support for storing trace information either in memory,
    or in Apache Cassandra, Elasticsearch, or MySQL. Added to this, a number of extensions
    are available. For details, refer to [https://zipkin.apache.org/pages/extensions_choices.html](https://zipkin.apache.org/pages/extensions_choices.html)[.](https://zipkin.apache.org/pages/extensions_choices.html) In
    this chapter, we will store the trace information in memory.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Zipkin支持本地存储跟踪信息，存储在内存中，或存储在Apache Cassandra、Elasticsearch或MySQL中。此外，还有许多扩展可用。具体信息请参考[https://zipkin.apache.org/pages/extensions_choices.html](https://zipkin.apache.org/pages/extensions_choices.html)。在本章中，我们将把跟踪信息存储在内存中。
- en: Adding distributed tracing to the source code
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向源代码添加分布式跟踪。
- en: 'In this section, we will learn how to update the source code to enable distributed
    tracing using Spring Cloud Sleuth and Zipkin. This can be done through the following
    steps:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何更新源代码，使用Spring Cloud Sleuth和Zipkin启用分布式跟踪。可以通过以下步骤完成：
- en: Add dependencies to the build files to bring in Spring Cloud Sleuth and the
    capability of sending trace information to Zipkin.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向构建文件添加依赖项，以引入Spring Cloud Sleuth和将跟踪信息发送到Zipkin的能力。
- en: Add dependencies to RabbitMQ and Kafka for the projects that haven't used them
    before, that is, the Spring Cloud projects `authorization-server`, `eureka-server`, and
    `gateway`.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为之前未使用过的项目（即Spring Cloud项目的`authorization-server`、`eureka-server`和`gateway`）添加RabbitMQ和Kafka依赖项。
- en: Configure the microservices to send trace information to Zipkin using either
    RabbitMQ or Kafka.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置微服务使用RabbitMQ或Kafka将跟踪信息发送到Zipkin。
- en: Add a Zipkin server to the Docker compose files.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Docker Compose文件中添加一个Zipkin服务器。
- en: Add the `kafka` Spring profile in `docker-compose-kafka.yml` to the Spring Cloud
    projects `authorization-server`, `eureka-server`, and `gateway`.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`docker-compose-kafka.yml`中为Spring Cloud项目的`authorization-server`、`eureka-server`和`gateway`添加`kafka`
    Spring配置文件。
- en: Adding the Zipkin server will be effected using a Docker image from Docker Hub
    that has been published by the Zipkin project. Refer to [https://hub.docker.com/r/openzipkin/zipkin](https://hub.docker.com/r/openzipkin/zipkin)
    for details.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 添加Zipkin服务器将通过使用Docker Hub上由Zipkin项目发布的Docker镜像来实现。具体细节请参考[https://hub.docker.com/r/openzipkin/zipkin](https://hub.docker.com/r/openzipkin/zipkin)。
- en: Zipkin is itself a Spring Boot application and is, at the time of writing, undergoing
    incubation at the **Apache Software Foundation** (**ASF**). Refer to [https://zipkin.apache.org/](https://zipkin.apache.org/)
    for more information.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Zipkin本身是一个Spring Boot应用程序，在撰写本文时，它正在Apache软件基金会（ASF）下孵化。更多信息请参考[https://zipkin.apache.org/](https://zipkin.apache.org/)。
- en: Adding dependencies to build files
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向构建文件添加依赖项。
- en: To be able to utilize Spring Cloud Sleuth and the ability to send trace information
    to Zipkin, we need to add a couple of dependencies to the Gradle project build
    files, `build.gradle`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够使用Spring Cloud Sleuth并发送跟踪信息到Zipkin，我们需要在Gradle项目的构建文件`build.gradle`中添加几个依赖项：
- en: 'This is accomplished by adding the following two lines:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这通过添加以下两行来实现：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'For the Gradle projects that haven''t used RabbitMQ and Kafka before, that
    is, the Spring Cloud projects `authorization-server`, `eureka-server`, and `gateway`,
    the following dependencies have to be added:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于尚未使用过RabbitMQ和Kafka的Gradle项目，即Spring Cloud项目`authorization-server`、`eureka-server`和`gateway`，需要添加以下依赖项：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Adding configuration for Spring Cloud Sleuth and Zipkin
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为Spring Cloud Sleuth和Zipkin添加配置
- en: 'Configuration for using Spring Cloud Sleuth and Zipkin is added to the common
    configuration file, `config-repo/application.yml`. In the default profile, it
    is specified that trace information shall be sent to Zipkin using RabbitMQ:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在公共配置文件`config-repo/application.yml`中添加了使用Spring Cloud Sleuth和Zipkin的配置。在默认配置文件中，指定跟踪信息应通过RabbitMQ发送到Zipkin：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'By default, Spring Cloud Sleuth only sends 10% of the traces to Zipkin. To
    ensure that all traces are sent to Zipkin, the following property is added in
    the default profile:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Spring Cloud Sleuth只将10%的跟踪信息发送到Zipkin。为了确保所有跟踪信息都发送到Zipkin，在默认配置文件中添加了以下属性：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'When sending traces to Zipkin using Kafka, the Spring profile `kafka` will
    be used. In earlier chapters, the `kafka` Spring profile was defined in the configuration
    files specific to the composite and core microservices. In this chapter, where
    the Spring Cloud services will also use Kafka to send trace information to Zipkin,
    the `kafka` Spring profile is moved to the common configuration file, `config-repo/application.yml`.
    The following two properties have also been added to the `kafka` Spring profile:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用Kafka将跟踪信息发送到Zipkin时，将使用`kafka`Spring配置文件。在前几章中，`kafka`Spring配置文件是在特定于组合和核心微服务的配置文件中定义的。在本章中，Spring
    Cloud服务也将使用Kafka将跟踪信息发送到Zipkin，因此将`kafka`Spring配置文件移动到公共配置文件`config-repo/application.yml`中。在`kafka`Spring配置文件中还添加了以下两个属性：
- en: '`spring.zipkin.sender.type: kafka` tells Spring Cloud Sleuth to send trace
    information to Zipkin using Kafka.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spring.zipkin.sender.type: kafka`告诉Spring Cloud Sleuth使用Kafka将跟踪信息发送到Zipkin。'
- en: '`spring.kafka.bootstrap-servers: kafka:9092` specifies where to find the Kafka
    server.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spring.kafka.bootstrap-servers: kafka:9092`指定了Kafka服务器的所在位置。'
- en: 'All in all, the `kafka` Spring profile appears as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，`kafka`Spring配置文件如下所示：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Adding Zipkin to the Docker Compose files
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Zipkin添加到Docker Compose文件中
- en: 'As we mentioned previously, the Zipkin server is added to the Docker Compose
    files using an already existing Docker image, `openzipkin/zipkin`, published by
    the Zipkin project. In `docker-compose.yml` and `docker-compose-partitions.yml`,
    where RabbitMQ is used, the definition of the Zipkin server appears as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，Zipkin服务器是通过使用已经存在的Docker镜像`openzipkin/zipkin`添加到Docker Compose文件中的，该镜像是由Zipkin项目发布的。在`docker-compose.yml`和`docker-compose-partitions.yml`中，其中使用RabbitMQ时，Zipkin服务器的定义如下所示：
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s explain the preceding source code:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解释一下前面的源代码：
- en: The version of the Docker image, `openzipkin/zipkin`, is specified to be version
    `2.12.19`.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker镜像`openzipkin/zipkin`的版本被指定为`2.12.19`版本。
- en: The `RABBIT_ADDRESSES=rabbitmq` environment variable is used to specify that
    Zipkin shall receive trace information using RabbitMQ and that Zipkin shall connect
    to RabbitMQ using the hostname `rabbitmq`.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境变量`RABBIT_ADDRESSES=rabbitmq`用于指定Zipkin使用RabbitMQ接收跟踪信息，并且Zipkin使用主机名`rabbitmq`连接到RabbitMQ。
- en: The `STORAGE_TYPE=mem` environment variable is used to specify that Zipkin shall keep
    all trace information in memory.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境变量`STORAGE_TYPE=mem`用于指定Zipkin将所有跟踪信息保存在内存中。
- en: The memory limit for Zipkin is increased to 512 MB, compared to 350 MB for all
    other containers. The reason for this is that since Zipkin is configured to keep
    all trace information in memory, it will consume more memory than the other containers
    after a while.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zipkin的内存限制增加到512 MB，而其他容器的内存限制为350 MB。这是因为Zipkin被配置为将所有跟踪信息保存在内存中，所以过了一段时间后，它将比其他容器消耗更多的内存。
- en: Zipkin exposes the HTTP port `9411` for web browsers to access its web user
    interface.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zipkin暴露出HTTP端口`9411`，供浏览器访问其Web用户界面。
- en: Docker will wait to start up the Zipkin server until the RabbitMQ service reports
    being healthy to Docker.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker将等待启动Zipkin服务器，直到RabbitMQ服务向Docker报告自己运行正常。
- en: While this is OK to store the trace information in Zipkin in memory for development
    and test activities, Zipkin should be configured to store trace information in
    a database such as Apache Cassandra, Elasticsearch, or MySQL in a production environment.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这对于将跟踪信息存储在Zipkin内存中以进行开发和测试活动来说是可行的，但在生产环境中，Zipkin应配置为将跟踪信息存储在数据库中，例如Apache
    Cassandra、Elasticsearch或MySQL。
- en: 'In `docker-compose-kafka.yml`, where Kafka is used, the definition of the Zipkin
    server appears as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在`docker-compose-kafka.yml`中，其中使用了Kafka，Zipkin服务器的定义如下所示：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let''s explain for the preceding source code in detail:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细解释一下前面的源代码：
- en: The configuration for using Zipkin together with Kafka is similar to the configuration
    when using Zipkin with RabbitMQ previously.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Zipkin和Kafka的配置与之前使用Zipkin和RabbitMQ的配置相似。
- en: The main difference it the use of the `KAFKA_BOOTSTRAP_SERVERS=kafka:9092` environment
    variable, which is used to specify that Zipkin shall use Kafka to receive trace
    information and that Zipkin shall connect to Kafka using the hostname `kafka` and
    the port `9092`.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主要区别在于使用`KAFKA_BOOTSTRAP_SERVERS=kafka:9092`环境变量，该变量用于指定Zipkin应使用Kafka接收跟踪信息，并且Zipkin应通过主机名`kafka`和端口`9092`连接到Kafka。
- en: 'In `docker-compose-kafka.yml`, the `kafka` Spring profile is added to the Spring
    Cloud services `eureka`, `gateway`, and `auth-server`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在`docker-compose-kafka.yml`中，为Spring Cloud服务`eureka`、`gateway`和`auth-server`添加了`kafka`
    Spring配置文件：
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: That's what it takes to add distributed tracing using Spring Cloud Sleuth and
    Zipkin, so let's try it out in the next section!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是使用Spring Cloud Sleuth和Zipkin添加分布式跟踪所需的一切，所以在下一节让我们试试吧！
- en: Trying out distributed tracing
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 尝试分布式跟踪
- en: 'With the necessary changes to the source code in place, we can try out distributed
    tracing! We will do this by performing the following steps:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在源代码中进行了必要的更改后，我们可以尝试分布式跟踪！我们将通过执行以下步骤来实现：
- en: Build, start, and verify the system landscape with RabbitMQ as the queue manager.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建、启动并验证使用RabbitMQ作为队列管理器的系统架构。
- en: Send a successful API request and see what trace information we can find in
    Zipkin related to this API request.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送一个成功的API请求，看看我们可以找到与这个API请求相关的Zipkin中的跟踪信息。
- en: Send an unsuccessful API request and see what the trace information in Zipkin
    looks like.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送一个失败的API请求，看看Zipkin中的跟踪信息是什么样子。
- en: Send a successful API request that triggers asynchronous processing and see
    how its trace information is represented in Zipkin.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送一个成功的API请求，触发异步处理，并查看其在Zipkin中的跟踪信息表示。
- en: Investigate how we can monitor trace information that's passed to Zipkin in
    RabbitMQ.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调查如何监控通过RabbitMQ传递给Zipkin的跟踪信息。
- en: Switch the queue manager to Kafka and repeat the preceding steps.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将队列管理器切换到Kafka，并重复前面的步骤。
- en: We will discuss these steps in detail in the upcoming sections.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的部分详细讨论这些步骤。
- en: Starting up the system landscape with RabbitMQ as the queue manager
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用RabbitMQ作为队列管理器启动系统架构
- en: 'Let''s start up the system landscape. Build the Docker images with the following
    commands:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们启动系统架构。使用以下命令构建Docker镜像：
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Start the system landscape in Docker and run the usual tests with the following
    command:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Docker启动系统架构，并使用以下命令运行常规测试：
- en: '[PRE10]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Before we can call the API, we need an access token. Run the following commands
    to acquire an access token:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以调用API之前，我们需要一个访问令牌。运行以下命令以获取访问令牌：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Sending a successful API request
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发送一个成功的API请求
- en: 'Now, we are ready to send a normal request to the API. Run the following command:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备发送一个正常的API请求。运行以下命令：
- en: '[PRE12]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Expect the command to returns the HTTP status code for success, 200.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 期望命令返回成功的HTTP状态码，即200。
- en: 'We can now launch the Zipkin UI to look into what trace information has been
    sent to Zipkin:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以启动Zipkin UI，查看已经发送到Zipkin的跟踪信息：
- en: Open the following URL in your web browser: `http://localhost:9411/zipkin/.`
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的网络浏览器中打开以下URL：`http://localhost:9411/zipkin/`。
- en: 'To find the trace information for our request, implement the following steps:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了找到我们请求的跟踪信息，请执行以下步骤：
- en: Select Service Name: gateway.
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择“服务名称”：gateway。
- en: 'Set Sort order: to Newest First.'
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置排序顺序：最新优先。
- en: Click on the Find Traces button.
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“查找跟踪”按钮。
- en: 'The response from finding traces should look like the following screenshot:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 查找跟踪的响应应如下所示：
- en: '![](img/ee509be8-dcc5-41bb-b758-361379f8fe94.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee509be8-dcc5-41bb-b758-361379f8fe94.png)'
- en: 'The trace information from our preceding API request is the first one in the
    list. Click on it to see details pertaining to the trace:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前的API请求的跟踪信息是列表中的第一个。点击它以查看与跟踪相关的详细信息：
- en: '![](img/8fa726b9-d1b5-424a-ade5-c5324f925c2c.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8fa726b9-d1b5-424a-ade5-c5324f925c2c.png)'
- en: 'In the detailed trace information view, we can observe the following:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在详细的跟踪信息视图中，我们可以观察到以下内容：
- en: The request was received by the gateway service.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请求被网关服务接收。
- en: It delegated the processing of the request to the product-composite service.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将请求的处理委托给了`product-composite`服务。
- en: The product-composite service, in turn, sent three parallel requests to the
    core services: product, recommendation, and review.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`product-composite`服务反过来向核心服务发送了三个并行请求：`product`、`recommendation`和`review`。'
- en: Once the product-composite service received the response from all three core
    services, it created a composite response.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦`product-composite`服务收到了所有三个核心服务的响应，它就创建了一个复合响应。
- en: The composite response was sent back to the caller through the gateway service.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复合响应通过网关服务返回到调用者。
- en: When using Safari, I have noticed that the trace tree isn't always rendered
    correctly. Switching to either Chrome or Firefox resolved the issue.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用Safari时，我注意到跟踪树并不总是正确渲染。切换到Chrome或Firefox可以解决此问题。
- en: 'If we click on the first span, gateway, we can see even more details:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们点击第一个跨度，网关，我们可以看到更多细节：
- en: '![](img/f6f693ce-7cea-43ea-ba6c-8faa8db74269.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f6f693ce-7cea-43ea-ba6c-8faa8db74269.png)'
- en: Here, we can see the actual request we sent: product-composite/2\. This is very
    valuable when analyzing traces that, for example, take a long time to complete!
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们可以看到我们实际发送的请求：`product-composite/2`。这在我们分析例如长时间完成的跟踪时非常有价值！
- en: Sending an unsuccessful API request
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发送一个失败的API请求
- en: 'Let''s see what the trace information looks like if we make an unsuccessful
    API request; for example, searching for a product that does not exist:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如果我们发起一个失败的API请求会怎样，例如，搜索一个不存在的产品：
- en: 'Send an API request for product ID `12345` and verify that it returns the HTTP
    status code for Not Found, 404:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为产品ID `12345`发送API请求，并验证它返回了未找到的HTTP状态码，即404：
- en: '[PRE13]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In the Zipkin UI, go back to the search page (use the back button in the web
    browser) and click on the Find Traces button. You should see the failed request
    at the top of the returned list, in red:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Zipkin UI中，回到搜索页面（在网页浏览器中使用后退按钮）并点击“查找跟踪”按钮。你应该会在返回列表的顶部看到失败的请求，用红色标出：
- en: '![](img/3b7bf196-16fe-4277-8e51-3f393696278f.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3b7bf196-16fe-4277-8e51-3f393696278f.png)'
- en: 'Click on the top trace marked in red:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击标记为红色的顶部跟踪：
- en: '![](img/4ca53dfa-35ad-4c3c-b50f-8e3a3c357f61.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4ca53dfa-35ad-4c3c-b50f-8e3a3c357f61.png)'
- en: 'In the detailed trace view, we can see by the color-coding that the request
    went wrong when product-composite called the product service. Click on the product
    span to see details of what went wrong:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在详细跟踪视图中，我们可以通过颜色编码看到产品服务在调用`product-composite`时出了错。点击产品跨度以查看出错详情：
- en: '![](img/b33855c9-3b3e-4aaf-81ed-8a080c05dec7.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b33855c9-3b3e-4aaf-81ed-8a080c05dec7.png)'
- en: 'Here, we can see what request caused the error, product/12345, as well as the
    error code and the reason returned: 404 Not Found. This is very useful when analyzing
    the root cause of a failure!'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们可以看到导致错误的请求`product/12345`以及返回的错误代码和原因：404 Not Found。这在我们分析故障的根本原因时非常有用！
- en: Sending an API request that triggers asynchronous processing
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发送一个触发异步处理的API请求
- en: The third type of request that is interesting to see how it is represented in
    the Zipkin UI is a request where parts of its processing are done asynchronously.
    Let's try a delete request, where the delete process in the core services is done
    asynchronously. The `product-composite` service sends a delete event to each of
    the three core services over the message broker and each core service picks up
    the delete event and processes it asynchronously. Thanks to Spring Cloud Sleuth,
    trace information is added to the events that are sent to the message broker,
    resulting in a coherent view of the total processing of the delete request.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在Zipkin UI中看到的第三种有趣的请求类型是一个部分处理异步的请求。让我们尝试一个删除请求，其中核心服务中的删除过程是异步完成的。`product-composite`服务向消息代理的每个核心服务发送一个删除事件，并且每个核心服务都会拾取该删除事件并异步处理它。得益于Spring
    Cloud Sleuth，发送到消息代理的事件中添加了跟踪信息，从而实现了对删除请求整体处理的连贯视图。
- en: 'Run the following command to delete the product with a product ID of `12345` and verify
    that it returns the HTTP status code for success, 200:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下命令删除具有产品ID`12345`的产品，并验证它返回成功的HTTP状态码，200：
- en: '[PRE14]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Remember that the delete operation is idempotent, that is, it will succeed even
    if the product doesn't exist!
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 记住删除操作是幂等的，即即使产品不存在，它也会成功！
- en: 'In the Zipkin UI, go back to the search page (use the back button in the web
    browser) and click on the Find Traces button. You should see the trace from the
    delete request at the top of the returned list:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在Zipkin UI中，回到搜索页面（在Web浏览器中使用后退按钮）并点击`Find Traces`按钮。你应该在返回列表的顶部看到删除请求的跟踪：
- en: '![](img/c8304d85-6234-4bf4-9470-e18b2f92a68a.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c8304d85-6234-4bf4-9470-e18b2f92a68a.png)'
- en: 'Click on the first trace to see its trace information:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 点击第一个跟踪以查看其跟踪信息：
- en: '![](img/b06714c3-aec0-4166-a066-2001d3c14c3d.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b06714c3-aec0-4166-a066-2001d3c14c3d.png)'
- en: 'Here, we can see the trace information for processing the delete request:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到处理删除请求的跟踪信息：
- en: The request was received by the gateway service.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请求被`gateway`服务接收。
- en: It delegated the processing of the request to the product-composite service.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将请求的处理委托给了`product-composite`服务。
- en: The product-composite service, in turn, published three events on the message
    broker (RabbitMQ, in this case).
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 反过来，`product-composite`服务在消息代理（本例中为RabbitMQ）上发布了三个事件。
- en: The product-composite service is now done and returns a success HTTP status
    code, 200, through the gateway service back to the caller.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`product-composite`服务现在完成并返回一个成功的HTTP状态码，200，通过网关服务返回到调用者。'
- en: The core services, product, recommendation, and review, receive the delete events
    and start to process them asynchronously, that is, independent of one another.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 核心服务`product`、`recommendation`和`review`接收到删除事件并开始异步处理它们，即彼此独立处理。
- en: 'To see more detailed information, click on the product span:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看更详细的信息，点击产品跨度：
- en: '![](img/7fd269c2-3bc7-4c83-91cd-6a16c6010757.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7fd269c2-3bc7-4c83-91cd-6a16c6010757.png)'
- en: Here, we can see that the product service was triggered by an event coming in
    to its input channel, which was sent from the message broker.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到产品服务被输入通道的事件触发，该事件是从消息代理发送的。
- en: The Zipkin UI contains much more functionality for finding traces of interest!
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Zipkin UI包含更多查找感兴趣跟踪的功能！
- en: To get more accustomed to the Zipkin UI, try out the `Annotation Query` parameter;
    for example, search for a specific request using `http.path=/product-composite/214`
    or `error=401` to find requests that failed due to authorization failures. Watch
    out for the `Limit` parameter, which is set to `10` by default; this can hide
    results of interest if not raised. Also, ensure that the `Lookback` parameter
    doesn't remove traces of interest!
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更熟悉Zipkin UI，尝试使用`Annotation Query`参数；例如，使用`http.path=/product-composite/214`或`error=401`查找因授权失败而失败的请求。注意默认设置为`10`的`Limit`参数，这可能会隐藏感兴趣的结果。还要确保`Lookback`参数不会删除感兴趣的跟踪！
- en: Monitoring trace information passed to Zipkin in RabbitMQ
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控通过RabbitMQ发送到Zipkin的跟踪信息
- en: 'To monitor trace information that''s sent to Zipkin over RabbitMQ, we can use
    the RabbitMQ management web UI. Open the following URL in your web browser: `http://localhost:15672/#/queues/%2F/zipkin`.
    If required, log in using the username `guest` and the password `guest`. Expect
    a web page that looks like the following:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 要监控通过RabbitMQ发送到Zipkin的跟踪信息，我们可以使用RabbitMQ管理Web UI。在Web浏览器中打开以下URL：`http://localhost:15672/#/queues/%2F/zipkin`。如果需要，使用用户名`guest`和密码`guest`登录。期待一个看起来像以下的网页：
- en: '![](img/0ebbf762-280a-457c-b52e-7344c666c249.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0ebbf762-280a-457c-b52e-7344c666c249.png)'
- en: In the graph named `Message Rates`, we can see that trace messages are sent
    to Zipkin, currently at an average rate of 1.2 messages per second.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在名为`Message Rates`的图表中，我们可以看到跟踪消息正在以每秒1.2条消息的平均速率发送到Zipkin。
- en: 'Wrap up the tests of distributed tracing using RabbitMQ by bringing down the
    system landscape. Run the following command:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令结束RabbitMQ的分布式跟踪测试，关闭系统架构：
- en: '[PRE15]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Using Kafka as a message broker
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Kafka作为消息代理
- en: Let's also verify that we can send trace information to Zipkin using Kafka instead
    of RabbitMQ!
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也验证一下我们可以使用Kafka而不是RabbitMQ向Zipkin发送跟踪信息！
- en: 'Start up the system landscape using the following commands:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令启动系统架构：
- en: '[PRE16]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Repeat the commands we performed in the previous sections, where we used RabbitMQ,
    and verify that you can see the same trace information in the Zipkin UI when using
    Kafka!
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 重复我们在前面章节中执行的命令，当时我们使用RabbitMQ，并验证您可以在使用Kafka时在Zipkin UI中看到相同的跟踪信息：
- en: 'Kafka doesn''t come with a management web UI like RabbitMQ. Therefore, we need
    to run a few Kafka commands to be able to verify that the trace events actually
    were passed to the Zipkin server using Kafka:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka不提供像RabbitMQ那样的管理Web UI。因此，我们需要运行一些Kafka命令来验证跟踪事件实际上是通过Kafka发送到Zipkin服务器的：
- en: For a recap on how to run Kafka commands when running Kafka as a Docker container,
    refer to the *Using Kafka with two partitions per topic* section in [Chapter 7](436fb8c1-0c4d-410c-a3ec-da251aba4ca1.xhtml),
    *Developing Reactive Microservices.*
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Docker容器中运行Kafka命令，请参阅[第7章](436fb8c1-0c4d-410c-a3ec-da251aba4ca1.xhtml) *《开发响应式微服务》*
    中的“每个主题使用两个分区”部分。
- en: 'First, list the available topics in Kafka:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，列出Kafka中可用的主题：
- en: '[PRE17]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Expect to find a topic named `zipkin`:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：
- en: '![](img/8ce689f9-3d7a-49de-b487-817b43554f35.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: 跟踪事件的具体细节并不重要。Zipkin服务器为我们整理了信息，并在Zipkin UI中使其易于查看。这里的关键是我们可以看到通过Kafka发送到Zipkin服务器的跟踪事件。
- en: 'Next, ask for trace events that were sent to the `zipkin` topic:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，询问发送到`zipkin`话题的跟踪事件：
- en: '[PRE18]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Expect a lot of events similar to the following:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 期待很多与以下类似的长时间运行的请求：
- en: '![](img/8fcdde07-be13-497a-8b95-1b56e4fe3a95.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8fcdde07-be13-497a-8b95-1b56e4fe3a95.png)'
- en: The details of a trace event are not important. The Zipkin server sorts that
    out for us and makes the information presentable in the Zipkin UI. The important
    point here is that we can see that the trace events actually were sent to the
    Zipkin server using Kafka.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习容器编排器，特别是Kubernetes。我们将学习如何使用Kubernetes部署和管理微服务，同时提高重要的运行时特性，如可伸缩性、高可用性和弹性。
- en: 'Now, bring down the system landscape and unset the `COMPOSE_FILE` environment
    variable:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，请关闭系统架构并取消设置`COMPOSE_FILE`环境变量：
- en: '[PRE19]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: That concludes this chapter on distributed tracing!
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了关于分布式跟踪的章节！
- en: Summary
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have learned how to use distributed tracing to understand
    how our microservices cooperate. We have learned how to use Spring Cloud Sleuth
    to collect trace information, and how to use Zipkin to store and visualize the
    trace information.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 期待找到一个名为`zipkin`的话题：
- en: To promote the decoupling of runtime components, we have learned how to configure
    microservices to send trace information to the Zipkin server asynchronously while
    using RabbitMQ and Kafka as message brokers. We have seen how adding Spring Cloud
    Sleuth to microservices is effected by adding a couple of dependencies to the
    build files and setting up a few configuration parameters. We have also seen how
    the Zipkin UI makes it very easy to identify what part of a complex workflow caused
    either an unexpectedly long response time or an error. Both synchronous and asynchronous
    workflows can be visualized by Zipkin UI.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: Zipkin UI使识别复杂工作流中的哪个部分导致意外的长时间响应或错误变得非常容易。无论是同步还是异步工作流，都可以通过Zipkin UI进行可视化。
- en: In the next chapter, we will learn about container orchestrators, specifically
    Kubernetes. We will learn how to use Kubernetes to deploy and manage microservices,
    while also improving important runtime characteristics such as scalability, high
    availability, and resilience.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用分布式跟踪来了解微服务如何协同工作。我们还学习了如何使用Spring Cloud Sleuth收集跟踪信息，以及如何使用Zipkin存储和可视化跟踪信息。
- en: Questions
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`spring.sleuth.sampler.probability`配置参数的目的是什么？'
- en: What configuration parameter is used to control how trace information is sent
    to Zipkin?
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 控制跟踪信息发送到Zipkin的配置参数是什么？
- en: What is the purpose of the `spring.sleuth.sampler.probability` configuration
    parameter?
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何在执行`test-em-all.bash`测试脚本后识别最长的运行请求？
- en: How can you identify the longest-running request after executing the `test-em-all.bash` test
    script?
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何推广运行时组件的解耦？我们已经了解到如何在构建文件中添加几个依赖项，并设置一些配置参数。
- en: How can we find requests that have been interrupted by the timeout introduced
    in [Chapter 13](23795d34-4068-4961-842d-989cde26b642.xhtml), *Improving Resilience
    Using Resilience4j*?
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何在[第13章](23795d34-4068-4961-842d-989cde26b642.xhtml) *使用Resilience4j提高弹性*
    中找到被超时中断的请求？
- en: What does the trace look like for an API request when the circuit breaker introduced
    in [Chapter 13](23795d34-4068-4961-842d-989cde26b642.xhtml), *Improving Resilience
    Using Resilience4j*, is open?
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当[第13章](23795d34-4068-4961-842d-989cde26b642.xhtml)中引入的断路器*Improving Resilience
    Using Resilience4j*打开时，API请求的跟踪日志是什么样的？
- en: How can we locate APIs that failed on the caller not being authorized to perform
    the request?
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何定位因调用者未获得授权而失败的API？
