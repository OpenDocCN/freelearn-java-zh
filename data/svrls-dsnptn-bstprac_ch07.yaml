- en: Data Processing Using the Lambda Pattern
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Lambda 模式进行数据处理
- en: This chapter describes the Lambda pattern, which is not to be confused with
    AWS Lambda functions. The Lambda architecture consists of two layers, typically
    used in data analytics processing. The two layers include a speed layer to calculate
    data in near-real time and a batch layer that processes vast amounts of historical
    data in batches.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章描述了 Lambda 模式，不要与 AWS Lambda 函数混淆。Lambda 架构由两层组成，通常用于数据分析处理。这两层包括一个速度层，用于近实时计算数据，以及一个批量层，用于批量处理大量历史数据。
- en: Because serverless platforms allow us to scale horizontally very quickly, and
    since it's simple to store large amounts of data, the Lambda pattern is well suited
    for a serverless implementation. Lambda architectures are relatively new, coming
    onto the scene with the advent of big data processing and the desire to see the
    results of processing sooner than was previously available using batch systems
    such as Hadoop. This type of architecture or pattern is especially interesting
    since there are so many components involved in making it work, which we'll walk
    through using an example application that will calculate average prices for the
    cryptocurrencies Bitcoin and Ethereum.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 由于无服务器平台允许我们非常快速地进行水平扩展，并且存储大量数据很简单，因此 Lambda 模式非常适合无服务器实现。Lambda 架构相对较新，随着大数据处理的出现以及希望比以前使用
    Hadoop 等批量系统更快地看到处理结果的需求而出现。这种架构或模式特别有趣，因为它涉及许多组件才能使其工作，我们将通过一个示例应用程序来演示，该应用程序将计算比特币和以太坊加密货币的平均价格。
- en: 'By the end of this chapter, you can expect to have learned the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你可以期待学习以下内容：
- en: A thorough understanding of the Lambda architecture and when it may be appropriate
    to use
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对 Lambda 架构的深入理解以及何时可能适合使用
- en: What tooling and options are available when designing a Lambda architecture
    in a serverless environment
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在无服务器环境中设计 Lambda 架构时，可用的工具和选项有哪些
- en: How to create a speed layer for processing a stream of cryptocurrency prices
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何为处理加密货币价格流创建速度层
- en: How to develop a batch layer for processing historical prices
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何开发用于处理历史价格的批量层
- en: Alternate implementations and tooling when building a serverless Lambda architecture
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在构建无服务器 Lambda 架构时的替代实现和工具
- en: Introducing the lambda architecture
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 Lambda 架构
- en: To the best of my knowledge, Nathan Martz, author of Apache Storm, first introduced the
    lambda architecture in a 2011 blog post. You can read the post yourself at [http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html](http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html).
    In this post, Nathan proposes a new type of system that can calculate historical
    views of large datasets alongside a real-time layer that can answer queries for
    real or near-real-time data. He labels these two layers the batch layer and the
    real-time layer.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我所知，Apache Storm 的作者 Nathan Martz 在 2011 年的一篇博客文章中首次介绍了 Lambda 架构。[http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html](http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html)。在这篇文章中，Nathan
    提出了一种新的系统类型，该系统可以在实时层旁边计算大型数据集的历史视图，实时层可以回答关于真实或近实时数据的查询。他将这两个层称为批量层和实时层。
- en: 'The Lambda architecture was derived from trying to solve the problem of answering
    queries for data that is continuously updated. It''s important to keep in mind
    the type of data we''re dealing with here. Streaming data in this context are
    factual records. Some examples of streaming factual data are the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 架构是从尝试解决对持续更新的数据进行查询的问题中衍生出来的。在此背景下，我们需要牢记我们处理的数据类型。流数据是事实记录。以下是一些流事实数据的示例：
- en: The temperature at a given location at a given time
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在特定时间和特定位置的气温
- en: An HTTP log record from a web server
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自网络服务器的 HTTP 日志记录
- en: The price of Bitcoin from a given exchange at a given time
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在特定时间从特定交易所获取的比特币价格
- en: You can imagine the case where a temperature sensor is taking measurements in
    a given location and sending those readings somewhere every 5 seconds. If the
    temperature reading on January 31, 2018, at 12:00:00 was 75.4 °F, that fact should
    never change. A reading 5 seconds later may be 75.5 °F, but that does not nullify
    the prior reading. In this and other cases, we are working with an append-only
    data stream of facts.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以想象一个温度传感器在特定位置进行测量，并且每5秒将读数发送到某处的场景。如果2018年1月31日12:00:00的温度读数是75.4°F，这个事实永远不会改变。5秒后的读数可能是75.5°F，但这并不取消之前的读数。在这种情况下和其他情况下，我们正在处理一个只追加的事实数据流。
- en: 'Using our temperature analogy, imagine that we need to answer questions about
    this data such as the following:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们的温度类比，想象我们需要回答关于这些数据的问题，例如以下问题：
- en: What was the average weekly temperature since 2010?
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自2010年以来平均每周气温是多少？
- en: What was the average monthly temperature since 2000?
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自2000年以来平均每月气温是多少？
- en: What were the daily high and low temperatures over the past year?
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过去一年中每天的气温最高和最低是多少？
- en: What is the temperature trend over the past 2 hours?
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过去2小时的温度趋势是什么？
- en: Not only are we working with immutable data, but there is a time domain to consider
    as well in the queries to which we need to respond. If we had a naive implementation,
    we could store each piece of data in a relational database and perform queries
    on demand. There are 31,540,000 seconds in a year. If our system was uploading
    measurements every 5 seconds, that is 6,308,000 each year. Now, assume that we
    need to keep track of 10,000 different sensors around the world. This means our
    system would be adding 63,080,000,000 new records each year.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不仅处理不可变数据，还需要考虑查询中需要响应的时间域。如果我们有一个简单的实现，我们可以在关系型数据库中存储每条数据，并在需要时执行查询。一年中有31,540,000秒。如果我们每5秒上传一次测量值，那么一年就是6,308,000次。现在，假设我们需要跟踪全球10,000个不同的传感器。这意味着我们的系统每年会增加63,080,000,000条新记录。
- en: The initial challenge using a relational database would simply be finding a
    subset of those records for a particular location, for example, `SELECT * FROM
    temperatures where location_id = 1234`. Of course, we can undertake this type
    of query quickly using indexes, but there are significant limitations and trade-offs
    when dealing with billions or trillions of rows.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 使用关系型数据库的初始挑战可能仅仅是找到特定位置的那些记录的子集，例如，`SELECT * FROM temperatures where location_id
    = 1234`。当然，我们可以通过索引快速执行此类查询，但在处理数十亿或数万亿行数据时，存在显著的局限性和权衡。
- en: The second challenge would be performing calculations to get the right answer
    (that is, average temperature by week, high-low temperature each day). If our
    query was pulling data from 20 years ago until today, that would mean a lot of
    disk access and a significant load on the database, presuming the analytical query
    could be done in SQL.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个挑战是执行计算以获得正确答案（即按周平均气温，每天的高低温）。如果我们的查询是从20年前到今天的数据，这意味着大量的磁盘访问和数据库的显著负载，假设分析查询可以用SQL完成。
- en: Admittedly, there are systems that can deal with this level of scale, such as
    data warehouses or NoSQL data stores. However, data warehouses are not designed
    for real-time queries. NoSQL systems may be better at storing large amounts of
    data, but they lack flexibility or ability when it comes to running calculations
    on that data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然确实存在可以处理这种规模级别的系统，例如数据仓库或NoSQL数据存储，但数据仓库并不是为实时查询设计的。NoSQL系统可能在存储大量数据方面做得更好，但在对数据进行计算时缺乏灵活性和能力。
- en: What is the solution when we have the level of scale of a data warehouse, a
    continually updated data stream and the requirement to serve queries in real time?
    This is where the Lambda pattern can help. Comprised of a batch layer and speed
    layer, the Lambda pattern is designed to solve this problem of responding to queries
    in real time, pulling data from both the batch layer and speed layer outputs.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们拥有数据仓库级别的规模、持续更新的数据流以及需要实时服务查询的要求时，我们该怎么办？这正是Lambda模式可以发挥作用的地方。由批处理层和速度层组成，Lambda模式旨在解决实时响应查询的问题，从批处理层和速度层的输出中提取数据。
- en: Technically speaking, the view layer is a separate component of this architecture.
    As mentioned at the start of this chapter, there are many moving parts and components
    to a serverless implementation of the lambda pattern. For this reason, I won't
    be discussing the view layer in much detail so we can focus on the data portion
    of this pattern, which is more in tune with this chapter's theme. For a discussion
    of frontend applications in serverless systems, I'll refer you to [Chapter 2](svrls-dsnptn-bstprac_ch02.html),
    *A Three-Tier Web Application Using RE**ST*.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术角度讲，视图层是这个架构的一个独立组件。如本章开头所述，无服务器lambda模式的实现有许多移动部件和组件。因此，我将不会详细讨论视图层，以便我们可以专注于这个模式的数据部分，这部分更符合本章的主题。关于无服务器系统中的前端应用程序的讨论，请参考[第2章](svrls-dsnptn-bstprac_ch02.html)，*使用REST的三层Web应用程序*。
- en: 'The architecture is shown in the following diagram:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 架构如下所示：
- en: '![](img/9358ca3b-b4c3-4c7e-9faf-8fd1b0e46415.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9358ca3b-b4c3-4c7e-9faf-8fd1b0e46415.jpg)'
- en: Batch layer
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批处理层
- en: When the lambda architecture was proposed, Hadoop was already widely adopted
    and regarded as a proven technology. Hadoop is a linearly scalable system and
    can easily churn through terabytes of data in a reasonable amount of time to calculate
    nearly anything from your dataset. Here, *reasonable* may mean a job that runs
    for a few hours in the middle of the night so that new views of your data are
    ready first thing in the morning.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当lambda架构被提出时，Hadoop已经被广泛采用，并被认为是一项成熟的技术。Hadoop是一个线性可扩展的系统，可以在合理的时间内轻松处理数以兆字节的数据，以计算数据集中几乎任何内容。在这里，“合理”可能意味着一个在深夜运行几小时的工作，以便数据的新视角可以在早上第一时间准备好。
- en: Using our temperature monitoring analogy, a day's worth of data will require
    a new batch job run if we need to calculate the average temperature in the month
    or year. Also, imagine we wanted to calculate trends day by day, month by month,
    or year by year. Whenever a new batch of daily temperatures is completed, our
    system would need to perform some work to calculate the pre-materialized views.
    By pre-calculating all of this data, any query would just look up the answer on
    demand without needing to calculate anything.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们的温度监控类比，如果我们需要计算月或年的平均温度，就需要运行一个新的批处理作业。想象一下，如果我们想按日、按月或按年计算趋势。每当完成一批每日温度数据时，我们的系统就需要进行一些工作来计算预计算视图。通过预先计算所有这些数据，任何查询只需在需要时查找答案，而无需进行任何计算。
- en: Speed layer
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 速度层
- en: A batch layer by itself isn't anything new. The problem we're trying to solve
    here is answering queries quickly and up to date with a real-time view of our
    data stream. The magic with the Lambda pattern is the combination of the batch
    layer in conjunction with a speed layer.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 批处理层本身并不新鲜。我们试图解决的问题是快速回答查询，并实时查看我们的数据流。Lambda模式中的魔力在于批处理层与速度层的结合。
- en: 'The speed layer is a constantly updating system that processes new data from
    the data stream in real time. The calculations here will be the same as in the
    batch later, but it only works on a small subset of data as it arrives from the
    data stream. For example, to get the daily high temperature for a given location
    since 2015 in response to such a query, our system would do the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 速度层是一个不断更新的系统，它实时处理数据流中的新数据。这里的计算将与批处理中的相同，但它只处理从数据流中到达的小部分数据。例如，为了响应这样的查询，获取自2015年以来某个位置的每日最高温度，我们的系统会执行以下操作：
- en: Fetch daily high temperatures from January 1, 2015, until yesterday from the
    batch layer
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从批处理层获取2015年1月1日到昨天的每日最高温度
- en: Fetch the high temperature from today from the speed layer
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从速度层获取今天的最高温度
- en: Merge the two datasets into one to present back to the user
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将两个数据集合并成一个，然后呈现给用户
- en: Also note that in such a system, we could go even further. Our view layer could
    display the historical data in one area of the application and present the real-time
    information separately, which could be continually updated using a WebSocket connection
    or polling. By separating out these two layers, many options open up regarding
    application development and interaction.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，在这样的系统中，我们可以更进一步。我们的视图层可以在应用程序的一个区域显示历史数据，并分别展示实时信息，这些信息可以通过WebSocket连接或轮询不断更新。通过分离这两个层，在应用程序开发和交互方面会打开许多选项。
- en: Lambda serverless architecture
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Lambda无服务器架构
- en: While the overall design and theme of a lambda architecture remain the same
    as a traditional system, there are variations and adaptations that we need to
    make. Perhaps more importantly, there are many different ways to implement this
    pattern using serverless systems or, at the very least, managed services.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然lambda架构的整体设计和主题与传统系统相同，但我们需要进行一些变化和调整。也许更重要的是，有多种不同的方式可以使用无服务器系统或至少是托管服务来实现此模式。
- en: Streaming data producers
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流数据生产者
- en: 'Any system must start with data to process. On serverless platforms, there
    are multiple choices for streaming systems. Azure, Google Compute, and AWS all
    offer some form of streaming systems. I mentioned these in [Chapter 6](svrls-dsnptn-bstprac_ch06.html), *Asynchronous
    Processing with the Messaging Pattern,* when discussing the differences between
    queues and streams:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 任何系统都必须从要处理的数据开始。在无服务器平台上，有多个选择用于流系统。Azure、Google Compute和AWS都提供某种形式的流系统。我在[第6章](svrls-dsnptn-bstprac_ch06.html)，“使用消息模式进行异步处理”中提到了这些，当时讨论了队列和流之间的区别：
- en: '**Azure**: Event Hubs'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure**: 事件中心'
- en: '**AWS**: Kinesis'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS**: Kinesis'
- en: '**Google Compute Cloud**: Cloud Dataflow'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google Compute Cloud**: 云数据流'
- en: It's worth briefly touching on the topic of queues versus streams again. As
    mentioned in [Chapter 6](svrls-dsnptn-bstprac_ch06.html), *Asynchronous Processing
    with the Messaging Pattern*, one of the main differentiators is that queues are
    primarily designed for once-only processing. That is, once a message is pulled
    from a queue, no other consumer will see it. Data in a stream, on the other hand,
    has a given lifetime and cannot be removed by any consumer of that data. For example,
    a stream can set data to expire after 24 hours, or after 30 days. At any point
    in time, one or more readers can come along and begin reading data from the stream.
    It's up to the readers to keep track of where they are in the history of a stream.
    A new reader may start at the beginning of the stream, in the middle, or at the
    end.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '值得再次简要提及队列与流的话题。如[第6章](svrls-dsnptn-bstprac_ch06.html)中提到的，“使用消息模式进行异步处理”，其中一个主要区别是队列主要设计为一次处理。也就是说，一旦消息从队列中取出，其他消费者将看不到它。流中的数据具有给定的生命周期，并且不能被任何数据消费者删除。例如，流可以设置数据在24小时后或30天后过期。在任何时候，一个或多个读者可以出现并开始从流中读取数据。读者需要跟踪他们在流历史中的位置。新读者可以从流的开始、中间或末尾开始。 '
- en: Data storage
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据存储
- en: Since there are two distinct layers in this pattern, storage choices will likely
    be different since the two layers are drastically different in their data requirements.
    The batch layer requires extreme scalability and should perform well for a high
    number of concurrent reads during batch processing. The speed layer, on the other
    hand, doesn't need to store as much data but should be extremely fast for both
    reads and writes.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于该模式中有两个不同的层级，因此存储选择可能会不同，因为这两个层的数据需求差异很大。批处理层需要极高的可扩展性，并且在批处理期间应该能够很好地处理大量并发读取。另一方面，速度层不需要存储大量数据，但应该对读取和写入都极为快速。
- en: In many examples of this pattern, you'll see references to **Hadoop Filesystem**
    (**HDFS**) for storing historical data and NoSQL databases for real-time data.
    While it's near impossible to say what you should pick, it is possible to speak
    to some of your options.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多该模式的示例中，你会看到对**Hadoop文件系统**（**HDFS**）用于存储历史数据和NoSQL数据库用于实时数据的引用。虽然很难说你应该选择什么，但可以讨论一些你的选项。
- en: 'Cloud storage systems such as AWS S3 or Google Cloud Storage were designed
    to fill a similar role as HDFS, that is, to store practically as much data as
    you need. The advantages of storing plain files on services such as this are that
    it''s straightforward, requires almost no management, and is very durable. What
    I like about using flat or structured files is that it becomes possible to process
    the data later and store it in a different system such as a database. Also, there
    are a myriad of serverless or hosted systems that you can leverage that read data
    from these systems. Focusing only on AWS, the following systems can perform batch
    processing or analytical queries on S3 data:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 云存储系统，如AWS S3或Google Cloud Storage，旨在填补与HDFS类似的角色，即存储你需要的几乎所有数据。在类似服务上存储普通文件的优势在于，它使得以后处理数据并将其存储在不同的系统（如数据库）中成为可能。此外，还有许多无服务器或托管系统可以利用，这些系统可以从这些系统中读取数据。仅关注AWS，以下系统可以在S3数据上执行批处理或分析查询：
- en: '**Elastic MapReduce** (**EMR)**'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**弹性MapReduce** (**EMR**)'
- en: Athena
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Athena
- en: Redshift
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Redshift
- en: DynamoDB or other NoSQL are also options for historical data. Azure Cosmos DB
    and Google Bigtable are other services that I cannot speak to directly but that
    are options if you're building on top of those cloud providers.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: DynamoDB或其他NoSQL也是历史数据的选项。Azure Cosmos DB和Google Bigtable是其他服务，我无法直接评价，但如果你在这些云服务提供商之上构建，它们是可行的选项。
- en: At least in the case of DynamoDB, special consideration should be made since
    read and write throughput needs to be carefully considered to maintain a workable
    system.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 至少在DynamoDB的情况下，应该特别考虑，因为需要仔细考虑读写吞吐量以保持系统可操作。
- en: For the speed layer, there are also multiple tools you can use. DynamoDB is
    a viable choice since it's linearly scalable and you should have a fair idea of
    the read and write capacity needed. Managed Redis services such as AWS ElastiCache
    or Azure Redis Cache are also decent choices since Redis is exceptionally performant
    and the dataset is limited.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于速度层，也有多种工具可以使用。DynamoDB是一个可行的选择，因为它线性可扩展，你应该对所需的读写容量有一个合理的了解。AWS ElastiCache或Azure
    Redis Cache等托管的Redis服务也是不错的选择，因为Redis性能卓越，数据集有限。
- en: Computation in the speed layer
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 速度层的计算
- en: It makes sense that, since we're using serverless systems, our serverless functions
    will perform any computations necessary. Serverless functions are a natural choice,
    for what should be obvious reasons at this point. Running functions on demand
    or in response to new data arriving on our streams is incredibly simple. Additionally,
    FaaS allows us to scale horizontally.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用的是无服务器系统，我们的无服务器函数将执行所需的任何计算，这是合乎逻辑的。到这一点，无服务器函数作为自然选择的原因应该是显而易见的。按需或在我们的流中到达新数据时运行函数非常简单。此外，FaaS允许我们水平扩展。
- en: In a lambda architecture, we may need to calculate many different metrics at
    the same time, from the same data stream. Doing this from a `single` serverless
    function could be possible. However, in the case where the computation is heavier,
    we may need to split out the computation into multiple functions, each calculating
    their own set of metrics from the same stream. Numerous readers allow us to scale
    out horizontally and provide the flexibility needed when data changes or new metrics
    need to be calculated.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在lambda架构中，我们可能需要同时计算许多不同的指标，来自同一数据流。从单个无服务器函数中完成这项工作可能是可能的。然而，在计算较重的情况下，我们可能需要将计算拆分为多个函数，每个函数从同一流中计算自己的指标集。多个读者允许我们水平扩展，并在数据变化或需要计算新指标时提供所需的灵活性。
- en: While serverless functions are a natural choice and easily understood, there
    are other options. On AWS, it's possible to use Spark Streaming from within the
    EMR system. Spark Streaming is purpose-built for this type of workload. In the
    case that your data stream outgrows the limitations of cloud functions such as
    Lambda, moving to Spark Streaming is a good alternative.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然无服务器函数是自然的选择且易于理解，但还有其他选项。在AWS上，可以在EMR系统中使用Spark Streaming。Spark Streaming专为这种类型的工作负载而构建。如果你的数据流超过了云函数（如Lambda）的限制，转向Spark
    Streaming是一个不错的选择。
- en: Computation in the batch layer
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批量层的计算
- en: Many lambda architecture systems will rely on Hadoop or Spark for the batch
    layer. Since we don't want to manage a cluster ourselves, we'll have to pick some
    other serverless system or, at the very least, a managed service. There are a
    variety of options here.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 许多lambda架构系统将依赖于Hadoop或Spark进行批量层。由于我们不希望自行管理集群，我们必须选择其他无服务器系统，或者至少是一个托管服务。这里有多种选择。
- en: First, it's possible to implement our MapReduce system entirely using serverless
    technologies. You'll read about this in [Chapter 8,](svrls-dsnptn-bstprac_ch08.html) The *MapReduce
    Pattern*[](svrls-dsnptn-bstprac_ch08.html). If you'd rather not build a MapReduce
    system, there are other services that you can leverage. Both Spark and Hadoop
    are available within AWS EMR. HDInsight from Azure provides the same or similar
    functionality to EMR.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以完全使用无服务器技术来实现我们的MapReduce系统。你将在[第8章](svrls-dsnptn-bstprac_ch08.html)《*MapReduce模式*》中了解到这一点。如果你不想构建MapReduce系统，还有其他服务可以利用。Spark和Hadoop都可在AWS
    EMR中使用。Azure的HDInsight提供了与EMR相同或类似的功能。
- en: Batch processing is a solved problem nowadays, and you should have no problems
    finding a solution that works for your needs. Since there are so many options
    for batch processing, you may find it challenging to narrow down your choices.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 批量处理现在是一个已解决的问题，你应该能够找到满足你需求的解决方案。由于批量处理有许多选项，你可能会发现很难缩小选择范围。
- en: Processing cryptocurrency prices using lambda architecture
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Lambda架构处理加密货币价格
- en: In this chapter, our example application will perform a single task of reading
    prices in real time for a variety of cryptocurrencies and calculating the average
    prices by the minute, hour, and day. Of course, this isn't all that useful in
    the real world because there is so much data on cryptocurrencies already. However,
    this presents an excellent scenario and dataset for an example application to
    illustrate this pattern. As is usual in this book, I'll build the application
    on top of AWS with Python. It's also important to note that none of the concepts
    are unique to AWS or Python and that this example application is portable to other
    languages and cloud providers.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们的示例应用程序将执行一个单一的任务，即实时读取各种加密货币的价格，并按分钟、小时和日计算平均价格。当然，这在现实世界中并不那么有用，因为已经有大量关于加密货币的数据。然而，这为示例应用程序提供了一个极好的场景和数据集，以说明这种模式。正如本书惯例，我将在AWS上使用Python构建应用程序。同样重要的是要注意，这些概念并非仅限于AWS或Python，并且这个示例应用程序可以移植到其他语言和云服务提供商。
- en: You can find the code for this chapter at [https://github.com/brianz/serverless-design-patterns/tree/master/ch7](https://github.com/brianz/serverless-design-patterns/tree/master/ch7).[](https://github.com/brianz/serverless-design-patterns/tree/master/ch7)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://github.com/brianz/serverless-design-patterns/tree/master/ch7](https://github.com/brianz/serverless-design-patterns/tree/master/ch7)找到本章的代码。
- en: System architecture
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 系统架构
- en: 'The architecture of this is perhaps the most complex in this book, even though
    the implementation itself is relatively simple. As mentioned earlier in this chapter,
    there are many moving parts in a lambda architecture since it is two distinct
    systems that work side by side, with each having its own unique set of services.
    I show a high-level architecture in the following diagram:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管实现本身相对简单，但这个架构可能是本书中最复杂的。正如本章前面提到的，Lambda架构中有许多动态部分，因为它是由两个并行工作的独立系统组成的，每个系统都有自己的独特服务集。以下图表显示了高级架构：
- en: This design is somewhat contrived and overly simplified. A system with true
    scale likely would not be able to get away with a serverless function that calculated
    historical prices by year, as I do in the batch layer. To fit this example application
    into a single chapter, I had to make the system relatively simple to demonstrate
    the pattern and techniques. While this may be an oversimplification of an actual
    big data system, it does show that the design works on a serverless platform and
    is even applicable to a decent-sized data problem.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这个设计有些牵强且过于简化。一个真正按比例缩放的系统可能无法像我在批量层中那样，通过一个按年计算历史价格的函数来逃避无服务器函数。为了将这个示例应用程序压缩到单个章节中，我不得不使系统相对简单，以便演示模式和技巧。虽然这可能是一个实际大数据系统的过度简化，但它确实表明设计可以在无服务器平台上工作，甚至适用于相当大的数据问题。
- en: '![](img/cd62972d-2a1f-42c0-90a2-9f48ff2c47f0.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![系统架构](img/cd62972d-2a1f-42c0-90a2-9f48ff2c47f0.jpg)'
- en: I'll break this down piece by piece and describe how each layer and component
    works. While there may be a lot going on in this design, each part is quite simple.
    Most of the complexity of this system comes from the system setup and concepts,
    instead of application code.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我将逐个分解并描述每一层和组件的工作原理。虽然这个设计中可能有很多内容，但每个部分都非常简单。这个系统的复杂性大部分来自系统设置和概念，而不是应用程序代码。
- en: Data producer
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据生产者
- en: To start, we need to have some data to process. In a real system where you are
    creating the data or wish to send some data *out* from your system, this isn't
    much of an issue. In our case, we need to pull data in real time from somewhere,
    and I've chosen the public API from GDAX ([https://www.gdax.com](https://www.gdax.com)),
    which is a digital exchange for cryptocurrencies from Coinbase. This API is suitable
    for our example application mainly because there are many transactions and there
    is a WebSocket endpoint that we can subscribe to. A simple script that subscribes
    to the GDAX WebSocket API and publishes those messages to our Kinesis stream will
    serve as our data producer.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一些要处理的数据。在一个真实系统中，如果你正在创建数据或希望从你的系统中发送一些数据*出去*，这并不是一个问题。在我们的情况下，我们需要实时地从某处拉取数据，我选择了GDAX的公共API（[https://www.gdax.com](https://www.gdax.com)），这是Coinbase的加密货币数字交易所。这个API适合我们的示例应用，主要是因为有很多交易，并且有一个我们可以订阅的WebSocket端点。一个简单的脚本，订阅GDAX
    WebSocket API并将这些消息发布到我们的Kinesis流，将作为我们的数据生产者。
- en: Speed layer
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 速度层
- en: The speed layer is also relatively simple. Each message published to the Kinesis
    stream will trigger a Lambda function. This Lambda function will just write the
    data to DynamoDB so that we can serve data in real time for any queries. With
    this design, we're set up for a decent amount of real-time load and concurrency.
    The data producer will deliver data at a reasonably fast rate, perhaps a few messages
    per second. If there was a burst of traffic and the speed layer started seeing
    tens or hundreds of messages per second, it would not be a problem.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 速度层也相对简单。每个发布到Kinesis流的消息都会触发一个Lambda函数。这个Lambda函数只是将数据写入DynamoDB，这样我们就可以为任何查询提供实时数据。在这种设计下，我们已经为相当数量的实时负载和并发性做好了准备。数据生产者将以合理的速度交付数据，可能每秒几条消息。如果出现流量高峰，速度层开始看到每秒数十或数百条消息，这不会是问题。
- en: Since serverless functions and databases such as DynamoDB scale linearly, the
    speed layer can absorb practically any amount of real-time traffic. There are,
    of course, provisioning and throughput concerns, as well as maximum concurrent
    limits to contend. However, these issues are just configuration settings that
    you can quickly change and increase as needed.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 由于无服务器函数和如DynamoDB这样的数据库是线性扩展的，速度层可以吸收几乎任何数量的实时流量。当然，还有配置和吞吐量方面的考虑，以及最大并发限制需要竞争。然而，这些问题只是你可以快速更改并按需增加的配置设置。
- en: Batch layer
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批量层
- en: Our batch layer gets a bit more interesting. Some of the details are AWS-centric,
    but you can carry the general idea across cloud providers. AWS Kinesis Firehose
    is another version of Kinesis that is designed to transport data in batches to
    various locations. In this architecture, we'll set up the Kinesis Firehose stream
    to ingest data from the primary Kinesis stream.  I'll also configure the Firehose
    stream to deliver batches of messages to S3 every minute.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的批量层会变得更有趣。一些细节是AWS特定的，但你可以在不同的云服务提供商之间传递这个一般想法。AWS Kinesis Firehose是Kinesis的另一种版本，旨在将数据批量传输到各种位置。在这个架构中，我们将设置Kinesis
    Firehose流从主Kinesis流中摄取数据。我还会配置Firehose流，使其每分钟将消息批量发送到S3。
- en: If you have heard about AWS Kinesis but the term Kinesis Firehose is new to
    you, don't worry. Kinesis Firehose's specialty is loading data into various services,
    such as S3 and Redshift. A plain Kinesis stream captures data and makes it available
    for consumption, but that consumption is your responsibility. Kinesis Firehose
    is useful when you'd like to dump the streaming data to S3 or Redshift automatically.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你听说过AWS Kinesis，但对Kinesis Firehose这个术语感到陌生，请不要担心。Kinesis Firehose的专业技能是将数据加载到各种服务中，例如S3和Redshift。一个普通的Kinesis流会捕获数据并使其可供消费，但这种消费是你的责任。当你希望自动将流数据倒入S3或Redshift时，Kinesis
    Firehose非常有用。
- en: 'With a new file being delivered to S3 every minute, we can set up a Lambda
    function to trigger on that event and perform some work. The work here will be
    reading the list of messages, calculating the average price per currency, and
    writing out a new file back to S3\. If you follow the flow of time and data, you
    should be able to see that we can extend this pattern down at different time increments
    - minutes, hours, days, months, and even years. The general flow and set of triggers
    look like this:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 每分钟都会有一个新文件被发送到S3，我们可以设置一个Lambda函数来触发这个事件并执行一些工作。这里的工作将是读取消息列表，计算每种货币的平均价格，并将新文件写回S3。如果你跟随时间和数据的流动，你应该能够看到我们可以将这种模式扩展到不同的时间增量——分钟、小时、天、月甚至年。一般流程和触发器集合看起来像这样：
- en: Every minute, a Lamba function reads data stored on S3 and calculates the average
    price for the last minute
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每分钟，一个 Lambda 函数读取存储在 S3 上的数据，并计算过去一分钟的平均价格
- en: Every hour, a Lamba function reads data stored on S3 and calculates the average
    price for the last hour
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每小时，一个 Lambda 函数读取存储在 S3 上的数据，并计算过去一小时的平均价格
- en: Every day, a Lamba function reads data stored on S3 and calculates the average
    price for the previous day
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每天晚上，一个 Lambda 函数读取存储在 S3 上的数据，并计算前一天的平均价格
- en: Since data is stored on S3, nothing is stopping this system from evolving to
    create an entirely new batch layer using more powerful tools such as Spark and
    Athena.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据存储在 S3 上，这个系统没有阻止它发展成为一个全新的批量层，使用更强大的工具，如 Spark 和 Athena。
- en: AWS resources
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS 资源
- en: 'In my opinion, the most complicated part of this entire system is set up all
    of the various resources and the interplay between them all. If you count up the
    number of resources we need to make this system work, the list quickly grows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，这个整个系统最复杂的部分是设置所有各种资源以及它们之间的相互作用。如果你计算我们需要使这个系统工作的资源数量，列表会迅速增长：
- en: Two S3 buckets
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个 S3 桶
- en: One Kinesis stream
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 Kinesis 流
- en: One Kinesis Firehose stream
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 Kinesis Firehose 流
- en: One DynamoDB table
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 DynamoDB 表
- en: Four Lambda functions
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 四个 Lambda 函数
- en: Multiple IAM roles
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多个 IAM 角色
- en: Not only do we need to create all of the preceding resources, but we need to
    ensure they can communicate with one another. As is often the case with building
    with AWS, much of the work involved in managing a stack such as this is getting
    permissions correct so that the Lambda function can read/write from/to the right
    S3 buckets, DynamoDB table, or Kinesis stream.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不仅需要创建所有前面的资源，还需要确保它们可以相互通信。正如在 AWS 中构建时经常发生的那样，管理此类堆栈所涉及的大部分工作都是确保权限正确，以便
    Lambda 函数可以从正确的 S3 桶、DynamoDB 表或 Kinesis 流中读取/写入。
- en: 'You can see proof of this if we use `cloc` to count the lines of code in this
    application. Looking at the following output, you''ll see that the amount of configuration
    code in `serverless.yml` is higher than the application code, with 165 lines of
    YAML configuration to 128 lines of Python code:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用 `cloc` 来计算这个应用程序的代码行数，你就可以看到这个证据。查看以下输出，你会发现 `serverless.yml` 中的配置代码量高于应用程序代码，有
    165 行 YAML 配置与 128 行 Python 代码：
- en: '[PRE0]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'I will walk through some interesting bits of the `serverless.yml` file here:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我将在这里介绍 `serverless.yml` 文件的一些有趣部分：
- en: '[PRE1]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: First, we need to ensure our Lambda functions will have access to the various
    resources. In the preceding `iamRoleStatements`, I'm giving various permissions
    for all Lambda functions in this stack to the two S3 buckets we'll use as well
    as DynamoDB. This shouldn't come as a big surprise. Our Lambda functions will
    be reading and writing data from and to S3\. Likewise, our speed layer will be
    writing new records to DynamoDB.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要确保我们的 Lambda 函数将能够访问各种资源。在先前的 `iamRoleStatements` 中，我正在为这个堆栈中的所有 Lambda
    函数授予对我们将使用的两个 S3 桶以及 DynamoDB 的各种权限。这 shouldn't come as a big surprise。我们的 Lambda
    函数将读取和写入 S3 中的数据。同样，我们的速度层将向 DynamoDB 写入新记录。
- en: Next, I'll walk through how to create a Kinesis stream that we can write to
    from our data producer, which, in turn, forwards messages on to a Kinesis Firehose
    delivery stream. Be warned; this is a bit raw and can seem complicated. I'll break
    this down bit by bit, hopefully in an order that is comprehensible.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将介绍如何创建一个 Kinesis 流，我们可以从我们的数据生产者写入，然后它将消息转发到 Kinesis Firehose 传输流。请注意；这有点原始，可能会显得复杂。我会一点一点地分解，希望以一个可理解的方式。
- en: 'The first step is creating a Kinesis stream. This part is straightforward using
    the `Resources` section of `serverless.yml`, which is straight-up CloudFormation.
    In this case, we only need a single shard since our application throughput is
    reasonably small. If the amount of data you''re pushing is larger, you can add
    additional throughput by increasing the number of shards. The following code snippet
    is the `resources` section from `serverless.yml` and shows how I''m creating the
    Kinesis stream:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是创建一个 Kinesis 流。这部分使用 `serverless.yml` 文件的 `Resources` 部分非常直接，它实际上是 CloudFormation。在这种情况下，我们只需要一个分片，因为我们的应用程序吞吐量相对较小。如果你推送的数据量更大，你可以通过增加分片数量来增加额外的吞吐量。以下是从
    `serverless.yml` 文件中的 `resources` 部分摘录的代码片段，展示了我是如何创建 Kinesis 流的：
- en: '[PRE2]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next up is the bit which is a bit more complicated. Kinesis Firehose is still
    a Kinesis stream, that behaves a bit differently as I mentioned earlier. In a
    standard Kinesis stream, you are responsible for doing something with the messages
    that producers push onto the stream. Kinesis Firehose, on the other hand, will
    automatically deliver a batch of messages to some destination. Your choices for
    final destinations are as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是稍微复杂一点的部分。Kinesis Firehose 仍然是一个 Kinesis 流，但它的行为与之前提到的略有不同。在一个标准的 Kinesis
    流中，您需要对生产者推送到流中的消息进行处理。另一方面，Kinesis Firehose 将自动将一批消息发送到某个目的地。您可以选择以下最终目的地：
- en: AWS S3
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS S3
- en: AWS Redshift
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS Redshift
- en: AWS Elasticsearch service
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS Elasticsearch 服务
- en: Splunk
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Splunk
- en: 'We can create a Kinesis Firehose stream by adding some CloudFormation code
    in the `Resources` block. What we need to create via CloudFormation is the following:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在 `Resources` 块中添加一些 CloudFormation 代码来创建一个 Kinesis Firehose 流。我们需要通过
    CloudFormation 创建以下内容：
- en: A Firehose stream that received data from the previous Kinesis stream and batch
    write data to S3 every 60 seconds
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个接收来自先前 Kinesis 流的数据的 Firehose 流，并且每 60 秒将数据批量写入 S3
- en: An IAM role that grants access to Firehose to read/write to/from our S3 buckets
    and also read the Kinesis stream
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 IAM 角色允许访问 Firehose，以便从我们的 S3 存储桶中读取/写入，并读取 Kinesis 流
- en: This CloudFormation code is a bit verbose. Rather than putting the entire code
    block here, I'll refer you to the GitHub repository. You can read the full details
    of setting up the Kinesis Firehose stream at the following URL: [https://github.com/brianz/serverless-design-patterns/blob/master/ch7/serverless/serverless.yml#L47-L113](https://github.com/brianz/serverless-design-patterns/blob/master/ch7/serverless/serverless.yml#L47-L113).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这段 CloudFormation 代码有点冗长。而不是在这里放置整个代码块，我会将您引导到 GitHub 仓库。您可以在以下 URL 中阅读设置 Kinesis
    Firehose 流的完整细节：[https://github.com/brianz/serverless-design-patterns/blob/master/ch7/serverless/serverless.yml#L47-L113](https://github.com/brianz/serverless-design-patterns/blob/master/ch7/serverless/serverless.yml#L47-L113)。
- en: The data source for this Firehose stream is the primary Kinesis stream, which
    I named `GdaxKinesisStream`. You can see the configuration to use this stream
    as a data source in the `KinesisStreamSourceConfiguration` and `DeliveryStreamType`
    keys. These two settings say that we're going to be using a Kinesis stream as
    a data source, as opposed to putting data directly on this Firehose stream via
    API calls. It also tells the Firehose stream where to find this source Kinesis
    stream via the `KinesisStreamSourceConfiguration`, which can be a bit confusing.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 此 Firehose 流的数据源是主要的 Kinesis 流，我将其命名为 `GdaxKinesisStream`。您可以在 `KinesisStreamSourceConfiguration`
    和 `DeliveryStreamType` 键中看到使用此流作为数据源的配置。这两个设置说明我们将使用 Kinesis 流作为数据源，而不是通过 API
    调用直接将数据放在此 Firehose 流上。它还通过 `KinesisStreamSourceConfiguration` 告诉 Firehose 流在哪里可以找到这个源
    Kinesis 流，这可能会有些令人困惑。
- en: Here, `KinesisStreamSourceConfiguration` is comprised of two keys, `KinesisStreamARN`
    and `RoleARN`. The former, `KinesisStreamARN`, refers to the location of the Kinesis
    stream we're connecting to. `RoleARN`, on the other hand, has to do with permissions.
    This referenced role must permit for the reading of the source Kinesis stream.
    It's a bit too much to cover here, but if you look at the entirety of the configuration,
    it should make some amount of sense.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`KinesisStreamSourceConfiguration` 包含两个键，`KinesisStreamARN` 和 `RoleARN`。前者，`KinesisStreamARN`，指的是我们连接到的
    Kinesis 流的位置。另一方面，`RoleARN` 与权限有关。这个引用的角色必须允许读取源 Kinesis 流。这里涉及的内容有点多，但如果查看整个配置，应该能理解一些。
- en: Now that we've taken care of the input source, we need to set up the S3 destination
    configuration in the `S3DestinationConfiguration` key. This configuration is analogous
    to that of the source stream; we need to give our Firehose stream the data on
    where to write data with the `BucketARN` and also give it a role with the necessary
    access.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经处理好了输入源，我们需要在 `S3DestinationConfiguration` 键中设置 S3 目标配置。此配置类似于源流；我们需要通过
    `BucketARN` 给我们的 Firehose 流指定数据写入的位置，并给它一个具有必要访问权限的角色。
- en: The other interesting and important part of the `S3DestinationConfiguration`
    is that it's configured to write data to S3 every 60 seconds or every 5 MB, whichever
    comes first. Since the GDAX WebSocket feed isn't all that chatty, we can count
    on hitting the 60-second limit before the buffer in Firehose reaches 5 MB.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`S3DestinationConfiguration` 的另一个有趣且重要的部分是它被配置为每 60 秒或每 5 MB（以先到者为准）将数据写入 S3。由于
    GDAX WebSocket 推送并不那么频繁，我们可以预计在 Firehose 缓冲区达到 5 MB 之前会先达到 60 秒的限制。'
- en: 'From here, we can turn our attention to the Lambda functions that will be running
    our application code. I''ve implemented four different Lambda functions, which
    will handle the following:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，我们可以将注意力转向将运行我们的应用程序代码的 Lambda 函数。我实现了四个不同的 Lambda 函数，它们将处理以下任务：
- en: Single events from the Kinesis stream
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自 Kinesis 流的单个事件
- en: S3 objects created every 60 seconds from Kinesis Firehose
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每 60 秒从 Kinesis Firehose 创建的 S3 对象
- en: S3 objects created from the aggregated minute views of data
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数据的聚合分钟视图创建的 S3 对象
- en: S3 objects created from the aggregated hour views of data
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数据的聚合小时视图创建的 S3 对象
- en: 'The configuration of these four Lambda functions is shown as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 以下展示了这四个 Lambda 函数的配置：
- en: '[PRE3]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can see that the first function, `ProcessPrice`, is triggered upon delivery
    of a message onto our Kinesis stream. Once this function executes, its job is
    done. There is no other interaction with this function and any other function.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，第一个函数 `ProcessPrice` 在消息被投递到我们的 Kinesis 流上时被触发。一旦这个函数执行完毕，它的任务就完成了。这个函数与其他任何函数都没有其他交互。
- en: The next three functions work in coordination. This process starts when `CalculateMinuteView`
    is triggered when the Firehose stream delivers a new batch of messages every 60
    seconds to S3\. This function will calculate the average prices using all of the
    delivered messages and upload a new file to S3 named `MM-minute.json`, where `MM`
    is a numerical representation of the minute calculated (`00, 01...59`).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的三个函数协同工作。这个过程从 `CalculateMinuteView` 被触发开始，当 Firehose 流每 60 秒向 S3 交付一批新消息时。这个函数将使用所有交付的消息计算平均价格，并将一个新文件上传到
    S3，文件名为 `MM-minute.json`，其中 `MM` 是计算出的分钟的数值表示（00，01...59）。
- en: Once we reach the end of an hour, this function will write a file named `59-minute.json`.
    Since that file signifies the end of an hour, we can trigger the `CalculateHourlyView`
    function to calculate the average prices for the past hour. This function produces
    files named `HH-hour.json`, where `HH` represents the 24 hours in a day `(00,
    01...23)`. The same strategy holds true for hours and days. Once a file named
    `23-hour.json` arrives, it's time to calculate the daily average prices from `CalculateDailyView`.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们到达一个小时的末尾，这个函数将写入一个名为 `59-minute.json` 的文件。由于该文件表示一个小时的结束，我们可以触发 `CalculateHourlyView`
    函数来计算过去一个小时的平均价格。这个函数生成名为 `HH-hour.json` 的文件，其中 `HH` 代表一天中的 24 小时（00，01...23）。对于小时和天，同样的策略也是适用的。一旦收到名为
    `23-hour.json` 的文件，就到了计算每日平均价格的时候，由 `CalculateDailyView` 来完成。
- en: Data producer
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据生产者
- en: 'The following example code shows what a simple client application looks like
    if you''re interested in prices for Bitcoin and Ethereum. This code doesn''t do
    anything other than deserializing the JSON payload from each message and printing
    it to the Terminal:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例代码展示了如果您对比特币和以太坊的价格感兴趣，一个简单的客户端应用程序看起来是什么样的。这段代码除了从每条消息中反序列化 JSON 负载并将其打印到终端外，不做任何其他操作：
- en: '[PRE4]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Executing this code, I''ll see payloads printing out whenever there is a buy
    or sell transaction for either of the two currencies to which I''ve subscribed:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此代码，每当我对订阅的两种货币中的任何一种进行买卖交易时，我都会看到负载打印出来：
- en: '[PRE5]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To get this data into our system, we need a few extra lines of code to publish
    data into an AWS Kinesis stream. The changes to the preceding client code are
    quite simple. Upon receiving a new message, I''ll check whether the payload is
    of the correct type, merely by looking for the time key. Some messages that we
    get back are confirmations to our subscription and do not include the time key,
    indicating some other message other than a trade. The following code shows these
    changes and how I use the `boto3` library to publish data to a Kinesis stream:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将此数据引入我们的系统，我们需要添加几行额外的代码来将数据发布到 AWS Kinesis 流中。对前面的客户端代码的更改相当简单。在接收到一条新消息后，我会检查负载是否为正确的类型，只需查找时间键即可。我们收到的某些消息是对我们订阅的确认，并且不包含时间键，这表明除了交易之外的其他消息。以下代码展示了这些更改以及我是如何使用
    `boto3` 库将数据发布到 Kinesis 流的：
- en: '[PRE6]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This part of our application is completely standalone. I ran this small script
    on an EC2 instance inside of a `screen` session, so the code continued to run
    when I logged out. This implementation isn't suitable for a real production system,
    but it worked just fine for the few days that I ran it. If I were doing this for
    an actual production system, I'd run this code with some daemon management systems
    such as `supervisord`, `upstart`, or `runit`.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用程序的这一部分是完全独立的。我在一个`screen`会话中的EC2实例上运行了这个小脚本，所以当我登出时代码仍然在运行。这种实现不适合真正的生产系统，但在我运行它的那几天里它工作得很好。如果我要为实际的生产系统做这件事，我会使用一些守护进程管理系统，如`supervisord`、`upstart`或`runit`来运行这段代码。
- en: Speed layer
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 速度层
- en: 'Our speed layer is the simplest part of the entire system. With the configuration
    in place—a `single` Lambda function to execute whenever a new stream message arrives—the
    only work we need to do is decode the data from the message payload, calculate
    the DynamoDB partition key, and write it to DynamoDB. The following code block
    shows all of this work in the `single` function, which is processing a single
    message from AWS Kinesis:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的速度层是整个系统中最简单的一部分。有了配置到位——一个`single` Lambda函数，每当有新的流消息到达时就会执行——我们唯一需要做的工作是从消息有效负载中解码数据，计算DynamoDB分区键，并将其写入DynamoDB。以下代码块显示了所有这些工作都在`single`函数中完成，该函数正在处理来自AWS
    Kinesis的单个消息：
- en: This code is all located in a single `handler.py` function, which goes against
    a best practice of splitting up application code and decoupling application logic
    from the cloud-specific bits. However, this application code is for demonstration
    purposes, and I can get away with breaking some rules for the sake of clarity
    and brevity. If there were a real system rather than a demo, I would be much more
    deliberate and organized with this code. Some of the import statements will be
    used in the batch layer code.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码全部位于一个单独的`handler.py`函数中，这与将应用程序代码拆分和将应用程序逻辑与云特定部分解耦的最佳实践相悖。然而，这段应用程序代码仅用于演示目的，我可以为了清晰和简洁而打破一些规则。如果有一个真实系统而不是演示，我会对这个代码更加谨慎和有组织。一些导入语句将在批处理层代码中使用。
- en: '[PRE7]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The result of this code is that every single GDAX transaction we''re interested
    in ends up in our DynamoDB table. The following screenshot shows a subset of the
    data stored. With the data in DynamoDB, our view layer can quickly look up a set
    of rows for a particular time range:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的结果是，我们感兴趣的每一个GDAX交易最终都会出现在我们的DynamoDB表中。下面的截图显示了存储数据的一个子集。有了DynamoDB中的数据，我们的视图层可以快速查找特定时间范围内的行集：
- en: '![](img/8cc2640e-7f08-4798-8e9d-a8ab7510e8b1.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8cc2640e-7f08-4798-8e9d-a8ab7510e8b1.png)'
- en: Prices for DynamoDB are more dependent on the reads and writes you need for
    this system. Even though there is no code to trim out data we no longer need (that
    is, data that is historical and handled the batch layer), it's not a huge concern.
    Still, if there were a production system, you'd want to consider some techniques
    on expiring data that is no longer needed.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: DynamoDB的价格更多地取决于您对这个系统所需的读取和写入操作。尽管没有代码来删除我们不再需要的数据（即历史数据和处理批处理层的数据），但这并不是一个巨大的问题。然而，如果有一个生产系统，您会希望考虑一些关于过期不再需要的数据的技术。
- en: Batch layer
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批处理层
- en: Whereas our speed layer is only interacting with DynamoDB, our batch layer will
    just be interacting with S3\. There are two distinct types of functions in this
    layer—the functions that respond to S3 objects that arrive from Firehose, and
    functions that respond to S3 objects coming from Lambda functions. There isn't
    all that much difference, but it's important to point out the two different categories.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 而我们的速度层只与DynamoDB交互，我们的批处理层将与S3交互。在这个层中有两种不同的函数——响应来自Firehose的S3对象的函数，以及响应来自Lambda函数的S3对象的函数。它们之间没有太大的区别，但重要的是要指出这两个不同的类别。
- en: 'The following code block, taken from `handler.py`, shows the application code
    that comprises our batch layer:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块是从`handler.py`中摘取的，显示了构成我们批处理层的应用程序代码：
- en: '[PRE8]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Batch processing starts with the `minute` function. Again, this function starts
    when a new file arrives in S3 from our Firehose stream. At this point, we can
    be assured that the `minute` function is invoked once a minute based on our configuration.
    We don't need to go through this line by line, but we can look at the final results
    as well as some small tricks.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 批处理从`minute`函数开始。同样，这个函数在从我们的Firehose流到达S3的新文件时启动。在这个时候，我们可以确信`minute`函数根据我们的配置每分钟被调用一次。我们不需要逐行检查，但我们可以查看最终结果以及一些小技巧。
- en: 'You may notice the line that splits data using `split(''|||'')`. Firehose will
    concatenate records together before delivering to any data source. The AWS documentation
    on Kinesis Firehose explicitly states this, but it''s still easy to overlook:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到使用 `split('|||')` 分割数据的行。Firehose 在将记录交付到任何数据源之前会将记录连接起来。AWS 关于 Kinesis
    Firehose 的文档明确指出这一点，但仍然容易忽略：
- en: '"For data delivery to Amazon S3, Kinesis Firehose concatenates multiple incoming
    records based on buffering configuration of your delivery stream and then delivers
    them to Amazon S3 as an S3 object. You may want to add a record separator at the
    end of each record before you send it to Kinesis Firehose so that you can divide
    a delivered S3 object to individual records."'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: “为了将数据交付到 Amazon S3，Kinesis Firehose 根据你的交付流缓冲区配置将多个传入记录连接起来，然后将它们作为 S3 对象交付给
    Amazon S3。在你将记录发送到 Kinesis Firehose 之前，你可能想在每条记录的末尾添加一个记录分隔符，这样你就可以将交付的 S3 对象分割成单个记录。”
- en: The preceding has been quoted from [https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html](https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html).[](https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的内容摘自 [https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html](https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html)。[链接](https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html)
- en: If you look back up at the data producer, you can see that we're appending the
    `'|||'` string to each message. With this delimiter, it's possible for us to break
    apart individual messages in this function.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你回顾一下数据生产者，你可以看到我们在每条消息后面附加了 `'|||'` 字符串。有了这个分隔符，我们就可以在这个函数中拆分单个消息。
- en: 'The final results that the `minute` function uploads to S3 have the following
    form. For each currency, it includes the list of individual buy prices along with
    the average price:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`minute` 函数上传到 S3 的最终结果具有以下形式。对于每种货币，它包括单个购买价格列表以及平均价格：'
- en: '[PRE9]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Our `CalculateHourlyView` executes once a file named `59-minute.json` arrives
    in S3\. The arrival of this S3 object signifies the end of an hour, so it's time
    to calculate the average prices for the entire hour. That work for the hour calculation,
    as well as the calculation of the daily average, is all wrapped up in the `_aggregate_prices`
    function. By using the prefix of the S3 object that triggers the functions, we'll
    only scan through a subset of the S3 records that are used in the calculation
    of the averages. For example, when a new S3 object arrives with a key name of
    `$BUCKET/2018/03/19/04/59-minute.json`, our application code can pick apart the `$BUCKET/2018/03/19/04`
    prefix and only scan files in that location. When an S3 object arrives named `$BUCKET/2018/03/19/23-hour.json`,
    the daily function will scan through files with the `$BUCKET/2018/03/19` prefix.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 `CalculateHourlyView` 在名为 `59-minute.json` 的文件到达 S3 后执行一次。这个 S3 对象的到来标志着小时的结束，因此是计算整个小时平均价格的时候了。小时计算以及每日平均的计算都被封装在
    `_aggregate_prices` 函数中。通过使用触发函数的 S3 对象的前缀，我们只会扫描用于计算平均值的 S3 记录的子集。例如，当一个新的 S3
    对象以键名 `$BUCKET/2018/03/19/04/59-minute.json` 到达时，我们的应用程序代码可以解析 `$BUCKET/2018/03/19/04`
    前缀，并只扫描该位置的文件。当一个名为 `$BUCKET/2018/03/19/23-hour.json` 的 S3 对象到达时，每日函数将扫描具有 `$BUCKET/2018/03/19`
    前缀的文件。
- en: Results
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: After running this system for a few days, I was able to produce many S3 files
    as expected, as well as keeping track of each trade in DynamoDB. As I mentioned
    earlier in this chapter, implementing some view layer wasn't feasible for this
    example system. However, querying DynamoDB is quite easy, provided primary keys
    and sort keys are set up correctly. Any view layer that needed to get historical
    data could easily grab files from S3.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行这个系统几天后，我能够如预期地生成许多 S3 文件，同时还在 DynamoDB 中跟踪每一笔交易。正如我在本章前面提到的，对于这个示例系统来说，实现一些视图层是不切实际的。然而，只要设置了主键和排序键，查询
    DynamoDB 就相当容易。任何需要获取历史数据的视图层都可以轻松地从 S3 中获取文件。
- en: 'The following screenshot shows listings of S3 files for a given hour. Each
    file has the format shown earlier with individual prices, along with the pre-computed
    average for each currency:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了给定小时的 S3 文件列表。每个文件都具有前面显示的格式，包括单个价格，以及每种货币的预先计算的平均值：
- en: '![](img/84eb37ec-4bcb-429d-9d44-11d7ae582ff8.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/84eb37ec-4bcb-429d-9d44-11d7ae582ff8.png)'
- en: 'Looking one level up in the S3 hierarchy, we can see the hour files that contain
    the average prices:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在 S3 层次结构中向上查看一个级别，我们可以看到包含平均价格的每小时文件：
- en: '![](img/ea568325-0b31-4753-9ead-2547ea41f0ec.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ea568325-0b31-4753-9ead-2547ea41f0ec.png)'
- en: Summary
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the Lambda pattern at a conceptual level as well
    as in detail. I walked through an example implementation with serverless technologies
    to calculate average cryptocurrency prices for different time slices. Our example
    application was fed by a simple script that receives data from the GDAX WebSocket
    API. This data producer script published data to a single AWS Kinesis stream,
    which, in turn, triggered a series of events, ultimately resulting in real-time
    updates to DynamoDB and triggering batch jobs to calculate historical views of
    the minute, hourly, and daily average prices for multiple cryptocurrencies.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们从概念层面以及详细层面讨论了Lambda模式。我通过一个使用无服务器技术计算不同时间段的平均加密货币价格的示例实现进行了说明。我们的示例应用程序由一个简单的脚本提供数据，该脚本从GDAX
    WebSocket API接收数据。这个数据生产者脚本将数据发布到单个AWS Kinesis流中，这反过来又触发了一系列事件，最终导致DynamoDB的实时更新，并触发批量作业来计算多种加密货币的分钟、小时和日平均价格的历史视图。
- en: I discussed when the Lambda pattern may be appropriate and the types of data
    for which it's well suited. We talked through various systems and services that
    one may leverage when building a lambda architecture using serverless technologies.
    I introduced AWS Kinesis and AWS Kinesis Firehose, which are streaming systems
    you may leverage for real-time applications.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我讨论了Lambda模式可能适用的情况以及它非常适合的数据类型。我们探讨了在构建使用无服务器技术的Lambda架构时可能利用的各种系统和服务。我介绍了AWS
    Kinesis和AWS Kinesis Firehose，这些是您可以用于实时应用的流式系统。
- en: While the details of a Lambda pattern implementation can be quite intricate,
    readers should have a decent understanding of its advantages, disadvantages, and
    when they should consider it.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Lambda模式实现的细节可能相当复杂，但读者应该对它的优点、缺点以及何时应该考虑使用它有一个相当好的理解。
- en: In the next chapter, I'll cover the MapReduce pattern and work through an example
    where we will build our very own serverless implementation of this pattern.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我将介绍MapReduce模式，并通过一个示例来构建我们自己的无服务器实现。
