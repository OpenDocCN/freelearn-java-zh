- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Architecting a Batch Processing Pipeline
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 架构批处理管道
- en: In the previous chapter, we learned how to architect medium- to low-volume batch-based
    solutions using Spring Batch. We also learned how to profile such data using DataCleaner.
    However, with data growth becoming exponential, most companies have to deal with
    huge volumes of data and analyze it to their advantage.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何使用 Spring Batch 架构中等到低量的批处理解决方案。我们还学习了如何使用 DataCleaner 对此类数据进行分析。然而，随着数据增长呈指数级，大多数公司不得不处理大量数据并分析以获得优势。
- en: In this chapter, we will discuss how to analyze, profile, and architect a big
    data solution for a batch-based pipeline. Here, we will learn how to choose the
    technology stack and design a data pipeline to create an optimized and cost-efficient
    big data solution. We will also learn how to implement this solution using Java,
    Spark, and various AWS components and test our solution. After that, we will discuss
    how to optimize the solution to be more time and cost-efficient. By the end of
    this chapter, you will know how to architect and implement a data analysis pipeline
    in AWS using S3, Apache Spark (Java), AWS EMR, AWS Lambda, and AWS Athena. You
    will also know how to fine-tune the code for optimized performance, as well as
    how to plan and optimize the cost of implementations.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '在本章中，我们将讨论如何分析、分析和架构一个基于批处理的大数据解决方案。在这里，我们将学习如何选择技术栈并设计一个数据管道，以创建一个优化且成本效益高的大数据解决方案。我们还将学习如何使用
    Java、Spark 以及各种 AWS 组件来实现此解决方案，并测试我们的解决方案。之后，我们将讨论如何优化解决方案以更节省时间和成本。到本章结束时，您将了解如何使用
    S3、Apache Spark（Java）、AWS EMR、AWS Lambda 和 AWS Athena 在 AWS 中架构和实现数据分析管道。您还将了解如何微调代码以实现优化性能，以及如何规划和优化实施成本。 '
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Developing the architecture and choosing the right tools
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 架构开发和选择合适的工具
- en: Implementing the solution
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现解决方案
- en: Querying the ODL using AWS Athena
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 AWS Athena 查询 ODL
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To follow along with this chapter, you’ll need the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟随本章内容，您需要以下内容：
- en: Prior knowledge of Java
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 熟悉 Java
- en: Prior knowledge of the basics of Apache Spark
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 熟悉 Apache Spark 的基础知识
- en: Java 1.8 or above installed on your local machine
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在您的本地机器上安装了 Java 1.8 或更高版本
- en: IntelliJ Idea community or ultimate edition installed on your local machine
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在您的本地机器上安装了 IntelliJ Idea 社区版或终极版
- en: An AWS account
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 AWS 账户
- en: 'The code for this chapter can be found in this book’s GitHub repository: [https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05](https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在本书的 GitHub 仓库中找到：[https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05](https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05)。
- en: Developing the architecture and choosing the right tools
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 架构开发和选择合适的工具
- en: In data engineering, after the data has been successfully ingested and stored
    in a data lake or a data warehouse, often, it needs to be mined and stored for
    specific needs in a more sorted and customized form for reporting and analysis.
    In this chapter, we will discuss such a problem where a huge volume of data needs
    to be analyzed and stored in a more customized format for a specific downstream
    audience.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据工程中，数据成功摄入并存储在数据湖或数据仓库后，通常需要对其进行挖掘和存储，以满足特定需求，以更有序和定制化的形式进行报告和分析。在本章中，我们将讨论这样一个问题，即需要分析并存储大量数据，以便为特定的下游受众提供更定制化的格式。
- en: Problem statement
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题陈述
- en: Let’s assume that an e-commerce firm, ABC, wants to analyze various kinds of
    user interaction on its products and determine the top-selling products for each
    category each month. They want to provide incentives to the top-selling products
    in each category. They also want to provide special offers and marketing promotion
    tools to products with top view-to-sale ratios but are not the top-selling products.
    In addition, they want to market seller tools and training, as well as marketing
    services, to the team with the lowest-selling product in each category. Currently,
    ABC stores all user transactions in its transactional databases for a product,
    but there is no monthly data view where information about the top seller, worst
    seller, and the top view-to-sale ratio is available. They want an **Organized
    Data Layer** (**ODL**) to be created so that such analytical queries can easily
    be performed with optimum performance every month.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一家电商公司ABC想要分析其产品上的各种用户互动，并确定每个月每个类别的畅销产品。他们希望为每个类别的畅销产品提供激励措施。他们还希望为那些具有最高浏览到销售比率的但不是畅销产品的产品提供特别优惠和营销推广工具。此外，他们还希望向每个类别中销量最低的产品团队提供卖家工具和培训，以及营销服务。目前，ABC将其产品交易的所有用户交易存储在其产品交易数据库中，但没有提供关于顶级卖家、最差卖家和最高浏览到销售比率的月度数据视图。他们希望创建一个**组织化数据层**（**ODL**），以便可以轻松地以最佳性能每月执行此类分析查询。
- en: Analyzing the problem
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析问题
- en: Let’s analyze the given problem. First, let’s analyze the requirements in terms
    of the four dimensions of data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来分析给定的问题。首先，让我们从数据的四个维度来分析需求。
- en: First, we will try to answer the question, *what is the velocity of the data?* Here,
    as evident from the requirements, we need to create an ODL with monthly analyzed
    data. Hence, our data will be used after a month, so we have no real-time data
    processing requirement. So, we can safely assume that we are dealing with a batch
    processing problem. However, it will be helpful to know how frequently the data
    arrives, which will help us determine at what frequency we can schedule a batch
    job. So, we must ask the e-commerce firm, *how frequently will source data be
    provided to us?* ABC tells us that the source data will be dropped to us as CSV
    files on a monthly or bi-monthly basis, but never twice daily. This information
    is helpful to us, but that brings other questions to mind.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将尝试回答这个问题：*数据速度是什么？* 从需求中可以看出，我们需要创建一个包含月度分析数据的ODL。因此，我们的数据将在一个月后使用，所以我们没有实时数据处理需求。因此，我们可以安全地假设我们正在处理一个批处理问题。然而，了解数据到达的频率将有助于我们确定可以安排批处理作业的频率。因此，我们必须询问电商公司，*源数据将以多高的频率提供给我们？*
    ABC告诉我们，源数据将以每月或双月为基础以CSV文件的形式提供给我们，但不会每天两次。这个信息对我们很有帮助，但也引发了一些其他问题。
- en: Now, the most obvious next question that comes to our mind is, *how big is the
    data/file that will be shared once or twice monthly?* Considering that each record
    will be an event on each transaction that any user has made on any product in
    the e-commerce marketplace, the data is likely to be huge. ABC tells us that transactions
    can be either view, cart, or purchase transactions. So, for each action, such
    as viewing a product, adding to the cart, and purchasing a product, there will
    be separate entries in the file. ABC also tells us that the number of products
    and categories is likely to increase in the future. From our guestimate and ABC’s
    internal data, each file sent to us can vary from hundreds of gigabytes to terabytes
    of data. The data that needs to be processed is in the range of hundreds of gigabytes
    and terabytes, which is ideal for big data processing. Our analysis also tells
    that the e-commerce traffic is going to increase over time. These observations
    indicate that this is a big data problem. So, we need to develop a big data solution
    to solve this batch processing problem.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们心中最明显的问题就是，*每月或每两个月共享的数据/文件有多大？* 考虑到每条记录都将是在电商市场中任何用户对任何产品进行的每次交易的单独事件，数据可能非常庞大。ABC告诉我们，交易可以是查看、购物车或购买交易。因此，对于每个动作，例如查看产品、添加到购物车和购买产品，文件中都会有单独的条目。ABC还告诉我们，产品和类别的数量可能会在未来增加。根据我们的估计和ABC的内部数据，发送给我们的每个文件的数据量可能从数百GB到数TB不等。需要处理的数据量在数百GB到数TB之间，非常适合大数据处理。我们的分析还表明，电商流量将会随着时间的推移而增加。这些观察结果表明这是一个大数据问题。因此，我们需要开发一个大数据解决方案来解决这个批处理问题。
- en: Now, we will look at the *variety of the data*. From our previous discussion,
    we know that data is arriving in CSV format. So, this is structured data that
    needs to be analyzed and processed. We will hold the discussion on the variety
    of data for a while as we will be taking that up during the implementation phase.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将探讨数据的*多样性*。从我们之前的讨论中，我们知道数据是以CSV格式到达的。因此，这是需要分析和处理的结构化数据。我们将暂时讨论数据的多样性，因为我们将在实施阶段进行这一讨论。
- en: 'The next decision that we must make, as architects, is to choose the right
    platform. Should we run this application on-premise or in the cloud? There are
    pros and cons to both. However, there are a few vital points regarding why the
    cloud may be a better choice in this case:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 作为架构师，我们必须做出的下一个决定是选择正确的平台。我们应该在本地运行这个应用程序还是在云中？两者都有利弊。然而，有几个关键点说明了为什么在这种情况下云可能是一个更好的选择：
- en: '**Cost saving**: Running a big data job with terabytes of data will require
    a very good big data infrastructure to run on-premise. However, these jobs will
    only run once or twice a month. If we choose to create an on-premise environment,
    it doesn’t make sense to spend so many dollars creating a clustered Hadoop infrastructure
    that will only be used once or twice a month, but where the infrastructure needs
    to be maintained and running at all times. The amount of cost and effort involved
    in creating and maintaining such an infrastructure doesn’t justify the utilization.
    This will be much cheaper on the cloud, where you pay only for the resources you
    utilize during the job run. The cloud can give you the choice to only pay for
    what you use.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本节约**：运行一个包含数TB数据的大数据作业需要一个非常好的大数据基础设施来在本地运行。然而，这些作业每月只会运行一次或两次。如果我们选择创建本地环境，那么花费大量美元创建一个每月只使用一次或两次的集群Hadoop基础设施就没有意义了，但基础设施需要始终维护和运行。创建和维护此类基础设施的成本和努力并不合理地证明其利用率。在云中，你只需为作业运行期间使用的资源付费，这会便宜得多。云可以让你选择只为你使用的资源付费。'
- en: For example, in the cloud, you can choose to keep your Hadoop environment running
    for only 2 hours daily; this way, you only pay for those 2 hours and not for the
    whole day. More importantly, it supports elasticity, which means you can auto-scale
    your number of nodes to a higher or lower number based on your usage. This gives
    you the flexibility to use only the required resource each time. For example,
    if we know that the data (which needs to be processed) will be huge in November
    and the jobs will take up more resources and time in November, we can increase
    the resource capacity for November and bring it down when the volume reduces to
    a normal level. Such capabilities of cloud technologies enable huge cost savings
    on the overall execution of the system (especially **capital expenditure** (**CapEx**)
    costs).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在云中，你可以选择每天只让Hadoop环境运行2小时；这样，你只需为那2小时付费，而不是一整天。更重要的是，它支持弹性，这意味着你可以根据你的使用情况自动扩展你的节点数量到更高的或更低的数量。这给了你每次只使用所需资源的灵活性。例如，如果我们知道11月需要处理的数据量会很大，作业在11月需要更多的资源和时间，我们可以在11月增加资源容量，并在数据量减少到正常水平时降低它。云技术的这些能力使得整个系统的执行（尤其是**资本支出**（**CapEx**）成本）可以大幅节省。
- en: '**Seasonal variation in workloads**: Usually, in an e-commerce site, the activity
    during the holiday season or festival season is high, while at other times, the
    activity is low. User activity directly impacts the size of the file for that
    month. So, we must be able to scale the infrastructure up and down as we need.
    This can easily be achieved in the cloud.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工作负载的季节性变化**：通常，在电子商务网站上，节假日或节庆期间的活跃度很高，而在其他时间，活跃度则较低。用户活动直接影响到该月的文件大小。因此，我们必须能够根据需要调整基础设施的规模。这在云中可以轻松实现。'
- en: '**Future elasticity**: As one of the requirements clearly states that the number
    of products and categories is likely to increase, this means we will need to scale
    up both processing and storage capacities in the future. While such changes require
    a lot of time and resources in on-premise environments, this can easily be achieved
    in the cloud.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未来的弹性**：作为明确要求之一，产品类别数量很可能会增加，这意味着我们将来需要扩大处理和存储容量。虽然此类更改在本地环境中需要大量时间和资源，但在云中可以轻松实现。'
- en: '**Lack of sensitive data**: There is no specific federal or **Protected Health
    Information** (**PHI**) data involved in our use case that needs to be encrypted
    or tokenized before it is stored in the cloud. So, we should be good with legal
    and data security requirements.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏敏感数据**：在我们的用例中，没有特定的联邦或**受保护的健康信息**（**PHI**）数据需要加密或标记后存储在云中。因此，我们应该符合法律和数据安全要求。'
- en: Although we can choose any public cloud platform, for our convenience, we will
    use AWS as our cloud platform in this book.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们可以选择任何公共云平台，但为了方便起见，我们将在这本书中使用AWS作为我们的云平台。
- en: Architecting the solution
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建解决方案
- en: 'Now that we have gathered and analyzed our requirements, let’s try building
    the architecture for the solution. To architect this solution, we need to answer
    the following questions:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经收集并分析了我们的需求，让我们尝试构建解决方案的架构。为了构建这个解决方案，我们需要回答以下问题：
- en: Where should we store or land the input data?
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该在何处存储或放置输入数据？
- en: How should we process the input data?
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该如何处理输入数据？
- en: Where and how should we store the output data/ODL?
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该在何处以及如何存储输出数据/ODL？
- en: How should we provide a querying interface to the ODL?
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该如何提供一个查询接口给ODL？
- en: How and when should we schedule a processing job?
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该如何以及何时安排处理作业？
- en: 'Let’s see what options we have for storing the input data. We can store the
    data in one of the following services:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们存储输入数据有哪些选项。我们可以将数据存储在以下服务之一：
- en: '**S3**: **S3** or **Simple Storage Service** is a very popular object storage
    service. It is also cheap and very reliable.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**S3**：**S3**或**简单存储服务**是一个非常流行的对象存储服务。它既便宜又非常可靠。'
- en: '**EMR/EC2 attached EBS volumes**: **Elastic Block Storage** (**EBS**) is a
    block storage solution where storage volumes can be attached to any virtual server,
    such as an EC2 instance. For a big data solution, if you use **Elastic Map Reduce**
    (**EMR**), EBS volumes can be attached to each participating EC2 node in that
    EMR cluster.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**EMR/EC2附加的EBS卷**：**弹性块存储**（**EBS**）是一种可以将存储卷附加到任何虚拟服务器（如EC2实例）的块存储解决方案。对于大数据解决方案，如果您使用**弹性MapReduce**（**EMR**），EBS卷可以附加到该EMR集群中的每个参与EC2节点。'
- en: '**Elastic File System (EFS)**: EFS is a shared filesystem that’s often attached
    to a NAS server. It is usually used for content repositories, media stores, or
    user home directories.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**弹性文件系统（EFS）**：EFS是一个共享文件系统，通常连接到NAS服务器。它通常用于内容存储库、媒体存储或用户主目录。'
- en: Let’s discuss the different factors to consider before choosing your storage.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论在选择存储之前需要考虑的不同因素。
- en: Factors that affect your choice of storage
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 影响您存储选择的因素
- en: 'Cost is an important factor that we need to consider when choosing any cloud
    component. However, let’s look at factors other than cost that affect our choice
    of storage. These factors are as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 成本是我们在选择任何云组件时需要考虑的重要因素。然而，让我们看看除了成本之外影响我们存储选择的其他因素。以下是一些因素：
- en: '**Performance**: Both EBS and EFS can perform faster than S3 in terms of IOPS.
    Although performance is slower in S3, it’s not significantly slower to read the
    data from other storage options. From a performance perspective, an EFS or EBS
    volume will still be preferred.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能**：从IOPS的角度来看，EBS和EFS可以比S3更快地执行。尽管S3的性能较慢，但读取其他存储选项中的数据并不显著较慢。从性能角度来看，EFS或EBS卷仍然会被优先考虑。'
- en: '**Scalability**: Although all three storage options are scalable, S3 has the
    most seamless scalability without any manual effort or interruption. Since scalability
    is one of our important needs as our data grows over time and there is a possibility
    of bigger file sizes in the future (according to the requirements), from this
    perspective, S3 is a clear winner.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：尽管所有三种存储选项都是可扩展的，但S3具有最无缝的可扩展性，无需任何手动努力或中断。由于可扩展性是我们随着数据随时间增长的重要需求之一，并且未来可能存在更大的文件大小（根据要求），从这个角度来看，S3是一个明显的赢家。'
- en: '**Life cycle management**: Both S3 and EFS have life cycle management features.
    Suppose you believe that older files (older than a year) need to be archived;
    these programs can seamlessly move to another cheaper storage class, which provides
    seamless archival storage as well as cost savings.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生命周期管理**：S3和EFS都具有生命周期管理功能。假设你认为旧文件（超过一年的文件）需要存档；这些程序可以无缝地移动到另一个更便宜的存储类别，这提供了无缝的存档存储以及成本节约。'
- en: '**Serverless architecture support**: Both S3 and EFS provide serverless architecture
    support.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无服务器架构支持**：S3和EFS都提供无服务器架构支持。'
- en: '**High availability and robustness**: Again, both S3 and EFS are highly robust
    and available options for storage. In this regard, EBS is not on par with the
    other two storage options.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高可用性和鲁棒性**：再次强调，S3和EFS都是高度鲁棒和可用的存储选项。在这方面，EBS与其他两种存储选项不相上下。'
- en: '**Big data analytic tool compatibility**: Reading and writing data from an
    S3 or EBS volume is much easier from big data processing engines such as Spark
    and MapReduce. Also, creating external Hive or Athena tables is much easier if
    the data resides in S3 or EBS.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大数据分析工具兼容性**：从S3或EBS卷读取和写入数据对于Spark和MapReduce等大数据处理引擎来说要容易得多。如果数据存储在S3或EBS中，创建外部Hive或Athena表也要容易得多。'
- en: As we can see, both S3 and EFS seem to be promising options to use. Now, let’s
    look at how crucial cost is in determining cloud storage solutions.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，S3和EFS似乎都是很有前景的选项。现在，让我们看看成本在确定云存储解决方案中的重要性。
- en: Determining storage based on cost
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于成本确定存储
- en: 'One of the most important tools for any cloud solution architect is a cost
    estimator or pricing calculator. As we are using AWS, we will use AWS Pricing
    Calculator: [https://calculator.aws/#/](https://calculator.aws/#/).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何云解决方案架构师来说，最重要的工具之一是成本估算器或定价计算器。由于我们使用AWS，我们将使用AWS定价计算器：[https://calculator.aws/#/](https://calculator.aws/#/)。
- en: We will use this tool to compare the cost of storing input data in EFS versus
    S3 storage. In our use case, we’ll assume that we get 2 TB of data per month and
    that we must store monthly data for 3 months before we can archive it. We also
    need to store data for up to 1 year. Let’s see how our cost varies based on our
    choice of storage.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这个工具来比较在EFS和S3存储中存储输入数据的成本。在我们的用例中，我们假设每月获得2 TB的数据，并且我们必须存储每月数据3个月才能存档。我们还需要存储长达1年的数据。让我们看看我们的成本如何根据我们的存储选择而变化。
- en: Here, for either kind of storage, we will use **S3 Intelligent-Tiering** (which
    supports automatic life cycle management and reduces cost) to do the calculation.
    It asks for the average data storage per month and the amount stored in the frequent
    access layer, infrequent access layer, and archive layers.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，对于任何类型的存储，我们将使用**S3智能分层**（它支持自动生命周期管理和降低成本）来进行计算。它要求我们提供每月的平均数据存储量以及频繁访问层、不频繁访问层和存档层的存储量。
- en: 'To calculate the average data storage required per month, 2 TB of new data
    per month gets generated for our use case. So, we have 2 TB of data to store in
    the first month, 4 TB of data to store in the second, 6 TB of data to store in
    the third, and so on. So, to calculate the average data, we must add all the storage
    requirements for each month together and divide the result by 12\. The mathematical
    equation for this is as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算每月所需的数据存储平均量，在我们的用例中，每月会生成2 TB的新数据。因此，在第一个月，我们需要存储2 TB的数据，第二个月需要存储4 TB的数据，第三个月需要存储6
    TB的数据，以此类推。所以，为了计算平均数据量，我们必须将每个月的存储需求相加，然后将结果除以12。这个数学方程如下：
- en: '![](img/B17084_Formula_5.1.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17084_Formula_5.1.png)'
- en: 'The preceding formula gives us a 13 TB per month calculation. Now, it asks
    us for the percentage stored in the frequent access layer – the layer that we
    will read the data from. The data in the frequent access layer can only be 2 TB
    for each month (which is around 15% of 13 TB). Using these values, we can calculate
    the estimated cost, as shown in the following screenshot:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的公式给出了每月13 TB的计算结果。现在，它要求我们提供频繁访问层存储的百分比——即我们将从该层读取数据的层。频繁访问层中的数据每月只能有2 TB（大约是13
    TB的15%）。使用这些值，我们可以计算出估算成本，如下面的截图所示：
- en: '![Figure 5.1 – AWS S3 cost estimation tool ](img/B17084_05_001.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图5.1 – AWS S3成本估算工具](img/B17084_05_001.jpg)'
- en: Figure 5.1 – AWS S3 cost estimation tool
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 – AWS S3成本估算工具
- en: Using the previously mentioned calculation, ballpark estimates for Amazon S3
    come to 97.48 USD per month on average. However, a similar calculation for Amazon
    EFS would cost 881.92 USD. This depicts that using EFS will be nine times costlier
    than using Amazon S3\.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用之前提到的计算方法，Amazon S3的平均估算成本为每月97.48美元。然而，对Amazon EFS的类似计算将花费881.92美元。这表明使用EFS将比使用Amazon
    S3贵九倍。
- en: So, looking at the cost, combined with other parameters, we can safely decide
    on choosing Amazon S3 as our input storage. Based on a similar set of logic and
    calculations, we can store the ODL in S3 as well.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从成本和其他参数综合考虑，我们可以安全地决定选择Amazon S3作为我们的输入存储。基于类似的逻辑和计算，我们也可以将ODL存储在S3中。
- en: 'However, a discussion about the storage layer for the output data is incomplete
    without deciding on the schema and format of the output files. Based on the requirements,
    we can conclude that the output data should have the following columns:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在未决定输出文件的架构和格式的情况下，关于输出数据存储层的讨论是不完整的。根据要求，我们可以得出结论，输出数据应包含以下列：
- en: '`year`'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`year`'
- en: '`month`'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`month`'
- en: '`category_id`'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`category_id`'
- en: '`product_id`'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`product_id`'
- en: '`tot_sales`'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tot_sales`'
- en: '`tot_onlyview`'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tot_onlyview`'
- en: '`sales_rev`'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sales_rev`'
- en: '`rank_by_revenue`'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rank_by_revenue`'
- en: '`rank_by_sales`'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rank_by_sales`'
- en: It is advisable to partition the table on a yearly and monthly basis since most
    of the queries on the ODL will be monthly. Now that we have finalized all the
    details of the storage layer, let’s discuss the processing layer of the solution.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 由于ODL上的大多数查询都是按月进行的，因此建议按年度和月度对表进行分区。现在我们已经最终确定了存储层的所有细节，让我们讨论解决方案的处理层。
- en: 'Now, we must look at the options that are available in AWS for processing a
    big data batch job. Primarily, there are two native alternatives. One is running
    Spark on EMR clusters, while the other is running Glue jobs (Glue is a fully managed
    serverless AWS service). AWS Glue allows you to write a script in Scala or Python
    and trigger Glue jobs either through the AWS Management Console or programmatically.
    Since we are interested in implementing the solution in Java, AWS Glue is not
    an option for us. Also, AWS Glue scripts have less portability and a higher learning
    curve. Here, we will stick to Spark on EMR. However, Spark jobs can be run on
    an EMR cluster in two ways:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们必须考虑AWS中可用于处理大数据批处理作业的选项。主要有两个本地替代方案。一个是运行EMR集群上的Spark，另一个是运行Glue作业（Glue是一个完全管理的无服务器AWS服务）。AWS
    Glue允许你用Scala或Python编写脚本，并通过AWS管理控制台或编程方式触发Glue作业。由于我们感兴趣的是用Java实现解决方案，因此AWS Glue不是我们的选择。此外，AWS
    Glue脚本的可移植性较低，学习曲线较高。在这里，我们将坚持使用EMR上的Spark。然而，Spark作业可以在EMR集群中以两种方式运行：
- en: The classical approach of running `spark submit` from the command line
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从命令行运行`spark submit`的经典方法
- en: The cloud-specific approach of adding a `spark submit` step
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在创建集群时添加`spark submit`步骤的云特定方法
- en: Now, let’s see how the cost matrix helps us determine which approach we should
    take to submit a Spark job among the two options mentioned earlier.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看成本矩阵如何帮助我们确定在前面提到的两种选项中，我们应该采取哪种方法来提交Spark作业。
- en: The cost factor in the processing layer
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理层中的成本因素
- en: The first option is to keep the EMR cluster up and running all the time and
    trigger the `spark submit` command using a shell script from a cronjob trigger
    at specific time intervals (very similar to what we would do on an on-premise
    Hadoop cluster). Such a cluster is known as a *persistent EMR cluster*.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种选择是始终保持EMR集群运行，并使用cronjob在特定时间间隔从shell脚本中触发`spark submit`命令（这与我们在本地Hadoop集群上所做的工作非常相似）。这种集群被称为*持久EMR集群*。
- en: The second option is to add an EMR step to run the Spark job while creating
    the cluster and then terminate it once it has run successfully. This kind of EMR
    cluster is known as a *transient EMR cluster*. Let’s see how the cost estimates
    vary for each option.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种选择是在创建集群时添加EMR步骤以运行Spark作业，一旦成功运行，就终止它。这种类型的EMR集群被称为*临时EMR集群*。让我们看看每种选择的成本估计如何变化。
- en: 'In an EMR cluster, there are three types of nodes: *master node*, *core node*,
    and *task node*. The master node manages the cluster and acts as the NameNode
    and the Jobtracker. The core node acts as the DataNode, as well as the worker
    node, which is responsible for processing the data. TaskNodes are optional, but
    they are required for separate task tracker activities.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在EMR集群中，有三种类型的节点：*主节点*、*核心节点*和*任务节点*。主节点管理集群，充当NameNode和Jobtracker。核心节点充当DataNode，同时也是工作节点，负责处理数据。任务节点是可选的，但它们对于单独的任务跟踪活动是必需的。
- en: Due to their nature of work, usually, selecting a compute-optimized instance
    works great for the master node, while a mixed instance works best for the core
    nodes. In our calculation, we will use the c4.2xlarge instance type for the master
    node and the m4.4xlarge instance type for the core nodes. If we need four core
    nodes, a persistent EMR cluster would cost us around 780 USD per month. A similar
    configuration on a transient EMR cluster would only cost around 7 USD per month,
    considering the job runs two or three times a month with a job run duration not
    exceeding 2 hours each. As we can see, the second option is nearly 100 times more
    cost-effective. Therefore, we will choose a transient EMR cluster.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它们的工作性质，通常选择计算优化实例对主节点工作很好，而对于核心节点，混合实例效果最佳。在我们的计算中，我们将使用c4.2xlarge实例类型作为主节点，m4.4xlarge实例类型作为核心节点。如果我们需要四个核心节点，一个持久EMR集群将每月花费我们大约780美元。在临时EMR集群上的类似配置每月只需花费大约7美元，考虑到作业每月运行两到三次，每次作业运行时间不超过2小时。正如我们所见，第二种选择几乎提高了100倍的成本效益。因此，我们将选择临时EMR集群。
- en: Now, let’s figure out how to create and schedule the transient EMR clusters.
    In our use case, the data arrives in the S3 buckets. Each successful creation
    event in an S3 bucket generates an event that can trigger an AWS Lambda function.
    We can use such a Lambda function to create the transient cluster every time a
    new file lands in the landing zone of the S3 bucket.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们弄清楚如何创建和调度临时的EMR集群。在我们的用例中，数据到达S3桶。S3桶中的每个成功创建事件都会生成一个事件，可以触发AWS Lambda函数。我们可以使用这样的Lambda函数在S3桶的着陆区每次有新文件到达时创建临时集群。
- en: 'Based on the preceding discussion, the following diagram depicts the architecture
    of the solution that’s been proposed:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的讨论，以下图展示了所提出解决方案的架构：
- en: '![Figure 5.2 – Solution architecture ](img/B17084_05_002.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图5.2 – 解决方案架构](img/B17084_05_002.jpg)'
- en: Figure 5.2 – Solution architecture
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 – 解决方案架构
- en: 'As shown in the preceding diagram, the input data lands in the S3 bucket (also
    known as landing zone) as the source data. Here, one source data file arrives
    twice a month. The architecture diagram depicts four steps denoted by numerals.
    Let’s look at these steps in more detail:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，输入数据作为源数据进入S3桶（也称为着陆区）。在这里，一个源数据文件每月到达两次。架构图描述了四个步骤，用数字表示。让我们更详细地看看这些步骤：
- en: A CloudWatch event is generated when an incoming source file is completely written
    in the S3 bucket. This generates a Lambda trigger, which, in turn, invokes a Lambda
    function.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当传入的源文件在S3桶中完全写入时，将生成一个CloudWatch事件。这会生成一个Lambda触发器，反过来，它会调用一个Lambda函数。
- en: The Lambda function receives the creation event records and creates a transient
    EMR cluster with a step configured to run a Spark job to read and process the
    new input file(s).
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Lambda函数接收创建事件记录并创建一个临时EMR集群，其中配置了一个步骤来运行Spark作业以读取和处理新的输入文件。
- en: The Spark job in the EMR step reads and processes the data. Then, it writes
    the transformed output data to the S3 bucket for the ODL layer. Upon successfully
    terminating the Spark step, the transient cluster gets terminated.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: EMR步骤中的Spark作业读取并处理数据。然后，它将转换后的输出数据写入ODL层的S3桶。在Spark步骤成功终止后，临时集群将被终止。
- en: All the data residing in the ODL layer will be exposed as Athena tables that
    can be queried for any analytical purposes.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ODL层中驻留的所有数据都将作为Athena表公开，可以用于任何分析目的。
- en: This gives us a very simple yet powerful architecture to solve such big data
    batch processing problems. The logs and metrics in all the processing and storage
    components will be captured by AWS CloudWatch logs. We can further improve this
    architecture by adding auditing and alert features using CloudWatch logs and metrics.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了一个非常简单但强大的架构来解决这样的大数据批处理问题。所有处理和存储组件中的日志和指标都将由AWS CloudWatch日志捕获。我们可以通过添加审计和警报功能来进一步改进此架构，这些功能使用CloudWatch日志和指标。
- en: Important note
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 重要注意事项
- en: 'It is advisable to use the Parquet format as the output storage format because
    of the following factors:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 由于以下因素，建议使用Parquet格式作为输出存储格式：
- en: '**Cost saving and performance**: Since multiple output columns can potentially
    have low cardinality, the ODL data storage format should be a columnar format,
    which can give cost savings as well as better performance.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**成本节省和性能**：由于多个输出列可能具有低基数，ODL数据存储格式应该是一个列式格式，这不仅可以节省成本，还可以提高性能。'
- en: '**Technology compatibility**: Since we are dealing with big data processing,
    and our processing layer is Spark-based, Parquet will be the most suitable data
    format to use for the ODL layer.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**技术兼容性**：由于我们处理的是大数据处理，并且我们的处理层基于 Spark，Parquet 将是 ODL 层使用最合适的数据格式。'
- en: Now that we have analyzed the problem and developed a robust, reliable, and
    cost-effective architecture, let’s implement the solution.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经分析了问题并开发了一个稳健、可靠且成本效益高的架构，让我们来实施解决方案。
- en: Implementing the solution
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施解决方案
- en: The first step of any implementation is always understanding the source data.
    This is because all our low-level transformation and cleansing will be dependent
    on the variety of the data. In the previous chapter, we used DataCleaner to profile
    the data. However, this time, we are dealing with big data and the cloud. DataCleaner
    may not be a very effective tool for profiling the data if its size runs into
    the terabytes. For our scenario, we will use an AWS cloud-based data profiling
    tool called AWS Glue DataBrew.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 任何实施的第一步始终是理解源数据。这是因为我们所有低级转换和清洗都将依赖于数据的多样性。在前一章中，我们使用了 DataCleaner 来概览数据。然而，这次我们处理的是大数据和云。如果数据量达到千兆字节，DataCleaner
    可能不是进行数据概览的一个非常有效的工具。对于我们的场景，我们将使用一个名为 AWS Glue DataBrew 的基于 AWS 云的数据概览工具。
- en: Profiling the source data
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 源数据概览
- en: 'In this section, we will learn how to do data profiling and analysis to understand
    the incoming data (you can find the sample file for this on GitHub at [https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05](https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05).
    Follow these steps:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何进行数据概览和分析，以了解传入的数据（您可以在 GitHub 上找到此示例文件：[https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05](https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05)。按照以下步骤操作：
- en: 'Create an S3 bucket called `scalabledataarch` using the AWS Management Console
    and upload the sample input data to the S3 bucket:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 AWS 管理控制台创建一个名为 `scalabledataarch` 的 S3 存储桶，并将示例输入数据上传到 S3 存储桶：
- en: '![Figure 5.3 – Creating an S3 bucket and uploading the input file ](img/B17084_05_003.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.3 – 创建 S3 存储桶并上传输入文件](img/B17084_05_003.jpg)'
- en: Figure 5.3 – Creating an S3 bucket and uploading the input file
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3 – 创建 S3 存储桶并上传输入文件
- en: 'From the AWS Management Console, go to the AWS Glue DataBrew service. Click
    on the **DATASET** side tab. Then, click the **Connect new dataset** button. A
    dialog box similar to the one shown in the following screenshot will appear. Select
    **Amazon S3** and then enter the source data path of the S3 bucket. Finally, click
    the **Create Dataset** button to create a new dataset:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 AWS 管理控制台进入 AWS Glue DataBrew 服务。点击 **DATASET** 侧边栏。然后，点击 **连接新数据集** 按钮。将出现一个类似于以下截图的对话框。选择
    **Amazon S3** 并输入 S3 存储桶的源数据路径。最后，点击 **创建数据集** 按钮以创建新的数据集：
- en: '![Figure 5.4 – Adding a new dataset to AWS Glue DataBrew ](img/B17084_05_004.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.4 – 向 AWS Glue DataBrew 添加新数据集](img/B17084_05_004.jpg)'
- en: Figure 5.4 – Adding a new dataset to AWS Glue DataBrew
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4 – 向 AWS Glue DataBrew 添加新数据集
- en: 'Now, let’s create a data profiling job using the dataset that we’ve added.
    First, select the newly added dataset and go to the **Data profile overview**
    tab, as shown in the following screenshot:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用我们添加的数据集创建一个数据概览作业。首先，选择新添加的数据集并转到 **数据概览** 选项卡，如图所示：
- en: '![Figure 5.5 – The Data profile overview tab ](img/B17084_05_005.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.5 – 数据概览选项卡](img/B17084_05_005.jpg)'
- en: Figure 5.5 – The Data profile overview tab
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5 – 数据概览选项卡
- en: 'Now, click on the **Run data profile** button, which will take you to a **Create
    job** popup. Enter the job name and choose to run the sample using the **Full
    dataset** option, as shown here:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，点击 **运行数据概览** 按钮，这将带您到一个 **创建作业** 弹出窗口。输入作业名称并选择使用 **全数据集** 选项运行样本，如图所示：
- en: '![Figure 5.6 – Creating a data profiling job ](img/B17084_05_006.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.6 – 创建数据概览作业](img/B17084_05_006.jpg)'
- en: Figure 5.6 – Creating a data profiling job
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6 – 创建数据概览作业
- en: 'Set the output location as `scalablearch-dataprof` (our S3 bucket). The output
    files of the data profiling job will be stored here:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 将输出位置设置为 `scalablearch-dataprof`（我们的 S3 存储桶）。数据概览作业的输出文件将存储在此：
- en: '![Figure 5.7 – Configuring the data profiling job ](img/B17084_05_007.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.7 – 配置数据概览作业](img/B17084_05_007.jpg)'
- en: Figure 5.7 – Configuring the data profiling job
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7 – 配置数据概览作业
- en: Then, configure `product_id`, `category_id`, and `brand`,
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，配置 `product_id`、`category_id` 和 `brand`，
- en: 'we have configured them accordingly, as shown in the following screenshot:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已相应地配置了它们，如下面的屏幕截图所示：
- en: '![Figure 5.8 – Configuring the Correlations widget ](img/B17084_05_008.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.8 – 配置关联小部件](img/B17084_05_008.jpg)'
- en: Figure 5.8 – Configuring the Correlations widget
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8 – 配置关联小部件
- en: 'Then, we must set up the security roles for the data profiling job. Once you’ve
    done this, click the **Create Job** button to create the data profiling job:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须设置数据概要作业的安全角色。一旦完成此操作，点击 **创建作业** 按钮来创建数据概要作业：
- en: '![Figure 5.9 – Setting the security permissions for the data profiling job
    ](img/B17084_05_009.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.9 – 设置数据概要作业的安全权限](img/B17084_05_009.jpg)'
- en: Figure 5.9 – Setting the security permissions for the data profiling job
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9 – 设置数据概要作业的安全权限
- en: 'Finally, we can see the newly created data profiling job in the **Profile jobs**
    tab. We can run the data profiling job by clicking the **Run job** button on this
    screen:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以在 **概要作业** 选项卡中看到新创建的数据概要作业。我们可以通过在此屏幕上点击 **运行作业** 按钮来运行数据概要作业：
- en: '![Figure 5.10 – Data profiling job created and listed ](img/B17084_05_010.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.10 – 已创建并列出的数据概要作业](img/B17084_05_010.jpg)'
- en: Figure 5.10 – Data profiling job created and listed
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 – 已创建并列出的数据概要作业
- en: 'Once the job successfully runs, we can go to the dataset, open the **Data lineage**
    tab, and view the data lineage, as well as the time interval before which the
    last successful data profiling job ran:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦作业成功运行，我们可以转到数据集，打开 **数据谱系** 选项卡，查看数据谱系以及最后一次成功的数据概要作业运行之前的时间间隔：
- en: '![Figure 5.11 – Lineage of the data profiling job ](img/B17084_05_011.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.11 – 数据概要作业的谱系](img/B17084_05_011.jpg)'
- en: Figure 5.11 – Lineage of the data profiling job
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11 – 数据概要作业的谱系
- en: 'We can visualize the report to find missing values, cardinalities, the correlation
    between columns, and the distribution of the data. These metrics help us determine
    whether there are anomalies in the data that need to be cleaned up or if there
    are missing values and if they need to be handled. It also helps us understand
    the quality of the data that we are dealing with. This helps us do proper cleansing
    and transformation so that it doesn’t give us surprises later during our implementation.
    The following screenshot shows some sample metrics that AWS Glue DataBrew displays:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以将报告可视化以查找缺失值、基数、列之间的相关性以及数据的分布。这些度量帮助我们确定数据中是否存在需要清理的异常值，或者是否存在缺失值以及是否需要处理。这也有助于我们了解我们正在处理的数据质量。这有助于我们进行适当的清理和转换，以免在实施过程中出现意外。以下屏幕截图显示了
    AWS Glue DataBrew 显示的一些示例度量：
- en: '![Figure 5.12 – Data profile metrics ](img/B17084_05_012.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.12 – 数据概要度量](img/B17084_05_012.jpg)'
- en: Figure 5.12 – Data profile metrics
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 – 数据概要度量
- en: Here, we can see some useful statistics. For example, `event_type` has no noise
    and it has a very low cardinality. It also shows that the data is not uniformly
    distributed by this column.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到一些有用的统计数据。例如，`event_type` 没有噪声，并且具有非常低的基数。它还显示数据不是通过此列均匀分布的。
- en: Now that we have analyzed the data, let’s develop the Spark application that
    will process the records.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经分析了数据，让我们开发一个 Spark 应用程序来处理记录。
- en: Writing the Spark application
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写 Spark 应用程序
- en: 'Based on the analysis in the previous section, we will create the incoming
    record schema string. Then, we will use that schema string to read the incoming
    data, as shown in the following code snippet:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 基于上一节的分析，我们将创建输入记录模式字符串。然后，我们将使用该模式字符串来读取输入数据，如下面的代码片段所示：
- en: '[PRE0]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, we will calculate the total sales and total views for each product using
    the `count_if` aggregation function of Spark, as shown in the following code snippet:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用 Spark 的 `count_if` 聚合函数计算每个产品的总销售额和总浏览量，如下面的代码片段所示：
- en: '[PRE1]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will create another DataFrame to calculate the total revenue for only the
    purchase events. The following code snippet shows how to do this:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建另一个 DataFrame 来计算仅购买事件的收入总额。以下代码片段显示了如何进行此操作：
- en: '[PRE2]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, we will combine the `countAggDf` and `revenueAggDf` DataFrames using a
    `LEFT OUTER JOIN` SparkSQL query, as shown in the following code snippet. The
    null values for `total_sales` for the product that didn’t have a single sale are
    set to `0.0` using the `na.fill()` method of Spark:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用 `LEFT OUTER JOIN` SparkSQL 查询将 `countAggDf` 和 `revenueAggDf` DataFrame
    合并，如下面的代码片段所示。对于没有单次销售的产品，使用 Spark 的 `na.fill()` 方法将 `total_sales` 的空值设置为 `0.0`：
- en: '[PRE3]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, we will apply window functions on the resultant `combinedEnrichedDf` DataFrame
    to derive the columns – that is, `rank_by_revenue` and `rank_by_sales`:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将对结果`combinedEnrichedDf` DataFrame应用窗口函数，以推导出列 – 即`rank_by_revenue`和`rank_by_sales`：
- en: '[PRE4]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The result is ready and is in the same format as the output. So, we must write
    the transformed data to the output S3 bucket using Parquet format while ensuring
    it’s partitioned by year and month:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 结果已准备好，并且与输出格式相同。因此，我们必须使用Parquet格式将转换后的数据写入输出S3桶，同时确保它按年份和月份分区：
- en: '[PRE5]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The full source code for this application is available on GitHub at [https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05/sourcecode/EcommerceAnalysis](https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05/sourcecode/EcommerceAnalysis).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 此应用程序的完整源代码可在GitHub上找到，网址为[https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05/sourcecode/EcommerceAnalysis](https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05/sourcecode/EcommerceAnalysis)。
- en: In the next section, we will learn how to deploy and run the Spark application
    on an EMR cluster.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将学习如何在EMR集群上部署和运行Spark应用程序。
- en: Deploying and running the Spark application
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署和运行Spark应用程序
- en: 'Now that we have developed the Spark job, let’s try to run it using a transient
    EMR cluster. First, we will create an EMR cluster manually and run the job. To
    create the transient EMR cluster manually, follow these steps:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经开发了Spark作业，让我们尝试使用临时EMR集群运行它。首先，我们将手动创建EMR集群并运行作业。要手动创建临时EMR集群，请按照以下步骤操作：
- en: First, build the Spark application JAR file and upload it to an S3 bucket.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，构建Spark应用程序JAR文件并将其上传到S3桶。
- en: Go to the AWS Management Console for AWS EMR. Click the **Create Cluster** button
    to create a new transient cluster manually.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往AWS管理控制台中的AWS EMR。点击**创建集群**按钮以手动创建新的临时集群。
- en: 'Set up the EMR configuration. Make sure that you set **Launch mode** to **Step
    execution**. Make sure that you select **emr-6.4.0** as the value of the **Release**
    field in the **Software configuration** section. Also, for **Add Steps**, choose
    **Spark application** for **Step type**. Leave all the other fields as-is. Your
    configuration should look as follows:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置EMR配置。确保将**启动模式**设置为**步骤执行**。确保在**软件配置**部分的**版本**字段中选择**emr-6.4.0**。此外，对于**添加步骤**，选择**Spark应用程序**作为**步骤类型**。保留所有其他字段不变。您的配置应如下所示：
- en: '![Figure 5.13 – Manual transient EMR cluster creation ](img/B17084_05_013.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图5.13 – 手动创建临时EMR集群](img/B17084_05_013.jpg)'
- en: Figure 5.13 – Manual transient EMR cluster creation
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.13 – 手动创建临时EMR集群
- en: 'Now, to add the Spark step, click on the **Configure** button. This will make
    a dialog box appear where you can enter various Spark step-related configurations,
    as shown in the following screenshot:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，要添加Spark步骤，请点击**配置**按钮。这将弹出一个对话框，您可以在其中输入各种与Spark步骤相关的配置，如下面的屏幕截图所示：
- en: '![Figure 5.14 – Adding a Spark step to the EMR cluster ](img/B17084_05_014.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图5.14 – 向EMR集群添加Spark步骤](img/B17084_05_014.jpg)'
- en: Figure 5.14 – Adding a Spark step to the EMR cluster
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.14 – 向EMR集群添加Spark步骤
- en: Please ensure that you specify the driver class name in the **Spark-submit options**
    area and provide the necessary information in the **Application location*** and
    **Arguments** boxes.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保在**Spark-submit选项区域**中指定驱动类名称，并在**应用程序位置**和**参数**框中提供必要的信息。
- en: 'Click **Add** to add the step. Once added, it will look similar to what’s shown
    in the following screenshot. Then, click **Create Cluster**. This will create
    the transient cluster, run the Spark job, and terminate the cluster once the Spark
    job has finished executing:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**添加**以添加步骤。一旦添加，它将类似于以下屏幕截图所示。然后，点击**创建集群**。这将创建临时集群，运行Spark作业，并在Spark作业执行完毕后终止集群：
- en: '![Figure 5.15 – EMR cluster configuration with an added Spark step ](img/B17084_05_015.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图5.15 – 添加Spark步骤的EMR集群配置](img/B17084_05_015.jpg)'
- en: Figure 5.15 – EMR cluster configuration with an added Spark step
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.15 – 添加Spark步骤的EMR集群配置
- en: 'Once it has successfully run, you will see that the job succeeded in the **Steps**
    tab of the cluster:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦成功运行，您将在集群的**步骤**标签页中看到作业已成功：
- en: '![Figure 5.16 – Job monitoring in the EMR cluster ](img/B17084_05_016.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图5.16 – EMR集群中的作业监控](img/B17084_05_016.jpg)'
- en: Figure 5.16 – Job monitoring in the EMR cluster
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.16 – EMR集群中的作业监控
- en: Troubleshooting Spark errors
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 故障排除Spark错误
- en: A Spark job runs on huge volumes of data and can throw multiple exceptions.
    It can also report multiple stage failures, such as `OutOfMemoryException`, large
    frame errors, throttling errors from multipart files uploaded in AWS S3, and so
    on. Covering all of these is beyond the scope of this book. However, you can refer
    to a very concise Spark troubleshooting guide at [https://docs.qubole.com/en/latest/troubleshooting-guide/spark-ts/troubleshoot-spark.xhtml#troubleshooting-spark-issues](https://docs.qubole.com/en/latest/troubleshooting-guide/spark-ts/troubleshoot-spark.xhtml#troubleshooting-spark-issues)
    for more information.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 作业在大量数据上运行并可能抛出多个异常。它还可以报告多个阶段失败，例如 `OutOfMemoryException`、大帧错误、来自 AWS
    S3 上传的多部分文件的节流错误等等。涵盖所有这些内容超出了本书的范围。然而，您可以参考一个非常简洁的 Spark 故障排除指南 [https://docs.qubole.com/en/latest/troubleshooting-guide/spark-ts/troubleshoot-spark.xhtml#troubleshooting-spark-issues](https://docs.qubole.com/en/latest/troubleshooting-guide/spark-ts/troubleshoot-spark.xhtml#troubleshooting-spark-issues)
    以获取更多信息。
- en: Now that we have deployed and run the Spark application manually, let’s automate
    how Spark jobs are created and run by implementing a Lambda trigger.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经手动部署和运行了 Spark 应用程序，让我们通过实现 Lambda 触发器来自动化 Spark 作业的创建和运行。
- en: Developing and testing a Lambda trigger
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开发和测试 Lambda 触发器
- en: AWS Lambda functions are fully managed serverless services that help process
    information. They are supported by multiple languages such as Python, JavaScript,
    Java, and so on. Although Python or JavaScript runtimes are faster, we will use
    the Java runtime in this book to implement the solution (since we are focusing
    on Java-based implementations in this book).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Lambda 函数是完全托管的无服务器服务，有助于处理信息。它们支持多种语言，如 Python、JavaScript、Java 等。尽管 Python
    或 JavaScript 运行时更快，但我们将在这本书中使用 Java 运行时来实现解决方案（因为我们在这本书中专注于基于 Java 的实现）。
- en: 'To write a Lambda function that will react to an S3 event, we must create a
    Java class that implements the `RequestHandler` interface and takes `S3Event`
    as its generic `Input` type, as shown in the following code block:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 要编写一个对 S3 事件做出反应的 Lambda 函数，我们必须创建一个实现 `RequestHandler` 接口并接受 `S3Event` 作为其泛型
    `Input` 类型的 Java 类，如下代码块所示：
- en: '[PRE6]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In this class, we must implement the `handleRequest` method of the `RequestHandler`
    interface. In the `handleRequest` method, we loop through each `S3EventNotificationRecord`,
    which denotes a new file being created or updated. We collect all the S3 object
    names attached to this `S3EventNotificationRecord` in `S3ObjectNames`. For each
    distinct S3 object name present in `S3ObjectNames`, we create and launch an AWS
    transient EMR cluster. The following code snippet shows the implementation of
    the `handleRequest` method:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个类中，我们必须实现 `RequestHandler` 接口的 `handleRequest` 方法。在 `handleRequest` 方法中，我们遍历每个
    `S3EventNotificationRecord`，它表示一个新文件的创建或更新。我们在 `S3ObjectNames` 中收集附加到该 `S3EventNotificationRecord`
    的所有 S3 对象名称。对于 `S3ObjectNames` 中存在的每个不同的 S3 对象名称，我们创建并启动一个 AWS 短暂 EMR 集群。以下代码片段显示了
    `handleRequest` 方法的实现：
- en: '[PRE7]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, let’s look at the implementation of the `createClusterAndRunJob` method.
    This takes two arguments: `inputS3path` and the Lambda logger. This method uses
    AWS SDK to create an `ElasticMapReduce` object. This method uses the `StepConfig` API
    to build a `spark submit` step. Then, it uses all the configuration details, along
    with `SparkSubmitStep`, to configure the `RunJobFlowRequest` object.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看 `createClusterAndRunJob` 方法的实现。该方法接受两个参数：`inputS3path` 和 Lambda 记录器。此方法使用
    AWS SDK 创建一个 `ElasticMapReduce` 对象。此方法使用 `StepConfig` API 构建一个 `spark submit`
    阶段。然后，它使用所有配置细节以及 `SparkSubmitStep` 来配置 `RunJobFlowRequest` 对象。
- en: 'Finally, we can submit a request to create and run an EMR cluster using the
    `runJobFlow` method of the `ElasticMapReduce` object, as shown here:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以通过 `ElasticMapReduce` 对象的 `runJobFlow` 方法提交请求以创建和运行 EMR 集群，如下所示：
- en: '[PRE8]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now that we developed the Lambda function, let’s deploy, run, and test it:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经开发了 Lambda 函数，让我们来部署、运行和测试它：
- en: 'Create an IAM security role for the Lambda function to trigger the EMR cluster,
    as shown in the following screenshot:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为 Lambda 函数创建一个 IAM 安全角色以触发 EMR 集群，如下截图所示：
- en: '![Figure 5.17 – Creating a new IAM role ](img/B17084_05_017.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.17 – 创建新的 IAM 角色](img/B17084_05_017.jpg)'
- en: Figure 5.17 – Creating a new IAM role
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.17 – 创建新的 IAM 角色
- en: 'Create a Lambda function using the AWS Management Console. Please provide the
    name and runtime of the function, as shown in the following screenshot:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 AWS 管理控制台创建一个 Lambda 函数。请提供函数的名称和运行时，如下截图所示：
- en: '![Figure 5.18 – Creating an AWS Lambda function ](img/B17084_05_018.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.18 – 创建 AWS Lambda 函数](img/B17084_05_018.jpg)'
- en: Figure 5.18 – Creating an AWS Lambda function
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.18 – 创建 AWS Lambda 函数
- en: 'While creating the Lambda function, please make sure that you change the default
    execution role to the IAM role you created in *Step 1*:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在创建 Lambda 函数时，请确保您将默认执行角色更改为在*步骤 1*中创建的 IAM 角色：
- en: '![Figure 5.19 – Setting the IAM role to an AWS Lambda function ](img/B17084_05_019.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.19 – 将 IAM 角色设置到 AWS Lambda 函数](img/B17084_05_019.jpg)'
- en: Figure 5.19 – Setting the IAM role to an AWS Lambda function
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.19 – 将 IAM 角色设置到 AWS Lambda 函数
- en: 'Now, you must add an S3 trigger for the Lambda function, as shown in the following
    screenshot. Make sure that you enter the proper bucket name and prefix where you
    will push your source files:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您必须为 Lambda 函数添加一个 S3 触发器，如下面的截图所示。请确保您输入了正确的存储桶名称和前缀，您将在此处推送源文件：
- en: '![Figure 5.20 – Creating an S3 event trigger for the Lambda function ](img/B17084_05_020.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.20 – 为 Lambda 函数创建 S3 事件触发器](img/B17084_05_020.jpg)'
- en: Figure 5.20 – Creating an S3 event trigger for the Lambda function
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.20 – 为 Lambda 函数创建 S3 事件触发器
- en: 'Then, you must build the JAR file locally from the Lambda function we developed
    using our Maven Java project (the full source code for the project can be found
    at [https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05/sourcecode/S3lambdaTriggerEmr](https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05/sourcecode/S3lambdaTriggerEmr)).
    Once the JAR file has been built, you must upload it using the **Upload from**
    | **.zip or .jar file** option, as shown in the following screenshot:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，您必须使用我们的 Maven Java 项目（项目的完整源代码可以在[https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05/sourcecode/S3lambdaTriggerEmr](https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter05/sourcecode/S3lambdaTriggerEmr)找到）开发的
    Lambda 函数来本地构建 JAR 文件。一旦构建了 JAR 文件，您必须使用**从** | **.zip 或 .jar 文件**选项上传它，如下面的截图所示：
- en: '![Figure 5.21 – Deploying an AWS Lambda JAR file ](img/B17084_05_021.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.21 – 部署 AWS Lambda JAR 文件](img/B17084_05_021.jpg)'
- en: Figure 5.21 – Deploying an AWS Lambda JAR file
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.21 – 部署 AWS Lambda JAR 文件
- en: 'Now, you can test the whole workflow by placing a new data file in the S3 bucket
    mentioned in the S3 trigger. Once the Lambda function executes, it creates a transient
    EMR cluster where the Spark job will run. You can monitor the metrics of the Lambda
    function from the AWS Management Console:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您可以通过将新的数据文件放置在 S3 触发器中提到的 S3 存储桶中来测试整个工作流程。一旦 Lambda 函数执行，它将创建一个临时的 EMR
    集群，其中 Spark 作业将在其中运行。您可以从 AWS 管理控制台监控 Lambda 函数的指标：
- en: '![Figure 5.22 – Monitoring the AWS Lambda function ](img/B17084_05_022.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.22 – 监控 AWS Lambda 函数](img/B17084_05_022.jpg)'
- en: Figure 5.22 – Monitoring the AWS Lambda function
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.22 – 监控 AWS Lambda 函数
- en: 'You can monitor the Spark application from the AWS EMR management console by
    looking through the **Persistent user interfaces** options in the transient cluster’s
    **Summary** tab, as shown in the following screenshot:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过查看临时集群的**摘要**选项卡中的**持久用户界面**选项来从 AWS EMR 管理控制台监控 Spark 应用程序，如下面的截图所示：
- en: '![Figure 5.23 – EMR Cluster management console ](img/B17084_05_023.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.23 – EMR 集群管理控制台](img/B17084_05_023.jpg)'
- en: Figure 5.23 – EMR Cluster management console
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.23 – EMR 集群管理控制台
- en: Troubleshooting a Lambda function
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 函数故障排除
- en: In the real world, you may have trouble when invoking or executing a Lambda
    function. A very concise guide to troubleshoot all such issues has been published
    by AWS. For more information, check out [https://docs.aws.amazon.com/lambda/latest/dg/lambda-troubleshooting.xhtml](https://docs.aws.amazon.com/lambda/latest/dg/lambda-troubleshooting.xhtml).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，在调用或执行 Lambda 函数时可能会遇到麻烦。AWS 已发布了一份非常简洁的故障排除指南来解决所有这些问题。有关更多信息，请参阅[https://docs.aws.amazon.com/lambda/latest/dg/lambda-troubleshooting.xhtml](https://docs.aws.amazon.com/lambda/latest/dg/lambda-troubleshooting.xhtml)。
- en: Now, let’s see if we can further optimize the Spark application by monitoring
    the Spark job.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看我们是否可以通过监控 Spark 作业来进一步优化 Spark 应用程序。
- en: Performance tuning a Spark job
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调优 Spark 作业
- en: 'We can investigate the Spark UI to see its **directed acyclic graph** (**DAG**).
    In our case, our DAG looks like this:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以检查 Spark UI 来查看其**有向无环图**（**DAG**）。在我们的案例中，我们的 DAG 看起来是这样的：
- en: '![Figure 5.24 – DAG of the Spark job ](img/B17084_05_024.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.24 – Spark 作业的 DAG](img/B17084_05_024.jpg)'
- en: Figure 5.24 – DAG of the Spark job
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.24 – Spark 作业的 DAG
- en: 'As we can see, both *Stage 5* and *Stage 6* are performing the same job of
    scanning and reading the CSV into a DataFrame. This is because we have a DataFrame
    called `ecommerceEventDf` that is being used to derive two different DataFrames.
    Both derived DataFrames calculate `ecommerceEventDf` separately due to Spark’s
    lazy evaluation technique, which causes the performance to slow down. We can overcome
    this issue by persisting the `ecommerceEventDf` DataFrame, as shown in the following
    code snippet:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，**阶段 5** 和 **阶段 6** 都在进行相同的工作，即扫描和读取 CSV 文件到 DataFrame 中。这是因为我们有一个名为 `ecommerceEventDf`
    的 DataFrame，它被用来派生出两个不同的 DataFrame。由于 Spark 的懒加载技术，这两个派生 DataFrame 分别计算 `ecommerceEventDf`，这导致性能变慢。我们可以通过持久化
    `ecommerceEventDf` DataFrame 来解决这个问题，如下面的代码片段所示：
- en: '[PRE9]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After making this change, the new DAG will look as follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行此更改后，新的 DAG 将如下所示：
- en: '![Figure 5.25 – Optimized DAG of the Spark job ](img/B17084_05_025.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.25 – Spark 作业的优化 DAG](img/B17084_05_025.jpg)'
- en: Figure 5.25 – Optimized DAG of the Spark job
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.25 – Spark 作业的优化 DAG
- en: In the new DAG, there’s a green dot in the `InMemoryTableScan` task. This green
    dot represents the in-memory persistence of the data by Spark so that it doesn’t
    scan the CSV file twice, thus saving processing time. In this use case, it will
    speed up the performance of the Spark job by around 20%.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在新的 DAG 中，`InMemoryTableScan` 任务中有一个绿色圆点。这个绿色圆点代表 Spark 通过内存持久化数据，这样它就不会两次扫描
    CSV 文件，从而节省处理时间。在这个用例中，它将提高 Spark 作业的性能大约 20%。
- en: Now that we have implemented and tested our solution, let’s learn how to build
    an Athena table on top of the output folder and enable easy querying of the results.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经实施并测试了我们的解决方案，让我们学习如何在输出文件夹上构建 Athena 表并启用结果的简单查询。
- en: Querying the ODL using AWS Athena
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 AWS Athena 查询 ODL
- en: 'In this section, we will learn how to perform data querying on the ODL that
    we have created using our architecture. We will focus on how to set up Athena
    on our output folder to do easy data discovery and querying:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何使用我们的架构在创建的 ODL 上执行数据查询。我们将重点介绍如何在输出文件夹上设置 Athena 以进行简单的数据发现和查询：
- en: 'Navigate to AWS Athena via the AWS Management Console. Click on **Explore the
    query editor**. First, go to the **Manage settings** form of the **Query editor**
    area and set up an S3 bucket where the query results can be stored. You can create
    an empty bucket for this purpose:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 AWS 管理控制台导航到 AWS Athena。点击 **探索查询编辑器**。首先，转到 **查询编辑器** 区域的 **管理设置** 表单，并设置一个可以存储查询结果的
    S3 桶。您可以为这个目的创建一个空桶：
- en: '![Figure 5.26 – Setting up AWS Athena ](img/B17084_05_026.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.26 – 设置 AWS Athena](img/B17084_05_026.jpg)'
- en: Figure 5.26 – Setting up AWS Athena
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.26 – 设置 AWS Athena
- en: 'We will create an Athena table on top of our S3 output bucket. For this, we
    will create a DDL to create a table called `ecom_odl`, which is a partitioned
    table on the `year` and `month` columns. The DDL of the table can be seen in the
    following code snippet:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在我们的 S3 输出桶上创建一个 Athena 表。为此，我们将创建一个 DDL 来创建一个名为 `ecom_odl` 的表，这是一个基于 `year`
    和 `month` 列的分区表。该表的 DDL 可以在下面的代码片段中看到：
- en: '[PRE10]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We will run this DDL statement in the **Query editor** area of Athena to create
    the table shown in the following screenshot:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 Athena 的 **查询编辑器** 区域的 **查询编辑器** 区域运行此 DDL 语句来创建以下屏幕截图所示的表：
- en: '![Figure 5.27 – Creating an Athena table based on the output data ](img/B17084_05_027.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.27 – 基于输出数据创建 Athena 表](img/B17084_05_027.jpg)'
- en: Figure 5.27 – Creating an Athena table based on the output data
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.27 – 基于输出数据创建 Athena 表
- en: 'Once the table has been created, we need to add the partition. We can do this
    by using the `MSCK REPAIR` command (similar to Hive):'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦表创建完成，我们需要添加分区。我们可以通过使用 `MSCK REPAIR` 命令（类似于 Hive）来完成此操作：
- en: '[PRE11]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Upon running the previous command, all partitions are auto-discovered from
    the S3 bucket. Now, you can run any query on the `ecom_odl` table and get the
    result. As shown in the following screenshot, we run a sample query to find the
    top three products by revenue for each category in October 2019:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行前面的命令后，所有分区都将自动从 S3 桶中检测到。现在，您可以在 `ecom_odl` 表上运行任何查询并获取结果。如下面的屏幕截图所示，我们运行了一个示例查询，以找到
    2019 年 10 月每个类别的收入最高的前三个产品：
- en: '![Figure 5.28 – Querying ODL using an Athena table ](img/B17084_05_028.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.28 – 使用 Athena 表查询 ODL](img/B17084_05_028.jpg)'
- en: Figure 5.28 – Querying ODL using an Athena table
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.28 – 使用 Athena 表查询 ODL
- en: With that, we have successfully architected, designed, and developed a big data
    batch processing solution and created an interface for the downstream teams to
    query our analyzed data using AWS Athena. Now, let’s summarize what we have learned
    in this chapter.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，我们已经成功架构、设计和开发了一个大数据批处理解决方案，并为下游团队创建了一个使用 AWS Athena 查询我们分析数据的接口。现在，让我们总结一下本章所学的内容。
- en: Summary
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned how to analyze a problem and identified that it
    was a big data problem. We also learned how to choose a platform and technology
    that will be performance-savvy, optimized, and cost-effective. We learned how
    to use all these factors judiciously to develop a big data batch processing solution
    in the cloud. Then, we learned how to analyze, profile, and draw inferences from
    big data files using AWS Glue DataBrew. After that, we learned how to develop,
    deploy, and run a Spark Java application in the AWS cloud to process a huge volume
    of data and store it in an ODL. We also discussed how to write an AWS Lambda trigger
    function in Java to automate the Spark jobs. Finally, we learned how to expose
    the processed ODL data through an AWS Athena table so that downstream systems
    can easily query and use the ODL data.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何分析问题，并确定这是一个大数据问题。我们还学习了如何选择一个性能高效、优化且成本效益高的平台和技术。我们学习了如何明智地使用所有这些因素来在云中开发大数据批处理解决方案。然后，我们学习了如何使用
    AWS Glue DataBrew 分析、分析并从大数据文件中得出推论。之后，我们学习了如何在 AWS 云中开发、部署和运行一个 Spark Java 应用程序来处理大量数据并将其存储在
    ODL 中。我们还讨论了如何用 Java 编写 AWS Lambda 触发函数来自动化 Spark 作业。最后，我们学习了如何通过 AWS Athena 表暴露处理后的
    ODL 数据，以便下游系统可以轻松查询和使用 ODL 数据。
- en: Now that we have learned how to develop optimized and cost-effective batch-based
    data processing solutions for different kinds of data volumes and needs, in the
    next chapter, we will learn how to effectively build solutions that help us process
    and store data in real time.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学会了如何为不同类型的数据量和需求开发优化且成本效益高的基于批处理的数据处理解决方案，在下一章中，我们将学习如何有效地构建帮助我们实时处理和存储数据的解决方案。
