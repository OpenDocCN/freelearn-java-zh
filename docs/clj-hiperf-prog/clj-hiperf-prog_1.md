# 第一章. 设计性能

Clojure 是一种安全、函数式编程语言，为用户带来了巨大的力量和简洁性。Clojure 也是动态和强类型化的，并且具有非常好的性能特性。自然地，计算机上进行的每一项活动都有相关的成本。构成可接受性能的标准因用例和工作负载而异。在当今世界，性能甚至成为多种类型应用程序的决定性因素。我们将从性能的角度讨论 Clojure（在**JVM**（**Java 虚拟机**）上运行），以及其运行环境，这正是本书的目标。

Clojure 应用程序的性能取决于各种因素。对于一个特定的应用程序，理解其用例、设计实现、算法、资源需求和与硬件的匹配，以及底层软件能力是至关重要的。在本章中，我们将研究性能分析的基础，包括以下内容：

+   根据用例类型对性能预期进行分类

+   概述分析性能的结构化方法

+   术语表，通常用于讨论性能方面

+   每个程序员都应该知道的性能数字

# 用例分类

不同类型的用例的性能要求和优先级各不相同。我们需要确定各种用例可接受的性能标准。因此，我们将它们分类以识别其性能模型。在细节上，对于任何类型的用例，都没有一成不变的性能秘方，但研究它们的普遍性质肯定有帮助。请注意，在现实生活中，本节中列出的用例可能相互重叠。

## 面向用户的软件

面向用户的软件性能与用户的预期紧密相关。相差数十毫秒可能对用户来说并不明显，但与此同时，等待几秒钟以上可能不会受到欢迎。在正常化预期中的一个重要元素是通过提供基于持续时间的反馈来吸引用户。处理此类场景的一个好主意是在后台异步启动任务，并从 UI 层轮询它以生成基于持续时间的用户反馈。另一种方法是对用户逐步渲染结果，以平衡预期。

预期并不是用户界面性能的唯一因素。常见的技巧，如数据分阶段或预计算，以及其他一般优化技术，可以在很大程度上提高用户体验的性能。请记住，所有类型的用户界面都落入此类用例类别——网页、移动网页、GUI、命令行、触摸、语音操作、手势……无论你叫它什么。

## 计算和数据处理任务

非平凡的密集型计算任务需要相应数量的计算资源。CPU、缓存、内存、计算算法的效率和并行性都会涉及到性能的确定。当计算结合网络分布或从磁盘读取/写入时，I/O 限制因素就会发挥作用。这类工作负载可以进一步细分为更具体的用例。

### CPU 密集型计算

CPU 密集型计算受执行它所花费的 CPU 周期的限制。循环中的算术处理、小矩阵乘法、判断一个数是否是**梅森素数**等，都会被认为是 CPU 密集型任务。如果算法复杂度与迭代/操作数*N*相关，例如*O(N)*，*O(N²)*等，那么性能取决于*N*的大小以及每一步需要多少 CPU 周期。对于可并行化的算法，可以通过分配多个 CPU 核心给任务来提高这类任务的性能。在虚拟硬件上，如果 CPU 周期是突发性的，性能可能会受到影响。

### 内存限制型任务

内存限制型任务受内存的可用性和带宽限制。例如，大文本处理、列表处理等。例如，在 Clojure 中，如果`coll`是一个由大映射组成的大序列，那么`(reduce f (pmap g coll))`操作将是内存限制型，即使我们在这里使用`pmap`来并行化操作。请注意，当内存是瓶颈时，更高的 CPU 资源无法帮助，反之亦然。内存不可用可能迫使你一次处理更小的数据块，即使你有足够的 CPU 资源可用。如果你的内存最大速度是*X*，而你的算法在单核上以速度*X/3*访问内存，那么你的算法的多核性能不能超过当前性能的三倍，无论你分配多少 CPU 核心给它。内存架构（例如，SMP 和 NUMA）对多核计算机的内存带宽有贡献。与内存相关的性能也受页面错误的影响。

### 缓存限制型任务

当任务的速度受可用缓存量限制时，该任务就是缓存限制型。当一个任务从少量重复的内存位置检索值时，例如小矩阵乘法，这些值可能会被缓存并从那里检索。请注意，CPU（通常是）有多个缓存层，当处理的数据适合缓存时，性能将达到最佳，但如果数据不适合缓存，处理仍然会发生，但速度会慢一些。可以使用**缓存无关**算法最大限度地利用缓存。如果并发缓存/内存限制型线程的数量高于 CPU 核心数，很可能会在上下文切换时清空指令流水线和缓存，这可能导致性能严重下降。

### 一个输入/输出（I/O）密集型任务

如果依赖的 I/O 子系统运行得更快，一个输入/输出（I/O）密集型任务会运行得更快。磁盘/存储和网络是数据处理中最常用的 I/O 子系统，但也可以是串行端口、USB 连接的卡片阅读器或任何 I/O 设备。一个 I/O 密集型任务可能消耗很少的 CPU 周期。根据设备速度、连接池、数据压缩、异步处理、应用程序缓存等，可能会有助于性能。I/O 密集型任务的一个显著方面是，性能通常依赖于等待连接/查找的时间以及我们进行的序列化程度，而很少依赖于其他资源。

实际上，许多数据处理工作负载通常是 CPU 密集型、内存密集型、缓存密集型和 I/O 密集型任务的组合。这类混合工作负载的性能实际上取决于在整个操作过程中 CPU、缓存、内存和 I/O 资源的均匀分布。只有当某一资源过于繁忙而无法为其他资源让路时，才会出现瓶颈情况。

## 在线事务处理

**在线事务处理**（**OLTP**）系统按需处理业务交易。它们可以位于用户界面 ATM 机、销售点终端、网络连接的票务柜台、ERP 系统等系统之后。OLTP 系统以低延迟、可用性和数据完整性为特点。它们运行日常业务交易。任何中断或故障都可能导致销售或服务直接且立即受到影响。这类系统应设计为具有弹性，而不是从故障中延迟恢复。当性能目标不明确时，您可能希望考虑优雅降级作为一种策略。

请求 OLTP 系统回答分析查询是一个常见的错误，它们并不是为此优化的。一个有经验的程序员了解系统的能力，并根据需求提出设计更改是可取的。

## 在线分析处理

**在线分析处理**（**OLAP**）系统旨在短时间内回答分析查询。它们通常从 OLTP 操作中获取数据，其数据模型针对查询进行了优化。它们基本上提供数据合并（汇总）、钻取和切片切块，以供分析使用。它们通常使用可以即时优化即席分析查询的特殊数据存储。对于这类数据库来说，提供类似数据透视表的功能非常重要。通常，OLAP 立方体用于快速访问分析数据。

将 OLTP 数据输入到 OLAP 系统中可能涉及工作流程和多阶段批量处理。这类系统的性能关注点是高效处理大量数据的同时，还要处理不可避免的故障和恢复。

## 批量处理

**批处理**是指预定义作业的自动化执行。这些通常是批量作业，在非高峰时段执行。批处理可能涉及一个或多个作业处理阶段。通常批处理与工作流自动化结合使用，其中一些工作流步骤是在离线状态下执行的。许多批处理作业工作在数据准备阶段，为下一阶段的处理挑选数据。

批处理作业通常优化以最佳利用计算资源。由于几乎没有东西可以调节对降低某些特定子任务延迟的需求，这些系统倾向于优化吞吐量。许多批处理作业涉及大量的 I/O 处理，并且通常分布在集群上。由于分布，处理作业时优先考虑数据局部性；也就是说，数据和处理应该是本地的，以避免在读写数据时的网络延迟。

# 对性能的

在实践中，非平凡应用程序的性能很少是巧合或预测的结果。对于许多项目来说，性能不是一种选择（而是一种必需品），这就是为什么这在今天尤为重要。容量规划、确定性能目标、性能建模、测量和监控是关键。

调整一个设计不良的系统以实现性能，如果不说实际上是不可能的，那么比从一开始就设计一个良好的系统要困难得多。为了达到性能目标，在应用程序设计之前应该知道性能目标。性能目标用延迟、吞吐量、资源利用率和工作负载来表述。这些术语将在本章下一节中讨论。

资源成本可以根据应用场景来识别，例如浏览产品、将产品添加到购物车、结账等。创建代表用户执行各种操作的工作负载配置文件通常是有帮助的。

**性能建模**是检查应用程序设计是否支持性能目标的一种现实检查。它包括性能目标、应用程序场景、约束、测量（基准结果）、工作负载目标以及如果有的话，性能基线。它不是测量和负载测试的替代品，相反，模型是通过这些来验证的。性能模型可能包括性能测试用例，以断言应用程序场景的性能特征。

将应用程序部署到生产环境几乎总是需要某种形式的**容量规划**。它必须考虑今天的性能目标和可预见的未来的目标。它需要了解应用程序架构，以及外部因素如何转化为内部工作负载。它还需要对系统提供的响应性和服务水平有合理的预期。通常，容量规划在项目早期进行，以减轻配置延迟的风险。

# 性能词汇表

在性能工程中，有几个技术术语被广泛使用。理解这些术语很重要，因为它们是性能相关讨论的基础。这些术语共同构成了性能词汇表。性能通常以几个参数来衡量，每个参数都有其作用——这样的参数是词汇表的一部分。

## 延迟

**延迟** 是单个工作单元完成任务所需的时间。它并不表示任务的完成成功。延迟不是集体的，它与特定的任务相关。如果两个类似的工作任务——`j1` 和 `j2` 分别耗时 3 毫秒和 5 毫秒，它们的延迟将被视为如此。如果 `j1` 和 `j2` 是不同的任务，那么这并没有区别。在许多情况下，类似工作的平均延迟被用于性能目标、测量和监控结果。

延迟是衡量系统健康状况的重要指标。高性能系统通常依赖于低延迟。高于正常水平的延迟可能是由于负载或瓶颈造成的。在负载测试期间测量延迟分布有助于了解情况。例如，如果超过 25% 的类似工作在类似负载下比其他工作有显著更高的延迟，那么这可能是值得调查的瓶颈场景的指标。

当一个名为 `j1` 的任务由名为 `j2`、`j3` 和 `j4` 的较小任务组成时，`j1` 的延迟不一定是 `j2`、`j3` 和 `j4` 各自延迟的总和。如果 `j1` 的任何子任务与其他任务并发，`j1` 的延迟可能会小于 `j2`、`j3` 和 `j4` 延迟的总和。I/O 密集型任务通常更容易出现较高的延迟。在网络系统中，延迟通常基于往返另一个主机的总时间，包括从源到目的地的延迟，然后返回源。

## 吞吐量

**吞吐量**是指在单位时间内完成的成功任务或操作的数量。在单位时间内执行的最顶层操作通常属于同一类，但延迟可能不同。那么，吞吐量告诉我们关于系统的什么信息呢？它是系统执行的速度。当你进行负载测试时，你可以确定特定系统可以执行的最大速率。然而，这并不能保证系统性能的最终、整体和最大速率。

吞吐量是决定系统可扩展性的因素之一。较高层次任务的吞吐量取决于并行生成多个此类任务的能力，以及这些任务的平均延迟。吞吐量应在负载测试和性能监控期间进行测量，以确定峰值吞吐量和最大持续吞吐量。这些因素有助于决定系统的规模和性能。

## 带宽

**带宽**是指通信通道上的原始数据速率，以每秒一定数量的比特来衡量。这包括不仅包括有效载荷，还包括执行通信所需的所有开销。一些例子包括：Kbits/sec、Mbits/sec 等。大写字母 B，如 KB/sec，表示字节，即每秒千字节。带宽通常与吞吐量进行比较。虽然带宽是原始容量，但对于同一系统，吞吐量是成功任务完成率，通常涉及往返。请注意，吞吐量涉及延迟的操作。为了在给定带宽下实现最大吞吐量，通信/协议开销和操作延迟应尽可能小。

对于存储系统（如硬盘、固态硬盘等），衡量性能的主要方式是**IOPS**（每秒输入输出），它是通过传输大小乘以的，表示为每秒字节数，或者进一步表示为 MB/sec、GB/sec 等。IOPS 通常用于顺序和随机工作负载的读写操作。

将系统的吞吐量映射到另一个带宽可能会导致处理两个系统之间的阻抗不匹配。例如，一个订单处理系统可能执行以下任务：

+   与磁盘上的数据库进行交易

+   将结果通过网络发送到外部系统

根据磁盘子系统、网络带宽以及订单处理执行模型的不同，吞吐量可能不仅取决于磁盘子系统和网络的带宽，还取决于它们当前的负载情况。并行化和流水线是提高给定带宽吞吐量的常见方法。

## 基准和基准测试

性能**基准线**，或简称基准线，是参考点，包括对已知配置中良好定义和理解的性能参数的测量。基准线用于收集我们可能后来为另一个配置基准测试的相同参数的性能测量。例如，收集“在 50 个并发线程负载下 10 分钟内的吞吐量分布”是这样一种性能参数，我们可以用它作为基准和基准测试。基准线与硬件、网络、操作系统和 JVM 配置一起记录。

性能**基准**，或简称基准，是在各种测试条件下记录性能参数测量的过程。一个基准可以由一个性能测试套件组成。基准可能收集从小到大的数据量，并且可能根据用例、场景和环境特性而持续不同时长。

基准线是在某个时间点进行的基准测试的结果。然而，基准与基准线是独立的。

## 性能分析

**性能** **分析**，或简称分析，是在程序运行时对其执行的分析。程序可能由于各种原因表现不佳。分析器可以分析和找出程序各部分的执行时间。手动在程序中放置语句以打印代码块的执行时间是可能的，但随着您尝试迭代地改进代码，这会变得非常繁琐。

分析器对开发者非常有帮助。根据分析器的工作原理，主要有三种类型——仪器化、采样和基于事件。

+   **基于事件的分析器**：这些分析器仅适用于选定的语言平台，并在开销和结果之间提供了良好的平衡；Java 通过 JVMTI 接口支持基于事件的性能分析。

+   **仪器分析器**：这些分析器在编译时或运行时修改代码以注入性能计数器。它们本质上是侵入性的，并增加了显著的性能开销。然而，您可以使用仪器分析器非常选择性地分析代码区域。

+   **采样分析器**：这些分析器在“采样间隔”暂停运行时并收集其状态。通过收集足够的样本，它们可以了解程序大部分时间花在了哪里。例如，在 1 毫秒的采样间隔下，分析器在一秒钟内会收集 1000 个样本。采样分析器也适用于执行速度超过采样间隔的代码（即，代码可能在两次采样事件之间执行几个工作迭代），因为暂停和采样的频率与任何代码的整体执行时间成比例。

分析并不仅限于测量执行时间。有能力的分析器可以提供内存分析、垃圾回收、线程等方面的视图。这些工具的组合有助于找到内存泄漏、垃圾回收问题等。

## 性能优化

简而言之，**优化**是在性能分析之后增强程序的资源消耗。性能不佳的程序的症状可以从高延迟、低吞吐量、无响应、不稳定、高内存消耗、高 CPU 消耗等方面观察到。在性能分析期间，可以通过分析程序来识别瓶颈，并通过观察性能参数逐步调整性能。

选择更好和更合适的算法是优化代码的全面好方法。对于 CPU 密集型代码，可以通过计算成本更低的操作进行优化。对于缓存密集型代码，可以尝试使用更少的内存查找来保持良好的命中率。对于内存密集型代码，可以使用自适应内存使用和保守的数据表示来存储在内存中进行优化。对于 I/O 密集型代码，可以尝试尽可能少地序列化数据，并且操作批处理将使操作更少地聊天，从而提高性能。并行性和分布式是其他，整体上好的提高性能的方法。

## 并发与并行

我们今天使用的绝大多数计算机硬件和操作系统都提供了并发功能。在 x86 架构上，对并发的硬件支持可以追溯到 80286 芯片。**并发**是在同一台计算机上同时执行多个进程。在较老的处理器中，并发是通过操作系统内核的上下文切换来实现的。当并发部分由硬件并行执行而不是仅仅切换上下文时，这被称为**并行性**。并行性是硬件的特性，尽管软件堆栈必须支持它，以便你在程序中利用它。我们必须以并发的方式编写程序，以利用硬件的并行性特性。

虽然并发是利用硬件并行性和加快操作的自然方式，但值得记住的是，拥有比你的硬件支持的并行性显著更高的并发性可能会导致任务调度到不同的处理器核心，从而降低分支预测并增加缓存未命中。

在低级别上，用于并发的进程/线程、互斥锁、信号量、锁定、共享内存和进程间通信是通过创建进程/线程、互斥锁、信号量、锁定、共享内存和进程间通信来实现的。JVM 对这些并发原语和线程间通信提供了出色的支持。Clojure 既有低级也有高级并发原语，我们将在并发章节中讨论。

## 资源利用率

**资源利用率**是衡量应用程序消耗的服务器、网络和存储资源的度量。资源包括 CPU、内存、磁盘 I/O、网络 I/O 等。可以从 CPU 密集型、内存密集型、缓存密集型和 I/O 密集型任务的角度分析应用程序。资源利用率可以通过基准测试、在给定吞吐量下测量利用率来得出。

## 工作负载

**工作负载**是指应用程序需要完成的工作量。它通过总用户数、并发活跃用户、交易量、数据量等来衡量。处理工作负载时应考虑负载条件，例如数据库当前持有的数据量、消息队列的填充程度、I/O 任务的积压情况以及更多。

# 每个程序员都应该知道的延迟数字

随着时间的推移，硬件和软件都取得了进步。各种操作的延迟使事情有了新的视角。以下表格展示了 2015 年的延迟数字，经加州大学伯克利分校的 Aurojit Panda 和 Colin Scott 允许复制（[`www.eecs.berkeley.edu/~rcs/research/interactive_latency.html`](http://www.eecs.berkeley.edu/~rcs/research/interactive_latency.html)）。每个程序员都应该知道的延迟数字如下表所示：

| 操作 | 2015 年所需时间 |
| --- | --- |
| L1 缓存引用 | 1ns（纳秒） |
| 分支预测错误 | 3 ns |
| L2 缓存引用 | 4 ns |
| 互斥锁/解锁 | 17 ns |
| 使用 Zippy（Zippy/Snappy：[`code.google.com/p/snappy/`](http://code.google.com/p/snappy/)) 压缩 1KB | 2μs（1000 ns = 1μs：微秒） |
| 在商品网络上发送 2000 字节 | 200ns（即 0.2μs） |
| SSD 随机读取 | 16 μs |
| 同一数据中心内的往返 | 500 μs |
| 从 SSD 顺序读取 1,000,000 字节 | 200 μs |
| 磁盘寻道 | 4 ms（1000 μs = 1 ms） |
| 从磁盘顺序读取 1,000,000 字节 | 2 ms |
| 从 CA 到荷兰的数据包往返 | 150 ms |

前面的表格显示了计算机中的操作及其引起的延迟。当 CPU 核在 CPU 寄存器中处理一些数据时，它可能需要几个 CPU 循环（以 3 GHz CPU 为例，每纳秒运行 3000 个循环），但一旦它必须回退到 L1 或 L2 缓存，延迟就会慢数千倍。前面的表格没有显示主内存访问延迟，这大约是 100 纳秒（根据访问模式而变化）——大约是 L2 缓存的 25 倍慢。

# 摘要

我们学习了深入思考性能的基础知识。我们了解了常见的性能词汇，以及性能方面可能变化的用例。通过查看不同硬件组件的性能数据，我们得出了性能优势如何传递到我们的应用中的结论。在下一章中，我们将深入探讨各种 Clojure 抽象的性能方面。
