- en: Chapter 10. Best Practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '"It is insanity to keep doing things the same way and expect things to improve."'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Anonymous
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Writing clean, readable, and maintainable JUnit test cases, just like writing
    clean code, is an art. A well-written unit test can prevent maintenance nightmare
    and acts as a system documentation; however, if not used carefully, it can produce
    meaningless boilerplate test cases. Mistakes are part of the learning process
    as long as you aren't making them repeatedly. JUnit is not rocket science, so
    we can practice, follow guidelines, and learn from others to make it perfect.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers JUnit guidelines and best practices. The following categories
    are covered in depth:'
  prefs: []
  type: TYPE_NORMAL
- en: Writing meaningful tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test automation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assertion convention
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exception handling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test smells and refactoring test smells
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing meaningful tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The common understanding of unit testing is testing the smallest possible part
    of software, specifically a method. In reality, we do not test methods; rather,
    we test a logical unit or the behavior of the system.
  prefs: []
  type: TYPE_NORMAL
- en: Logical units can extent to a single method, to an entire class, or a collaboration
    of multiple classes. For example, a standard calculator program can have an add
    method for adding two numbers. We can verify the add behavior by invoking the
    `add` method, or we can design the calculator program to have a simple calculate
    API that can take two numbers and an operation (add, subtract, divide, and so
    on), and depending on the operand type (integer, double, and so on), the calculator
    may delegate the calculation to a collaborator class, such as a double calculator
    or a long calculator. We can still unit test the add behavior, but now multiple
    classes are involved. We can call this new test an integration test.
  prefs: []
  type: TYPE_NORMAL
- en: A unit test verifies an assumption about the behavior of the system. In addition
    to this, if a test tests the entire system, it can't be a unit test—we call these
    tests **confederation** tests because they set up the entire ecosystem, including
    setting up the necessary components.
  prefs: []
  type: TYPE_NORMAL
- en: The following section elaborates on writing meaningful tests.
  prefs: []
  type: TYPE_NORMAL
- en: Improving readability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Martin Fowler said *Any fool can write code that a computer can understand.
    Good programmers write code that humans can understand*. Writing obscure code
    can be fashionable for old timers but it's not a standard Java practice. We should
    write readable and maintainable code such that anybody can understand the purpose
    of the code and enhance or maintain the code in future.
  prefs: []
  type: TYPE_NORMAL
- en: JUnit tests are written to test logical units. A test method name should portray
    the intention of the test so that a reader can understand what is being tested,
    such as the condition and the expectation or action.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose you are writing a test for a role-based system and the system denies
    unauthorized access. You can use the following patterns, but if you choose to
    follow one pattern, it''s best to stick to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '`testDenialOfUnauthorizedAccess()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`when_unauthorized_user_then_denies_the_access()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`should_deny_access_for_unauthorized_users()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I prefer the underscore (_) pattern as it's more readable.
  prefs: []
  type: TYPE_NORMAL
- en: 'For boundary value conditions, you can follow these patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '`testRegisteringNullUser()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`should_not_register_a_null_user()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`should_throw_exception_when_a_null_user_is_registered()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`when_null_user_then_registrar_throws_exception()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Likewise, a test class should portray the intention of the tests. Usually, we
    follow two conventions, `Test<class name>` or `<class name>Test`. Suppose you
    are testing the `UserRegistration` behavior. You can use `UserRegistrationTest`
    or `TestUserRegistration`. Several test coverage tools fail to recognize classes
    without the `Test` suffix. So, `UserRegistrationTest` is a safe choice.
  prefs: []
  type: TYPE_NORMAL
- en: Breaking everything that could possibly break
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An Extreme Programming concept is *test everything that could possibly break*.
    This means trying all different combinations of inputs to make sure we don't miss
    any combination that can cause the class to generate an error. However, this is
    an impossible thing to do in practice. We can test boundary value conditions.
    We can even cover all branches and lines, but we cannot test all input combinations.
    Suppose a method adds two integers. We can pass `NULL`, `0`, `Integer.MAX_VALUE`,
    negative numbers, and so on, but we literally cannot test the method with all
    possible integer values.
  prefs: []
  type: TYPE_NORMAL
- en: Ignoring simple test cases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Writing trivial JUnits (such that for getter and setter) is mostly a waste of
    time and money. We don't have the luxury to write infinite tests as it can eat
    our development time, application build time, and reduce test maintainability.
    If we start writing tests for getter/setters, we may miss more useful test cases.
    Usually, unit tests are automated and run during a build process. A build is required
    to finish early providing feedback, but the process will be delayed if we keep
    adding trivial tests. Unit tests are system documentation, so they portray the
    system behavior; however, if we keep adding tests for trivial things, then it
    defeats the purpose. Write tests that will pay you back with information.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying invalid parameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Test invalid parameters to every method. Your code needs to recognize and handle
    invalid data. The tests that pass using incorrect data and boundary value conditions
    provide comprehensive API documentation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose you are writing a test for an `add` method. It takes two integers and
    returns an integer. The following is the `Adder` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The boundary values that can be tested are null, zero, negative numbers, and
    overflow conditions, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Your class may have a public API that accepts user input and delegates input
    formatting to a dependent class or method. You should verify the user input in
    the public API only, not on all methods or dependent classes.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose the class `A` has a `doSomething(String input)` method. `A` calls `B`
    to format the input. If clients can call only class `A`, then you should not worry
    about validating the null input in class `B`. However, if both `A` and `B` are
    exposed, then `B` definitely should check for the `NULL` values. Checking `NULL`
    everywhere is defensive programming.
  prefs: []
  type: TYPE_NORMAL
- en: Relying on direct testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Suppose you have a facade class that depends on a utility class. Testing the
    facade class can cover the utility class. This is an example of indirect testing.
    The following `Facade` class depends on a `StringService` class for formatting;
    when we test the `Facade` class with a `String` value, then the `StringService`
    class is also tested:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We should test `StringService` directly, even though its methods are also invoked
    by the tests of the `Facade` class. We should have two test classes: `FacadeTest`
    and `StringServiceTest`.'
  prefs: []
  type: TYPE_NORMAL
- en: It's not a good idea to rely on indirect testing because if we change the implementation
    of the `Facade` class, then the dependent class may be uncovered. Suppose we change
    the implementation of the `Facade` class, so that it no longer depends on `StringService`.
    The tests in `StringServiceTest` will no longer invoke the methods of `StringService`,
    so we will lose code coverage.
  prefs: []
  type: TYPE_NORMAL
- en: Staying away from debugging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A common practice when we find a bug is to start debugging an application—stop
    doing this. Rather, add more tests to break the code; this will enrich your test
    suite and improve the system documentation. Similarly, don't put a catch block
    to print stacktrace. Rather, assert the exception message using the `ExpectedException`
    rule (explained in the *Handling exceptions* section). Sometimes, it's not possible
    to avoid debugging entirely. So anyway, before starting to debug, create a (integration)
    test that reproduces the issue and then debug it. This will narrow down the problem,
    create a unit test for the lowest possible unit, and keep both the tests for future
    reference.
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding generic matchers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We tend to use wildcard matchers to stub mock object methods; in the same way,
    verify the method invocations with generic matchers. This is a bad practice; you
    should go for an exact parameter match when possible. The following example demonstrates
    the wildcard argument matching.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `StringDecorator` class decorates the input with an exclamation symbol:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `PrinterService` interface connects to a LAN printer and prints the input
    text as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Facade` class accepts an input, decorates the input, and sends it to `PrinterService`
    for printing. To unit test this behavior, we need to mock out `PrinterService`
    with a mock object using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Generally, `PrintService` is stubbed with an `anyString()`generic matcher,
    and the `PrintService` call is verified using `verify(mockService).print(anyString());`,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We can use `eq("hello!")` instead of `anyString()`, as we know the `StringDecorator`
    method appends an exclamation to the `String` input; the test will fail if the
    `StringDecorator` method doesn't append the exclamation symbol. So, the side effects
    of `StringDecorator` can be identified immediately.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping away from @ignore
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Do not skip unit tests using the `@ignore` or `@exclude` annotations. As we
    know dead code removal is a refactoring technique, dead codes are never used.
    However, they create confusion. Similarly, when we ignore tests using the `@ignore`
    annotations, the tests are skipped, but the code remains in the file as dead code
    and creates confusion. Unit tests that are skipped provide no benefit. Instead
    of skipping unit tests, remove them from source control. If you need the test,
    you can get it from the source control history. Sometimes people create tests
    to easily understand some sort of APIs, but they don't want the tests to be executed
    when the test suite runs, or it may not be possible to run some tests on all platforms.
    With Maven (and Gradle), you can have different profiles with different test suites.
    For utility tests, it's always helpful to create a specific module for this.
  prefs: []
  type: TYPE_NORMAL
- en: Eluding debug messages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In early days, we used print (`System.out` or `System.err`) messages to console
    for debugging or unit testing code. Unit tests are system documentation, and a
    print statement does not fit in there. If you need to print something, just write
    a test and assert the expected value. Also, you can add a logging utility such
    as Log4J and log the debug messages. If a problem occurs in production, you just
    turn on these logs and see what's going on there to be able to reproduce the issue
    with tests better. So, tests and logs should rather complement each other.
  prefs: []
  type: TYPE_NORMAL
- en: Automating JUnit tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Chapter 2](part0018_split_000.html#page "Chapter 2. Automating JUnit Tests"),
    *Automating JUnit Tests*, covered the importance of test automation, CI, and test
    automation with Gradle, Maven, and Ant. This section reiterates the benefits of
    test automation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the benefits of test automation:'
  prefs: []
  type: TYPE_NORMAL
- en: Assumptions are continually verified. We refactor the code (change the internal
    structure of the code without affecting the output of the system) to improve code
    quality such as maintainability, readability, or extensibility. We can refactor
    the code with confidence if automated unit tests are running and providing feedback.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Side effects are detected immediately. This is useful for fragile, tightly coupled
    systems when a change in one module breaks another module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test automation saves time and there is no need of immediate regression testing.
    Suppose you are adding a scientific computation behavior to an existing calculator
    program and modifying the code. After every piece of change, you perform regression
    testing to verify the integrity of the system. Regression testing is tedious and
    time consuming, but if you have an automated unit test suite, then you can delay
    the regression testing until the functionality is done. This is because the automated
    suite will inform you at every stage if you disrupt an existing feature.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Always integrate your JUnits with build script and configure CI.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section deals with the test configuration. Unit tests are not testing
    the system. In TDD, unit tests are written to obtain the following benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: They drive your design. You write a test, add code to fix the test, refactor
    code with confidence, and apply the design. This results in a simple, clean, maintainable,
    loosely coupled, and cohesive design. You write code to satisfy a failing test,
    so it limits the code you write to only what is needed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The tests provide fast, automated regression for refactoring and enhancing the
    code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You should configure your tests to follow the following principles:'
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests should be executed extremely fast so that they can provide quick
    feedback. Would you withdraw money from an ATM that takes 10 minutes to dispense
    money?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tests should be reliable. Tests should fail if the production code is broken.
    Your tests will be considered unreliable in situations where you break the production
    logic but the tests pass, or you don't touch the production code but still your
    tests fail.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following section covers the test configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Running in-memory tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Do not write unit tests that make HTTP requests, look up JNDI resources, access
    a database, call SOAP-based web services, or read from the filesystem. These actions
    are slow and unreliable, so they should not be considered as unit tests; rather,
    they are integration tests. You can mock out such external dependencies using
    Mockito. [Chapter 4](part0027_split_000.html#page "Chapter 4. Progressive Mockito"),
    *Progressive Mockito*, explains the mocking external dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Staying away from Thread.sleep
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`Thread.sleep` is used in the production code to halt the current execution
    for some time so that the current execution can sync up with the system, such
    that the current thread waits for a resource used by another thread. Why do we
    need `Thread.sleep` in a unit test? Unit tests are meant to get executed faster.'
  prefs: []
  type: TYPE_NORMAL
- en: '`Thread.sleep` can be used to wait for a long running process (this is usually
    used to test concurrency), but what if the process takes time in a slow machine?
    The test will fail though the code is not broken, and this defeats the test reliability
    principle. Avoid using `Thread.sleep` in unit tests; rather, simulate the long
    running process using a mock object.'
  prefs: []
  type: TYPE_NORMAL
- en: Keeping unit tests away from the production code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Don't deliver unit tests to customers; they are not going to execute the tests.
    The test code should be separated from the production code. Keep them in their
    respective source directory tree with the same package naming structure. This
    will keep them separate during a build.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following Eclipse screenshot shows the separate source folder structure.
    Source files are located under the `src` folder, and the tests are placed under
    the `test` source folder. Note that the `Adder.java` and `AdderTest.java` files
    are placed in the same package named `com.packt.bestpractices.invalidinput`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Keeping unit tests away from the production code](img/00131.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Avoiding static variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Static variables hold state. When you use a static variable in your test, it
    signifies that you want to save the state of something. So, you are creating inter-test
    dependency. If the execution order changes, the test will fail though the code
    is not broken, and this defeats the test reliability principle. Do not use static
    variables in unit tests to store global state.
  prefs: []
  type: TYPE_NORMAL
- en: Don't initialize the class to be tested as static and use the `setUp` method
    (annotated with `@Before`) to initialize objects. These will protect you from
    accidental modification problems. The following example demonstrates the accidental
    modification side effects.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Employee` class stores employee names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The `HRService` class has a `generateUniqueIdFor(Employee emp)` method. It
    returns a unique employee ID based on the surname. Two employees with the surname
    Smith will have the IDs `smith01` and `smith02`, respectively. Consider the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The unit test class initializes the service as static. The service stores the
    input of the first test and fails the second test, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The following JUnit output shows the error details:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Avoiding static variables](img/00132.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Assuming the test execution order
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: JUnit was designed to execute the tests in random order. It depends on the Java
    reflection API to execute the tests. So, the execution of one test should not
    depend on another. Suppose you are testing the database integration of `EmployeeService`,
    where the `createEmployee()` test creates a new `Employee`, `updateEmployee()`
    method and updates the new employee created in `createEmployee()`, and `deleteEmployee()`
    deletes the employee. So, we are dependent on the test execution order; if `deleteEmployee()`
    or `updateEmployee()` is executed before `createEmployee()`, the test will fail
    as the employee is not created yet.
  prefs: []
  type: TYPE_NORMAL
- en: To fix this problem, just merge the tests into a single test named `verifyEmployeePersistence()`.
  prefs: []
  type: TYPE_NORMAL
- en: So, don't believe in the test execution order; if you have to change one test
    case, then you need to make changes in multiple test cases unnecessarily.
  prefs: []
  type: TYPE_NORMAL
- en: Loading data from files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The JUnit `Theory` framework offers an `abstract` class `ParameterSupplier`
    for supplying test data for test cases. The `ParameterSupplier` implementation
    can read from a filesystem, such as a CSV or an Excel file. However, it is not
    recommended that you read from the filesystem. This is because reading a file
    is an I/O (input/output) process, and it is unpredictable and slow. We don't want
    our tests to create a delay. Also, reading from a hardcoded file path may fail
    in different machines. Instead of reading from a file, create a test data supplier
    class and return the hardcoded data.
  prefs: []
  type: TYPE_NORMAL
- en: Invoking super.setUp() and super.tearDown()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes the data setup for unit testing is monotonous and ugly. Often, we
    create a base test class, set up the data, and create subclasses to use the data.
    From subclasses, always invoke the setup of the super classes and teardown methods.
    The following example shows the fault of not invoking the super class.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have `EmployeeService` and `EmployeeServiceImpl` to perform some business
    logic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The `BaseEmployeeTest` class is an `abstract` class, and it sets up the data
    for subclasses, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The `EmployeeServiceTest` class extends the `BaseEmployeeTest` class and uses
    the `employee` map, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The test execution fails with a `NullPointerException`. The following is the
    JUnit output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Invoking super.setUp() and super.tearDown()](img/00133.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To fix this, call `super.setUp()` from the `setUp()` method. The following
    is the modified `setUp()` method in `EmployeeServiceTest`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Staying away from side effects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Do not write test cases that affect the data of other test cases, for example,
    you are examining the JDBC API call using an in-memory `HashMap` and a test case
    clears the map, or you are testing the database integration and a test case deletes
    the data from the database. It may affect the other test cases or external systems.
    When a test case removes data from a database, any application using the data
    can fail. It's important to roll back the changes in the final block and not just
    at the end of the test.
  prefs: []
  type: TYPE_NORMAL
- en: Working with locales
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Be aware of internationalization while working with `NumberFormat`, `DateFormat`,
    `DecimalFormat`, and `TimeZones`. Unit tests can fail if they are run on a machine
    with a different locale.
  prefs: []
  type: TYPE_NORMAL
- en: The following example demonstrates the internationalization context.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose you have a class that formats money. When you pass 100.99, it rounds
    up the amount to 101.00\. The following formatter class uses `NumberFormat` to
    add a currency symbol and format the amount:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The following JUnit test verifies the formatting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run this test in a different locale, the test will fail. We can simulate
    this by changing the locale and restoring back to the default locale, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Before test execution, the default locale value is stored to `defaultLocale`,
    the default locale is changed to `GERMANY`, and after test execution, the default
    locale is restored. The following is the JUnit execution failure output. In `GERMANY`,
    the currency will be formatted to **101,00 €** but our test expects **$101.00**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Working with locales](img/00134.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: You can change your code to always return the USD format, or you can change
    your test to run in the US locale by changing the default locale to US, and after
    test execution, restore it back to the default one. Similarly, be careful while
    working with date and decimal formatters.
  prefs: []
  type: TYPE_NORMAL
- en: Working with dates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If not used carefully, dates may act bizarrely in tests. Be careful when using
    hardcoded dates in unit tests. You are working with dates and checking business
    logic with a future date. On January 1, 2014, you set a future date as April 10,
    2014\. The test works fine till April 9 and starts failing thereafter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Do not use hardcoded dates. Instead use `Calendar` to get the current date
    and time and add `MONTH`, `DATE`, `YEAR`, `HOUR`, `MINUTE`, or `SECOND` to it
    to get a future date time. The following self explanatory code snippet demonstrates
    how to create a dynamic future date:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The following are the future dates when the program was run on April 16, 2014:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Working with dates](img/00135.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Working with assertions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An assertion is a predicate used to verify a programmer assumption (expectation)
    with an actual outcome of a program implementation. For example, a programmer
    can expect that the addition of two positive numbers will result in a positive
    number. So, the programmer can write a program to add two numbers and assert the
    expected result with the actual result.
  prefs: []
  type: TYPE_NORMAL
- en: The `org.junit.Assert` package provides static overloaded methods for asserting
    expected and actual values for all primitive types, objects, and arrays.
  prefs: []
  type: TYPE_NORMAL
- en: This section covers the proper usage of the `Assertion` APIs. The following
    are the best practices.
  prefs: []
  type: TYPE_NORMAL
- en: Using the correct assertion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the correct assertion method. JUnit supports many assertion options, such
    as `assertEquals`, `assertTrue`, `assertFalse`, `assertNull`, `assertNotNull`,
    `assertSame`, and `assertThat`. Use the most appropriate one. The following are
    the examples:'
  prefs: []
  type: TYPE_NORMAL
- en: Use `assertTrue(yourClass.someMethod())` instead of using `assertEquals(true,
    yourClass.someMethod())`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `assertFalse(yourClass.someMethod())` instead of calling `assertTrue(!yourClass.someMethod())`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `assertNull(yourClass.someMethod())` rather than `assertEquals(null, yourClass.someMethod())`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `assertEquals(expected, yourClass.someMethod())` instead of using `assertTrue(expected.equals(yourClass.someMethod()))`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `assertThat(age, is(30))` method is more readable than `assertEquals(30,
    age)`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, `assertThat(age, is(not(33)))` is more readable than `assertTrue(age
    != 33)`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maintaining the assertEquals parameter order
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `assertEquals` method is a very useful method to verify the expectation.
    The `assertEquals` method has the `assertEquals(Object expected, Object actual)`
    signature.
  prefs: []
  type: TYPE_NORMAL
- en: 'Maintain the parameter order: first the expected value and then the actual
    result. The following JUnit snippet reverses the order, passes the actual value
    first, and then the expected result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the `Assertion` failure output with an informative message:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Maintaining the assertEquals parameter order](img/00137.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Striving for one assertion per test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Strive for one assertion per test method. When you check one assertion per test
    and a unit test fails, it is much easier to determine what went wrong. When a
    unit test has more than one assertion, and one assertion fails, extra effort is
    required to determine which one failed; for one assertion per test, no extra effort
    is required.
  prefs: []
  type: TYPE_NORMAL
- en: When a unit test performs more than one assertion, and a runtime exception is
    thrown, the assertions after the exception do not get verified; the JUnit framework
    marks the unit test as erroneous and proceeds to the next test method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following JUnit test asserts three conditions—the formatted amount is not
    null, the formatted amount contains a $ symbol, and the exact formatting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'When any assertion fails, the output doesn''t tell you what is wrong (you get
    the line number in the source code file, though, it is not very convenient to
    work with). The following is the JUnit output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Striving for one assertion per test](img/00138.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Instead of using three assertions, you can create three tests, or you can pass
    meaningful error messages to the assertion methods. The following JUnit test is
    modified to pass error messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the failing test gives you additional information about the failure. The
    following is the test output. It reads **Currency is not USD($)**, which means
    the second assertion failed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Striving for one assertion per test](img/00139.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Handling exceptions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Exception handling is an important part of Java coding. The Java community
    follows a set of best practices about exception handling. The following are the
    exception handling best practices for unit testing:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Do not write catch blocks to pass a unit test. Consider the following example
    where a `Calculator` program has a `divide` method. It takes two integers, divides,
    and returns a result. When `divide` encounters a divide by zero, the program should
    throw an exception. The following is the code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following is the test:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instead of catching `ArithmeticException`, we can apply the JUnit 4 pattern
    as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A more elegant way is to check the `ExpectedException` rule. The following
    is the modified test with `ExpectedException`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`ExpectedException` expects an exception and an error message. If the exception
    is not thrown, or the message doesn''t match, the test fails.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Do not write catch blocks to fail a test; the JUnit framework takes care of
    runtime exceptions. The following is an example of an unnecessary catch block:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instead, just write the following lines. The test will fail automatically if
    any exception is thrown:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Do not catch an exception and assert the failure to pass a test. The following
    test code catches `ArithmeticException` and sets a Boolean flag, and finally asserts
    the flag. If no exception is thrown, the flag remains false and the test fails:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Use the JUnit 4 patterns explained in the preceding example.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Do not add catch blocks to test a method that throws **checked** exceptions.
    The following example explains the problem. The `sum(int… arg)` method throws
    a `NumberOverflowException` checked exception when the integer overflows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A catch block is used to catch a checked exception and compile the test, as
    follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Do not follow this pattern; instead, use `throws Exception`. The following
    JUnit test uses the `throws Exception` clause:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Do not throw specific `Exceptions` from your tests. Instead, use the generic
    `throws Exception`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following example throws a specific `NumberOverflowException` exception:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Suppose the code is changed such that it could throw either `NumberOverflowException`
    or a `ParseException`. In that case, we have to change the test method to throw
    both the exceptions to compile the test. If we use the generic `throws Exception`
    clause, then this problem won't arise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Working with test smells
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Code smell is a technical debt or symptom that indicates a deeper problem.
    Smells are not bugs, or they don''t fail tests. Instead, they indicate a problem
    in design or code such that a rigid code cannot be enhanced or can create a maintenance
    issue. This section covers the test smells that should be refactored for maintenance
    and readability. The following topics are covered:'
  prefs: []
  type: TYPE_NORMAL
- en: Test code duplication
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conditions in test code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test logic in the production code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Over engineering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refactoring duplicates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Two `Person` objects and two `Address` objects are created and initialized.
    They are logically duplicate statements. Many other tests can write similar duplicate
    statements. Extract the method to refactor the duplicate smell. Extract the builder
    methods for the `Person` and `Address` objects as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'From the test code, just pass the required values and call the build methods
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: We can refactor the duplicate code in many test classes by moving the common
    code to a base test class or a helper class.
  prefs: []
  type: TYPE_NORMAL
- en: Refactoring the test control logic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unit test code verifies the behavior of the code under test, and usually, no
    conditional logic is written to verify the code. However, when a test contains
    code that is executed based on some condition, it gets complicated for the reader.
    The test executes fine but creates a maintainability problem.
  prefs: []
  type: TYPE_NORMAL
- en: When we post JMS messages to a destination (such as the TIBCO Enterprise Messaging
    Service), internally, the JMS provider posts administrative messages such as message
    received, message sent, and message acknowledged. However, each message contains
    the same JMS message ID. If we create a message logger program to listen to the
    JMS events (including administrative events), and log all events to a database
    for an audit trail, then the logger will save many messages with the same JMS
    message ID.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of the test control logic. The message is defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: The `eventType` variable indicates the administrative message type (received
    is 1, sent is 2, and acknowledged is 3).
  prefs: []
  type: TYPE_NORMAL
- en: 'The `MessagingService` interface is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll verify the logging capability as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The `Test` method loops through the messages, finds a message, and then verifies
    the payload. The test contains logic. Do we need another test for this test? This
    is confusing.
  prefs: []
  type: TYPE_NORMAL
- en: To refactor our test, you can move the logic to the code under test. The API
    should have a method to return a specific type of message. That way, we can check
    the message object directly instead of looping and checking.
  prefs: []
  type: TYPE_NORMAL
- en: Removing the test logic from the production code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Writing code for testability is a quality. Often, we put testing logic into
    the production code for unit testing, such as a new constructor or new method.
    To make the code testable, the tests require extra logic in production code to
    gain access to the code's internal state for testing configuration or result verification.
    Testing logic in production code is a smell, though it doesn't break the code
    under test but increases the complexity of the code, and this can create severe
    maintainability problems or system failure if anything gets misconfigured.
  prefs: []
  type: TYPE_NORMAL
- en: 'The testing logic is inserted into the production code under the following
    conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding conditional logic to return a hardcoded value during testing. The code
    under test acts as a dynamic stub as shown in the following example:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`EncounterManager` cannot be overridden as the class is declared as `final`;
    so, you cannot create a mock or fake object of this class. If your code under
    test needs to stub the `save()` behavior, then somehow you need to bypass the
    database call made in the `EncounterServiceImpl` method to persist the check-in
    data into a database. So, the `save()` method has an `isHack` conditional logic.
    This Boolean variable is added for testing purposes. From test, the Boolean variable
    `isHack` is set to `true`. If accidentally this variable is set to `true`, then
    encounters will not be created in production.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Additional code is written only for test execution, or private variables are
    exposed as public. The following is an example:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `retrieveEncounters()` method is a private method used for lazy instantiation
    of `encounters List`. However, for testing purposes, `encounters List` is exposed
    as `public` and a `public` setter method is used. From test, either the setter
    method is called with a hardcoded `List` or directly the `encounters List` is
    set. If `encounters List` is accidentally set in production, users will see the
    wrong data in the UI.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Mockito doesn''t allow stubbing the `equals()` and `hashcode()` methods, as
    they should not be overridden unless the logic is comprehensible. Yet, often for
    testing, we override the `equals()` and `hashcode()` methods and perform testing
    logic or return the hardcoded value. This is very dangerous. In production, if
    we need to put the objects in a collection or need to perform an equality check,
    then the system behaves in a bizarre fashion. The following code snippet overrides
    the `hashcode()` and `equals()` methods:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `equals()` method returns `false` in the production code and `hashcode()`
    returns `0`. The `EncounterManager` class cannot be used in conjunction with the
    Java collection framework.
  prefs: []
  type: TYPE_NORMAL
- en: To refactor the production code, remove the final keyword, override the class
    in the test context, and return the hardcoded values. However, never ever touch
    the `equals()` and `hashcode()` methods for testing.
  prefs: []
  type: TYPE_NORMAL
- en: Refactoring over engineered tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tests are system documentation. They should tell the reader what is being executed.
    Often, we put too much documentation and make it more complex for the reader to
    understand the intention. Sometimes, we refactor the test and extract clean, meaningful
    methods, pass variables to the extracted methods, and from test just invoke the
    methods. Now the reader fails to understand the utility of the test case, and
    everything is carried out elsewhere.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following test example demonstrates `Test` with less or no information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The unit test calls three methods: `createCheckInRequestForAPatientWithAGuarantor`,
    `checkInaPatient`, and `assertResult`. From the test body, it is not possible
    to understand what is being tested, what data is created, and what is asserted.
    A test should configure data, call the actual method, and assert results.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of a test with overly verbose documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: The test builds two `Person` objects and two `Address` objects. Two builder
    methods are extracted for code reuse. For better documentation, variables are
    created and the hardcoded values are set and passed to the builder methods. These
    hardcoded variables make it tough to understand what is going on.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of creating a custom builder method in test class, you can modify the
    main data class to follow the builder pattern and build the object in multiple
    steps. That way, we don't have to create hardcoded variables such as `johnsStreetAddress`,
    we can directly call the methods we need.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Person` class is modified; the setter methods return an instance of `this`
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: From test, we can build the object easily. The following test example needs
    only an e-mail ID, first name, and phone number for testing, so it should not
    populate other values.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can build the object in three steps, and we no longer need the hardcoded
    strings to document the behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covered the JUnit best practices and explained the underlying principles.
    The best practices are writing meaningful tests, automating unit tests, test configuration,
    working with assertions, exception handling in test cases, identifying test smells,
    and refactoring test smells.
  prefs: []
  type: TYPE_NORMAL
- en: Now you will be able to write clean and maintainable test cases.
  prefs: []
  type: TYPE_NORMAL
