- en: Project 1 - Building Microservices with Scala
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: During this book, we have gradually increased the scope of our interests. In
    the first part, we started with language constructs and small building blocks,
    such as types and functions. The second part was dedicated to the patterns of functional
    programming. In the third part, we looked at even bigger abstractions—the actor
    model and streaming.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we'll zoom out once again, this time moving from design aspects
    up to the architectural level. We will use what we've learned so far to build
    two fully-scoped projects.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, it goes without saying that all server-side software should provide
    an API, specifically an HTTP RESTful API. Software providing an API is called
    a **service** and if it conforms to a set of principles, it is often called a
    **microservice**. We will follow the crowd and design our projects as microservices.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll cover two topics. First, we'll discuss the concept of
    microservices and describe their advantages and building principles. We'll also
    take a look at few technical and organizational challenges related to the microservice-based
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: Second, we'll use the knowledge gained from the rest of the book to build two
    real projects from scratch. Both represent simple microservices implementing stateful
    REST APIs, which represent the grocery shop you're familiar with from the third
    section of the book. This time, we'll provide not only an opportunity to place
    orders, but also to create and delete articles, and to replenish items in stock
    and get the current status of the stock.
  prefs: []
  type: TYPE_NORMAL
- en: The first project will be built on principles covered in the second section
    of this book. We will build it using open source functional programming libraries—http4s
    and circe for the client API, and doobie for database access.
  prefs: []
  type: TYPE_NORMAL
- en: The second project will be built using reactive programming libraries and techniques
    covered in the third section of this book. We'll use Akka-HTTP to construct an
    API layer, and Akka Persistence to implement the stateful part of it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Essentials of microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Purely functional HTTP APIs with http4s
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Purely functional database access with doobie
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: API integration testing with Http1Client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reactive HTTP API with Akka-HTTP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Event-sourced persistent state with Akka Persistence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we begin, make sure you have the following installed:'
  prefs: []
  type: TYPE_NORMAL
- en: SBT 1.2+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Java 1.8+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The source code for this chapter is available on GitHub at [https://github.com/PacktPublishing/Learn-Scala-Programming/tree/master/Chapter14](https://github.com/PacktPublishing/Learn-Scala-Programming/tree/master/Chapter14).
  prefs: []
  type: TYPE_NORMAL
- en: Essentials of microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When discussing microservices, it is better to start with the question of size.
    Evidently, software systems are growing in size in response to increasing demands
    from users. The number of features, their complexity and sophistication grow and
    so do the lines of code in software projects. Even in well-structured living systems,
    the size of components and their number is getting bigger over time. Given limited
    human mental capabilities, the proportion of the system that is understood by
    a single programmer shrinks, which leads to the increased number for developers
    in the team. Bigger team size leads to the growth of the communication overhead
    and so less time for writing code, leading to the need for additional developers,
    which introduces a self-reinforced cycle.
  prefs: []
  type: TYPE_NORMAL
- en: The *traditional* monolithic way to build systems as a single project with a
    single deployment module or executable and a single database is therefore becoming
    less and less efficient, and ultimately just makes it impossible to deliver working
    software in a timely manner. An alternative approach is to split the monolith
    into separate projects, called microservices, that can be developed independently.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices look like the only feasible alternative to the monolithic approach,
    and are therefore becoming more and more popular. But, what are they precisely?
    According to [http://microservices.io](http://microservices.io), microservices—also
    known as the microservice architecture—is an architectural style that structures
    an application as a collection of loosely-coupled services, which implement business
    capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: What does it mean? In essence, this is what would happen to the well-structured
    application if one would tear it apart and make an autonomous application from
    each module responsible for single business feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *autonomy* in this definition applies on multiple levels:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Codebase and technological stack**: The code of the service should not be
    shared with other services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment:** The service is deployed independently of other services both
    in terms of time and underlying infrastructure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**State:** The service has its own persistent store and the only way for other
    services to access the data is by calling the owning service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Failure-handling:** Microservices are expected to be resilient. In the case
    of failures of downstream services, the one in question is expected to isolate
    failure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These aspects of autonomy allow us to reap a number of benefits from a microservice-based
    architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: Continuous delivery even for very complex applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The complexity of each service is low because it is limited to a single business
    capability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Independent deployment implies independent scalability for services with different
    loads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code-independence enables polyglot environments and makes the adoption of new
    technologies easier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Teams can be scaled down in size, which reduces communication overhead and speeds
    up decision-making
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Of course, there are downsides to this approach as well. The most obvious drawbacks
    are related to the fact that microservices need to communicate with each other.
    To name a few important difficulties:'
  prefs: []
  type: TYPE_NORMAL
- en: Unavailability of habitual transactions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Debugging, testing, and tracing calls involving multiple microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The complexity shifts from the individual service into the space between them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service location and protocol discovery require lots of effort
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: But don't be scared! In the reminder of this chapter, we'll build just a single
    microservice so we won't be affected by these weaknesses.
  prefs: []
  type: TYPE_NORMAL
- en: Building a microservice with http4s and doobie
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's take a look at how a microservice with a RESTful interface will look if
    implemented with open source libraries based on the principles we've learned in
    first two sections of the book.
  prefs: []
  type: TYPE_NORMAL
- en: We will start with the discussion of the building blocks that constitute the
    application and how they connect together. Speaking of blocks, we'll need to briefly
    talk about the FS2 library, which is a foundation of other libraries we will use
    and thus shapes the ways we join them together. After that, we'll go over database
    migrations, project configurations, the implementation of the database logic,
    and the service layer. Naturally we conclude our discourse with the implementation
    of integration testing for the service we've built.
  prefs: []
  type: TYPE_NORMAL
- en: Project structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our project will include the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: Database repository represents an abstraction layer over the database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Database migrator contains initialization logic for the database table
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The REST API defines available HTTP calls and associated business logic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The configuration consolidates application parameters, such as server binding
    and database properties
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The server wires all other components together, and spawns and binds an HTTP
    server to the configured address
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We''ll start by adding following dependencies to `build.sbt` (the exact versions
    can be found in the GitHub repository):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This list definitely looks longer than what you would expect for an example
    project. Let''s inspect carefully why we need each of the dependencies we''ve
    put into it:'
  prefs: []
  type: TYPE_NORMAL
- en: http4s is the library we will be using for the HTTP layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: doobie is a functional JDBC (Java DataBase Connectivity) decorator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: H2 is an embedded database which we will use to avoid installing a standalone
    instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flyway is for database migrations (versioned SQL statements used to change the
    database structure)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Circe is a JSON Swiss Army knife
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PureConfig` is a typed configuration wrapper'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Cats` is a library containing general functional programming abstractions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FS2 – functional streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You may be wondering why we have a section about the FS2 library if we're not
    using it as a component for our application. Well, in fact, we are. It is an underlying
    building block for the database and HTTP libraries we're using, and therefore
    it is important to briefly discuss it to give you an understanding of how the
    other building blocks are connected.
  prefs: []
  type: TYPE_NORMAL
- en: '[FS2](https://github.com/functional-streams-for-scala/fs2) is a streaming library
    that allows us to construct and transform complex streams. The streams in FS2
    do not only contain elements, but also can embody effects such as IO. This feature
    makes it possible to describe almost everything as an FS2 stream. Libraries such
    as `http4s` and `doobie` are built upon this and give a higher-level API to the
    user. But this API is still a streaming one.'
  prefs: []
  type: TYPE_NORMAL
- en: The stream is represented as `Stream[F,O]`, where `F` describes a possible effect
    of the stream and `O` is a type of its elements or output. This definition needs
    to be given two type parameters in order to fully specify it. If the stream has
    no effects, it will be pure: `Stream[Pure, O]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s construct a stream of `chars`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Pure streams can be converted to the `List` or `Vector` without evaluation:
    `chars.toList`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Streams with effects can''t be converted the same way because of the presence
    of effects. The effects first need to be *reduced* to a single effect. At the
    same time, we need to define how the output of the stream should be dealt with.
    Finally, we can execute the effect and get the output of the stream. This process
    is similar to the definition and materialization of the Akka streams we looked
    at in [Chapter 13](8b5e55e4-de37-4ab1-8baa-7e0c3ad3a6ed.xhtml), *Basics of Akka
    Streams*. Because we have quite a number of things to define, the syntax is a
    bit cumbersome, but it reflects the logic we described:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s go over this snippet line by line and look at what is happening. The
    numbers in the code will correspond to the numbers in the following explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: We are using the cats `IO` as type of our effect.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We define an `IO` as a by-name parameter to write to the console and return
    `aa`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We `eval` our `IO`. This creates a single-element stream.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By compiling the stream, we create its projection to a single effect.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By converting a `ToEffect` projection to `Vector` it is compiled to the expected
    effect type. The process can be thought of as executing a stream of effects and
    logging emitted results into the desired structure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We demonstrate another way to define conversion to collection.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`drain` is used to discard any emitted values and is useful if we are only
    interested in executing effects.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There are also other possibilities to define what should happen with output
    elements of the stream, for example, just collecting the `last` one.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`unsafeRunSync()` runs the definition, synchronously producing effects and
    emitting output. This is the first moment anything appears in the console because
    so far we''ve just created and modified the definition of the stream.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The definition is immutable and can be shared. Because of this, we can run the
    same stream description multiple times (with respect to the kind effects).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'All of this is usually defined as a one-liner: eval the effect, compile the
    stream to the single effect, define the type of the output for the elements, run
    the stream later.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now let's see how FS2 are utilized by `http4s` and `doobie`. We'll start with
    the database layer as its implementation will guide the structure of other layers.
  prefs: []
  type: TYPE_NORMAL
- en: Database migrations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order for the database to be used in the application, it needs to contain
    all required tables, indexes, and other definitions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll represent our store as a simple table with the name of the item serving
    as a primary key and a non-negative count of each item:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We'll place this definition into `db_migrations/V1__inventory_table.sql` and
    use Flyway to check that our database is in the correct state during startup time.
  prefs: []
  type: TYPE_NORMAL
- en: Flyway provides a mechanism to define and change database schema in well-defined
    steps by adhering to specific naming conventions while placing  schema migrations
    SQL in the project folder. You can learn more about it at [https://flywaydb.org](https://flywaydb.org).
  prefs: []
  type: TYPE_NORMAL
- en: 'The Flyway code for migrations is straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Given a `transactor` (which we'll describe a bit later, at the moment we'll
    talk about `doobie`), we use the datasource it provides to create an instance
    of `Flyway`, configure it to use proper migrations location, and perform the migration.
    Please note that the initialization logic is wrapped into the `IO` effect and
    thus delayed until the effect is evaluated.
  prefs: []
  type: TYPE_NORMAL
- en: 'The transactor is created using the utility provided by doobie from the configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Again it is wrapped in `IO` so no effects will be evaluated until we run the
    result of this function.
  prefs: []
  type: TYPE_NORMAL
- en: Before going over to the definition of the database repository, let's have a
    quick look at the configuration abstraction we've used in the `transactor` method.
  prefs: []
  type: TYPE_NORMAL
- en: Configuration with PureConfig
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''re already familiar with the Typesafe Config library, which we actively
    used in our bakery examples. It is a very useful and flexible library. Unfortunately,
    because of this flexibility, it has one shortcoming: each configuration bit needs
    to be read and converted to the appropriate type individually. Ideally, we''d
    like our configuration to be represented as case classes and rely on naming conventions
    to map the structure of the configuration file to the structure of the (typed)
    configuration we have in the application. Ideally, we''d like to fail fast at
    startup time if the configuration file can''t be mapped to the case classes that
    describe the configuration at the code level.'
  prefs: []
  type: TYPE_NORMAL
- en: The `pureconfig` library makes this possible. This library can be found at [https://github.com/pureconfig/pureconfig](https://github.com/pureconfig/pureconfig).
  prefs: []
  type: TYPE_NORMAL
- en: 'Using it, we can define the configuration structure in Scala like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This definition reflects the structure of the configuration in [HOCON](https://github.com/lightbend/config/blob/master/HOCON.md)
    format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can load and map it to the case classes directly using `pureconfig`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Again, wrapped in `IO` and thus delayed, we're trying to load and map the configuration
    and raise an appropriate error in the context of an `IO` in the case this attempt has
    failed.
  prefs: []
  type: TYPE_NORMAL
- en: The configuration bit concludes the infrastructural part of the example and
    we can finally turn to the core—the database repository.
  prefs: []
  type: TYPE_NORMAL
- en: Doobie – functional database access
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The database layer in our example is implemented with the Doobie library. Its
    official website describes it as *a pure functional JDBC layer for Scala and Cats*. It
    allows us to abstract existing JDBC functionality in a nice functional way. Let''s
    show how this is done. The library can be found at[ https://tpolecat.github.io/doobie/](https://tpolecat.github.io/doobie/).
    In the following examples, please assume the following imports to be in scope:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need some model classes to persist, and for the purpose of the example,
    we''ll keep the ADT as small as possible:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This model will allow us to represent the inventory of our shop as a map with
    keys referring to the article name and a values denoting number of the respective
    items in stock. We'll also have two operations that can be applied to the inventory—the
    Purchase operation will reduce the number of corresponding items and the Restock
    operation will increase number of respective items by combining our existing stocks
    together.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can define our repository for this model. We''ll do this in the same
    pure functional way we did before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The repository is given `Transactor[IO]` as a constructor parameter. The `IO`
    in this example is `cats.effect.IO`. The transactor knows how to work with database
    connections. It can manage connections in the same logical way a connection pool
    does. In our implementation, `Transactor` is used to convert an FS2 `Stream[IO,
    ?]` into the `IO`, which will connect to the database and execute SQL statements
    if run. Let''s see in detail how this is done for article-creation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s go over this definition line by line to see what is going on here:'
  prefs: []
  type: TYPE_NORMAL
- en: We define a `Fragment`, which is an SQL statement that can include interpolated
    values. Fragments can be combined together.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From `Fragment`, we construct an `Update`. `Update` can be used to construct
    a `ConnectionIO` later.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We construct a `ConnectionIO` by calling the `run` method on  `update`. `ConnectionIO`
    is basically an abstraction over the possible operations available on the JDBC
    connection.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By calling an `attempt` method, we're adding error-handling to our `ConnectionIO`.
    This is the reason the type parameter of `ConnectionIO` has changed from `Int`
    to `Either[Throwable, Int]`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By providing a `transactor` to the `transact` method, we convert `ConnectionIO` into `IO`,
    which represents a runnable doobie program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We coerce different sides of `Either` to a single Boolean value. We expect the
    number of created rows to be exactly one, in which case the call was a success.
    If we failed to create a row or if there was an exception thrown, it is a failure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It would be more appropriate in the erroneous case to differentiate between
    the *unique index or primary key violation* and other cases but unfortunately
    different database drivers have different encoding for that, so it is not possible
    to provide concise generic implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other methods in our repository will follow the same pattern. `deleteArticle`
    is a one-liner and we don''t bother to handle errors in this case (exceptions
    will bubble up to the upper layers and be propagated to the client if they will
    be thrown), so we can just check whether the number of affected rows was exactly
    one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '`getInventory` is a bit different because it needs to return the results of
    the query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Here, we see that the query is of the `doobie.Query0[(String, Int)]` type with
    the type parameter representing the column types of the result. We convert the
    query to `Stream[ConnectionIO, (String, Int)]` (an FS2 stream with the `ConnectionIO`
    effect type and the tuple as a type of elements) by calling a `stream` method
    and then convert `ConnectionIO` to `IO` by providing a transactor. At last, we
    fold elements of the stream into `Map`, thus constructing the inventory state
    at the present moment from individual rows.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the inventory has another caveat. We would like to update multiple
    articles at once so that if there is insufficient supply for some of the articles,
    we discard the whole purchase.
  prefs: []
  type: TYPE_NORMAL
- en: This is a design decision. We could decide to return a partially-fulfilled order
    to the client.
  prefs: []
  type: TYPE_NORMAL
- en: 'The count of every article needs to be updated separately, therefore we need
    to have multiple update statements running in a single transaction. This is how
    it is done:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We're given a map of `name -> count` pairs as a parameter. The first thing we
    do is to convert each of these pairs into an update operation by mapping over
    them. This leaves us with a collection of `CollectionIO[Int]`. We then combine
    these updates together by using the cats `Apply` operator, which produces a single `CollectionIO[Int]`.
  prefs: []
  type: TYPE_NORMAL
- en: JDBC by default has auto-commit enabled, which will lead to the effect that
    our updates in the batch will be executed and committed one by one. This can lead
    to partially-fulfilled orders. In order to avoid that, we wrap the updates into
    the stream, which will disable auto-commits before the updates and enable auto-commits
    again after all of them are executed. We then lift the error-handling of the result
    and convert it into the runnable `IO` as before.
  prefs: []
  type: TYPE_NORMAL
- en: The result of the method is the `Stream[IO, Either[Throwable, Unit]]` type.
    The type of the elements of the stream encodes the possibilities to have both
    updates that weren't possible because there were insufficient articles in the
    inventory as `Left` and a successful update as `Right` .
  prefs: []
  type: TYPE_NORMAL
- en: With these four methods, we actually have all the required basic functionality
    and can start to use it in the API layer.
  prefs: []
  type: TYPE_NORMAL
- en: http4s – streaming HTTP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The implementation of the HTTP interface in our project is based on the http4s
    ([https://http4s.org)](https://http4s.org)) library. http4s is built on top of
    the FS2 and Cats IO and therefore we have a nice interplay with the persistence
    layer implemented with doobie. With http4s, it is possible to build functional
    server-side services using high-level DSL, as well as use it on the client-side
    to call HTTP APIs. We will use the client functionality to build an integration
    test for our API later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The server side is represented by `HttpService[F]`, which is essentially just
    a mapping from `Request` to `F[Response]` and `F` is a cats `IO` in our case.
    http4s DSL helps to construct such RESTful services by using pattern-matching.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how it looks in practice. First we need to have following imports for
    `fs2` and `IO`, and http4s DSL and circe in scope:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'With these imports in place, we can start to build up our service definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The service is given a database repository as a parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The routes are defined separately for each HTTP verb and a URL template. We
    start with the definition of the service method, which takes a partial function
    from request to response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we follow with the simple route for article deletion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Here we are using `http4s` DSL in order to deconstruct `Request` into parts
    and pattern-match against these parts. The `->` object extracts the path from
    the request and the `/` class allows us to represent the concatenation of subpaths
    of the request URL (there is also `/:`, which matches the URL from the point of
    application and to the end of the url). The pattern-match itself is just a normal
    Scala case, hence we can use its full power. In this case, we're mapping the last
    part of the URL to `name` and have a guardian to make sure the path only matches
    if `name` is not empty (because we don't want to have anonymous articles in our
    shop!).
  prefs: []
  type: TYPE_NORMAL
- en: The expected result of the function is the `IO[Response[IO]]` type. Luckily,
    the return type of the `deleteArticle` method of our repository is `IO[Boolean]`,
    so we can just `flatMap` the returned boolean value into the response body *inside*
    of an `IO`. In this case, we don't want to respond with the body, but just inform
    the caller about the success of the operation, which is represented with the respective
    response codes: `204 No Content` and `404 Not Found`. http4s provides a nice constructors
    for this with a bit of a verbose type: `IO[Response[IO]]`. In our case, we define
    a function from `Boolean` to this type and use this function to `flatMap` the
    result of the repository call, which leaves us with `IO[Response[IO]]` as an end
    result, which is exactly the type expected to be returned.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, all of this logic can be written in a succinct manner. Here is an
    example for the API call to create an article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The approach is absolutely the same as the one we had for article deletion.
  prefs: []
  type: TYPE_NORMAL
- en: The API we're building is not a principle RESTful API. For this example to be
    a valid, level two API, we need to also implement a `GET` call that retrieves
    a representation for the individual articles. This can be done by adding a corresponding
    method to the repository and a `case` to the service. The implementation is left
    to the reader as an exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have created a few articles in the repository, we would like to
    be able to retrieve the current state of it. We can implement it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The above pattern-match is straightforward and so is the call to the `getInventory`
    method of the repository. But it returns the result of the `Stream[IO, Inventory]` type
    and we need to convert it to the matching type for `HttpService[IO]`. `http4s`
    has a concept of `EntityEncoder` for this.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the corresponding implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Here, we prepare the inventory to be represented as an HTTP response by converting
    the returned `Map[String, Int]` to JSON. We rely on circe ([https://github.com/circe/circe](https://github.com/circe/circe))
    to perform automatic conversion. Next, the stream is converted to the appropriate
    response type by the `Ok` status constructor and an implicit `EntityEncoder[IO,
    String]`. We explicitly force the content type of the response to be `application/json`
    in order to have it correctly represented in the response.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we want to provide a way to modify the state of the inventory like
    we did with the repository. We''ll implement two API calls, one for replenishing
    the inventory and another for purchases. They are implemented similarly, so we''ll
    cover only one of them; the other can be found in the [GitHub](https://github.com/PacktPublishing/Learn-Scala---Fundamentals-of-Scala-2.12/blob/master/ch14/http4s-doobie/src/main/scala/ch14/Service.scala#L22)
    repository. Here is the implementation for the restock call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We need a request to read its body, therefore we bind it to the `req` variable
    in the pattern match. Next, we decode the JSON body of the request and map it
    to our model. Here we rely on circe to do the heavy lifting again. The `updateStock`
    repository method returns the stream, so we need to bring our parameter in the
    same context in order to be able to use it nicely in the `for` comprehension.
    We're doing this by wrapping the result of the decoding into `Stream.eval`.
  prefs: []
  type: TYPE_NORMAL
- en: Then we call the repository and provide the required changes in the form of `Inventory`.
    This method returns `Stream[IO, Either[Throwable, Unit]]`, so we ignore the result
    (it will shortcut the for comprehension in the case of an error). Finally, we
    read the new state of the repository and render it for the caller as before.
  prefs: []
  type: TYPE_NORMAL
- en: The read-after-write is a known database anti-pattern. We used this approach
    to illustrate how streaming calls can be nicely chained in a for comprehension.
    In a real project, it might be better to formulate SQL statements in a way that
    the new state is returned immediately after the update.
  prefs: []
  type: TYPE_NORMAL
- en: The service layer is implemented now. We can wire our application together and
    see how it works.
  prefs: []
  type: TYPE_NORMAL
- en: Bringing it all together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The server code will require a few new imports in addition to our usual set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '`BlazeBuilder` is a server factory, and `ExecutionContext` will be needed at
    the moment we start the server. The server is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '`StreamApp` requires us to implement a `stream` method, with the solely purpose
    to produce side-effects and provides cleanup hooks for this stream. This is our
    implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We just read the configuration and delegate the actual server creation to `ServerInstance`.
    Let''s have a look at it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Here again we see the same approach: we lift `config` into the context of `Stream`,
    create a transactor, initialize the database, build the repository from the transactor
    and the service from the repository, and finally mount the service by using the
    `BlazeBuilder` factory.'
  prefs: []
  type: TYPE_NORMAL
- en: The caller method will then execute the serve method of the server, starting
    the whole IO program we've built so far.
  prefs: []
  type: TYPE_NORMAL
- en: We were following a pattern for providing dependencies as we've build up this
    example—we gave them as constructor parameters at the moment we constructed class
    instances. The approach of passing dependencies as constructor parameters is called constructor-based
    dependency-injection in Scala.
  prefs: []
  type: TYPE_NORMAL
- en: Now our application can be started and played with. But we want to be sure that
    it behaves correctly by testing it.
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This example is quite simple and basically just an HTTP facade over the database,
    so we won't test components in isolation. Instead, we'll use integration-testing
    to check the system as a whole.
  prefs: []
  type: TYPE_NORMAL
- en: In order to have SBT properly recognize our integration tests, we need to add
    the proper configurations to `build.sbt`. Please refer to the chapter code on
    GitHub ([https://github.com/PacktPublishing/Learn-Scala-Programming](https://github.com/PacktPublishing/Learn-Scala-Programming))
    to see how this is done.
  prefs: []
  type: TYPE_NORMAL
- en: In our integration test, we will let our system run normally (but with the test
    database) and use an HTTP client to call the API and inspect the responses it
    will return.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to prepare our HTTP client and server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Here we create the client we'll be using to query our API by instantiating the `Http1Client`
    provided by the `http4s` library. We also read a test config that overrides database
    settings so that we can freely modify the data. We're using an in-memory H2 database,
    which is destroyed after our test finishes so that we don't need to clean up the
    state after the test. Then we're building a server by re-using `ServerInstance`.
    In contrast to the production code, we're starting it with the `start` method,
    which returns a server instance. We'll use this instance after the test to shut
    down the server.
  prefs: []
  type: TYPE_NORMAL
- en: Please note how we use `unsafeRunSync()` in multiple places to evaluate the
    contents of `IO`. For the server, we're even doing this twice, once for `IO` and
    once for `Stream[IO, ...]`. This is okay to do in the test code as it helps to
    keep the testing logic concise.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to shut down the client and the server after the test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Again, we're running an IO here because we want the have the shutdown happen
    right now.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at one of the test methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Here we first create a test request using a factory provided by http4s. We then
    check that the API returns the correct `NoContent` status if we send this request
    with the client we created earlier in this section. We then create the second
    article by using the same approach.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we're using the client to call the URL directly and let it parse the
    response to the JSON form. Finally, we check that the inventory has a correct
    state by comparing the JSON response with circe's JSON literal.
  prefs: []
  type: TYPE_NORMAL
- en: For testing other API calls, we could also provide a request body using circe
    JSON literals. Please refer to the chapter's source code placed on GitHub to see
    how this is done.
  prefs: []
  type: TYPE_NORMAL
- en: It is absolutely possible to implement the same testing logic using other HTTP
    clients or even command-line tools. The `Http1Client` provided by `http4s` allows
    for nice syntax and concise expectation definitions.
  prefs: []
  type: TYPE_NORMAL
- en: Running the application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The easiest way to run our API is in the SBT shell by issuing a `run` command.
    The project for this chapter is configured as a multi-module SBT project. Because
    of this, the `run` command has to be prefixed by the module name so that it is
    fully spelled as `http4s/run` as shown in the next screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2401065b-ee26-436e-9bd8-a7ba24222d2a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Different components of our API will output lots of information. The application
    is started after the address of the HTTP server is shown. You can see how this
    looks on the bottom of the next screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0d09d8e4-e358-4398-aa5f-3a2cf2fc00c7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After that, the API should serve HTTP requests, for example, issued with curl
    in another terminal window as the following screenshot demonstrates:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dbf77382-7def-433e-a4d5-22c0b15f4c32.png)'
  prefs: []
  type: TYPE_IMG
- en: As our example uses in-memory database, it will lose its state after restart.
  prefs: []
  type: TYPE_NORMAL
- en: Building microservices with Akka-HTTP and Akka Persistence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we've seen how the principle functional approach to the implementation
    of the microservice works, let's change our technological stack and implement
    the same shop with Akka-HTTP and Akka Persistence. The flow of the discussion
    for this example will be similar to the one we had about the functional approach—we
    will start with looking at the way to persist the state of the service and the
    configuration needed for that. We'll then address the task of actually persisting
    the data and providing access to it via the HTTP service. As before, we'll conclude
    our journey by testing the implementation we'll come up with.
  prefs: []
  type: TYPE_NORMAL
- en: Project structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The project structure, in this case, will be almost the same as we had before.
  prefs: []
  type: TYPE_NORMAL
- en: We'll have an API layer responsible for the interaction with HTTP clients. We'll
    also inevitably have some configuration and a database initialization code that
    will be implemented in a similar, or identical, way to what we did as we've built
    the previous microservice.
  prefs: []
  type: TYPE_NORMAL
- en: The persistence layer will be represented by a persistent actor. This will affect
    the definition of the model as well as the structure of the database tables.
  prefs: []
  type: TYPE_NORMAL
- en: Akka Persistence introduces different paradigms of how the state of the system
    is stored and represented. The approach is called **Event-Sourcing** and it makes
    sense to take a minute to discuss it.
  prefs: []
  type: TYPE_NORMAL
- en: Event-Sourcing and CQRS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Event-sourcing is about how the state of the system is stored. Normally the
    state of the system is persisted into the database as a number of related tables.
    Changes to the state are reflected in the database by modifying, adding, or deleting
    table rows. The database contains the current state of the system with this approach.
  prefs: []
  type: TYPE_NORMAL
- en: Event-sourcing provides an alternative method. It handles updates of the state
    very much like functional programming handles effects. Instead of executing a
    computation, it just describes it so that it is possible to execute it later.
    Descriptions of computations can be combined, as we saw in the second section
    of this book. The same way the changes of the state can be combined in an event-sourced
    approach to produce current state. In essence, event-sourcing is to the state
    what functional programming is to the computations and effects.
  prefs: []
  type: TYPE_NORMAL
- en: This description of the state change is called **event** and it usually (but
    not necessarily!) corresponds to some user action, called **command**. The system
    receives commands, validates them, and if the command makes sense in the context
    of current system state, respective event(s) is created and persisted into the
    event journal. The event is then applied to the in-memory representation(s) of
    the state and the required side-effects are executed.
  prefs: []
  type: TYPE_NORMAL
- en: When the event-sourced system is restarted, the events are read from the journal
    and applied to the initial state one by one, modifying it but not executing side-effects.
    At the end, after all events are applied, the internal state of the system should
    be the same as it was before the restart. Hence, *events* are the *source* of
    the state representation of the system in this scenario. The reconstructed state
    often represents only one aspect of the whole system and is called **view**.
  prefs: []
  type: TYPE_NORMAL
- en: The event journal is used only for appending events. Because of this, it is
    usually seen as an append-only storage, and often solutions other than relational
    databases are used.
  prefs: []
  type: TYPE_NORMAL
- en: CQRS is another name that goes hand in hand with Event-Sourcing. This is an
    abbreviation for Command Query Responsibility Segregation, which in turn is just
    a fancy way to name a principle of *Command–Query Separation* implemented with
    Command and Query entities (as opposed to the method calls). The CQS principle
    states that every method should be either *command*, which modifies the state,
    or *query*, which returns the state, and these responsibilities should not be
    mixed. With Event-Sourcing, this separation comes naturally from the definition
    of the *Event* (which is the Command in the CQS definition) and the concept of
    internal state as a *View* that needs to be queried separately.
  prefs: []
  type: TYPE_NORMAL
- en: 'Event-Sourcing has a lots of advantages over the traditional database-mutating
    approach:'
  prefs: []
  type: TYPE_NORMAL
- en: Append-only approach to store data scales much better than traditional relational
    databases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Events provide audit, traceability, and in the case of special storages, security
    for free.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No need to use an ORM.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The domain model and event model can evolve at a different pace.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is possible to recover the state of the system to any specific moment in
    the past.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Events can be combined in different ways, allowing us to construct different
    representations of state. Combined with the previous advantage, it gives us the
    ability to analyze past data in ways that weren't known at the time of the event's
    creation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Of course, there are some drawbacks as well:'
  prefs: []
  type: TYPE_NORMAL
- en: The state does not exists until it is reconstructed from events. Depending on
    the format of the journal, it might even impossible to analyze the events without
    writing special code for this purpose. In any case, it requires some effort to
    build the state representation from events.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explosion of domain model in complex projects. Implementing new use-cases always
    requires the introduction of new commands and events.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changes in the model as the project evolves. Changes in existing use-cases often
    mean changes in the structure of existing evens, which need to be done in the
    code because the event journal is append-only.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of events can grow rapidly. In actively-used systems, there may be
    millions of events produced daily, which can affect the time needed to build the
    state representation. Snapshotting is used to work around this issue.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring Akka Persistence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Akka Persistence allows us to store and replay messages sent to `PersistentActor`
    and thus implements an event-sourcing approach. Before going into the details
    of the actors implementation, let's look at the arrangements we need to make in
    the project configuration.
  prefs: []
  type: TYPE_NORMAL
- en: We're going to use the H2 relational database for this project. Akka Persistence
    supports many different storage plugins, including a local filesystem for storing
    snapshots, and in our case, it appears to be a good idea to use the same database
    we used with doobie to underline the differences in the architectural style.
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, we''re using Flyway to create the structure of the database. The tables
    will be different though. This is the table that will store events:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '`persistence_id` is an ID of a specific persistent actor, which needs to be
    unique for the whole actor system (we''ll see in a minute how this maps to the
    code), the `tags` field holds tags assigned to the events (this makes constructing
    views easier). `message` holds an event in serialized form. The serialization
    mechanism is decoupled from the storage. Akka supports different flavours, including
    Java serialization, Google Protobuf, Apache Thrift, or Avro and JSON. We''ll use
    the JSON format in order to keep the example small.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The snapshots table is even simpler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Basically, it's just a snapshot in serialized form, with a timestamp and the
    `persistence_id` of the actor it belongs to.
  prefs: []
  type: TYPE_NORMAL
- en: 'With these tables in the migrations file, we now need to add following dependencies
    to `build.sbt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The `akka-persistence` dependency is obvious. `akka-persistence-jdbc` is an
    implementation of the JDBC storage for the h2 database. `Flyway-core` is used
    to set up the database like in the previous example. `stamina-json` allows for
    schema migrations—it gives us a way to describe how the events stored in the old
    format in the database should be converted to the new format used in the code
    if needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need to put quite a bit of configuration for the Akka persistence in `application.conf` to
    configure journals. This configuration is quite verbose, so we will not discuss
    it here in full, but we will take a look at one part of it that describes serialization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we configure serialization for the stamina. Let''s take a look at `EventSerializer`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we tell stamina which serializers to use. The serializers are defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `PersistenceSupport` object, we define persisters for our events. We
    don''t need any migrations yet, but in the case we would, the migrations would
    be described here. Persister requires implicit `RootJsonFormat` to be available
    and we provide them in the `JsonSupport` trait:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: We extend `SprayJsonSupport` and import `DefaultJsonProtocol._` to get implicit
    formats for basic types already defined by `spray-json`. Then we define `RootJsonFormat`
    for all of our commands (these formats will be used by the API layer to un-marshall
    request bodies), events (which will be used by both the API layer to marshall
    responses, and the persistence layer to serialize events), and an Inventory (which
    is required for snapshots to be serializable). Here we're not relying on circe's
    auto-derivation and hence describe each case class individually.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have persisters and formats for the model, but what is that model? It
    reflects the event-sourcing approach!
  prefs: []
  type: TYPE_NORMAL
- en: Domain models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With event-sourcing, we want to store changes of the state as events. Not every
    interaction with the client is an event. Until we know that we can comply, we''re
    modeling it as a command. Specifically, in our example it is represented as sealed
    traits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'In the spirit of CQRS, we model incoming data as four commands and one query.
    The commands can be made into the events if the current state allows that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: In our simple case, commands and events correspond to each other, but in the
    real project, this won't always be the case.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also have a representation of the current state of the store:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '`Inventory` extends `Persistable` so that we can make snapshots later. We will
    keep the business logic separate from the actor-related code. Because of this,
    our inventory should be able to handle events itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The `create` method adds an article to the store and assigns some initial counts
    to it if possible. It returns an inventory in the new state in the case of success:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The `delete` method tries to delete an article from the inventory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The `add` method sums the count of articles from another inventory with counts
    of all articles existing in this inventory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Now our inventory can accept events and return itself in an updated state,
    but we still have to deal with commands first. One possible implementation of
    the logic for command-handling could look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: The `canUpdate` method takes a command and returns a corresponding event in
    the case that it is possible to apply the command successfully. For creating and
    deleting articles, we're checking that the operation will produce a valid result;
    for purchases, we're checking that there are enough articles in stock, and restock
    should always succeed.
  prefs: []
  type: TYPE_NORMAL
- en: Our Inventory is not synchronized and hence it is not safe to work within a
    concurrent scenario. Moreover, if one thread makes modifications to the inventory
    at the time another thread already called `canUpdate`, but has not called `update`
    yet, we might end up with the incorrect state because of this race condition.
    But we don't need to worry about that because we're going to use our inventory
    inside of an actor.
  prefs: []
  type: TYPE_NORMAL
- en: The persistent actor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The persistent actor in Akka extends the normal `Actor` and mixes in a `PersistentActor`. `PersistentActor`
    implements the `receive` method but requires a few other methods to be implemented
    by us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Besides the `inventory` that we need as a representation of state, we need to
    define a unique `persistenceId` and two methods: `receiveRecover` and `receiveCommand`.
    The former is called during the recovery time, for example at startup or if the
    persistent actor is restarted, and it receives all events from the journal. It
    is expected to modify the internal state but not to execute any side-effects.
    The latter is called during the normal lifetime and it receives all the commands.
    It is supposed to convert valid commands to events, persist the events, modify
    the internal state, and execute side-effecting code after that.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, `receiveRecover` just delegates the event processing to `inventory`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Additionally, it handles instances of `SnapshotOffer` by restoring the inventory
    as a whole from the latest snapshot. `SnapshotOffer` will be the first message
    the actor receives if there are snapshots available, and it will contain the latest
    snapshot so it is safe to restore the inventory from it. The events in the journal
    before the snapshot will not be replayed. Finally, after receiving the `RecoveryCompleted`
    event, we save the current state as a snapshot for use after the next restart.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `receiveCommand` implementation is a bit more involved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: We handle the `GetInventory` query by sending a current state to the sender.
    Inventory is a wrapper over an immutable map, so it is safe to share.
  prefs: []
  type: TYPE_NORMAL
- en: We handle all `Commands` the same way, by letting Inventory do the actual work.
    If a command cannot be applied, we respond to the sender with `None`. In the opposite
    case, we asynchronously persist corresponding events and provide a callback that
    will be executed after the event is persisted. In the callback, we apply the event
    to the internal state and send the new state to the sender. In contrast to the
    normal actor, it is safe to use `sender()` in an async block.
  prefs: []
  type: TYPE_NORMAL
- en: And this is it, we now have a persistent actor that will restore its state after
    the restart. Time to make it available for HTTP clients.
  prefs: []
  type: TYPE_NORMAL
- en: Akka-HTTP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Akka-HTTP provides a nice DSL to describe a server-side API similar to doobie.
    But Akka''s language flows a bit differently. Instead of pattern-matching the
    request by applying rules one by one, it works more like a sieve. It filters requests
    by providing a number of directives, each matching some aspect of the request.
    The directives are nested so that each request travels deeper and deeper into
    matching branches until it reaches the processing logic. Such a combination of
    directives is called route. This is the inventory route:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'This route contains three smaller routes, one matching `GET /inventory`, another
    `POST /purchase`, and the third `POST /restock`. The second and third routes also
    define that the request entity must be parseable as `PurchaseArticles` and `RestockArticles`
    respectively and provide the result of the parsing as a parameter to the body.
    Let''s see how the internals of these routes are implemented. We know that the
    inventory route should return the current state so we ask the inventory actor
    about that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: The `complete` method takes `ToResponseMarshallable`, and we rely on the Akka-HTTP
    and JSON serializers we defined earlier to do the implicit conversion from the `Future[Inventory]` that
    we're getting as the result of the application of the ask pattern here.
  prefs: []
  type: TYPE_NORMAL
- en: '`inventory` is provided as an abstract field for now. This is how it looks
    in the definition of `Routes`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: We define an abstract `config` that we then use to define an `implicit timeout`
    for the ask. We also define `ExecutionContext` in order to be able to map over `Future`
    in other routes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of the other two routes is similar. This is the purchase
    route:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The logic is almost the same with differences related to the situation we can't
    satisfy the requirements. In this case, we return the `409 Conflict` error code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The restock route is even simpler because it always succeeds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: The definition of `articleRoute` for article creation and deletion is very similar
    and is available on GitHub so we will omit it here.
  prefs: []
  type: TYPE_NORMAL
- en: 'The routes are combined together using `~`, the same way we already did inline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Bringing it all together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Having the routes implemented, we can now go on with the server definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: We mix together the `Routes` and `JsonSupport` traits and define abstract fields.
    The actor system is needed in order to instantiate the materializer, and a materializer
    is a machine driving Akka-HTTP. Then we initialize the database, instantiate our
    persistent actor (which starts to receive events from the journal and restore
    its state), bind and start the server, and wait for the termination of the actor
    system.
  prefs: []
  type: TYPE_NORMAL
- en: The way we injected dependencies by defining abstract members and then mixing
    traits together is called trait-based DI or the thin cake pattern. Usually, in
    simple cases, we would prefer constructor-based DI, like in the http4s example.
  prefs: []
  type: TYPE_NORMAL
- en: Compared to the http4s implementation, this server is eager. Every statement
    is executed the moment it is defined (with respect for laziness).
  prefs: []
  type: TYPE_NORMAL
- en: Now we have another version of our store done and can test it as well.
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Of course, Akka would not be Akka if it did not provide a nice DSL for testing HTTP
    routes. The DSL allows us to test routes in a way that it is not needed to start
    a real server. It is possible to provide a mock implementation of the business
    logic to test routes in isolation. In our case, the logic is so simple that it
    actually makes sense to test the app as a whole, the same way we did in the http4s
    case.
  prefs: []
  type: TYPE_NORMAL
- en: 'The definition of the specification should not be surprising:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The good news is that `ScalatestRouteTest` already provides a definition for
    the actor system and `materializer` so we don't need to initialize them before
    the test and close after the test. The `Routes` are the same `Routes` we defined
    earlier and are about to test now. We still have abstract definitions of `config`
    and `inventory` here, so provide an implementation for them.
  prefs: []
  type: TYPE_NORMAL
- en: 'And this is how we can test a route:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: First, we define the `request` we want the route to be checked against. Then
    we transform it with the `route` to the response, which in turn gets transformed
    into `check`. In the body of `check`, we can refer to the properties of the response
    in a simple way.
  prefs: []
  type: TYPE_NORMAL
- en: The `routes` in `request ~> routes ~> check` refer to the field defined in the `Routes` trait.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, it is possible to create a request with a body and use it to test
    a route that expects such request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Here we `Marshal` the restock case class to `Entity` the same way it worked
    on routes. `.futureValue` is from the ScalaTest's `ScalaFutures` helper. The rest
    of the snippet is very similar to the previous example.
  prefs: []
  type: TYPE_NORMAL
- en: Running the application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To run the Akka-HTTP API, we have to use the same approach as we used for the
    http4s version. The name of the module will be, well, `akkaHttp`, but the principle
    is the same. The next screenshot shows the output in the console after `akkaHttp/run`
    was entered in the SBT shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a81ae74e-a962-4552-9ad7-ccab8e778ce6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The application outputs a few lines and then waits for incoming requests. It
    is now safe to play with it the same way we did with the http4s version:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86d8f174-f069-4e6c-a926-3748f9f4f257.png)'
  prefs: []
  type: TYPE_IMG
- en: One subtle but important difference is that the Akka version persists the database
    into the filesystem and retains the state between restarts, as shown by the first
    request on the previous screen.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we briefly discussed the pros and cons of the microservice-based
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: We've built two small examples with similar functionality but different technological
    stacks.
  prefs: []
  type: TYPE_NORMAL
- en: The first project was built using a purely functional approach with wrapping
    effects in IO monad and functional streams. This allowed us to describe a system
    as a computation that is only started at the *end of the world*. We used the ORM
    approach in this case by mapping the state of the system to the database table
    and modifying it in response to the required changes. Finally, we demonstrated
    how to use the http4s client to test the system as a whole by building an integration
    test.
  prefs: []
  type: TYPE_NORMAL
- en: The basis for the second project was the "*official*" Lightbend stack. We looked
    at how well Akka-HTTP and Akka Persistence play together. We demonstrated that
    the event-sourced approach allows us to reconstruct state in memory by recombining
    it from persistent events. This helped us to avoid writing any SQL statements.
    We also looked at how the Akka-HTTP test kit can be used to test routes without
    the need to start the real HTTP server.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is a database migration?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe what could be an alternative approach to discard an order completely
    in the case of insufficient stock for some articles.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe the conceptual difference between http4s and Akka-HTTP with regard
    to defining routes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name a reason why event-sourced data storage can scale better than traditional
    relational databases.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement a `GET /articles/:name` call with http4s and doobie.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement a `GET /articles/:name` call with Akka-HTTP and Akka Persistence.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vinicius Feitosa Pacheco, *Microservice Patterns and Best Practices[ **Explore
    the concepts and tools you need to discover the world of microservices with various
    design patterns*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jatin Puri, Selvam Palanimalai, *Scala Microservices: **Design,* *build*, *and
    run microservices elegantly using Scala*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Héctor Veiga Ortiz, Piyush Mishra, *Akka Cookbook: **Learn how to use the Akka
    framework to build effective applications in Scala*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rambabu Posa, *Scala Reactive Programming: Build fault-tolerant, robust, and
    distributed applications in Scala*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Christian Baxter, *Mastering Akka: **Master the art of creating scalable, concurrent,
    and reactive applications using Akka*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
