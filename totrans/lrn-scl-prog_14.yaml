- en: Project 1 - Building Microservices with Scala
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目1 - 使用Scala构建微服务
- en: During this book, we have gradually increased the scope of our interests. In
    the first part, we started with language constructs and small building blocks,
    such as types and functions. The second part was dedicated to the patterns of functional
    programming. In the third part, we looked at even bigger abstractions—the actor
    model and streaming.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们逐渐扩大了我们的兴趣范围。在第一部分，我们从语言结构和小型构建块开始，例如类型和函数。在第二部分，我们专注于函数式编程的模式。在第三部分，我们探讨了更大的抽象——actor模型和流。
- en: In this section, we'll zoom out once again, this time moving from design aspects
    up to the architectural level. We will use what we've learned so far to build
    two fully-scoped projects.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将再次放大视角，这次从设计层面上升到架构层面。我们将利用到目前为止所学的内容来构建两个全面的项目。
- en: Nowadays, it goes without saying that all server-side software should provide
    an API, specifically an HTTP RESTful API. Software providing an API is called
    a **service** and if it conforms to a set of principles, it is often called a
    **microservice**. We will follow the crowd and design our projects as microservices.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，不言而喻，所有服务器端软件都应该提供API，特别是HTTP RESTful API。提供API的软件被称为**服务**，如果它符合一系列原则，通常被称为**微服务**。我们将跟随潮流，将我们的项目设计为微服务。
- en: In this chapter, we'll cover two topics. First, we'll discuss the concept of
    microservices and describe their advantages and building principles. We'll also
    take a look at few technical and organizational challenges related to the microservice-based
    approach.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖两个主题。首先，我们将讨论微服务的概念，描述其优势和构建原则。我们还将探讨与基于微服务的方法相关的几个技术和组织挑战。
- en: Second, we'll use the knowledge gained from the rest of the book to build two
    real projects from scratch. Both represent simple microservices implementing stateful
    REST APIs, which represent the grocery shop you're familiar with from the third
    section of the book. This time, we'll provide not only an opportunity to place
    orders, but also to create and delete articles, and to replenish items in stock
    and get the current status of the stock.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，我们将利用本书其余部分获得的知识，从头开始构建两个真实项目。这两个项目都代表了简单的微服务，实现了有状态的REST API，这些API代表了你在本书第三部分熟悉的杂货店。这次，我们不仅提供下单的机会，还可以创建和删除商品，以及补充库存并获取当前库存状态。
- en: The first project will be built on principles covered in the second section
    of this book. We will build it using open source functional programming libraries—http4s
    and circe for the client API, and doobie for database access.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个项目将基于本书第二部分介绍的原则构建。我们将使用开源函数式编程库——http4s和circe用于客户端API，以及doobie用于数据库访问。
- en: The second project will be built using reactive programming libraries and techniques
    covered in the third section of this book. We'll use Akka-HTTP to construct an
    API layer, and Akka Persistence to implement the stateful part of it.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个项目将使用本书第三部分涵盖的响应式编程库和技术构建。我们将使用Akka-HTTP构建API层，并使用Akka Persistence实现其有状态的部分。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Essentials of microservices
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务基础
- en: Purely functional HTTP APIs with http4s
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用http4s的纯函数式HTTP API
- en: Purely functional database access with doobie
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用doobie的纯函数式数据库访问
- en: API integration testing with Http1Client
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Http1Client进行API集成测试
- en: Reactive HTTP API with Akka-HTTP
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Akka-HTTP的响应式HTTP API
- en: Event-sourced persistent state with Akka Persistence
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Akka Persistence的事件源持久状态
- en: Technical requirements
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'Before we begin, make sure you have the following installed:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，请确保您已安装以下内容：
- en: SBT 1.2+
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SBT 1.2+
- en: Java 1.8+
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java 1.8+
- en: The source code for this chapter is available on GitHub at [https://github.com/PacktPublishing/Learn-Scala-Programming/tree/master/Chapter14](https://github.com/PacktPublishing/Learn-Scala-Programming/tree/master/Chapter14).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的源代码可在GitHub上找到：[https://github.com/PacktPublishing/Learn-Scala-Programming/tree/master/Chapter14](https://github.com/PacktPublishing/Learn-Scala-Programming/tree/master/Chapter14)。
- en: Essentials of microservices
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微服务基础
- en: When discussing microservices, it is better to start with the question of size.
    Evidently, software systems are growing in size in response to increasing demands
    from users. The number of features, their complexity and sophistication grow and
    so do the lines of code in software projects. Even in well-structured living systems,
    the size of components and their number is getting bigger over time. Given limited
    human mental capabilities, the proportion of the system that is understood by
    a single programmer shrinks, which leads to the increased number for developers
    in the team. Bigger team size leads to the growth of the communication overhead
    and so less time for writing code, leading to the need for additional developers,
    which introduces a self-reinforced cycle.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论微服务时，最好从大小问题开始。显然，软件系统的大小在满足用户日益增长的需求时也在增长。功能数量、它们的复杂性和复杂性都在增长，软件项目中的代码行数也在增加。即使在结构良好的活系统中，组件的大小和数量也会随着时间的推移而增加。鉴于有限的人类心智能力，单个程序员所能理解的系统比例会缩小，这导致团队中开发人员数量的增加。更大的团队规模会导致通信开销的增加，从而减少编写代码的时间，导致需要更多的开发人员，这引入了一个自我强化的循环。
- en: The *traditional* monolithic way to build systems as a single project with a
    single deployment module or executable and a single database is therefore becoming
    less and less efficient, and ultimately just makes it impossible to deliver working
    software in a timely manner. An alternative approach is to split the monolith
    into separate projects, called microservices, that can be developed independently.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，将系统作为单一项目构建的传统单体方式，即使用单一部署模块或可执行文件和单一数据库，正变得越来越低效，最终使得及时交付可工作的软件变得不可能。一种替代方法是，将单体拆分为独立的项目，称为微服务，这些项目可以独立开发。
- en: Microservices look like the only feasible alternative to the monolithic approach,
    and are therefore becoming more and more popular. But, what are they precisely?
    According to [http://microservices.io](http://microservices.io), microservices—also
    known as the microservice architecture—is an architectural style that structures
    an application as a collection of loosely-coupled services, which implement business
    capabilities.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务似乎是单体方法的唯一可行替代方案，因此越来越受欢迎。但是，它们究竟是什么？根据[http://microservices.io](http://microservices.io)，微服务，也称为微服务架构，是一种将应用程序结构化为一系列松散耦合的服务，这些服务实现业务能力。
- en: What does it mean? In essence, this is what would happen to the well-structured
    application if one would tear it apart and make an autonomous application from
    each module responsible for single business feature.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着什么？本质上，这就是如果将结构良好的应用程序拆分，并从每个负责单一业务功能的模块中创建一个自主应用程序会发生的情况。
- en: 'The *autonomy* in this definition applies on multiple levels:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个定义中，“自主性”适用于多个层面：
- en: '**Codebase and technological stack**: The code of the service should not be
    shared with other services.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码库和技术栈**：服务的代码不应与其他服务共享。'
- en: '**Deployment:** The service is deployed independently of other services both
    in terms of time and underlying infrastructure.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署**：服务在时间和底层基础设施方面都是独立于其他服务的。'
- en: '**State:** The service has its own persistent store and the only way for other
    services to access the data is by calling the owning service.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**状态**：服务拥有自己的持久存储，其他服务访问数据的唯一方式是通过调用拥有该数据的服务。'
- en: '**Failure-handling:** Microservices are expected to be resilient. In the case
    of failures of downstream services, the one in question is expected to isolate
    failure.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**故障处理**：预期微服务具有弹性。在下游服务出现故障的情况下，预期相关服务将隔离故障。'
- en: 'These aspects of autonomy allow us to reap a number of benefits from a microservice-based
    architecture:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些自主性方面使我们能够从基于微服务的架构中获得许多好处：
- en: Continuous delivery even for very complex applications
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使对于非常复杂的应用程序，持续交付也是可行的
- en: The complexity of each service is low because it is limited to a single business
    capability
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个服务的复杂性都很低，因为它仅限于单一业务能力
- en: Independent deployment implies independent scalability for services with different
    loads
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立部署意味着具有不同负载的服务可以独立扩展
- en: Code-independence enables polyglot environments and makes the adoption of new
    technologies easier
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码无关性使得多语言环境成为可能，并使得采用新技术更加容易
- en: Teams can be scaled down in size, which reduces communication overhead and speeds
    up decision-making
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 团队可以缩小规模，这减少了通信开销并加快了决策速度
- en: 'Of course, there are downsides to this approach as well. The most obvious drawbacks
    are related to the fact that microservices need to communicate with each other.
    To name a few important difficulties:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这种方法也有缺点。最明显的缺点与微服务需要相互通信的事实有关。以下是几个重要的困难：
- en: Unavailability of habitual transactions
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 习惯性事务不可用
- en: Debugging, testing, and tracing calls involving multiple microservices
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试、测试和跟踪涉及多个微服务的调用
- en: The complexity shifts from the individual service into the space between them
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂性从单个服务转移到它们之间的空间
- en: Service location and protocol discovery require lots of effort
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务位置和协议发现需要大量努力
- en: But don't be scared! In the reminder of this chapter, we'll build just a single
    microservice so we won't be affected by these weaknesses.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 但不要害怕！在本章的剩余部分，我们只构建一个微服务，这样我们就不会受到这些弱点的困扰。
- en: Building a microservice with http4s and doobie
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用http4s和doobie构建微服务
- en: Let's take a look at how a microservice with a RESTful interface will look if
    implemented with open source libraries based on the principles we've learned in
    first two sections of the book.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看，如果使用基于本书前两章所学的原则的开源库来实现，一个具有RESTful接口的微服务将是什么样子。
- en: We will start with the discussion of the building blocks that constitute the
    application and how they connect together. Speaking of blocks, we'll need to briefly
    talk about the FS2 library, which is a foundation of other libraries we will use
    and thus shapes the ways we join them together. After that, we'll go over database
    migrations, project configurations, the implementation of the database logic,
    and the service layer. Naturally we conclude our discourse with the implementation
    of integration testing for the service we've built.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从讨论构成应用程序的基本构建块以及它们如何连接在一起开始。说到块，我们需要简要地谈谈FS2库，它是我们将使用的其他库的基础，因此它决定了我们如何将它们组合在一起。之后，我们将讨论数据库迁移、项目配置、数据库逻辑的实现以及服务层。当然，我们将通过为我们构建的服务实现集成测试来结束我们的讨论。
- en: Project structure
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目结构
- en: 'Our project will include the following components:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的项目将包括以下组件：
- en: Database repository represents an abstraction layer over the database
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库仓库代表数据库上的一个抽象层
- en: Database migrator contains initialization logic for the database table
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库迁移器包含数据库表的初始化逻辑
- en: The REST API defines available HTTP calls and associated business logic
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: REST API定义了可用的HTTP调用和相关业务逻辑
- en: The configuration consolidates application parameters, such as server binding
    and database properties
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置合并了应用程序参数，例如服务器绑定和数据库属性
- en: The server wires all other components together, and spawns and binds an HTTP
    server to the configured address
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器将所有其他组件连接在一起，并在配置的地址上启动和绑定HTTP服务器
- en: 'We''ll start by adding following dependencies to `build.sbt` (the exact versions
    can be found in the GitHub repository):'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将以下依赖项添加到`build.sbt`（确切版本可以在GitHub仓库中找到）：
- en: '[PRE0]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This list definitely looks longer than what you would expect for an example
    project. Let''s inspect carefully why we need each of the dependencies we''ve
    put into it:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表肯定比您期望的示例项目要长。让我们仔细检查为什么我们需要将其中的每个依赖项都放入其中：
- en: http4s is the library we will be using for the HTTP layer
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: http4s是我们将用于HTTP层的库
- en: doobie is a functional JDBC (Java DataBase Connectivity) decorator
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: doobie是一个功能性的JDBC（Java数据库连接）装饰器
- en: H2 is an embedded database which we will use to avoid installing a standalone
    instance
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H2是一个嵌入式数据库，我们将使用它来避免安装独立实例
- en: Flyway is for database migrations (versioned SQL statements used to change the
    database structure)
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flyway用于数据库迁移（用于更改数据库结构的版本化SQL语句）
- en: Circe is a JSON Swiss Army knife
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Circe是一个JSON瑞士军刀
- en: '`PureConfig` is a typed configuration wrapper'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PureConfig`是一个类型化配置包装器'
- en: '`Cats` is a library containing general functional programming abstractions'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Cats`是一个包含通用函数式编程抽象的库'
- en: FS2 – functional streams
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FS2 – 功能流
- en: You may be wondering why we have a section about the FS2 library if we're not
    using it as a component for our application. Well, in fact, we are. It is an underlying
    building block for the database and HTTP libraries we're using, and therefore
    it is important to briefly discuss it to give you an understanding of how the
    other building blocks are connected.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能想知道，如果我们不将FS2库作为应用程序的组件使用，为什么我们还要有一个关于FS2库的部分。实际上，我们是。它是我们使用的数据库和HTTP库的底层构建块，因此简要讨论它对于您了解其他构建块是如何连接在一起的是很重要的。
- en: '[FS2](https://github.com/functional-streams-for-scala/fs2) is a streaming library
    that allows us to construct and transform complex streams. The streams in FS2
    do not only contain elements, but also can embody effects such as IO. This feature
    makes it possible to describe almost everything as an FS2 stream. Libraries such
    as `http4s` and `doobie` are built upon this and give a higher-level API to the
    user. But this API is still a streaming one.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[FS2](https://github.com/functional-streams-for-scala/fs2)是一个流库，允许我们构建和转换复杂的流。FS2中的流不仅包含元素，还可以体现效果，如IO。这个特性使得几乎可以将任何东西描述为FS2流。像`http4s`和`doobie`这样的库建立在它之上，并为用户提供更高级别的API。但这个API仍然是流式的。'
- en: The stream is represented as `Stream[F,O]`, where `F` describes a possible effect
    of the stream and `O` is a type of its elements or output. This definition needs
    to be given two type parameters in order to fully specify it. If the stream has
    no effects, it will be pure: `Stream[Pure, O]`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 流被表示为`Stream[F,O]`，其中`F`描述了流的可能效果，`O`是其元素或输出的类型。为了完全指定它，需要给出两个类型参数。如果流没有效果，它将是纯的：`Stream[Pure,
    O]`。
- en: 'Let''s construct a stream of `chars`:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们构建一个`chars`流：
- en: '[PRE1]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Pure streams can be converted to the `List` or `Vector` without evaluation:
    `chars.toList`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 纯流可以在不评估的情况下转换为`List`或`Vector`：`chars.toList`
- en: 'Streams with effects can''t be converted the same way because of the presence
    of effects. The effects first need to be *reduced* to a single effect. At the
    same time, we need to define how the output of the stream should be dealt with.
    Finally, we can execute the effect and get the output of the stream. This process
    is similar to the definition and materialization of the Akka streams we looked
    at in [Chapter 13](8b5e55e4-de37-4ab1-8baa-7e0c3ad3a6ed.xhtml), *Basics of Akka
    Streams*. Because we have quite a number of things to define, the syntax is a
    bit cumbersome, but it reflects the logic we described:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 由于存在效果，带有效果的数据流不能以相同的方式进行转换。首先需要将效果*减少*到单个效果。同时，我们需要定义如何处理流的输出。最后，我们可以执行效果并获得流的输出。这个过程类似于我们在第13章中看到的Akka流的定义和具体化，*Akka
    Streams基础*。因为我们有很多东西要定义，所以语法有点繁琐，但它反映了我们描述的逻辑：
- en: '[PRE2]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let''s go over this snippet line by line and look at what is happening. The
    numbers in the code will correspond to the numbers in the following explanation:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐行分析这个片段，看看发生了什么。代码中的数字将对应于以下解释中的数字：
- en: We are using the cats `IO` as type of our effect.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用cats的`IO`作为效果的类型。
- en: We define an `IO` as a by-name parameter to write to the console and return
    `aa`.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将`IO`定义为带名称的参数，用于写入控制台并返回`aa`。
- en: We `eval` our `IO`. This creates a single-element stream.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们`eval`我们的`IO`。这创建了一个单元素流。
- en: By compiling the stream, we create its projection to a single effect.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过编译流，我们创建其投影到单个效果。
- en: By converting a `ToEffect` projection to `Vector` it is compiled to the expected
    effect type. The process can be thought of as executing a stream of effects and
    logging emitted results into the desired structure.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将`ToEffect`投影转换为`Vector`，它被编译为预期的效果类型。这个过程可以被视为执行一系列效果并将发出的结果记录到所需的结构中。
- en: We demonstrate another way to define conversion to collection.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们展示了另一种定义转换为集合的方法。
- en: '`drain` is used to discard any emitted values and is useful if we are only
    interested in executing effects.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`drain`用于丢弃任何发出的值，如果我们只对执行效果感兴趣，它非常有用。'
- en: There are also other possibilities to define what should happen with output
    elements of the stream, for example, just collecting the `last` one.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还有其他可能性来定义应该对流的输出元素做什么，例如，只收集最后一个。
- en: '`unsafeRunSync()` runs the definition, synchronously producing effects and
    emitting output. This is the first moment anything appears in the console because
    so far we''ve just created and modified the definition of the stream.'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`unsafeRunSync()`运行定义，同步产生效果并发出输出。这是第一次在控制台出现任何内容，因为我们到目前为止只是创建和修改了流的定义。'
- en: The definition is immutable and can be shared. Because of this, we can run the
    same stream description multiple times (with respect to the kind effects).
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义是不可变的，可以共享。正因为如此，我们可以多次运行相同的流描述（相对于效果类型）。
- en: 'All of this is usually defined as a one-liner: eval the effect, compile the
    stream to the single effect, define the type of the output for the elements, run
    the stream later.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有这些通常都定义为一行：评估效果，将流编译为单个效果，定义元素的输出类型，稍后运行流。
- en: Now let's see how FS2 are utilized by `http4s` and `doobie`. We'll start with
    the database layer as its implementation will guide the structure of other layers.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看 `http4s` 和 `doobie` 如何利用 FS2。我们将从数据库层开始，因为它的实现将指导其他层的结构。
- en: Database migrations
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据库迁移
- en: In order for the database to be used in the application, it needs to contain
    all required tables, indexes, and other definitions.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使数据库能够在应用程序中使用，它需要包含所有必需的表、索引和其他定义。
- en: 'We''ll represent our store as a simple table with the name of the item serving
    as a primary key and a non-negative count of each item:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将我们的存储表示为一个简单的表，其中项目的名称作为主键，每个项目的非负计数：
- en: '[PRE3]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We'll place this definition into `db_migrations/V1__inventory_table.sql` and
    use Flyway to check that our database is in the correct state during startup time.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这个定义放入 `db_migrations/V1__inventory_table.sql`，并使用 Flyway 在启动时检查我们的数据库是否处于正确的状态。
- en: Flyway provides a mechanism to define and change database schema in well-defined
    steps by adhering to specific naming conventions while placing  schema migrations
    SQL in the project folder. You can learn more about it at [https://flywaydb.org](https://flywaydb.org).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Flyway 通过遵循特定的命名约定，将数据库模式迁移 SQL 放置在项目文件夹中，提供了一种机制来定义和更改数据库模式。您可以在[https://flywaydb.org](https://flywaydb.org)了解更多相关信息。
- en: 'The Flyway code for migrations is straightforward:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Flyway 迁移的代码非常简单：
- en: '[PRE4]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Given a `transactor` (which we'll describe a bit later, at the moment we'll
    talk about `doobie`), we use the datasource it provides to create an instance
    of `Flyway`, configure it to use proper migrations location, and perform the migration.
    Please note that the initialization logic is wrapped into the `IO` effect and
    thus delayed until the effect is evaluated.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个 `transactor`（我们将在稍后进行描述，目前我们将讨论 `doobie`），我们使用它提供的数据源来创建一个 `Flyway` 实例，配置它使用适当的迁移位置，并执行迁移。请注意，初始化逻辑被封装在
    `IO` 效应中，因此延迟到效应被评估时。
- en: 'The transactor is created using the utility provided by doobie from the configuration:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 doobie 提供的实用工具创建 transactor：
- en: '[PRE5]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Again it is wrapped in `IO` so no effects will be evaluated until we run the
    result of this function.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 再次封装在 `IO` 中，因此直到我们运行此函数的结果，不会有任何效应被评估。
- en: Before going over to the definition of the database repository, let's have a
    quick look at the configuration abstraction we've used in the `transactor` method.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们转到数据库仓库的定义之前，让我们快速看一下我们在 `transactor` 方法中使用的配置抽象。
- en: Configuration with PureConfig
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 PureConfig 进行配置
- en: 'We''re already familiar with the Typesafe Config library, which we actively
    used in our bakery examples. It is a very useful and flexible library. Unfortunately,
    because of this flexibility, it has one shortcoming: each configuration bit needs
    to be read and converted to the appropriate type individually. Ideally, we''d
    like our configuration to be represented as case classes and rely on naming conventions
    to map the structure of the configuration file to the structure of the (typed)
    configuration we have in the application. Ideally, we''d like to fail fast at
    startup time if the configuration file can''t be mapped to the case classes that
    describe the configuration at the code level.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经熟悉 Typesafe Config 库，我们在面包店示例中积极使用了它。这是一个非常有用且灵活的库。不幸的是，由于这种灵活性，它有一个缺点：每个配置位都需要单独读取并转换为适当的类型。理想情况下，我们希望我们的配置以案例类的形式表示，并依赖于命名约定将配置文件的结构映射到应用程序中（有类型的）配置结构。理想情况下，我们希望在启动时快速失败，如果配置文件无法映射到代码级别的配置描述的案例类。
- en: The `pureconfig` library makes this possible. This library can be found at [https://github.com/pureconfig/pureconfig](https://github.com/pureconfig/pureconfig).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`pureconfig` 库使得这一点成为可能。这个库可以在[https://github.com/pureconfig/pureconfig](https://github.com/pureconfig/pureconfig)找到。'
- en: 'Using it, we can define the configuration structure in Scala like the following:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用它，我们可以在 Scala 中定义配置结构，如下所示：
- en: '[PRE6]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This definition reflects the structure of the configuration in [HOCON](https://github.com/lightbend/config/blob/master/HOCON.md)
    format:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这个定义反映了 [HOCON](https://github.com/lightbend/config/blob/master/HOCON.md) 格式中的配置结构：
- en: '[PRE7]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now we can load and map it to the case classes directly using `pureconfig`:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用 `pureconfig` 直接将其加载并映射到案例类：
- en: '[PRE8]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Again, wrapped in `IO` and thus delayed, we're trying to load and map the configuration
    and raise an appropriate error in the context of an `IO` in the case this attempt has
    failed.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 再次封装在 `IO` 中，因此延迟，我们正在尝试加载和映射配置，并在 `IO` 的上下文中引发适当的错误，如果这个尝试失败。
- en: The configuration bit concludes the infrastructural part of the example and
    we can finally turn to the core—the database repository.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 配置位完成了示例的基础设施部分，我们最终可以转向核心——数据库仓库。
- en: Doobie – functional database access
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Doobie – 函数式数据库访问
- en: 'The database layer in our example is implemented with the Doobie library. Its
    official website describes it as *a pure functional JDBC layer for Scala and Cats*. It
    allows us to abstract existing JDBC functionality in a nice functional way. Let''s
    show how this is done. The library can be found at[ https://tpolecat.github.io/doobie/](https://tpolecat.github.io/doobie/).
    In the following examples, please assume the following imports to be in scope:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，数据库层是用Doobie库实现的。它的官方网站将其描述为*Scala和Cats的纯函数式JDBC层*。它允许我们以优雅的函数式方式抽象现有的JDBC功能。让我们看看这是如何实现的。该库可以在[https://tpolecat.github.io/doobie/](https://tpolecat.github.io/doobie/)找到。在以下示例中，请假设以下导入是有效的：
- en: '[PRE9]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We also need some model classes to persist, and for the purpose of the example,
    we''ll keep the ADT as small as possible:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要一些模型类来持久化，为了示例的目的，我们将ADT保持尽可能小：
- en: '[PRE10]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This model will allow us to represent the inventory of our shop as a map with
    keys referring to the article name and a values denoting number of the respective
    items in stock. We'll also have two operations that can be applied to the inventory—the
    Purchase operation will reduce the number of corresponding items and the Restock
    operation will increase number of respective items by combining our existing stocks
    together.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型将允许我们以映射的形式表示我们商店的库存，键指的是文章名称，值表示相应物品的库存数量。我们还将有两个可以应用于库存的操作——购买操作将减少相应物品的数量，而补货操作将通过组合我们的现有库存来增加相应物品的数量。
- en: 'Now we can define our repository for this model. We''ll do this in the same
    pure functional way we did before:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以为这个模型定义我们的仓库。我们将以之前相同纯函数的方式来做这件事：
- en: '[PRE11]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The repository is given `Transactor[IO]` as a constructor parameter. The `IO`
    in this example is `cats.effect.IO`. The transactor knows how to work with database
    connections. It can manage connections in the same logical way a connection pool
    does. In our implementation, `Transactor` is used to convert an FS2 `Stream[IO,
    ?]` into the `IO`, which will connect to the database and execute SQL statements
    if run. Let''s see in detail how this is done for article-creation:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 仓库被赋予`Transactor[IO]`作为构造参数。在这个例子中，`IO`是`cats.effect.IO`。事务处理者知道如何与数据库连接一起工作。它可以以与连接池相同的方式管理连接。在我们的实现中，`Transactor`被用来将FS2的`Stream[IO,
    ?]`转换为`IO`，如果运行，它将连接到数据库并执行SQL语句。让我们详细看看这是如何为文章创建完成的：
- en: '[PRE12]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let''s go over this definition line by line to see what is going on here:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐行查看这个定义，看看这里发生了什么：
- en: We define a `Fragment`, which is an SQL statement that can include interpolated
    values. Fragments can be combined together.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义了一个`Fragment`，它是一个可以包含插值值的SQL语句。片段可以组合在一起。
- en: From `Fragment`, we construct an `Update`. `Update` can be used to construct
    a `ConnectionIO` later.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`Fragment`，我们构建了一个`Update`。`Update`可以用来稍后构建一个`ConnectionIO`。
- en: We construct a `ConnectionIO` by calling the `run` method on  `update`. `ConnectionIO`
    is basically an abstraction over the possible operations available on the JDBC
    connection.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过在`update`上调用`run`方法来构建一个`ConnectionIO`。`ConnectionIO`基本上是对JDBC连接上可能进行的操作的一种抽象。
- en: By calling an `attempt` method, we're adding error-handling to our `ConnectionIO`.
    This is the reason the type parameter of `ConnectionIO` has changed from `Int`
    to `Either[Throwable, Int]`.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过调用`attempt`方法，我们在`ConnectionIO`中添加了错误处理。这也是为什么`ConnectionIO`的类型参数从`Int`变为`Either[Throwable,
    Int]`的原因。
- en: By providing a `transactor` to the `transact` method, we convert `ConnectionIO` into `IO`,
    which represents a runnable doobie program.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过向`transact`方法提供一个`transactor`，我们将`ConnectionIO`转换为`IO`，这代表了一个可运行的doobie程序。
- en: We coerce different sides of `Either` to a single Boolean value. We expect the
    number of created rows to be exactly one, in which case the call was a success.
    If we failed to create a row or if there was an exception thrown, it is a failure.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将`Either`的不同方面强制转换为单个布尔值。我们期望创建的行数正好为一行，在这种情况下，调用是成功的。如果我们未能创建行或抛出了异常，则视为失败。
- en: It would be more appropriate in the erroneous case to differentiate between
    the *unique index or primary key violation* and other cases but unfortunately
    different database drivers have different encoding for that, so it is not possible
    to provide concise generic implementation.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在错误情况下，区分*唯一索引或主键违反*和其他情况可能更合适，但不幸的是，不同的数据库驱动程序对这一点的编码不同，因此无法提供简洁的通用实现。
- en: 'Other methods in our repository will follow the same pattern. `deleteArticle`
    is a one-liner and we don''t bother to handle errors in this case (exceptions
    will bubble up to the upper layers and be propagated to the client if they will
    be thrown), so we can just check whether the number of affected rows was exactly
    one:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仓库中的其他方法将遵循相同的模式。`deleteArticle`是一个单行代码，我们在这个情况下不处理错误（异常将向上层冒泡，并在抛出时传播给客户端），所以我们只需检查受影响的行数是否正好为一：
- en: '[PRE13]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`getInventory` is a bit different because it needs to return the results of
    the query:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '`getInventory`有点不同，因为它需要返回查询的结果：'
- en: '[PRE14]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Here, we see that the query is of the `doobie.Query0[(String, Int)]` type with
    the type parameter representing the column types of the result. We convert the
    query to `Stream[ConnectionIO, (String, Int)]` (an FS2 stream with the `ConnectionIO`
    effect type and the tuple as a type of elements) by calling a `stream` method
    and then convert `ConnectionIO` to `IO` by providing a transactor. At last, we
    fold elements of the stream into `Map`, thus constructing the inventory state
    at the present moment from individual rows.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到查询是`doobie.Query0[(String, Int)]`类型，类型参数表示结果列的类型。我们通过调用`stream`方法将查询转换为`Stream[ConnectionIO,
    (String, Int)]`（一个带有`ConnectionIO`效果类型和元组作为元素类型的FS2流），然后通过提供一个事务转换器将`ConnectionIO`转换为`IO`。最后，我们将流中的元素折叠到`Map`中，从而从单个行构建当前时刻的库存状态。
- en: Updating the inventory has another caveat. We would like to update multiple
    articles at once so that if there is insufficient supply for some of the articles,
    we discard the whole purchase.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 更新库存还有一个需要注意的地方。我们希望一次性更新多个文章，这样如果某些文章的供应不足，我们就放弃整个购买。
- en: This is a design decision. We could decide to return a partially-fulfilled order
    to the client.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个设计决策。我们可以决定将部分完成的订单返回给客户。
- en: 'The count of every article needs to be updated separately, therefore we need
    to have multiple update statements running in a single transaction. This is how
    it is done:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 每个文章的计数都需要单独更新，因此我们需要在单个事务中运行多个更新语句。这是如何实现的：
- en: '[PRE15]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We're given a map of `name -> count` pairs as a parameter. The first thing we
    do is to convert each of these pairs into an update operation by mapping over
    them. This leaves us with a collection of `CollectionIO[Int]`. We then combine
    these updates together by using the cats `Apply` operator, which produces a single `CollectionIO[Int]`.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到一个`name -> count`对的映射作为参数。我们首先将这些对中的每一个转换为更新操作，通过映射它们。这给我们留下了一个`CollectionIO[Int]`的集合。然后我们使用cats的`Apply`操作符将这些更新组合在一起，它产生一个单一的`CollectionIO[Int]`。
- en: JDBC by default has auto-commit enabled, which will lead to the effect that
    our updates in the batch will be executed and committed one by one. This can lead
    to partially-fulfilled orders. In order to avoid that, we wrap the updates into
    the stream, which will disable auto-commits before the updates and enable auto-commits
    again after all of them are executed. We then lift the error-handling of the result
    and convert it into the runnable `IO` as before.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: JDBC默认启用自动提交，这将导致我们的批量更新逐个执行和提交。这可能导致部分完成的订单。为了避免这种情况，我们将更新包装到流中，这将禁用在更新之前自动提交，并在所有更新执行完毕后再次启用自动提交。然后我们提升结果的错误处理，并将其转换为之前的可运行`IO`。
- en: The result of the method is the `Stream[IO, Either[Throwable, Unit]]` type.
    The type of the elements of the stream encodes the possibilities to have both
    updates that weren't possible because there were insufficient articles in the
    inventory as `Left` and a successful update as `Right` .
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法的结果是`Stream[IO, Either[Throwable, Unit]]`类型。流中元素的类型编码了两种可能性：由于库存中文章不足而无法进行的更新作为`Left`，以及成功的更新作为`Right`。
- en: With these four methods, we actually have all the required basic functionality
    and can start to use it in the API layer.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这四个方法，我们实际上拥有了所有必需的基本功能，并可以开始在API层使用它们。
- en: http4s – streaming HTTP
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: http4s – 流式HTTP
- en: The implementation of the HTTP interface in our project is based on the http4s
    ([https://http4s.org)](https://http4s.org)) library. http4s is built on top of
    the FS2 and Cats IO and therefore we have a nice interplay with the persistence
    layer implemented with doobie. With http4s, it is possible to build functional
    server-side services using high-level DSL, as well as use it on the client-side
    to call HTTP APIs. We will use the client functionality to build an integration
    test for our API later in this chapter.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们项目中HTTP接口的实现基于http4s ([https://http4s.org](https://http4s.org))库。http4s建立在FS2和Cats
    IO之上，因此我们与使用doobie实现的持久层有很好的交互。使用http4s，我们可以使用高级DSL构建功能性的服务器端服务，也可以在客户端调用HTTP
    API。我们将在本章后面使用客户端功能来构建我们的API的集成测试。
- en: The server side is represented by `HttpService[F]`, which is essentially just
    a mapping from `Request` to `F[Response]` and `F` is a cats `IO` in our case.
    http4s DSL helps to construct such RESTful services by using pattern-matching.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器端由`HttpService[F]`表示，这本质上只是从`Request`到`F[Response]`的映射，在我们的情况下`F`是cats的`IO`。http4s
    DSL通过使用模式匹配帮助构建这样的RESTful服务。
- en: 'This is how it looks in practice. First we need to have following imports for
    `fs2` and `IO`, and http4s DSL and circe in scope:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在实际中的样子。首先我们需要为`fs2`和`IO`，以及http4s DSL和circe添加以下导入，并将它们放入作用域：
- en: '[PRE16]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'With these imports in place, we can start to build up our service definition:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些导入就绪后，我们可以开始构建我们的服务定义：
- en: '[PRE17]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The service is given a database repository as a parameter.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 该服务以数据库存储库作为参数提供。
- en: 'The routes are defined separately for each HTTP verb and a URL template. We
    start with the definition of the service method, which takes a partial function
    from request to response:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个HTTP动词和URL模板，路由被单独定义。我们首先定义服务方法，该方法从请求到响应接收一个部分函数：
- en: '[PRE18]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then we follow with the simple route for article deletion:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们继续使用简单的文章删除路由：
- en: '[PRE19]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Here we are using `http4s` DSL in order to deconstruct `Request` into parts
    and pattern-match against these parts. The `->` object extracts the path from
    the request and the `/` class allows us to represent the concatenation of subpaths
    of the request URL (there is also `/:`, which matches the URL from the point of
    application and to the end of the url). The pattern-match itself is just a normal
    Scala case, hence we can use its full power. In this case, we're mapping the last
    part of the URL to `name` and have a guardian to make sure the path only matches
    if `name` is not empty (because we don't want to have anonymous articles in our
    shop!).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用`http4s` DSL来分解`Request`为部分，并对这些部分进行模式匹配。`->`对象从请求中提取路径，`/`类允许我们表示请求URL的子路径的连接（还有`/:`，它匹配从应用点开始的URL到URL的末尾）。模式匹配本身只是一个普通的Scala
    case，因此我们可以使用其全部功能。在这种情况下，我们将URL的最后一部分映射到`name`，并有一个保护者来确保只有当`name`不为空时路径才匹配（因为我们不希望在商店中拥有匿名文章！）。
- en: The expected result of the function is the `IO[Response[IO]]` type. Luckily,
    the return type of the `deleteArticle` method of our repository is `IO[Boolean]`,
    so we can just `flatMap` the returned boolean value into the response body *inside*
    of an `IO`. In this case, we don't want to respond with the body, but just inform
    the caller about the success of the operation, which is represented with the respective
    response codes: `204 No Content` and `404 Not Found`. http4s provides a nice constructors
    for this with a bit of a verbose type: `IO[Response[IO]]`. In our case, we define
    a function from `Boolean` to this type and use this function to `flatMap` the
    result of the repository call, which leaves us with `IO[Response[IO]]` as an end
    result, which is exactly the type expected to be returned.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 函数的预期结果是`IO[Response[IO]]`类型。幸运的是，我们存储库的`deleteArticle`方法的返回类型是`IO[Boolean]`，因此我们可以在`IO`内部将返回的布尔值`flatMap`到响应体中。在这种情况下，我们不想响应体，只想通知调用者操作的成功，这通过相应的响应代码表示：`204
    No Content`和`404 Not Found`。http4s提供了一个带有一些冗长类型的良好构造函数：`IO[Response[IO]]`。在我们的情况下，我们定义一个从`Boolean`到这种类型的函数，并使用这个函数`flatMap`存储库调用的结果，这样我们最终得到`IO[Response[IO]]`作为最终结果，这正是预期返回的类型。
- en: 'Of course, all of this logic can be written in a succinct manner. Here is an
    example for the API call to create an article:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，所有这些逻辑都可以以简洁的方式编写。以下是一个创建文章API调用的示例：
- en: '[PRE20]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The approach is absolutely the same as the one we had for article deletion.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法与我们之前用于文章删除的方法完全相同。
- en: The API we're building is not a principle RESTful API. For this example to be
    a valid, level two API, we need to also implement a `GET` call that retrieves
    a representation for the individual articles. This can be done by adding a corresponding
    method to the repository and a `case` to the service. The implementation is left
    to the reader as an exercise.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have created a few articles in the repository, we would like to
    be able to retrieve the current state of it. We can implement it as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The above pattern-match is straightforward and so is the call to the `getInventory`
    method of the repository. But it returns the result of the `Stream[IO, Inventory]` type
    and we need to convert it to the matching type for `HttpService[IO]`. `http4s`
    has a concept of `EntityEncoder` for this.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the corresponding implementation:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Here, we prepare the inventory to be represented as an HTTP response by converting
    the returned `Map[String, Int]` to JSON. We rely on circe ([https://github.com/circe/circe](https://github.com/circe/circe))
    to perform automatic conversion. Next, the stream is converted to the appropriate
    response type by the `Ok` status constructor and an implicit `EntityEncoder[IO,
    String]`. We explicitly force the content type of the response to be `application/json`
    in order to have it correctly represented in the response.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we want to provide a way to modify the state of the inventory like
    we did with the repository. We''ll implement two API calls, one for replenishing
    the inventory and another for purchases. They are implemented similarly, so we''ll
    cover only one of them; the other can be found in the [GitHub](https://github.com/PacktPublishing/Learn-Scala---Fundamentals-of-Scala-2.12/blob/master/ch14/http4s-doobie/src/main/scala/ch14/Service.scala#L22)
    repository. Here is the implementation for the restock call:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We need a request to read its body, therefore we bind it to the `req` variable
    in the pattern match. Next, we decode the JSON body of the request and map it
    to our model. Here we rely on circe to do the heavy lifting again. The `updateStock`
    repository method returns the stream, so we need to bring our parameter in the
    same context in order to be able to use it nicely in the `for` comprehension.
    We're doing this by wrapping the result of the decoding into `Stream.eval`.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Then we call the repository and provide the required changes in the form of `Inventory`.
    This method returns `Stream[IO, Either[Throwable, Unit]]`, so we ignore the result
    (it will shortcut the for comprehension in the case of an error). Finally, we
    read the new state of the repository and render it for the caller as before.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: The read-after-write is a known database anti-pattern. We used this approach
    to illustrate how streaming calls can be nicely chained in a for comprehension.
    In a real project, it might be better to formulate SQL statements in a way that
    the new state is returned immediately after the update.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: The service layer is implemented now. We can wire our application together and
    see how it works.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Bringing it all together
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The server code will require a few new imports in addition to our usual set:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '`BlazeBuilder` is a server factory, and `ExecutionContext` will be needed at
    the moment we start the server. The server is defined as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '`StreamApp` requires us to implement a `stream` method, with the solely purpose
    to produce side-effects and provides cleanup hooks for this stream. This is our
    implementation:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We just read the configuration and delegate the actual server creation to `ServerInstance`.
    Let''s have a look at it:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Here again we see the same approach: we lift `config` into the context of `Stream`,
    create a transactor, initialize the database, build the repository from the transactor
    and the service from the repository, and finally mount the service by using the
    `BlazeBuilder` factory.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: The caller method will then execute the serve method of the server, starting
    the whole IO program we've built so far.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: We were following a pattern for providing dependencies as we've build up this
    example—we gave them as constructor parameters at the moment we constructed class
    instances. The approach of passing dependencies as constructor parameters is called constructor-based
    dependency-injection in Scala.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Now our application can be started and played with. But we want to be sure that
    it behaves correctly by testing it.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This example is quite simple and basically just an HTTP facade over the database,
    so we won't test components in isolation. Instead, we'll use integration-testing
    to check the system as a whole.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: In order to have SBT properly recognize our integration tests, we need to add
    the proper configurations to `build.sbt`. Please refer to the chapter code on
    GitHub ([https://github.com/PacktPublishing/Learn-Scala-Programming](https://github.com/PacktPublishing/Learn-Scala-Programming))
    to see how this is done.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: In our integration test, we will let our system run normally (but with the test
    database) and use an HTTP client to call the API and inspect the responses it
    will return.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to prepare our HTTP client and server:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Here we create the client we'll be using to query our API by instantiating the `Http1Client`
    provided by the `http4s` library. We also read a test config that overrides database
    settings so that we can freely modify the data. We're using an in-memory H2 database,
    which is destroyed after our test finishes so that we don't need to clean up the
    state after the test. Then we're building a server by re-using `ServerInstance`.
    In contrast to the production code, we're starting it with the `start` method,
    which returns a server instance. We'll use this instance after the test to shut
    down the server.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Please note how we use `unsafeRunSync()` in multiple places to evaluate the
    contents of `IO`. For the server, we're even doing this twice, once for `IO` and
    once for `Stream[IO, ...]`. This is okay to do in the test code as it helps to
    keep the testing logic concise.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to shut down the client and the server after the test:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Again, we're running an IO here because we want the have the shutdown happen
    right now.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at one of the test methods:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Here we first create a test request using a factory provided by http4s. We then
    check that the API returns the correct `NoContent` status if we send this request
    with the client we created earlier in this section. We then create the second
    article by using the same approach.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we're using the client to call the URL directly and let it parse the
    response to the JSON form. Finally, we check that the inventory has a correct
    state by comparing the JSON response with circe's JSON literal.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: For testing other API calls, we could also provide a request body using circe
    JSON literals. Please refer to the chapter's source code placed on GitHub to see
    how this is done.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: It is absolutely possible to implement the same testing logic using other HTTP
    clients or even command-line tools. The `Http1Client` provided by `http4s` allows
    for nice syntax and concise expectation definitions.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Running the application
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The easiest way to run our API is in the SBT shell by issuing a `run` command.
    The project for this chapter is configured as a multi-module SBT project. Because
    of this, the `run` command has to be prefixed by the module name so that it is
    fully spelled as `http4s/run` as shown in the next screenshot:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2401065b-ee26-436e-9bd8-a7ba24222d2a.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
- en: 'Different components of our API will output lots of information. The application
    is started after the address of the HTTP server is shown. You can see how this
    looks on the bottom of the next screenshot:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0d09d8e4-e358-4398-aa5f-3a2cf2fc00c7.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
- en: 'After that, the API should serve HTTP requests, for example, issued with curl
    in another terminal window as the following screenshot demonstrates:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dbf77382-7def-433e-a4d5-22c0b15f4c32.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
- en: As our example uses in-memory database, it will lose its state after restart.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Building microservices with Akka-HTTP and Akka Persistence
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we've seen how the principle functional approach to the implementation
    of the microservice works, let's change our technological stack and implement
    the same shop with Akka-HTTP and Akka Persistence. The flow of the discussion
    for this example will be similar to the one we had about the functional approach—we
    will start with looking at the way to persist the state of the service and the
    configuration needed for that. We'll then address the task of actually persisting
    the data and providing access to it via the HTTP service. As before, we'll conclude
    our journey by testing the implementation we'll come up with.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Project structure
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The project structure, in this case, will be almost the same as we had before.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: We'll have an API layer responsible for the interaction with HTTP clients. We'll
    also inevitably have some configuration and a database initialization code that
    will be implemented in a similar, or identical, way to what we did as we've built
    the previous microservice.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: The persistence layer will be represented by a persistent actor. This will affect
    the definition of the model as well as the structure of the database tables.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Akka Persistence introduces different paradigms of how the state of the system
    is stored and represented. The approach is called **Event-Sourcing** and it makes
    sense to take a minute to discuss it.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Event-Sourcing and CQRS
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Event-sourcing is about how the state of the system is stored. Normally the
    state of the system is persisted into the database as a number of related tables.
    Changes to the state are reflected in the database by modifying, adding, or deleting
    table rows. The database contains the current state of the system with this approach.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Event-sourcing provides an alternative method. It handles updates of the state
    very much like functional programming handles effects. Instead of executing a
    computation, it just describes it so that it is possible to execute it later.
    Descriptions of computations can be combined, as we saw in the second section
    of this book. The same way the changes of the state can be combined in an event-sourced
    approach to produce current state. In essence, event-sourcing is to the state
    what functional programming is to the computations and effects.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: This description of the state change is called **event** and it usually (but
    not necessarily!) corresponds to some user action, called **command**. The system
    receives commands, validates them, and if the command makes sense in the context
    of current system state, respective event(s) is created and persisted into the
    event journal. The event is then applied to the in-memory representation(s) of
    the state and the required side-effects are executed.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: When the event-sourced system is restarted, the events are read from the journal
    and applied to the initial state one by one, modifying it but not executing side-effects.
    At the end, after all events are applied, the internal state of the system should
    be the same as it was before the restart. Hence, *events* are the *source* of
    the state representation of the system in this scenario. The reconstructed state
    often represents only one aspect of the whole system and is called **view**.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: The event journal is used only for appending events. Because of this, it is
    usually seen as an append-only storage, and often solutions other than relational
    databases are used.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: CQRS is another name that goes hand in hand with Event-Sourcing. This is an
    abbreviation for Command Query Responsibility Segregation, which in turn is just
    a fancy way to name a principle of *Command–Query Separation* implemented with
    Command and Query entities (as opposed to the method calls). The CQS principle
    states that every method should be either *command*, which modifies the state,
    or *query*, which returns the state, and these responsibilities should not be
    mixed. With Event-Sourcing, this separation comes naturally from the definition
    of the *Event* (which is the Command in the CQS definition) and the concept of
    internal state as a *View* that needs to be queried separately.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: 'Event-Sourcing has a lots of advantages over the traditional database-mutating
    approach:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Append-only approach to store data scales much better than traditional relational
    databases.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Events provide audit, traceability, and in the case of special storages, security
    for free.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No need to use an ORM.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The domain model and event model can evolve at a different pace.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is possible to recover the state of the system to any specific moment in
    the past.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Events can be combined in different ways, allowing us to construct different
    representations of state. Combined with the previous advantage, it gives us the
    ability to analyze past data in ways that weren't known at the time of the event's
    creation.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Of course, there are some drawbacks as well:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: The state does not exists until it is reconstructed from events. Depending on
    the format of the journal, it might even impossible to analyze the events without
    writing special code for this purpose. In any case, it requires some effort to
    build the state representation from events.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explosion of domain model in complex projects. Implementing new use-cases always
    requires the introduction of new commands and events.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changes in the model as the project evolves. Changes in existing use-cases often
    mean changes in the structure of existing evens, which need to be done in the
    code because the event journal is append-only.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of events can grow rapidly. In actively-used systems, there may be
    millions of events produced daily, which can affect the time needed to build the
    state representation. Snapshotting is used to work around this issue.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring Akka Persistence
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Akka Persistence allows us to store and replay messages sent to `PersistentActor`
    and thus implements an event-sourcing approach. Before going into the details
    of the actors implementation, let's look at the arrangements we need to make in
    the project configuration.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: We're going to use the H2 relational database for this project. Akka Persistence
    supports many different storage plugins, including a local filesystem for storing
    snapshots, and in our case, it appears to be a good idea to use the same database
    we used with doobie to underline the differences in the architectural style.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, we''re using Flyway to create the structure of the database. The tables
    will be different though. This is the table that will store events:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '`persistence_id` is an ID of a specific persistent actor, which needs to be
    unique for the whole actor system (we''ll see in a minute how this maps to the
    code), the `tags` field holds tags assigned to the events (this makes constructing
    views easier). `message` holds an event in serialized form. The serialization
    mechanism is decoupled from the storage. Akka supports different flavours, including
    Java serialization, Google Protobuf, Apache Thrift, or Avro and JSON. We''ll use
    the JSON format in order to keep the example small.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: 'The snapshots table is even simpler:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Basically, it's just a snapshot in serialized form, with a timestamp and the
    `persistence_id` of the actor it belongs to.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'With these tables in the migrations file, we now need to add following dependencies
    to `build.sbt`:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The `akka-persistence` dependency is obvious. `akka-persistence-jdbc` is an
    implementation of the JDBC storage for the h2 database. `Flyway-core` is used
    to set up the database like in the previous example. `stamina-json` allows for
    schema migrations—it gives us a way to describe how the events stored in the old
    format in the database should be converted to the new format used in the code
    if needed.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need to put quite a bit of configuration for the Akka persistence in `application.conf` to
    configure journals. This configuration is quite verbose, so we will not discuss
    it here in full, but we will take a look at one part of it that describes serialization:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Here, we configure serialization for the stamina. Let''s take a look at `EventSerializer`:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Here, we tell stamina which serializers to use. The serializers are defined
    as follows:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'In the `PersistenceSupport` object, we define persisters for our events. We
    don''t need any migrations yet, but in the case we would, the migrations would
    be described here. Persister requires implicit `RootJsonFormat` to be available
    and we provide them in the `JsonSupport` trait:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We extend `SprayJsonSupport` and import `DefaultJsonProtocol._` to get implicit
    formats for basic types already defined by `spray-json`. Then we define `RootJsonFormat`
    for all of our commands (these formats will be used by the API layer to un-marshall
    request bodies), events (which will be used by both the API layer to marshall
    responses, and the persistence layer to serialize events), and an Inventory (which
    is required for snapshots to be serializable). Here we're not relying on circe's
    auto-derivation and hence describe each case class individually.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Now we have persisters and formats for the model, but what is that model? It
    reflects the event-sourcing approach!
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: Domain models
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With event-sourcing, we want to store changes of the state as events. Not every
    interaction with the client is an event. Until we know that we can comply, we''re
    modeling it as a command. Specifically, in our example it is represented as sealed
    traits:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'In the spirit of CQRS, we model incoming data as four commands and one query.
    The commands can be made into the events if the current state allows that:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: In our simple case, commands and events correspond to each other, but in the
    real project, this won't always be the case.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: 'We also have a representation of the current state of the store:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '`Inventory` extends `Persistable` so that we can make snapshots later. We will
    keep the business logic separate from the actor-related code. Because of this,
    our inventory should be able to handle events itself:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The `create` method adds an article to the store and assigns some initial counts
    to it if possible. It returns an inventory in the new state in the case of success:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The `delete` method tries to delete an article from the inventory:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The `add` method sums the count of articles from another inventory with counts
    of all articles existing in this inventory:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now our inventory can accept events and return itself in an updated state,
    but we still have to deal with commands first. One possible implementation of
    the logic for command-handling could look like this:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The `canUpdate` method takes a command and returns a corresponding event in
    the case that it is possible to apply the command successfully. For creating and
    deleting articles, we're checking that the operation will produce a valid result;
    for purchases, we're checking that there are enough articles in stock, and restock
    should always succeed.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: Our Inventory is not synchronized and hence it is not safe to work within a
    concurrent scenario. Moreover, if one thread makes modifications to the inventory
    at the time another thread already called `canUpdate`, but has not called `update`
    yet, we might end up with the incorrect state because of this race condition.
    But we don't need to worry about that because we're going to use our inventory
    inside of an actor.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: The persistent actor
  id: totrans-275
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The persistent actor in Akka extends the normal `Actor` and mixes in a `PersistentActor`. `PersistentActor`
    implements the `receive` method but requires a few other methods to be implemented
    by us:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Besides the `inventory` that we need as a representation of state, we need to
    define a unique `persistenceId` and two methods: `receiveRecover` and `receiveCommand`.
    The former is called during the recovery time, for example at startup or if the
    persistent actor is restarted, and it receives all events from the journal. It
    is expected to modify the internal state but not to execute any side-effects.
    The latter is called during the normal lifetime and it receives all the commands.
    It is supposed to convert valid commands to events, persist the events, modify
    the internal state, and execute side-effecting code after that.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, `receiveRecover` just delegates the event processing to `inventory`:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Additionally, it handles instances of `SnapshotOffer` by restoring the inventory
    as a whole from the latest snapshot. `SnapshotOffer` will be the first message
    the actor receives if there are snapshots available, and it will contain the latest
    snapshot so it is safe to restore the inventory from it. The events in the journal
    before the snapshot will not be replayed. Finally, after receiving the `RecoveryCompleted`
    event, we save the current state as a snapshot for use after the next restart.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: 'The `receiveCommand` implementation is a bit more involved:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: We handle the `GetInventory` query by sending a current state to the sender.
    Inventory is a wrapper over an immutable map, so it is safe to share.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: We handle all `Commands` the same way, by letting Inventory do the actual work.
    If a command cannot be applied, we respond to the sender with `None`. In the opposite
    case, we asynchronously persist corresponding events and provide a callback that
    will be executed after the event is persisted. In the callback, we apply the event
    to the internal state and send the new state to the sender. In contrast to the
    normal actor, it is safe to use `sender()` in an async block.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: And this is it, we now have a persistent actor that will restore its state after
    the restart. Time to make it available for HTTP clients.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: Akka-HTTP
  id: totrans-287
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Akka-HTTP provides a nice DSL to describe a server-side API similar to doobie.
    But Akka''s language flows a bit differently. Instead of pattern-matching the
    request by applying rules one by one, it works more like a sieve. It filters requests
    by providing a number of directives, each matching some aspect of the request.
    The directives are nested so that each request travels deeper and deeper into
    matching branches until it reaches the processing logic. Such a combination of
    directives is called route. This is the inventory route:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'This route contains three smaller routes, one matching `GET /inventory`, another
    `POST /purchase`, and the third `POST /restock`. The second and third routes also
    define that the request entity must be parseable as `PurchaseArticles` and `RestockArticles`
    respectively and provide the result of the parsing as a parameter to the body.
    Let''s see how the internals of these routes are implemented. We know that the
    inventory route should return the current state so we ask the inventory actor
    about that:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The `complete` method takes `ToResponseMarshallable`, and we rely on the Akka-HTTP
    and JSON serializers we defined earlier to do the implicit conversion from the `Future[Inventory]` that
    we're getting as the result of the application of the ask pattern here.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: '`inventory` is provided as an abstract field for now. This is how it looks
    in the definition of `Routes`:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: We define an abstract `config` that we then use to define an `implicit timeout`
    for the ask. We also define `ExecutionContext` in order to be able to map over `Future`
    in other routes.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of the other two routes is similar. This is the purchase
    route:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: The logic is almost the same with differences related to the situation we can't
    satisfy the requirements. In this case, we return the `409 Conflict` error code.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: 'The restock route is even simpler because it always succeeds:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The definition of `articleRoute` for article creation and deletion is very similar
    and is available on GitHub so we will omit it here.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: 'The routes are combined together using `~`, the same way we already did inline:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Bringing it all together
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Having the routes implemented, we can now go on with the server definition:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: We mix together the `Routes` and `JsonSupport` traits and define abstract fields.
    The actor system is needed in order to instantiate the materializer, and a materializer
    is a machine driving Akka-HTTP. Then we initialize the database, instantiate our
    persistent actor (which starts to receive events from the journal and restore
    its state), bind and start the server, and wait for the termination of the actor
    system.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: The way we injected dependencies by defining abstract members and then mixing
    traits together is called trait-based DI or the thin cake pattern. Usually, in
    simple cases, we would prefer constructor-based DI, like in the http4s example.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: Compared to the http4s implementation, this server is eager. Every statement
    is executed the moment it is defined (with respect for laziness).
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: Now we have another version of our store done and can test it as well.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Of course, Akka would not be Akka if it did not provide a nice DSL for testing HTTP
    routes. The DSL allows us to test routes in a way that it is not needed to start
    a real server. It is possible to provide a mock implementation of the business
    logic to test routes in isolation. In our case, the logic is so simple that it
    actually makes sense to test the app as a whole, the same way we did in the http4s
    case.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: 'The definition of the specification should not be surprising:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The good news is that `ScalatestRouteTest` already provides a definition for
    the actor system and `materializer` so we don't need to initialize them before
    the test and close after the test. The `Routes` are the same `Routes` we defined
    earlier and are about to test now. We still have abstract definitions of `config`
    and `inventory` here, so provide an implementation for them.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: 'And this is how we can test a route:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: First, we define the `request` we want the route to be checked against. Then
    we transform it with the `route` to the response, which in turn gets transformed
    into `check`. In the body of `check`, we can refer to the properties of the response
    in a simple way.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: The `routes` in `request ~> routes ~> check` refer to the field defined in the `Routes` trait.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, it is possible to create a request with a body and use it to test
    a route that expects such request:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Here we `Marshal` the restock case class to `Entity` the same way it worked
    on routes. `.futureValue` is from the ScalaTest's `ScalaFutures` helper. The rest
    of the snippet is very similar to the previous example.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: Running the application
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To run the Akka-HTTP API, we have to use the same approach as we used for the
    http4s version. The name of the module will be, well, `akkaHttp`, but the principle
    is the same. The next screenshot shows the output in the console after `akkaHttp/run`
    was entered in the SBT shell:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a81ae74e-a962-4552-9ad7-ccab8e778ce6.png)'
  id: totrans-325
  prefs: []
  type: TYPE_IMG
- en: 'The application outputs a few lines and then waits for incoming requests. It
    is now safe to play with it the same way we did with the http4s version:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86d8f174-f069-4e6c-a926-3748f9f4f257.png)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
- en: One subtle but important difference is that the Akka version persists the database
    into the filesystem and retains the state between restarts, as shown by the first
    request on the previous screen.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we briefly discussed the pros and cons of the microservice-based
    approach.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: We've built two small examples with similar functionality but different technological
    stacks.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: The first project was built using a purely functional approach with wrapping
    effects in IO monad and functional streams. This allowed us to describe a system
    as a computation that is only started at the *end of the world*. We used the ORM
    approach in this case by mapping the state of the system to the database table
    and modifying it in response to the required changes. Finally, we demonstrated
    how to use the http4s client to test the system as a whole by building an integration
    test.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: The basis for the second project was the "*official*" Lightbend stack. We looked
    at how well Akka-HTTP and Akka Persistence play together. We demonstrated that
    the event-sourced approach allows us to reconstruct state in memory by recombining
    it from persistent events. This helped us to avoid writing any SQL statements.
    We also looked at how the Akka-HTTP test kit can be used to test routes without
    the need to start the real HTTP server.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-334
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is a database migration?
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe what could be an alternative approach to discard an order completely
    in the case of insufficient stock for some articles.
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe the conceptual difference between http4s and Akka-HTTP with regard
    to defining routes.
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name a reason why event-sourced data storage can scale better than traditional
    relational databases.
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement a `GET /articles/:name` call with http4s and doobie.
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement a `GET /articles/:name` call with Akka-HTTP and Akka Persistence.
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vinicius Feitosa Pacheco, *Microservice Patterns and Best Practices[ **Explore
    the concepts and tools you need to discover the world of microservices with various
    design patterns*.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jatin Puri, Selvam Palanimalai, *Scala Microservices: **Design,* *build*, *and
    run microservices elegantly using Scala*.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Héctor Veiga Ortiz, Piyush Mishra, *Akka Cookbook: **Learn how to use the Akka
    framework to build effective applications in Scala*.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rambabu Posa, *Scala Reactive Programming: Build fault-tolerant, robust, and
    distributed applications in Scala*.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Christian Baxter, *Mastering Akka: **Master the art of creating scalable, concurrent,
    and reactive applications using Akka*.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
