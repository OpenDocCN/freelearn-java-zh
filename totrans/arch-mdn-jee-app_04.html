<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Lightweight Java EE</h1>
                </header>
            
            <article>
                
<p>Lightweight Java EE. Is that even possible? In the past, J2EE applications and especially application servers have been considered a heavyweight and cumbersome technology. And up to some degree deservedly so. APIs were quite unwieldy to use. There was a lot of XML configuration required, which eventually led to the use of <strong>XDoclet</strong>, a tool used to generate XML based on meta information put into JavaDoc comments. Application servers were also cumbersome to work with, especially with regard to startup and deployment times.</p>
<p>However, since the name change to Java EE and especially since version 6, these assumptions are not true anymore. Annotations were introduced, which originally emerged from the XDoclet-motivated JavaDoc tags. And a lot has happened to improve the productivity and developer experience.</p>
<p>This chapter will cover the following topics:</p>
<ul>
<li>What makes a technology lightweight</li>
<li>Why Java EE standards help reducing work</li>
<li>How to choose project dependencies and archive formats</li>
<li>The benefits of zero-dependency enterprise applications</li>
<li>Modern Java EE application servers</li>
<li>The <em>one application per application server</em> approach</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Lightweight enterprise technology</h1>
                </header>
            
            <article>
                
<p>What makes a technology <em>lightweight</em>? And how lightweight, productive and relevant is Java EE in the age of containers and cloud?</p>
<p>One of the most important aspects of a lightweight technology is the productivity and effectiveness it enables. The time the development team spends is precious and expensive and the less time spent on overhead the better. This includes developing glue code, building projects, writing and executing tests, and deploying software, on both local and remote environments. Ideally, engineers can spend as much time as possible on implementing revenue-generating business functionality.</p>
<p>A technology should therefore not add much overhead on top of the business use cases. Technical cross-cutting concerns are certainly necessary but should be kept to a minimum. In the previous chapter, we have seen how Java EE enables developers to implement business use cases in a productive way. Project artifact builds and deployments should in the same way aim to minimize the required time and effort.</p>
<p>This and the following chapter will show <span>how Java EE supports crafting productive development workflows.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Why Java EE standards?</h1>
                </header>
            
            <article>
                
<p>One of the principles of Java EE is to provide a productive enterprise API. As seen in the <em>Concepts and design principles of modern Java EE</em> section in the previous chapter, one of the biggest advantages is the ability to integrate different standards without developer-side configuration required. The Java EE umbrella requires the different standards to work well together. The enterprise container has to meet this requirement. The software engineers only develop against the APIs and let the application server do the <em>hard integration work</em>.</p>
<p>Following the convention over configuration approach, using different, integrated standards that are part of the umbrella specification doesn't require initial configuration. As seen in various examples previously, the technologies that have emerged from different standards within Java EE work well with each other. We have seen examples such as using JSON-B to automatically map objects to JSON in JAX-RS resources; integrating Bean Validation into JAX-RS and therefore HTTP responses by introducing a single annotation; injecting managed beans into instances defined by other standards, such as Bean Validation validators or JSON-B type adapters; or managing technical transactions that span JPA database operations in EJBs.</p>
<p>What is the alternative to using an umbrella standard that embraces various reusable technologies? Well, to introduce vendor-specific frameworks with third-party dependencies that need to be wired together with manual developer work involved. One of the biggest advantages of the Java EE API is having the whole variety of technology right at the developer's fingertips; providing productive integration and saving developers time for focusing on business use cases.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Convention over configuration</h1>
                </header>
            
            <article>
                
<p>Pursuing the idea of convention over configuration, further, enterprise applications can be developed without any initial configuration required. The APIs provide default behavior that matches the majority of use cases. Engineer are only required to put extra effort in if that behavior is not sufficient.</p>
<p>This implies that in today's world, enterprise projects can be set up with minimal configuration involved. The days of extensive XML configuration are over. Especially, applications that don't ship web frontend technology can keep XML files to a minimum.</p>
<p>Let's start with a simple example of an application that offers REST endpoints, and accesses databases and external systems. REST endpoints are integrated by JAX-RS that internally uses servlets to handle requests. Servlets traditionally are configured using the <kbd>web.xml</kbd> deployment descriptor file residing under <kbd>WEB-INF</kbd>. However, JAX-RS ships a shortcut by sub-classing <kbd>Application</kbd>, annotated with <kbd>@ApplicationPath</kbd>, as shown in the previous chapter. This registers a JAX-RS application servlet for the provided path. At startup time, the project will be scanned for JAX-RS related classes such as resources or providers. After the application has been started, the REST endpoints are available to handle requests even without a provided <kbd>web.xml</kbd> file.</p>
<p>Managed beans are traditionally configured using a <kbd>beans.xml</kbd> configuration file. In web archive applications this file also resides under <kbd>WEB-INF</kbd>. Nowadays, it is primarily used to specify the bean discovery mode, that is, which CDI beans are considered per default. It's advisable to configure the <kbd>bean-discovery-mode</kbd> of <kbd>all</kbd>, not just <kbd>annotated</kbd> beans. The <kbd>beans.xml</kbd> file can override CDI bean composition of all sorts, such as interceptors, alternatives, decorators, and so on. As the CDI specification states, for the simplest example it's sufficient for this file to be empty.</p>
<p>The JPA persistence units are configured using the <kbd>persistence.xml</kbd> file under <kbd>META-INF</kbd>. As previously shown, it comprises the datasource definitions that are used in the the application. Mapping JPA entities to database tables is configured via annotations in domain model classes. This approach keeps the concerns in a single place and minimizes XML usage.</p>
<p>For the majority of enterprise applications that don't include a web frontend, this amount of configuration is already sufficient. Frontend technologies such as JSF are usually configured via <kbd>web.xml</kbd> and <kbd>faces-config.xml</kbd> or if required, via additional, implementation-specific files.</p>
<p>In the past, vendor-specific configuration files, such as <kbd>jboss-web.xml</kbd> or <kbd>glassfish-web.xml</kbd>, were quite common. In a modern Java EE world, the majority of applications don't require these workarounds anymore. In order to allow portability, it is highly advisable to implement features using standard APIs first and only if this is not possible within reasonable effort to go with vendor-specific features. Experience with legacy projects showed that this approach leads to better manageable situations. Unlike vendor-specific features, Java EE standards are guaranteed to continue to work in the future.</p>
<p>At application startup, the container scans the available classes for annotations and known types. Managed beans, resources, entities, extensions, and cross-cutting concerns are discovered and configured appropriately. This mechanism is a great benefit for developers. They don't need to explicitly specify required classes in configuration files but can rely on the server's discovery; inversion of control at its best.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dependency management of Java EE projects</h1>
                </header>
            
            <article>
                
<p>The dependency management of an enterprise project targets the dependencies that are added on top of the JDK. This includes dependencies that are required during compilation, tests, and at runtime. In a Java enterprise project, the Java EE API is required with <em>provided</em> dependency scope. Since the APIs are available on the application server, they don't have to be included in the packaged archive. The provided Java EE API therefore doesn't have an implication on the package size.</p>
<p>Real-world enterprise projects usually include more dependencies than this. Typical examples for third-party dependencies include logging frameworks such as <strong>Slf4j</strong>, <strong>Log4j</strong>, or <strong>Logback</strong>, JSON mapping frameworks such as <strong>Jackson</strong>, or general purpose libraries such as <strong>Apache Commons</strong>. There are several issues with these dependencies.</p>
<p>First of all, third-party dependencies are usually not provided, thus increasing the size of the artifact. This doesn't sound that harmful, but has some implications that we'll see later. The more dependencies are added to the resulting artifact, the longer the build will take. Build systems need to copy potentially big dependencies into the artifact each and every time the project is built. As we will see in <a href="599c6821-8971-4489-931c-9e11b5e23afd.xhtml">Chapter 6</a>, <em>Application Development Workflows</em>, project builds need to be as fast as possible. Every dependency added to the package increases the turnaround time.</p>
<p>Potential collisions of dependencies and their versions represent an even bigger challenge. This includes both packaged dependencies and transitive dependencies as well as libraries that already exist on the application server. For example, logging frameworks are often already present in the container's classpath, potentially in a different version. Different versions being used introduce potential issues with the aggregate of libraries being there. Experience shows that implicit dependencies that are added transitively represent the biggest challenge in this regard.</p>
<p>Aside from technical reasons, there are some other aspects to consider before lightheadedly introducing dependencies to a software project. Dependency licenses, for example, can become an issue when developing a software product that is shipped to customers. It's not only required that the company is permitted to use certain dependencies, but also that involved licenses are compatible to each other, when shipped in a software package. The simplest way to meet licensing criteria is to avoid dependencies, at least, if they serve no business purpose. Engineers should make similar consideration in regard to security, especially for software being developed for sectors with high demands in security.</p>
<p>I was once involved in a <em>firefighter</em> job responsible for updating versions of used frameworks in an enterprise project. The project included a lot of build dependencies. With all its included third-party dependencies, the project runtime eventually contained <em>all</em> known logging frameworks. The same was true for JSON mapping frameworks, which introduced a lot of version conflicts and runtime dependency mismatches. This was before the advent of JSON-B and JSON-P. We spent most of the time configuring the project build, untangling and excluding the transitive dependencies from the project artifact. This is a typical issue when using third-party libraries. The price for saving project code is to spend time and effort configuring the project build and potentially untangling dependencies, especially if they introduce a lot of transitive functionality.</p>
<p>By managing build dependencies, engineers focus on aspects that are insignificant to the business use cases. The question to be asked is whether it pays off to save some lines of code, when at the same time we introduce dependencies. Experience shows that the trade-off of duplication versus lightweightness, such as in dependency-free projects, is too often in favor of avoiding duplication. A prime example for this are projects that introduce the whole Apache Commons library to use a functionality that could have been realized with a few lines of code.</p>
<p>Whereas it's good practice to not reinvent the wheel by developing own versions of functionality that could be reused, the consequences also have to be considered. Experience shows that introduced dependencies are quite often neglected and only utilized marginally. Most of them serve little business value.</p>
<p>When engineers inspect code quality, for example using code analysis tools, what also should be considered is the ratio of dependencies and project code that target business use cases versus <em>plumbing</em>. There is a straightforward method that can be applied for dependencies. Before a third-party dependency is introduced, consider a few questions. Does adding the functionality add value to the business? How much project code does it save? How big is the impact on the resulting artifact?</p>
<p>For example, imagine part of the use case of the car manufacture application is to communicate with specific factory software using a proprietary Java API. Obviously, the communication is crucial to fulfill the business purpose and it makes a lot of sense to include this dependency in the project. On the contrary, adding a different logging framework hardly improves the application's business value. Furthermore, <a href="">Chapter 9</a>, <em>Monitoring, Performance, and Logging</em> will discuss the issues with traditional logging.</p>
<p>However, in order not to unnecessarily increase the build size, crucial dependencies can be installed on the application server and be declared as provided in the project's build.</p>
<p>In the first chapter, we saw the difficulties with shared business dependencies such as shared models. Ideally, applications are as self-sufficient as possible. <a href="">Chapter 8</a>, <em>Microservices and System Architecture</em> will deep-dive into self-contained systems and the motivation for architectures that share nothing.</p>
<p>In regard to technical dependencies, however, the Java EE API already includes the technology that the majority of enterprise applications need. Ideally, engineers develop zero-dependency Java EE applications that are packaged as thin deployment artifacts containing the application-relevant classes only. If some use cases require third-party dependencies, they can be installed in the container. The goal is to have a light footprint of deployment artifacts.</p>
<p>For production code, this means that only provided dependencies are included, ideally, only the Java EE API. Test dependencies, however, are a different story; software tests require some additional technology. <a href="">Chapter 7</a>, <em>Testing</em> covers the required dependencies for the test scope.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Lightweight way of packaging applications</h1>
                </header>
            
            <article>
                
<p>The approach of zero-dependency applications simplifies many project build concerns. There is no need to manage third-party dependencies with regard to versions or collisions since there aren't any included.</p>
<p>What other aspects does this approach simplify? Project builds, no matter whether Gradle or Maven are being used, always show the best performance when nothing needs to be added to the artifact. The resulting size of the packages directly impacts the build time. In the case of zero-dependency applications, only the compiled classes are included, that is, only the actual business logic. Therefore, the resulting build times are as minimal as they will get. All build time is spent on compiling the project's classes, running the test cases, and packaging the classes into a thin deployment artifact. Building this approach should happen in seconds. Yes, seconds. As a general rule, every project build that takes more than 10 seconds should be reconsidered.</p>
<p>This rule, of course, puts certain pressure on project builds. It naturally requires to avoid including any larger dependency or implementation; these should be provided by the application server. Test run times are usually another aspect that prevents fast builds. <a href="">Chapter 7</a>, <em>Testing</em>, will shed light on how to develop tests in an effective way.</p>
<p>Fast builds are one benefit of crafting zero-dependency applications. Another implication is fast artifact transmission. Built artifacts, such as WAR or JAR files, are usually kept in an artifact repository for later use, for example, <strong>Sonatype Nexus</strong> or <strong>JFrog Artifactory</strong>. Transmitting these artifacts over the wire greatly speeds up if only a few kilobytes of data are involved. This applies to all sorts of artifact deployment. No matter where the built archives are shipped to, smaller footprints always pay off especially when workflows are executed often, as it is the case for Continuous Delivery.</p>
<p>The goal of reconsidering practices and stripping everything which does not provide value also targets the way of packaging applications. Traditionally, enterprise applications have been shipped as EAR files. The structure of these included a web archive, a WAR file, and one or more enterprise JARs. Enterprise JAR archives contained the business logic, usually implemented in EJBs. The web archive contained the web services and frontend technology communicating with the business logic using local or remote EJBs. However, this separation is not necessary, as all components are shipped on a single server instance.</p>
<p>Packaging several technical concerns in several sub-archives is not required anymore. All business logic as well as web services and cross-cutting concerns are packaged into a single WAR file. This greatly simplifies the project setup as well as the build process. Applications don't have to be zipped in multiple hierarchies just to be unzipped on a single server instance again. WAR files containing the required business code deployed in a container is the best implementation of thin artifacts. Because of this reason, deploying thin WAR files is faster than the corresponding EAR files.</p>
<p>The following demonstrates the contents of a thin web application artifact with typical components:</p>
<div class="CDPAlignCenter CDPAlign"><img height="427" width="333" src="assets/fb372acc-bd04-436a-9058-306fd1046ebe.png"/></div>
<p>The deployment artifact only contains classes that are required to implement the business use case, no technology-specific implementation, and only minimal configuration. Especially, there are no library JAR files included.</p>
<p>The architecture of the Java EE platform encourages lightweight artifacts. This is due to the platform separating the API from the implementations. Developers only program against the API; the application server implements the API. This makes it possible to ship only the business logic, which includes certain aspects in lightweight artifacts. Besides the obvious benefits of avoiding dependency collisions and building vendor-independent solutions, this approach also enables fast deployments. The less content the artifacts include, the less unpacking needs to be done on the container side. Therefore, it's highly advisable to package enterprise applications into a single WAR file.</p>
<p>In the last year, we have seen more and more interest in shipping enterprise applications as <em>fat</em> JARs, that is, shipping the application together with the implementation. The approaches of fat deployment artifacts have usually been used in enterprise frameworks such as the Spring Framework. The motivation behind these approaches is that the versions of the required dependencies and frameworks are explicitly specified and shipped together with the business logic. Fat deployment artifacts can be created as fat WARs, which are deployed on a servlet container, or fat JARs started as standalone, executable JARs. A Java EE application packaged as fat JAR therefore ships the enterprise container together with the application in an executable JAR. However, as stated before, the build, shipping, and deployment times increase greatly if third-party dependencies are added to the artifact.</p>
<p>Experience shows that explicitly shipping the enterprise implementation together with the application is in most cases not technically but business-politically motivated. Operational environments within companies that are inflexible regarding application server and Java installations, especially regarding version upgrades, in some cases force developers to find workarounds. Enterprise applications that are built using newer technology cannot be deployed on older, existing server installations. Sometimes, the business-politically easier solution is to ignore the existing installations altogether and to directly execute the standalone JAR, which <span>only requires a certain Java version</span>. However, whereas these solutions are certainly justified, the technically more reasonable solutions would be to package applications into thin deployment artifacts. Interestingly, as we will see in the next chapter, shipping software in Linux containers holds the advantages of both approaches.</p>
<p>There is another interesting approach that enables to ship the whole application as an executable package and to keep fast workflows of thin deployments. Several application server vendors provide the solution to ship a custom application container as executable JAR that deploys the thin application as additional argument at startup time. By doing so, the whole package of both artifacts includes the business logic as well as the implementation and is started as a standalone application. The application is still separated from its runtime and packaged as thin artifact, as a so-called <em>hollow</em> JAR or WAR file. This approach especially makes sense if the addressed flexibility is required without the use of Linux containers.</p>
<p>As a conclusion, it is highly advisable to build thin deployment artifacts, ideally thin WAR files. If this approach does not work for business-political reasons, hollow JARs can provide a reasonable workaround. However, as we will see in the next chapter, container technologies such as Docker <span>don't require to make use of executable JAR approaches and</span> provide the same benefits.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Java EE application servers</h1>
                </header>
            
            <article>
                
<p>What else makes an enterprise technology lightweight besides the productiveness of the API? What about the runtime, the enterprise container?</p>
<p>Developers often complained about J2EE application servers being too slow, too cumbersome, and unwieldy to use. Installation sizes and memory consumption were quite high. Typically, a lot of applications ran on a server instance in parallel with being redeployed individually. This approach sometimes introduced additional challenges, such as classloader hierarchy issues.</p>
<p>Modern application servers are far from this negative image. Most of them have been heavily optimized for startup and deployment time. Especially, server-internal module approaches such as <strong>Open Service Gateway Initiative</strong> (<strong>OSGi</strong>) tackled the necessity of supporting the full Java EE API by loading required modules on demand and greatly speeding up operations. In terms of resource usage, application servers also greatly improved compared to the past. A modern container consumes less memory than a running browser instance on a desktop computer. For example, an <strong>Apache TomEE</strong> instance starts up in one second, consumes less than 40 megabytes on disk and less than 30 megabytes of memory.</p>
<p>The performance overhead of managed beans is equally negligible. In fact, compared to CDI managed beans and other frameworks such as Spring Framework, stateless EJBs show the best results. This is due to the fact that stateless session beans are pooled and reused after their business methods have been invoked.</p>
<p>Besides that, application servers manage pools of connections and threads and they enable engineers to gather statistics and performance insights <span>out of the box</span>. The container is responsible for providing monitoring for these aspects. DevOps engineers have the possibility to directly use this data without introducing custom metrics.</p>
<p>Besides these aspects, the application servers also manage the bean instances and life cycles, resources, and database transactions, as we have seen in the previous chapter.</p>
<p>This is the point of having an application container. It does the required work to run an enterprise application in production; the software engineers are responsible for dealing with the business logic. The container provides and manages the required resources and is forced by the standards to provide insights into deployed applications. Due to the vendors that put a lot of effort into optimizing the required technologies, the resource overhead can be kept low.</p>
<p>Application servers' installation sizes are still somewhat bigger than other enterprise frameworks. As of writing this book, vendors are striving to provide smaller, on-demand runtimes tailored for the application's needs. The <strong>MicroProfile</strong> initiative includes several application server vendors that define additional enterprise profiles complementary to the Java EE umbrella. These profiles are assembled from Java EE standards as well. This is a very interesting approach for developers since it doesn't require any change on the application side. The runtime, that is, the set of standards included, will be fitted to what the application needs in order to fulfill its business logic.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">One application per application server</h1>
                </header>
            
            <article>
                
<p>Traditionally, with big installation sizes and long startup times, application servers have been used to deploy several, if not dozens of, enterprise applications. A server instance was shared among several teams, sometimes a whole company. This comes with certain inflexibility, similar to shared application models. Teams cannot simply choose newer JDK or server versions, or restart or reconfigure the application server without coordinating with other teams. This naturally inhibits fast and productive processes, and complicates Continuous Delivery.</p>
<p>In terms of team working methods, and project and application life cycles, the easiest approach therefore is to deploy an application on a dedicated application server. The DevOps team has full control over its version, configuration, and life cycle. This approach simplifies processes and avoids potential issues such as collisions with other teams and used technology. Issues with hierarchical classloading that deploying several applications could introduce are avoided as well.</p>
<p>An application server certainly represents quite a construct for just a single application. However, as we have seen previously, the installation sizes of application servers have already decreased compared to the past. Apart from that, developers should care more about the sizes of the deployment artifacts, since these are the moving parts of the development workflow. In a Continuous Delivery approach, the application is potentially built and packaged many times a day. The longer the time spent on the project build and transmitting artifacts, the longer the turnaround times. This affects each and every build and can add up to a lot of overhead during a day. The application server is not installed and shipped that often. Therefore, it is advisable to deploy an application to a single, dedicated Java EE server:</p>
<div class="CDPAlignCenter CDPAlign"><img height="267" width="473" src="assets/f7fc2681-0118-4d06-ba47-a32640353b73.png"/></div>
<p>In the next chapter, we will see how container technologies such as Docker support this approach. Shipping the application, including the whole stack down to the operating system as a container, encourages the approach of one application per application server.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>The seamless integration of multiple Java EE standards with the convention over configuration approach minimizes the amount of boilerplate work developers have to do. The configuration of modern enterprise applications is thus kept to a minimum. Especially the default conventions, which work for the majority of enterprise applications and the possibility of overriding configuration only if required, increases the developer's productivity.</p>
<p>Enterprise applications should minimize their dependencies ideally to only the provided Java EE API. The third-party dependencies should only be added if they are a business necessity and not a technical one.</p>
<p>Java EE applications should be packaged as thin WAR files, following a zero-dependency approach. This has a positive impact on the time spend to build as well as to publish the application.</p>
<p>Modern Java EE applications are far from the negative image of heavyweight J2EE runtimes. They start up and deploy fast and try to reduce the memory impact. Whereas application servers might not be the most lightweight runtime out there, they ship with enough benefits for enterprise applications such as integrating technology or managing life cycles, connections, transactions, or threads, that would have to be implemented otherwise.</p>
<p>In order to simplify application life cycles and deployments it's advisable to deploy one application per application server. This gets rid of a few potential challenges and perfectly fits into a modern world of container technologies. The next chapter will show you this modern world in the age of cloud platforms, what container technologies are about and how Java EE fits into this picture.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    </body></html>