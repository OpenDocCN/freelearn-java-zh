- en: '*Chapter 15*: Reactive Programming'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will be introduced to the **Reactive Manifesto** and the
    world of reactive programming. We start with defining and discussing the main
    concepts of reactive programming – asynchronous, non-blocking, and responsive.
    Using them, we then define and discuss reactive programming, the main reactive
    frameworks, and talk about **RxJava** in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-blocking APIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reactive – responsive, resilient, elastic, and message-driven systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reactive streams
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RxJava
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of the chapter, you will be able to write code for asynchronous processing
    using reactive programming.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To be able to execute the code examples that are provided in this chapter,
    you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A computer with an operating system: Microsoft Windows, Apple macOS, or Linux'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Java SE version 17 or later
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any IDE or code editor you prefer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The instructions for how to set up a Java SE and IntelliJ IDEA editor were provided
    in [*Chapter 1*](B18388_01_ePub.xhtml#_idTextAnchor015), *Getting Started with
    Java 17*, of this book. The files and the code examples for this chapter are available
    from the GitHub repository at [https://github.com/PacktPublishing/Learn-Java-17-Programming.git](https://github.com/PacktPublishing/Learn-Java-17-Programming.git).
    You can locate them in the [examples/src/main/java/com/packt/learnjava/ch15_reactive](https://examples/src/main/java/com/packt/learnjava/ch15_reactive)
    folder.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Asynchronous** means that the requestor gets the response immediately, but
    the result is not there. Instead, the requestor waits until the result is sent
    to them, saved in the database, or, for example, presented as an object that allows
    you to check whether the result is ready. If the latter is the case, the requestor
    calls a certain method to this object periodically and, when the result is ready,
    retrieves it using another method on the same object. The advantage of asynchronous
    processing is that the requestor can do other things while waiting.'
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 8*](B18388_08_ePub.xhtml#_idTextAnchor187), *Multithreading and
    Concurrent Processing*, we demonstrated how a child thread can be created. Such
    a child thread then sends a non-asynchronous (blocking) request and waits for
    its return doing nothing. Meanwhile, the main thread continues executing and periodically
    calls the child thread object to see whether the result is ready. That is the
    most basic of asynchronous processing implementations. In fact, we already used
    it when we used parallel streams.
  prefs: []
  type: TYPE_NORMAL
- en: The parallel stream operations that work behind the scenes to create the child
    threads break the stream into segments, assign each segment to a dedicated thread
    for processing, and then aggregate the partial results from all the segments into
    the final result. In the previous chapter, we even wrote functions that did the
    aggregating job. As a reminder, the function was called **combiner**.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s compare the performance of sequential and parallel streams using an example.
  prefs: []
  type: TYPE_NORMAL
- en: Sequential and parallel streams
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To demonstrate the difference between sequential and parallel processing, let’s
    imagine a system that collects data from 10 physical devices (such as sensors)
    and calculates an average. The following is the `get()` method, which collects
    a measurement from a sensor identified by its ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We have included a delay of 100 ms to imitate the time it takes to collect the
    measurement from the sensor. As for the resulting measurement value, we use the
    `Math.random()` method. We are going to call this `get()` method using an object
    of the `MeasuringSystem` class, which is where the method belongs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we are going to calculate an average to offset the errors and other idiosyncrasies
    of individual devices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Notice how we convert the stream of IDs into `DoubleStream` using the `mapToDouble()`
    operation so that we can apply the `average()` operation. The `average()` operation
    returns an `Optional<Double>` object, and we call its `orElse(0)` method, which
    returns either the calculated value or zero (for example, if the measuring system
    could not connect to any of its sensors and returned an empty stream).
  prefs: []
  type: TYPE_NORMAL
- en: The last line of the `getAverage()` method prints the result and the time it
    took to calculate it. In real code, we would return the result and use it for
    other calculations. However, for demonstration purposes, we will just print it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can compare the performance of sequential stream processing with the
    performance of parallel processing (see the `MeasuringSystem` class and the `compareSequentialAndParallelProcessing()`
    method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The results might be different if you run this example because, as you might
    recall, we simulate the collected measurements as random values.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the processing of a parallel stream is five times faster than
    the processing of a sequential stream. The results are different because the measurement
    produces a slightly different result each time.
  prefs: []
  type: TYPE_NORMAL
- en: Although the parallel stream uses asynchronous processing behind the scenes,
    this is not what programmers have in mind when talking about the asynchronous
    processing of requests. From the application’s perspective, it is just parallel
    (also called concurrent) processing. It is faster than sequential processing,
    but the main thread has to wait until all the calls are made and the data has
    been retrieved. If each call takes at least 100 ms (as it is in our case), then
    the processing of all the calls cannot be completed in less time, even when each
    call is made by a dedicated thread.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we can create a service that uses a child thread to make all the
    calls, while the main thread does something else. Later, the main thread can call
    the service again and get the result or pick it up from a previously agreed location.
    That truly would be the asynchronous processing programmers are talking about.
  prefs: []
  type: TYPE_NORMAL
- en: But before writing such code, let’s look at the `CompletableFuture` class located
    in the `java.util.concurrent` package. It does everything described and more.
  prefs: []
  type: TYPE_NORMAL
- en: Using the CompletableFuture object
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using the `CompletableFuture` object, we can separate sending the request to
    the measuring system from getting the result from the `CompletableFuture` object.
    That is exactly the scenario we described while explaining what asynchronous processing
    was. Let’s demonstrate it in the code (see the `MeasuringSystem` class and the
    `completableFuture()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The `supplyAsync()` method does not wait for the call to the measuring system
    to return. Instead, it immediately creates a `CompletableFuture` object and returns
    it. This is so that a client can use this object any time later on to retrieve
    the result returned by the measuring system. The following code takes the list
    of `CompletableFuture` objects and iterates over it, retrieving the result from
    each object and calculating the average value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Additionally, some methods allow you to check whether the value was returned
    at all, but that is not the point of this demonstration, which is to show how
    the `CompletableFuture` class can be used to organize asynchronous processing.
  prefs: []
  type: TYPE_NORMAL
- en: The created list of `CompletableFuture` objects can be stored anywhere and processed
    very quickly (in our case, in 6 ms), provided that the measurements have been
    received already (all the `get()` methods were invoked and returned values). After
    creating the list of `CompletableFuture` objects and before processing it, the
    system is not blocked and can do something else. That is the advantage of asynchronous
    processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `CompletableFuture` class has many methods and is supported by several
    other classes and interfaces. For example, a fixed-size thread pool can be added
    to limit the number of threads (see the `MeasuringSystem` class and the `threadPool()`
    method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: There is a variety of such pools for different purposes and different performances.
    But using a pool does not change the overall system design, so we omit such a
    detail.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the power of asynchronous processing is great. There is also
    a variation of the asynchronous API called a **non-blocking API**. We are going
    to discuss this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Non-blocking APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The client of a non-blocking API gets the results without being blocked for
    a significant amount of time, thus allowing the client to do something else during
    the period when the results are being prepared. So, the notion of a non-blocking
    API implies a highly responsive application. The processing of the request (that
    is, getting the results) can be done synchronously or asynchronously – it does
    not matter to the client. In practice, though, typically, the application uses
    asynchronous processing to facilitate an increased throughput and improved performance
    of the API.
  prefs: []
  type: TYPE_NORMAL
- en: 'The term `java.nio` package. The **non-blocking input/output** (**NIO**) provides
    support for intensive **input/output** (**I/O**) operations. It describes how
    the application is implemented: it does not dedicate an execution thread to each
    of the requests but provides several lightweight worker threads that do the processing
    asynchronously and concurrently.'
  prefs: []
  type: TYPE_NORMAL
- en: The java.io package versus the java.nio package
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Writing and reading data to and from external memory (for example, a hard drive)
    is a much slower operation than processing in memory only. Initially, the already-existing
    classes and interfaces of the `java.io` package worked well, but once in a while,
    they would create a performance bottleneck. The new `java.nio` package was created
    to provide more effective I/O support.
  prefs: []
  type: TYPE_NORMAL
- en: The `java.io` implementation is based on I/O stream processing. As we saw in
    the previous section, essentially, this is a blocking operation even if some kind
    of concurrency is happening behind the scenes. To increase speeds, the `java.nio`
    implementation was introduced based on the reading/writing to/from a buffer in
    the memory. Such a design allowed it to separate the slow process of filling/emptying
    the buffer and quickly reading/writing from/to it.
  prefs: []
  type: TYPE_NORMAL
- en: In a way, it is similar to what we have done in our example of `CompletableFuture`
    usage. The additional advantage of having data in a buffer is that it is possible
    to inspect the data, going there and back along with the buffer, which is impossible
    while reading sequentially from the stream. It has provided more flexibility during
    data processing. In addition, the `java.nio` implementation introduced another
    middleman process called a **channel** for bulk data transfers to and from a buffer.
  prefs: []
  type: TYPE_NORMAL
- en: The reading thread is getting data from a channel and only receives what is
    currently available or nothing at all (if no data is in the channel). If data
    is not available, the thread, instead of remaining blocked, can do something else–for
    example, reading/writing to/from other channels in the same way the main thread
    in our `CompletableFuture` example was free to do whatever had to be done while
    the measuring system was getting data from its sensors.
  prefs: []
  type: TYPE_NORMAL
- en: This way, instead of dedicating a thread to one I/O process, a few worker threads
    can serve many I/O processes. Such a solution was eventually called NIO and was
    later applied to other processes, the most prominent being the *event processing
    in an event loop*, which is also called a **run loop**.
  prefs: []
  type: TYPE_NORMAL
- en: The event/run loop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many non-blocking systems are based on the **event** (or **run**) loop – a thread
    that is continually executed. It receives events (requests and messages) and then
    dispatches them to the corresponding event handlers (workers). There is nothing
    special about event handlers. They are just methods (functions) dedicated by the
    programmer for the processing of the particular event type.
  prefs: []
  type: TYPE_NORMAL
- en: Such a design is called a **reactor design pattern**. It is constructed around
    processing events and service requests concurrently. Also, it gives the name to
    the **reactive programming** and **reactive systems** that *react* to events and
    process them concurrently.
  prefs: []
  type: TYPE_NORMAL
- en: Event loop-based design is widely used in operating systems and graphical user
    interfaces. It has been available in Spring WebFlux since Spring 5 and can be
    implemented in JavaScript and the popular executing environment, Node.js. The
    latter uses an event loop as its processing backbone. The toolkit, Vert.x, is
    built around the event loop, too.
  prefs: []
  type: TYPE_NORMAL
- en: Before the adoption of an event loop, a dedicated thread was assigned to each
    incoming request – much like in our demonstration of stream processing. Each of
    the threads required the allocation of a certain amount of resources that were
    not request-specific, so some of the resources – mostly memory allocation – were
    wasted. Then, as the number of requests grew, the CPU needed to switch its context
    from one thread to another more frequently to allow more or less concurrent processing
    of all the requests. Under the load, the overhead of switching the context is
    substantial enough to affect the performance of an application.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing an event loop has addressed these two issues. It has eliminated
    the waste of resources by avoiding the creation of a thread for each request and
    removed the overhead of switching the context. With an event loop in place, a
    much smaller memory allocation is needed for each request to capture its specifics,
    which makes it possible to keep many more requests in memory so that they can
    be processed concurrently. The overhead of the CPU context-switching has become
    far smaller too because of the diminishing context size.
  prefs: []
  type: TYPE_NORMAL
- en: The non-blocking API is a way of processing requests so that systems are able
    to handle a much bigger load while remaining highly responsive and resilient.
  prefs: []
  type: TYPE_NORMAL
- en: Reactive
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Usually, the term `java.util.concurrent` package. It allows a `Publisher` to
    generate a stream of data to which a `Subscriber` can asynchronously subscribe.
  prefs: []
  type: TYPE_NORMAL
- en: One principal difference between reactive streams and standard streams (which
    are also called `java.util.stream` package) is that a source (publisher) of the
    reactive stream pushes elements to subscribers at its own rate, while in standard
    streams, a new element is pulled and emitted only after the previous one has been
    processed (in fact, it acts like a `for` loop).
  prefs: []
  type: TYPE_NORMAL
- en: 'As you have seen, we were able to process data asynchronously even without
    this new API by using `CompletableFuture`. But after writing such code a few times,
    you might notice that most of the code is just plumbing, so you get the feeling
    that there has to be an even simpler and more convenient solution. That’s how
    the reactive streams initiative ([http://www.reactive-streams.org](http://www.reactive-streams.org))
    was born. The scope of the effort was defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The scope of Reactive Streams is to find a minimal set of interfaces, methods,
    and protocols that will describe the necessary operations and entities to achieve
    the goal – asynchronous streams of data with non-blocking back pressure.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The term **non-blocking backpressure** refers to one of the problems of asynchronous
    processing: coordinating the speed rate of the incoming data with the ability
    of the system to process them without the need for stopping (blocking) the data
    input. The solution is to inform the source that the consumer has difficulty keeping
    up with the input. Also, processing should react to the change in the rate of
    the incoming data in a more flexible manner than just blocking the flow, hence
    the name *reactive*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Several libraries already implement the reactive streams API: RxJava ([http://reactivex.io](http://reactivex.io)),
    Reactor ([https://projectreactor.io](https://projectreactor.io)), Akka Streams
    ([https://akka.io/docs](https://akka.io/docs)), and Vert.x ([https://vertx.io/](https://vertx.io/))
    are among the most well known. Writing code using RxJava or another library of
    asynchronous streams constitutes *reactive programming*. It realizes the goal
    declared in the Reactive Manifesto ([https://www.reactivemanifesto.org](https://www.reactivemanifesto.org))
    by building reactive systems that are *responsive*, *resilient*, *elastic*, and
    *message-driven*.'
  prefs: []
  type: TYPE_NORMAL
- en: Responsive
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This term is relatively self-explanatory. The ability to respond in a timely
    manner is one of the primary qualities of any system. There are many ways to achieve
    it. Even a traditional blocking API supported by enough servers and other infrastructure
    can achieve decent responsiveness under a growing load.
  prefs: []
  type: TYPE_NORMAL
- en: Reactive programming helps to do this using less hardware. It comes at a price,
    as reactive code requires changing the way we think about control flow. But after
    some time, this new way of thinking becomes as natural as any other familiar skill.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we will see quite a few examples of reactive programming.
  prefs: []
  type: TYPE_NORMAL
- en: Resilient
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Failures are inevitable. The hardware crashes, the software has defects, unexpected
    data is received, or an untested execution path has been taken – any of these
    events, or a combination of them, can happen at any time. *Resilience* is the
    ability of a system to continue delivering the expected results under unexpected
    circumstances.
  prefs: []
  type: TYPE_NORMAL
- en: For example, it can be achieved using redundancy of the deployable components
    and hardware, using isolation of parts of the system so the domino effect becomes
    less probable, by designing the system with automatically replaceable parts, or
    by raising an alarm so that qualified personnel can interfere. Additionally, we
    have talked about distributed systems as a good example of resilient systems by
    design.
  prefs: []
  type: TYPE_NORMAL
- en: A distributed architecture eliminates a single point of failure. Also, breaking
    the system into many specialized components that talk to one another using messages
    allows better tuning for the duplication of the most critical parts and creates
    more opportunities for their isolation and potential failure containment.
  prefs: []
  type: TYPE_NORMAL
- en: Elastic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Usually, the ability to sustain the biggest possible load is associated with
    **scalability**. But the ability to preserve the same performance characteristics
    under a varying load, not just under the growing one, is called **elasticity**.
  prefs: []
  type: TYPE_NORMAL
- en: The client of an elastic system should not notice any difference between the
    idle periods and the periods of peak load. A non-blocking reactive style of implementation
    facilitates this quality. Also, breaking the program into smaller parts and converting
    them into services that can be deployed and managed independently allows for the
    fine-tuning of resource allocation.
  prefs: []
  type: TYPE_NORMAL
- en: Such small services are called microservices, and many of them together can
    comprise a reactive system that can be both scalable and elastic. We will talk
    about such architecture, in more detail, in the following sections and the next
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Message-driven
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have already established that component isolation and system distribution
    are two aspects that help to keep the system responsive, resilient, and elastic.
    Loose and flexible connections are important conditions that support these qualities,
    too. And the asynchronous nature of the reactive system simply does not leave
    the designer any other choice but to build communication between the components
    and the messages.
  prefs: []
  type: TYPE_NORMAL
- en: It creates breathing space around each component without which the system would
    become a tightly coupled monolith that was susceptible to all kinds of problems,
    not to mention a maintenance nightmare.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to look at an architectural style that can
    be used to build an application as a collection of loosely coupled microservices
    that communicate using messages.
  prefs: []
  type: TYPE_NORMAL
- en: Reactive streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The reactive streams API, which was introduced in Java 9, consists of the following
    four interfaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: A `Flow.Subscriber` object can be passed, as a parameter, into the `subscribe()`
    method of `Flow.Publisher<T>`. Then, the publisher calls the subscriber’s `onSubscribe()`
    method and passes to it a `Flow.Subscription` object as a parameter. Now, the
    subscriber can call `request(long numberOfItems)` on the subscription object to
    request data from the publisher. That is the way the `cancel()` method on the
    subscription.
  prefs: []
  type: TYPE_NORMAL
- en: In return, the publisher can pass a new item to the subscriber by calling the
    subscriber’s `onNext()` method. When no more data will be coming (that is, all
    the data from the source was emitted) the publisher calls the subscriber’s `onComplete()`
    method. Also, by calling the subscriber’s `onError()` method, the publisher can
    tell the subscriber that it has encountered a problem.
  prefs: []
  type: TYPE_NORMAL
- en: The `Flow.Processor` interface describes an entity that can act as both a subscriber
    and a publisher. It allows you to create chains (or pipelines) of such processors,
    so a subscriber can receive an item from a publisher, transform it, and then pass
    the result to the next subscriber or processor.
  prefs: []
  type: TYPE_NORMAL
- en: In a push model, the publisher can call `onNext()` without any request from
    the subscriber. If the rate of processing is lower than the rate of the item being
    published, the subscriber can use various strategies to relieve the pressure.
    For example, it can skip the items or create a buffer for temporary storage with
    the hope that the item production will slow down and the subscriber will be able
    to catch up.
  prefs: []
  type: TYPE_NORMAL
- en: This is the minimal set of interfaces that the reactive streams initiative has
    defined in support of the asynchronous data streams with non-blocking backpressure.
    As you can see, it allows the subscriber and publisher to talk to each other and
    coordinate the rate of incoming data; therefore, it makes possible a variety of
    solutions for the backpressure problem that we discussed in the *Reactive* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many ways to implement these interfaces. Currently, in JDK 9, there
    is only one implementation of one of the interfaces: the `SubmissionPublisher`
    class implements `Flow.Publisher`. The reason for this is that these interfaces
    are not supposed to be used by an application developer. It is a **Service Provider
    Interface** (**SPI**) that is used by the developers of the reactive streams libraries.
    If needed, use one of the already-existing toolkits to implement the reactive
    streams API that we mentioned earlier: RxJava, Reactor, Akka Streams, Vert.x,
    or any other library of your preference.'
  prefs: []
  type: TYPE_NORMAL
- en: RxJava
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In our examples, we will use **RxJava 2.2.21** ([http://reactivex.io](http://reactivex.io))
    . It can be added to the project using the following dependency:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'First, let’s compare two implementations of the same functionality using the
    `java.util.stream` package and the `io.reactivex` package. The sample program
    is going to be very simple:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a stream of integers: `1`, `2`, `3`, `4`, and `5`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Only filter the even numbers (that is, `2` and `4`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculate the square root of each of the filtered numbers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculate the sum of all the square roots.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is how it can be implemented using the `java.util.stream` package (see
    the `ObservableIntro` class and the `squareRootSum()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Additionally, the same functionality implemented with RxJava looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: RxJava is based on the `Observable` object (which plays the role of `Publisher`)
    and `Observer` that subscribes to the `Observable` object and waits for the data
    to be emitted.
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast to the `Stream` functionality, `Observable` has significantly different
    capabilities. For example, a stream, once closed, cannot be reopened, while an
    `Observable` object can be used again. Here is an example (see the `ObservableIntro`
    class and the `reuseObservable()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, as you can see from the comments, the `doOnNext()`
    operation was called twice, which means the observable object also emitted values
    twice, once for each processing pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_15.1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If we do not want `Observable` to run twice, we can cache its data, by adding
    the `cache()` operation (see the `ObservableIntro` class and the `cacheObservableData()`
    method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the second usage of the same `Observable` object took advantage
    of the cached data, thus allowing for better performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_15.2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: RxJava provides such a rich functionality that there is no way we can review
    it all in this book. Instead, we will try to cover the most popular functionality.
    The API describes the methods available for invocation using an `Observable` object.
    Such methods are also called **operations** (as in the case with the standard
    Java 8 streams) or **operators** (this term is mostly used in connection to reactive
    streams). We will use these three terms – methods, operations, and operators –
    interchangeably as synonyms.
  prefs: []
  type: TYPE_NORMAL
- en: Observable types
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Talking about the RxJava 2 API (notice that is it quite different from RxJava
    1), we will use the online documentation, which can be found at [http://reactivex.io/RxJava/2.x/javadoc/index.html](http://reactivex.io/RxJava/2.x/javadoc/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'An observer subscribes to receive values from an observable object, which can
    behave as one of the following types:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Blocking**: This waits until the result is returned.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Non-blocking**: This processes the emitted elements asynchronously.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cold**: This emits an element at the observer’s request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hot**: This emits elements whether an observer has subscribed or not.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An observable object can be an object of one of the following classes of the
    `io.reactivex` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Observable<T>`: This can emit none, one, or many elements; it does not support
    backpressure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Flowable<T>`: This can emit none, one, or many elements; it supports backpressure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Single<T>`: This can emit either one element or an error; the notion of backpressure
    does not apply.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Maybe<T>`: This represents a deferred computation. It can emit either no value,
    one value, or an error; the notion of backpressure does not apply.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Completable`: This represents a deferred computation without any value. This
    indicates the completion of a task or an error; the notion of backpressure does
    not apply.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An object of each of these classes can behave as a blocking, non-blocking, cold,
    or hot observable. They differ from each other by the number of values that can
    be emitted, their ability to defer the returning of the result or returning the
    flag of the task completion only, and their ability to handle backpressure.
  prefs: []
  type: TYPE_NORMAL
- en: Blocking versus non-blocking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To demonstrate this behavior, we create an observable that emits five sequential
    integers, starting with `1` (see the `BlockingOperators` class and the `observableBlocking1()`
    method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'All the blocking methods (operators) of `Observable` start with the “blocking.”
    For example, the `blockingLast()` operator blocks the pipeline until the last
    elements are emitted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we only select even numbers, print the selected element, and
    then calculate the square root and wait for 100 ms (imitating a long-running calculation).
    The result of this example is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_15.3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The non-blocking version of the same functionality is as follows (see the `BlockingOperators`
    class and the second half of the `observableBlocking1()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: We use the `List` object to capture the result because, as you might remember,
    the lambda expression does not allow us to use the non-final variables.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the resulting list is empty. That is because the pipeline calculations
    are performed without blocking (asynchronously). We set a delay of 100 ms (to
    simulate processing, which takes a long time), but there is no blocking operation,
    so the control goes down to the next line that prints the list content, which
    is still empty.
  prefs: []
  type: TYPE_NORMAL
- en: 'To prevent the control from going to this line too early, we can set a delay
    in front of it (see the `BlockingOperators` class and the `observableBlocking2()`
    method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: Note that the delay has to be 200 ms at least because the pipeline processes
    two elements, each with a delay of 100 ms. Now you can see the list contains an
    expected value of `2.0`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Esentially, that is the difference between blocking and non-blocking operators.
    Other classes that represent an `observable` have similar blocking operators.
    Here are some examples of blocking `Flowable`, `Single`, and `Maybe` (see the
    `BlockingOperators` class and the `flowableBlocking()`, `singleBlocking()`, and
    `maybeBlocking()` methods):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Completable` class has blocking operators that allow us to set a timeout
    (see the `BlockingOperators` class and the second half of the `completableBlocking()`
    method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE152]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of the preceding code is presented in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_15.4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The first `Run` message comes from line 2 in response to the call of the blocking
    `blockingGet()` method. The first `null` message comes from line 3\. Line 4 throws
    an exception because the timeout was set to 15 ms, while the actual processing
    was set to a delay of 100 ms. The second `Run` message comes from line 5 in response
    to the `blockingGet()` method call. This time, the timeout is set to 150 ms, which
    is more than 100 ms, so the method is able to return before the timeout was up.
  prefs: []
  type: TYPE_NORMAL
- en: The last two lines, 7 and 8, demonstrate the usage of the `blockingAwait()`
    method with and without a timeout. This method does not return a value but allows
    the observable pipeline to run its course. Interestingly, it does not break with
    an exception even when the timeout is set to a smaller value than the time the
    pipeline takes to finish. Apparently, it starts waiting after the pipeline has
    finished processing unless it is a defect that will be fixed later (the documentation
    is not clear regarding this point).
  prefs: []
  type: TYPE_NORMAL
- en: Although blocking operations do exist (and we will review more of them while
    talking about each observable type in the following sections), they are and should
    only be used in cases when it is not possible to implement the required functionality
    of using non-blocking operations only. The main thrust of reactive programming
    is to strive to process all requests asynchronously in a non-blocking style.
  prefs: []
  type: TYPE_NORMAL
- en: Cold versus hot
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'So far, all the examples we have seen have only demonstrated a cold observable,
    which only provides the next value at the request of the processing pipeline after
    the previous value has been processed. Here is another example (see the `ColdObservable`
    class and the `main()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE156]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE157]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE158]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE159]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE160]'
  prefs: []
  type: TYPE_PRE
- en: 'We have used the `interval()` method to create an `Observable` object that
    represents a stream of sequential numbers emitted at every specified interval
    (in our case, every 10 ms). Then, we subscribe to the created object, wait 25
    ms, subscribe again, and wait another 55 ms. The `pauseMs()` method is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE161]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE162]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE163]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE164]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE165]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE166]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE167]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run the preceding example, the output will look similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_15.5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, each of the pipelines processed every value emitted by the cold
    observable.
  prefs: []
  type: TYPE_NORMAL
- en: 'To convert the *cold* observable into a *hot* one, we use the `publish()` method,
    which converts the observable into a `ConnectableObservable` object that extends
    the `Observable` object (see the `HotObservable` class and the `hot1()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE168]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE169]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE170]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE171]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE172]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE173]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE174]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, we have to call the `connect()` method so that the `ConnectableObservable`
    object starts emitting values. The output looks similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_15.6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding output shows that the second pipeline did not receive the first
    three values because it was subscribed to the observable later on. So, the observable
    emits values independent of the ability of the observers to process them. If the
    processing falls behind, and new values keep coming while the previous ones are
    not fully processed yet, the `Observable` class puts them into a buffer. If this
    buffer grows large enough, the JVM can run out of memory because, as we mentioned
    earlier, the `Observable` class is not capable of backpressure management.
  prefs: []
  type: TYPE_NORMAL
- en: 'For such cases, the `Flowable` class is a better candidate for the observable
    because it does have the ability to handle backpressure. Here is an example (see
    the `HotObservable` class and the `hot2()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE175]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE176]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE177]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE178]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE179]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE180]'
  prefs: []
  type: TYPE_PRE
- en: The `PublishProcessor` class extends `Flowable` and has an `onNext(Object o)`
    method that forces it to emit the passed-in object. Before calling it, we have
    subscribed to the observable using the `Schedulers.io()` thread. We will talk
    about schedulers in the *Multithreading (scheduler)* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `subscribe()` method has several overloaded versions. We decided to use
    the one that accepts two `Consumer` functions: the first one processes the passed-in
    value, and the second one processes an exception if it was thrown by any of the
    pipeline operations (it works similar to a `Catch` block).'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we run the preceding example, it will successfully print the first 127 values
    and then throw `MissingBackpressureException`, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_15.7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The message in the exception provides a clue: `Could not emit value due to
    lack of requests`. Apparently, the rate of emitting values is higher than the
    rate of consuming them, while an internal buffer can only keep 128 elements. If
    we add a delay (to simulate a longer processing time), the result will be even
    worse (see the `HotObservable` class and the `hot3()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE181]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE182]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE183]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE184]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE185]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE186]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE187]'
  prefs: []
  type: TYPE_PRE
- en: Even the first 128 elements will not get through and the output will only have
    `MissingBackpressureException`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To address this issue, a backpressure strategy has to be set. For example,
    let’s drop every value that the pipeline did not manage to process (see the `HotObservable`
    class and the `hot4()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE188]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE189]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE190]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE191]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE192]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE193]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE194]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the strategy has to be set before the `observeOn()` operation, so
    it will be picked up by the created `Schedulers.io()` thread.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output shows that many of the emitted values were dropped. Here is an output
    fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_15.8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We will talk about other backpressure strategies in the *Operators* section
    when we overview the corresponding operators.
  prefs: []
  type: TYPE_NORMAL
- en: Disposable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Notice that a `subscribe()` method actually returns a `Disposable` object that
    can be queried to check whether the pipeline processing has been completed and
    disposed of (see the `DisposableUsage` class and the `disposable1()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE195]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE196]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE197]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE198]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE199]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE200]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE201]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE202]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE203]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE204]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE205]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE206]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE207]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE208]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE209]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE210]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE211]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE212]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE213]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE214]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE215]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE216]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, it is possible to enforce the disposing of a pipeline, thus effectively
    canceling the processing (see the `DisposableUsage` class and the `disposable2()`
    method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE217]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE218]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE219]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE220]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE221]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE222]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE223]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE224]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE225]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE226]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE227]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE228]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE229]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE230]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE231]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE232]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE233]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE234]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE235]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE236]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE237]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE238]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE239]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, by adding the call to `disposable.dispose()`, we have stopped
    processing, so even after a delay of 200 ms, the list remains empty (see the last
    line of the preceding example).
  prefs: []
  type: TYPE_NORMAL
- en: This method of forced disposal can be used to make sure that there are no runaway
    threads. Each created `Disposable` object can be disposed of in the same way that
    resources are released in a `finally` block. The `CompositeDisposable` class helps
    us to handle multiple `Disposable` objects in a coordinated manner.
  prefs: []
  type: TYPE_NORMAL
- en: When an `onComplete` or `onError` event happens, the pipeline is disposed of
    automatically.
  prefs: []
  type: TYPE_NORMAL
- en: For example, you can use the `add()` method and add a newly created `Disposable`
    object to the `CompositeDisposable` object. Then, when necessary, the `clear()`
    method can be invoked on the `CompositeDisposable` object. It will remove the
    collected `Disposable` objects and call the `dispose()` method on each of them.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an observable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You have already seen a few methods of how to create an observable in our examples.
    There are many other factory methods, including `Observable`, `Flowable`, `Single`,
    `Maybe`, and `Completable`. However, not all of the following methods are available
    in each of these interfaces (see the comments; *all* means that all of the listed
    interfaces have it):'
  prefs: []
  type: TYPE_NORMAL
- en: '`create()`: This creates an `Observable` object by providing the full implementation
    (all).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`defer()`: This creates a new `Observable` object every time a new `Observer`
    subscribes (all).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`empty()`: This creates an empty `Observable` object that completes immediately
    upon subscription (all, except for `Single`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`never()`: This creates an `Observable` object that does not emit anything
    and does nothing at all; it does not even complete (all).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`error()`: This creates an `Observable` object that emits an exception immediately
    upon subscription (all).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fromXXX()`: This creates an `Observable` object, where XXX can be *Callable*,
    *Future* (all), *Iterable*, *Array*, *Publisher* (`Observable` and `Flowable`),
    *Action*, or *Runnable* (`Maybe` and `Completable`); this means it creates an
    `Observable` object based on the provided function or object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generate()`: This creates a cold `Observable` object that generates values
    based on the provided function or object (`Observable` and `Flowable` only).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`range(), rangeLong(), interval(), intervalRange()`: This creates an `Observable`
    object that emits sequential `int` or `long` values, which may or may not be limited
    by the specified range and spaced by the specified time interval (`Observable`
    and `Flowable` only).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`just()`: This creates an `Observable` object based on the provided object
    or a set of objects (all, except for `Completable`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timer()`: This creates an `Observable` object that, after the specified time,
    emits an `0L` signal (all) and then completes for `Observable` and `Flowable`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are also many other helpful methods, such as `repeat()`, `startWith()`,
    and more. We just do not have enough space to list all of them. Refer to the online
    documentation ([http://reactivex.io/RxJava/2.x/javadoc/index.html](http://reactivex.io/RxJava/2.x/javadoc/index.html)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at an example of the `create()` method usage. The `create()` method
    of `Observable` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE240]'
  prefs: []
  type: TYPE_PRE
- en: 'The passed-in object has to be an implementation of the `ObservableOnSubscribe<T>`
    functional interface, which only has one abstract method, `subscribe()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE241]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ObservableEmitter<T>` interface contains the following methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`boolean isDisposed()`: This returns `true` if the processing pipeline was
    disposed of or the emitter was terminated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ObservableEmitter<T> serialize()`: This provides the serialization algorithm
    used by the calls to `onNext()`, `onError()`, and `onComplete()`, located in the
    `Emitter` base class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void setCancellable(Cancellable c)`: This sets, on this emitter, a `Cancellable`
    implementation (that is, a functional interface that has only one method, `cancel()`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void setDisposable(Disposable d)`: This sets, on this emitter, a `Disposable`
    implementation (which is an interface that has two methods: `isDispose()` and
    `dispose()`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`boolean tryOnError(Throwable t)`: This handles the error condition, attempts
    to emit the provided exception, and returns `false` if the emission is not allowed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To create an observable, all the preceding interfaces can be implemented as
    follows (see the `CreateObservable` class and the `main()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE242]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE243]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE244]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE245]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE246]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE247]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE248]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE249]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE250]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE251]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE252]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s take a closer look at the preceding example. We created an `ObservableOnSubscribe`
    function as `source` and implemented the emitter: we told the emitter to emit
    `One` at the first call to `onNext()`, to emit `Two` at the second call to `onNext()`,
    and then to call `onComplete()`. We passed the `source` function to the `create()`
    method and built the pipeline to process all of the emitted values.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To make it more interesting, we added the `filter()` operator, which only allows
    you to further propagate the values with the *w* character. Additionally, we chose
    the `subscribe()` method version with three parameters: the `Consumer onNext`,
    `Consumer onError`, and `Action onComplete` functions. The first is called every
    time a next value reached the method, the second is called when an exception was
    emitted, and the third is called when the source emits an `onComplete()` signal.
    After creating the pipeline, we paused for 100 ms to give the asynchronous process
    a chance to finish. The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_15.9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If we remove the `emitter.onComplete()` line from the emitter implementation,
    only the message `Two` will be displayed.
  prefs: []
  type: TYPE_NORMAL
- en: So, those are the basics of how the `create()` method can be used. As you can
    see, it allows for full customization. In practice, it is rarely used because
    there are far simpler ways to create an observable. We will review them in the
    following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, you will see examples of other factory methods that are used in
    our examples throughout other sections of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Operators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are literally hundreds (if we count all of the overloaded versions) of
    operators available in each of the observable interfaces, `Observable`, `Flowable`,
    `Single`, `Maybe`, and `Completable`.
  prefs: []
  type: TYPE_NORMAL
- en: In the `Observable` and `Flowable` interfaces, the number of methods goes beyond
    500\. That is why, in this section, we are going to provide just an overview and
    a few examples that will help you to navigate the maze of possible options.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have grouped all the operators into 10 categories: transforming, filtering,
    combining, converting from XXX, exceptions handling, life cycle events handling,
    utilities, conditionals and Booleans, backpressure, and connectable.'
  prefs: []
  type: TYPE_NORMAL
- en: Please note that these are not all of the operators that are available. You
    can see more in the online documentation ([http://reactivex.io/RxJava/2.x/javadoc/index.html](http://reactivex.io/RxJava/2.x/javadoc/index.html)).
  prefs: []
  type: TYPE_NORMAL
- en: Transforming
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following operators transform the values emitted by an observable:'
  prefs: []
  type: TYPE_NORMAL
- en: '`buffer()`: This collects the emitted values into bundles according to the
    provided parameters or by using the provided functions. It periodically emits
    these bundles one at a time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`flatMap()`: This produces observables based on the current observable and
    inserts them into the current flow; it is one of the most popular operators.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`groupBy()`: This divides the current `Observable` object into groups of observables
    (`GroupedObservables` objects).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`map()`: This transforms the emitted value using the provided function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scan()`: This applies the provided function to each value in combination with
    the value produced as the result of the previous application of the same function
    to the previous value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`window()`: This emits groups of values similar to `buffer()` but as observables,
    each of which emits a subset of values from the original observable and then terminates
    with `onCompleted()`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code demonstrates the use of `map()`, `flatMap()`, and `groupBy()`
    (see the `NonBlockingOperators` class and the `transforming()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE253]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE254]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE255]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE256]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE257]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE258]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE259]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE260]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE261]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE262]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE263]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE264]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE265]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE266]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE267]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE268]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE269]'
  prefs: []
  type: TYPE_PRE
- en: Filtering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following operators (and their multiple overloaded versions) select which
    of the values will continue to flow through the pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '`debounce()`: This emits a value only when a specified span of time has passed
    without the observable emitting another value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`distinct()`: This selects unique values only.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`elementAt(long n)`: This emits only one value with the specified `n` position
    in the stream.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`filter()`: This emits only the values that match the specified criteria.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`firstElement()`: This emits the first value only.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ignoreElements()`: This does not emit values; only the `onComplete()` signal
    goes through.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lastElement()`: This emits the last value only.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sample()`: This emits the most recent value emitted within the specified time
    interval.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`skip(long n)`: This skips the first `n` values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`take(long n)`: This only emits the first `n` values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code showcases examples of some of the uses of the preceding
    operators (see the `NonBlockingOperators` class and the `filtering()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE270]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE271]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE272]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE273]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE274]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE275]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE276]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE277]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE278]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE279]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE280]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE281]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE282]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE283]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE284]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE285]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE286]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE287]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE288]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE289]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE290]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE291]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE292]'
  prefs: []
  type: TYPE_PRE
- en: Combining
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following operators (and their multiple overloaded versions) create a new
    observable using multiple source observables:'
  prefs: []
  type: TYPE_NORMAL
- en: '`concat(src1, src2)`: This creates an `Observable` object that emits all values
    of `src1` and then all values of `src2`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`combineLatest(src1, src2, combiner)`: This creates an `Observable` object
    that emits a value emitted by either of the two sources combined with the latest
    value emitted by each source using the provided `combiner` function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`join(src2, leftWin, rightWin, combiner)`: This combines the values emitted
    by two observables during the `leftWin` and `rightWin` time windows according
    to the `combiner` function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`merge()`: This combines multiple observables into one; in contrast to `concat()`,
    it might interleave them, whereas `concat()` never interleaves the emitted values
    from different observables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`startWith(T item)`: This adds the specified value before emitting values from
    the source observable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`startWith(Observable<T> other)`: This adds the values from the specified observable
    before emitting values from the source observable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`switchOnNext(Observable<Observable> observables)`: This creates a new `Observable`
    object that emits the most-recently emitted values of the specified observables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`zip()`: This combines the values of the specified observables using the provided
    function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code demonstrates the use of some of these operators (see the
    `NonBlockingOperators` class and the `combined()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE293]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE294]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE295]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE296]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE297]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE298]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE299]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE300]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE301]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE302]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE303]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE304]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE305]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE306]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE307]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE308]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE309]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE310]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE311]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE312]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE313]'
  prefs: []
  type: TYPE_PRE
- en: Converting from XXX
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'These operators are pretty straightforward. Here is a list of from-XXX operators
    of the `Observable` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '`fromArray(T... items)`: This creates an `Observable` object from a varargs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fromCallable(Callable<T> supplier)`: This creates an `Observable` object from
    a `Callable` function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fromFuture(Future<T> future)`: This creates an `Observable` object from a
    `Future` object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fromFuture(Future<T> future, long timeout, TimeUnit unit)`: This creates an
    `Observable` object from a `Future` object with the timeout parameters applied
    to the `future`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fromFuture(Future<T> future, long timeout, TimeUnit unit, Scheduler scheduler)`:
    This creates an `Observable` object from a `Future` object with the timeout parameters
    applied to the `future` and the scheduler (note that `Schedulers.io()` is recommended;
    please see the *Multithreading (scheduler)* section).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fromFuture(Future<T> future, Scheduler scheduler)`: This creates an `Observable`
    object from a `Future` object on the specified scheduler (note that `Schedulers.io()`
    is recommended; please see the *Multithreading (scheduler)* section).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fromIterable(Iterable<T> source)`: This creates an `Observable` object from
    an iterable object (for example, `List`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fromPublisher(Publisher<T> publisher)`: This creates an `Observable` object,
    for example from a `Publisher` object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exceptions handling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `subscribe()` operator has an overloaded version that accepts the `Consumer<Throwable>`
    function, which handles exceptions raised anywhere in the pipeline. It works in
    a similar way to the all-embracing `try-catch` block. If you have this function
    passed into the `subscribe()` operator, you can be sure that is the only place
    where all exceptions will end up.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if you need to handle the exceptions in the middle of the pipeline,
    the values flow can be recovered and processed by the rest of the operators, that
    is, after the operator has thrown the exception. The following operators (and
    their multiple overloaded versions) can help with that:'
  prefs: []
  type: TYPE_NORMAL
- en: '`onErrorXXX()`: This resumes the provided sequence when an exception was caught;
    XXX indicates what the operator does: `onErrorResumeNext()`, `onErrorReturn()`,
    or `onErrorReturnItem()`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`retry()`: This creates an `Observable` object that repeats the emissions emitted
    from the source; it resubscribes to the source `Observable` if it calls `onError()`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The demo code appears as follows (see the `NonBlockingOperators` class and
    the `exceptions()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE314]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE315]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE316]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE317]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE318]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE319]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE320]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE321]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE322]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE323]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE324]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE325]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE326]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE327]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE328]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE329]'
  prefs: []
  type: TYPE_PRE
- en: Life cycle events handling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: These operators are each invoked on a certain event that happened anywhere in
    the pipeline. They work similarly to the operators described in the *Exceptions
    handling* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The format of these operators is `doXXX()`, where XXX is the name of the event:
    `onComplete`, `onNext`, `onError`, and similar. Not all of them are available
    in all the classes, and some of them are slightly different in `Observable`, `Flowable`,
    `Single`, `Maybe`, or `Completable`. However, we do not have space to list all
    the variations of all these classes and will limit our overview to a few examples
    of the life cycle events-handling operators of the `Observable` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '`doOnSubscribe(Consumer<Disposable> onSubscribe)`: This executes when an observer
    subscribes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`doOnNext(Consumer<T> onNext)`: This applies the provided `Consumer` function
    when the source observable calls `onNext`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`doAfterNext(Consumer<T> onAfterNext)`: This applies the provided `Consumer`
    function to the current value after it is pushed downstream.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`doOnEach(Consumer<Notification<T>> onNotification)`: This executes the `Consumer`
    function for each emitted value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`doOnEach(Observer<T> observer)`: This notifies an `Observer` object for each
    emitted value and the terminal event it emits.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`doOnComplete(Action onComplete)`: This executes the provided `Action` function
    after the source observable generates the `onComplete` event.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`doOnDispose(Action onDispose)`: This executes the provided `Action` function
    after the pipeline was disposed of downstream.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`doOnError(Consumer<Throwable> onError)`: This executes when the `onError`
    event is sent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`doOnLifecycle(Consumer<Disposable> onSubscribe, Action onDispose)`: This calls
    the corresponding `onSubscribe` or `onDispose` function for the corresponding
    event.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`doOnTerminate(Action onTerminate)`: This executes the provided `Action` function
    when the source observable generates the `onComplete` event or an exception (the
    `onError` event) is raised.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`doAfterTerminate(Action onFinally)`: This executes the provided `Action` function
    after the source observable generates the `onComplete` event or an exception (the
    `onError` event) is raised.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`doFinally(Action onFinally)`: This executes the provided `Action` function
    after the source observable generates the `onComplete` event or an exception (the
    `onError` event) is raised, or the pipeline was disposed of downstream.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is demo code (see the `NonBlockingOperators` class and the `events()`
    method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE330]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE331]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE332]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE333]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE334]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE335]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE336]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run this code, the output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_15.10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You will also see other examples of these operators’ usage in the *Multithreading
    (scheduler)* section.
  prefs: []
  type: TYPE_NORMAL
- en: Utilities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Various useful operators (and their multiple overloaded versions) can be used
    for controlling the pipeline behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '`delay()`: This delays the emission for a specified period.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`materialize()`: This creates an `Observable` object that represents both the
    emitted values and the notifications sent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dematerialize()`: This reverses the result of the `materialize()` operator.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`observeOn()`: This specifies the `Scheduler` (thread) on which the `Observer`
    should observe the `Observable` object (see the *Multithreading (scheduler)* section).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`serialize()`: This forces the serialization of the emitted values and notifications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`subscribe()`: This subscribes to the emissions and notifications from an observable;
    various overloaded versions accept callbacks used for a variety of events, including
    `onComplete` and `onError`; only after `subscribe()` is invoked do the the values
    start flowing through the pipeline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`subscribeOn()`: This subscribes the `Observer` to the `Observable` object
    asynchronously using the specified `Scheduler` (see the *Multithreading (scheduler)*
    section).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeInterval(), timestamp()`: This converts an `Observable<T>` class that
    emits values into `Observable<Timed<T>>`, which, in turn, emits the amount of
    time elapsed between the emissions or the timestamp correspondingly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeout()`: This repeats the emissions of the source `Observable`; it generates
    an error if no emissions happen after the specified period of time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`using()`: This creates a resource that is disposed of automatically along
    with the `Observable` object; it works similarly to the try-with-resources construct.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code contains examples of some of these operators being used
    in a pipeline (see the `NonBlockingOperators` class and the `utilities()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE337]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE338]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE339]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE340]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE341]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE342]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE343]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE344]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE345]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE346]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE347]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE348]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE349]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE350]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE351]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE352]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE353]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run all these examples, the output will appear as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_15.11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, when completed, the pipeline sends the `DISPOSED` signal to
    the `using` operator (the third parameter), so the `Consumer` function we pass
    as the third parameter can dispose of the resources used by the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Conditional and Boolean
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following operators (and their multiple overloaded versions) allow you
    to the evaluate one or more observables or emitted values and change the logic
    of the processing accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: '`all(Predicate criteria)`: This returns `Single<Boolean>` with a `true` value,
    that is, if all the emitted values match the provided criteria.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`amb()`: This accepts two or more source observables and emits values from
    only the first of them that starts emitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`contains(Object value)`: This returns `Single<Boolean>` with `true`, that
    is, if the observable emits the provided value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`defaultIfEmpty(T value)`: This emits the provided value if the source `Observable`
    does not emit anything.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sequenceEqual()`: This returns `Single<Boolean>` with `true`, that is, if
    the provided sources emit the same sequence; an overloaded version allows us to
    provide the equality function used for comparison.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`skipUntil(Observable other)`: This discards emitted values until the provided
    `Observable other` emits a value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`skipWhile(Predicate condition)`: This discards emitted values as long as the
    provided condition remains `true`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`takeUntil(Observable other)`: This discards emitted values after the provided
    `Observable other` emits a value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`takeWhile(Predicate condition)`: This discards emitted values after the provided
    condition becomes `false`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code contains a few demo examples (see the `NonBlockingOperators`
    class and the `conditional()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE354]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE355]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE356]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE357]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE358]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE359]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE360]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE361]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE362]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE363]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE364]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE365]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE366]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE367]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE368]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE369]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE370]'
  prefs: []
  type: TYPE_PRE
- en: Backpressure
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'So, we discussed and demonstrated the **backpressure** effect and the possible
    drop strategy in the *Cold versus hot* section. The other strategy might be as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE371]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE372]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE373]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE374]'
  prefs: []
  type: TYPE_PRE
- en: The buffering strategy allows you to define the buffer size and provide a function
    that can be executed if the buffer overflows. The latest strategy tells the values
    producer to pause (when the consumer cannot process the emitted values on time)
    and emit the next value on request.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the backpressure operators are available only in the `Flowable` class.
  prefs: []
  type: TYPE_NORMAL
- en: Connectable
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The operators of this category allow us to connect observables and, thus, achieve
    more precisely controlled subscription dynamics:'
  prefs: []
  type: TYPE_NORMAL
- en: '`publish()`: This converts an `Observable` object into a `ConnectableObservable`
    object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`replay()`: This returns a `ConnectableObservable` object that repeats all
    the emitted values and notifications every time a new `Observer` subscribes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`connect()`: This instructs a `ConnectableObservable` object to begin emitting
    values to the subscribers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`refCount()`: This converts a `ConnectableObservable` object into an `Observable`
    object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have demonstrated how `ConnectableObservable` works in the *Cold versus hot*
    section. One principal difference between `ConnectableObservable` and `Observable`
    is that `ConnectableObservable` does not start emitting values until its `connect`
    operator has been called.
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading (scheduler)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By default, RxJava is single-threaded. This means that the source observable
    and all its operators notify the observers on the same thread that the `subscribe()`
    operator is called.
  prefs: []
  type: TYPE_NORMAL
- en: Тhere are two operators, `observeOn()` and `subscribeOn()`, that allow you to
    move the execution of individual actions to a different thread. These methods
    take a `Scheduler` object as an argument that, well, schedules the individual
    actions to be executed on a different thread.
  prefs: []
  type: TYPE_NORMAL
- en: The `subscribeOn()` operator declares which scheduler should emit the values.
  prefs: []
  type: TYPE_NORMAL
- en: The `observeOn()` operator declares which scheduler should observe and process
    values.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Schedulers` class contains factory methods that create `Scheduler` objects
    with different life cycles and performance configurations:'
  prefs: []
  type: TYPE_NORMAL
- en: '`computation()`: This creates a scheduler based on a bounded thread pool with
    a size up to the number of available processors; it should be used for CPU-intensive
    computations. Use `Runtime.getRuntime().availableProcessors()` to avoid using
    more of these types of schedulers than available processors; otherwise, the performance
    might become degraded because of the overhead of the thread-context switching.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`io()`: This creates a scheduler based on an unbounded thread pool used for
    I/O-related work, such as working with files and databases in general when the
    interaction with the source is blocking by nature; avoid using it otherwise because
    it might spin too many threads and negatively affect performance and memory usage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`newThread()`: This creates a new thread every time and does not use any pool;
    it is an expensive way to create a thread, so you are expected to know exactly
    what the reason is for using it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`single()`: This creates a scheduler based on a single thread that executes
    all the tasks sequentially; this is useful when the sequence of the execution
    matters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trampoline()`: This creates a scheduler that executes tasks in a first-in-first-out
    manner; this is useful for executing recursive algorithms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`from(Executor executor)`: This creates a scheduler based on the provided executor
    (thread pool), which allows for better control over the max number of threads
    and their life cycles.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In [*Chapter 8*](B18388_08_ePub.xhtml#_idTextAnchor187), *Multithreading and
    Concurrent Processing*, we talked about thread pools. To remind you, here are
    the pools we discussed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE375]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE376]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE377]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE378]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE379]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, some of the other factory methods of the `Schedulers` class
    are backed by one of these thread pools, and they serve as just a simpler and
    shorter expression of a thread pool declaration. To make the examples simpler
    and more comparable, we are only going to use a `computation()` scheduler. Let’s
    look at the basics of parallel/concurrent processing in RxJava.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code is an example of delegating CPU-intensive calculations to
    dedicated threads (see the `Scheduler` class and the `parallel1()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE380]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE381]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE382]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE383]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE384]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE385]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE386]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE387]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE388]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE389]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE390]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE391]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE392]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we decided to create a sub-flow of characters from each emitted
    word and let a dedicated thread process the characters of each word. The output
    of this example appears as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_15.12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the main thread was used to emit the words, and the characters
    of each word were processed by a dedicated thread. Please note that although in
    this example the sequence of the results coming to the `subscribe()` operation
    corresponds to the sequence the words and characters were emitted, in real-life
    cases, the calculation time of each value will not be the same. So, there is no
    guarantee that the results will come in the same sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'If needed, we can put each word emission on a dedicated non-main thread too,
    so the main thread can be free to do anything else. For example, note the following
    (see the `Scheduler` class and the `parallel2()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE393]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE394]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE395]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE396]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE397]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE398]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE399]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE400]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE401]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE402]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE403]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this example is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_15.13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the main thread no longer emits the words.
  prefs: []
  type: TYPE_NORMAL
- en: 'In RxJava 2.0.5, a new, simpler way of parallel processing was introduced,
    similar to parallel processing in the standard Java 8 streams. Using `ParallelFlowable`,
    the same functionality can be achieved as follows (see the `Scheduler` class and
    the `parallel3()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE404]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE405]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE406]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE407]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE408]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE409]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE410]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE411]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE412]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE413]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE414]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE415]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the `ParallelFlowable` object is created by applying the `parallel()`
    operator to the regular `Flowable` operator. Then, the `runOn()` operator tells
    the created observable to use the `computation()` scheduler to emit the values.
    Please note that there is no need to set another scheduler (for processing the
    characters) inside the `flatMap()` operator. It can be set outside it – just in
    the main pipeline, which makes the code simpler. The result looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Text'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B18388_Figure_15.14.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'As for the `subscribeOn()` operator, its location in the pipeline does not
    play any role. Wherever it is placed, it still tells the observable which scheduler
    should emit the values. Here is an example (see the `Scheduler` class and the
    `subscribeOn1()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE416]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE417]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE418]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE419]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE420]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE421]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE422]'
  prefs: []
  type: TYPE_PRE
- en: 'The result looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_15.15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Even if we change the location of the `subscribeOn()` operator, as shown in
    the following example, the result does not change (see the `Scheduler` class and
    the `subscribeOn2()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE423]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE424]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE425]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE426]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE427]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE428]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE429]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, here is the example with both operators (see the `Scheduler` class
    and the `subscribeOnAndObserveOn()` method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE430]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE431]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE432]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE433]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE434]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE435]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE436]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE437]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the result shows that two threads are used: one for subscribing and another
    for observing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_15.16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This concludes our short overview of RxJava, which is a big and still-growing
    library with a lot of possibilities, many of which we just did not have space
    in this book to review. We encourage you to try and learn it because it seems
    that reactive programming is the way modern data processing is heading.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapters, we will demonstrate how to build reactive applications
    (microservices) using Spring Boot and Vert.x.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, you learned what reactive programming is and what its main
    concepts are: asynchronous, non-blocking, responsive, and more. Reactive streams
    were introduced and explained in simple terms, along with the RxJava library,
    which is the first solid implementation that supports reactive programming principles.'
  prefs: []
  type: TYPE_NORMAL
- en: Now you can write code for asynchronous processing using reactive programming.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will talk about microservices as the foundation for
    creating reactive systems, and we will review another library that successfully
    supports reactive programming: **Vert.x**. We will use it to demonstrate how various
    microservices can be built.'
  prefs: []
  type: TYPE_NORMAL
- en: Quiz
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Select all the correct statements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Asynchronous processing always provides results later.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Asynchronous processing always provides responses quickly.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Asynchronous processing can use parallel processing.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Asynchronous processing always provides results faster than a blocking call.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Can `CompletableFuture` be used without using a thread pool?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the *nio* in `java.nio` stand for?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is an `event` loop the only design that supports a non-blocking API?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the *Rx* in RxJava stand for?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which Java package of the **Java Class Library** (**JCL**) supports reactive
    streams?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select all classes from the following list that can represent an observable
    in a reactive stream:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Flowable`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Probably`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`CompletableFuture`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Single`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: How do you know that a particular method (operator) of the `Observable` class
    is blocking?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between a cold and a hot observable?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `subscribe()` method of `Observable` returns a `Disposable` object. What
    happens when the `dispose()` method is called on this object?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select all the names of the methods that create an `Observable` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`interval()`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`new()`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`generate()`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`defer()`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Name two transforming `Observable` operators.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name two filtering `Observable` operators.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name two backpressure-processing strategies.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name two `Observable` operators that allow you to add threads to the pipeline
    processing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
