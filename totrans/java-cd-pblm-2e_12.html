<html><head></head><body>
  <div id="_idContainer312" class="Basic-Text-Frame">
    <h1 class="chapterNumber">12</h1>
    <h1 id="_idParaDest-519" class="chapterTitle">Garbage Collectors and Dynamic CDS Archives</h1>
    <p class="normal">This chapter includes 15 problems covering garbage collectors and <strong class="keyWord">Application Class Data Sharing</strong> (<strong class="keyWord">AppCDS</strong>). </p>
    <p class="normal">By the end of this chapter, you’ll have a profound understanding of how a <strong class="keyWord">garbage collector</strong> (<strong class="keyWord">GC</strong>) works and how you can tune it for maximum performance. Moreover, you’ll have a good understanding of how AppCDS can boost your application startup.</p>
    <h1 id="_idParaDest-520" class="heading-1">Problems</h1>
    <p class="normal">Use the following problems to test your advanced programming prowess in garbage collectors and application class data sharing in Java. I strongly encourage you to give each problem a try before you turn to the solutions and download the example programs:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="243"><strong class="keyWord">Hooking the garbage collector goal</strong>: Introduce Java garbage collectors quickly. Highlight the main objectives (advantages) and disadvantages of a garbage collector.</li>
      <li class="numberedList"><strong class="keyWord">Handling the garbage collector stages</strong>: List and briefly describe the most common stages of a garbage collector.</li>
      <li class="numberedList"><strong class="keyWord">Covering some garbage collector terminology</strong>: A garbage collector has specific terminology. Provide here the main terms used in conjunction with garbage collectors.</li>
      <li class="numberedList"><strong class="keyWord">Tracing the generational GC process</strong>: Exemplify and explain a hypothetical scenario containing several consecutive runs of a generational garbage collector.</li>
      <li class="numberedList"><strong class="keyWord">Choosing the correct garbage collector</strong>: List and explain the three main factors that should be considered for choosing the correct garbage collector.</li>
      <li class="numberedList"><strong class="keyWord">Categorizing garbage collectors</strong>: Highlight the main categories of garbage collector across JDK’s evolution.</li>
      <li class="numberedList"><strong class="keyWord">Introducing G1</strong>: Provide a brief introduction to the G1 GC, including its design principles.</li>
      <li class="numberedList"><strong class="keyWord">Tackling G1 throughput improvements</strong>: List the main improvements of G1 GC throughput across JDK versions.</li>
      <li class="numberedList"><strong class="keyWord">Tackling G1 latency improvements</strong>: List the main improvements of G1 GC latency across JDK versions.</li>
      <li class="numberedList"><strong class="keyWord">Tackling G1 footprint improvements</strong>: List the main improvements of the G1 GC footprint across JDK versions.</li>
      <li class="numberedList"><strong class="keyWord">Introducing ZGC</strong>: Provide a brief introduction to the Z Garbage Collector.</li>
      <li class="numberedList"><strong class="keyWord">Monitoring garbage collectors</strong>: Explain and exemplify at least one tool for monitoring garbage collectors.</li>
      <li class="numberedList"><strong class="keyWord">Logging garbage collectors</strong>: Provide the steps needed to log the garbage collector activity. Moreover, highlight some tools capable of analyzing and plotting the logged data.</li>
      <li class="numberedList"><strong class="keyWord">Tuning garbage collectors</strong>: Explain how to tune garbage collectors, including G1 and ZGC.</li>
      <li class="numberedList"><strong class="keyWord">Introducing Application Class Data Sharing (AppCDS, or Java’s Startup Booster)</strong>: Give a quick and practical guide to using CDS and AppCDS in JDK 10/11, 13, and 19.</li>
    </ol>
    <p class="normal">The following sections describe solutions to the preceding problems. Remember that there usually isn’t a single correct way to solve a particular problem. Also, remember that the explanations shown here include only the most interesting and important details needed to solve the problems. Download the example solutions to see additional details and experiment with the programs at <a href="https://github.com/PacktPublishing/Java-Coding-Problems-Second-Edition/tree/main/Chapter12"><span class="url">https://github.com/PacktPublishing/Java-Coding-Problems-Second-Edition/tree/main/Chapter12</span></a>.</p>
    <h1 id="_idParaDest-521" class="heading-1">243. Hooking the garbage collector goal</h1>
    <p class="normal">Every programming language has to manage memory usage. Some programming languages delegate this task to programmers, while others leverage different mechanisms to partially control how <a id="_idIndexMarker1341"/>memory is used. Java programmers can focus 100% on the functionalities of the application and let the <em class="italic">garbage collector</em> manage how memory is used.</p>
    <p class="normal">The name <em class="italic">garbage collector </em>suggests an entity capable of finding and collecting garbage from memory. Actually, a garbage collector is a very complex process representing the climax of Java memory management that is capable of tracking every object from the heap and identifying and removing the ones that are not used/referenced by the application. The main advantages of a garbage collector include:</p>
    <ul>
      <li class="bulletList">The Java programmer doesn’t need to manually handle the allocation/deallocation of memory.</li>
      <li class="bulletList">The Java programmer doesn’t need to deal with <em class="italic">dangling</em> and <em class="italic">wild pointers</em> (<a href="https://en.wikipedia.org/wiki/Dangling_pointer"><span class="url">https://en.wikipedia.org/wiki/Dangling_pointer</span></a>).</li>
      <li class="bulletList">In a wide range of scenarios, a garbage collector prevents <em class="italic">memory leaks</em> (<a href="https://en.wikipedia.org/wiki/Memory_leak"><span class="url">https://en.wikipedia.org/wiki/Memory_leak</span></a>). However, this issue is not 100% covered.</li>
    </ul>
    <p class="normal">While these advantages are major, there are a few disadvantages as well:</p>
    <ul>
      <li class="bulletList">A garbage collector itself is a resource that needs CPU power to work. We’re talking about CPU power that is in addition to the CPU power needed by the application. More garbage collector activity requires more CPU power.</li>
      <li class="bulletList">The programmer <a id="_idIndexMarker1342"/>cannot control the garbage collector scheduler. This may cause performance issues at peaks or when the application deals with intensive computations.</li>
      <li class="bulletList">Some garbage collectors cause long and unpredictable pauses of the application.</li>
      <li class="bulletList">Learning and tuning the correct garbage collector can be really cumbersome.</li>
    </ul>
    <p class="normal">In the next problems, we’ll go deeper into this topic.</p>
    <h1 id="_idParaDest-522" class="heading-1">244. Handling the garbage collector stages</h1>
    <p class="normal">During its work, GC passes through different stages or steps. It can pass through <a id="_idIndexMarker1343"/>one or more of the following stages:</p>
    <ul>
      <li class="bulletList"><em class="italic">Mark</em> – In this stage, the GC identifies and marks (or paints) all pieces of memory (blocks) that are used (have references) and not used (have no references). The marked (painted) blocks are called <em class="italic">live objects</em>, while the rest are called <em class="italic">non-live objects</em>. <em class="italic">Imagine that you go to the pantry and identify all the fresh fruits and vegetables and separate them from the spoiled ones</em>.</li>
      <li class="bulletList"><em class="italic">Sweep</em> – In this stage, the GC removes all <em class="italic">non-live objects</em> from memory. <em class="italic">Next, you take all the spoiled fruits and vegetables out of the pantry and throw them away</em>.</li>
      <li class="bulletList"><em class="italic">Compact</em> – In this stage, the GC attempts to group the <em class="italic">live objects </em>closer together – in other words, it arranges the live objects at the start of the heap in a continuous sequence of memory blocks. So, compacting involves <em class="italic">defragmentation</em> and <em class="italic">relocation</em> of the <em class="italic">live objects</em>. The goal of compaction is to obtain large memory blocks that are free and ready to serve other objects. <em class="italic">Next, we go to the pantry and stack all the fruits and vegetables in crates so that we get as much free space as possible. We will use this space for other fruits and vegetables that we are going to buy</em>.</li>
      <li class="bulletList"><em class="italic">Copy</em> – This is another stage dedicated to organizing memory. It is an alternative to the <em class="italic">mark</em> stage. In this stage, the GC moves the <em class="italic">live objects</em> into a so-called <em class="italic">ToSpace</em>. The rest of the objects are considered <em class="italic">non-live</em> and remain in the so-called <em class="italic">FromSpace</em>.</li>
    </ul>
    <p class="normal">Typically, a GC <a id="_idIndexMarker1344"/>follows one of these three scenarios:</p>
    <ul>
      <li class="bulletList">Mark -&gt; Sweep -&gt; Compact</li>
      <li class="bulletList">Copy</li>
      <li class="bulletList">Mark -&gt; Compact</li>
    </ul>
    <p class="normal">Next, let’s cover some GC terminology.</p>
    <h1 id="_idParaDest-523" class="heading-1">245. Covering some garbage collector terminology</h1>
    <p class="normal">Garbage <a id="_idIndexMarker1345"/>collection has its own terminology that it is essential to know in order to better understand how it works. Some of these terms are presented here; we start with <em class="italic">epoch</em>, <em class="italic">single pass</em>, and <em class="italic">multiple passes</em>.</p>
    <h2 id="_idParaDest-524" class="heading-2">Epoch </h2>
    <p class="normal">A GC <a id="_idIndexMarker1346"/>works in cycles. A complete cycle of a GC is known <a id="_idIndexMarker1347"/>as an <em class="italic">epoch</em>.</p>
    <h2 id="_idParaDest-525" class="heading-2">Single and multiple passes</h2>
    <p class="normal">A GC can <a id="_idIndexMarker1348"/>handle its internal steps in a single <a id="_idIndexMarker1349"/>pass (<em class="italic">single-pass</em>) or multiple passes (<em class="italic">multi-pass</em>). In the case of <em class="italic">single-pass</em>, the GC groups multiple steps and handles them in a single run. On the other hand, in the case of <em class="italic">multi-pass</em>, the GC handles multiple steps in a sequence of several passes.</p>
    <h2 id="_idParaDest-526" class="heading-2">Serial and parallel</h2>
    <p class="normal">A GC is <a id="_idIndexMarker1350"/>considered <em class="italic">serial</em> if it <a id="_idIndexMarker1351"/>uses a single <a id="_idIndexMarker1352"/>thread. On <a id="_idIndexMarker1353"/>the other hand, a GC is considered <em class="italic">parallel</em> if it uses multiple threads.</p>
    <h2 id="_idParaDest-527" class="heading-2">Stop-the-World (STW) and concurrent</h2>
    <p class="normal">A GC <a id="_idIndexMarker1354"/>is of the type <em class="italic">Stop-the-World</em> (STW) if it <a id="_idIndexMarker1355"/>has to stop (temporarily suspend) the <a id="_idIndexMarker1356"/>application execution in order to carry out its cycle. On the <a id="_idIndexMarker1357"/>other hand, a GC is <em class="italic">concurrent</em> if it is capable of running at the same time as the application without affecting its execution.</p>
    <h2 id="_idParaDest-528" class="heading-2">Live set</h2>
    <p class="normal">A GC <em class="italic">live set</em> represents <a id="_idIndexMarker1358"/>all the <em class="italic">live objects</em> of the current <a id="_idIndexMarker1359"/>application. If there is no memory leak (or other issues), then the <em class="italic">live set</em> should have a constant load factor and a relatively constant size. During application execution, objects are added/removed from the heap and from the <em class="italic">live set </em>respectively.</p>
    <h2 id="_idParaDest-529" class="heading-2">Allocation rate</h2>
    <p class="normal">Java allows us to set the size of the heap memory via the <code class="inlineCode">–Xmx</code> options. This size should not exceed the <a id="_idIndexMarker1360"/>memory available on your machine (server) and should be big enough to <a id="_idIndexMarker1361"/>serve the <em class="italic">live set</em>. This can be achieved by taking into account the <em class="italic">allocation rate</em>, which is expressed as the amount of memory (for instance, MB) allocated per unit of time (for instance, seconds).</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Important note</strong></p>
      <p class="normal">As a rule of thumb, try to set the heap size as 2.5 to 5 times the average size of the <em class="italic">live set</em>. </p>
    </div>
    <p class="normal">In other words, when many objects are created, there will be many cleanups as well. This means that the GC will run at a high frequency and will need a higher <em class="italic">allocation rate</em>.</p>
    <h2 id="_idParaDest-530" class="heading-2">NUMA </h2>
    <p class="normal">NUMA is <a id="_idIndexMarker1362"/>the acronym for <a id="_idIndexMarker1363"/>non-uniform memory access. A processor has its own memory (called local memory) but it can also access the memory of other processors. Access to its local memory is faster than access to non-local memory. Basically, NUMA is a memory architecture that attempts to optimize access to local memory.</p>
    <h2 id="_idParaDest-531" class="heading-2">Region-based</h2>
    <p class="normal">A <em class="italic">region-based</em> GC divides <a id="_idIndexMarker1364"/>the heap into smaller (eventually equal) regions/chunks <a id="_idIndexMarker1365"/>of memory (for instance, G1 and ZGC are <em class="italic">region-based</em> GCs). Each such region can be allocated for different purposes.</p>
    <h2 id="_idParaDest-532" class="heading-2">Generational garbage collection</h2>
    <p class="normal"><em class="italic">Generational garbage collection</em> is an algorithm that excels in handling short-living objects. A GC that <a id="_idIndexMarker1366"/>implements this algorithm is called a <em class="italic">generational GC</em>.</p>
    <p class="normal">This algorithm <a id="_idIndexMarker1367"/>distinguishes between <em class="italic">young</em> and <em class="italic">old</em> objects and keeps them separate. The <em class="italic">young</em> objects are kept in an area called the <em class="italic">Young </em>generation or <em class="italic">Nursery</em> space, while the <em class="italic">old</em> objects are kept in an area called the <em class="italic">Old </em>generation or <em class="italic">Tenured</em> space. The following figure highlights the transitions of objects through the <em class="italic">Young</em> and <em class="italic">Old</em> generations:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_01.png" alt="Figure 12.1.png"/></figure>
    <p class="packt_figref">Figure 12.1: The transitions of objects through Young and Old generations</p>
    <p class="normal">As you can see, the <em class="italic">Young</em> generation is divided into two regions/spaces, named the <em class="italic">Eden</em> region or <em class="italic">Eden</em> space and the <em class="italic">Survivor</em> region or <em class="italic">Survivor</em> space. Initially, the <em class="italic">Young</em> generation is empty.</p>
    <p class="normal">Objects that are newly created are placed in the <em class="italic">Eden</em> space by default. However, there is an exception for extremely large objects, called <em class="italic">humongous objects</em>, that exceed 50% of the region’s size. These objects are placed directly into the <em class="italic">Old</em> generation area, which may cause performance issues due to the increased occurrence of <em class="italic">major</em>/<em class="italic">full</em> GC events. It is important to note that GCs can trigger different types of events:</p>
    <ul>
      <li class="bulletList"><em class="italic">MinorGC</em> – This event occurs in the <em class="italic">Young</em> generation when the <em class="italic">Eden</em> space becomes full. Its purpose is to collect <em class="italic">non-live</em> objects and promote the remaining ones into the <em class="italic">Survivor</em> space. This event is the most commonly triggered by a GC.</li>
      <li class="bulletList"><em class="italic">MajorGC </em>– This event occurs in the <em class="italic">Old</em> generation and is responsible for collecting garbage from this area.</li>
      <li class="bulletList"><em class="italic">MixedGC</em> – This is a <em class="italic">MinorGC</em> event followed by reclaiming the <em class="italic">Old</em> generation.</li>
      <li class="bulletList"><em class="italic">FullGC</em> – Clean up the <em class="italic">Young</em> and <em class="italic">Old</em> generations and perform compacting of the <em class="italic">Old</em> generation (we can programmatically force a <em class="italic">FullGC</em> via <code class="inlineCode">System.gc()</code> or <code class="inlineCode">Runtime.getRunTime().gc()</code>).</li>
    </ul>
    <p class="normal">Next, let’s return to the topic of the <em class="italic">Young</em> generation. During the <em class="italic">epoch</em> (a GC complete cycle), the objects <a id="_idIndexMarker1368"/>that survive (have not been garbage collected) are promoted into the <em class="italic">Survivor</em> space (the GC algorithm chooses between <em class="italic">Survivor space 0</em> (known as <em class="italic">S0</em> or <em class="italic">FromSpace</em>) or <em class="italic">1</em> (known as <em class="italic">S1</em> or <em class="italic">ToSpace</em>)). The objects that <a id="_idIndexMarker1369"/>don’t fit into the <em class="italic">Survivor</em> space (if any) will be moved into the <em class="italic">Tenured</em> space – this is known as <em class="italic">premature promotion</em>. Usually, the GC handles the <em class="italic">Eden</em> space pretty quickly via the <em class="italic">MinorGC</em> events. Using local variables with short-living methods encourages the usage of <em class="italic">Eden</em> space and sustains the GC’s performance.</p>
    <p class="normal">Objects that are considered old enough (they have survived during multiple epochs) are eventually promoted into the <em class="italic">Old</em> generation. This is an area typically (but not mandatorily) larger than the <em class="italic">Young</em> generation. Some GCs use a fixed delimitation between these areas (for instance, the <strong class="keyWord">Concurrent Mark Sweep</strong> (<strong class="keyWord">CMS</strong>) GC) while others use an elastic boundary between these areas (for instance, the G1 GC). The <em class="italic">Old</em> generation area takes a relatively long time to be garbage collected and has a lower frequency than the <em class="italic">Young</em> generation.</p>
    <p class="normal">As you can see in <em class="italic">Figure 12.1</em>, the heap also contains an area named the <em class="italic">Metadata</em> space. Before JDK 8, this area was named <em class="italic">PermGenSpace</em> or <em class="italic">Permanent</em> generation. This area is used to store classes and methods. This area is specially designed to grow beyond the heap size into the native memory (if the size of this area goes beyond the physical memory, the operating system will use virtual memory – but be aware that moving data between physical and virtual memory is a costly operation that will affect the application performance). Via <em class="italic">Metadata</em> space, JVM avoids out-of-memory errors. However, this area can be garbage collected in order to remove unused classes/methods. In this context, there are a few flags that can help us to tune it, but we will cover these flags in <em class="italic">Problem 256</em>.</p>
    <h1 id="_idParaDest-533" class="heading-1">246. Tracing the generational GC process</h1>
    <p class="normal">In this <a id="_idIndexMarker1370"/>problem, let’s start from an arbitrary initial state of a generational GC and follow a few hypothetical epochs (generally, all generational GC works more or less as you’ll see in this problem). We start with the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_02.png" alt="Figure 12.2.png"/></figure>
    <p class="packt_figref">Figure 12.2: GC initial state</p>
    <p class="normal">At its initial state, the GC has an almost full <em class="italic">Eden</em> space (it stores objects 1, 4, 5, 2, 6, and 3, and some free space – represented by those white gaps between objects) and empty <em class="italic">Survivor</em> and <em class="italic">Tenured</em> spaces. Moreover, object 7 should be added in the <em class="italic">Eden</em> space but there is <a id="_idIndexMarker1371"/>not enough memory for it. When the <em class="italic">Eden</em> space cannot accommodate more objects, the GC triggers a <em class="italic">MinorGC</em> event. First, the <em class="italic">non-live objects</em> are identified. Here (as you can see in the following diagram), we have three objects (5, 2, and 3) that should be collected as garbage:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_03.png" alt="Figure 12.3.png"/></figure>
    <p class="packt_figref">Figure 12.3: Identify the non-live objects from the Eden space</p>
    <p class="normal">These three objects are collected as garbage, so they are removed from the heap. Next, the <em class="italic">live objects</em> (1, 4, and 6) are moved into <em class="italic">Survivor space 0</em>. Finally, the new object (7) is added into the <em class="italic">Eden</em> space, as in the following figure:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_04.png" alt="Figure 12.4.png"/></figure>
    <p class="packt_figref">Figure 12.4: Removing objects from memory (5, 2, and 3), moving objects to Survivor space 0 (1, 4, and 6), and adding object 7 into the Eden space</p>
    <p class="normal">Here, an <em class="italic">epoch</em> (complete GC cycle) has ended. </p>
    <p class="normal">Later on, more <a id="_idIndexMarker1372"/>objects are added into the <em class="italic">Eden</em> space until it is almost full again:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_05.png" alt="Figure 12.5.png"/></figure>
    <p class="packt_figref">Figure 12.5: The Eden space is almost full again</p>
    <p class="normal">Adding the new object (12) requires a <em class="italic">Minor GC</em> event. Again, the <em class="italic">non-living objects</em> are identified as follows:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_06.png" alt="Figure 12.6.png"/></figure>
    <p class="packt_figref">Figure 12.6: There are non-live objects in the Eden and Survivor 0 spaces</p>
    <p class="normal">There are four objects that should be collected as garbage. In the <em class="italic">Eden</em> space, there are three objects (11, 10, and 9), and in <em class="italic">Survivor space 0</em>, there is one object (4). All four of these objects are removed from the heap. The <em class="italic">live objects</em> from <em class="italic">Survivor space 0</em> (1 and 6) are moved to <em class="italic">Survivor space 1</em>. The <em class="italic">live objects</em> from the <em class="italic">Eden</em> space (7 and 8) are also moved into <em class="italic">Survivor space 1</em>. At any moment in time, one of the <em class="italic">Survivor</em> spaces is empty. Finally, the new object (12) is added to <em class="italic">Eden</em> space, as in the following figure:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_07.png" alt="Figure 12.7.png"/></figure>
    <p class="packt_figref">Figure 12.7: At the end of another epoch</p>
    <p class="normal">Here, another <a id="_idIndexMarker1373"/>epoch has ended.</p>
    <p class="normal">Next, objects 13, 14, 15, and 16 are added to the <em class="italic">Eden</em> space, which is almost full again:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_08.png" alt="Figure 12.8.png"/></figure>
    <p class="packt_figref">Figure 12.8: There is no memory available for object 17</p>
    <p class="normal">Being almost full, the <em class="italic">Eden</em> space cannot accommodate the new object, 17. A new <em class="italic">Minor GC</em> event is triggered and objects 12, 15, 16, 13, 6, and 8 are identified as <em class="italic">non-live objects</em>:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_09.png" alt="Figure 12.9.png"/></figure>
    <p class="packt_figref">Figure 12.9: There are several non-live objects in different spaces</p>
    <p class="normal">These objects (12, 15, 16, 13, 6, and 8) are removed from the heap. Next, object 14 is moved <a id="_idIndexMarker1374"/>from the <em class="italic">Eden</em> space to <em class="italic">Survivor space 0</em>. Afterward, objects 1 and 7 (from <em class="italic">Survivor space 1</em>) are moved into <em class="italic">Survivor space 0</em>. Finally, the new object 17 is moved into the <em class="italic">Eden</em> space, as in the following figure:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_10.png" alt="Figure 12.10.png"/></figure>
    <p class="packt_figref">Figure 12.10: The new object (17) is added to the Eden space</p>
    <p class="normal">Here, another <em class="italic">epoch</em> has ended.</p>
    <p class="normal">We repeat the scenario and fill up the <em class="italic">Eden</em> space again. We stop when object 22 should be added into the <em class="italic">Eden</em> space:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_11.png" alt="Figure 12.11.png"/></figure>
    <p class="packt_figref">Figure 12.11: Trying to add in Eden space object 22</p>
    <p class="normal">As we already know, the GC marks all the <em class="italic">non-live objects</em> (here, 17, 21, 18, and 7):</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_12.png" alt="Figure 12.12.png"/></figure>
    <p class="packt_figref">Figure 12.12: Marking the non-live objects</p>
    <p class="normal">This time, the GC promotes object 1 (when it is considered old enough) from the <em class="italic">Young</em> generation <a id="_idIndexMarker1375"/>to the <em class="italic">Old</em> generation. Next, the objects from the <em class="italic">Eden</em> space (19 and 20) and the objects from <em class="italic">Survivor space 0</em> (14) are moved into <em class="italic">Survivor space 1</em>. The result is sketched in the next figure:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_13.png" alt="Figure 12.13.png"/></figure>
    <p class="packt_figref">Figure 12.13: We have the first object promoted to Old generation</p>
    <p class="normal">At the end of this <em class="italic">epoch</em>, we finally have an object (1) in <em class="italic">Tenured</em> space. Continuing to run <em class="italic">epoch</em> after <em class="italic">epoch</em> will eventually fill up the <em class="italic">Tenured</em> space, which will not be able to accommodate more objects. In other words, the <em class="italic">Minor GC</em> events (which are <em class="italic">stop-the-world</em> events) will reclaim the memory of the <em class="italic">Young</em> generation until the <em class="italic">Old</em> generation is full. When that happens, a <em class="italic">Mixed GC</em> or even <em class="italic">Full GC</em> event will be triggered (the <em class="italic">Full GC</em> is also an STW event and will handle the <em class="italic">Metadata</em> space as well).</p>
    <p class="normal">In a nutshell, this is how a GC works. Of course, there are many other internal/external factors that may influence the GC’s decisions.</p>
    <h1 id="_idParaDest-534" class="heading-1">247. Choosing the correct garbage collector</h1>
    <p class="normal">As you’ll see in the next problem, Java allows us to choose between several garbage collectors. There <a id="_idIndexMarker1376"/>is no silver bullet, so choosing the correct garbage collector for your particular application is an important decision that should be made based on three factors: <em class="italic">throughput</em>, <em class="italic">latency</em>, and <em class="italic">footprint</em>.</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_14.png" alt="Figure 12.14.png"/></figure>
    <p class="packt_figref">Figure 12.14: The factors that affect the choice of GC</p>
    <p class="normal"><em class="italic">Throughput</em> represents the total time spent running the application code vs. running the GC. For instance, your application may run 97% of the total time, so you have a throughput of 97%. The remaining 3% is the time spent running the GC.</p>
    <p class="normal"><em class="italic">Latency</em> measures how much the execution of the application is delayed by pauses caused by the GC. This is important because latency can affect the application’s responsiveness. These pauses may lead, at the interactivity level, to an unpleasant experience for the end users.</p>
    <p class="normal"><em class="italic">Footprint</em> represents the extra memory needed by the GC to run its algorithms. This is the memory needed in addition to the memory used by the application itself.</p>
    <p class="normal">Choosing the proper GC based on these three factors is a very subjective decision. You may need a massive throughput while you can bear latencies, or you may not be able to afford latencies because you have high interactivity with the end users, or your scalability is in direct correlation with limited physical memory, so you are really interested in the footprint factor. As you’ll see in the next problem, each GC type has its own advantages and disadvantages in the context of these three factors.</p>
    <h1 id="_idParaDest-535" class="heading-1">248. Categorizing garbage collectors</h1>
    <p class="normal">Garbage <a id="_idIndexMarker1377"/>collectors have evolved exactly as Java itself has evolved. Today (JDK 21), we distinguish between several GC types, as follows:</p>
    <ul>
      <li class="bulletList">Serial garbage collector</li>
      <li class="bulletList">Parallel garbage collector</li>
      <li class="bulletList">Garbage-First (G1) collector</li>
      <li class="bulletList">Z Garbage Collector (ZGC)</li>
      <li class="bulletList">Shenandoah Garbage Collector (not generational)</li>
      <li class="bulletList">Concurrent Mark Sweep (CMS) collector (deprecated)</li>
    </ul>
    <p class="normal">Let’s tackle the main aspects of each GC type.</p>
    <h2 id="_idParaDest-536" class="heading-2">Serial garbage collector</h2>
    <p class="normal">The serial garbage collector is an STW single-threaded generational collector. Before running <a id="_idIndexMarker1378"/>its own algorithms, this GC freezes/pauses all the application threads. This means that this GC is not suitable for multi-threaded <a id="_idIndexMarker1379"/>applications such as server-side components. However, being focused on a very small footprint (useful for small heaps), this collector is a good fit for single-threaded applications (and single-processor machines) that can easily accommodate and tolerate a significant latency (for instance, batch jobs or bulk processing).</p>
    <h2 id="_idParaDest-537" class="heading-2">Parallel garbage collector</h2>
    <p class="normal">The parallel garbage collector is an STW multi-threaded generational collector. Before running its <a id="_idIndexMarker1380"/>own algorithms, this GC freezes/pauses all the application threads, but it speeds up the garbage collection by using multiple threads. In other words, this GC <a id="_idIndexMarker1381"/>can take advantage of multi-processor machines and can be a good fit for multi-threaded applications that use medium/large datasets. This GC is focused on throughput rather than latency and comes with pauses of 1 second or more. So, if you are in a multi-threaded context that can afford pauses of 1 second or more, then this GC is the right choice.</p>
    <h2 id="_idParaDest-538" class="heading-2">Garbage-First (G1) collector</h2>
    <p class="normal">The Garbage-First (G1) collector is an STW multi-threaded, region-based, generational collector <a id="_idIndexMarker1382"/>focused on balanced performance. This <a id="_idIndexMarker1383"/>GC was introduced in JDK 7 update 4 as a default (since JDK 9) solution that sustains high throughput and low latency (a few hundred milliseconds). The price to pay for this performance is a more frequent rate of epochs. The GC will run more often, so be prepared to provide a CPU ready to accommodate more cycles than other GCs. This GC was designed for server-style applications that are executed on multi-processor machines with massive memory (large heap size). Also <a id="_idIndexMarker1384"/>known as a <em class="italic">mostly concurrent</em> collector, G1 performs <a id="_idIndexMarker1385"/>heavily next to the application <a id="_idIndexMarker1386"/>using equally sized spaces/regions (from 1 to 32 MB). So, if you can afford a large heap size and need low latency, then G1 is the proper choice. We will talk in detail about G1 in subsequent problems.</p>
    <h2 id="_idParaDest-539" class="heading-2">Z Garbage Collector (ZGC)</h2>
    <p class="normal">Z Garbage Collector (ZGC) was introduced for production starting with JDK 15 as a low-latency <a id="_idIndexMarker1387"/>GC that can handle large heap sizes (terabytes). Like G1, ZGC works <a id="_idIndexMarker1388"/>concurrently but it guarantees to not stop the application threads for more than a few milliseconds (the documentation even states that ZGC can perform with sub-millisecond max pause times). We will cover it in detail in subsequent problems.</p>
    <h2 id="_idParaDest-540" class="heading-2">Shenandoah Garbage Collector</h2>
    <p class="normal">Shenandoah Garbage Collector was introduced in JDK 12 (and became more reliable in JDK 17) as a very <a id="_idIndexMarker1389"/>low-latency, highly responsive GC (sub-millisecond pauses). It performs its job (including compaction) concurrently <a id="_idIndexMarker1390"/>with the application. Shenandoah pauses are extremely short and independent of the heap size. Garbage collecting a 1 GB heap or a 300 GB heap should produce similar pauses.</p>
    <h2 id="_idParaDest-541" class="heading-2">Concurrent Mark Sweep (CMS) collector (deprecated)</h2>
    <p class="normal">CMS is <a id="_idIndexMarker1391"/>a <em class="italic">mostly concurrent</em> collector deprecated <a id="_idIndexMarker1392"/>by G1. Since it is deprecated, I will not talk about it further.</p>
    <h1 id="_idParaDest-542" class="heading-1">249. Introducing G1</h1>
    <p class="normal">The G1 Garbage Collector is probably the most mature, maintained, and improved GC in Java. It was <a id="_idIndexMarker1393"/>introduced in JDK 7 update 4, and from JDK 9, it became the default GC. This GC sustains high throughput and low latency (a few hundred milliseconds), being known for its balanced performance.</p>
    <p class="normal">Internally, G1 splits the heap into equally small chunks (max size of 32 MB), which are independent of each other and can be allocated dynamically to <em class="italic">Eden</em>, <em class="italic">Survivor</em>, or <em class="italic">Tenured</em> spaces. Each such <a id="_idIndexMarker1394"/>chunk is called the G1 <em class="italic">heap region</em>. So, G1 is a region-based GC.</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_15.png" alt="Figure 12.15.png"/></figure>
    <p class="packt_figref">Figure 12.15: G1 splits the memory heap into equal small chunks</p>
    <p class="normal">This architecture has a significant number of advantages. Probably, the most important one is represented <a id="_idIndexMarker1395"/>by the fact that the <em class="italic">Old</em> generation can be cleaned up efficiently by cleaning it up in parts that sustain low latency.</p>
    <p class="normal">For a heap size smaller than 4 GB, G1 will create regions of 1 MB. For heaps between 4 and 8 GB, G1 will create regions of 2 MB, and so on, up to 32 MB for a heap of 64 GB or larger. Basically, the JVM sets a number of regions that have a power of 2 and between 1 and 32 MB (typically, during the application start, the JVM sets up around 2,000+ regions).</p>
    <h2 id="_idParaDest-543" class="heading-2">Design principles</h2>
    <p class="normal">G1 was <a id="_idIndexMarker1396"/>designed on a set of principles, as follows:</p>
    <ul>
      <li class="bulletList">Balanced performance – Designed to balance throughput and low latency to sustain performance.</li>
      <li class="bulletList">Generational – Dynamically split the heap into the <em class="italic">Young</em> and <em class="italic">Old</em> generations and focus on the <em class="italic">Young</em> generation, since in this region there is more garbage (most objects die in the <em class="italic">Young</em> generation region). The idea that most objects are short-lived is also known as the <em class="italic">generational hypothesis</em>.</li>
      <li class="bulletList">Incremental collecting of <em class="italic">Old</em> generation – G1 eventually moves objects from the <em class="italic">Young</em> to the <em class="italic">Old</em> generation and leaves them there to die slowly and collects them incrementally.</li>
      <li class="bulletList">Mostly concurrent – G1 strives to perform heavy tasks next to the application (concurrently) with low and predictable pauses.</li>
    </ul>
    <p class="normal">Thanks to these design principles, G1 has deprecated the CMS collector.</p>
    <h1 id="_idParaDest-544" class="heading-1">250. Tackling G1 throughput improvements</h1>
    <p class="normal">G1 has made major progress from JDK 8 to JDK 20. Some of these improvements have been reflected <a id="_idIndexMarker1397"/>in throughput. Of course, this throughput improvement is dependent on a lot of factors (application, machine, tuning, and so on) but you may expect at least 10% higher throughput in JDK 18/20 than in JDK 8.</p>
    <p class="normal">In order to increase throughput, G1 has passed through several changes, as follows.</p>
    <h2 id="_idParaDest-545" class="heading-2">Delaying the start of the Old generation</h2>
    <p class="normal">Starting <a id="_idIndexMarker1398"/>with JDK 9, G1 is heavily focused on collecting garbage from the <em class="italic">Young</em> generation while delaying the start (initialization, resource allocation, and so on) of the <em class="italic">Old</em> generation to the last moment (it anticipates when the <em class="italic">Old</em> generation should be started).</p>
    <h2 id="_idParaDest-546" class="heading-2">Focusing on easy pickings</h2>
    <p class="normal">By <a id="_idIndexMarker1399"/>easy pickings, we mean objects that are short-lived (for instance, temporary buffers), occupy a significant amount of heap, and can be collected easily at low cost with important benefits. Starting with JDK 9, G1 is highly focused on easy pickings.</p>
    <h2 id="_idParaDest-547" class="heading-2">Improving NUMA-aware memory allocation</h2>
    <p class="normal">NUMA <a id="_idIndexMarker1400"/>stands for non-uniform memory access and <a id="_idIndexMarker1401"/>it was described in <em class="italic">Problem 245</em>. G1 takes advantage of NUMA from JDK 14 and it is continuously improved. If NUMA is enabled, then JVM requires the OS to place G1 heap regions on NUMA nodes. At the end of this process, the whole heap should be located evenly across the NUMA nodes that are active.</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_16.png" alt="Figure 12.16.png"/></figure>
    <p class="packt_figref">Figure 12.16: Heap memory without and with NUMA</p>
    <p class="normal">The <a id="_idIndexMarker1402"/>relationship between G1 heap regions and memory pages (operating system pages – <a href="https://en.wikipedia.org/wiki/Page_(computer_memory)"><span class="url">https://en.wikipedia.org/wiki/Page_(computer_memory)</span></a> falls into one of these two cases:</p>
    <ul>
      <li class="bulletList">If the size of a G1 heap region is greater than or equal to the size of a memory page, then a G1 heap region will consist of multiple memory pages (<em class="italic">Figure 12.17</em>, left-hand side).</li>
      <li class="bulletList">If the size of a G1 heap region is smaller than or equal to the size of a memory page, then a memory page will consist of multiple G1 heap regions (<em class="italic">Figure 12.17</em>, right-hand side).</li>
    </ul>
    <figure class="mediaobject"><img src="../Images/B19665_12_17.png" alt="Figure 12.17.png"/></figure>
    <p class="packt_figref">Figure 12.17: G1 heap region and memory page relationship</p>
    <p class="normal">Without NUMA, the G1 GC allocates memory to threads from a single common memory allocator. With NUMA, there is a memory allocator per NUMA node, and memory is allocated to threads based on these NUMA nodes.</p>
    <p class="normal">Improving NUMA allocation awareness is a continuous goal of G1.</p>
    <h2 id="_idParaDest-548" class="heading-2">Parallelized full-heap collections</h2>
    <p class="normal">Among <a id="_idIndexMarker1403"/>other not-so-common optimizations, we have the parallelization of full-heap collection. This was added in JDK 10 as a solution to make full-heap collections as fast as possible.</p>
    <h2 id="_idParaDest-549" class="heading-2">Other improvements</h2>
    <p class="normal">Tons of small improvements have been added to JVM itself, and their effects are reflected in GC performance as well. This means that by simply updating to the latest JDK, our GC will perform better. You’ll notice an improvement of at least 10% between JDK 8 and JDK 20.</p>
    <h1 id="_idParaDest-550" class="heading-1">251. Tackling G1 latency improvements</h1>
    <p class="normal">G1 GC <a id="_idIndexMarker1404"/>latency has also recorded some improvements from JDK 8 to JDK 20 (which are obviously reflected in G1 GC throughput as well). </p>
    <p class="normal">In order to decrease latency, G1 has passed through several changes, as follows.</p>
    <h2 id="_idParaDest-551" class="heading-2">Merge parallel phases into a larger one</h2>
    <p class="normal">Starting with JDK 8, many aspects of G1 have been parallelized. In other words, at any moment <a id="_idIndexMarker1405"/>in time, we may have in execution multiple parallel phases. Starting with JDK 9, these parallel phases can be merged into a single larger one. In practice, this means less synchronization and less time spent creating/destroying threads. As a result, this improvement speeds up the parallelization processing, leading to less latency.</p>
    <h2 id="_idParaDest-552" class="heading-2">Reduction of metadata</h2>
    <p class="normal">Reduction <a id="_idIndexMarker1406"/>of metadata was added in JDK 11. Practically, G1 attempts to manage less metadata by reducing its amount as much as possible. Less data to manage means better latency. Of course, this means a smaller footprint as well.</p>
    <h2 id="_idParaDest-553" class="heading-2">Better work balancing</h2>
    <p class="normal">Work balancing was improved starting with JDK 11. In a nutshell, this means that threads that have <a id="_idIndexMarker1407"/>finished their current work can steal work from other threads. In practice, this means that the tasks are done faster since all threads are working (on their own work or on stolen work) and none of them are just hanging on. So, smarter algorithms have been developed to orchestrate and keep threads busy in order to finish the tasks faster and decrease latency. However, reducing the overhead of stealing work is still a subject of improvement.</p>
    <h2 id="_idParaDest-554" class="heading-2">Better parallelization</h2>
    <p class="normal">Better <a id="_idIndexMarker1408"/>parallelization is available starting with JDK 14. In practice, G1 removes all duplicates from potential areas with references. Afterward, it applies parallelization instead of brute force.</p>
    <h2 id="_idParaDest-555" class="heading-2">Better reference scanning</h2>
    <p class="normal">In order to sustain better parallelization, JDK 15 has also improved the reference scanning in the <a id="_idIndexMarker1409"/>collected areas. JDK 14 knows how to remove duplicates and parallelize the data processing, while JDK 15 knows how to scan references more optimally. Their effects are combined into decreasing latency.</p>
    <h2 id="_idParaDest-556" class="heading-2">Other improvements</h2>
    <p class="normal">A lot of time has been spent improving so-called uncommon situations. For instance, special attention has been focused on <em class="italic">evacuation failures</em> (the attempt of moving the <em class="italic">live objects</em> between two memory areas and compacting them is known as <em class="italic">evacuation fashion</em>, and when moving objects around leads to out-of-memory issues, then we have an <em class="italic">evacuation failure</em>). This corner case has been seriously improved in order to handle such scenarios faster than before (before JDK 17).</p>
    <h1 id="_idParaDest-557" class="heading-1">252. Tackling G1 footprint improvements</h1>
    <p class="normal">Between JDK 8 and JDK 20, the G1 footprint has been improved by focusing on efficient metadata <a id="_idIndexMarker1410"/>and freeing the memory as quickly as possible.</p>
    <p class="normal">In order to optimize its footprint, G1 has passed through several changes, as follows.</p>
    <h2 id="_idParaDest-558" class="heading-2">Maintain only the needed metadata</h2>
    <p class="normal">In order <a id="_idIndexMarker1411"/>to maintain only the needed metadata, JDK 11 is capable of concurrently (re)creating the needed data and freeing it as fast as possible. In JDK 17, the focus on the needed metadata has been reiterated and only the absolutely required data is kept around. Moreover, JDK 18 comes up with a denser representation of data. All these improvements are reflected in a smaller footprint.</p>
    <h2 id="_idParaDest-559" class="heading-2">Release memory</h2>
    <p class="normal">Starting <a id="_idIndexMarker1412"/>with JDK 17, the G1 GC is capable of concurrently releasing memory (giving it back to the OS). This means that memory can be optimally reused and is available to serve other tasks.</p>
    <h1 id="_idParaDest-560" class="heading-1">253. Introducing ZGC</h1>
    <p class="normal">Z Garbage <a id="_idIndexMarker1413"/>Collector (ZGC) was introduced for the first time (as an experimental feature) in JDK 11. It was promoted to the production stage (production ready) in JDK 15 under JEP 377. It continues to be improved as we speak – in JDK 21, ZGC sustains application performance by maintaining separate generations for young and old objects. Basically, this minimizes allocation stalls and heap memory overhead. Moreover, JDK 21 (JEP 439) has promoted ZGC’s status from Targeted to Completed.</p>
    <p class="normal">ZGC is concurrent (works at the same time as the application based on low-level concurrency primitives such as <em class="italic">load barriers</em> and <em class="italic">colored pointers</em>), tracing (traversing the object graph to identify <em class="italic">live</em> and <em class="italic">non-live</em> objects), and compacting (fight against fragmentation). It is also NUMA-aware and region-based.</p>
    <p class="normal">ZGC was specially designed as a low-latency, highly scalable GC capable of handling from small (a few megabytes; the documentation states 8 MB) to massive heaps (terabytes; the documentation states 16 TB) with pauses (pulse times) of a maximum of a few milliseconds (the documentation states sub-millisecond max pause times).</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_18.png" alt="Figure 12.18.png"/></figure>
    <p class="packt_figref">Figure 12.18: ZGC is focused on low latency</p>
    <p class="normal">It is very important to say that pauses don’t increase with the heap size (pulse times are O(1), so they execute in constant time).</p>
    <p class="normal">The shortcoming (trade-off) of ZGC relies on throughput. In other words, ZGC throughput is slightly reduced (a few percent, for instance from 0% to 10% in some cases) in comparison with G1 throughput.</p>
    <p class="normal">Starting <a id="_idIndexMarker1414"/>with JDK 16, ZGC takes advantage of a concurrent thread stack, and starting with JDK 18, it supports string de-duplication. These are just two of the major improvements next to many other improvements.</p>
    <p class="normal">ZGC is auto-tuned. In other words, as you’ll see in <em class="italic">Problem 256</em>, ZGC has just a few options that we can tune while most of the tuning is automatic.</p>
    <h2 id="_idParaDest-561" class="heading-2">ZGC is concurrent</h2>
    <p class="normal">G1 and ZGC are both concurrent, but they don’t follow the same path. ZGC strives to collect as much <a id="_idIndexMarker1415"/>garbage as possible in a concurrent fashion. For this, ZGC relies on three main lightweight (very short, sub-millisecond) pauses and three concurrent phases, as in the following figure:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_19.png" alt="Figure 12.19.png"/></figure>
    <p class="packt_figref">Figure 12.19: ZGC concurrency</p>
    <p class="normal">Each of the three phases is signaled by a synchronization point (pause):</p>
    <ul>
      <li class="bulletList"><em class="italic">Pause Mark Start – </em>This pause signals that the <em class="italic">Concurrent Mark</em> phase follows. During this synchronization point, ZGC prepares the current state for executing the <em class="italic">Concurrent Mark</em> phase. This is a lightweight pause that performs some settings on <em class="italic">colored pointers</em> and resets a few flags and counters. Next, the <em class="italic">Concurrent Mark</em> phase runs concurrently and marks the objects from the heap.</li>
      <li class="bulletList"><em class="italic">Pause Mark End – </em>This pause signals the end of the <em class="italic">Concurrent Mark </em>phase. It also pauses before executing the <em class="italic">Concurrent Prepare for Relocation </em>phase. This phase is responsible for locating all the <em class="italic">live</em> objects from sparsely populated regions and marks them as candidates to be moved/evacuated to other regions. Moreover, during this phase, ZGC deallocates regions that don’t contain <em class="italic">live</em> objects.</li>
      <li class="bulletList"><em class="italic">Pause Relocate Start </em>– This pause signals that the <em class="italic">Concurrent Relocate</em> phase follows. During this phase, the objects marked as evacuation candidates in the previous phase are effectively moved (copied) from the current region to the new region. Their references are also restored, being deallocated from the current region and reallocated to the new region.</li>
    </ul>
    <h2 id="_idParaDest-562" class="heading-2">ZGC and colored pointers</h2>
    <p class="normal">ZGC runs <a id="_idIndexMarker1416"/>next to the application and manipulates (moves around) the objects used by that application. This may lead to unexpected errors (for instance, the application may attempt to use out-of-date references) that cause the application to act weirdly or even crash. In order to prevent such scenarios, ZGC relies on two low-level concurrency primitives known as <em class="italic">colored pointer</em> and <em class="italic">load barriers</em>.</p>
    <p class="normal">A <em class="italic">colored pointer</em> is a 64-bit pointer. This pointer is used by ZGC with a 44-bit object address capable of handling up to 16 terabytes.</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_20.png" alt="Figure 12.20.png"/></figure>
    <p class="packt_figref">Figure 12.20: Colored pointer</p>
    <p class="normal">A <em class="italic">colored pointer</em> reserves 20 bits for storing metadata about this pointer. The most important metadata is:</p>
    <ul>
      <li class="bulletList"><em class="italic">Finalizable</em> – 1 bit that indicates if an object is reachable (<em class="italic">live</em> object)</li>
      <li class="bulletList"><em class="italic">Remapped</em> – 1 bit that indicates if an object doesn’t point into a relocation set</li>
      <li class="bulletList"><em class="italic">Marked0</em>/<em class="italic">Marked1</em> – 2 bits that indicate if an object is or is not marked</li>
    </ul>
    <p class="normal">As well as colored pointers, ZGC needs load barriers.</p>
    <h2 id="_idParaDest-563" class="heading-2">ZGC and load barriers</h2>
    <p class="normal"><em class="italic">Load barriers</em> are portions of code injected by the compiler to handle <em class="italic">colored pointers</em>. While the <a id="_idIndexMarker1417"/>application is not aware of <em class="italic">colored pointers</em>, ZGC needs to interpret and work with them, and this is exactly the job of <em class="italic">load barriers</em>. For instance, let’s assume that we have, in the application, the following snippet of code (I’ve intentionally added the line numbers manually):</p>
    <pre class="programlisting code"><code class="hljs-code">1: <span class="hljs-type">Manager</span> <span class="hljs-variable">manager</span> <span class="hljs-operator">=</span> company.manager;
2: <span class="hljs-type">Manager</span> <span class="hljs-variable">cManager</span> <span class="hljs-operator">=</span> manager;
3: manager.attendMeeting();
4: <span class="hljs-type">int</span> <span class="hljs-variable">employeeNr</span> = company.size;
</code></pre>
    <p class="normal">The compiler analyzes the code to decide where to inject a <em class="italic">load barrier</em>. The conclusion is that the only place where a <em class="italic">load barrier</em> should be injected is between lines 1 and 2 because that is the <a id="_idIndexMarker1418"/>only place where an object is loaded from the heap. In line 2, there is no need for a <em class="italic">load barrier</em> since there is a copy of the memory reference. In line 3, there is also no need for a <em class="italic">load barrier</em> since there is a method reference. Finally, in line 4, there is no need for a <em class="italic">load barrier</em> since there is no object reference. So, ZGC sees this code as follows:</p>
    <pre class="programlisting code"><code class="hljs-code">1: <span class="hljs-type">Manager</span> <span class="hljs-variable">manager</span> <span class="hljs-operator">=</span> company.manager;
<span class="code-highlight"><strong class="hljs-slc">&lt;load barrier injected at this point&gt;</strong></span>
2: <span class="hljs-type">Manager</span> <span class="hljs-variable">cManager</span> <span class="hljs-operator">=</span> manager;    <span class="hljs-comment">// copying reference</span>
3: manager.attendMeeting();       <span class="hljs-comment">// method reference</span>
4: <span class="hljs-type">int</span> <span class="hljs-variable">employeeNr</span> <span class="hljs-operator">=</span> company.size; <span class="hljs-comment">// no object reference</span>
</code></pre>
    <p class="normal">The purpose of the <em class="italic">load barrier</em> is to ensure that the pointers are valid (shown by having a good color). If a bad color is encountered, then the <em class="italic">load barrier</em> tries to heal it (update the pointer, relocate the object reference, and so on).</p>
    <h2 id="_idParaDest-564" class="heading-2">ZGC is region-based</h2>
    <p class="normal">ZGC is a <em class="italic">region-based </em>GC, so it divides the heap into smaller regions/chunks that are allocated <a id="_idIndexMarker1419"/>to the <em class="italic">Young</em> or <em class="italic">Old</em> generation, as in the following figure:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_21.png" alt="Figure 12.21.png"/></figure>
    <p class="packt_figref">Figure 12.21: ZGC heap regions</p>
    <p class="normal">Exactly like G1, ZGC is a <em class="italic">region-based</em> GC. Nevertheless, ZGC is more powerful than G1 and has the capability to dynamically increase/decrease the number of active regions during runtime. Moreover, ZGC can rely on regions of three sizes, as follows:</p>
    <ul>
      <li class="bulletList">Small region – These regions are 2 MB. </li>
      <li class="bulletList">Medium region – These regions can be from 4 MB to 32 MB. They are dynamically sized.</li>
      <li class="bulletList">Large region – These are regions reserved for <em class="italic">humongous</em> objects. These are tightly fitted regions that can be smaller or larger than a medium region.</li>
    </ul>
    <p class="normal">So, at a <a id="_idIndexMarker1420"/>glance, ZGC is a concurrent GC with constant pause times (sub-millisecond), working in parallel mode, and capable of fighting against fragmentation via compacting. Moreover, it is region-based, NUMA-aware, capable of auto-tuning, and relies on <em class="italic">colored pointers </em>and <em class="italic">load barriers</em>.</p>
    <h1 id="_idParaDest-565" class="heading-1">254. Monitoring garbage collectors</h1>
    <p class="normal">Monitoring the activity and evolution in the timeline of your GC is a major aspect in order to identify potential <a id="_idIndexMarker1421"/>performance issues. For instance, you may be interested in monitoring pause times, identifying the frequency and types of GC events, what spaces are filled up by the triggered GC events, and so on. The main goal is to collect as much information as possible that can be helpful in troubleshooting performance issues related to heap memory and GC evolution.</p>
    <p class="normal">Any modern IDE provides profilers that contain (among other related things) information and real-time graphs about the GC <em class="italic">epochs</em>/cycles. For instance, the following figure is from the NetBeans IDE, which displays the GC evolution (heap status) as an item of the toolbar (by simply clicking on that area, you can force the GC to perform garbage collection):</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_22.png" alt="Figure 12.22.png"/></figure>
    <p class="packt_figref">Figure 12.22: NetBeans display GC evolution on the toolbar</p>
    <p class="normal">Of course, a more detailed view is available via the NetBeans profiler:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_23.png" alt="Figure 12.23.png"/></figure>
    <p class="packt_figref">Figure 12.23: NetBeans profiler for GC</p>
    <p class="normal">Among other tools that can be used to monitor your GC are the <em class="italic">jstat</em> command-line utility (<code class="inlineCode">jstat -gc $JAVA_PID</code>) and <em class="italic">JConsole</em> (Java Monitoring and Management Console). </p>
    <p class="normal">The following <a id="_idIndexMarker1422"/>figure is a screenshot from <em class="italic">JConsole</em>:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_24.png" alt="Figure 12.24.png"/></figure>
    <p class="packt_figref">Figure 12.24: Monitoring the GC via JConsole</p>
    <p class="normal">You <a id="_idIndexMarker1423"/>may also <a id="_idIndexMarker1424"/>be interested <a id="_idIndexMarker1425"/>in <strong class="keyWord">visualgc</strong> (<strong class="keyWord">Visual Garbage Collection Monitoring Tool</strong>) from Oracle, <strong class="keyWord">JDK VisualGC</strong> (IntelliJ IDE plugin), and <strong class="keyWord">Memory Analyzer</strong> (<strong class="keyWord">MAT</strong>) from Eclipse.</p>
    <h1 id="_idParaDest-566" class="heading-1">255. Logging garbage collectors</h1>
    <p class="normal">Analyzing the GC logs is another approach that can be useful for finding memory issues. Since GC logs <a id="_idIndexMarker1426"/>don’t add a significant overhead, they can be enabled in production for debugging purposes. Really, GC logs have an insignificant overhead, so you should definitely use them!</p>
    <p class="normal">Let’s consider some simple Java code that adds and removes from <code class="inlineCode">List&lt;String&gt;</code>. Adding and removing the code requires a full GC via <code class="inlineCode">System.gc()</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> List&lt;String&gt; strings = <span class="hljs-keyword">new</span> <span class="hljs-title">ArrayList</span>&lt;&gt;();
...
logger.info(<span class="hljs-string">"Application started ..."</span>);
<span class="hljs-type">String</span> <span class="hljs-variable">string</span> <span class="hljs-operator">=</span> <span class="hljs-string">"prefixedString_"</span>;
<span class="hljs-comment">// Add in heap 5 millions String instances</span>
<span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">5_000_000</span>; i++) {
  <span class="hljs-type">String</span> <span class="hljs-variable">newString</span> <span class="hljs-operator">=</span> string + i;
  strings.add(newString);
}
logger.info(() -&gt; <span class="hljs-string">"List size: "</span> + strings.size());
<span class="hljs-comment">// Force GC execution</span>
System.gc();
<span class="hljs-comment">// Remove 10_000 out of 5 millions</span>
<span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10_000</span>; i++) {
  <span class="hljs-type">String</span> <span class="hljs-variable">newString</span> <span class="hljs-operator">=</span> string + i;
  strings.remove(newString); 
}
logger.info(() -&gt; <span class="hljs-string">"List size: "</span> + strings.size());
logger.info(<span class="hljs-string">"Application done ..."</span>);
</code></pre>
    <p class="normal">Next, we want to run this simple application and log the GC activity.</p>
    <p class="normal">Before JDK 9, we can obtain a quick and verbose log of GC via the <code class="inlineCode">-verbose:gc</code> option:</p>
    <pre class="programlisting con"><code class="hljs-con">java … -verbose:gc
</code></pre>
    <p class="normal">A possible output will look as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">[0.319s][info][gc] Using G1
<span class="code-highlight"><strong class="hljs-con-slc">[17:03:47] [INFO] Application started ... </strong></span>
[0.917s][info][gc] GC(0) Pause Young (Normal) 
        (G1 Evacuation Pause) 27M-&gt;24M(96M) 34.391ms
[0.948s][info][gc] GC(1) Pause Young (Normal) 
        (G1 Evacuation Pause) 40M-&gt;40M(96M) 21.300ms
[0.986s][info][gc] GC(2) Pause Young (Normal) 
        (G1 Evacuation Pause) 60M-&gt;60M(96M) 24.085ms
[0.997s][info][gc] GC(3) Pause Young (Concurrent Start) 
        (G1 Humongous Allocation) 63M-&gt;64M(96M) 8.072ms
[0.997s][info][gc] GC(4) Concurrent Mark Cycle
[1.030s][info][gc] GC(5) Pause Young (Normal) 
        (G1 Evacuation Pause) 78M-&gt;78M(288M) 17.036ms
[1.059s][info][gc] GC(4) Pause Remark 101M-&gt;94M(288M) 0.867ms
[1.083s][info][gc] GC(4) Pause Cleanup 109M-&gt;109M(288M) 0.14ms
[1.085s][info][gc] GC(4) Concurrent Mark Cycle 87.261ms
[1.125s][info][gc] GC(6) Pause Young (Prepare Mixed) 
        (G1 Evacuation Pause) 116M-&gt;118M(288M) 32.640ms
[1.220s][info][gc] GC(7) Pause Young (Mixed) 
        (G1 Evacuation Pause) 181M-&gt;181M(288M) 42.497ms
[1.257s][info][gc] GC(8) Pause Young (Concurrent Start) 
        (G1 Humongous Allocation) 200M-&gt;201M(288M) 23.297ms
[1.257s][info][gc] GC(9) Concurrent Mark Cycle
[1.316s][info][gc] GC(10) Pause Young (Normal) 
        (G1 Evacuation Pause) 243M-&gt;244M(288M) 24.492ms
[1.345s][info][gc] GC(11) Pause Young (Normal) 
        (G1 Evacuation Pause) 256M-&gt;258M(776M) 12.445ms
[1.400s][info][gc] GC(9) Pause Remark 290M-&gt;274M(776M) 0.732ms
[1.461s][info][gc] GC(9) Pause Cleanup 335M-&gt;335M(776M) 0.25ms
[1.466s][info][gc] GC(9) Concurrent Mark Cycle 209.289ms
[1.531s][info][gc] GC(12) Pause Young (Prepare Mixed) 
        (G1 Evacuation Pause) 344M-&gt;345M(776M) 54.939ms
<span class="code-highlight"><strong class="hljs-con-slc">[17:03:48] [INFO] List size: 5000000 </strong></span>
[1.830s][info][gc] GC(13) Pause Full (System.gc()) 
        368M-&gt;330M(776M) 277.793ms
<span class="code-highlight"><strong class="hljs-con-slc">[17:04:15] [INFO] List size: 4990000 </strong></span>
<span class="code-highlight"><strong class="hljs-con-slc">[17:04:15] [INFO] Application done ...</strong></span>
</code></pre>
    <p class="normal">This is the <a id="_idIndexMarker1427"/>simplest GC log. For more details, we can add the <code class="inlineCode">-XX:+PrintGCDetails</code> option:</p>
    <pre class="programlisting con"><code class="hljs-con">java … -XX:+PrintGCDetails -verbose:gc
</code></pre>
    <p class="normal">Moreover, we can attach a few options for obtaining information about tenuring distribution (<code class="inlineCode">-XX:+PrintTenuringDistribution</code>), garbage collector time stamps (<code class="inlineCode">-XX:+PrintGCTimeStamps</code>), the class histogram (<code class="inlineCode">-XX:+PrintClassHistogram</code>), and the application stopped time (<code class="inlineCode">-XX:+PrintGCApplicationStoppedTime</code>).</p>
    <p class="normal">In this context, GC logs are available on the console (stdout) using the info level. You can easily redirect the GC logs to a file via the <code class="inlineCode">-Xloggc</code> option:</p>
    <pre class="programlisting con"><code class="hljs-con">java … -verbose:gc -Xloggc:gclog.txt
</code></pre>
    <p class="normal">Actually, <code class="inlineCode">-Xloggc</code> is deprecated and you should use it only if you are using a JDK earlier than version 9. Starting with JDK 9 (JEP 158 – <a href="https://openjdk.org/jeps/158"><span class="url">https://openjdk.org/jeps/158</span></a>), we have a <em class="italic">unified logging system</em> for all JVM components.</p>
    <p class="normal">So, starting with JDK 9, we have a unified logging system via the <code class="inlineCode">–Xlog</code> option. The equivalent of <code class="inlineCode">-XX:+PrintGCDetails -verbose:gc</code> is <code class="inlineCode">-Xlog:gc*</code>. If we want to redirect GC logs to a file using the debug level, then we can do it as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">java … -Xlog:gc*=debug:file=gclog.txt
</code></pre>
    <p class="normal">The <code class="inlineCode">gclog.txt</code> will be saved in the application root folder. If you remove the <code class="inlineCode">*</code> character, then you’ll get a less verbose GC log.</p>
    <p class="normal">Logging only <a id="_idIndexMarker1428"/>NUMA logs is available via <code class="inlineCode">-Xlog:numa*={log level}</code>.</p>
    <p class="normal">Having the GC log is half of the problem. The other half consists of interpreting this log. As you can see, this is not that easy. Fortunately, you don’t have to bother reading the log files because we have tools capable of parsing, analyzing, and providing detailed reports from GC logs.</p>
    <p class="normal">One of <a id="_idIndexMarker1429"/>these tools is Universal GC Log Analyzer (<a href="https://gceasy.io/"><span class="url">https://gceasy.io/</span></a>). Using the free version, we can upload our <code class="inlineCode">gclog.txt</code> file and get a detailed report. For instance, in the following figure, we can see how memory was allocated for our application.</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_25.png" alt="Figure 12.25.png"/></figure>
    <p class="packt_figref">Figure 12.25: A screenshot from Universal GC Log Analyzer (GCEasy) report</p>
    <p class="normal">This figure is just a very small part of the report. Try it yourself to see the full report. Other similar tools that you may like to try are GCViewer, GCPlot, IBM Garbage Collection and Memory Visualizer, garbagecat, SolarWinds Loggly, Sematext Logs, <strong class="keyWord">Java Flight Recorder</strong> (<strong class="keyWord">JFR</strong>), jvm-gc-logs-analyzer, and so on.</p>
    <h1 id="_idParaDest-567" class="heading-1">256. Tuning garbage collectors</h1>
    <p class="normal">Garbage collectors are complex machinery whose performances are highly related to their settings (startup parameters) in the context of the current JVM, current application, and hardware. Since the <a id="_idIndexMarker1430"/>GC consumes and shares resources (memory, CPU time, and so on) with our application, it is essential to tune it to work as efficiently as possible. If the GC is not efficient, then we may face significant pause times that will negatively impact the application run.</p>
    <p class="normal">In this problem, we will cover the main tuning options available for the serial GC, parallel GC, G1 GC, and ZGC.</p>
    <h2 id="_idParaDest-568" class="heading-2">How to tune</h2>
    <p class="normal">Before attempting to tune the GC, ensure that it is really causing trouble. By inspecting and correlating the charts and logs, you can identify such troubles and decide where you should act (what parameters should be tuned). Check out the usage of the heap memory and how objects fill up the <em class="italic">Eden</em>, <em class="italic">Survivor</em>, and <em class="italic">Tenured</em> spaces.</p>
    <p class="normal">Typically, a healthy GC produces a heap usage graph known as <em class="italic">shark teeth</em>, as in the following figure:</p>
    <figure class="mediaobject"><img src="../Images/B19665_12_26.png" alt="Figure 12.26.png"/></figure>
    <p class="packt_figref">Figure 12.26: Healthy heap usage</p>
    <p class="normal">Moreover, check out the 90<sup class="superscript">th</sup> and 99<sup class="superscript">th</sup> percentiles along with the average GC time. This information can give you a hint about whether more memory is needed or if it is cleared properly.</p>
    <p class="normal">Once you identify the GC troubles, try to tackle them one by one. Don’t rush to change several parameters at once because it will be hard to manage and analyze their combined effect. Try to modify one of them and experiment to see what’s happening and what the results are. If you see some benefits, then go for the next one and experiment again. Observe if the combined effect has been improved or not. Otherwise, maybe it is better to restore this one to its default value before going for the next one.</p>
    <h2 id="_idParaDest-569" class="heading-2">Tuning the serial garbage collector</h2>
    <p class="normal">The serial <a id="_idIndexMarker1431"/>garbage collector can be enabled <a id="_idIndexMarker1432"/>via <code class="inlineCode">-XX:+UseSerialGC</code>. </p>
    <p class="normal">Since this is a single-threaded GC, there is not much to tune. However, you may adjust the heap size via <code class="inlineCode">–Xmx</code> and <code class="inlineCode">–Xms</code> (for instance, a heap size of 3 GB can be set via <code class="inlineCode">–Xmx3g</code> and <code class="inlineCode">–Xms3g</code>) and the <em class="italic">Young</em> generation size via the <code class="inlineCode">–Xmn</code> option. Nevertheless, these options work with all types of GC for setting the heap size.</p>
    <h2 id="_idParaDest-570" class="heading-2">Tunning the parallel garbage collector</h2>
    <p class="normal">The parallel garbage collector can be enabled via <code class="inlineCode">-XX:+UseParallelGC</code>.</p>
    <p class="normal">This GC is <a id="_idIndexMarker1433"/>multi-threaded and we can control the number <a id="_idIndexMarker1434"/>of threads used for cleaning tasks via the <code class="inlineCode">-XX:ParallelGCThreads</code> option (for instance, setting six threads can be done with <code class="inlineCode">-XX:ParallelGCThreads=6</code>). </p>
    <p class="normal">Keep in mind that a higher number of threads results in a higher fragmentation of the heap reserved for the <em class="italic">Tenured</em> space. Each thread that participates in a <em class="italic">Minor</em> GC event will reserve some space in the <em class="italic">Tenured</em> space for its promotions goals. This will lead to serious fragmentation of the <em class="italic">Tenured</em> space. Fixing this issue requires reducing the number of threads and increasing the size of the <em class="italic">Old</em> generation.</p>
    <p class="normal">The maximum pause time can be controlled via the <code class="inlineCode">-XX:MaxGCPauseMillis</code> option (for instance, <code class="inlineCode">-XX:MaxGCPauseMillis=150</code>, which will ensure maximum pause times of 150 milliseconds between two consecutive runs/events of GC). However, be aware that bigger pause times will allow more garbage to hit the heap. This means that the next run of the GC will be more expensive. On the other hand, a small pause time will instruct the GC to run more frequently, and this may cause the application to spend too much time on garbage collection.</p>
    <p class="normal">Next, the maximum throughput that we want to achieve can be set via the <code class="inlineCode">-XX:GCTimeRatio</code> option. This option is evaluated as the ratio between the time spent inside vs. outside the GC. It is a percentage computed as 1/(1 + n). In other words, <code class="inlineCode">-XX:GCTimeRatio</code> specifies the amount of time dedicated to garbage collection in a 1/(1+n) ratio. </p>
    <p class="normal">For instance, if we set this option as <code class="inlineCode">-XX:GCTimeRatio=14</code>, then we target a goal of 1/15. This means that 6% of the total time should be spent in garbage collection (by default, this option is set to 99, or 1% of time is spent on garbage collection).</p>
    <p class="normal">If you get an <code class="inlineCode">OutOfMemoryError</code>, then most probably, this is caused by too much time spent on garbage collection. For instance, if more than 98% of the time is spent recovering less than 2% of the heap, then you’ll see such an error. In other words, GC has spent a lot of time cleaning a small part of the heap. This may indicate memory leaks or a heap that is too small. Nevertheless, if you can live with this error, then you can suppress it via the <code class="inlineCode">-XX:-UseGCOverheadLimit</code> option.</p>
    <p class="normal">We can also control the size of the <em class="italic">Young</em>/<em class="italic">Old</em> generation. You can control the growth of the <em class="italic">Young</em> generation via <code class="inlineCode">-XX:YoungGenerationSizeIncrement</code>, and the growth of the <em class="italic">Old</em> generation via <code class="inlineCode">-XX:TenuredGenerationSizeIncrement</code>. The values of these options are percentages (by default, the growth percentage is 20% and the shrinking percentage is 5%). Moreover, you <a id="_idIndexMarker1435"/>can control the shrinking percentage by simply <a id="_idIndexMarker1436"/>setting the <code class="inlineCode">-XX:AdaptiveSizeDecrementScaleFactor</code> option. The shrinking of the <em class="italic">Young</em> generation is automatically computed via <code class="inlineCode">-XX:YoungGenerationSizeIncrement</code>/<code class="inlineCode">-XX:AdaptiveSizeDecrementScaleFactor</code>.</p>
    <h2 id="_idParaDest-571" class="heading-2">Tuning the G1 garbage collector</h2>
    <p class="normal">The G1 garbage collector can be enabled via <code class="inlineCode">-XX:+UseG1GC</code>.</p>
    <p class="normal">By default, G1 takes care of the <em class="italic">Young</em> generation. Basically, it cleans the <em class="italic">Young</em> generation and promotes <a id="_idIndexMarker1437"/>the reachable objects to the <em class="italic">Old</em> generation until it hits a threshold of 45%. This default value can be altered via <code class="inlineCode">-XX:InitiatingHeapOccupancyPercent</code>. </p>
    <p class="normal">When tuning <a id="_idIndexMarker1438"/>the G1 collector, we can target throughput, latency, or footprint. When tuning for latency, we have to focus on low pause times. This can be achieved by setting the <code class="inlineCode">–Xmx</code> and <code class="inlineCode">–Xms</code> options at the same value (to avoid heap resizing). Moreover, we can rely on the <code class="inlineCode">-XX:+AlwaysPreTouch</code> and <code class="inlineCode">-XX:+UseLargePages</code> flag options to load the (large) memory pages at the start of the application. </p>
    <p class="normal">If latency is affected by the <em class="italic">Young</em> generation size, then it is a good idea to decrease its size via <code class="inlineCode">-XX:G1NewSizePercent</code> and <code class="inlineCode">-XX:G1MaxNewSizePercent</code>. On the other hand, if the <em class="italic">Mixed</em> GC events affect latency, then we should focus on spreading the <em class="italic">Tenured</em> space across more collections via the <code class="inlineCode">-XX:G1MixedGCCountTarget</code> flag option. In addition, we may want to focus on <code class="inlineCode">-XX:G1HeapWastePercent</code> (stop earlier the <em class="italic">Tenured</em> space cleanup) and <code class="inlineCode">-XX:G1MixedGCLiveThresholdPercent</code> (the <em class="italic">Tenured</em> space becomes part of a mixed collection only when this threshold is exceeded (defaults to 65)). You may also be interested in <code class="inlineCode">-XX:G1RSetUpdatingPauseTimePercent</code>, <code class="inlineCode">-XX:-ReduceInitialCardMarks</code>, and <code class="inlineCode">-XX:G1RSetRegionEntries</code> (for details, see the G1 documentation).</p>
    <p class="normal">When tuning for throughput (applications that manipulate a lot of data need a GC capable of cleaning as much garbage as possible), we have to focus on the <code class="inlineCode">-XX:MaxGCPauseMillis</code> option. When this option has a low effect, then you should focus on <code class="inlineCode">-XX:G1NewSizePercent</code> and <code class="inlineCode">-XX:G1MaxNewSizePercent</code>. Basically, G1 strives to bound the <em class="italic">Young</em> generation size between the values of <code class="inlineCode">-XX:G1NewSizePercent</code> (default is 5) and <code class="inlineCode">-XX:G1MaxNewSizePercent</code> (default is 60). By juggling these three options, we can relax the GC and give it more time and space to process a lot of garbage. In addition, throughput can be sustained via the <code class="inlineCode">-XX:G1RSetUpdatingPauseTimePercent</code> option. </p>
    <p class="normal">By increasing the value of this option, we decrease the time spent in concurrent parts while performing more work when pausing the application’s threads. In addition, as in the case of tuning for latency, we may want to avoid heap resizing (set <code class="inlineCode">–Xmx</code> and <code class="inlineCode">–Xms</code> at the same value) and turn on the <code class="inlineCode">-XX:+AlwaysPreTouch</code> and <code class="inlineCode">-XX:+UseLargePages</code> flag options.</p>
    <p class="normal">Tuning for footprint may be influenced by setting the <code class="inlineCode">-XX:GCTimeRatio</code>. This defaults to 12 (8%) but we can increase it to force the GC to spend more time in garbage collection. As a result, more heap memory will be free, but this is not a general rule. It is recommended to experiment and see how it really works. Moreover, since JDK 8 (update 20), we can set up the <code class="inlineCode">-XX:+UseStringDeduplication</code> flag option. Practically, if this option is enabled, then G1 locates <a id="_idIndexMarker1439"/>duplicate strings and holds a single reference to one string while cleaning up the duplicates. This should result in a more efficient and <a id="_idIndexMarker1440"/>optimal usage of the heap memory. You also may want to consult the documentation for <code class="inlineCode">-XX:+PrintStringDeduplicationStatistics</code> and <code class="inlineCode">-XX:StringDeduplicationAgeThreshold=n</code>.</p>
    <p class="normal">As you already know, G1 splits the heap into small regions up to 32 MB. In practice, this may lead to performance degradation, especially for large objects on very large heaps. But, starting with JDK 18, the maximum region size was set up to 512 MB. Whenever you need, you can control the maximum region size via the <code class="inlineCode">-XX:G1HeapRegionSize</code>.</p>
    <h2 id="_idParaDest-572" class="heading-2">Tuning Z Garbage Collector</h2>
    <p class="normal">Z Garbage <a id="_idIndexMarker1441"/>Collector can be enabled via <code class="inlineCode">-XX:+UseZGC</code> (before JDK 15, you may also need <code class="inlineCode">-XX:+UnlockExperimentalVMOptions</code>).</p>
    <p class="normal">One of the <a id="_idIndexMarker1442"/>most important settings of this GC is <code class="inlineCode">–Xmx</code> to set up the maximum heap size. Next to this one, we have <code class="inlineCode">-XX:ConcGCThreads=n</code>, where <code class="inlineCode">n</code> is the number of threads used by ZGC. However, ZGC is fully capable of dynamically determining the optimal value for this option, so think twice before modifying it.</p>
    <h2 id="_idParaDest-573" class="heading-2">Tuning Metaspace (Metadata space)</h2>
    <p class="normal">If your <a id="_idIndexMarker1443"/>focus is on tuning Metaspace, then you’ll be interested in the following options:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">-XX:MetaspaceSize</code> – Set the initial size of Metaspace</li>
      <li class="bulletList"><code class="inlineCode">-XX:MaxMetaspaceSize</code> – Set the maximum size of Metaspace</li>
      <li class="bulletList"><code class="inlineCode">-XX:MinMetaspaceFreeRatio</code> – Set the class metadata capacity that should be free after running the GC (this is the minimum value as a percentage)</li>
      <li class="bulletList"><code class="inlineCode">-XX:MaxMetaspaceFreeRatio</code> – Set the class metadata capacity that should be free after running the GC (this is the maximum value as a percentage)</li>
    </ul>
    <p class="normal">Controlling the size and behavior of the Metaspace can also be part of tuning your GC. Again, experimenting and comparing the results is the main rule of thumb that can lead you to a successful and optimal GC.</p>
    <h1 id="_idParaDest-574" class="heading-1">257. Introducing Application Class Data Sharing (AppCDS, or Java’s Startup Booster)</h1>
    <p class="normal">Launching <a id="_idIndexMarker1444"/>a Java application is a multi-step process. Before executing the bytecode of a class, the JVM has to perform at least the following steps for a given class name:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">Look up the class on disk (JVM has to scan the disk and find the given class name).</li>
      <li class="numberedList">Load the class (JVM opens the file and loads its content).</li>
      <li class="numberedList">Check the bytecode (JVM verifies the integrity of the content).</li>
      <li class="numberedList">Pull the bytecode internally (JVM transfers the code into an internal data structure). </li>
    </ol>
    <p class="normal">Obviously, these steps are not cost-free. Loading hundreds/thousands of classes will have a significant overhead on launching time and memory footprint. Typically, an application’s JAR remains unchanged for a long time, but JVM performs the previous steps and obtains the same result every time we launch the application.</p>
    <p class="normal">Improving/accelerating the startup performance and even reducing the memory footprint are the main goals of Application Class Data Sharing (AppCDS). In a nutshell, AppCDS was initially popularized in JDK 10 (2018), and it was simplified in JDK 13 and JDK 19. The idea of AppCDS is to perform the previous steps once and dump the result into an archive. This archive can be reused for subsequent launches and even shared across multiple JVM instances running on the same host. The bigger the application is, the bigger the startup benefits are.</p>
    <p class="normal">Putting these ideas into practice requires the following three steps:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">Create the list of classes that should be shared between the application instances.</li>
      <li class="numberedList">Archive this list of classes in an archive suitable for memory mapping.</li>
      <li class="numberedList">Give the resulting archive to every application startup (every application instance).</li>
    </ol>
    <p class="normal">Depending on the JDK used, you may have to manually follow these steps or only a part of them. The AppCDS algorithm is constantly improved, so its use depends on your JDK, as follows:</p>
    <ul>
      <li class="bulletList">In JDK 10/11, you have to follow the previous three steps. However, if you want to share only the JDK classes (not the application classes), then you can skip step 1. JDK has already prepared the list of classes that should be shared in <code class="inlineCode">$JAVA_HOME\lib\classlist</code> (there are around 1,200 classes).</li>
      <li class="bulletList">In JDK 12+, you can skip steps 1 and 2 because an archive of JDK classes is already available. However, if you want to share the application classes as well, then you need to follow all three steps.</li>
      <li class="bulletList">In JDK 13+, we can take advantage of dynamic CDS archives. Practically, JVM collects the classes to be added into the archive at application runtime. Steps 1 and 2 are merged automatically.</li>
      <li class="bulletList">In JDK 19+, we can take advantage of the autogenerated shared archive. The CDS archive is built and used in a single command.</li>
    </ul>
    <h2 id="_idParaDest-575" class="heading-2">Tackling a JDK class data archive</h2>
    <p class="normal">Tackling a <a id="_idIndexMarker1445"/>JDK class data archive <a id="_idIndexMarker1446"/>means that we will create a reusable archive containing only JDK classes, not the classes of our application.</p>
    <h3 id="_idParaDest-576" class="heading-3">JDK 10/JDK 11</h3>
    <p class="normal">In JDK 10/11, we can use the already existent <code class="inlineCode">$JAVA_HOME/lib/classlist</code>. This is a file that contains <a id="_idIndexMarker1447"/>the list of JDK classes, and you can easily inspect <a id="_idIndexMarker1448"/>it with a text editor. Having the class list, we can create the proper CDS archive via the <code class="inlineCode">–Xshare:dump</code> option, as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">java … -Xshare:dump
</code></pre>
    <p class="normal">The resulting archive will be stored in <code class="inlineCode">$JAVA_HOME\bin\server\classes.jsa</code> (this is the default location and you may need to run this command as an administrator to avoid a permission denied restriction).</p>
    <p class="normal">Next, we can use this archive via <code class="inlineCode">–Xshare:on</code>, as follows (if you run under JDK 11, then <code class="inlineCode">--enable-preview</code> is also needed, but I’ll skip it here):</p>
    <pre class="programlisting con"><code class="hljs-con">java … -Xshare:on
</code></pre>
    <p class="normal">We can use the unified logging system to track CDS work via <code class="inlineCode">–Xlog</code>, as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">java … -Xshare:on -Xlog:class+load:file=cds.log 
</code></pre>
    <p class="normal">In the output, we can see that a shared object is marked with a significant message, as follows (objects that are not shared don’t contain the “<em class="italic">shared objects file</em>” text):</p>
    <pre class="programlisting con"><code class="hljs-con">[6.376s][info][class,load] java.lang.Object source: shared objects file
</code></pre>
    <p class="normal">By default, JVM scans for archives in the default location. But, if we move the archive to another location (for instance, in the application root folder), then we have to indicate this location via <code class="inlineCode">-XX:SharedArchiveFile</code>, as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">java … -Xshare:on -XX:SharedArchiveFile=./classes.jsa
       -Xlog:class+load:file=cds.log
</code></pre>
    <p class="normal">Actually, the default value of <code class="inlineCode">–Xshare</code> is <code class="inlineCode">auto</code>. This means that if an archive is found, then it is used automatically. So, if you omit <code class="inlineCode">–Xshare:on</code>, then JVM relies on <code class="inlineCode">–Xshare:auto</code>, which has the same effect. If you want to shut down CDS support, then use <code class="inlineCode">–Xshare:off</code>.</p>
    <h3 id="_idParaDest-577" class="heading-3">JDK 12+</h3>
    <p class="normal">JDK 12+ comes <a id="_idIndexMarker1449"/>with an already prepared archive for JDK classes, so there is no need <a id="_idIndexMarker1450"/>to create one (no need to use <code class="inlineCode">–Xshare:dump</code>). JVM will use it automatically thanks to <code class="inlineCode">–Xshare:auto</code> or via the explicit <code class="inlineCode">–Xshare:on</code>:</p>
    <pre class="programlisting con"><code class="hljs-con">java … -Xshare:on -Xlog:class+load:file=cds.log 
</code></pre>
    <p class="normal">Of course, if you have a different location than the default one (<code class="inlineCode">$JAVA_HOME\bin\server\classes.jsa</code>), then use <code class="inlineCode">-XX:SharedArchiveFile</code>.</p>
    <h2 id="_idParaDest-578" class="heading-2">Tackling application class data archive</h2>
    <p class="normal">Besides <a id="_idIndexMarker1451"/>the JDK classes, we <a id="_idIndexMarker1452"/>may want to share our application classes as well. This can be done in several steps depending on the JDK.</p>
    <h3 id="_idParaDest-579" class="heading-3">Before JDK 13</h3>
    <p class="normal">Before JDK 13, we need to create the list of classes that we want to share. We can do it manually <a id="_idIndexMarker1453"/>or via the <code class="inlineCode">-XX:DumpLoadedClassList</code> option, as follows (I’ll skip it here, but you’ll need <code class="inlineCode">--enable-preview</code> as well):</p>
    <pre class="programlisting con"><code class="hljs-con">java ... -XX:DumpLoadedClassList=classes.lst
</code></pre>
    <p class="normal">The generated <code class="inlineCode">classes.lst</code> contains all classes (classes used by the JDK + your application classes) that will be shared. Next, we can obtain the archive, as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">java … -Xshare:dump -XX:SharedClassListFile=classes.lst
       -XX:SharedArchiveFile=appcds.jsa --class-path app.jar
</code></pre>
    <p class="normal">Consider the following important note.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Important note</strong></p>
      <p class="normal">Notice that CDS (AppCDS) can archive classes from JAR files only. Don’t use classpaths with wildcards or exploded paths such as <code class="inlineCode">target/classes</code>. Replace <code class="inlineCode">app.jar</code> with your JAR.</p>
    </div>
    <p class="normal">The archive (<code class="inlineCode">appcds.jsa</code>) is stored in the application root folder, not in <code class="inlineCode">$JAVA_HOME</code>. </p>
    <p class="normal">Finally, we can share the archive and get some logs, as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">java … -Xshare:on -XX:SharedArchiveFile=./appcds.jsa
       -Xlog:class+load:file=cds.log
</code></pre>
    <p class="normal">Done!</p>
    <h3 id="_idParaDest-580" class="heading-3">JDK 13+</h3>
    <p class="normal">Starting <a id="_idIndexMarker1454"/>with JDK 13, we can take advantage of <em class="italic">dynamic application class-data sharing</em>. In other words, we can obtain the archive when JVM exits via the <code class="inlineCode">-XX:ArchiveClassesAtExit</code> option, as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">java ... -XX:ArchiveClassesAtExit=appcds.jsa -jar app.jar
</code></pre>
    <p class="normal">Replace <code class="inlineCode">app.jar</code> with your JAR. Use the generated archive as usual via <code class="inlineCode">-Xshare:on</code> and <code class="inlineCode">-XX:SharedArchiveFile</code>.</p>
    <h3 id="_idParaDest-581" class="heading-3">JDK 19+</h3>
    <p class="normal">Starting <a id="_idIndexMarker1455"/>with JDK 19, we can rely on autogenerated archives. This is possible in a single command, as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">java … -XX:+AutoCreateSharedArchive
-XX:SharedArchiveFile=appcds.jsa –jar app.jar
</code></pre>
    <p class="normal">This time, JVM checks if an archive exists at the path given via <code class="inlineCode">-XX:SharedArchiveFile</code>. If such an archive exists, then JVM loads and uses it; otherwise, at exit, JVM will generate an archive at that location. Moreover, JVM checks the JDK version used for creating the archive. If the current JDK version (the JVM JDK version) and the archive JDK are not the same, then JVM will overwrite the existing archive.</p>
    <p class="normal">You may also be interested in the following article: <a href="https://spring.io/blog/2023/12/04/cds-with-spring-framework-6-1"><span class="url">https://spring.io/blog/2023/12/04/cds-with-spring-framework-6-1</span></a>.</p>
    <h1 id="_idParaDest-582" class="heading-1">Summary</h1>
    <p class="normal">This chapter covered 15 problems with garbage collectors and AppCDS. Even if these problems have been mostly theoretical, they still represent major topics that can boost your application performance at runtime (in the GC case) and startup (in the AppCDS case).</p>
    <h1 class="heading-1">Join our community on Discord</h1>
    <p class="normal">Join our community’s Discord space for discussions with the author and other readers:</p>
    <p class="normal"><a href="https://discord.gg/8mgytp5DGQ "><span class="url">https://discord.gg/8mgytp5DGQ</span></a></p>
    <p class="normal"><img src="../Images/QR_Code1139613064111216156.png" alt="" role="presentation"/></p>
  </div>
</body></html>