<html><head></head><body>
        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Concurrent Programming in Scala</h1>
                
            
            <article>
                
<p class="calibre2"/>
<div class="packt_quote">"Yesterday is not ours to recover, but today is to try and tomorrow is to win or lose."</div>
<div class="packt_quote1">- Anonymous</div>
<p class="calibre2">The idea that modern computers with multicore architectures give better performance is based on the fact that multiple processors can run separate processes simultaneously. Each process can run more than one thread to complete specific tasks. Picturing this, we can write programs with multiple threads working simultaneously to ensure better performance and responsiveness. We call this concurrent programming. In this chapter, our goal is to understand Scala's offerings in concurrent programming. There are multiple ways we can use constructs to write concurrent programs. We'll learn about them in this chapter. Let's check out what will be here for us:</p>
<ul class="calibre7">
<li class="calibre8">Concurrent programming</li>
<li class="calibre8">Building blocks of concurrency:
<ul class="calibre28">
<li class="calibre8">Process and threads</li>
<li class="calibre8">Synchronization and locks</li>
<li class="calibre8">Executor and ExecutionContext</li>
<li class="calibre8">Lock free programming</li>
</ul>
</li>
<li class="calibre8">Asynchronous programming using Futures and Promises</li>
<li class="calibre8">Parallel Collections</li>
</ul>
<p class="calibre2">Before we start learning about the ways we can write concurrent programs, it's important to understand the underlying picture. Let's start understanding concurrent programming and then we'll go through the basic building blocks of concurrency.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Concurrent programming</h1>
                
            
            <article>
                
<p class="calibre2">It's a programming approach where a set of computations can be performed simultaneously. These set of computations might share the same resources such as memory. How's it different from sequential programming? In sequential programming, every computation can be performed one after another. In the case of concurrent programs, more than one computation can be performed in the same time period.</p>
<p class="calibre2">By executing multiple computations, we can perform multiple logical operations in the program at the same time, resulting in better performance. Programs can run faster than before. This may sound cool; concurrency actually makes implementing real scenarios easier. Think about an internet browser; we can stream our favorite videos and download some content at the same time. The download thread does not affect the streaming of the video in any way. This is possible because content download and video streams on a browser tab are separate logical program parts, and hence can run simultaneously.</p>
<p class="calibre2">Similarly, in programs where we might have the user to perform some I/O operations for input, at the same time we want to run the program. We need these two parts to run simultaneously. Running these parts together makes it responsive to user interactions. Writing a concurrent program comes in handy in such cases. From a very cool web application running on an internet browser to games running on your mobile device, responsiveness and good user experience is possible because of concurrent programs.</p>
<p class="calibre2">This is why learning about concurrency abstractions is important, and what's more important is to keep them simple in our program implementations. So, let's go through the basic building blocks of concurrency.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Building blocks of concurrency</h1>
                
            
            <article>
                
<p class="calibre2">Scala is a JVM-based language, so programs written in Scala run in JVM. <strong class="calibre1">JVM</strong>, as we already know, is <strong class="calibre1">Java Virtual Machine</strong>, and runs as a single process in our operating system. In JVM, one of the basic concurrency constructs is a <em class="calibre18">thread</em>; we can create/use multiple threads as part of our Scala program. So, for a basic understanding of processes and threads, let's go through them.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Understanding processes and threads</h1>
                
            
            <article>
                
<p class="calibre2">Think of a process as a program or application that our computer might have to run. This process is going to have some code that's executable, a <strong class="calibre1">process identifier</strong> (<strong class="calibre1">pid</strong>), and at least one thread of execution. The process might consume some computer resources as well, such as memory. Every process isolates itself from other processes when it comes to consume memory; this means two processes cannot use the same memory block.</p>
<p class="calibre2">Modern computers come with multiple processor cores. These cores are assigned tasks as executable program parts for execution in certain time slices. The task of assigning these executable parts is done by the operating system. Most of the operating systems nowadays use a mechanism called <strong class="calibre1">pre-emptive multitasking</strong>, which is the simultaneous execution of multiple executable parts from all running processes. These executable parts are nothing but threads. It means that each process needs to have at least one thread, we can call it the main thread, in order to run properly.</p>
<p class="calibre2">It's clear that the process within an operating system uses some memory resources, and it can contain multiple threads. Now, these threads from a particular process are free to share the memory block assigned, but two processes cannot do the same. It'll be easier to understand this with the help of the following figure:</p>
<div class="title-page-name">
<div class="cdpaligncenter"><img src="../images/00056.jpeg" class="calibre62"/></div>
</div>
<p class="calibre2">The previous diagram is a simplified version for a system with two processor cores, a <em class="calibre18">pre-emptive multitasking operating system</em> and <em class="calibre18">memory</em>. We have a separate memory resource allocated for different processes running, in our case, <strong class="calibre1">Process 1</strong>, <strong class="calibre1">Process 2</strong>, and <strong class="calibre1">Process 3</strong>. The memory block for <strong class="calibre1">Process 1</strong> has no access to the memory block for <strong class="calibre1">Process 2</strong> or <strong class="calibre1">Process 3</strong>. Each process contains more than one thread. Each thread can access the memory allocated from the parent process. These threads can share the memory allocated. Now, what happens is the operating system assigns these executable blocks, in other words <em class="calibre18">threads</em>, to process cores for execution, as shown in our preceding diagram.</p>
<p class="calibre2">In a particular time slice:</p>
<ul class="calibre7">
<li class="calibre8"><strong class="calibre1">Core 1</strong> is executing <strong class="calibre1">Thread 1</strong> from <strong class="calibre1">Process 1</strong></li>
<li class="calibre8"><strong class="calibre1">Core 2</strong> is executing <strong class="calibre1">Thread 2</strong> from <strong class="calibre1">Process 3</strong></li>
</ul>
<p class="calibre2">These two executions are happening simultaneously. We already know that JVM runs as a process; the programs we write are going to have threads as entities. For our program to run, we need at least a <em class="calibre18">main thread</em> that can be the entry point to our application. We can create more threads as instances of the <kbd class="calibre11">java.lang.Thread</kbd> class.</p>
<p class="calibre2">Now that we know we can have multiple parts of our application running together, it's important to understand that we need some way to synchronize them. By synchronizing, we can ensure one particular execution is not going to affect any other. Threads within a process have access to the same memory block, hence it might be possible that two threads try to access the memory at the same time—this might cause problems. Threads are low-level concurrency abstractions in Scala, and as the number of concurrent parts or threads increases, complexity also increases with them. To understand how do we restrict other threads to access some block of code simultaneously, first we need to understand how synchronization works.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Locks and synchronization</h1>
                
            
            <article>
                
<p class="calibre2">We talked about threads in previous sections—we'll first try to create a few ourselves before discussing them further. Let's write some code for that:</p>
<pre class="calibre19">object ThreadFirstEncounter extends App { 
 
  class FirstThread extends Thread { 
    override def run(): Unit = println(s"FirstThread's run!") 
  } 
 
  val firstThread = new FirstThread() 
  firstThread.start() 
 
  println(s"CurrentThread: ${Thread.currentThread().getName}") 
  println(s"firstThread: ${firstThread.getName}") 
 
} </pre>
<p class="calibre2">A few pointers for the preceding code:</p>
<ol class="calibre13">
<li value="1" class="calibre8">We simply created an object extending <kbd class="calibre11">App</kbd> to create the application entry point.</li>
<li value="2" class="calibre8">We created a class named <kbd class="calibre11">FirstThread</kbd> that extends <kbd class="calibre11">Thread</kbd>, which is nothing but the same <kbd class="calibre11">java.lang.Thread</kbd> we talked about in the previous section.</li>
<li value="3" class="calibre8">When we create a thread, we might want to specify what it needs to run. That can be defined via overriding the <kbd class="calibre11">run</kbd> method.</li>
</ol>
<p class="calibre2"> </p>
<ol start="4" class="calibre13">
<li value="4" class="calibre8">Until <em class="calibre18">point 3</em>, we have defined our thread class; now, to run the thread, we'll create its instance, and then call the <kbd class="calibre11">start</kbd> method.</li>
<li value="5" class="calibre8">The <kbd class="calibre11">start</kbd> method triggers the execution of the thread.</li>
<li value="6" class="calibre8">Finally, we printed the thread's name. First, the <kbd class="calibre11">main</kbd> current thread, and then the <kbd class="calibre11">firstThread</kbd> class name.</li>
</ol>
<p class="calibre2">Running the application will give us the following output:</p>
<pre class="calibre19">FirstThread's run! 
CurrentThread: main 
firstThread: Thread-0 </pre>
<p class="calibre2">So from the first run, it's clear that a thread called <kbd class="calibre11">main</kbd> runs the application, and as we create more and more threads, these threads also come into the picture. It's great to have multiple threads working together for us to perform some computation. We know from our previous discussions that an OS performs the scheduling of task execution, so it's out of our control which thread will get executed in which order. Now, think of a scenario where you might want to perform a read and write operation to a variable in your program. With multiple threads performing such a task, it might be possible to see inconsistencies in the result. It means that this execution is exposed to <em class="calibre18">race conditions</em>; in other words, it depends on the execution schedule of statements by the OS. To better understand this, let's try out the scenario we discussed:</p>
<pre class="calibre19">object TowardsLocking extends App { 
  var counter = 0 // counter variable 
 
  def readWriteCounter(): Int = { 
    val incrementedCounter = counter + 1  //Reading counter 
    counter = incrementedCounter // Writing to counter 
    incrementedCounter 
  } 
 
  def printCounter(nTimes: Int): Unit = { 
    val readWriteCounterNTimes = for(i &lt;- 1 to nTimes) yield readWriteCounter() 
    println(s"${Thread.currentThread.getName} executing :: counter $nTimes times:  $readWriteCounterNTimes") 
  } 
 
  class First extends Thread { 
    override def run(): Unit = { 
      printCounter(10) 
    } 
  } 
 
  val first = new First 
  first.start() // thread-0 
   
  printCounter(10)   // main thread 
 
} </pre>
<p class="calibre2">In this small application, we first create a variable <kbd class="calibre11">counter</kbd>; we are going to read and write to this variable using two threads. Next, we have two methods, first <kbd class="calibre11">readWriteCounter</kbd> and <kbd class="calibre11">printCounter</kbd>. The <kbd class="calibre11">readWriteCounter</kbd> method is doing as the name says. This method increments the counter (reading operation) and assigns the <kbd class="calibre11">incrementedCounter</kbd> to the <kbd class="calibre11">counter</kbd> variable. The second method, <kbd class="calibre11">printCounter</kbd>, takes an integer parameter to increment counter the number of times specified and prints that.</p>
<p class="calibre2">After defining all these, we created a thread with the name <kbd class="calibre11">First</kbd> and called our <kbd class="calibre11">printCounter</kbd> method, overriding the <kbd class="calibre11">run</kbd> method. To observe the behavior, we're supposed to call the <kbd class="calibre11">printCounter</kbd> from this <kbd class="calibre11">First</kbd> thread and the main application thread. Since two threads are working simultaneously, it's expected that output of these two shouldn't contain the same number. We also called <kbd class="calibre11">printCounter</kbd> from the application as the final statement of the program.</p>
<p class="calibre2">Running the program couple of times (if you're lucky, for the first time), you might be able to see some inconsistent behavior.</p>
<p class="calibre2">Run:</p>
<pre class="calibre19">main executing :: counter 10 times:  Vector(1, 3, 5, 7, 9, 11, 13, 15, 17, 18) 
Thread-0 executing :: counter 10 times:  Vector(1, 2, 4, 6, 8, 10, 11, 12, 14, 16) </pre>
<p class="calibre2">In the output from both the threads, we can see the number <kbd class="calibre11">1</kbd> appeared twice, while we know it shouldn't have happened. We see that behaviour due to read and write operations happening to our <kbd class="calibre11">counter</kbd> variable via multiple threads in the following snippet:</p>
<pre class="calibre19">def readWriteCounter(): Int = { 
    val incrementedCounter = counter + 1  //Reading counter 
    counter = incrementedCounter // Writing to counter 
    incrementedCounter 
  } </pre>
<p class="calibre2">By the time the <kbd class="calibre11">counter = incrementCounter</kbd> statement gets a chance to execute, the <kbd class="calibre11">counter</kbd> variable gets incremented twice (by multiple threads). This is causing inconsistency. The problem lies in the execution of these two statements; these have to be atomic in nature to give a consistent output where the same number cannot appear for different threads. By <em class="calibre18">atomic</em>, we mean these two statements have to be executed together by the same thread.</p>
<p class="calibre2">If we somehow achieve that atomicity for this block of code, it'll provide some satisfactory output to us. It feels like we need some synchronization mechanism which protects the block of code exposed. Using a synchronization mechanism, while the block is being executed by a single thread, no other thread should be able to execute that at the same time. This can be achieved using an <em class="calibre18">intrinsic locking</em> mechanism that puts a lock on the block and prevents other threads from executing that snippet of code. There's a <em class="calibre18">synchronized</em> statement in Scala, using which we can implement a locking mechanism. Let's try that and see how it looks:</p>
<pre class="calibre19">object TowardsLockingOne extends App { 
  var counter = 0 // counter variable 
 
  def readWriteCounter(): Int = this.synchronized { 
    val incrementedCounter = counter + 1  //Reading counter 
    counter = incrementedCounter // Writing to counter 
    incrementedCounter 
  } 
 
  def printCounter(nTimes: Int): Unit = { 
    val readWriteCounterNTimes = for(i &lt;- 1 to nTimes) yield readWriteCounter() 
    println(s"${Thread.currentThread.getName} executing :: counter $nTimes times:  $readWriteCounterNTimes") 
  } 
 
  class First extends Thread { 
    override def run(): Unit = { 
      printCounter(10) 
    } 
  } 
 
  val first = new First 
  first.start() // thread-0 
 
  printCounter(10)   // main thread 
} </pre>
<p class="calibre2">In the application, it can be seen that our concerned method block is not guarded by this <em class="calibre18">synchronized</em> statement:</p>
<pre class="calibre19">def readWriteCounter(): Int = this.synchronized { 
    val incrementedCounter = counter + 1  //Reading counter 
    counter = incrementedCounter // Writing to counter 
    incrementedCounter 
  } </pre>
<p class="calibre2">By using this, we make the synchronized statement refer to the current object to guard the block. We could also make a particular instance of some type, let's say <em class="calibre18">Any</em> and that instance can work as a guard to our synchronised clock. It's shown as following:</p>
<pre class="calibre19">val any = new Any() 
 
def readWriteCounter(): Int = any.synchronized { 
    val incrementedCounter = counter + 1  //Reading counter 
    counter = incrementedCounter // Writing to counter 
    incrementedCounter 
  } </pre>
<p class="calibre2">By using a synchronized statement, we are able to put a lock on this snippet of code and only one thread can execute the code enclosed. Apart from synchronized statements, there are other synchronization mechanisms in Scala, in the forms of <em class="calibre18">volatile</em> and <em class="calibre18">atomic variables</em>. These are lightweight and less expensive than synchronized statements, and better in performance. They need additional mechanisms to ensure correct synchronization when you only use volatile variables large in numbers. We should be aware that OS scheduler can also freeze any thread for any reason, which might also cause a thread carrying locks to freeze. In this case, if a thread holding a lock gets frozen, it'll block execution of other threads as well; that's not something we want for sure.</p>
<p class="calibre2">Creating a thread is an expensive operation—if you have more computations, you want to perform concurrently and you create several threads to compute those. It'll be less performant and with some shared data access, your life will be worse. So, to prevent this costly operation from happening, JDK has come up with the concept of <em class="calibre18">thread-pools.</em> In <em class="calibre18">thread-pools</em>, there are multiple thread instances provided. These threads within a pool remain in <em class="calibre18">waiting</em> state; when you want to perform some computation, we can run these. The job of running these is done by the <kbd class="calibre11">executor</kbd><em class="calibre18">.</em> Let's try to understand it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Executor and ExecutionContext</h1>
                
            
            <article>
                
<p class="calibre2">Executor is an interface that encapsulates the <em class="calibre18">thread-pool</em> and deals with executing computations via one of the threads or the caller thread itself. One example of an executor is <kbd class="calibre11">java.util.concurrent.ForkJoinPool</kbd><em class="calibre18">.</em> Scala's implementation of such an executor is <kbd class="calibre11">ExecutionContext</kbd> which internally uses the same <kbd class="calibre11">ForkJoinPool</kbd><em class="calibre18">.</em> Before going further to see an example, why not think of the need for this <kbd class="calibre11">Executor</kbd> mechanism?</p>
<p class="calibre2">As programmers, while writing performance-efficient concurrent applications, we might have to deal with two major tasks, the first being defining instances of concurrency abstraction, let's say <em class="calibre18">threads</em>, and making sure they handle our data/state in the right manner. Second, to use these <em class="calibre18">threads</em> in our program. Now, the creation of all these threads, if created by us, are:</p>
<ul class="calibre7">
<li class="calibre8">Costly operations</li>
<li class="calibre8">Complex to manage</li>
</ul>
<p class="calibre2">Hence, mechanisms like <kbd class="calibre11">Executor</kbd> take away the work of creating these threads. We don't explicitly decide which thread will execute the logic we provide; we also don't need to manage those. Executor implementations, when used, create daemon and worker threads. When we assign computation via the <kbd class="calibre11">execute</kbd> method, a particular worker thread is assigned the task. Shutting down a daemon thread shuts down all the worker threads. This'll be easier to understand with the help of the following code snippet:</p>
<pre class="calibre19">import java.util.concurrent.ForkJoinPool 
import scala.concurrent.{ExecutionContext, ExecutionContextExecutor} 
 
object TowardsExecutor extends App { 
 
  val executor: ForkJoinPool = new java.util.concurrent.ForkJoinPool() 
  executor.execute(new Runnable { 
    override def run(): Unit = 
      println(s"${Thread.currentThread().getName()} printing this in execution of juc.ForkJoinPool!") 
  }) 
 
  val ec: ExecutionContextExecutor = ExecutionContext.global 
  ec.execute(new Runnable { 
    override def run(): Unit = 
      println(s"${Thread.currentThread().getName()} printing this in execution of sc.ExecutionContext!") 
  }) 
} </pre>
<p class="calibre2">In the application, we used two <kbd class="calibre11">Executor</kbd> implementations; the first is from <kbd class="calibre11">java.util.concurrent.ForkJoinPool</kbd> and the second is similar to Scala-specific <kbd class="calibre11">ExecutionContext</kbd>:</p>
<pre class="calibre19">val executor: ForkJoinPool = new java.util.concurrent.ForkJoinPool() 
val ec: ExecutionContextExecutor = ExecutionContext.global </pre>
<p class="calibre2">For both implementations, we have an execute method, which expects a <kbd class="calibre11">Runnable</kbd> instance. To create <kbd class="calibre11">Runnable</kbd> instances, we have to define a run method. It's another way to create a thread instance. In the definition of the run method, we just printed the executor thread's name.</p>
<p class="calibre2">But running the above program gives you no output. The reason for such behavior is that both the implementations create a <em class="calibre18">daemon thread,</em> which shuts down after the first run. Shutdown of a daemon thread kills all worker threads. Calling the <kbd class="calibre11">execute</kbd> method wakes up <kbd class="calibre11">workerthreads</kbd><em class="calibre18">.</em> These <kbd class="calibre11">workerthreads</kbd> execute the run method asynchronously. Hence, we'll try to include some timeout to wait for a small duration as the last statement by calling the <kbd class="calibre11">Thread.sleep</kbd> method:</p>
<pre class="calibre19">import java.util.concurrent.ForkJoinPool 
import scala.concurrent.{ExecutionContext, ExecutionContextExecutor} 
 
object TowardsExecutor extends App { 
 
  val executor: ForkJoinPool = new java.util.concurrent.ForkJoinPool() 
  executor.execute(new Runnable { 
    override def run(): Unit = 
      println(s"${Thread.currentThread().getName()} printing this in execution of juc.ForkJoinPool!") 
  }) 
 
  val ec: ExecutionContextExecutor = ExecutionContext.global 
  ec.execute(new Runnable { 
    override def run(): Unit = 
      println(s"${Thread.currentThread().getName()} printing this in execution of sc.ExecutionContext!") 
  }) 
   
  Thread.sleep(500) 
 
} </pre>
<p class="calibre2">Run:</p>
<pre class="calibre19">scala-execution-context-global-11 printing this in execution of sc.ExecutionContext! 
ForkJoinPool-1-worker-1 printing this in execution of juc.ForkJoinPool! </pre>
<p class="calibre2">After including some waiting time for the execution by the worker threads, we get the output. As shown, the output tells us the <em class="calibre18">thread</em> names: both are <em class="calibre18">worker threads.</em> The first one, named <kbd class="calibre11">scala-execution-context-global-11</kbd>, is from Scala's <kbd class="calibre11">ExecutionContext</kbd> and the second, named <kbd class="calibre11">ForkJoinPool-1-worker-1</kbd>, is from Java's <kbd class="calibre11">ForkJoinPool</kbd><em class="calibre18">.</em></p>
<p class="calibre2">These <em class="calibre18">thread-pools</em> and their implementations become the basis for higher-level concurrency abstractions. We also encountered a bit of asynchrony in the example when we waited for the result of the execution. It's not wrong to say asynchrony is subsumed in <em class="calibre18">concurrency</em>, as asynchronous programs tend to execute outside of the main flow of the program. Hence, multiple async computations can be performed at the same time; once we get back the results for these computations, we can perform the desired operation then.</p>
<p class="calibre2">Scala provides constructs from the standard library for asynchronous programming, as well as multiple libraries that provide async constructs to make it easier to develop programs for us, the developers. Let's go through those constructs.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Asynchronous programming</h1>
                
            
            <article>
                
<p class="calibre2">If we try to define <em class="calibre18">asynchronous programming,</em> we come up with something that states that it's a programming approach in which computations, which can be <em class="calibre18">tasks or threads,</em> execute outside of the basic program flow. In programming terminologies, these computations execute on different call stacks, not the current one. Because of this, it's possible for us to think of more than one async computation happening at the same time; we can wait for each to happen so that aggregation of a result or some other result manipulation is possible.</p>
<p class="calibre2">Up until now, we've looked at three of these terminologies such as <em class="calibre18">concurrency</em>, <em class="calibre18">multithreading</em>, and <em class="calibre18">asynchronous</em>. We tend to confuse these but given our discussions, it's clear that <em class="calibre18">asynchronous</em> subsumes <em class="calibre18">concurrency</em> and not <em class="calibre18">multithreading.</em> We know that asynchrony can be achieved using scheduling:</p>
<div class="title-page-name">
<div class="cdpaligncenter"><img src="../images/00057.jpeg" class="calibre63"/></div>
</div>
<p class="calibre2">Well, the fact that we have to compose the results of multiple async problems running at the same time means we might end up needing some sort of synchronization. Fortunately, we don't have to deal with managing these cumbersome tasks, as Scala's offerings manage those using the <kbd class="calibre11">ExecutionContext</kbd><em class="calibre18">.</em> One of those asynchronous offerings is <em class="calibre18">Futures</em> in Scala. Let's talk about <kbd class="calibre11">Futures</kbd> in Scala.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Working with Futures</h1>
                
            
            <article>
                
<p class="calibre2">The idea here is simple; we have our simple program flow. If we make some complex time-consuming computation in the main program flow, it'll be blocking and the experience won't be good. Hence, we want to perform that time-consuming computation outside of the basic program flow, and continue doing other stuff in the main program flow, keeping the value (that will be available at a later point in time) of computation. Once the value is available, we use it via a mechanism. The way we can picture this is as follows:</p>
<div class="title-page-name">
<div class="cdpaligncenter"><img src="../images/00058.jpeg" class="calibre64"/></div>
</div>
<p class="calibre2">For now, the two entities we can think of are: <kbd class="calibre11">Futurecomputation</kbd> and a future <kbd class="calibre11">value</kbd><em class="calibre18">.</em> These two are different; a Future computation is the time-consuming part you want to compute asynchronously and future value is the <kbd class="calibre11">value</kbd> reference on which we depend on our program flow. Once the Future computation starts in a separate flow, the program does not stop its execution and when the value becomes available, the part gets executed. The <kbd class="calibre11">ExecutionContext</kbd> takes care of the execution of that part, where we may use the <kbd class="calibre11">value</kbd> <span>Future</span><em class="calibre18">.</em></p>
<p class="calibre2">It's clear that whenever we start some Future computation, we might have to provide an execution context with it. In Scala, the Future type resides in the <kbd class="calibre11">scala.concurrent</kbd> package, the same package that has <kbd class="calibre11">ExecutionContext</kbd> and its executor <kbd class="calibre11">ExecutionContextExecutor</kbd><em class="calibre18">.</em></p>
<p class="calibre2">The Future value is represented by <kbd class="calibre11">Future[T]</kbd>, where <kbd class="calibre11">T</kbd> is the type of the value that'll be available at some later point in time. Hence in our programs, whenever we need some value that's a result of some asynchronous computation, we represent that value with this mentioned type. An example will clear this up:</p>
<pre class="calibre19">import scala.concurrent._ 
import scala.concurrent.ExecutionContext.Implicits.global 
 
object FutureExample extends App { 
 
  val fileSource = "/Users/vika/Documents/LSProg/LSPWorkspace/FirstProject/src/chapter5/football_stats.csv" 
 
  def listOfPlayers(): Future[List[Player]] = Future { 
    val source = io.Source.fromFile(fileSource) 
    val list = source.getLines().toList 
    source.close() 
    giveMePlayers(list) 
  } 
 
  println(s"listOfPlayers completed: ${listOfPlayers.isCompleted}") 
 
  Thread.sleep(500) 
 
  println(s"listOfPlayers completed: ${listOfPlayers.isCompleted}") 
 
  def giveMePlayers(list: List[String]): List[Player] = list match { 
    case head :: tail =&gt; tail map {line =&gt; 
      val columns = line.split((",")).map(_.trim) 
      Player(columns(5),columns(6),columns(9),columns(7), 
        columns(8),columns(10), columns(12), columns(0),columns(2)) 
    } 
    case Nil =&gt; List[Player]() 
  } 
 
} 
 
case class Player(name: String, nationality: String, age:String, club: String, domesticLeague: String, rawTotal: String, finalScore: String,ranking2016: String, ranking2015: String) </pre>
<p class="calibre2">Run:</p>
<pre class="calibre19">listOfPlayers completed: false 
listOfPlayers completed: true </pre>
<p class="calibre2">In this simple application, we specified a  file with some content. The file has information about few football players. Now, to read the file contents as well as parsing and encoding them to <kbd class="calibre11">Player</kbd> instances may take some time, hence we decided to take the <kbd class="calibre11">load</kbd><em class="calibre18">,</em> <kbd class="calibre11">parse</kbd>, and <kbd class="calibre11">encode</kbd> step as a Future computation, and the resulting value is going to be a Future value of type <kbd class="calibre11">Future[List[Player]]</kbd><em class="calibre18">.</em></p>
<p class="calibre2">Now, after defining such a computation, we checked if computation completed. Then we waited for some time and again tried to check if it completed. Running the application gives us <kbd class="calibre11">false</kbd> and then <kbd class="calibre11">true</kbd> respectively. If we think of this example via a diagram the flow might look like this:</p>
<div class="title-page-name">
<div class="cdpaligncenter"><img src="../images/00059.jpeg" class="calibre65"/></div>
</div>
<p class="calibre2">It's easy to understand the execution flow with the help of this diagram; for the duration in which the computation is in progress, the <kbd class="calibre11">isCompleted</kbd> flag remains false. After completion, it's set to true. After that, we can use the value of future, but in this example, we didn't use the value; also, the question arises of how we can use it. Do we have to check again and again for the value to be available? This sounds bad, so another way is to register a <em class="calibre18">callback</em> for this async computation.</p>
<p class="calibre2">Okay, what's a callback? To answer this, let's first extend our program to register one for our Future computation:</p>
<pre class="calibre19">import scala.concurrent._ 
import scala.concurrent.ExecutionContext.Implicits.global 
 
object FutureExample extends App { 
 
  val fileSource = 
"/Users/vika/Documents/LSProg/LSPWorkspace/FirstProject/src/chapter13/football_stats.csv" 
 
  val listOfPlayers: Future[List[Player]] = Future { 
      val source = io.Source.fromFile(fileSource) 
      val list = source.getLines().toList 
 
      source.close() 
 
      giveMePlayers(list) 
  } 
 
  def giveMePlayers(list: List[String]): List[Player] = list match { 
    case head :: tail =&gt; tail map {line =&gt; 
      val columns = line.split((",")).map(_.trim) 
      Player(columns(5),columns(6),columns(9),columns(7), 
        columns(8),columns(10), columns(12), columns(0),columns(2)) 
    } 
    case Nil =&gt; List[Player]() 
  } 
 
  // Registering a callback 
  listOfPlayers foreach { 
    case list =&gt; list foreach println 
  } 
 
  Thread.sleep(5000) 
 
} 
 
case class Player(name: String, nationality: String, age: String, club: String, domesticLeague: String, rawTotal: String, finalScore: String,ranking2016: String, ranking2015: String) </pre>
<p class="calibre2">So, the previous snippet is the same program; the only difference is that in the few final statements of our program, we've a call to a <kbd class="calibre11">foreach</kbd> function, on Future value. This is exactly what we mean when we say registering a <em class="calibre18">callback.</em> When the value of Future computation becomes available, it gets executed. That's going to work only if we get some value out of our Future computation. But we should be aware of the fact that the computation might fail. In that case, this callback is not going to be executed. The task of callback execution is taken care of by the execution context.</p>
<p class="calibre2">It's worth noting that callbacks are one of the ways we handle the result of an async computation. At the same time, we know that we need to provide some execution context that manages when and where the computation takes place as well as when the <em class="calibre18">callback</em> gets executed. This allows us to register more than one callback to a single async computation with a random execution order. The execution of callback in a random manner can be explained by this extended version of the previous diagram; now, we have callback as well in the diagram:</p>
<div class="title-page-name">
<div class="cdpaligncenter"><img src="../images/00060.jpeg" class="calibre66"/></div>
</div>
<p class="calibre2">The callback execution only happens after the completion of the Future computation, as depicted in the diagram. The execution of <em class="calibre18">callbacks</em> takes place only if the computation gets successfully completed. In other cases, there should be a way to tell the program that things went wrong so that we can do something with it. Let's see what we can do about this big question.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">What if Future computations go wrong?</h1>
                
            
            <article>
                
<p class="calibre2">The Future computation might succeed, resulting in a value, or fail, ending up throwing an exception. We need a mechanism to handle both the scenarios. Scala's Future has this mechanism as a method, <kbd class="calibre11">onComplete</kbd><em class="calibre18">.</em> First let's see it in practice; to do that, let's comment the callback code snippet we added last time, and add this snippet:</p>
<p class="calibre2"> </p>
<pre class="calibre19">listOfPlayers onComplete { 
  case Success(list) =&gt; list foreach println 
  case Failure(_) =&gt; println(s"listOfPlayers couldn't be fetched.") 
} </pre>
<p class="calibre2">The previous snippet is also a callback named <kbd class="calibre11">onComplete</kbd><em class="calibre18">,</em> which gets called once the Future's value is available; in other words, when Future gets completed. Let's take a look at the <kbd class="calibre11">onComplete</kbd> method's signature for a <kbd class="calibre11">Future[T]</kbd>:</p>
<p class="calibre2"> </p>
<pre class="calibre19">def onComplete[U](f: Try[T] =&gt; U)(implicit executor: ExecutionContext): Unit </pre>
<p class="calibre2">The function expects a function to execute; we have to also provide the execution context. The function literal is of type <kbd class="calibre11">Try[T] =&gt; U</kbd>. Fortunately, the execution context is taken from the implicit scope. Hence, we can directly provide the partial function to execute; in our case, we provided the same. Now, there's a possibility that one async call depends on the result of another async call, and in this case we might have to perform nesting of callback functions. This might look something like this:</p>
<p class="calibre2"> </p>
<pre class="calibre19">import scala.concurrent.Future 
import scala.concurrent.ExecutionContext.Implicits.global 
import scala.util.{Failure, Success} 
 
object TowardsFutureComposition extends App { 
 
def firstFuture: Future[String] = Future { "1" } 
def secondFuture(str: String): Future[Int] = Future { str.toInt } 
 
  firstFuture onComplete { 
    case Success(value1) =&gt; 
         secondFuture(value1) onComplete { 
      case Success(value2) =&gt; println(s"Converted int: $value2") 
      case Failure(exception) =&gt; println(s"Conversion failed due to ${exception.getMessage} ") 
    } 
    case Failure(excep) =&gt; Future.failed(excep) 
  } 
 
  Thread.sleep(5000) 
} </pre>
<p class="calibre2">In the previous code, we have only two futures nested along with <em class="calibre18">callbacks</em>, and this already seems like it should be done in simpler manner. Now think about more of such futures and callbacks together. It'll be a callback hell. Hence, what's needed here is composition. That's one of the powers of Scala Futures; you can compose two futures to perform some complex logic that contains the nesting of callbacks. How can <span>we </span>do that? By using the set of higher order functions given to us in Scala's Future API. Let's check it out.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Why not compose two or more Futures?</h1>
                
            
            <article>
                
<p class="calibre2">Now that we've got the previous toy example where we had two Futures called in sequence, let's compose over those two. What we'll do is first call the <kbd class="calibre11">flatMap</kbd> function on <kbd class="calibre11">firstFuture</kbd><em class="calibre18">, </em>and that'll give us the value. We'll take that value and call <kbd class="calibre11">secondFuture</kbd><em class="calibre18">.</em> Finally, we'll call the <kbd class="calibre11">map</kbd> function to perform the print operation:</p>
<pre class="calibre19">object FutureComposition extends App { 
 
  def firstFuture: Future[String] = Future { "1" } 
 
  def secondFuture(str: String): Future[Int] = Future { str.toInt } 
 
  firstFuture flatMap( secondFuture(_) ) map(result =&gt; println(s"Converted int: $result")) 
 
  Thread.sleep(5000) 
} </pre>
<p class="calibre2">Run:</p>
<pre class="calibre19">Converted int: 1 </pre>
<p class="calibre2">The whole callback logic is magically gone and we have used Future composition to achieve the same. All the magic happens in the line:</p>
<pre class="calibre19">firstFuture flatMap( secondFuture(_) ) map(result =&gt; println(s"Converted int: $result")) </pre>
<p class="calibre2">So, let's try to understand this with the help of a diagram:</p>
<div class="title-page-name">
<div class="cdpaligncenter"><img src="../images/00061.jpeg" class="calibre67"/></div>
</div>
<p class="calibre2">As shown, stars here represent a Future; we take the first future and call the <kbd class="calibre11">flatMap</kbd> function on it. The <kbd class="calibre11">flatMap</kbd> function's signature looks like this:</p>
<pre class="calibre19">def flatMap[S](f: T =&gt; Future[S])(implicit executor: ExecutionContext): Future[S] </pre>
<p class="calibre2">Comparing the signature to the diagram, we can see that the <kbd class="calibre11">flatMap</kbd> function takes the future value and calls subsequent calls to get another Future. The output of the <kbd class="calibre11">flatMap</kbd> function happens to be another Future value, hence we call a <kbd class="calibre11">map</kbd> function that sucks the value out of future, and then we can perform whatever operation we want to perform; in our case, we just printed the value. And from our previous knowledge, we know, comprehension works as a syntactic hack to our <kbd class="calibre11">flatMap</kbd> and map call. So, the following code also works well for our future's composition:</p>
<pre class="calibre19">for { 
  value1 &lt;- firstFuture 
  value2 &lt;- secondFuture(value1) 
} yield println(s"Converted int: $value2") </pre>
<p class="calibre2">A point to note is that in our <kbd class="calibre11">for</kbd> comprehension, the second statement only gets executed once the first value, <kbd class="calibre11">value1</kbd>, is available. That lets us use the first value in the second statement, as shown in the example. So, that's all for future's composition. This mechanism lets us chain several future/async calls together. This composition makes Scala's Future so powerful.</p>
<p class="calibre2">So, we've just discussed the way we create a Future computation by creating a future object; it's worth knowing that Scala also provides a mechanism to assign a particular value to this future object. That mechanism exists in the form of Promises. Let's introduce ourselves to Scala's Promises.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Working with Promises</h1>
                
            
            <article>
                
<p class="calibre2">As we talked about, Promises are used to assign a value to a future object. A Promise itself is an object that corresponds to a particular future object. We can access this <kbd class="calibre11">future</kbd> object by calling <kbd class="calibre11">future</kbd> method on the respective Promise. Let's start by creating a Promise object first:</p>
<pre class="calibre19">import scala.concurrent._ 
import scala.concurrent.ExecutionContext.Implicits.global 
 
object ItsAPromise extends App { 
 
  val firstPromise = Promise[String] 
 
  for { 
    value1 &lt;- firstPromise.future 
  } yield println(s"Value1: $value1") 
 
  firstPromise.success("1") 
 
  Thread.sleep(500) 
} </pre>
<p class="calibre2">Run:</p>
<pre class="calibre19">Value1: 1 </pre>
<p class="calibre2">In the previous code, we created a <kbd class="calibre11">Promise</kbd> instance by simply calling the <kbd class="calibre11">Promise.apply</kbd> method:</p>
<pre class="calibre19">def apply[T](): Promise[T] </pre>
<p class="calibre2">Here, the <kbd class="calibre11">apply</kbd> method takes no parameters, hence the <kbd class="calibre11">Promise</kbd> instance contains no value in itself; the assignment of values to this object can be done using one of the methods available in the Promise API. Methods like <kbd class="calibre11">success</kbd>, <kbd class="calibre11">failure</kbd>, and <kbd class="calibre11">complete</kbd> are used to assign values to a <kbd class="calibre11">Promise</kbd> instance. Each <kbd class="calibre11">Promise</kbd> instance's corresponding Future can be obtained by calling the <kbd class="calibre11">future</kbd> method. In our example, we called the <kbd class="calibre11">success</kbd> method on the <kbd class="calibre11">Promise</kbd> object to assign a value to a linked future. We also used this for comprehension to retrieve the future's value and print it. Running this program will yield the result we passed via this call to success:</p>
<pre class="calibre19">  firstPromise.success("1") </pre>
<p class="calibre2">We can also assign a failure object to linked futures via a call to the <kbd class="calibre11">failure</kbd> method. There are a few points to note:</p>
<ul class="calibre7">
<li class="calibre8">Calling the <kbd class="calibre11">Promise.apply</kbd> method creates an instance without values, just like we did with Futures</li>
<li class="calibre8">Promises do not start any asynchronous computations</li>
<li class="calibre8">Each Promise corresponds to only one <kbd class="calibre11">Future</kbd> object</li>
<li class="calibre8">Each Promise object can be assigned a value only once</li>
<li class="calibre8">Promises provide a way to assign values to <kbd class="calibre11">Future</kbd> objects</li>
</ul>
<p class="calibre2">These points clear up the concept of Promises, and also give us a hint about the implementation of the Future API in Scala.</p>
<p class="calibre2">Futures and Promises provide a simple abstraction over low-level constructs to achieve asynchrony in our programs. We've seen the ways we can use and compose these Futures to chain multiple async calls to get things done. There are other async libraries available in Scala to perform asynchronous programming. Some of the examples of these libraries are <kbd class="calibre11">scala-async</kbd> (<a href="https://github.com/scala/scala-async)" class="calibre10">https://github.com/scala/scala-async</a>) and <kbd class="calibre11">monix</kbd> (<a href="https://github.com/monix/monix)" class="calibre10">https://github.com/monix/monix)</a>. You may want to check out these libraries to understand and try out other asynchronous programming constructs.</p>
<p class="calibre2">There might be use cases where a large collection of data needs to be manipulated to perform some logic. Let's take an example of our <kbd class="calibre11">football.csv</kbd> file. We've read the data and converted the lines from that to <kbd class="calibre11">List[String]</kbd>, and now every element can be parsed to a <kbd class="calibre11">Player</kbd> object giving us <kbd class="calibre11">List[Player]</kbd><em class="calibre18">.</em> If we think a bit, the step where we need to parse <kbd class="calibre11">String</kbd> to <kbd class="calibre11">Player</kbd> does not need to be executed in sequence and can be done in parallel. Now, Scala comes up with the concept of <em class="calibre18">parallel c</em>ollections. Hence, if you need to do some functionality on data in some collections, functionality can be done in parallel. You have an option to convert the collection to its parallel counterpart by calling a simple method <kbd class="calibre11">par</kbd> on the usual collection. Let's look at parallel collections in Scala and try this out.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Parallel collections</h1>
                
            
            <article>
                
<p class="calibre2">Well, before discussing parallel collections in Scala, it's important to have some insight about what parallel computation is. How's it different from concurrent and asynchronous?</p>
<p class="calibre2">Well, we have spent some time understanding that asynchronous computation is non-blocking, hence we know that async computation happens from outside of the main program flow and gives you the value once the computation gets completed. To understand the difference between <em class="calibre18">concurrent</em> and <em class="calibre18">parallel</em> computation, let's look at the following example:</p>
<div class="title-page-name">
<div class="cdpaligncenter"><img src="../images/00062.jpeg" class="calibre68"/></div>
</div>
<p class="calibre2">In the example, we are given a collection of numbers where we want to apply a function to each element of the collection to get a new collection. One method is to take a value out from the starting collection, add one to it, and put that value in a new collection, until the first collection is empty. Now, this process can be made faster by introducing <em class="calibre18">two</em> threads to perform the task of adding one to an element of the collection; let's put it another way by saying we can create two <em class="calibre18">threads</em> to enable <em class="calibre18">concurrent access</em> to our collection:</p>
<div class="title-page-name">
<div class="cdpaligncenter"><img src="../images/00063.jpeg" class="calibre69"/></div>
</div>
<p class="calibre2">Another way can be to break down the collection into two sub collections and perform the task of adding in parallel. This parallelism is possible because the kind of operation we perform is not related to the sequence of elements in the starting collection, nor does it depend on any other element in the collection. Hence, the operation can be carried out in a separate manner in parallel. That's what the difference between concurrent and parallel computations is. The semantics themselves explain whether parallelism is applicable or not:</p>
<div class="title-page-name">
<div class="cdpaligncenter"><img src="../images/00064.jpeg" class="calibre70"/></div>
</div>
<p class="calibre2">This becomes the basis of <em class="calibre18">parallel collections</em> in Scala. Let's try out our well-known example with the <kbd class="calibre11">football.csv</kbd> file. We'll convert the <kbd class="calibre11">List[String]</kbd> to its parallel counterpart and then perform the parsing logic in parallel:</p>
<pre class="calibre19">import scala.collection.parallel.immutable.ParSeq 
import scala.concurrent.Future 
import scala.util.{Failure, Success} 
import scala.concurrent.ExecutionContext.Implicits.global 
 
object TowardsParallelCollections extends App { 
 
  val fileSource =    "/Users/vika/Documents/LSProg/LSPWorkspace/FirstProject/src/chapter13/football_stats.csv" 
 
  val listOfPlayers: Future[List[Player]] = Future { 
    val source = io.Source.fromFile(fileSource) 
    val list: List[String] = source.getLines().toList 
 
    source.close() 
 
    val parSequence = list.par.tail 
     
    val playerParSequence: ParSeq[Player] = parSequence.map { 
      case line =&gt; val columns = line.split((",")).map(_.trim) 
        Player(columns(5),columns(6),columns(9),columns(7), 
          columns(8),columns(10), columns(12), columns(0),columns(2)) 
    } 
 
 
    playerParSequence.toList 
  } 
 
  listOfPlayers foreach { 
    case list =&gt; list foreach println 
  } 
 
  Thread.sleep(5000) 
 
} </pre>
<p class="calibre2">In the example, we converted the <kbd class="calibre11">List[String]</kbd> to a <kbd class="calibre11">ParSeq</kbd> that is <em class="calibre18">a parallel</em> counterpart of our Scala collection <kbd class="calibre11">List</kbd><em class="calibre18">.</em> After converting to a parallel collection, we called a <kbd class="calibre11">map</kbd> method on the parallel collection and performed the parsing operation. The parallel collection API is so consistent that it looks so normal to call the<em class="calibre18"> </em><kbd class="calibre11">map</kbd> method and perform some operation, but underlying task execution is taken care of by multiple processors at the same time; in other words, computations are happening in parallel. Running the previous code will print out the list of players as expected.</p>
<p class="calibre2">Scala's parallel collections reside in the <kbd class="calibre11">scala.collection.parallel</kbd> package. To create one parallel collection, we can either use the new keyword along with the collection name or we can convert a sequential collection to its parallel counterpart by calling the <kbd class="calibre11">par</kbd> function, which we did in our example.</p>
<p class="calibre2">A few of the available parallel collections are:</p>
<ul class="calibre7">
<li class="calibre8"><kbd class="calibre11">ParArray</kbd></li>
<li class="calibre8"><kbd class="calibre11">ParVector</kbd></li>
<li class="calibre8"><kbd class="calibre11">mutable.ParHashMap</kbd></li>
<li class="calibre8"><kbd class="calibre11">mutable.ParHashSet</kbd></li>
<li class="calibre8"><kbd class="calibre11">immutable.ParHashMap</kbd></li>
<li class="calibre8"><kbd class="calibre11">immutable.ParHashSet</kbd></li>
<li class="calibre8"><kbd class="calibre11">ParRange</kbd></li>
<li class="calibre8"><kbd class="calibre11">ParTrieMap</kbd></li>
</ul>
<p class="calibre2">We can instantiate these parallel collections the same way we do for sequential collections; that's the power of Scala's parallel collections. This makes a lot of collection-based computations faster to perform. With this, we can go and summarize our chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            <article>
                
<p class="calibre2">In this chapter, we learned about the building blocks of concurrency in Scala. It was fascinating to understand the underlying blocks of concurrency in OS and JVM. We learned the difference between processes and threads. We discussed <kbd class="calibre11">ExecutionContext</kbd> and why we need one. Then, we talked about asynchronous programming using Future and Promises. Finally, we discussed parallel collections in Scala.</p>
<p class="calibre2">In our next chapter, we'll be discussing another important and much talked about reactive programming abstraction available in Scala. We'll go through the reactive extensions available in Scala.</p>


            </article>

            
        </section>
    </body></html>