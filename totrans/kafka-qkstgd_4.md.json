["```java\n{\n   \"event\":\"HEALTH_CHECK\",\n   \"factory\":\"Duckburg\",\n   \"serialNumber\":\"R2D2-C3P0\",\n   \"type\":\"GEOTHERMAL\",\n   \"status\":\"RUNNING\",\n   \"lastStartedAt\":\"2017-09-04T17:27:28.747+0000\",\n   \"temperature\":31.5,\n   \"ipAddress\":\"192.166.197.213\"}\n}\n```", "```java\n$ gradle init --type java-library\n```", "```java\nStarting a Gradle Daemon (subsequent builds will be faster)\nBUILD SUCCESSFUL in 3s\n2 actionable tasks: 2 execute BUILD SUCCESSFUL\n```", "```java\napply plugin: 'java'\napply plugin: 'application'\nsourceCompatibility = '1.8'\nmainClassName = 'kioto.ProcessingEngine'\nrepositories {\n    mavenCentral()\n    maven { url 'https://packages.confluent.io/maven/' }\n}\nversion = '0.1.0'\ndependencies {\n    compile 'com.github.javafaker:javafaker:0.15'\n    compile 'com.fasterxml.jackson.core:jackson-core:2.9.7'\n    compile 'io.confluent:kafka-avro-serializer:5.0.0'\n    compile 'org.apache.kafka:kafka_2.12:2.0.0'\n}\njar {\n    manifest {\n        attributes 'Main-Class': mainClassName\n    } from {\n        configurations.compile.collect {\n            it.isDirectory() ? it : zipTree(it)\n        }\n    }\n    exclude \"META-INF/*.SF\"\n    exclude \"META-INF/*.DSA\"\n    exclude \"META-INF/*.RSA\"\n}\n```", "```java\n$ gradle compileJava\n```", "```java\nBUILD SUCCESSFUL in 3s\n1 actionable task: 1 executed\n```", "```java\npackage kioto;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.SerializationFeature;\nimport com.fasterxml.jackson.databind.util.StdDateFormat;\npublic final class Constants {\n  private static final ObjectMapper jsonMapper;\n  static {\n    ObjectMapper mapper = new ObjectMapper();\n    mapper.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);\n    mapper.setDateFormat(new StdDateFormat());\n    jsonMapper = mapper;\n  }\n  public static String getHealthChecksTopic() {\n    return \"healthchecks\";\n  }\n  public static String getHealthChecksAvroTopic() {\n    return \"healthchecks-avro\";\n  }\n  public static String getUptimesTopic() {\n    return \"uptimes\";\n  }\n  public enum machineType {GEOTHERMAL, HYDROELECTRIC, NUCLEAR, WIND, SOLAR}\n  public enum machineStatus {STARTING, RUNNING, SHUTTING_DOWN, SHUT_DOWN}\n  public static ObjectMapper getJsonMapper() {\n    return jsonMapper;\n  }\n}\n```", "```java\npackage kioto;\nimport java.util.Date;\npublic final class HealthCheck {\n  private String event;\n  private String factory;\n  private String serialNumber;\n  private String type;\n  private String status;\n  private Date lastStartedAt;\n  private float temperature;\n  private String ipAddress;\n}\n```", "```java\nHealthCheck fakeHealthCheck =\n   new HealthCheck(\n        \"HEALTH_CHECK\",\n        faker.address().city(),                    //1\n        faker.bothify(\"??##-??##\", true),    //2\n              Constants.machineType.values()\n                   [faker.number().numberBetween(0,4)].toString(), //3\n        Constants.machineStatus.values()\n                   [faker.number().numberBetween(0,3)].toString(), //4\n        faker.date().past(100, TimeUnit.DAYS),           //5\n        faker.number().numberBetween(100L, 0L),          //6\n        faker.internet().ipV4Address());                 //7\n```", "```java\nString fakeHealthCheckJson fakeHealthCheckJson = Constants.getJsonMapper().writeValueAsString(fakeHealthCheck);\n```", "```java\n{\"event\":\"HEALTH_CHECK\",\"factory\":\"Port Roelborough\",\"serialNumber\":\"QT89-TZ50\",\"type\":\"GEOTHERMAL\",\"status\":\"SHUTTING_DOWN\",\"lastStartedAt\":\"2018-09-13T00:36:39.079+0000\",\"temperature\":28.0,\"ipAddress\":\"235.180.238.3\"}\n\n{\"event\":\"HEALTH_CHECK\",\"factory\":\"Duckburg\",\"serialNumber\":\"NB49-XL51\",\"type\":\"NUCLEAR\",\"status\":\"RUNNING\",\"lastStartedAt\":\"2018-08-18T05:42:29.648+0000\",\"temperature\":49.0,\"ipAddress\":\"42.181.105.188\"}\n...\n```", "```java\nimport org.apache.kafka.clients.producer.KafkaProducer;\nimport org.apache.kafka.clients.producer.Producer;\nimport org.apache.kafka.common.serialization.StringSerializer;\npublic final class PlainProducer {\n  private final Producer<String, String> producer;\n  public PlainProducer(String brokers) {\n    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", brokers);                //1\n    props.put(\"key.serializer\", StringSerializer.class);    //2\n    props.put(\"value.serializer\", StringSerializer.class);  //3\n    producer = new KafkaProducer<>(props);                  //4\n  }\n  ...\n}\n```", "```java\npackage kioto.plain;\nimport ...\npublic final class PlainProducer {\n  /* here the Constructor code in Listing 4.6 */\n  public void produce(int ratePerSecond) {\n    long waitTimeBetweenIterationsMs = 1000L / (long)ratePerSecond; //1\n    Faker faker = new Faker();\n    while(true) { //2\n      HealthCheck fakeHealthCheck /* here the code in Listing 4.5 */;\n      String fakeHealthCheckJson = null;\n      try {\n        fakeHealthCheckJson = Constants.getJsonMapper().writeValueAsString(fakeHealthCheck); //3\n      } catch (JsonProcessingException e) {\n         // deal with the exception\n      }\n      Future futureResult = producer.send(new ProducerRecord<>\n         (Constants.getHealthChecksTopic(), fakeHealthCheckJson)); //4\n      try {\n        Thread.sleep(waitTimeBetweenIterationsMs); //5\n        futureResult.get(); //6\n      } catch (InterruptedException | ExecutionException e) {\n         // deal with the exception\n      }\n    }\n  }\n  public static void main(String[] args) {\n    new PlainProducer(\"localhost:9092\").produce(2); //7\n  }\n}\n```", "```java\n$ gradle jar\n```", "```java\nBUILD SUCCESSFUL in 3s\n1 actionable task: 1 executed\n```", "```java\n$ ./bin/confluent start\n```", "```java\n$ ./bin/kafka-topics --zookeeper localhost:2181 --create --topic             \nhealthchecks --replication-factor 1 --partitions 4\n```", "```java\n$ ./bin/kafka-console-consumer --bootstrap-server localhost:9092       \n--topic healthchecks\n```", "```java\n{\"event\":\"HEALTH_CHECK\",\"factory\":\"Lake Anyaport\",\"serialNumber\":\"EW05-HV36\",\"type\":\"WIND\",\"status\":\"STARTING\",\"lastStartedAt\":\"2018-09-17T11:05:26.094+0000\",\"temperature\":62.0,\"ipAddress\":\"15.185.195.90\"}\n\n{\"event\":\"HEALTH_CHECK\",\"factory\":\"Candelariohaven\",\"serialNumber\":\"BO58-SB28\",\"type\":\"SOLAR\",\"status\":\"STARTING\",\"lastStartedAt\":\"2018-08-16T04:00:00.179+0000\",\"temperature\":75.0,\"ipAddress\":\"151.157.164.162\"}\n\n{\"event\":\"HEALTH_CHECK\",\"factory\":\"Ramonaview\",\"serialNumber\":\"DV03-ZT93\",\"type\":\"SOLAR\",\"status\":\"RUNNING\",\"lastStartedAt\":\"2018-07-12T10:16:39.091+0000\",\"temperature\":70.0,\"ipAddress\":\"173.141.90.85\"}\n...\n```", "```java\nimport org.apache.kafka.clients.consumer.KafkaConsumer;\nimport org.apache.kafka.clients.consumer.Consumer;\nimport org.apache.kafka.common.serialization.StringSerializer;\npublic final class PlainConsumer {\n  private Consumer<String, String> consumer;\n  public PlainConsumer(String brokers) {\n    Properties props = new Properties();\n    props.put(\"group.id\", \"healthcheck-processor\");         //1\n    props.put(\"bootstrap.servers\", brokers);                   //2\n    props.put(\"key.deserializer\", StringDeserializer.class);   //3\n    props.put(\"value.deserializer\", StringDeserializer.class); //4\n    consumer = new KafkaConsumer<>(props);                        //5\n  }\n  ...\n}\n```", "```java\npackage kioto.plain;\nimport ...\npublic final class PlainProcessor {\n  private Consumer<String, String> consumer;\n  private Producer<String, String> producer;\n  public PlainProcessor(String brokers) {\n    Properties consumerProps = new Properties();\n    consumerProps.put(\"bootstrap.servers\", brokers);\n    consumerProps.put(\"group.id\", \"healthcheck-processor\");\n    consumerProps.put(\"key.deserializer\", StringDeserializer.class);\n    consumerProps.put(\"value.deserializer\", StringDeserializer.class);\n    consumer = new KafkaConsumer<>(consumerProps);\n    Properties producerProps = new Properties();\n    producerProps.put(\"bootstrap.servers\", brokers);\n    producerProps.put(\"key.serializer\", StringSerializer.class);\n    producerProps.put(\"value.serializer\", StringSerializer.class);\n    producer = new KafkaProducer<>(producerProps);\n  }\n```", "```java\n public final void process() {\n    consumer.subscribe(Collections.singletonList(\n               Constants.getHealthChecksTopic()));           //1\n    while(true) {\n      ConsumerRecords records = consumer.poll(Duration.ofSeconds(1L)); //2\n      for(Object record : records) {                //3\n        ConsumerRecord it = (ConsumerRecord) record;\n        String healthCheckJson = (String) it.value();\n        HealthCheck healthCheck = null;\n        try {\n          healthCheck = Constants.getJsonMapper()\n           .readValue(healthCheckJson, HealthCheck.class);     // 4\n        } catch (IOException e) {\n            // deal with the exception\n        }\n        LocalDate startDateLocal =healthCheck.getLastStartedAt().toInstant()                   .atZone(ZoneId.systemDefault()).toLocalDate();        //5\n        int uptime =\n             Period.between(startDateLocal, LocalDate.now()).getDays();  //6\n        Future future =\n             producer.send(new ProducerRecord<>(\n                              Constants.getUptimesTopic(),\n                              healthCheck.getSerialNumber(),\n                              String.valueOf(uptime)));                  //7\n        try {\n          future.get();\n        } catch (InterruptedException | ExecutionException e) {\n          // deal with the exception\n        }\n      }\n    }\n  }\n  public static void main( String[] args) {\n    (new PlainProcessor(\"localhost:9092\")).process();\n  }\n}\n```", "```java\n$ gradle jar\n```", "```java\nBUILD SUCCESSFUL in 3s\n1 actionable task: 1 executed\n```", "```java\n$ ./bin/kafka-topics --zookeeper localhost:2181 --create --topic \nuptimes --replication-factor 1 --partitions 4\n```", "```java\n$ ./bin/kafka-console-consumer --bootstrap-server localhost:9092 \n--topic uptimes --property print.key=true\n```", "```java\nEW05-HV36   33\nBO58-SB28   20\nDV03-ZT93   46\n...\n```", "```java\npackage kioto.serde;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport kioto.Constants;\nimport java.util.Map;\nimport org.apache.kafka.common.serialization.Serializer;\npublic final class HealthCheckSerializer implements Serializer {\n  @Override\n  public byte[] serialize(String topic, Object data) {\n    if (data == null) {\n      return null;\n    }\n    try {\n      return Constants.getJsonMapper().writeValueAsBytes(data);\n    } catch (JsonProcessingException e) {\n      return null;\n    }\n  }\n\n  @Override\n  public void close() {}\n  @Override\n  public void configure(Map configs, boolean isKey) {}\n}\n```", "```java\nimport kioto.serde.HealthCheckSerializer;\nimport org.apache.kafka.clients.producer.KafkaProducer;\nimport org.apache.kafka.clients.producer.Producer;\nimport org.apache.kafka.common.serialization.StringSerializer;\npublic final class CustomProducer {\n  private final Producer<String, HealthCheck> producer;\n  public CustomProducer(String brokers) {\n    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", brokers);                    //1\n    props.put(\"key.serializer\", StringSerializer.class);        //2\n    props.put(\"value.serializer\", HealthCheckSerializer.class); //3\n    producer = new KafkaProducer<>(props);                      //4\n  }\n```", "```java\npackage kioto.plain;\nimport ...\npublic final class CustomProducer {\n  /* here the Constructor code in Listing 4.12 */\n  public void produce(int ratePerSecond) {\n    long waitTimeBetweenIterationsMs = 1000L / (long)ratePerSecond; //1\n    Faker faker = new Faker();\n    while(true) { //2\n      HealthCheck fakeHealthCheck /* here the code in Listing 4.5 */;\n      Future futureResult = producer.send( new ProducerRecord<>(\n         Constants.getHealthChecksTopic(), fakeHealthCheck));       //3\n      try {\n        Thread.sleep(waitTimeBetweenIterationsMs); //4\n        futureResult.get();      //5          \n      } catch (InterruptedException | ExecutionException e) {\n        // deal with the exception\n      }\n    }\n  }\npublic static void main(String[] args) {\n    new CustomProducer(\"localhost:9092\").produce(2); //6\n  }\n}\n```", "```java\n$ gradle jar\n```", "```java\nBUILD SUCCESSFUL in 3s\n1 actionable task: 1 executed\n```", "```java\n$ ./bin/kafka-console-consumer --bootstrap-server localhost:9092 \n--topic healthchecks\n```", "```java\n{\"event\":\"HEALTH_CHECK\",\"factory\":\"Lake Anyaport\",\"serialNumber\":\"EW05-HV36\",\"type\":\"WIND\",\"status\":\"STARTING\",\"lastStartedAt\":\"2018-09-17T11:05:26.094+0000\",\"temperature\":62.0,\"ipAddress\":\"15.185.195.90\"}\n\n{\"event\":\"HEALTH_CHECK\",\"factory\":\"Candelariohaven\",\"serialNumber\":\"BO58-SB28\",\"type\":\"SOLAR\",\"status\":\"STARTING\",\"lastStartedAt\":\"2018-08-16T04:00:00.179+0000\",\"temperature\":75.0,\"ipAddress\":\"151.157.164.162\"}\n\n{\"event\":\"HEALTH_CHECK\",\"factory\":\"Ramonaview\",\"serialNumber\":\"DV03-ZT93\",\"type\":\"SOLAR\",\"status\":\"RUNNING\",\"lastStartedAt\":\"2018-07-12T10:16:39.091+0000\",\"temperature\":70.0,\"ipAddress\":\"173.141.90.85\"}\n\n...\n```", "```java\npackage kioto.serde;\nimport kioto.Constants;\nimport kioto.HealthCheck;\nimport java.io.IOException;\nimport java.util.Map;\nimport org.apache.kafka.common.serialization.Deserializer;\npublic final class HealthCheckDeserializer implements Deserializer {\n  @Override\n  public HealthCheck deserialize(String topic, byte[] data) {\n    if (data == null) {\n      return null;\n    }\n    try {\n      return Constants.getJsonMapper().readValue(data, HealthCheck.class);\n    } catch (IOException e) {\n      return null;\n    }\n  }\n  @Override\n  public void close() {}\n  @Override\n  public void configure(Map configs, boolean isKey) {}\n}\n```", "```java\nimport kioto.HealthCheck;\nimport kioto.serde.HealthCheckDeserializer;\nimport org.apache.kafka.clients.consumer.KafkaConsumer;\nimport org.apache.kafka.clients.consumer.Consumer;\nimport org.apache.kafka.common.serialization.StringSerializer;\npublic final class CustomConsumer {\n  private Consumer<String, HealthCheck> consumer;\n  public CustomConsumer(String brokers) {\n    Properties props = new Properties();\n    props.put(\"group.id\", \"healthcheck-processor\");//1\n    props.put(\"bootstrap.servers\", brokers);//2\n    props.put(\"key.deserializer\", StringDeserializer.class);//3\n    props.put(\"value.deserializer\", HealthCheckDeserializer.class); //4\n    consumer = new KafkaConsumer<>(props);//5\n  }\n  ...\n}\n```", "```java\npackage kioto.custom;\nimport ...\n\npublic final class CustomProcessor {\n\n  private Consumer<String, HealthCheck> consumer;\n  private Producer<String, String> producer;\n\n  public CustomProcessor(String brokers) {\n    Properties consumerProps = new Properties();\n    consumerProps.put(\"bootstrap.servers\", brokers);\n    consumerProps.put(\"group.id\", \"healthcheck-processor\");\n    consumerProps.put(\"key.deserializer\", StringDeserializer.class);\n    consumerProps.put(\"value.deserializer\",                        HealthCheckDeserializer.class);\n    consumer = new KafkaConsumer<>(consumerProps);\n    Properties producerProps = new Properties();\n    producerProps.put(\"bootstrap.servers\", brokers);\n    producerProps.put(\"key.serializer\", StringSerializer.class);\n    producerProps.put(\"value.serializer\", StringSerializer.class);\n    producer = new KafkaProducer<>(producerProps);\n  }\n```", "```java\npublic final void process() {\n    consumer.subscribe(Collections.singletonList(\n             Constants.getHealthChecksTopic()));           //1\n    while(true) {\n      ConsumerRecords records = consumer.poll(Duration.ofSeconds(1L)); //2\n      for(Object record : records) {                 //3\n        ConsumerRecord it = (ConsumerRecord) record;\n        HealthCheck healthCheck = (HealthCheck) it.value(); //4\n        LocalDate startDateLocal =healthCheck.getLastStartedAt().toInstant()\n                 .atZone(ZoneId.systemDefault()).toLocalDate();         //5\n        int uptime =\n             Period.between(startDateLocal, LocalDate.now()).getDays();  //6\n        Future future =\n             producer.send(new ProducerRecord<>(\n                              Constants.getUptimesTopic(),\n                              healthCheck.getSerialNumber(),\n                             String.valueOf(uptime)));                  //7\n        try {\n          future.get();\n        } catch (InterruptedException | ExecutionException e) {\n          // deal with the exception\n        }\n      }\n    }\n  }\n  public static void main( String[] args) {\n    new CustomProcessor(\"localhost:9092\").process();\n  }\n}\n```", "```java\n$ gradle jar\n```", "```java\nBUILD SUCCESSFUL in 3s\n1 actionable task: 1 executed\n```", "```java\n$ ./bin/kafka-console-consumer --bootstrap-server localhost:9092 \n--topic uptimes --property print.key=true\n```", "```java\nEW05-HV36   33\nBO58-SB28   20\nDV03-ZT93   46\n...\n```"]