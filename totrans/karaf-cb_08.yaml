- en: Chapter 8. Providing a Big Data Integration Layer with Apache Cassandra
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章。使用Apache Cassandra提供大数据集成层
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Installing Cassandra client bundles in Apache Karaf
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Apache Karaf中安装Cassandra客户端包。
- en: Modeling data with Apache Cassandra
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Apache Cassandra建模数据。
- en: Building a project with a persistence layer for deployment in Karaf
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Karaf中构建具有持久化层的项目以进行部署。
- en: Introduction
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: As illustrated in the previous chapters, persistence is a large part of most
    deployments and applications. So far, we've focused on relational databases. Let's
    start off with some history.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '如前几章所示，持久性是大多数部署和应用程序的重要组成部分。到目前为止，我们一直专注于关系数据库。让我们从一些历史开始。 '
- en: In 1970, IBM published a paper named *A Relational Model of Data for Large Shared
    Data Banks*. This paper became the foundation for RDBMS and modern relational
    databases in that it described joins and relationships between entities. From
    this work, followed SQL (1986), ACID (Atomic, Consistent, Isolated, and Durable),
    schema design, and sharding for scalability.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在1970年，IBM发表了一篇名为*大型共享数据银行的关系数据模型*的论文。这篇论文成为了关系数据库管理系统（RDBMS）和现代关系数据库的基础，因为它描述了实体之间的连接和关系。从这个工作出发，随后出现了SQL（1986年）、ACID（原子性、一致性、隔离性和持久性）、模式设计和分片以实现可扩展性。
- en: 'Let''s fast forward to the advent of social networks; a term called **WebScale**
    was coined based on Reed''s law that states:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快进到社交网络的兴起；一个基于Reed定律的术语**WebScale**被提出，该定律指出：
- en: '*"The utility of large networks, particularly social networks, can scale exponentially
    with the size of the network."*'
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*"大型网络，尤其是社交网络，其效用可以随着网络规模的指数级增长。"*'
- en: 'Does this mean that RDBMS cannot be scaled? No, but it led to the development
    of NoSQL. NoSQL is usually based on the following definitions:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这是否意味着RDBMS不能进行扩展？不，但它导致了NoSQL的发展。NoSQL通常基于以下定义：
- en: It was originally coined by Carlo Strozzi who developed the Strozzi NoSQL database
    in 1998
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它最初是由Carlo Strozzi提出的，他在1998年开发了Strozzi NoSQL数据库。
- en: It typically has the key/value style of storage in columns/tables
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它通常具有列/表中的键/值存储风格。
- en: It is generally schema-less, or each row can contain a different structure
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它通常是模式无关的，或者每一行可以包含不同的结构。
- en: It does not require SQL as a language; thus the name *NoSQL*
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它不需要使用SQL作为语言；因此得名*NoSQL*。
- en: Many support BASE consistency
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多支持BASE一致性。
- en: Most are distributed and fault-tolerant in nature
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数都是分布式和容错的。
- en: Apache Cassandra was originally developed at Facebook, then released as open
    source in 2008, incubated at Apache in 2009, and became a top-level Apache project
    in 2010\. Through rapid adaptation and features desirable in many use cases, Apache
    Cassandra has rapidly gained traction and wide distribution. Today's versions
    of Cassandra have a slightly stricter schema orientation with the introduction
    of **Cassandra Query Language** (**CQL**), a way of helping to drive transition
    from traditional RDBMS models to a more unstructured key/value pair storage model
    while retaining a structure and data model familiar to users in general. For an
    annotated history of the transition of Apache Cassandra, see [http://www.datastax.com/documentation/articles/cassandra/cassandrathenandnow.html](http://www.datastax.com/documentation/articles/cassandra/cassandrathenandnow.html).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Cassandra最初在Facebook开发，于2008年作为开源发布，2009年在Apache孵化，并于2010年成为Apache顶级项目。通过快速适应和许多用例中期望的特性，Apache
    Cassandra迅速获得了牵引力和广泛分布。Cassandra的当前版本在引入**Cassandra查询语言**（**CQL**）后，具有略微严格的模式导向，这是一种帮助推动从传统的RDBMS模型到更无结构的键/值对存储模型过渡的方式，同时保留了用户普遍熟悉的结构和数据模型。有关Apache
    Cassandra过渡的注释历史，请参阅[http://www.datastax.com/documentation/articles/cassandra/cassandrathenandnow.html](http://www.datastax.com/documentation/articles/cassandra/cassandrathenandnow.html)。
- en: CQL is the default and primary interface into the Cassandra DBMS. Using CQL
    is similar to using SQL. CQL and SQL share the same abstract idea of a table constructed
    of columns and rows. The main difference is that Cassandra does not support joins
    or subqueries, except for batch analysis through Apache Hive. Instead, Cassandra
    emphasizes denormalization through CQL features like collections and clustering
    specified at the schema level.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: CQL是Cassandra数据库管理系统（DBMS）的默认和主要接口。使用CQL与使用SQL相似。CQL和SQL共享相同的抽象概念，即由列和行构成的表。主要区别在于Cassandra不支持连接或子查询，除了通过Apache
    Hive进行批量分析。相反，Cassandra强调通过CQL的集合和聚类等特性在模式级别进行去规范化。
- en: What this basically means is that there are other client APIs—they are, as of
    Cassandra release 2.x, actively discouraged from use by the Cassandra community.
    A healthy debate over the usage of schema modeling versus column family is still
    quite active on mailing lists and in user communities.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这基本上意味着还有其他客户端 API——截至 Cassandra 发布 2.x 版本，Cassandra 社区积极不建议使用它们。关于使用模式建模与列族使用的健康辩论仍然在邮件列表和用户社区中非常活跃。
- en: Installing Cassandra client bundles in Apache Karaf
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Apache Karaf 中安装 Cassandra 客户端包
- en: Before we begin to explore how to build Cassandra-backed applications, we must
    first install all the required client modules into the Karaf container.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始探索如何构建基于 Cassandra 的应用程序之前，我们必须首先将所有必需的客户端模块安装到 Karaf 容器中。
- en: Getting ready
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: The official *GettingStarted* document from the Cassandra community can be found
    at [http://wiki.apache.org/cassandra/GettingStarted](http://wiki.apache.org/cassandra/GettingStarted).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Cassandra 社区的官方 *GettingStarted* 文档可以在 [http://wiki.apache.org/cassandra/GettingStarted](http://wiki.apache.org/cassandra/GettingStarted)
    找到。
- en: 'The ingredients of this recipe include the Apache Karaf distribution kit, access
    to JDK, and Internet connectivity. We also assume that an Apache Cassandra database
    is downloaded and installed. Apache Cassandra can be downloaded and installed
    as RPMs, Debian `.deb` packages, or `.tar` archives. In a binary `.tar` archive,
    you''ll have to open and change two configuration files: the `cassandra.yaml`
    and the `log4-server.properties` files of the `conf` folder. The changes pertain
    to where you store data, which is by default in the `/var/lib/cassandra/*` folder
    for the data backend and in the `/var/log/cassandra/*` folder for the system log.
    Once these changes are done, you can start Cassandra using the `bin/cassandra
    –F` command.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这个菜谱的成分包括 Apache Karaf 分发套件、对 JDK 的访问和互联网连接。我们还假设 Apache Cassandra 数据库已下载并安装。Apache
    Cassandra 可以作为 RPM、Debian `.deb` 包或 `.tar` 归档下载和安装。在二进制 `.tar` 归档中，您需要打开并更改 `conf`
    文件夹中的两个配置文件：`cassandra.yaml` 和 `log4-server.properties` 文件。更改涉及数据存储的位置，默认情况下数据后端存储在
    `/var/lib/cassandra/*` 文件夹中，系统日志存储在 `/var/log/cassandra/*` 文件夹中。一旦完成这些更改，您可以使用
    `bin/cassandra –F` 命令启动 Cassandra。
- en: How to do it…
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: Cassandra's drivers aren't part of the standard Karaf feature library; so, we
    either have to write our own feature or manually install the necessary bundles
    for the client to run.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Cassandra 的驱动程序不是标准 Karaf 功能库的一部分；因此，我们或者必须编写自己的功能，或者手动安装客户端运行所需的必要包。
- en: 'We use the following commands to install Apache Cassandra''s driver and supplemental
    bundles into Karaf:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下命令将 Apache Cassandra 的驱动程序和补充包安装到 Karaf 中：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We can verify the installation by executing the `list -t 0 | grep -i cass` command,
    which will list the DataStax driver bundle.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过执行 `list -t 0 | grep -i cass` 命令来验证安装，该命令将列出 DataStax 驱动程序包。
- en: With this, we have access to the Cassandra driver from our own bundles.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们可以从自己的包中访问 Cassandra 驱动程序。
- en: Modeling data with Apache Cassandra
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Apache Cassandra 建模数据
- en: Before we start writing a bundle using Apache Cassandra, let's look a little
    at how we model data in Cassandra using CQL 3.x.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始使用 Apache Cassandra 编写包之前，让我们简要看看如何使用 CQL 3.x 在 Cassandra 中建模数据。
- en: Getting ready
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Let's define a very simple schema, and as we are using CQL, Cassandra isn't
    schema-less from a client perspective even if the data storage internally works
    slightly differently.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个非常简单的模式，因为我们使用 CQL，从客户端的角度来看，Cassandra 即使在内部数据存储略有不同的情况下也不是无模式的。
- en: 'We can reuse the `RecipeService` class from the previous chapter. We will just
    modify it slightly for our Cassandra integration. The original entity (and by
    virtue of using JPA) provides a basic table definition, which is as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以重用前一章中的 `RecipeService` 类。我们只需对其进行轻微修改以适应 Cassandra 集成。原始实体（以及通过使用 JPA）提供了一个基本的表定义，如下所示：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'So, we have two fields in this table: an ID field named `title` and a data
    field we call `ingredients` for consistency and simplicity.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这个表中我们有两个字段：一个名为 `title` 的 ID 字段和一个我们称为 `ingredients` 的数据字段，以保持一致性和简单性。
- en: First, we need a place to store this. Cassandra partitions data in keyspaces
    at the top level. Think of a keyspace as a map containing tables and their rules.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一个地方来存储这些。Cassandra 在顶级键空间中分区数据。将键空间想象成一个包含表及其规则的映射。
- en: How to do it…
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'We''ll need to perform the following two steps:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要执行以下两个步骤：
- en: 'The first step is starting the Cassandra client. The basic creation command
    in Cassandra''s client, `cqlsh`, is shown as follows:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是启动Cassandra客户端。Cassandra客户端的基本创建命令`cqlsh`如下所示：
- en: '[PRE2]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The next step is creating our data store. Now that we have started the interactive
    client session, we can create a keyspace as shown in the following command:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是创建我们的数据存储。既然我们已经启动了交互式客户端会话，我们可以创建一个键空间，如下命令所示：
- en: '[PRE3]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The previous command-line prompt returns no response indicating that we have
    successfully created a new keyspace where we can store data. To use this keyspace,
    we need to tell Cassandra that this is where we'll be working right now.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 之前的命令行提示符没有返回响应，表明我们已经成功创建了一个新的键空间，我们可以在此存储数据。要使用此键空间，我们需要告诉Cassandra我们现在将在这里工作。
- en: Tip
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: We rely on SimpleStrategy as we only have one Cassandra node, we don't have
    a real cluster defined, nor do we have multiple data centers. If this was the
    case, we could change the strategy class for replication. We also set the `replication_factor`
    value to `1`; this can be set to more replicas and certainly should be done in
    security-related contexts where you, for instance, store account information.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于我们只有一个Cassandra节点，我们没有定义真实集群，也没有多个数据中心，所以我们依赖SimpleStrategy。如果情况是这样，我们可以更改复制策略类。我们还设置了`replication_factor`值为`1`；这可以设置为更多副本，并且在安全性相关的环境中，例如存储账户信息时，这肯定应该完成。
- en: 'To switch the keyspace, we issue a `USE` command as follows:'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要切换键空间，我们发出以下`USE`命令：
- en: '[PRE4]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The preceding command prompt indicates that we are in the `karaf_demo` keyspace.
    Consider the following command:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前述命令提示符表明我们处于`karaf_demo`键空间。考虑以下命令：
- en: '[PRE5]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As the preceding command indicates, we have nothing defined schema-wise in
    this keyspace, and so we need to define a table. This can be done as follows:'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如前述命令所示，我们在该键空间中未定义任何模式，因此我们需要定义一个表。可以按照以下方式完成：
- en: '[PRE6]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We now have a defined table and the columns in this table are defined as the
    storage type `text` and the primary key and retrieval token as the `title`.
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们已经定义了一个表，并且该表中的列被定义为存储类型`text`，主键和检索令牌为`title`。
- en: How it works…
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: It is beyond the scope of this book to explore the under-the-hood functioning
    of Apache Cassandra. However, you can examine its source code at [http://git-wip-us.apache.org/repos/asf/cassandra.git](http://git-wip-us.apache.org/repos/asf/cassandra.git).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 本书范围之外，不涉及Apache Cassandra底层工作原理的探讨。然而，您可以在[http://git-wip-us.apache.org/repos/asf/cassandra.git](http://git-wip-us.apache.org/repos/asf/cassandra.git)查看其源代码。
- en: 'In terms of our data store, we can let Cassandra describe exactly what is being
    stored. Consider the following command-line snippet:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的数据存储方面，我们可以让Cassandra精确描述正在存储的内容。考虑以下命令行片段：
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: As you can see, there are quite a few options you, as a data modeler, can work
    with. These will affect replication, caching, lifetime, compression, and several
    other factors.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，作为数据模型师，您有很多选项可以操作。这些将影响复制、缓存、生命周期、压缩以及许多其他因素。
- en: Building a project with a persistence layer for deployment in Karaf
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Karaf中构建具有持久化层的项目以进行部署
- en: Application developers often need to make use of a persistence layer in their
    projects; one of the preferred methodologies to perform this in Karaf is to make
    use of the Java Persistence API. As we are building on the existing JPA project,
    we will try and set up a new service layer and reuse (copy) the same project model
    while moving over the storage backend to Apache Cassandra. This is not a complete
    refactoring nor a reuse of code. Technically, we could have moved the API parts
    from [Chapter 7](ch07.html "Chapter 7. Providing a Persistence Layer with Apache
    Aries and OpenJPA"), *Providing a Persistence Layer with Apache Aries and OpenJPA*,
    into a new module and then refactored the chapter to have the Cassandra-related
    dependencies and a slightly different set of imports. This isn't really in the
    scope of a Cookbook, hence the copied structure.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序开发人员通常需要在他们的项目中使用持久化层；在Karaf中执行此操作的一种首选方法是使用Java Persistence API。由于我们基于现有的JPA项目构建，我们将尝试设置一个新的服务层并重用（复制）相同的项目模型，同时将存储后端迁移到Apache
    Cassandra。这既不是完全重构也不是代码重用。技术上，我们可以将API部分从[第7章](ch07.html "第7章。使用Apache Aries和OpenJPA提供持久化层")
    *使用Apache Aries和OpenJPA提供持久化层* 移动到一个新模块，然后重构章节以包含与Cassandra相关的依赖项和一组略有不同的导入。这实际上并不在Cookbook的范围内，因此保留了复制的结构。
- en: In the *Installing Cassandra client bundles in Apache Karaf* recipe, we learned
    how to install the necessary JAR files into Karaf. Continuing with this recipe,
    we'll make use of the drivers to build a simple application that persists recipes
    to a database using the `RecipeBookService` class, which will hide the complexities
    of data storage and retrieval from its users.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在*在Apache Karaf中安装Cassandra客户端捆绑包*的配方中，我们学习了如何将必要的JAR文件安装到Karaf中。继续这个配方，我们将使用驱动程序构建一个简单的应用程序，使用`RecipeBookService`类将配方持久化到数据库中，这将隐藏数据存储和检索的复杂性，使其用户难以察觉。
- en: Getting ready
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: The ingredients of this recipe include the Apache Karaf distribution kit, access
    to JDK, and Internet connectivity. The sample code for this recipe is available
    at [https://github.com/jgoodyear/ApacheKarafCookbook/tree/master/chapter8/chapter8-recipe1](https://github.com/jgoodyear/ApacheKarafCookbook/tree/master/chapter8/chapter8-recipe1).
    Remember, you need both the drivers installed and Apache Cassandra running for
    these recipes to work!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方的成分包括Apache Karaf发行套件、对JDK的访问和互联网连接。这个配方的示例代码可在[https://github.com/jgoodyear/ApacheKarafCookbook/tree/master/chapter8/chapter8-recipe1](https://github.com/jgoodyear/ApacheKarafCookbook/tree/master/chapter8/chapter8-recipe1)找到。记住，为了使这些配方工作，你需要安装驱动程序并确保Apache
    Cassandra正在运行！
- en: How to do it…
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点……
- en: 'Building a project with a JPA persistence layer will require the following
    eight steps:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用JPA持久化层构建项目需要以下八个步骤：
- en: The first step is generating a Maven-based bundle project. Create an empty Maven-based
    project. A `pom.xml` file containing the essential Maven coordinate information
    and bundle packaging directives will suffice.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是生成一个基于Maven的捆绑项目。创建一个空的基于Maven的项目。一个包含基本Maven坐标信息和捆绑打包指令的`pom.xml`文件就足够了。
- en: 'The next step is adding dependencies to the POM file. This is shown in the
    following code:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是向POM文件中添加依赖项。这在上面的代码中显示：
- en: '[PRE8]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: For Karaf 3.0.0, we use the OSGi Version 5.0.0\. The Cassandra driver only depends
    on three external projects. We are in luck as all of these are available as bundles—there
    isn't going to be much difficulty in deploying this in any version of Karaf. The
    majority of our dependencies are now related to our commands.
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于Karaf 3.0.0，我们使用OSGi版本5.0.0。Cassandra驱动程序只依赖于三个外部项目。我们很幸运，所有这些都可以作为捆绑包提供——在Karaf的任何版本中部署都不会有很大困难。我们的大多数依赖现在都与我们的命令相关。
- en: 'The next step is adding build plugins. Our recipe requires only one build plugin
    to be configured, which is the bundle plugin. We configure the `maven-bundle-plugin`
    to assemble our project code into an OSGi bundle. We add the following plugin
    configuration to our POM file:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是添加构建插件。我们的配方只需要配置一个构建插件，即捆绑插件。我们配置`maven-bundle-plugin`将我们的项目代码组装成一个OSGi捆绑包。我们将以下插件配置添加到我们的POM文件中：
- en: '[PRE9]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The Felix and Karaf imports are required by the optional Karaf commands.
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Felix和Karaf的导入是可选的Karaf命令所必需的。
- en: Once again, compared to the JPA project, we have less complexity in the `pom.xml`
    file as we are relying on fewer external resources. We only make sure that we
    have the correct Karaf and Felix imports to activate our commands.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 再次强调，与JPA项目相比，在`pom.xml`文件中我们的复杂性更少，因为我们依赖于更少的外部资源。我们只需确保我们有了正确的Karaf和Felix导入以激活我们的命令。
- en: 'The next step is creating a Blueprint descriptor file. Create the directory
    tree as `src/main/resources/OSGI-INF` in your project. Then, create a file named
    `blueprint.xml` in this folder. Consider the following code:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是创建一个Blueprint描述符文件。在你的项目中创建目录树`src/main/resources/OSGI-INF`。然后，在这个文件夹中创建一个名为`blueprint.xml`的文件。考虑以下代码：
- en: '[PRE10]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In the preceding Blueprint structure, we ended up removing the transaction manager.
    Remember, Cassandra doesn't work in the same way as a traditional relational database.
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的Blueprint结构中，我们最终移除了事务管理器。记住，Cassandra的工作方式与传统的关系型数据库不同。
- en: 'The next step is developing an OSGi service with a new Cassandra backend. We''ve
    created the basic project structure and plumbed in configurations for Blueprint
    descriptors. Now, we''ll focus on the underlying Java code of our Cassandra-backed
    application. We break down this process into three steps: defining a service interface,
    implementing the service DAO, and implementing a very simple class that we will
    use as an entity.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是开发一个带有新Cassandra后端的OSGi服务。我们已经创建了基本的项目结构，并配置了Blueprint描述符的配置。现在，我们将专注于我们Cassandra支持应用程序的底层Java代码。我们将这个过程分解为三个步骤：定义服务接口、实现服务DAO以及实现一个非常简单的类，我们将将其用作实体。
- en: In this recipe, we will be using the raw CQL driver in a more extensive project.
    It is highly likely that something like a DataMapper or another ORM-like solution
    will be of benefit. A higher level library will help hide type conversion between
    Cassandra and Java, manage relations, and help generalize data access.
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将在一个更广泛的项目中使用原始的CQL驱动程序。很可能像DataMapper或另一个ORM-like解决方案将会有所帮助。一个更高层次的库将有助于隐藏Cassandra和Java之间的类型转换，管理关系，并帮助通用数据访问。
- en: 'The following is a brief list of CQL-friendly libraries to use as a starting
    point:'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是一个简短的CQL-friendly库列表，作为起点：
- en: '**Astyanax**: This is available at [https://github.com/Netflix/astyanax](https://github.com/Netflix/astyanax)'
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Astyanax**：可在[https://github.com/Netflix/astyanax](https://github.com/Netflix/astyanax)找到'
- en: '**Spring data-cassandra**: This is available at [http://projects.spring.io/spring-data-cassandra/](http://projects.spring.io/spring-data-cassandra/)'
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spring data-cassandra**：可在[http://projects.spring.io/spring-data-cassandra/](http://projects.spring.io/spring-data-cassandra/)找到'
- en: '**Hecate**: This is available at [https://github.com/savoirtech/hecate](https://github.com/savoirtech/hecate)'
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hecate**：可在[https://github.com/savoirtech/hecate](https://github.com/savoirtech/hecate)找到'
- en: 'The first step is defining a service interface. The service interface will
    define the user API to our project. In our sample code, we implement the `RecipeBookService`
    class, which provides the methods required to interact with a collection of recipes.
    Consider the following code:'
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是定义服务接口。服务接口将定义我们的项目对用户的API。在我们的示例代码中，我们实现了`RecipeBookService`类，它提供了与一系列菜谱交互所需的方法。考虑以下代码：
- en: '[PRE11]'
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The interface's implementation follows standard Java conventions, requiring
    no special OSGi packages.
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接口的实现遵循标准的Java约定，不需要特殊的OSGi包。
- en: 'The next step is implementing the service DAO. Now that we have defined our
    service interface, we''ll provide an implementation as a DAO. By using Cassandra,
    we don''t necessarily need to follow a DAO pattern, although this isn''t a bad
    idea, as this will make refactoring existing JPA code fairly simple and approachable.
    We use the same interface and accommodate the implementation to work with the
    Cassandra CQL syntax instead. Consider the following code:'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是实现服务DAO。现在我们已经定义了服务接口，我们将提供一个作为DAO的实现。虽然使用Cassandra不一定需要遵循DAO模式，但这并不是一个坏主意，因为这将使重构现有的JPA代码变得相对简单和可行。我们使用相同的接口，并调整实现以与Cassandra
    CQL语法一起工作。考虑以下代码：
- en: '[PRE12]'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Our Cassandra class is now pretty much self-contained. On startup, we print
    out some information about where we are connected and which rack and datacenter
    our cluster node exists in.
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们现在拥有的Cassandra类几乎是自包含的。在启动时，我们打印出一些关于我们连接的位置以及我们的集群节点所在的机架和数据中心的信息。
- en: 'The next step is implementing entities. These entities in the Cassandra case
    are just plain old POJO classes. They no longer contain persistence information.
    We utilize them to conform to the existing API and ensure that we hide the underlying
    Cassandra implementation from the end user. Consider the following code:'
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是实现实体。在Cassandra的情况下，这些实体只是普通的POJO类。它们不再包含持久化信息。我们利用它们来符合现有的API，并确保我们隐藏底层的Cassandra实现对最终用户。考虑以下代码：
- en: '[PRE13]'
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This class is now just a plain old POJO class that we use to transport data
    in accordance with the already established API. For more complex mapping and ORM-like
    structure, there are several DataMappers that are built on top of the existing
    Cassandra data drivers. As they are not standardized as JPA, recommending one
    in particular isn't as easy. They all have their little quirks.
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个类现在只是一个普通的POJO类，我们用它来根据已经建立的API传输数据。对于更复杂的映射和ORM-like结构，有几个DataMappers是基于现有的Cassandra数据驱动程序构建的。由于它们没有像JPA那样标准化，因此推荐其中一个并不容易。它们都有自己的小怪癖。
- en: The next step is the optional creation of Karaf commands to directly test the
    persistence service. To simplify manual testing of our `recipeBookService` instance,
    we can create a set of custom Karaf commands, which will invoke our Cassandra
    storage and retrieval operations. The sample implementations of these optional
    commands are available in the book's code bundle. Of particular interest is how
    they obtain a reference to the `recipeBookService` instance and make calls to
    the service.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是可选的创建Karaf命令以直接测试持久化服务。为了简化对`recipeBookService`实例的手动测试，我们可以创建一组自定义Karaf命令，这些命令将调用我们的Cassandra存储和检索操作。这些可选命令的示例实现可在本书的代码包中找到。特别值得注意的是它们如何获取`recipeBookService`实例的引用并调用服务。
- en: 'Now, we must wire the command implementation into Karaf via Blueprint as shown
    in the following code:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们必须通过Blueprint将命令实现连接到Karaf，如下面的代码所示：
- en: '[PRE14]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Each of our custom commands implementation classes are wired to our `recipeBookService`
    instance.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们每个自定义命令的实现类都连接到我们的`recipeBookService`实例。
- en: 'The next step is deploying the project into Karaf. We install our project bundle
    by executing the `install` command on its Maven coordinates as follows:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是将项目部署到Karaf。我们通过在其Maven坐标上执行`install`命令来安装我们的项目包，如下所示：
- en: '[PRE15]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: This demo will require a running instance of Cassandra!
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个演示需要一个正在运行的Cassandra实例！
- en: 'The final step is testing the project. As soon as the bundle is deployed, you''ll
    see some startup information; it''ll be something like the following:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一步是测试项目。一旦部署了包，你将看到一些启动信息；它可能如下所示：
- en: '[PRE16]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Consider the following commands:'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 考虑以下命令：
- en: '[PRE17]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: When you run the preceding commands, you'll have the stored recipe displayed
    on the console as output!
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当你运行前面的命令时，你将在控制台输出中看到存储的配方！
- en: How it works…
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Our persistence layer works with the official Apache Cassandra driver in a Karaf
    container. Providing access to Cassandra is quite simple; we only need to look
    at one external project and make sure that we have two dependencies and that we
    can connect to an existing Cassandra cluster. The key to using Cassandra lies
    more in data modeling, structuring of clusters, amount of read/writes, and the
    size of clusters and participating nodes and their usage and storage patterns.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据持久层与官方Apache Cassandra驱动在Karaf容器中一起工作。提供对Cassandra的访问相当简单；我们只需要查看一个外部项目，并确保我们有两个依赖项，并且可以连接到现有的Cassandra集群。使用Cassandra的关键更多在于数据建模、集群的结构化、读写次数、集群的大小以及参与节点及其使用和存储模式。
- en: The data driver we connect with will provide us with cluster awareness, failover,
    and high availability as well as the features necessary to control replication
    factors and cluster behavior of our data. The official Cassandra documentation
    can be found at [http://cassandra.apache.org/](http://cassandra.apache.org/).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们连接的数据驱动将为我们提供集群意识、故障转移和高可用性，以及控制数据复制因子和集群行为所需的功能。官方Cassandra文档可以在[http://cassandra.apache.org/](http://cassandra.apache.org/)找到。
- en: An extremely useful resource to get the historical context of the evolution
    of Cassandra can be found at [http://www.datastax.com/documentation/articles/cassandra/cassandrathenandnow.html](http://www.datastax.com/documentation/articles/cassandra/cassandrathenandnow.html).
    This will show and explain why things have changed, how CQL came about, and why
    certain designs were chosen.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取Cassandra演变的历史背景，一个非常有用的资源可以在[http://www.datastax.com/documentation/articles/cassandra/cassandrathenandnow.html](http://www.datastax.com/documentation/articles/cassandra/cassandrathenandnow.html)找到。这将展示并解释为什么事情会改变，CQL是如何产生的，以及为什么选择了某些设计。
