- en: Chapter 8. Providing a Big Data Integration Layer with Apache Cassandra
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Installing Cassandra client bundles in Apache Karaf
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modeling data with Apache Cassandra
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a project with a persistence layer for deployment in Karaf
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As illustrated in the previous chapters, persistence is a large part of most
    deployments and applications. So far, we've focused on relational databases. Let's
    start off with some history.
  prefs: []
  type: TYPE_NORMAL
- en: In 1970, IBM published a paper named *A Relational Model of Data for Large Shared
    Data Banks*. This paper became the foundation for RDBMS and modern relational
    databases in that it described joins and relationships between entities. From
    this work, followed SQL (1986), ACID (Atomic, Consistent, Isolated, and Durable),
    schema design, and sharding for scalability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s fast forward to the advent of social networks; a term called **WebScale**
    was coined based on Reed''s law that states:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"The utility of large networks, particularly social networks, can scale exponentially
    with the size of the network."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Does this mean that RDBMS cannot be scaled? No, but it led to the development
    of NoSQL. NoSQL is usually based on the following definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: It was originally coined by Carlo Strozzi who developed the Strozzi NoSQL database
    in 1998
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It typically has the key/value style of storage in columns/tables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is generally schema-less, or each row can contain a different structure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It does not require SQL as a language; thus the name *NoSQL*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many support BASE consistency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most are distributed and fault-tolerant in nature
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Cassandra was originally developed at Facebook, then released as open
    source in 2008, incubated at Apache in 2009, and became a top-level Apache project
    in 2010\. Through rapid adaptation and features desirable in many use cases, Apache
    Cassandra has rapidly gained traction and wide distribution. Today's versions
    of Cassandra have a slightly stricter schema orientation with the introduction
    of **Cassandra Query Language** (**CQL**), a way of helping to drive transition
    from traditional RDBMS models to a more unstructured key/value pair storage model
    while retaining a structure and data model familiar to users in general. For an
    annotated history of the transition of Apache Cassandra, see [http://www.datastax.com/documentation/articles/cassandra/cassandrathenandnow.html](http://www.datastax.com/documentation/articles/cassandra/cassandrathenandnow.html).
  prefs: []
  type: TYPE_NORMAL
- en: CQL is the default and primary interface into the Cassandra DBMS. Using CQL
    is similar to using SQL. CQL and SQL share the same abstract idea of a table constructed
    of columns and rows. The main difference is that Cassandra does not support joins
    or subqueries, except for batch analysis through Apache Hive. Instead, Cassandra
    emphasizes denormalization through CQL features like collections and clustering
    specified at the schema level.
  prefs: []
  type: TYPE_NORMAL
- en: What this basically means is that there are other client APIs—they are, as of
    Cassandra release 2.x, actively discouraged from use by the Cassandra community.
    A healthy debate over the usage of schema modeling versus column family is still
    quite active on mailing lists and in user communities.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Cassandra client bundles in Apache Karaf
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we begin to explore how to build Cassandra-backed applications, we must
    first install all the required client modules into the Karaf container.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The official *GettingStarted* document from the Cassandra community can be found
    at [http://wiki.apache.org/cassandra/GettingStarted](http://wiki.apache.org/cassandra/GettingStarted).
  prefs: []
  type: TYPE_NORMAL
- en: 'The ingredients of this recipe include the Apache Karaf distribution kit, access
    to JDK, and Internet connectivity. We also assume that an Apache Cassandra database
    is downloaded and installed. Apache Cassandra can be downloaded and installed
    as RPMs, Debian `.deb` packages, or `.tar` archives. In a binary `.tar` archive,
    you''ll have to open and change two configuration files: the `cassandra.yaml`
    and the `log4-server.properties` files of the `conf` folder. The changes pertain
    to where you store data, which is by default in the `/var/lib/cassandra/*` folder
    for the data backend and in the `/var/log/cassandra/*` folder for the system log.
    Once these changes are done, you can start Cassandra using the `bin/cassandra
    –F` command.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cassandra's drivers aren't part of the standard Karaf feature library; so, we
    either have to write our own feature or manually install the necessary bundles
    for the client to run.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the following commands to install Apache Cassandra''s driver and supplemental
    bundles into Karaf:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We can verify the installation by executing the `list -t 0 | grep -i cass` command,
    which will list the DataStax driver bundle.
  prefs: []
  type: TYPE_NORMAL
- en: With this, we have access to the Cassandra driver from our own bundles.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling data with Apache Cassandra
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we start writing a bundle using Apache Cassandra, let's look a little
    at how we model data in Cassandra using CQL 3.x.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's define a very simple schema, and as we are using CQL, Cassandra isn't
    schema-less from a client perspective even if the data storage internally works
    slightly differently.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can reuse the `RecipeService` class from the previous chapter. We will just
    modify it slightly for our Cassandra integration. The original entity (and by
    virtue of using JPA) provides a basic table definition, which is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'So, we have two fields in this table: an ID field named `title` and a data
    field we call `ingredients` for consistency and simplicity.'
  prefs: []
  type: TYPE_NORMAL
- en: First, we need a place to store this. Cassandra partitions data in keyspaces
    at the top level. Think of a keyspace as a map containing tables and their rules.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ll need to perform the following two steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is starting the Cassandra client. The basic creation command
    in Cassandra''s client, `cqlsh`, is shown as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The next step is creating our data store. Now that we have started the interactive
    client session, we can create a keyspace as shown in the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The previous command-line prompt returns no response indicating that we have
    successfully created a new keyspace where we can store data. To use this keyspace,
    we need to tell Cassandra that this is where we'll be working right now.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: We rely on SimpleStrategy as we only have one Cassandra node, we don't have
    a real cluster defined, nor do we have multiple data centers. If this was the
    case, we could change the strategy class for replication. We also set the `replication_factor`
    value to `1`; this can be set to more replicas and certainly should be done in
    security-related contexts where you, for instance, store account information.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To switch the keyspace, we issue a `USE` command as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The preceding command prompt indicates that we are in the `karaf_demo` keyspace.
    Consider the following command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As the preceding command indicates, we have nothing defined schema-wise in
    this keyspace, and so we need to define a table. This can be done as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We now have a defined table and the columns in this table are defined as the
    storage type `text` and the primary key and retrieval token as the `title`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is beyond the scope of this book to explore the under-the-hood functioning
    of Apache Cassandra. However, you can examine its source code at [http://git-wip-us.apache.org/repos/asf/cassandra.git](http://git-wip-us.apache.org/repos/asf/cassandra.git).
  prefs: []
  type: TYPE_NORMAL
- en: 'In terms of our data store, we can let Cassandra describe exactly what is being
    stored. Consider the following command-line snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, there are quite a few options you, as a data modeler, can work
    with. These will affect replication, caching, lifetime, compression, and several
    other factors.
  prefs: []
  type: TYPE_NORMAL
- en: Building a project with a persistence layer for deployment in Karaf
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Application developers often need to make use of a persistence layer in their
    projects; one of the preferred methodologies to perform this in Karaf is to make
    use of the Java Persistence API. As we are building on the existing JPA project,
    we will try and set up a new service layer and reuse (copy) the same project model
    while moving over the storage backend to Apache Cassandra. This is not a complete
    refactoring nor a reuse of code. Technically, we could have moved the API parts
    from [Chapter 7](ch07.html "Chapter 7. Providing a Persistence Layer with Apache
    Aries and OpenJPA"), *Providing a Persistence Layer with Apache Aries and OpenJPA*,
    into a new module and then refactored the chapter to have the Cassandra-related
    dependencies and a slightly different set of imports. This isn't really in the
    scope of a Cookbook, hence the copied structure.
  prefs: []
  type: TYPE_NORMAL
- en: In the *Installing Cassandra client bundles in Apache Karaf* recipe, we learned
    how to install the necessary JAR files into Karaf. Continuing with this recipe,
    we'll make use of the drivers to build a simple application that persists recipes
    to a database using the `RecipeBookService` class, which will hide the complexities
    of data storage and retrieval from its users.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The ingredients of this recipe include the Apache Karaf distribution kit, access
    to JDK, and Internet connectivity. The sample code for this recipe is available
    at [https://github.com/jgoodyear/ApacheKarafCookbook/tree/master/chapter8/chapter8-recipe1](https://github.com/jgoodyear/ApacheKarafCookbook/tree/master/chapter8/chapter8-recipe1).
    Remember, you need both the drivers installed and Apache Cassandra running for
    these recipes to work!
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Building a project with a JPA persistence layer will require the following
    eight steps:'
  prefs: []
  type: TYPE_NORMAL
- en: The first step is generating a Maven-based bundle project. Create an empty Maven-based
    project. A `pom.xml` file containing the essential Maven coordinate information
    and bundle packaging directives will suffice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The next step is adding dependencies to the POM file. This is shown in the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: For Karaf 3.0.0, we use the OSGi Version 5.0.0\. The Cassandra driver only depends
    on three external projects. We are in luck as all of these are available as bundles—there
    isn't going to be much difficulty in deploying this in any version of Karaf. The
    majority of our dependencies are now related to our commands.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The next step is adding build plugins. Our recipe requires only one build plugin
    to be configured, which is the bundle plugin. We configure the `maven-bundle-plugin`
    to assemble our project code into an OSGi bundle. We add the following plugin
    configuration to our POM file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The Felix and Karaf imports are required by the optional Karaf commands.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once again, compared to the JPA project, we have less complexity in the `pom.xml`
    file as we are relying on fewer external resources. We only make sure that we
    have the correct Karaf and Felix imports to activate our commands.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The next step is creating a Blueprint descriptor file. Create the directory
    tree as `src/main/resources/OSGI-INF` in your project. Then, create a file named
    `blueprint.xml` in this folder. Consider the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding Blueprint structure, we ended up removing the transaction manager.
    Remember, Cassandra doesn't work in the same way as a traditional relational database.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The next step is developing an OSGi service with a new Cassandra backend. We''ve
    created the basic project structure and plumbed in configurations for Blueprint
    descriptors. Now, we''ll focus on the underlying Java code of our Cassandra-backed
    application. We break down this process into three steps: defining a service interface,
    implementing the service DAO, and implementing a very simple class that we will
    use as an entity.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this recipe, we will be using the raw CQL driver in a more extensive project.
    It is highly likely that something like a DataMapper or another ORM-like solution
    will be of benefit. A higher level library will help hide type conversion between
    Cassandra and Java, manage relations, and help generalize data access.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following is a brief list of CQL-friendly libraries to use as a starting
    point:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Astyanax**: This is available at [https://github.com/Netflix/astyanax](https://github.com/Netflix/astyanax)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spring data-cassandra**: This is available at [http://projects.spring.io/spring-data-cassandra/](http://projects.spring.io/spring-data-cassandra/)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hecate**: This is available at [https://github.com/savoirtech/hecate](https://github.com/savoirtech/hecate)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first step is defining a service interface. The service interface will
    define the user API to our project. In our sample code, we implement the `RecipeBookService`
    class, which provides the methods required to interact with a collection of recipes.
    Consider the following code:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: The interface's implementation follows standard Java conventions, requiring
    no special OSGi packages.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The next step is implementing the service DAO. Now that we have defined our
    service interface, we''ll provide an implementation as a DAO. By using Cassandra,
    we don''t necessarily need to follow a DAO pattern, although this isn''t a bad
    idea, as this will make refactoring existing JPA code fairly simple and approachable.
    We use the same interface and accommodate the implementation to work with the
    Cassandra CQL syntax instead. Consider the following code:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: Our Cassandra class is now pretty much self-contained. On startup, we print
    out some information about where we are connected and which rack and datacenter
    our cluster node exists in.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The next step is implementing entities. These entities in the Cassandra case
    are just plain old POJO classes. They no longer contain persistence information.
    We utilize them to conform to the existing API and ensure that we hide the underlying
    Cassandra implementation from the end user. Consider the following code:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: This class is now just a plain old POJO class that we use to transport data
    in accordance with the already established API. For more complex mapping and ORM-like
    structure, there are several DataMappers that are built on top of the existing
    Cassandra data drivers. As they are not standardized as JPA, recommending one
    in particular isn't as easy. They all have their little quirks.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: The next step is the optional creation of Karaf commands to directly test the
    persistence service. To simplify manual testing of our `recipeBookService` instance,
    we can create a set of custom Karaf commands, which will invoke our Cassandra
    storage and retrieval operations. The sample implementations of these optional
    commands are available in the book's code bundle. Of particular interest is how
    they obtain a reference to the `recipeBookService` instance and make calls to
    the service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, we must wire the command implementation into Karaf via Blueprint as shown
    in the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Each of our custom commands implementation classes are wired to our `recipeBookService`
    instance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The next step is deploying the project into Karaf. We install our project bundle
    by executing the `install` command on its Maven coordinates as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: This demo will require a running instance of Cassandra!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The final step is testing the project. As soon as the bundle is deployed, you''ll
    see some startup information; it''ll be something like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Consider the following commands:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: When you run the preceding commands, you'll have the stored recipe displayed
    on the console as output!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our persistence layer works with the official Apache Cassandra driver in a Karaf
    container. Providing access to Cassandra is quite simple; we only need to look
    at one external project and make sure that we have two dependencies and that we
    can connect to an existing Cassandra cluster. The key to using Cassandra lies
    more in data modeling, structuring of clusters, amount of read/writes, and the
    size of clusters and participating nodes and their usage and storage patterns.
  prefs: []
  type: TYPE_NORMAL
- en: The data driver we connect with will provide us with cluster awareness, failover,
    and high availability as well as the features necessary to control replication
    factors and cluster behavior of our data. The official Cassandra documentation
    can be found at [http://cassandra.apache.org/](http://cassandra.apache.org/).
  prefs: []
  type: TYPE_NORMAL
- en: An extremely useful resource to get the historical context of the evolution
    of Cassandra can be found at [http://www.datastax.com/documentation/articles/cassandra/cassandrathenandnow.html](http://www.datastax.com/documentation/articles/cassandra/cassandrathenandnow.html).
    This will show and explain why things have changed, how CQL came about, and why
    certain designs were chosen.
  prefs: []
  type: TYPE_NORMAL
