<html><head></head><body>
      
      <section>
         
         
         <header>
            
            <h1 class="header-title">Scale Up – Threading and Implications</h1>
            
         </header>
         
         
         <article>
            
            
            <p class="mce-root">Scalability has always been a concern for Java and, thus, a thread-related API was
               introduced in Java version 1.0. The idea is to be able to benefit from the most modern
               hardware updates in order to parallelize the processing of applications.
            </p>
            
            <p>Being able to handle multiple requests in parallel is crucial for a Java EE server
               to scale, but in our modern Java world, you also need to be able to control your own
               threads. Also, Java EE introduced the required API to do it in good conditions.
            </p>
            
            <p>In this chapter, we will go through the following topics:</p>
            
            <ul>
               
               <li>Java EE threading model</li>
               
               <li>Data consistency across threads</li>
               
               <li>Java EE hidden thread usages</li>
               
               <li>How to integrate reactive programming with the Java EE programming model</li>
               
            </ul>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">Java EE threading model</h1>
            
         </header>
         
         
         <article>
            
            
            <p>The Java EE philosophy has, for a long time, been able to give its users a well-defined
               and safe programming model. This is why most of the Java EE defaults are about being
               thread-safe, and that several specifications such as <strong>Enterprise Java Beans</strong> (<strong>EJB</strong>) defaults were preventing custom thread usage. It does not mean Java EE was ignoring
               threads at all, but explicitly using thread pools from an application was not very
               natural. Also, most of the time, the adopted coding style was either against Java
               EE's (strict) rules or were very verbose.
            </p>
            
            <p>Before detailing the new API added by Java EE to help you develop concurrent applications,
               let's see the basic Java EE model and how it can already help you to scale.
            </p>
            
            <p>If we take back the specifications included in Java EE 8 (full profile), we'll get
               a long list. Now, if we check which specifications use threads, the list will be shorter
               and we can find some common points among them. Here is a table trying to represent
               whether the specifications manage dedicated threads or not and whether they explicitly
               interact with threads (handling cross-thread calls by using the provided threads)
               or simply use the caller (contextual) thread:
            </p>
            
            <table>
               
               <tbody>
                  
                  <tr>
                     
                     <td><strong>Specification</strong></td>
                     
                     <td><strong>Manage dedicated threads</strong></td>
                     
                     <td><strong>Interacts with threads</strong></td>
                     
                     <td><strong>Comment</strong></td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>EJB 3.2</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p><kbd>@Asynchronous</kbd> allows you to execute tasks in a dedicated thread pool. <kbd>@Lock</kbd> used with <kbd>@Singleton</kbd> allows you to control the thread safety of the bean.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>Servlet 4.0</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Every request is executed in a single thread provided by the container by default.
                           When using <kbd>AsyncContext</kbd>, you can execute the task in a custom thread and resume the request from another
                           thread later.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>JSP 2.3/JSP Debugging 1.0</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Inherits from the servlet model.</p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>EL 3.0</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Uses the caller context.</p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>JMS 2.0</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>By itself, JMS can be seen as a specific sort of connector (as in <em>Connector 1.7</em>) but put a few specific words on this case. JMS has two sorts of usages: on the server
                           side and on the client side. The server side is generally a network server expecting
                           connection. This is where dedicated threads will be used (such as any socket server).
                           Then, the processing will be fully delegated to the connector. On the client side,
                           it generally inherits from the caller context but also uses custom threads, as it
                           is asynchronous by design. So, it needs its own thread pools to handle this part of
                           the JMS specification.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>JTA 1.2</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>JTA doesn't manage threads but <em>binds</em> its context to threads. Concretely, when a transaction starts, it is only valid for
                           the initial thread.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>JavaMail 1.6</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>JavaMail being the link between your Java code and the way mails are sent/received,
                           the implementation is, here again, linked to a socket, and thus, it often relies on
                           dedicated threads.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>Connector 1.7</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Connector specification is the standard way to interact with external systems (bi-directional
                           ways even if connector implementations often handle only one way). However, it generally
                           uses dedicated threads in two layers, the first one being related to the network interactions
                           and the second one being related to the container interaction that generally goes
                           through <kbd>WorkManager</kbd>, which is the ancestor of the <span><em>Concurrency Utilities for Java EE</em> specification. Like JTA, it also uses context-related information that is often bound
                              to the thread. Finally, since it interacts with the JTA, a part of the interactions
                              is, by design, bound to threads.</span></p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>Web Services 1.4 / <span>JAX-RPC 1.1</span></p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Web services generally just inherit from the servlet contextual threading model.</p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>JAX-RS 2.1</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p class="mce-root">JAX-RS inherits from the servlet contextual model, but since JAX-RS 2.0, the server
                           can asynchronously handle the requests, thanks to Servlet 3.0 <kbd>AsyncContext</kbd>. In this case, the developer must notify the container when a request is completed
                           and interacts with threads, as it is generally done from a different thread from the
                           servlet one.
                        </p>
                        
                        <p>On the client side, JAX-RS 2.1 now has a reactive API, able to use custom threads
                           to do the execution.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>WebSocket 1.1</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes/No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes/No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Normally, the WebSocket specification was designed to be implemented on top of the
                           servlet specification, which is really the Java EE central transport. However, for
                           several cases, it may be needed to use some customization of the threading for WebSocket
                           needs (long connections). This part highly depends on the container. The last thing
                           is that some custom WebSocket threads may be needed to handle connection evictions
                           and things like that, but it has less impact on the end user and performance.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>JSON-P 1.1 / JSON-B 1.0</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>This specification (JSON low-level API and JSON binding) does not have any thread-related
                           operations and simply executes in the caller context.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>Concurrency Utilities for Java EE 1.0</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Concurrency utilities mainly have the ability to define <em>Java EE thread pools</em> and, indeed, they manage custom threads. It also transparently facilitates (through <kbd>ContextService</kbd>) the propagation of some contexts, such as security, JNDI context, transaction, and
                           so on. Note that, however, the propagation is not standard and you may need to check
                           out your server documentation to know what it does precisely.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>Batch 1.0</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>JBatch is asynchronous by design. When you launch a batch, the invocation returns
                           before the batch is done, as it can be very long. To handle such behavior JBatch has
                           its own thread pools.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>JAXR 1.0</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>This specification is rarely used and has become old (before Java introduced nio).
                           Being a client, it doesn't use custom threads.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>Java EE Management 1.1 (or 1.2)</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes/No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>This specifications allows you to interact with the server and its definitions (resources
                           and applications). It uses another transport technology, so it generally needs dedicated
                           threads.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>JACC 1.5</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>This is a specification linking an authorization policy with the Java EE container.
                           It is contextually executed.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>JASPIC 1.1</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>This is a security specification, also contextually executed.</p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>Java EE Security API 1.0</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>This is the last security API of Java EE, making it pretty usable, but it stays contextual
                           to the caller.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>JSTL 1.2</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Inherits from the servlet model.</p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>Web Service Metadata 2.1</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>This mainly involves annotations for web services, so there's  no particular threading
                           model.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>JSF 2.3</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Inherits from the servlet threading model (<span>this is a simplification but good enough for this book's context).</span></p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>Common annotations 1.3</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Just a set of APIs reused by other specifications, no particular behavior directly
                           bound here.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>Java Persistence 2.2 (JPA)</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Inherits from the caller context.</p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>Bean Validation 2.0</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p><span>Inherits from the caller context.</span></p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>Interceptors 1.2</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p><span>Inherits from the caller context.</span></p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>Contexts and Dependency Injection for Java EE 2.0 (CDI)</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>Yes</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>CDI 2.0 supports asynchronous events, which rely on a dedicated thread pool. CDI being
                           about <em>contexts</em>, also binds contextual data to threads such as the <kbd>@RequestScoped</kbd> context.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>
                        
                        <p>Dependency Injection for Java 1.0 (@Inject)</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>No</p>
                        
                     </td>
                     
                     <td>
                        
                        <p>This is mainly a set of annotations of CDI, so there's no real thread-related behavior
                           here.
                        </p>
                        
                     </td>
                     
                  </tr>
                  
               </tbody>
               
            </table>
            
            <p>If we review all the thread usages, we can distinguish between some categories:</p>
            
            <ul>
               
               <li>Asynchronous usages: the specification using threads not to block the caller execution
                  (such as JAX-RS client, Batch API, CDI asynchronous events, and so on)
               </li>
               
               <li>Network-related implementations that need threads for the selector (partly accepting
                  the connections) and request handling
               </li>
               
            </ul>
            
            <p>In terms of code context, this is generally related to the outbound layers of the
               code. Indeed, the network is an outbound of the application, but asynchronous usages
               are also in the sense that they split the execution into two branches: the caller
               context that continues and a new branch that is no more linked to the caller.
            </p>
            
            <p>What does it mean for you? When you take the lead on an application, at least from
               a performance or configuration point of view, you need to be clear about the thread
               execution path of the application (when the application uses a different thread from
               the one it got affected by, when the request entered into the system). This is also
               true for inter-system architectures, such as microservices, where you need to track
               the execution context breakdowns.
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">Thread data and consistency</h1>
            
         </header>
         
         
         <article>
            
            
            <p>Before getting Java EE-specific, it is important to step back a moment and understand
               the implications of concurrency on the programming model.
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">Concurrent data access</h1>
            
         </header>
         
         
         <article>
            
            
            <p>When a single thread accesses data, then the access is always thread-safe, and it
               is not possible for a thread to mutate data while another one is reading it. When
               you increase the number of threads and multiple threads can access the same data structure
               instances, it is possible for a thread to read the data that's currently being modified,
               or for two concurrent modifications to happen, leading to an inconsistent result.
            </p>
            
            <p>Here is a schema representing this issue with two threads. Keep in mind that a Java
               EE server often handles  around 100 to 1000 threads, so the effects are more impacting:
            </p>
            
            <div class="CDPAlignCenter CDPAlign"><img height="250" src="assets/68e59b4f-1bb0-4fab-8e82-d359d7e6bb26.png" width="222"/></div>
            
            <p>In this simple example, we have a thread (<strong>Thread 1</strong>) setting data that is supposed to be a complex structure. In parallel, we have another
               thread (<strong>Thread 2</strong>) accessing the data. In the  preceding diagram, the very thin black line represents
               the thread life, whereas the bold black line represents the method execution in the
               thread's context. The blue box represents the data setter/getter execution time and
               the red zone represents the overlap of both threads on the data usage. In other words,
               you can consider that the vertical unit is time.
            </p>
            
            <p>To understand what can be the impact of such a code without any protection, let's
               materialize the data structure with this simple code:
            </p>
            <pre>public class UnsafeData {<br/>    private boolean initialized = false;<br/>    private String content;<br/><br/>    public void setData(String value) {<br/>        content = value;<br/>        initialized = true;<br/>    }<br/><br/>    public String getData() {<br/>        if (!initialized) {<br/>            throw new IllegalStateException("structure not initialized");<br/>        }<br/>        return content;<br/>    }<br/>}</pre>
            <p>This simple structure aims to store a <kbd>String</kbd> value and handle a state (<kbd>initialized</kbd>), which allows the structure to prevent access to the data if uninitialized.
            </p>
            
            <p>If we apply this structure on our previous picture timeline, it is possible that <strong>Thread 2</strong> calls <kbd>getData</kbd> and fails with <kbd>IllegalStateException</kbd>, whereas the <kbd>setData</kbd> method is called and sets the <kbd>initialized</kbd> variable. In other words, the structure (<kbd>getData</kbd>) was accessed while it was changing and, thus, the behavior was not consistent with
               the complete state of the data. In this case, the error is not dramatic, but if you
               take another example summing some values, you will just get the wrong data:
            </p>
            <pre>public class Account {<br/>    private double value; // + getter<br/><br/>    public void sum(double credit, double debit) {<br/>       value += credit;<br/>       value += debit;<br/>    }<br/>}</pre>
            <p>If the execution of <kbd>sum</kbd> is done and <kbd>value</kbd> is accessed at the same time, then the account value will be wrong, the reporting
               will potentially be inconsistent, and the validation (which likely considers <em>credit+debit=0</em>) will fail, making this account erroneous.
            </p>
            
            <p>If you look one step further and integrate some EE features, you will quickly understand
               that the situation is even worse. Let's take the case of a JPA entity, such as <kbd>Quote</kbd>, and assume that two threads are differently modifying the entity: one thread modifies
               the price and the other one modifies the name. What will happen when each thread updates
               the entity? The database can't handle both the updates at the same time, so if there
               is no failure, then the last update will win and only one of the two updates will
               be taken into account.
            </p>
            
            <div class="packt_tip">JPA provides optimistic and pessimistic locking to properly solve the aforementioned
               problem. As a general rule, try to use optimistic locking until you really need pessimistic
               locking. In fact, it will give you a better performance even if it will require you
               to potentially handle a retry logic if relevant.
            </div>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">Java and thread safety</h1>
            
         </header>
         
         
         <article>
            
            
            <p class="mce-root">This section doesn't intend to explain all the solutions that Java provides to ensure
               the thread safety of your code but just to give you some highlights on Java Standalone
               API, you can reuse in Java EE application if needed.
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">Synchronized</h1>
            
         </header>
         
         
         <article>
            
            
            <p>Surely the oldest solution, but still available in Java, the <kbd>synchronized</kbd> keyword allows you to ensure that methods are not concurrently executed. You just
               need to add it in your method definition as follows:
            </p>
            <pre>public class SafeData {<br/>    private boolean initialized = false;<br/>    private String content;<br/><br/>    public synchronized void setData(String value) {<br/>        content = value;<br/>        initialized = true;<br/>    }<br/><br/>    public synchronized String getData() {<br/>        if (!initialized) {<br/>            throw new IllegalStateException("structure not<br/>            initialized");<br/>        }<br/>        return content;<br/>    }<br/>}</pre>
            <p>This is the exact same structure as the one we just saw. But now, thanks to the <kbd>synchronized</kbd> keyword added to each method, the call to a method would enforce concurrent calls
               to other synchronized methods to wait for the first one to end before being executed.
               Concretely, it will chain method execution like in a single thread.
            </p>
            
            <div class="packt_tip">The <kbd>synchronized</kbd> keyword is linked to an instance, so two different instances that are synchronized
               will not lock each other. It is also possible to use <kbd>synchronized</kbd> as a block and pass the instance to synchronize on. If you do so and pass a static
               instance, then you will lock all the instances that can prevent the application from
               scaling if on a common code path.
            </div>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">Locks</h1>
            
         </header>
         
         
         <article>
            
            
            <p class="mce-root">Java 1.5 introduces the <kbd>Lock</kbd> interface with its <kbd><span>java.util.concurrent</span></kbd> package, which contains a lot of concurrency-related classes. It achieves the same
               goal as that of <kbd>synchronized</kbd> but allows you to control manually the scope of the synchronized code.
            </p>
            
            <div class="packt_tip">The performance of <kbd>Lock</kbd> and <kbd>synchronized</kbd> differs between Java versions, but recent versions have progressed a lot. And generally,
               if you don't optimize a computing algorithm, choosing one or the other will lead to
               something close. However, it is generally better to use <kbd>Lock</kbd> if the number of concurrent threads accessing the instance is high.
            </div>
            
            <p>As <kbd>Lock</kbd> is an interface, it needs an implementation. The JRE comes with a default implementation
               called <kbd>ReentrantLock</kbd>. Replacing a <kbd>synchronized</kbd> block is done in the following way:
            </p>
            <pre>final Lock lock = new ReentrantLock();<br/>lock.lock();<br/>try {<br/>    doSomeBusinessLogic();<br/>} finally {<br/>    lock.unlock();<br/>}</pre>
            <p>The lock instantiation is directly done through the <kbd>new</kbd> keyword. We will note here that <kbd>ReentrantLock</kbd> can take a Boolean parameter to request it to respect a fair order for the lock invocations
               (the default is <kbd>false</kbd> and generally good enough in terms of performance). Once you have a locked instance,
               you can call the <kbd>lock()</kbd> method to ensure that you are the only one executing the code. Once you are done
               with your protected code, you can call <kbd>unlock()</kbd> to release the current thread and let another one execute its code. Also, note that
               all this locking logic assumes that the lock is shared across the thread. Thus, the
               instantiation is generally done once per instance (in the constructor or in a <kbd>@PostConstruct</kbd> method).
            </p>
            
            <div class="packt_infobox">It is vital to call the <kbd>unlock()</kbd> method; otherwise, other locked threads will never be released.
            </div>
            
            <p>A more common usage of the Lock API is to split the lock and unlock calls into two.
               For instance, to take Java EE usage, you can lock an instance when a request starts
               and unlock it when the request ends in order to ensure that a single request is accessing
               it. This is feasible with Servlet 3 through a listener, even for asynchronous requests.
               But you will not have a block that you can surround; instead, you will have multiple
               callbacks, which you need to integrate with the following:
            </p>
            <pre><span>public class </span>LockAsyncListener <span>implements </span>AsyncListener {<br/>    <span>private final </span>Lock <span>lock</span>;<br/><br/>    <span>public </span>LockAsyncListener(Lock lock) {<br/>        <span>this</span>.<span>lock </span>= lock;<br/>        this.lock.lock();<br/>    }<br/><br/>    <span>@Override<br/></span><span>    </span><span>public void </span>onStartAsync(AsyncEvent event) <span>throws </span>IOException {<br/>        // no-op<br/>    }<br/>    <br/>    <span>private void </span>onEnd() {<br/>        <span>lock</span>.unlock();<br/>    }<br/><br/>    <span>@Override<br/></span><span>    </span><span>public void </span>onComplete(AsyncEvent event) <span>throws </span>IOException {<br/>        onEnd();<br/>    }<br/><br/>    <span>@Override<br/></span><span>    </span><span>public void </span>onTimeout(AsyncEvent event) <span>throws </span>IOException {<br/>        onEnd();<br/>    }<br/><br/>    <span>@Override<br/></span><span>    </span><span>public void </span>onError(AsyncEvent event) <span>throws </span>IOException {<br/>        onEnd();<br/>    }<br/>}</pre>
            <p class="mce-root">With this listener added to <kbd>AsyncContext</kbd>, the lock will follow the request's life cycle. The usage will probably look as follows:
            </p>
            <pre><span>public class </span>SomeServlet <span>extends </span>HttpServlet {<br/>    <span>@Override<br/></span><span>    </span><span>protected void </span>service(HttpServletRequest req, HttpServletResponse<br/>    resp)<br/><span>        throws </span>ServletException, IOException {<br/>        <span>final </span>AsyncContext asyncContext = req.startAsync();<br/>        final SomeInstance instance = getInstance();<br/>        asyncContext.addListener(<span>new<br/>        </span>LockAsyncListener(instance.getLock()));<br/>        execute(asyncContext, instance)<br/>    }<br/>}</pre>
            <p>Once <kbd>AsyncContext</kbd> is obtained, we add the lock listener onto it and execute the request. The lock will
               be released when the request ends because of a timeout, an exception, or, simply,
               a normal termination.
            </p>
            
            <p>This sort of implementation with a synchronized block is quite hard and often requires
               some workarounds. This is an example where the Lock API is more powerful.
            </p>
            
            <div class="packt_tip">We will not detail it here, but the <kbd>ReadWriteLock</kbd> API gives you a holder for two locks: one is used to protect read accesses, and the
               other one for write accesses. The goal is to let read accesses be done in parallel
               and ensure that write accesses are done only when a single thread accesses the data.
            </div>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">java.util.concurrent</h1>
            
         </header>
         
         
         <article>
            
            
            <p>Although a detailed coverage of the Java Standalone is beyond the context of this
               book, it is important to know that Java 7 and Java 8 got a lot of enhancements in
               this area. So don't hesitate to go through its packages. Among the interesting classes,
               we can note the following:
            </p>
            
            <ul>
               
               <li><kbd>CountDownLatch</kbd>: This is a simple and efficient way to ensure that N threads are waiting a condition
                  owned by another thread (a bit like a starter in a race).
               </li>
               
               <li><kbd>Semaphore</kbd>: This allows you to represent and implement permission <em>buckets</em>. The most interesting part is that you can increase and decrease the associated counter.
                  It can be a simple way to implement a bulkhead solution.
               </li>
               
               <li><kbd>CyclicBarrier</kbd>: This is a way to synchronize multiple threads in some points of the code. Its API
                  is interesting because it allows you to add shared logic that can be executed on all
                  the threads. It can be seen as the opposite of <kbd>CountDownLatch</kbd>.
               </li>
               
               <li><kbd>Phaser</kbd>: This is a more flexible barrier implementation than <kbd>CyclicBarrier</kbd> and <kbd>CountDownlatch</kbd>.
               </li>
               
               <li><kbd>Atomic*</kbd>: This is a way to update a data instance atomically.
               </li>
               
            </ul>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">The volatile data</h1>
            
         </header>
         
         
         <article>
            
            
            <p>Finally, to conclude this part of the Java Standalone concurrent programming, it is
               necessary to keep in mind why the <kbd>volatile</kbd> keyword is important. This keyword allows you to request the JVM to refresh the value
               it reads every time it accesses the data.
            </p>
            
            <p>It is very simple to use; just add the <kbd>volatile</kbd> keyword on the field declaration:
            </p>
            <pre>public class SomeData {<br/>    private volatile int value;<br/>}</pre>
            <p>To understand why this keyword changes everything, you need to keep in mind that the
               JVM can have some thread-related <em>caching</em> of the field values (this is very low-level caching and has nothing to do with what
               we'll see in the next section). Adding this keyword as in the previous snippet forces
               us to bypass this cache. It is supposed to be a bit slower. However, the usage is
               often fast by itself, so it is generally worth it.
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">Java EE and threads</h1>
            
         </header>
         
         
         <article>
            
            
            <p>As we saw at the beginning of the chapter, Java EE can silently use threads. Any thread
               usage is important to identify even if it is good to rely on the Java EE implementation,
               because it is code that you don't have to maintain. The issue with not identifying
               the thread is that you can come across cases where your context (<kbd>ThreadLocal</kbd>) will not be available or will be available with the wrong values. The other pitfall
               of not identifying the thread is that you may end up abusing the thread and consuming
               way more resources on the machine than you need. Let's review a few representative
               cases of such usages.
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">CDI asynchronous events</h1>
            
         </header>
         
         
         <article>
            
            
            <p>CDI 2.0 introduces the notion of asynchronous events. It is a manner of asynchronously
               firing an event for the caller. Here is a sample usage:
            </p>
            <pre><span>public class </span>AsyncSender {<br/>    <span>private static final </span>Logger <span>log </span>=<br/>    Logger.<span>getLogger</span>(AsyncSender.class.getName());<br/><br/>    <span>@Inject<br/></span><span>    </span><span>private </span>Event&lt;MyEvent&gt; <span>sender</span>;<br/><br/>    <span>public void </span>send(<span>final </span>MyEvent event) {<br/>        <span>final </span>CompletionStage&lt;MyEvent&gt; cs = <span>sender</span>.fireAsync(event);<br/>        cs.thenRun(() -&gt; {<br/>        <span>// some post processing once all observers got notified<br/></span><span>        </span>});<br/>    }<br/>}</pre>
            <p>This code snippet sends an asynchronous event, thanks to <kbd>fireAsync</kbd>. The interesting part of this API is that it returns <kbd>CompletionStage</kbd>, which enables you to chain some logic after the event has notified all the asynchronous
               observers.
            </p>
            
            <div class="packt_infobox">Asynchronous events notify only asynchronous observers. It uses a new observer marker: <kbd>@ObserverAsync</kbd>. Here is a signature sample<span><span>: <br/></span></span><kbd><span>public void</span> <span>onEvent(</span><span>@ObservesAsync</span> <span>MyEvent event);</span></kbd></div>
            
            <p>The way the CDI handles the submission of this kind of events is by using <kbd>CompletionFuture.all</kbd> or by chaining the asynchronous observers in a single asynchronous thread (this is
               configurable in Weld; OpenWebBeans only supports the first solution). In any case,
               it submits individual futures to a CDI thread pool. The pool configuration is not
               yet completely standard, though it is important to know that it is feasible in all
               the containers and is an important tuning configuration for your application if you
               rely on it.
            </p>
            
            <p>Several containers will default to the common fork join pool of the JVM, which doesn't
               scale a lot. So, you will probably want to provide a custom thread pool dedicated
               to your application usage.
            </p>
            
            <p>In terms of the user code, it is important to prefer <span>the signature taking a </span><kbd>NotificationOptions</kbd><span> instance</span> to <kbd>fireAsync</kbd> (which generally falls back on the default container pool). Doing so will allow you
               to give a custom pool:
            </p>
            <pre><span>sender</span>.fireAsync(event, NotificationOptions.<span>ofExecutor</span>(myExecutor));</pre>
            <p>This signature enables you to pass a custom pool and to properly tune it (using EE
               concurrency utilities for Java EE, for instance). It will also enable you to specify
               the pool you are using by event and to avoid putting them all in the same bucket.
               In fact, it can potentially lead to locking your application if there are some dependencies
               between the usages!
            </p>
            
            <div class="packt_tip">Last tip on this API is to make sure that you synchronize the event if you mutate
               it, to get a new state after through <kbd>CompletionStage</kbd>. You can use any of the Java Standalone techniques we talked about previously.
            </div>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">EJB @Asynchronous</h1>
            
         </header>
         
         
         <article>
            
            
            <p>EJB was one of the earliest Java EE specifications. At that time, it was the specification
               getting the most attention and features. Now, it is slowly being replaced by CDI and
               integrations, with other specifications such as JTA, JPA, and so on. However, it still
               contains a set of useful features that you don't find elsewhere in Java EE.
            </p>
            
            <p>EJB also has an asynchronous solution. It is more direct compared to CDI, since you
               can mark a method as asynchronous:
            </p>
            <pre>@Asynchronous<br/>public Future&lt;MyResult&gt; execute() {<br/>    return new AsyncResult&lt;&gt;(getResult());<br/>}</pre>
            <p><kbd>@Asynchronous</kbd> requests the server to execute the task in the EJB thread pool. The method can return
               void, but if it needs to return a value, it must return <kbd>Future</kbd>. With Java 8, it is easy to return <kbd>CompletionFuture</kbd>. However, since this API was designed before that, the easiest way was to return
               <kbd>AsyncResult</kbd>, which was provided by the specification, and pass it the actual value you want to
               return. Note that the container will wrap the returned <kbd>Future</kbd> value to add a particular specification handling, so you will not be able to cast
               it to <kbd>CompletionFuture</kbd>, even if that is the implementation you choose in your code.
            </p>
            
            <p>Here again, the pool configuration is highly dependent on the server, but it is generally
               workable and important, depending on the usage of this API in the application. If
               your application uses it a lot but the container provides only two threads and a small
               pool queue, then you will not scale very far.
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">EE concurrency utilities for Java EE</h1>
            
         </header>
         
         
         <article>
            
            
            <p>Java EE 7 introduces a new specification called EE concurrency utilities for Java
               EE. The main target is not only to provide a way to work with threads from your EE
               application, but also to handle EE context propagation, including security, transaction,
               and so on.
            </p>
            
            <div class="packt_infobox">When using this API, remember that the propagated context highly depends on the container.
               This API is, however, a very good choice compared to a custom thread pool management
               because the configuration is outside the application and <em>standard</em> for the container, and also because it gives you the ability to benefit from the
               API that we will see in this section.
            </div>
            
            <p>What is very clever to do at the specification level is to reuse the standard APIs,
               such as <kbd>ExecutorService</kbd>, <kbd>ScheduledExecutorService</kbd>, and so on. This gives the developers the ability to use them as a replacement for
               the SE API. In particular, it enables you to integrate <span>transparently</span> with third-party libraries.
            </p>
            
            <p>For example, you can integrate with RxJava (<a href="https://github.com/ReactiveX/RxJava">https://github.com/ReactiveX/RxJava</a>),<span> as you would do with any thread pool:</span><a href="https://github.com/ReactiveX/RxJava"/></p>
            <pre><span>@ApplicationScoped<br/></span><span>public class </span>RxService {<br/>    <span>@Resource</span>(lookup = <span>"java:global/threads/rx"</span>)<br/>    <span>private </span>ManagedExecutorService <span>mes</span>;<br/><br/>    <span>public </span>Flowable&lt;String&gt; getValues() <span>throws </span>Exception {<br/>        <span>final </span>WebSocketContainer container =<br/>        ContainerProvider.<span>getWebSocketContainer</span>();<br/>        <span>final </span>WebSocketPublisher publisher = <span>new </span>WebSocketPublisher();<br/><br/>        container.connectToServer(<span>new </span>Endpoint() {<br/>            <span>@Override<br/></span><span>            </span><span>public void </span>onOpen(<span>final </span>Session session, <span>final<br/>            </span>EndpointConfig config) {<br/>                session.addMessageHandler(<span>publisher</span>);<br/>            }<br/><br/>            <span>@Override<br/></span><span>            </span><span>public void </span>onClose(<span>final </span>Session session, <span>final<br/>            </span>CloseReason closeReason) {<br/>                <span>publisher</span>.close();<br/>            }<br/>        },      URI.<span>create</span>(<span>"ws://websocket.company.com"</span>));<br/><br/>        <span>final </span>Scheduler eeScheduler = Schedulers.<span>from</span>(<span>mes</span>);<br/>        <span>return </span>Flowable.<span>fromIterable</span>(publisher)<br/>        .debounce(<span>1</span>, <span>MINUTES</span>, eeScheduler);<br/>    }<br/>}</pre>
            <p class="mce-root">This code integrates the Java EE WebSocket API with the RxJava Flowable API. The global
               idea is to let the consumers handle the WebSocket messages, without knowing it comes
               from WebSocket. <span>This makes it easier to test (replacing the WebSocket layer by a mock) and it decouples
                  the code from the WebSocket layer.</span></p>
            
            <p class="mce-root"><span>In our service, we inject <kbd>ManagedExecutorService</kbd>, which is mainly <kbd>ExecutorService</kbd> managed by the container, and we wrap it in the thread pool API of RxJava through
                  the <kbd>Scheduler</kbd> API. Then we are done; we can use any asynchronous operation of RxJava relying on
                  the Java EE threads and, therefore, the context. In the previous code snippet, it
                  allowed us to debounce the messages (limit the number of messages emitted per unit
                  of time) in one simple line.</span></p>
            
            <p><span>Technically, we implement</span> <kbd>Iterator&lt;&gt;</kbd><span> to integrate with RxJava, but we could use <kbd>Future</kbd> or any other type supported by the </span>Flowable<span> API. The iterator is the part integrating with RxJava. However, to integrate with
                  the WebSocket API, we can also implement <kbd>MessageHandler</kbd>, which allows us to see the incoming message and register it at our endpoint in the
                  previous snippet. Here is a potential handler implementation:</span></p>
            <pre><span>public class </span>WebSocketPublisher <span>implements<br/></span><span>        </span>Iterable&lt;String&gt;, Iterator&lt;String&gt;, MessageHandler.Whole&lt;String&gt; {<br/>    <span>private final </span>Semaphore <span>semaphore </span>= <span>new </span>Semaphore(<span>0</span>);<br/>    <span>private final </span>List&lt;String&gt; <span>messages </span>= <span>new </span>ArrayList&lt;&gt;();<br/>    <span>private volatile boolean </span><span>closed</span>;<br/><br/>    <span>public void </span>close() {<br/>        <span>closed </span>= <span>true</span>;<br/>        <span>semaphore</span>.release();<br/>    }<br/><br/>    <span>@Override<br/></span><span>    </span><span>public void </span>onMessage(<span>final </span>String message) {<br/>        <span>synchronized </span>(<span>messages</span>) {<br/>            <span>messages</span>.add(message);<br/>        }<br/>        <span>semaphore</span>.release(); <br/><span>        // it case we are currently locked in hasNext()<br/></span><span>    </span>}<br/><br/>    <span>@Override<br/></span><span>    </span><span>public boolean </span>hasNext() {<br/>        <span>if </span>(<span>closed</span>) {<br/>            <span>return false</span>;<br/>        }<br/>        <span>try </span>{<br/>            <span>semaphore</span>.acquire();<br/>            <span>synchronized </span>(<span>messages</span>) {<br/>                <span>return </span>!<span>closed </span>&amp;&amp; !<span>messages</span>.isEmpty();<br/>            }<br/>        } <span>catch </span>(<span>final </span>InterruptedException e) {<br/>            <span>return false</span>;<br/>        }<br/>    }<br/><br/>    <span>@Override<br/></span><span>    </span><span>public </span>String next() {<br/>        <span>synchronized </span>(<span>messages</span>) {<br/>            <span>return </span><span>messages</span>.remove(<span>0</span>);<br/>        }<br/>    }<br/><br/>    <span>@Override<br/></span><span>    </span><span>public </span>Iterator&lt;String&gt; iterator() {<br/>        <span>return this</span>;<br/>    }<br/>}</pre>
            <p class="mce-root">Our publisher stacks the received messages and then serves them through the <kbd>Iterator&lt;&gt;</kbd> API. It requires some synchronization, as we saw in the previous section, to make
               sure we are able to correctly answer the iterator contract. Concretely, we cannot
               return anything in <kbd>hasNext()</kbd> if the connection was not closed or if we did not receive any message. Otherwise,
               it will stop the iterations.
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">ManagedExecutorService</h1>
            
         </header>
         
         
         <article>
            
            
            <p>As a quick reminder, <kbd>ExecutorService</kbd> is the standard Java Standalone abstraction for a thread pool. <kbd>ManagedExecutorService</kbd> is the Java EE flavor. If you compare both the APIs, you will notice that it inherits
               from all the features of its standalone siblings, but it gets enriched with an auditing:
               a<span> submitted task (</span><kbd>Runnable</kbd><span>) can implement the </span>ManagedTask <span>API, which will associate a listener to the task, which will be notified of the task's
                  phase (</span><kbd>Submitted</kbd><span>, </span><kbd>Starting</kbd><span>, </span><kbd>Aborted</kbd><span>, and </span><kbd>Done</kbd><span>).</span></p>
            
            <p>ManagedTask globally gives the following to the container:</p>
            
            <ul>
               
               <li>The listener that ManagedTask uses</li>
               
               <li>A set of properties to customize the behavior of the execution. Three main standard
                  properties are defined and portably usable on all the containers:
                  
                  <ul>
                     
                     <li> <kbd>javax.enterprise.concurrent.LONGRUNNING_HINT</kbd>: This allows the container to change the thread setup for a long time, taking the
                        tasks to complete (using other thread priorities or potentially using dedicated threads)
                     </li>
                     
                     <li><kbd>javax.enterprise.concurrent.TRANSACTION</kbd>: This can take the <kbd>SUSPEND</kbd> <span>value </span>that will suspend the current transaction (if any) and resume it after the task is
                        completed
                     </li>
                     
                     <li><kbd>USE_TRANSACTION_OF_EXECUTION_THREAD</kbd>: This propagates the transaction of the calling thread
                     </li>
                     
                  </ul>
                  
               </li>
               
            </ul>
            
            <p>If you cannot make your task implementing ManagedTask, then you also have <em>bridge</em> adapters to link a normal task to a listener through the  <kbd>ManagedExecutors</kbd> factory:
            </p>
            <pre>Runnable runnable = ManagedExecutors.<span>managedTask</span>(myTask, myListener);</pre>
            <p>This simple invocation will create <kbd>Runnable</kbd> and you can therefore submit to <kbd>ManagedExecutorService</kbd>, which also implements <kbd>ManagedTask</kbd> with the <kbd>myListener</kbd> listener. Indeed, there are wrapper factory methods for <kbd>Callable</kbd>, with the properties we mentioned earlier, to ensure it covers all the <kbd>ManagedTask</kbd> API's features.
            </p>
            
            <p>In terms of the overall platform consistency, it is important that this API tends
               to make EJB <kbd>@Asynchronous</kbd> legacy.
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">ManagedScheduledExecutorService</h1>
            
         </header>
         
         
         <article>
            
            
            <p><kbd>ManagedScheduledExecutorService</kbd> is <kbd>ScheduledExecutorService</kbd> Java EE API. Like <kbd>ExecutorService</kbd>, it integrates with the ManagedTask API.
            </p>
            
            <p>However, this scheduling-related API goes a bit further, providing two new methods
               to schedule a task—<kbd>Runnable</kbd> or <kbd>Callable</kbd> <span>—</span>based on a dedicated API (<kbd>Trigger</kbd>). This API enables you to handle the scheduling <span>programmatically</span> and it avoids relying on a constant time interval or delay.
            </p>
            
            <p>Even if, theoretically, this scheduling API can be distributed and was designed to
               support it, it is generally implemented with local support only. However, it is a
               good alternative to EJB <kbd>@Schedule</kbd> or <kbd>TimerService</kbd> when clustering is not mandatory, which is actually often the case in practice.
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">Java EE threads</h1>
            
         </header>
         
         
         <article>
            
            
            <p>The EE concurrency utilities also provide a Java EE ThreadFactory, which creates <kbd>ManageableThread</kbd> instead of a plain thread. The main difference is that they provide an <kbd>isShutdown()</kbd> method, allowing you to know whether the current thread is shutting down and, thereby,
               exit the process if it is indeed shutting down. <kbd>ManagedExecutors.isCurrentThreadShutdown()</kbd> allows you to directly test this flag, handling the casting of the thread automatically.
               This means that a long running task can be implemented as follows:
            </p>
            <pre>while (running &amp;&amp; !ManagedExecutors.isCurrentThreadShutdown()) {<br/>    process();<br/>}</pre>
            <p>You may think that testing only the thread state would be enough, but you still need
               an application state to ensure that you integrate with the application life cycle.
               Don't forget that the thread can be bound to the container and not the application
               deployment time. Also, depending on the strategy you define for the threads, you can
               evict them at runtime, potentially through the administration API of the container.
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">ContextService</h1>
            
         </header>
         
         
         <article>
            
            
            <p>The last interesting API of the EE concurrency utilities is <kbd>ContextService</kbd>. It allows you to create proxies, based on interfaces, inheriting from the context
               propagation of the <kbd>Managed*</kbd> API. You can see it as a way of using managed thread pool features in the standalone
               thread pools that you don't control:
            </p>
            <pre>Runnable wrappedTask = contextService.createContextualProxy(myTask, Runnable.class);<br/>framework.execute(wrappedTask);</pre>
            <p>Here, we wrap our task in a contextual proxy and we submit the wrapped task through
               a framework that we don't control. However, the execution will still be done in the
               EE context of the caller (same JNDI context, for instance), and using another framework
               is not much affecting.
            </p>
            
            <p>This <kbd>ContextService</kbd> is limited to proxy interfaces and doesn't support subclass proxying like CDI does
               for instance. Java EE understands that modern development is composed of motley frameworks
               and stacks and that it can't control everything and anything. This trend is traduced
               by the introduction of a new sort of API to easily integrate with others and enable
               any use case, rather than introducing a lot of new APIs, which will not evolve very
               well.
            </p>
            
            <p>It is important in terms of performance and monitoring—it not only allows you to easily
               trace invocations and application behavior but also to optimize the application with
               caching, as we will see in the next chapter.
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">EJB @Lock</h1>
            
         </header>
         
         
         <article>
            
            
            <p>The previous part showed that EJB <kbd>@Asynchronous</kbd> and <kbd>@Schedule</kbd> can be replaced with the new EE concurrency utilities in some measure. However, there
               are still some EJB APIs that are not easy to replace without coding them yourself.
               The <kbd>@Lock</kbd> API is one of them.
            </p>
            
            <p>The global idea is to ensure that the data owned by the EJB (<kbd>@Singleton</kbd>) is accessed in a thread-safe context.
            </p>
            
            <p>Indeed, this API is limited to the singleton EJB, since without a single instance
               usable in a concurrent environment, it doesn't make sense to lock.
            </p>
            
            <p>The usage is straightforward, as you just decorate a method or the bean with <kbd>@Lock</kbd>, passing <kbd>READ</kbd> or <kbd>WRITE</kbd> in the parameter, depending on the kind of access:
            </p>
            <pre>@Singleton<br/>public class MyLocalData {<br/>    private Data data;<br/><br/>    @Lock(READ)<br/>    public Data get() {<br/>        return data;<br/>    }<br/><br/>    @Lock(WRITE)<br/>    public void set(Data data) {<br/>        this.data = data;<br/>    }<br/>}</pre>
            <p>If you remember the part about Java Standalone, it is very close to the <kbd>synchronized</kbd> usage, as we define a lock on a block. However, the semantic is closer to the <kbd>ReadWriteLock</kbd> API.  This was a will of the API design as this is the way it is often implemented.
               Now, why mix both the styles (block and read/write API)? It enables you to scale on
               the read, keeping the API very simple (bound to blocks). However, it already fits
               a lot of cases!
            </p>
            
            <p>In terms of the performance, it is important to know that you can mix it with a timeout
               through <kbd>@AccessTimeout</kbd>:
            </p>
            <pre>@Singleton<br/>@AccessTimeout(500)<br/>public class MyLocalData {<br/>    // as before<br/>}</pre>
            <p>Here, we request the container to fail with the <kbd>ConcurrentAccessTimeout</kbd> exception if the lock (read or write) is not acquired after 500 milliseconds.
            </p>
            
            <p>For a reactive application, correctly configuring the timeouts is crucial and important
               to ensure that the application doesn't start with a huge response time because of
               all the threads waiting for a response. This means that you have to define a fallback
               behavior in the case of a timeout. To say it differently, you need to define a timeout
               to ensure you match your SLA, but you also need to define what to do when you get
               a timeout in order to avoid 100% of errors in case the server is overloaded.
            </p>
            
            <div class="packt_tip">The microprofile initiative has been created by most Java EE vendors and is mainly
               based on the CDI. So, even if it is not part of the Java EE, it integrates very well
               with it. Its primary targets are microservices, and, therefore, they define a bulkhead
               API and other concurrent solutions. However, it is an interesting solution if the <kbd>@Lock</kbd> is too simple for your needs.
            </div>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">HTTP threads</h1>
            
         </header>
         
         
         <article>
            
            
            <p>HTTP layers (server and client) are about network and connections. Therefore, they
               require some threading to handle the client connections on the server side and, potentially,
               the reactive processing on the client side. Let's go through these particular settings,
               which directly impact the scalability of your application.
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">Server side</h1>
            
         </header>
         
         
         <article>
            
            
            <p>The entry point of any web request is the HTTP container. Here, the server configuration
               is always server-dependent, but most of the vendors will share the same concepts.
               It is important to tune that part to make sure that the outbound of your application
               is not unintentionally throttling it too much; otherwise, you will limit the scalability
               of your application for no reason.
            </p>
            
            <p>For instance, for GlassFish, you can configure the HTTP connector in the UI administration
               or the corresponding configuration file. Here is what it looks like:
            </p>
            
            <div class="CDPAlignCenter CDPAlign"><img src="assets/d05f44a1-4cbe-429c-bfd0-36dfd19509f1.png"/></div>
            
            <p>This page is really about the tuning of the HTTP connector (not the binding address,
               port, or the supported SSL cipher algorithms). The corresponding configurations are
               summarized in the following table:
            </p>
            
            <table>
               
               <tbody>
                  
                  <tr>
                     
                     <td><strong>Configuration name</strong></td>
                     
                     <td><strong>Description</strong></td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>Max connections</td>
                     
                     <td>This is the maximum number of requests per client in the keep-alive mode. This is
                        not the maximum number of connections the server supports, compared with the other
                        Java EE servers.
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>Timeout</td>
                     
                     <td>This is the timeout after which the connection can be dropped in the keep-alive mode
                        if still idle. Here again, it is a client-based configuration and not a request timeout
                        like in most of the other servers.
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>Request timeout</td>
                     
                     <td>This is the duration after which the request will timeout and fail from the client
                        point of view.
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>Buffer size/length</td>
                     
                     <td>Buffers are used to read the incoming data in the input streams. Adjusting this size
                        to avoid memory overflows will significantly increase the performance, since the server
                        will no longer have to create a new volatile buffer to read the data. This tuning
                        can be hard to do if the application does lots of things. The trade-off is to not
                        use too much memory and to avoid unexpected allocations. Thus, the closer you are
                        to the most common requests in terms of size (a bit more than this value actually),
                        the better you will behave. 
                     </td>
                     
                  </tr>
                  
                  <tr>
                     
                     <td>Compression</td>
                     
                     <td>Compression is mainly for browser-based clients (supporting GZIP). It will automatically
                        compress the content of the configure mime types if the size of the resource is more
                        than the minimum configuration size. Concretely, it can, for instance, affect a JavaScript
                        of 2MB (which is no longer rare today). This will use some CPU resources to do the
                        compression, but the space gain on text-based resources (HTML, JavaScript, CSS, and
                        so on) is generally worth it, as the network duration will be reduced a lot.
                     </td>
                     
                  </tr>
                  
               </tbody>
               
            </table>
            
            <p> </p>
            
            <p>These parameters are mainly about the network optimization but are crucial to ensure
               that the application stays responsive. They are also influencing the way the HTTP
               threads are used, because bad tuning can imply more work for the server. Now, you
               also have an HTTP thread pool in GlassFish (as in most servers) that you can configure.
               Here is the corresponding screen:
            </p>
            
            <div class="CDPAlignCenter CDPAlign"><img src="assets/0b6b61da-be49-4375-9305-9ea9e4cc52d5.png"/></div>
            
            <p>The configuration of GlassFish is very common for a thread pool—its sizes (maximum/minimum),
               the queue size (the number of tasks that can be added even if the pool is full), and
               the timeout (when a thread is removed from the pool if not used).
            </p>
            
            <p>When you are benchmarking your application, ensure that you monitor the CPU usage
               of your application and the thread stacks (or profiling, depending on the way you
               monitor your server/application) to identify bad configuration. For instance, if you
               see a CPU usage of 50% and a few active threads, then you may need to increase the
               pool size. The overall goal is to make the CPU usage very high (85-95%) and the response
               time of the server almost constant. Note that it is not recommended to go up to 100%
               for the CPU usage because, then, you'll reach the limitations of the machine; the
               performance won't be relevant anymore and you will just see the response time increasing
               boundlessly.
            </p>
            
            <div class="packt_tip">This is a general rule for any thread pool that can become very important when going
               reactive. So, always try to name the threads of the application with a prefix that
               corresponds to the role that they have in order to ensure that you can identify them
               in the thread dumps.
            </div>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">Client side</h1>
            
         </header>
         
         
         <article>
            
            
            <p>Since JAX-RS 2.1, the client has been made to be reactive. As a quick reminder, here
               is what it can look like:
            </p>
            <pre><span>final </span>Client client = ClientBuilder.<span>newClient</span>();<br/><span>try </span>{<br/>    CompletionStage&lt;Response&gt; response =<br/>    client.target(<span>"http://google.com"</span>)<br/>          .request(<span>TEXT_HTML_TYPE</span>)<br/>          .rx()<br/>          .get();<br/>} <span>finally </span>{<br/>  client.close();<br/>}</pre>
            <p>This is normal JAX-RS client API usage, except for the call to <kbd>rx()</kbd>, which wraps the response into <kbd>CompletionStage</kbd>. The only interest is to become asynchronous; otherwise, it will just be another
               layer with poor gain in terms of user experience.
            </p>
            
            <p>The way the implementation handles asynchronous invocations is up to the implementation,
               but with Jersey (the reference implementation) and in a Java EE container, you will
               default to the managed executor service. Note that outside an EE container, Jersey
               will create a very big thread pool.
            </p>
            
            <p>This kind of configuration is the key to your application, since each client is supposed
               to have a different pool to ensure that it doesn't affect the other parts of the application,
               and also because thread usages can be different and may need different constraints.
               However, it is not yet standardized and, thus, you will need to check which implementation
               your server uses and how the configuration can be used. In general, the client-side
               configuration is accessible through the client's properties, so it is not that hard.
               However, sometimes, you may be limited by container integration. In such a case, you
               can wrap the invocation into your own pool and not use the <kbd>rx()</kbd> API to fully control it.
            </p>
            
            <p>To conclude this section, we can expect in some time (Java EE 8 and this new JAX-RS
               2 API) that this <kbd>rx()</kbd> method will be implemented directly using the NIO API, and therefore, it becomes
               really reactive at the network level and not just through another thread pool.
            </p>
            
            <p>We just saw that Java EE brings solutions to handle your application threading properly,
               but modern developments often require new paradigms. These modifications require a
               small change in the way the application is developed. Let's go through one of these
               new patterns.
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">Reactive programming and Java EE</h1>
            
         </header>
         
         
         <article>
            
            
            <p class="mce-root">Reactive programming lets your code be called instead of calling your code. You can
               visualize it as being event-based instead of procedural. Here is an example to compare
               both the styles:
            </p>
            <pre>public void processData(Data data) {<br/>    if (validator.isValid(data)) {<br/>        service.save(data);<br/>        return data;<br/>    }<br/>    throw new InvalidDataException();<br/>}</pre>
            <p class="mce-root">This is a very simple and common implementation of a business method where we call
               two services: <kbd>validator</kbd> and <kbd>service</kbd>. The first one will validate the data by checking whether it exists in the database,
               the values are in the expected ranges, and so on, while the second one will actually
               process the updates (a database, for instance).
            </p>
            
            <p>The issue with this style is that the data validation and persistence are bound in
               a single <kbd>processData</kbd> method, which defines the entire execution environment (threading, context, and so
               on).
            </p>
            
            <p>In the reactive style, it can be rewritten to replace the synchronous calls by a <em>chain</em>:
            </p>
            <pre>public Data processData(Data data) {    <br/>    return Stream.<span>of</span>(data)<br/>      .filter(validator::isValid)<br/>      .peek(service::save)<br/>      .findFirst()<br/>      .orElseThrow(() -&gt; <span>new </span>InvalidDataException(<span>"..."</span>));<br/>}</pre>
            <p class="mce-root">In this example, we used the Java 8 stream API, but using a reactive library such
               as RxJava generally makes more sense; <span>you will understand why </span>in the next paragraph. This code does the same thing as the previous one, but it orchestrates
               the calls through the definition of a chain, instead of making the calls directly.
            </p>
            
            <p>What is interesting with this pattern is that you split your logic (<kbd>validator</kbd>, <kbd>service</kbd>) from the way it is used (the stream in the previous example). It implies that you
               can enrich the way the calls are orchestrated, and if you think about the example
               of RxJava that we saw earlier, you can immediately think about executing each method
               in different threads.
            </p>
            
            <p>One common use case of such a pattern is when the response time is more important
               than the resources used. In other words, if you don't care about consuming more CPU
               cycles if it helps reduce the time you need to respond to your client, then you can
               put this pattern in place. If you are working with multiple concurrent data providers,
               or if you need to contact multiple remote services to process the data, then you will
               do the three invocations concurrently upfront. And once you have all the responses,
               you will execute the actual processing.
            </p>
            
            <p>To illustrate this, you can assume that the data has a contract identifier, a customer
               identifier, and an account identifier associated with the corresponding entities through
               three different remote services. The synchronous implementation of such a case will
               be something like the following:
            </p>
            <pre>Customer customer = findCustomer(data);<br/>Contract contract = fincContract(data);<br/>Account account = findAccount(data);<br/>process(customer, contract, account);</pre>
            <p>This will work. However, assuming that a remote call is about 10 ms, your method will
               then take more than 30 ms to process the data.
            </p>
            
            <p>You can optimize it a bit by doing the three requests concurrently:</p>
            <pre><span>public void </span>processData(Data data) {<br/>    <span>final </span>CompletableFuture&lt;Customer&gt; customer = findCustomer(data);<br/>    <span>final </span>CompletableFuture&lt;Contract&gt; contract = findContract(data);<br/>    <span>final </span>CompletableFuture&lt;Account&gt; account = findAccount(data);<br/>    <span>try </span>{<br/>        CompletableFuture.<span>allOf</span>(customer, contract, account).get();<br/>        processLoadedData(customer.get(), contract.get(), account.get());<br/>    } <span>catch </span>(<span>final </span>InterruptedException | ExecutionException e) {<br/>        <span>throw </span>handleException(e);<br/>    }<br/>}</pre>
            <p>In this case, you will reduce the invocation duration to 10 ms, more or less. However,
               you will block the thread for 10 ms (the three parallel invocations). The <kbd>CompletableFuture.allOf(...).get()</kbd> <span>line </span>waits for all the three asynchronous operations (<kbd>CompletableFutures</kbd>) to complete, keeping the thread unusable for other requests/processing.
            </p>
            
            <p>The direct implication is that you will not scale and will not be able to process
               many concurrent requests even if your CPU is probably doing nothing (that is, you
               are waiting on I/O if you obtain a thread dump at that time).
            </p>
            
            <p>The way to enhance this is to ensure that the main thread is not blocked and that
               the processing is triggered only when all the data is received:
            </p>
            <pre><span>public void </span>processData(Data data) {<br/>    <span>final </span>CompletableFuture&lt;Customer&gt; customer = findCustomer(data);<br/>    <span>final </span>CompletableFuture&lt;Contract&gt; contract = findContract(data);<br/>    <span>final </span>CompletableFuture&lt;Account&gt; account = findAccount(data);<br/>    CompletableFuture.<span>allOf</span>(customer, contract, account)<br/>         .thenRun(() -&gt; {<br/>             <span>try </span>{<br/>                 processLoadedData(<span>customer</span>.get(), <span>contract</span>.get(),<br/>                 <span>account</span>.get());<br/>             } <span>catch </span>(<span>final </span>InterruptedException | ExecutionException<br/>               e) {<br/>                 <span>throw </span>handleException(e);<br/>             }<br/>         });<br/>}</pre>
            <p>In this case, we still execute our three remote invocations in parallel—potentially,
               in a managed executor service if you need to access EE features<span>—</span>and, then, we wait for all three results to be retrieved in order to do our processing.
               However, we just register our processing to be done once the entire data is readable,
               and we don't block the thread waiting for this <em>ready</em> state; thus, we will be able to serve more requests simultaneously.
            </p>
            
            <p>What is important in going reactive is to try to avoid synchronizations as much as
               possible in order to ensure any thread time is active processing. Of course, it has
               limitations, like some JDBC drivers, which are still synchronous, it will block a
               thread waiting for I/O operations. Yet, with microservices becoming common, it is
               easy to add a lot of latency to your code and reduce the application scalability if
               you don't take care of it.
            </p>
            
            <p>A way to represent this kind of programming <span>mentally</span> is to visualize the CPU usage as a big queue and each element of the queue as some
               active computing time consumer (that is, a task). Then, your program is just a big
               event loop polling this task queue and executing the tasks. What is the result?—almost
               no passive time, only active time!
            </p>
            
            <p>Indeed, being asynchronous implies that all the work will become asynchronous (thread
               handling, context switching, queue management, and synchronization). Even if most
               of these tasks are hidden and done for you by the stack, it may make the CPU busy
               and slow down the application, compared with the same code executed in a single thread.
               This is true and means that you can't use this pattern for every single invocation.
               You need to ensure that you use it when relevant and when there is potentially a passive
               usage of the CPU (blocking time, sleep, and so on). Though, if you respect this pattern,
               you should be able to work with concurrency better than staying synchronous everywhere.
               Of course, this is a compromise because if you have a background task (a scheduled
               task executed once a day, for instance), you will not care about the waiting time
               since it concerns a single thread. This type of programming will only pay when used
               in accurate places, but if you respect this usage, you will really get a saner final
               behavior. However, don't forget that it brings more complexity because tracking is
               no more natural in Java (stack traces are almost no more useful since you don't have
               the full stack if you don't use a thread-tracing solution).
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">Message passing and Java EE</h1>
            
         </header>
         
         
         <article>
            
            
            <p>Message passing pattern refers to several theories, but in this part, we'll mainly
               care about the asynchronous flavor. One illustration of this pattern is the actor
               flavor. An actor is <em>something</em> that can receive messages, send messages to other actors, create other actors, and
               designate the behavior for the next received message.
            </p>
            
            <p>It is important to understand the basis of the underlying concepts:</p>
            
            <ul>
               
               <li>Global communication relies on an asynchronous bus</li>
               
               <li>C<em>urrent</em> message processing of an actor is based on a state (a bit like an internal state
                  machine)
               </li>
               
               <li>An actor can create other actors to process a message</li>
               
            </ul>
            
            <p>With such a pattern, it is highly recommended to have immutable messages to avoid
               any concurrency issues and hard-to-debug behavior (or non-deterministic behavior)
               going across the actor flow.
            </p>
            
            <p>Java EE doesn't allow you to handle everything of this pattern out of the box, but
               most of it is already here:
            </p>
            
            <ul>
               
               <li>CDI provides a bus</li>
               
               <li>CDI (asynchronous) observers are beans, so you can have a state machine</li>
               
               <li>The delegation chain (new actors) can be handled through a CDI context bound to the
                  messages
               </li>
               
            </ul>
            
            <p>Of course, this stays a poor man's implementation, compared with real actor systems,
               but it already gives you a solid pattern to avoid passive usage of threads, and, by
               the way, you should think about it when creating an internal architecture for your
               application.
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   

      
      <section>
         
         
         <header>
            
            <h1 class="header-title">Summary</h1>
            
         </header>
         
         
         <article>
            
            
            <p>In this chapter, you saw how Java EE ensures that you can parallelize the computing
               of your applications, and make your applications scale better and process multiple
               concurrent requests.
            </p>
            
            <p>Using Java Standalone synchronization mechanisms, Java EE threading management solutions
               and API will let you get the best out of your hardware and integrate with third-party
               libraries very easily.
            </p>
            
            <p>Now that we have seen what is related to the CPU, we need to go through the machine's
               other main resource that you can exploit to make your application's behavior better:
               the memory. When processing can't be optimized and is too impacting on the application,
               the solution is often just to skip it as much as possible. The most common—and probably,
               efficient<span>—</span>way of doing so is to make sure that the data is computed once and reused while valid.
               This is where the caching enters into the game and this is what our next chapter will
               be about.
            </p>
            
            
            
         </article>
         
         
         
      </section>
      
   </body></html>