<html><head></head><body><div class="chapter" title="Chapter&#xA0;3.&#xA0;Unleashing Scala Performance"><div class="titlepage"><div><div><h1 class="title"><a id="ch03"/>Chapter 3. Unleashing Scala Performance</h1></div></div></div><p>In this chapter, we will look at Scala-specific constructs and language features, and examine how they can help or hurt performance. Equipped with our newly-acquired performance measurement knowledge, we will analyze how to use the rich language features that are provided by the Scala programming language better. For each feature, we will introduce it, show you how it compiles to bytecode, and then identify caveats and other considerations when using this feature.</p><p>Throughout the chapter, we will show the Scala source code and generated bytecode that are emitted by the Scala compiler. It is necessary to inspect these artifacts to enrich your understanding of how Scala interacts with the JVM so that you can develop an intuition for the runtime performance of your software. We will inspect the bytecode by invoking the  <code class="literal">javap</code> Java disassembler after compiling the command, as follows:</p><pre class="programlisting">
<span class="strong"><strong>javap -c &lt;PATH_TO_CLASS_FILE&gt;</strong></span>
</pre><p>The minus <code class="literal">c</code> switch prints the disassembled code. Another useful option is <code class="literal">-private</code>, which prints the bytecode of privately defined methods. For more information on <code class="literal">javap</code>, refer to the manual page. The examples that we will cover do not require in-depth JVM bytecode knowledge, but if you wish to learn more about bytecode operations, refer to Oracle's JVM specification at <a class="ulink" href="http://docs.oracle.com/javase/specs/jvms/se7/html/jvms-3.html#jvms-3.4">http://docs.oracle.com/javase/specs/jvms/se7/html/jvms-3.html#jvms-3.4</a>.</p><p>Periodically, we will also inspect a version of the Scala source code with Scala-specific features removed by running the following command:</p><pre class="programlisting">
<span class="strong"><strong>scalac -print &lt;PATH&gt;</strong></span>
</pre><p>This is a useful way to see how the Scala compiler desugars convenient syntax into constructs that the JVM can execute. In this chapter, we will explore the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Value classes and tagged types</li><li class="listitem" style="list-style-type: disc">Specialization</li><li class="listitem" style="list-style-type: disc">Tuples</li><li class="listitem" style="list-style-type: disc">Pattern matching</li><li class="listitem" style="list-style-type: disc">Tail recursion</li><li class="listitem" style="list-style-type: disc">The <code class="literal">Option</code> data type</li><li class="listitem" style="list-style-type: disc">An alternative to <code class="literal">Option</code></li></ul></div><div class="section" title="Value classes"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec18"/>Value classes</h1></div></div></div><p>In <a class="link" href="ch02.html" title="Chapter 2.  Measuring Performance on the JVM">Chapter 2</a>, <span class="emphasis"><em>Measuring Performance on the JVM</em></span>, we introduced the domain model of the order book application. This domain model included two classes, <code class="literal">Price</code> and <code class="literal">OrderId</code>. We pointed out that we created domain classes for <code class="literal">Price</code> and <code class="literal">OrderId</code> to provide contextual meanings to the wrapped <code class="literal">BigDecimal</code> and <code class="literal">Long</code>. While providing us with readable code and compilation time safety, this practice also increases the number of instances that are created by our application. Allocating memory and generating class instances create more work for the garbage collector by increasing the frequency of collections and by potentially introducing additional long-lived objects. The garbage collector will have to work harder to collect them, and this process may severely impact our latency.</p><p>Luckily, as of Scala 2.10, the <code class="literal">AnyVal</code> abstract class is available for developers to define their own value classes to solve this problem. The <code class="literal">AnyVal</code> class is defined in the Scala doc (<a class="ulink" href="http://www.scala-lang.org/api/current/#scala.AnyVal">http://www.scala-lang.org/api/current/#scala.AnyVal</a>) as, "the root class of all value types, which describe values not implemented as objects in the underlying host system." The <code class="literal">AnyVal</code> class can be used to define a value class, which receives special treatment from the compiler. Value classes are optimized at compile time to avoid the allocation of an instance, and instead they use the wrapped type.</p><div class="section" title="Bytecode representation"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec20"/>Bytecode representation</h2></div></div></div><p>As an example, to improve the performance of our order book, we can define <code class="literal">Price</code> and <code class="literal">OrderId</code> as value classes:</p><pre class="programlisting">case class Price(value: BigDecimal) extends AnyVal &#13;
case class OrderId(value: Long) extends AnyVal &#13;
</pre><p>To illustrate the special treatment of value classes, we define a dummy method taking a <code class="literal">Price</code> value class and an <code class="literal">OrderId</code> value class as arguments:</p><pre class="programlisting">def printInfo(p: Price, oId: OrderId): Unit = &#13;
  println(s"Price: ${p.value}, ID: ${oId.value}") &#13;
</pre><p>From this definition, the compiler produces the following method signature:</p><pre class="programlisting">public void printInfo(scala.math.BigDecimal, long); &#13;
</pre><p>We see that the generated signature takes a <code class="literal">BigDecimal</code> object and a <code class="literal">long</code> object, even though the Scala code allows us to take advantage of the types defined in our model. This means that we cannot use an instance of <code class="literal">BigDecimal</code> or <code class="literal">Long</code> when calling <code class="literal">printInfo</code> because the compiler will throw an error.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note20"/>Note</h3><p>An interesting thing to notice is that the second parameter of <code class="literal">printInfo</code> is not compiled as <code class="literal">Long</code> (an object), but <code class="literal">long</code> (a primitive type, note the lower case 'l').  <code class="literal">Long</code> and other objects matching to primitive types, such as <code class="literal">Int</code>, <code class="literal">Float</code> or <code class="literal">Short</code>, are specially handled by the compiler to be represented by their primitive type at runtime.</p></div></div><p>Value classes can also define methods. Let's enrich our <code class="literal">Price</code> class, as follows:</p><pre class="programlisting">case class Price(value: BigDecimal) extends AnyVal { 
  def lowerThan(p: Price): Boolean = this.value &lt; p.value &#13;
} &#13;
 &#13;
// Example usage &#13;
val p1 = Price(BigDecimal(1.23)) &#13;
val p2 = Price(BigDecimal(2.03)) &#13;
p1.lowerThan(p2) // returns true &#13;
</pre><p>Our new method allows us to compare two instances of <code class="literal">Price</code>. At compile time, a companion object is created for <code class="literal">Price</code>. This companion object defines a <code class="literal">lowerThan</code> method that takes two <code class="literal">BigDecimal</code> objects as parameters. In reality, when we call <code class="literal">lowerThan</code> on an instance of <code class="literal">Price</code>, the code is transformed by the compiler from an instance method call to a static method call that is defined in the companion object:</p><pre class="programlisting">public final boolean lowerThan$extension(scala.math.BigDecimal, scala.math.BigDecimal); &#13;
    Code: &#13;
       0: aload_1 &#13;
       1: aload_2 &#13;
       2: invokevirtual #56  // Method scala/math/BigDecimal.$less:(Lscala/math/BigDecimal;)Z &#13;
       5: ireturn &#13;
</pre><p>If we were to write the pseudo-code equivalent to the preceding Scala code, it would look something like the following:</p><pre class="programlisting">val p1 = BigDecimal(1.23) &#13;
val p2 = BigDecimal(2.03) &#13;
Price.lowerThan(p1, p2)  // returns true &#13;
</pre></div><div class="section" title="Performance considerations"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec21"/>Performance considerations</h2></div></div></div><p>Value classes are a great addition to our developer toolbox. They help us reduce the count of instances and spare some work for the garbage collector, while allowing us to rely on meaningful types that reflect our business abstractions. However, extending <code class="literal">AnyVal</code> comes with a certain set of conditions that the class must fulfill. For example, a value class may only have one primary constructor that takes one public <code class="literal">val</code> as a single parameter. Furthermore, this parameter cannot be a value class. We saw that value classes can define methods via <code class="literal">def</code>. Neither <code class="literal">val</code> nor <code class="literal">var</code> is allowed inside a value class. A nested class or object definitions are also impossible. Another limitation prevents value classes from extending anything other than a universal trait, that is, a trait that extends <code class="literal">Any</code>, only has <code class="literal">defs</code> as members, and performs no initialization. If any of these conditions are not fulfilled, the compiler generates an error. In addition to the preceding constraints that are listed, there are special cases in which a value class has to be instantiated by the JVM. Such cases include performing a pattern matching or runtime type test, or assigning a value class to an array. An example of the latter looks like the following snippet:</p><pre class="programlisting">def newPriceArray(count: Int): Array[Price] = { &#13;
  val a = new Array[Price](count) &#13;
  for(i &lt;- 0 until count){ &#13;
    a(i) = Price(BigDecimal(Random.nextInt())) &#13;
  } &#13;
  a &#13;
} &#13;
</pre><p>The generated bytecode is as follows:</p><pre class="programlisting">public highperfscala.anyval.ValueClasses$$anonfun$newPriceArray$1(highperfscala.anyval.ValueClasses$Price[]); &#13;
    Code: &#13;
       0: aload_0 &#13;
       1: aload_1 &#13;
       2: putfield      #29  // Field a$1:[Lhighperfscala/anyval/ValueClasses$Price; &#13;
       5: aload_0 &#13;
       6: invokespecial #80  // Method scala/runtime/AbstractFunction1$mcVI$sp."&lt;init&gt;":()V &#13;
       9: return &#13;
 &#13;
public void apply$mcVI$sp(int); &#13;
    Code: &#13;
       0: aload_0 &#13;
       1: getfield      #29  // Field a$1:[Lhighperfscala/anyval/ValueClasses$Price; &#13;
       4: iload_1 &#13;
       5: new           #31  // class highperfscala/anyval/ValueClasses$Price &#13;
       // omitted for brevity &#13;
      21: invokevirtual #55  // Method scala/math/BigDecimal$.apply:(I)Lscala/math/BigDecimal; &#13;
      24: invokespecial #59  // Method highperfscala/anyval/ValueClasses$Price."&lt;init&gt;":(Lscala/math/BigDecimal;)V &#13;
      27: aastore &#13;
      28: return &#13;
</pre><p>Notice how <code class="literal">mcVI$sp</code> is invoked from <code class="literal">newPriceArray</code>, and this creates a new instance of <code class="literal">ValueClasses$Price</code> at the <code class="literal">5</code> instruction.</p><p>As turning a single field case class into a value class is as trivial as extending the <code class="literal">AnyVal</code> trait, we recommend that you always use <code class="literal">AnyVal</code> wherever possible. The overhead is quite low, and it generate high benefits in terms of garbage collection's performance. To learn more about value classes, their limitations, and use cases, you can find detailed descriptions at <a class="ulink" href="http://docs.scala-lang.org/overviews/core/value-classes.html">http://docs.scala-lang.org/overviews/core/value-classes.html</a>.</p></div><div class="section" title="Tagged types - an alternative to value classes"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec22"/>Tagged types - an alternative to value classes</h2></div></div></div><p>Value classes are an easy to use tool, and they can yield great improvements in terms of performance. However, they come with a constraining set of conditions, which can make them impossible to use in certain cases. We will conclude this section with a glance at an interesting alternative by leveraging the tagged type feature that is implemented by the <code class="literal">Scalaz</code> library (<a class="ulink" href="https://github.com/scalaz/scalaz">https://github.com/scalaz/scalaz</a>).</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note21"/>Note</h3><p>The <code class="literal">Scalaz</code> implementation of tagged types is inspired by another Scala library, named <code class="literal">shapeless</code>. The <code class="literal">shapeless</code> library provides tools to write type-safe, generic code with minimal boilerplate. While we will not explore <code class="literal">shapeless</code>, we encourage you to learn more about the project at <a class="ulink" href="https://github.com/milessabin/shapeless">https://github.com/milessabin/shapeless</a>.</p></div></div><p>Tagged types are another way to enforce compile-type checking without incurring the cost of instance instantiation. They rely on the <code class="literal">Tagged</code> structural type and the <code class="literal">@@</code> type alias that are defined in the <code class="literal">Scalaz</code> library, as follows:</p><pre class="programlisting">type Tagged[U] = { type Tag = U } &#13;
type @@[T, U] = T with Tagged[U] &#13;
</pre><p>Let's rewrite part of our code to leverage tagged types with our <code class="literal">Price</code> object:</p><pre class="programlisting">object TaggedTypes { &#13;
 &#13;
  sealed trait PriceTag &#13;
  type Price = BigDecimal @@ PriceTag &#13;
 &#13;
  object Price { &#13;
    def newPrice(p: BigDecimal): Price = &#13;
      Tag[BigDecimal, PriceTag](p) &#13;
 &#13;
    def lowerThan(a: Price, b: Price): Boolean = &#13;
      Tag.unwrap(a) &lt; Tag.unwrap(b) &#13;
  } &#13;
} &#13;
</pre><p>Let's perform a short walkthrough of the code snippet. We will define a <code class="literal">PriceTag</code> sealed trait that we will use to tag our instances, a <code class="literal">Price</code> type alias is created and defined as a <code class="literal">BigDecimal</code> object tagged with <code class="literal">PriceTag</code>. The <code class="literal">Price</code> object defines useful methods, including the <code class="literal">newPrice</code> factory function that is used to tag a given <code class="literal">BigDecimal</code> object and return a <code class="literal">Price</code> object (that is, a tagged <code class="literal">BigDecimal </code>object). We will also implement an equivalent to the <code class="literal">lowerThan</code> method. This function takes two <code class="literal">Price</code> objects (that is, two tagged <code class="literal">BigDecimal</code> objects), extracts the content of the tags that are two <code class="literal">BigDecimal</code> objects, and compares them.</p><p>Using our new <code class="literal">Price</code> type, we rewrite the same <code class="literal">newPriceArray</code> method that we previously looked at (the code is omitted for brevity, but you can refer to it in the attached source code), and print the following generated bytecode:</p><pre class="programlisting">public void apply$mcVI$sp(int); &#13;
    Code: &#13;
       0: aload_0 &#13;
       1: getfield      #29  // Field a$1:[Ljava/lang/Object; &#13;
       4: iload_1 &#13;
       5: getstatic     #35  // Field highperfscala/anyval/TaggedTypes$Price$.MODULE$:Lhighperfscala/anyval/TaggedTypes$Price$; &#13;
       8: getstatic     #40  // Field scala/package$.MODULE$:Lscala/package$; &#13;
      11: invokevirtual #44  // Method scala/package$.BigDecimal:()Lscala/math/BigDecimal$; &#13;
      14: getstatic     #49  // Field scala/util/Random$.MODULE$:Lscala/util/Random$; &#13;
      17: invokevirtual #53  // Method scala/util/Random$.nextInt:()I &#13;
      20: invokevirtual #58  // Method scala/math/BigDecimal$.apply:(I)Lscala/math/BigDecimal; &#13;
      23: invokevirtual #62  // Method highperfscala/anyval/TaggedTypes$Price$.newPrice:(Lscala/math/BigDecimal;)Ljava/lang/Object; &#13;
      26: aastore &#13;
      27: return &#13;
</pre><p>In this version, we no longer see an instantiation of <code class="literal">Price</code>, even though we are assigning it to an array. The tagged <code class="literal">Price</code> implementation involves a runtime cast, but we anticipate that the cost of this cast will be less than the instance allocations (and garbage collection) observed in the previous value class <code class="literal">Price</code> strategy. We will look  at tagged types again later in this chapter, and use them to replace a well-known tool of the standard library: the <code class="literal">Option</code>.</p></div></div></div>
<div class="section" title="Specialization"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec19"/>Specialization</h1></div></div></div><p>To understand the significance of specialization, it is important to first grasp the concept of object boxing. The JVM defines primitive types (<code class="literal">boolean</code>, <code class="literal">byte</code>, <code class="literal">char</code>, <code class="literal">float</code>, <code class="literal">int</code>, <code class="literal">long</code>, <code class="literal">short</code>, and <code class="literal">double</code>) that are stack-allocated rather than heap-allocated. When a generic type is introduced, for example, <code class="literal">scala.collection.immutable.List</code>, the JVM references an object equivalent, instead of a primitive type. In this example, an instantiated list of integers would be heap-allocated objects rather than integer primitives. The process of converting a primitive to its object equivalent is called boxing, and the reverse process is called unboxing. Boxing is a relevant concern for performance-sensitive programming because boxing involves heap allocation. In performance-sensitive code that performs numerical computations, the cost of boxing and unboxing can can create significant performance slowdowns. Consider the following example to illustrate boxing overhead:</p><pre class="programlisting">List.fill(10000)(2).map(_* 2) &#13;
</pre><p>Creating the list via <code class="literal">fill</code> yields 10,000 heap allocations of the integer object. Performing the multiplication in <code class="literal">map</code> requires 10,000 unboxings to perform multiplication and then 10,000 boxings to add the multiplication result into the new list. From this simple example, you can imagine how critical section arithmetic will be slowed down due to boxing or unboxing operations.</p><p>As shown in Oracle's tutorial on boxing at <a class="ulink" href="https://docs.oracle.com/javase/tutorial/java/data/autoboxing.html">https://docs.oracle.com/javase/tutorial/java/data/autoboxing.html</a>, boxing in Java and also in Scala happens transparently. This means that, without careful profiling or bytecode analysis, it is difficult to discern where you are paying the cost for object boxing. To ameliorate this problem, Scala provides a feature named specialization. Specialization refers to the compile-time process of generating duplicate versions of a generic trait or class that refer directly to a primitive type instead of the associated object wrapper. At runtime, the compiler-generated version of the generic class (or, as it is commonly referred to, the specialized version of the class) is instantiated. This process eliminates the runtime cost of boxing primitives, which means that you can define generic abstractions while retaining the performance of a handwritten, specialized implementation.</p><div class="section" title="Bytecode representation"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec23"/>Bytecode representation</h2></div></div></div><p>Let's look at a concrete example to better understand how the specialization process works. Consider a naive, generic representation of the number of shares purchased, as follows:</p><pre class="programlisting">case class ShareCount[T](value: T) &#13;
</pre><p>For this example, let's assume that the intended usage is to swap between an integer or long representation of <code class="literal">ShareCount</code>. With this definition, instantiating a long-based <code class="literal">ShareCount</code> instance incurs the cost of boxing, as follows:</p><pre class="programlisting">def newShareCount(l: Long): ShareCount[Long] = ShareCount(l) &#13;
</pre><p>This definition translates to the following bytecode:</p><pre class="programlisting">  public highperfscala.specialization.Specialization$ShareCount&lt;java.lang.Object&gt; newShareCount(long); &#13;
    Code: &#13;
       0: new           #21  // class orderbook/Specialization$ShareCount &#13;
       3: dup &#13;
       4: lload_1 &#13;
       5: invokestatic  #27  // Method scala/runtime/BoxesRunTime.boxToLong:(J)Ljava/lang/Long; &#13;
       8: invokespecial #30  // Method orderbook/Specialization$ShareCount."&lt;init&gt;":(Ljava/lang/Object;)V &#13;
      11: areturn &#13;
</pre><p>In the preceding bytecode, it is clear at instruction <code class="literal">5</code> that the primitive long value is boxed before instantiating the <code class="literal">ShareCount</code> instance. By introducing the <code class="literal">@specialized</code> annotation, we are able to eliminate the boxing by having the compiler provide an implementation of <code class="literal">ShareCount</code> that works with primitive long values. It is possible to specify which types you wish to specialize by supplying a set of types. As defined in the <code class="literal">Specializables</code> trait (<a class="ulink" href="http://www.scala-lang.org/api/current/index.html#scala.Specializable">http://www.scala-lang.org/api/current/index.html#scala.Specializable"</a>), you are able to specialize for all JVM primitives, as well as, <code class="literal">Unit</code> and <code class="literal">AnyRef</code>. For our example, let's specialize <code class="literal">ShareCount</code> for integers and longs, as follows:</p><pre class="programlisting">case class ShareCount[@specialized(Long, Int) T](value: T) &#13;
</pre><p>With this definition, the bytecode now becomes the following:</p><pre class="programlisting">  public highperfscala.specialization.Specialization$ShareCount&lt;java.lang.Object&gt; newShareCount(long); &#13;
    Code: &#13;
       0: new           #21  // class highperfscala.specialization/Specialization$ShareCount$mcJ$sp &#13;
       3: dup &#13;
       4: lload_1 &#13;
       5: invokespecial #24  // Method highperfscala.specialization/Specialization$ShareCount$mcJ$sp."&lt;init&gt;":(J)V &#13;
       8: areturn &#13;
</pre><p>The boxing disappears and is curiously replaced with a different class name, <code class="literal">ShareCount $mcJ$sp</code>. This is because we are invoking the compiler-generated version of <code class="literal">ShareCount</code> that is specialized for long values. By inspecting the output of <code class="literal">javap</code>, we see that the specialized class generated by the compiler is a subclass of <code class="literal">ShareCount</code>:</p><pre class="programlisting"> public class highperfscala.specialization.Specialization$ShareCount$mcI$sp extends highperfscala.specialization.Specialization$ShareCount&lt;java .lang.Object&gt; &#13;
</pre><p>Bear this specialization implementation detail in mind as we turn to the <span class="emphasis"><em>Performance considerations</em></span> section. The use of inheritance forces tradeoffs to be made in more complex use cases.</p></div><div class="section" title="Performance considerations"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec24"/>Performance considerations</h2></div></div></div><p>At first glance, specialization appears to be a simple panacea for JVM boxing. However, there are several caveats to consider when using specialization. A liberal use of specialization leads to significant increases in compile time and resulting code size. Consider specializing <code class="literal">Function3</code>, which accepts three arguments as input and produces one result. To specialize four arguments across all types (that is, <code class="literal">Byte</code>, <code class="literal">Short</code>, <code class="literal">Int</code>, <code class="literal">Long</code>, <code class="literal">Char</code>, <code class="literal">Float</code>, <code class="literal">Double</code>, <code class="literal">Boolean</code>, <code class="literal">Unit</code>, and <code class="literal">AnyRef</code>) yields 10^4 or 10,000 possible permutations. For this reason, the standard library conserves the application of specialization. In your own use cases, consider carefully which types you wish to specialize. If we specialize <code class="literal">Function3</code> only for <code class="literal">Int</code> and <code class="literal">Long</code>, the number of generated classes shrinks to 2^4 or 16. Specialization involving inheritance requires extra attention because it is trivial to lose specialization when extending a generic class. Consider the following example:</p><pre class="programlisting">  class ParentFoo[@specialized T](t: T) &#13;
  class ChildFoo[T](t: T) extends ParentFoo[T](t) &#13;
 &#13;
  def newChildFoo(i: Int): ChildFoo[Int] = new ChildFoo[Int](i) &#13;
</pre><p>In this scenario, you likely expect that <code class="literal">ChildFoo</code> is defined with a primitive integer. However, as <code class="literal">ChildFoo</code> does not mark its type with the <code class="literal">@specialized</code> annotation, zero specialized classes are created. Here is the bytecode to prove it:</p><pre class="programlisting">  public highperfscala.specialization.Inheritance$ChildFoo&lt;java.lang.Object&gt; newChildFoo(int); &#13;
    Code: &#13;
       0: new           #16  // class highperfscala/specialization/Inheritance$ChildFoo &#13;
       3: dup &#13;
       4: iload_1 &#13;
       5: invokestatic  #22  // Method scala/runtime/BoxesRunTime.boxToInteger:(I)Ljava/lang/Integer; &#13;
       8: invokespecial #25  // Method highperfscala/specialization/Inheritance$ChildFoo."&lt;init&gt;":(Ljava/lang/Object;)V &#13;
      11: areturn &#13;
</pre><p>The next logical step is to add the <code class="literal">@specialized</code> annotation to the definition of <code class="literal">ChildFoo</code>. In doing so, we stumble across a scenario where the compiler warns about the use of specialization, as follows:</p><pre class="programlisting">class ParentFoo must be a trait. Specialized version of class ChildFoo will inherit generic highperfscala.specialization.Inheritance.ParentFoo[Boolean] &#13;
class ChildFoo[@specialized T](t: T) extends ParentFoo[T](t) &#13;
</pre><p>The compiler indicates that you have created a diamond inheritance problem, where the specialized versions of <code class="literal">ChildFoo</code> extend both <code class="literal">ChildFoo</code> and the associated specialized version of <code class="literal">ParentFoo</code>. This issue can be resolved by modeling the problem with a trait, as follows:</p><pre class="programlisting">  trait ParentBar[@specialized T] { &#13;
    def t(): T &#13;
  } &#13;
 &#13;
  class ChildBar[@specialized T](val t: T) extends ParentBar[T] &#13;
 &#13;
  def newChildBar(i: Int): ChildBar[Int] = new ChildBar(i) &#13;
</pre><p>This definition compiles using a specialized version of <code class="literal">ChildBar</code>, as we originally were hoping for, as seen in the following code:</p><pre class="programlisting">  public highperfscala.specialization.Inheritance$ChildBar&lt;java.lang.Object&gt; newChildBar(int); &#13;
    Code: &#13;
       0: new           #32  // class highperfscala/specialization/Inheritance$ChildBar$mcI$sp &#13;
       3: dup &#13;
       4: iload_1 &#13;
       5: invokespecial #35  // Method highperfscala/specialization/Inheritance$ChildBar$mcI$sp."&lt;init&gt;":(I)V &#13;
       8: areturn &#13;
</pre><p>An analogous and equally error-prone scenario is when a generic method is defined around a specialized type. Consider the following definition:</p><pre class="programlisting">  class Foo[T](t: T) &#13;
 &#13;
  object Foo { &#13;
    def create[T](t: T): Foo[T] = new Foo(t) &#13;
  } &#13;
 &#13;
  def boxed: Foo[Int] = Foo.create(1) &#13;
</pre><p>Here, the definition of <code class="literal">create</code> is analogous to the child class from the inheritance example. Instances of <code class="literal">Foo</code> wrapping a primitive that are instantiated from the <code class="literal">create</code> method will be boxed. The following bytecode demonstrates how <code class="literal">boxed</code> leads to heap allocations:</p><pre class="programlisting">  public highperfscala.specialization.MethodReturnTypes$Foo&lt;java.lang.Object&gt; boxed(); &#13;
    Code: &#13;
       0: getstatic     #19  // Field highperfscala/specialization/MethodReturnTypes$Foo$.MODULE$:Lhighperfscala/specialization/MethodReturnTypes$Foo$; &#13;
       3: iconst_1 &#13;
       4: invokestatic  #25  // Method scala/runtime/BoxesRunTime.boxToInteger:(I)Ljava/lang/Integer; &#13;
       7: invokevirtual #29  // Method highperfscala/specialization/MethodReturnTypes$Foo$.create:(Ljava/lang/Object;)Lhighperfscala/specialization/MethodReturnTypes$Foo; &#13;
      10: areturn &#13;
</pre><p>The solution is to apply the <code class="literal">@specialized</code> annotation at the call site, as follows:</p><pre class="programlisting">def createSpecialized[@specialized T](t: T): Foo[T] = new Foo(t) &#13;
</pre><p>One final interesting scenario is when specialization is used with multiple types and one of the types extends <code class="literal">AnyRef</code> or is a value class. To illustrate this scenario, consider the following example:</p><pre class="programlisting">  case class ShareCount(value: Int) extends AnyVal &#13;
  case class ExecutionCount(value: Int) &#13;
 &#13;
  class Container2[@specialized X, @specialized Y](x: X, y: Y) &#13;
 &#13;
  def shareCount = new Container2(ShareCount(1), 1) &#13;
 &#13;
  def executionCount = new Container2(ExecutionCount(1), 1) &#13;
 &#13;
  def ints = new Container2(1, 1) &#13;
</pre><p>In this example, which methods do you expect to box the second argument to <code class="literal">Container2</code>? For brevity, we omit the bytecode, but you can easily inspect it yourself. As it turns out, <code class="literal">shareCount</code> and <code class="literal">executionCount</code> box the integer. The compiler does not generate a specialized version of <code class="literal">Container2</code> that accepts a primitive integer and a value extending <code class="literal">AnyVal</code> (for example, <code class="literal">ExecutionCount</code>). The <code class="literal">shareCount</code> method also causes boxing due to the order in which the compiler removes the value class type information from the source code. In both scenarios, the workaround is to define a case class that is specific to a set of types (for example, <code class="literal">ShareCount</code> and <code class="literal">Int</code>). Removing the generics allows the compiler to select the primitive types.</p><p>The conclusion to draw from these examples is that specialization requires extra focus to be used throughout an application without boxing. As the compiler is unable to infer scenarios where you accidentally forgot to apply the <code class="literal">@specialized</code> annotation, it fails to raise a warning. This places the onus on you to be vigilant about profiling and inspecting bytecode to detect scenarios where specialization is incidentally dropped.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note22"/>Note</h3><p>To combat some of the shortcomings that specialization brings, there is a compiler plugin under active development, named miniboxing, at <a class="ulink" href="http://scala-miniboxing.org/">http://scala-miniboxing.org/</a>. This compiler plugin applies a different strategy that involves encoding all primitive types into a long value and carrying metadata to recall the original type. For example, <code class="literal">boolean</code> can be represented in a <code class="literal">long</code> using a single bit to signal true or false. With this approach, performance is qualitatively similar to specialization while producing orders of magnitude fewer classes for large permutations. Additionally, miniboxing is able to more robustly handle inheritance scenarios and can warn when boxing will occur. While the implementations of specialization and miniboxing differ, the end user usage is quite similar. Like specialization, you must add appropriate annotations to activate the miniboxing plugin. To learn more about the plugin, you can view the tutorials on the miniboxing project site.</p></div></div><p>The extra focus to ensure specialization produces heap allocation free code is worthwhile because of the performance wins in performance-sensitive code. To drive home the value of specialization, consider the following microbenchmark that computes the cost of a trade by multiplying share count with execution price. For simplicity, primitive types are used directly instead of value classes. Of course, in production code this would never happen:</p><pre class="programlisting">@BenchmarkMode(Array(Throughput)) &#13;
@OutputTimeUnit(TimeUnit.SECONDS) &#13;
@Warmup(iterations = 3, time = 5, timeUnit = TimeUnit.SECONDS) &#13;
@Measurement(iterations = 30, time = 10, timeUnit = TimeUnit.SECONDS) &#13;
@Fork(value = 1, warmups = 1, jvmArgs = Array("-Xms1G", "-Xmx1G")) &#13;
class SpecializationBenchmark { &#13;
 &#13;
  @Benchmark &#13;
  def specialized(): Double = &#13;
    specializedExecution.shareCount.toDouble * specializedExecution.price &#13;
 &#13;
  @Benchmark &#13;
  def boxed(): Double = &#13;
    boxedExecution.shareCount.toDouble * boxedExecution.price &#13;
} &#13;
 &#13;
object SpecializationBenchmark { &#13;
  class SpecializedExecution[@specialized(Int) T1, @specialized(Double) T2]( &#13;
    val shareCount: Long, val price: Double) &#13;
  class BoxingExecution[T1, T2](val shareCount: T1, val price: T2) &#13;
 &#13;
  val specializedExecution: SpecializedExecution[Int, Double] = &#13;
    new SpecializedExecution(10l, 2d) &#13;
  val boxedExecution: BoxingExecution[Long, Double] = new BoxingExecution(10l, 2d) &#13;
} &#13;
</pre><p>In this benchmark, two versions of a generic execution class are defined. <code class="literal">SpecializedExecution</code> incurs zero boxing when computing the total cost because of specialization, while <code class="literal">BoxingExecution</code> requires object boxing and unboxing to perform the arithmetic. The microbenchmark is invoked with the following parameterization:</p><pre class="programlisting">
<span class="strong"><strong>sbt 'project chapter3' 'jmh:run SpecializationBenchmark -foe true'</strong></span>
</pre><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note23"/>Note</h3><p>We configure this JMH benchmark via annotations that are placed at the class level in the code. This is different from what we saw in <a class="link" href="ch02.html" title="Chapter 2.  Measuring Performance on the JVM">Chapter 2</a>, <span class="emphasis"><em>Measuring Performance on the JVM,</em></span> where we used command-line arguments. Annotations have the advantage of setting proper defaults for your benchmark, and simplifying the command-line invocation. It is still possible to override the values in the annotation with command-line arguments. We use the  <code class="literal">-foe</code> command-line argument to enable failure on error because there is no annotation to control this behavior. In the rest of this book, we will parameterize JMH with annotations and omit the annotations in the code samples because we always use the same values.</p></div></div><p>The results are summarized in the following table:</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/></colgroup><thead><tr><th>
<p><span class="strong"><strong>Benchmark</strong></span></p>
</th><th>
<p><span class="strong"><strong>Throughput (ops per second)</strong></span></p>
</th><th>
<p><span class="strong"><strong>Error as percentage of throughput</strong></span></p>
</th></tr></thead><tbody><tr><td>
<p>
<code class="literal">boxed</code>
</p>
</td><td>
<p>251,534,293.11</p>
</td><td>
<p>±2.23</p>
</td></tr><tr><td>
<p>
<code class="literal">specialized</code>
</p>
</td><td>
<p>302,371,879.84</p>
</td><td>
<p>±0.87</p>
</td></tr></tbody></table></div><p>This microbenchmark indicates that the specialized implementation yields approximately 17% higher throughput. By eliminating boxing in a critical section of the code, there is an order of magnitude performance improvement available through the judicious usage of specialization. For performance-sensitive arithmetic, this benchmark provides justification for the extra effort that is required to ensure that specialization is applied properly.</p></div></div>
<div class="section" title="Tuples"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec20"/>Tuples</h1></div></div></div><p>First-class tuple support in Scala simplifies use cases where multiple values need to be grouped together. With tuples, you can elegantly return multiple values using a concise syntax without defining a case class. The following section shows how the compiler translates Scala tuples.</p><div class="section" title="Bytecode representation"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec25"/>Bytecode representation</h2></div></div></div><p>Let's look at how the JVM handles creating a tuple to understand how the JVM supports tuples better. To develop our intuition, consider creating a tuple with an arity of two, as follows:</p><pre class="programlisting">def tuple2: (Int, Double) = (1, 2.0) &#13;
</pre><p>The corresponding bytecode for this method is as follows:</p><pre class="programlisting">  public scala.Tuple2&lt;java.lang.Object, java.lang.Object&gt; tuple2(); &#13;
    Code: &#13;
       0: new           #36  // class scala/Tuple2$mcID$sp &#13;
       3: dup &#13;
       4: iconst_1 &#13;
       5: ldc2_w        #37  // double 2.0d &#13;
       8: invokespecial #41  // Method scala/Tuple2$mcID$sp."&lt;init&gt;":(ID)V &#13;
      11: areturn &#13;
</pre><p>This bytecode shows that the compiler desugared the parenthesis tuple definition syntax into the allocation of a class named <code class="literal">Tuple2</code>. There is a tuple class that is defined for each supported arity (for example, <code class="literal">Tuple5</code> supports five members) up to <code class="literal">Tuple22</code>. The bytecode also shows at the  <code class="literal">4</code> and <code class="literal">5</code> instructions that the primitive versions of <code class="literal">Int</code> and <code class="literal">Double</code> are used to allocate this <code class="literal">tuple</code> instance.</p></div><div class="section" title="Performance considerations"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec26"/>Performance considerations</h2></div></div></div><p>In the preceding example, <code class="literal">Tuple2</code> avoids the boxing of primitives due to specialization on the two generic types. It is often convenient to tuple multiple values together because of Scala's expressive tupling syntax. However, this leads to excessive memory allocation because tuples with an arity larger than two are not specialized. Here is an example to illustrate this concern:</p><pre class="programlisting">def tuple3: (Int, Double, Int) = (1, 2.0, 3) &#13;
</pre><p>This definition is analogous to the first tuple definition that we reviewed, except that there is now an arity of three. This definition produces the following bytecode:</p><pre class="programlisting">  public scala.Tuple3&lt;java.lang.Object, java.lang.Object, java.lang.Object&gt; tuple3(); &#13;
    Code: &#13;
       0: new           #45  // class scala/Tuple3 &#13;
       3: dup &#13;
       4: iconst_1 &#13;
       5: invokestatic  #24  // Method scala/runtime/BoxesRunTime.boxToInteger:(I)Ljava/lang/Integer; &#13;
       8: ldc2_w        #37  // double 2.0d &#13;
      11: invokestatic  #49  // Method scala/runtime/BoxesRunTime.boxToDouble:(D)Ljava/lang/Double; &#13;
      14: iconst_3 &#13;
      15: invokestatic  #24  // Method scala/runtime/BoxesRunTime.boxToInteger:(I)Ljava/lang/Integer; &#13;
      18: invokespecial #52  // Method scala/Tuple3."&lt;init&gt;":(Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/Object;)V &#13;
      21: areturn &#13;
</pre><p>In this bytecode, the absence of specialization is clear because of the presence of integer and double boxing. If you are working on a performance-sensitive region of your application and find occurrences of tuples with an arity of three or larger, you should consider defining a case class to avoid the boxing overhead. The definition of your case class will not have any generics. This enables the JVM to use primitives instead of allocating objects on the heap for the primitive tuple members.</p><p>Even when using <code class="literal">Tuple2</code>, it is still possible that you are incurring the cost of boxing. Consider the following snippet:</p><pre class="programlisting">case class Bar(value: Int) extends AnyVal &#13;
def tuple2Boxed: (Int, Bar) = (1, Bar(2)) &#13;
</pre><p>Given what we know about the bytecode representation of Tuple2 and value classes, we expect the bytecode for this method to be two stack-allocated integers. Unfortunately, in this case, the resulting bytecode is as follows:</p><pre class="programlisting">  public scala.Tuple2&lt;java.lang.Object, highperfscala.patternmatch.PatternMatching$Bar&gt; tuple2Boxed(); &#13;
    Code: &#13;
       0: new           #18  // class scala/Tuple2 &#13;
       3: dup &#13;
       4: iconst_1 &#13;
       5: invokestatic  #24  // Method scala/runtime/BoxesRunTime.boxToInteger:(I)Ljava/lang/Integer; &#13;
       8: new           #26  // class highperfscala.patternmatch/PatternMatching$Bar &#13;
      11: dup &#13;
      12: iconst_2 &#13;
      13: invokespecial #29  // Method highperfscala.patternmatch/PatternMatching$Bar."&lt;init&gt;":(I)V &#13;
      16: invokespecial #32  // Method scala/Tuple2."&lt;init&gt;":(Ljava/lang/Object;Ljava/lang/Object;)V &#13;
      19: areturn &#13;
</pre><p>In the preceding bytecode, we see that the integer is boxed and an instance of Bar is instantiated. This example is analogous to the final specialization example that we investigated involving <code class="literal">Container2</code>. Looking back at that example, it should be evident that <code class="literal">Container2</code> is a close analog to Tuple2. As before, due to how specialization is implemented by the compiler, the compiler is unable to avoid boxing in this scenario. If you are faced with performance-sensitive code, the workaround remains defining a case class. Here is proof that defining a case class erases the undesired value class instantiation and primitive boxing:</p><pre class="programlisting"> case class IntBar(i: Int, b: Bar) &#13;
 def intBar: IntBar = IntBar(1, Bar(2)) &#13;
</pre><p>This definition produces the following bytecode:</p><pre class="programlisting">  public highperfscala.patternmatch.PatternMatching$IntBar intBar(); &#13;
    Code: &#13;
       0: new           #18  // class highperfscala.patternmatch/PatternMatching$IntBar &#13;
       3: dup &#13;
       4: iconst_1 &#13;
       5: iconst_2 &#13;
       6: invokespecial #21  // Method highperfscala.patternmatch/PatternMatching$IntBar."&lt;init&gt;":(II)V &#13;
       9: areturn &#13;
</pre><p>Note that <code class="literal">IntBar </code>is not defined as a value class because it has two parameters. In contrast to the tuple definition, there is neither boxing nor any reference to the <code class="literal">Bar</code> value class. In this scenario, defining a case class is a performance win for performance-sensitive code.</p></div></div>
<div class="section" title="Pattern matching"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec21"/>Pattern matching</h1></div></div></div><p>For programmers who are new to Scala, pattern matching is often one of the language features that is the simplest to understand, but it also unlocks new ways to think about writing software. This powerful mechanism enables you to match on disparate types with compile-time safety using an elegant syntax. Given how central this technique is to writing Scala in the functional paradigm, it is important to consider its runtime overhead.</p><div class="section" title="Bytecode representation"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec27"/>Bytecode representation</h2></div></div></div><p>Let's consider an example that involves order processing with an algebraic data type representing the possible sides of an order:</p><pre class="programlisting">  sealed trait Side &#13;
  case object Buy extends Side &#13;
  case object Sell extends Side &#13;
  def handleOrder(s: Side): Boolean = s match { &#13;
    case Buy =&gt; true &#13;
    case Sell =&gt; false &#13;
  } &#13;
</pre><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note24"/>Note</h3><p>The terminology <span class="strong"><strong>algebraic data type</strong></span> (<span class="strong"><strong>ADT</strong></span>) is a more formal way of referring to a sealed trait and its cases. For example, <code class="literal">Side</code>, <code class="literal">Buy</code>, and <code class="literal">Sell</code> form an ADT. For our purposes, an ADT defines a closed set of cases. For <code class="literal">Side</code>, the enclosed cases are <code class="literal">Buy</code> and <code class="literal">Sell</code>. The sealed modifier provides closed set semantics because it disallows the extension of <code class="literal">Side</code> in separate source files. The closed set semantics implied by an ADT is what allows the compiler to infer whether or not a pattern match statement is exhaustive. If you are interested in studying another example of an ADT, view the order book commands defined in <a class="link" href="ch02.html" title="Chapter 2.  Measuring Performance on the JVM">Chapter</a>
<a class="link" href="ch02.html" title="Chapter 2.  Measuring Performance on the JVM">2</a>, <span class="emphasis"><em>Measuring Performance on the JVM</em></span>.</p></div></div><p>As shown in the following bytecode, pattern matching is desugared into a set of if statements:</p><pre class="programlisting"> public boolean handleOrder(highperfscala.patternmatch.PatternMatching$Side); &#13;
    Code: &#13;
       0: aload_1 &#13;
       1: astore_2 &#13;
       2: getstatic     #148  // Field highperfscala.patternmatch/PatternMatching$Buy$.MODULE$:Lhighperfscala.patternmatch/PatternMatching$Buy$; &#13;
       5: aload_2 &#13;
       6: invokevirtual #152  // Method java/lang/Object.equals:(Ljava/lang/Object;)Z &#13;
       9: ifeq          17 &#13;
      12: iconst_1 &#13;
      13: istore_3 &#13;
      14: goto          29 &#13;
      17: getstatic     #157  // Field highperfscala.patternmatch/PatternMatching$Sell$.MODULE$:Lhighperfscala.patternmatch/PatternMatching$Sell$; &#13;
      20: aload_2 &#13;
      21: invokevirtual #152  // Method java/lang/Object.equals:(Ljava/lang/Object;)Z &#13;
      24: ifeq          31 &#13;
      27: iconst_0 &#13;
      28: istore_3 &#13;
      29: iload_3 &#13;
      30: ireturn &#13;
      31: new           #159  // class scala/MatchError &#13;
      34: dup &#13;
      35: aload_2 &#13;
      36: invokespecial #160  // Method scala/MatchError."&lt;init&gt;":(Ljava/lang/Object;)V &#13;
      39: athrow &#13;
</pre><p>Inspecting the bytecode shows how the Scala compiler is able to desugar pattern match expressions into a set of efficient if statements with the <code class="literal">ifeq</code> instructions at the <code class="literal">9</code> and <code class="literal">24</code> indexes. This an illustrative example of how Scala is able to provide expressive and elegant first-class language features that retain efficient bytecode equivalents.</p></div><div class="section" title="Performance considerations"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec28"/>Performance considerations</h2></div></div></div><p>Pattern matching against values that contain state (for example, a case class) imposes additional runtime costs that are not immediately clear when looking at the Scala source code. Consider the following extension to the previous example that introduces state:</p><pre class="programlisting">  sealed trait Order &#13;
  case class BuyOrder(price: Double) extends Order &#13;
  case class SellOrder(price: Double) extends Order &#13;
  def handleOrder(o: Order): Boolean = o match { &#13;
    case BuyOrder(price) if price &gt; 2.0 =&gt; true &#13;
    case BuyOrder(_) =&gt; false &#13;
    case SellOrder(_) =&gt; false &#13;
  } &#13;
</pre><p>Here, the example is more complicated because the instance type must be identified for all three cases with the added complexity of a predicate on the <code class="literal">BuyOrder</code> price in the first case. In the following, we look at a snippet of the <code class="literal">scalac</code> output with all Scala-specific features removed:</p><pre class="programlisting">        case10(){ &#13;
          if (x1.$isInstanceOf[highperfscala.patternmatch.PatternMatching$BuyOrder]()) &#13;
            { &#13;
              rc8 = true; &#13;
              x2 = (x1.$asInstanceOf[highperfscala.patternmatch.PatternMatching$BuyOrder](): highperfscala.patternmatch.PatternMatching$BuyOrder); &#13;
              { &#13;
                val price: Double = x2.price(); &#13;
                if (price.&gt;(2.0)) &#13;
                  matchEnd9(true) &#13;
                else &#13;
                  case11() &#13;
              } &#13;
            } &#13;
          else &#13;
            case11() &#13;
        }; &#13;
        case11(){ &#13;
          if (rc8) &#13;
            matchEnd9(false) &#13;
          else &#13;
            case12() &#13;
        }; &#13;
</pre><p>This desugaring illustrates several interesting points about the Scala compiler. Identifying the type of <code class="literal">Order</code> utilizes <code class="literal">isInstanceOf</code> from <code class="literal">java.lang.Object</code>, which maps to the <code class="literal">instanceOf</code> bytecode instruction. Casting, by way of <code class="literal">asInstanceOf</code>, coerces the <code class="literal">Order</code> into either a <code class="literal">BuyOrder</code> price or a <code class="literal">SellOrder</code>.  The first takeaway is that pattern matching types carrying state incurs the runtime cost of type-checking and casting.</p><p>A second insight is that the Scala compiler is able to optimize away the instance checking for the second pattern match by creating a Boolean variable named <code class="literal">rc8</code> to determine whether a <code class="literal">BuyOrder</code> was discovered. This neat optimization is simple to handwrite, but it removes the elegance and simplicity of pattern matching. This is another example of how the compiler is able to produce efficient bytecode from expressive, high-level code.</p><p>From the preceding examples, it is now clear that pattern matches are compiled to if statements. One performance consideration for critical path code is the ordering of pattern match statements. If your code has five pattern match statements and the fifth pattern is the most frequently accessed, then your code is paying the price of always evaluating four other branches. Let's devise a JMH microbenchmark that estimates the linear access cost of pattern matching. Each benchmark defines ten pattern matches using different values (for example, the value class, the integer literal, the case class, and so on). For each benchmark, the matched index is swept to show the cost of accessing the first, the fifth, and the the tenth pattern match statement. Here is the benchmark definition:</p><pre class="programlisting">class PatternMatchingBenchmarks { &#13;
 &#13;
  @Benchmark &#13;
  def matchIntLiterals(i: PatternMatchState): Int = i.matchIndex match { &#13;
    case 1 =&gt; 1 &#13;
    case 2 =&gt; 2 &#13;
    case 3 =&gt; 3 &#13;
    case 4 =&gt; 4 &#13;
    case 5 =&gt; 5 &#13;
    case 6 =&gt; 6 &#13;
    case 7 =&gt; 7 &#13;
    case 8 =&gt; 8 &#13;
    case 9 =&gt; 9 &#13;
    case 10 =&gt; 10 &#13;
  } &#13;
 &#13;
  @Benchmark &#13;
  def matchIntVariables(ii: PatternMatchState): Int = ii.matchIndex match { &#13;
    case `a` =&gt; 1 &#13;
    case `b` =&gt; 2 &#13;
    case `c` =&gt; 3 &#13;
    case `d` =&gt; 4 &#13;
    case `e` =&gt; 5 &#13;
    case `f` =&gt; 6 &#13;
    case `g` =&gt; 7 &#13;
    case `h` =&gt; 8 &#13;
    case `i` =&gt; 9 &#13;
    case `j` =&gt; 10 &#13;
  } &#13;
 &#13;
  @Benchmark &#13;
  def matchAnyVal(i: PatternMatchState): Int = CheapFoo(i.matchIndex) match { &#13;
    case CheapFoo(1) =&gt; 1 &#13;
    case CheapFoo(2) =&gt; 2 &#13;
    case CheapFoo(3) =&gt; 3 &#13;
    case CheapFoo(4) =&gt; 4 &#13;
    case CheapFoo(5) =&gt; 5 &#13;
    case CheapFoo(6) =&gt; 6 &#13;
    case CheapFoo(7) =&gt; 7 &#13;
    case CheapFoo(8) =&gt; 8 &#13;
    case CheapFoo(9) =&gt; 9 &#13;
    case CheapFoo(10) =&gt; 10 &#13;
  } &#13;
 &#13;
  @Benchmark &#13;
  def matchCaseClass(i: PatternMatchState): Int = &#13;
    ExpensiveFoo(i.matchIndex) match { &#13;
      case ExpensiveFoo(1) =&gt; 1 &#13;
      case ExpensiveFoo(2) =&gt; 2 &#13;
      case ExpensiveFoo(3) =&gt; 3 &#13;
      case ExpensiveFoo(4) =&gt; 4 &#13;
      case ExpensiveFoo(5) =&gt; 5 &#13;
      case ExpensiveFoo(6) =&gt; 6 &#13;
      case ExpensiveFoo(7) =&gt; 7 &#13;
      case ExpensiveFoo(8) =&gt; 8 &#13;
      case ExpensiveFoo(9) =&gt; 9 &#13;
      case ExpensiveFoo(10) =&gt; 10 &#13;
    } &#13;
} &#13;
 &#13;
object PatternMatchingBenchmarks { &#13;
 &#13;
  case class CheapFoo(value: Int) extends AnyVal &#13;
  case class ExpensiveFoo(value: Int) &#13;
 &#13;
  private val (a, b, c, d, e, f, g, h, i, j) = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10) &#13;
 &#13;
  @State(Scope.Benchmark) &#13;
  class PatternMatchState { &#13;
    @Param(Array("1", "5", "10")) &#13;
    var matchIndex: Int = 0 &#13;
  } &#13;
} &#13;
</pre><p>Performance was evaluated by running 30 trials, each lasting 10 seconds with three warm-up trials, each lasting 5 seconds. Here is the benchmark invocation:</p><pre class="programlisting">
<span class="strong"><strong>sbt 'project chapter3' 'jmh:run PatternMatchingBenchmarks -foe true'</strong></span>
</pre><p>The results are summarized in the following table:</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/><col/><col/></colgroup><tbody><tr><td>
<p>
<span class="strong"><strong>Benchmark</strong></span>
</p>
</td><td>
<p>
<span class="strong"><strong>Index to match</strong></span>
</p>
</td><td>
<p>
<span class="strong"><strong>Throughput (ops per second)</strong></span>
</p>
</td><td>
<p>
<span class="strong"><strong>Error as percentage of throughput</strong></span>
</p>
</td><td>
<p>
<span class="strong"><strong>Throughput change as percentage of base run</strong></span>
</p>
</td></tr><tr><td>
<p>
<code class="literal">matchAnyVal</code>
</p>
</td><td>
<p>1</p>
</td><td>
<p>350,568,900.12</p>
</td><td>
<p>±3.02</p>
</td><td>
<p>0</p>
</td></tr><tr><td>
<p>
<code class="literal">matchAnyVal</code>
</p>
</td><td>
<p>5</p>
</td><td>
<p>291,126,287.45</p>
</td><td>
<p>±2.63</p>
</td><td>
<p>-17</p>
</td></tr><tr><td>
<p>
<code class="literal">matchAnyVal</code>
</p>
</td><td>
<p>10</p>
</td><td>
<p>238,326,567.59</p>
</td><td>
<p>±2.95</p>
</td><td>
<p>-32</p>
</td></tr><tr><td>
<p>
<code class="literal">matchCaseClass</code>
</p>
</td><td>
<p>1</p>
</td><td>
<p>356,567,498.69</p>
</td><td>
<p>±3.66</p>
</td><td>
<p>0</p>
</td></tr><tr><td>
<p>
<code class="literal">matchCaseClass</code>
</p>
</td><td>
<p>5</p>
</td><td>
<p>287,597,483.22</p>
</td><td>
<p>±3.50</p>
</td><td>
<p>-19</p>
</td></tr><tr><td>
<p>
<code class="literal">matchCaseClass</code>
</p>
</td><td>
<p>10</p>
</td><td>
<p>234,989,504.60</p>
</td><td>
<p>±2.60</p>
</td><td>
<p>-34</p>
</td></tr><tr><td>
<p>
<code class="literal">matchIntLiterals</code>
</p>
</td><td>
<p>1</p>
</td><td>
<p>304,242,630.15</p>
</td><td>
<p>±2.95</p>
</td><td>
<p>0</p>
</td></tr><tr><td>
<p>
<code class="literal">matchIntLiterals</code>
</p>
</td><td>
<p>5</p>
</td><td>
<p>314,588,776.07</p>
</td><td>
<p>±3.70</p>
</td><td>
<p>3</p>
</td></tr><tr><td>
<p>
<code class="literal">matchIntLiterals</code>
</p>
</td><td>
<p>10</p>
</td><td>
<p>285,227,574.79</p>
</td><td>
<p>±4.33</p>
</td><td>
<p>-6</p>
</td></tr><tr><td>
<p>
<code class="literal">matchIntVariables</code>
</p>
</td><td>
<p>1</p>
</td><td>
<p>332,377,617.36</p>
</td><td>
<p>±3.28</p>
</td><td>
<p>0</p>
</td></tr><tr><td>
<p>
<code class="literal">matchIntVariables</code>
</p>
</td><td>
<p>5</p>
</td><td>
<p>263,835,356.53</p>
</td><td>
<p>±6.53</p>
</td><td>
<p>-21</p>
</td></tr><tr><td>
<p>
<code class="literal">matchIntVariables</code>
</p>
</td><td>
<p>10</p>
</td><td>
<p>170,460,049.63</p>
</td><td>
<p>±4.20</p>
</td><td>
<p>-49</p>
</td></tr></tbody></table></div><p>The last column takes the first trial of each benchmark when matching the first index as the base case. For trials matching the fifth and tenth indexes, the relative performance drop is displayed. In every case, except matching the fifth index of literal integers, throughput degrades nearly linearly as deeper indexes are matched. The one trial that defies this pattern is the trial matching literal integers. In this trial, performance improves relative to the first index when accessing the fifth index. Upon inspection of the bytecode, we discover that this scenario produces a jump table instead of a set of if statements. Here is a snippet from the generated bytecode:</p><pre class="programlisting">       6: tableswitch   { // 1 to 10 &#13;
                     1: 113 &#13;
                     2: 109 &#13;
                     3: 105 &#13;
                     4: 101 &#13;
                     5: 97 &#13;
                     6: 92 &#13;
                     7: 87 &#13;
                     8: 82 &#13;
                     9: 77 &#13;
                    10: 72 &#13;
               default: 60 &#13;
          } &#13;
</pre><p>This bytecode snippet demonstrates that the JVM converts a pattern match on integer literals to a jump table using the <code class="literal">tableswitch</code> instruction. This is a constant time operation rather than a linear traversal of if statements. Given that the observed error is several percentage points and the observed differences across the three trials are roughly several percentage points, we can deduce that the linear access cost does not apply to this scenario. Instead, matching literal integers at the N<sup>th</sup> index has a constant access cost due to the generated jump table. In contrast, matching an integer variable proves to be nearly twice as expensive at the tenth index. The clear takeaway from this experiment is that, for any pattern match that is generating a series of if statements, there is a linear cost to access the N<sup>th</sup> pattern match statement. If you pattern match at least three cases in performance-sensitive code, consider reviewing the code to determine whether the statement order matches the access frequency.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note25"/>Note</h3><p>Do you have examples of pattern matching containing only two patterns? In scenarios involving only two pattern match statements that directly match a value, the compiler is able to generate an efficient jump table. When matching primitive literals (for example, string literals or integer literals), the compiler is able to generate jump tables for larger pattern matches. Analogous to the <code class="literal">@tailrec</code> annotation, Scala defines a <code class="literal">@switch</code> annotation for you to indicate to the compiler that you expect this pattern match statement to be compiled to a jump table. If the compiler is unable to generate a jump table, and instead it produces a series of if statements, then a warning will be issued. Like the <code class="literal">@tailrec</code> annotation, the compiler will apply the jump table heuristic whether you provide the <code class="literal">@switch</code> annotation or not. In practice, we do not often use this annotation because of its limited applicability, but it is worthwhile to be aware of its existence. The following is an example of an annotated pattern match that compiles to a jump table:</p><div class="informalexample"><pre class="programlisting">def processShareCount(sc: ShareCount): Boolean = 
 (sc: @switch) match { 
 case ShareCount(1) =&gt; true 
 case _ =&gt; false 
}</pre></div></div></div></div></div>
<div class="section" title="Tail recursion"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec22"/>Tail recursion</h1></div></div></div><p>A function is said to be recursive when it calls itself. Recursion is a powerful tool, and it is often used in functional programming. It allows you to break complex problems into smaller subproblems, making them easier to reason through and solve. Recursion also works well with the idea of immutability. Recursive functions provide us with a good way to manage changing state without using mutable structures or reassignable variables. In this section, we focus on the different shortcomings of using recursion on the JVM, and especially in Scala.</p><p>Let's take a look at a simple example of a recursive method. The following snippet shows a <code class="literal">sum</code> method that is used to calculate the sum of a list of integers:</p><pre class="programlisting">def sum(l: List[Int]): Int = l match { &#13;
  case Nil =&gt; 0 &#13;
  case x :: xs =&gt; x + sum(xs) &#13;
} &#13;
</pre><p>The <code class="literal">sum</code> method presented in the preceding code snippet performs what is called head-recursion. The <code class="literal">sum(xs)</code> recursive call is not the last instruction in the function. This method needs the result of the recursive call to compute its own result. Consider the following call:</p><pre class="programlisting">sum(List(1,2,3,4,5))</pre><p>It can be represented as:</p><pre class="programlisting">1 + (sum(List(2,3,4,5))) &#13;
1 + (2 + (sum(List(3,4,5)))) &#13;
1 + (2 + (3 + (sum(List(4,5))))) &#13;
1 + (2 + (3 + (4 + (sum(List(5)))))) &#13;
1 + (2 + (3 + (4 + (5)))) &#13;
1 + (2 + (3 + (9))) &#13;
1 + (2 + (12)) &#13;
1 + (14) &#13;
15 &#13;
</pre><p>Note how each time we perform a recursive call, our function is left hanging, waiting for the right side of the computation to finish to be able to return. As the calling function needs to complete its own computation after receiving the result of the recursive call, a new entry is added to the stack for each call. The stack has a limited size, and nothing prevents us from calling <code class="literal">sum</code> with a very long list. With a sufficiently long list, a call to <code class="literal">sum</code> would result in a <code class="literal">StackOverflowError</code>:</p><pre class="programlisting"><span class="strong"><strong>    $ sbt 'project chapter3' console&#13;
    scala&gt; highperfscala.tailrec.TailRecursion.sum((1 to 1000000).toList)&#13;
    java.lang.StackOverflowError&#13;
      at scala.collection.immutable.Nil$.equals(List.scala:424)&#13;
      at highperfscala.tailrec.TailRecursion$.sum(TailRecursion.scala:12)&#13;
      at highperfscala.tailrec.TailRecursion$.sum(TailRecursion.scala:13)&#13;
      at highperfscala.tailrec.TailRecursion$.sum(TailRecursion.scala:13)&#13;
      at highperfscala.tailrec.TailRecursion$.sum(TailRecursion.scala:13)&#13;
    ...omitted for brevity&#13;
</strong></span></pre><p>The stack trace shows all the recursive calls piling up on the stack, waiting for the result from the following step. This proves that none of the calls to sum were able to complete without first completing the recursive call. Our stack ran out of space before the last call could be performed.</p><p>To avoid this problem, we need to refactor our method to make it tail-recursive. A recursive method is said to be tail-recursive if the recursive call is the last instruction performed. A tail-recursive method can be optimized to turn the series of recursive calls into something similar to a <code class="literal">while</code> loop. This means that only the first call is added to the stack:</p><pre class="programlisting">def tailrecSum(l: List[Int]): Int = { &#13;
  def loop(list: List[Int], acc: Int): Int = list match { &#13;
    case Nil =&gt; acc &#13;
    case x :: xs =&gt; loop(xs, acc + x) &#13;
  } &#13;
  loop(l, 0) &#13;
} &#13;
</pre><p>This new version of <code class="literal">sum</code> is tail-recursive. Note that we create an internal <code class="literal">loop</code> method, which takes the list to sum, as well as an accumulator to compute the current state of the result. The <code class="literal">loop</code> method is tail-recursive because the recursive <code class="literal">loop(xs, acc+x)</code> call is the last instruction. By calculating the accumulator as we iterate, we avoid stacking recursive calls. The initial accumulator value is <code class="literal">0</code>, as follows:</p><pre class="programlisting"><span class="strong"><strong>    scala&gt; highperfscala.tailrec.TailRecursion.tailrecSum((1 to 1000000).toList)&#13;
    res0: Int = 1784293664&#13;
</strong></span></pre><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note26"/>Note</h3><p>We mentioned that recursion is an important aspect of functional programming. However, in practice, you should only rarely have to write your own recursive method, especially when dealing with collections such as <code class="literal">List</code>. The standard API provides already optimized methods that should be preferred. For example, calculating the sum of a list of integers can be written, as follows:</p><p>
<code class="literal">list.foldLeft(0)((acc, x) =&gt; acc + x)</code>
Or when taking advantage of Scala sugar, we can use the following:</p><p>
<code class="literal">list.foldLeft(0)(+)</code>
The <code class="literal">foldLeft</code> function is internally implemented with a <code class="literal">while</code> loop and will not cause a <code class="literal">aStackOverflowError</code> exception.</p><p>Actually, <code class="literal">List</code> has a <code class="literal">sum</code> method, which makes calculating the sum of a list of integers even easier. The <code class="literal">sum </code>method is implemented with <code class="literal">foldLeft</code> and is similar to the preceding code.</p></div></div><div class="section" title="Bytecode representation"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec29"/>Bytecode representation</h2></div></div></div><p>As a matter of fact, the JVM does not support tail-recursion optimization. To make this work, the Scala compiler optimizes tail-recursive methods at compile time and turns them into a <code class="literal">while</code> loop. Let's compare the bytecode that was generated for each implementation.</p><p>Our original, head-recursive <code class="literal">sum</code> method compiled into the following bytecode:</p><pre class="programlisting">public int sum(scala.collection.immutable.List&lt;java.lang.Object&gt;); &#13;
    Code: &#13;
       0: aload_1 &#13;
// omitted for brevity        &#13;
      52: invokevirtual #41  // Method sum:(Lscala/collection/immutable/List;)I &#13;
      55: iadd &#13;
      56: istore_3 &#13;
      57: iload_3 &#13;
      58: ireturn &#13;
// omitted for brevity &#13;
</pre><p>While the tail recursive <code class="literal">loop</code> method produced the following:</p><pre class="programlisting">  private int loop(scala.collection.immutable.List&lt;java.lang.Object&gt;, int); &#13;
    Code: &#13;
       0: aload_1 &#13;
    // omitted for brevity &#13;
      60: goto          0 &#13;
   // omitted for brevity &#13;
</pre><p>Note how the <code class="literal">sum</code> method calls itself with the <code class="literal">invokevirtual</code> instruction at the <code class="literal">52</code> index and still has to perform some instructions with the returned value. On the contrary, the <code class="literal">loop</code> method uses a <code class="literal">goto</code> instruction at the <code class="literal">60</code> index to jump back to the beginning of its block, thus avoiding stacking several recursive calls to itself.</p></div><div class="section" title="Performance considerations"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec30"/>Performance considerations</h2></div></div></div><p>The compiler can only optimize simple tail-recursion cases. Specifically, only self-calling functions where the recursive call is the last instruction. There are many edge cases that could be described as tail-recursive, but they are too complex for the compiler to optimize. To avoid unknowingly writing a nonoptimizable recursive method, you should always annotate your tail-recursive methods with <code class="literal">@tailrec</code>. The <code class="literal">@tailrec</code> annotation is a way to tell the compiler, "I believe you will be able to optimize this recursive method; however, if you cannot, please give me an error at compile time." One thing to keep in mind is that <code class="literal">@tailrec</code> is not asking the compiler to optimize the method, it will do so anyway if it is possible. The annotation is for the developer to make sure the compiler can optimize the recursion.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note27"/>Note</h3><p>At this point, you should realize that all <code class="literal">while</code> loops can be replaced by a tail-recursive method without any loss in performance. If you have been using while loop constructs in Scala, you can reflect on how to replace them with a tail-recursive implementation. Tail recursion eliminates the use of mutable variables.</p></div></div><p>Here is the same <code class="literal">tailrecSum</code> method with the <code class="literal">@tailrec</code> annotation:</p><pre class="programlisting">def tailrecSum(l: List[Int]): Int = { &#13;
  @tailrec &#13;
  def loop(list: List[Int], acc: Int): Int = list match { &#13;
    case Nil =&gt; acc &#13;
    case x :: xs =&gt; loop(xs, acc + x) &#13;
  } &#13;
  loop(l, 0) &#13;
} &#13;
</pre><p>If we attempted to annotate our first, head-recursive, implementation, we would see the following error at compile time:</p><pre class="programlisting"><span class="strong"><strong>    [error] chapter3/src/main/scala/highperfscala/tailrec/TailRecursion.scala:12: could not optimize @tailrec annotated method sum: it contains a recursive call not in tail position&#13;
    [error]   def sum(l: List[Int]): Int = l match {&#13;
    [error]                                ^&#13;
    [error] one error found&#13;
    [error] (chapter3/compile:compileIncremental) Compilation failed&#13;
</strong></span></pre><p>We recommend always using <code class="literal">@tailrec</code> to ensure that your methods can be optimized by the compiler. As the compiler is only able to optimize simple cases of tail-recursion, it is important to ensure at compile time that you did not inadvertently write a nonoptimizable function that may cause a <code class="literal">StackOverflowError</code> exception. We now look at a few cases where the compiler is not able to optimize a recursive method:</p><pre class="programlisting">def sum2(l: List[Int]): Int = { &#13;
 &#13;
 def loop(list: List[Int], acc: Int): Int = list match { &#13;
   case Nil =&gt; acc &#13;
   case x :: xs =&gt; info(xs, acc + x) &#13;
 } &#13;
 def info(list: List[Int], acc: Int): Int = { &#13;
   println(s"${list.size} elements to examine. sum so far: $acc") &#13;
   loop(list, acc) &#13;
 } &#13;
 loop(l, 0) &#13;
} &#13;
</pre><p>The <code class="literal">loop</code> method in <code class="literal">sum2</code> cannot be optimized because the recursion involves two different methods calling each other. If we were to replace the call to <code class="literal">info</code> by its actual implementation, then the optimization would be possible, as follows:</p><pre class="programlisting">def tailrecSum2(l: List[Int]): Int = { &#13;
  @tailrec &#13;
  def loop(list: List[Int], acc: Int): Int = list match { &#13;
    case Nil =&gt; acc &#13;
    case x :: xs =&gt; &#13;
     println(s"${list.size} elements to examine. sum so far: $acc") &#13;
     loop(list, acc) &#13;
 } &#13;
 &#13;
 loop(l, 0) &#13;
} &#13;
</pre><p>A somewhat similar use case involves the compiler's inability to take into account by-name parameters:</p><pre class="programlisting">def sumFromReader(br: BufferedReader): Int = { &#13;
 def read(acc: Int, reader: BufferedReader): Int = { &#13;
   Option(reader.readLine().toInt) &#13;
     .fold(acc)(i =&gt; read(acc + i, reader)) &#13;
 } &#13;
 read(0, br) &#13;
} &#13;
</pre><p>The <code class="literal">read</code> method cannot  be optimized by the compiler because it is unable to use the definition of <code class="literal">Option.fold</code> to understand that the recursive call is effectively in the tail position. If we replace the call to fold by its exact implementation, we can annotate the method, as follows:</p><pre class="programlisting">def tailrecSumFromReader(br: BufferedReader): Int = { &#13;
  @tailrec &#13;
  def read(acc: Int, reader: BufferedReader): Int = { &#13;
    val opt = Option(reader.readLine().toInt) &#13;
    if (opt.isEmpty) acc else read(acc + opt.get, reader) &#13;
  } &#13;
  read(0, br) &#13;
} &#13;
</pre><p>The compiler will also refuse to optimize a nonfinal public method. This is to prevent the risk of a subclass overriding the method with a non-tail-recursive version. A recursive call from the super class may go through the subclass's implementation and break the tail-recursion:</p><pre class="programlisting">class Printer(msg: String) { &#13;
 def printMessageNTimes(n: Int): Unit = { &#13;
   if(n &gt; 0){ &#13;
     println(msg) &#13;
     printMessageNTimes(n - 1) &#13;
   } &#13;
 } &#13;
} &#13;
</pre><p>Attempting to flag the <code class="literal">printMessageNTimes</code> method as tail-recursive yields the following error:</p><pre class="programlisting"><span class="strong"><strong>    [error] chapter3/src/main/scala/highperfscala/tailrec/TailRecursion.scala:74: could not optimize @tailrec annotated method printMessageNTimes: it is neither private nor final so can be overridden&#13;
    [error]     def printMessageNTimes(n: Int): Unit = {&#13;
    [error]         ^&#13;
    [error] one error found&#13;
    [error] (chapter3/compile:compileIncremental) Compilation failed&#13;
</strong></span></pre><p>Another case of recursive methods that cannot be optimized is when the recursive call is part of a try/catch block:</p><pre class="programlisting">def tryCatchBlock(l: List[Int]): Int = { &#13;
 def loop(list: List[Int], acc: Int): Int = list match { &#13;
   case Nil =&gt; acc &#13;
   case x :: xs =&gt; &#13;
     try { &#13;
       loop(xs, acc + x) &#13;
     } catch { &#13;
       case e: IOException =&gt; &#13;
         println(s"Recursion got interrupted by exception") &#13;
         acc &#13;
     } &#13;
 } &#13;
 &#13;
 loop(l, 0) &#13;
} &#13;
</pre><p>In contrast to the prior examples, in this example the compiler is not to blame. The recursive call is not in the tail position. As it is surrounded by a try/catch, the method needs to be ready to receive a potential exception and perform more computations to address it. As proof, we can look at the generated bytecode and observe that the last instructions are related to the try/catch:</p><pre class="programlisting">private final int loop$4(scala.collection.immutable.List, int); &#13;
    Code: &#13;
       0: aload_1 &#13;
      // omitted for brevity       &#13;
      61: new           #43  // class scala/MatchError &#13;
      64: dup &#13;
      65: aload_3 &#13;
      66: invokespecial #46  // Method scala/MatchError."&lt;init&gt;":(Ljava/lang/Object;)V &#13;
      69: athrow &#13;
      // omitted for brevity &#13;
      114: ireturn &#13;
    Exception table: &#13;
       from    to  target type &#13;
          48    61    70   Class java/io/IOException &#13;
</pre><p>We hope that these few examples have convinced you that writing a non-tail-recursive method is an easy mistake to make. Your best defense against this is to always use the <code class="literal">@tailrec</code> annotation to verify your intuition that your method can be optimized.</p></div></div>
<div class="section" title="The Option data type"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec23"/>The Option data type</h1></div></div></div><p>The <code class="literal">Option</code> data type is used pervasively throughout the Scala standard library. Like pattern matching, it is a language feature often adopted early by Scala beginners. The <code class="literal">Option</code> data type provides an elegant way to transform and handle values that are not required, doing away with null checks often found in Java code. We assume you understand and appreciate the value that <code class="literal">Option</code> brings to writing Scala in the functional paradigm, so we will not reiterate its benefits further. Instead, we focus on analyzing its bytecode representation to drive performance insights.</p><div class="section" title="Bytecode representation"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec31"/>Bytecode representation</h2></div></div></div><p>Inspecting the Scala source code, we see that <code class="literal">Option</code> is implemented as an abstract class with the possible outcomes, <code class="literal">Some</code> and <code class="literal">None</code>, extending <code class="literal">Option</code> to encode this relationship. The class definitions with implementations removed are shown for convenience in the following code snippet:</p><pre class="programlisting">sealed abstract class Option[+A] extends Product with Serializable &#13;
final case class Some[+A](x: A) extends Option[A] &#13;
case object None extends Option[Nothing] &#13;
</pre><p>Studying the definitions, we can infer several points about the bytecode representation. Focusing on <code class="literal">Some</code>, we note the absence of extending <code class="literal">AnyVal</code>. As <code class="literal">Option</code> is implemented using inheritance, <code class="literal">Some</code> cannot be a value class due to limitations that we covered in the Value class section. This limitation implies that there is an allocation for each value wrapped as a <code class="literal">Some</code> instance. Furthermore, we observe that <code class="literal">Some</code> is not specialized. From our examination of specialization, we realize that primitives wrapped as <code class="literal">Some</code> instances will be boxed. Here is a simple example to illustrate both concerns:</p><pre class="programlisting">def optionalInt(i: Int): Option[Int] = Some(i) &#13;
</pre><p>In this trivial example, an integer is encoded as a <code class="literal">Some</code> instance to be used as an <code class="literal">Option</code> data type. The following bytecode is produced:</p><pre class="programlisting">  public scala.Option&lt;java.lang.Object&gt; optionalInt(int); &#13;
    Code: &#13;
       0: new           #16  // class scala/Some &#13;
       3: dup &#13;
       4: iload_1 &#13;
       5: invokestatic  #22  // Method scala/runtime/BoxesRunTime.boxToInteger:(I)Ljava/lang/Integer; &#13;
       8: invokespecial #25  // Method scala/Some."&lt;init&gt;":(Ljava/lang/Object;)V &#13;
      11: areturn &#13;
</pre><p>As we expected, there is an object allocation to create a <code class="literal">Some</code> instance, followed by the boxing of the provided integer to construct the <code class="literal">Some</code> instance.</p><p>The <code class="literal">None</code> instance is a simpler case to understand from the bytecode perspective. As <code class="literal">None</code> is defined as a Scala object, there is no instantiation cost to create a <code class="literal">None</code> instance. This makes sense because <code class="literal">None</code> represents a scenario where there is no state to maintain.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note28"/>Note</h3><p>Have you ever considered how the single value, <code class="literal">None</code>, represents no value for all the types? The answer lies in understanding the <code class="literal">Nothing</code> type. The <code class="literal">Nothing</code> type extends all other types, which allows <code class="literal">None</code> to be a subtype of any  <code class="literal">A</code> type. For more insight into the Scala type hierarchy, view this useful Scala language tutorial at <a class="ulink" href="http://docs.scala-lang.org/tutorials/tour/unified-types.html">http://docs.scala-lang.org/tutorials/tour/unified-types.html</a>.</p></div></div></div><div class="section" title="Performance considerations"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec32"/>Performance considerations</h2></div></div></div><p>In any non-performance-sensitive environments, it is sensible to default to using <code class="literal">Option</code> to represent values that are not required. In a performance-sensitive area of the code, the choice becomes more challenging and less clear-cut. Particularly in performance-sensitive code, you must first optimize for correctness and then performance. We suggest always implementing the first version of the problem that you are modeling in the most idiomatic style, which is to say, using <code class="literal">Option</code>. Using the awareness gained from the bytecode representation of <code class="literal">Some</code>, the logical next step is to profile in order to determine whether or not <code class="literal">Option</code> use is the bottleneck. In particular, you are focusing on memory allocation patterns and garbage collection costs. In our experience, there are often other overhead sources present in the code that are more costly than <code class="literal">Option</code> use. Examples include inefficient algorithm implementation, a poorly constructed domain model, or inefficient use of system resources. If, in your case, you have eliminated other sources of inefficiency and are positive that <code class="literal">Option</code> is the source of your performance woes, then you need to take further steps.</p><p>An incremental step towards improved performance might include removing use of the <code class="literal">Option</code> higher-order functions. On the critical path, there can be significant cost savings by replacing higher-order functions with inlined equivalents. Consider the following trivial example that transforms an <code class="literal">Option</code> data type into a <code class="literal">String</code> data type:</p><pre class="programlisting">Option(10).fold("no value")(i =&gt; s"value is $i") &#13;
</pre><p>On the critical path, the following change may yield substantive improvements:</p><pre class="programlisting">val o = Option(10) &#13;
if (o.isDefined) s"value is ${o.get} else "no value" &#13;
</pre><p>Replacing the <code class="literal">fold</code> operation with an if statement saves the cost of creating an anonymous function. It bears repeating that this type of change should only ever be considered after extensive profiling reveals <code class="literal">Option</code> usage to be the bottleneck. While this type of code change is likely to improve your performance, it is verbose and unsafe due to usage of <code class="literal">o.get</code>. When this technique is used judiciously, you may be able to retain use of the <code class="literal">Option</code> data type in critical path code.</p><p>If replacing higher-order <code class="literal">Option</code> function use with inlined and unsafe equivalents fails to sufficiently improve performance, then you need to consider more drastic measures. At this point, profiling should reveal that <code class="literal">Option</code> memory allocation is the bottleneck, preventing you from reaching your performance goals. Faced with this scenario, you have two options (pun intended!) to explore, both of which involve a high cost in terms of time to implement.</p><p>One way to proceed is to admit that, for the critical path, <code class="literal">Option</code> is unsuitable and must be removed from the type signatures and replaced with null checks. This is the most performant approach, but it brings significant maintenance costs because you and all other team members working on the critical path must be cognizant of this modeling decision. If you choose to proceed this way, define clear boundaries for the critical path to isolate null checks to the smallest possible region of the code. In the next section, we explore a second approach that involves building a new data type that leverages the knowledge that we gained in this chapter.</p></div></div>
<div class="section" title="Case study &#x2013; a more performant option"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec24"/>Case study – a more performant option</h1></div></div></div><p>If you are not yet ready to lose information that is encoded by the <code class="literal">Option</code> data type, then you may wish to explore alternative implementations of <code class="literal">Option</code> that are more garbage-collection-friendly. In this section, we present an alternative approach that also provides type-safety while avoiding boxing and instantiation of the <code class="literal">Some</code> instances. We leverage tagged types and specialization, and disallow null as a valid value for <code class="literal">Some</code> to come up with the following implementation:</p><pre class="programlisting">sealed trait Opt &#13;
 &#13;
object OptOps { &#13;
 &#13;
  def some[@specialized A](x: A): A @@ Opt = Tag(x) &#13;
  def nullCheckingSome[@specialized A](x: A): A @@ Opt = &#13;
    if (x == null) sys.error("Null values disallowed") else Tag(x) &#13;
  def none[A]: A @@ Opt = Tag(null.asInstanceOf[A]) &#13;
 &#13;
  def isSome[A](o: A @@ Opt): Boolean = o != null &#13;
  def isEmpty[A](o: A @@ Opt): Boolean = !isSome(o) &#13;
 &#13;
  def unsafeGet[A](o: A @@ Opt): A = &#13;
    if (isSome(o)) o.asInstanceOf[A] else sys.error("Cannot get None") &#13;
 &#13;
  def fold[A, B](o: A @@ Opt)(ifEmpty: =&gt; B)(f: A =&gt; B): B = &#13;
    if (o == null) ifEmpty else f(o.asInstanceOf[A]) &#13;
} &#13;
</pre><p>This implementation defines factory methods to construct optional types (that is, <code class="literal">some</code>, <code class="literal">nullCheckingSome</code>, and <code class="literal">none</code>). In contrast to Scala's <code class="literal">Option</code>, this implementation uses tagged types to add type information to a value rather than creating a new value to encode optionality. The implementation of <code class="literal">none</code> takes advantage of <code class="literal">null</code> being a value in Scala rather than a language in keyword as is the case in Java. Remember, unless performance requirements required such extreme measures, we would not default to these more esoteric approaches. The tagged type returned by each factory method preserves type-safety, and it requires an explicit unwrapping to access the underlying type.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note29"/>Note</h3><p>If you would like to learn more about Scala's representation of the <code class="literal">null</code> value, we encourage you to check out these two StackOverflow posts at <a class="ulink" href="http://stackoverflow.com/questions/8285916/why-doesnt-null-asinstanceofint-throw-a-nullpointerexception">http://stackoverflow.com/questions/8285916/why-doesnt-null-asinstanceofint-throw-a-nullpointerexception</a> and <a class="ulink" href="http://stackoverflow.com/questions/10749010/if-an-int-cant-be-null-what-does-null-asinstanceofint-mean">http://stackoverflow.com/questions/10749010/if-an-int-cant-be-null-what-does-null-asinstanceofint-mean</a>. In both posts, multiple responders provide excellent responses that will help you deepen your understanding.</p></div></div><p>The remaining methods in <code class="literal">OptOps</code> define methods that you would find in the implementation of Scala's <code class="literal">Option</code>. Rather than instance methods, we see that the methods are static because there are no new instances that are allocated by the factory methods. It is possible to define an implicit class that would provide a syntax emulating instance method invocation, but we avoid doing this because we are operating under the assumption of extreme performance sensitivity. Semantically, the operations that are defined in <code class="literal">OptOps</code> are equivalent to the Scala <code class="literal">Option</code> analogs. Instead of matching against a value representing no value (that is, <code class="literal">None</code>), we again take advantage of the ability to reference <code class="literal">null</code> as a value.</p><p>With this implementation, the runtime overhead consists of instance checking and invocations of <code class="literal">scalaz.Tag</code>. We lose the ability to pattern match, and instead we must either fold or, in extreme cases, use <code class="literal">isSome</code> and <code class="literal">unsafeGet</code>. To get a better understanding of runtime differences, we microbenchmarked <code class="literal">Option</code> creation using Scala's <code class="literal">Option</code> and the preceding tagged type implementation. The microbenchmark gives you a taste for the change in syntax. We encourage you to run <code class="literal">javap</code> to disassemble the bytecode in order to prove to yourself that this implementation avoids boxing and object creation:</p><pre class="programlisting"> class OptionCreationBenchmarks { &#13;
 &#13;
  @Benchmark &#13;
  def scalaSome(): Option[ShareCount] = Some(ShareCount(1)) &#13;
 &#13;
  @Benchmark &#13;
  def scalaNone(): Option[ShareCount] = None &#13;
 &#13;
  @Benchmark &#13;
  def optSome(): ShareCount @@ Opt = OptOps.some(ShareCount(1)) &#13;
 &#13;
  @Benchmark &#13;
  def optSomeWithNullChecking(): ShareCount @@ Opt = &#13;
    OptOps.nullCheckingSome(ShareCount(1)) &#13;
 &#13;
  @Benchmark &#13;
  def optNone(): ShareCount @@ Opt = OptOps.none &#13;
 &#13;
  @Benchmark &#13;
  def optNoneReuse(): ShareCount @@ Opt = noShares &#13;
} &#13;
 &#13;
object OptionCreationBenchmarks { &#13;
  case class ShareCount(value: Long) extends AnyVal &#13;
  val noShares: ShareCount @@ Opt = OptOps.none &#13;
} &#13;
</pre><p>We run the test with the following familiar parameters:</p><pre class="programlisting">
<span class="strong"><strong>sbt 'project chapter3' 'jmh:run OptionCreationBenchmarks  -foe true'</strong></span>
</pre><p>The results are summarized in the following table:</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/></colgroup><tbody><tr><td>
<p>
<span class="strong"><strong>Benchmark</strong></span>
</p>
</td><td>
<p>
<span class="strong"><strong>Throughput (ops per second)</strong></span>
</p>
</td><td>
<p>
<span class="strong"><strong>Error as percentage of throughput</strong></span>
</p>
</td></tr><tr><td>
<p>
<code class="literal">optNone</code>
</p>
</td><td>
<p>351,536,523.84</p>
</td><td>
<p>±0.75</p>
</td></tr><tr><td>
<p>
<code class="literal">optNoneReuse</code>
</p>
</td><td>
<p>344,201,145.90</p>
</td><td>
<p>±0.23</p>
</td></tr><tr><td>
<p>
<code class="literal">optSome</code>
</p>
</td><td>
<p>232,684,849.83</p>
</td><td>
<p>±0.37</p>
</td></tr><tr><td>
<p>
<code class="literal">optSomeWithNullChecking</code>
</p>
</td><td>
<p>233,432,224.39</p>
</td><td>
<p>±0.28</p>
</td></tr><tr><td>
<p>
<code class="literal">scalaNone</code>
</p>
</td><td>
<p>345,826,731.05</p>
</td><td>
<p>±0.35</p>
</td></tr><tr><td>
<p>
<code class="literal">scalaSome</code>
</p>
</td><td>
<p>133,583,718.28</p>
</td><td>
<p>±0.24</p>
</td></tr></tbody></table></div><p>Perhaps the most impressive result here is that throughput increases approximately 57% when using the tagged type implementation of <code class="literal">Some</code> over the Scala-provided implementation. This is likely due to reduced memory allocation pressure. We see that <code class="literal">None</code> creation throughput is qualitatively similar. We also observe that there appears to be zero cost to add a null check in the construction of a tagged <code class="literal">Some </code>option. If you trust your team to avoid passing around null values, then the check is superfluous.
We also created a set of benchmarks to evaluate fold performance to get a sense of the relative cost of using this alternative <code class="literal">Option</code> implementation. Here is the source code for a simple fold benchmark:</p><pre class="programlisting">class OptionFoldingBenchmarks { &#13;
 &#13;
  @Benchmark &#13;
  def scalaOption(): ShareCount = &#13;
    scalaSome.fold(ShareCount(0))(c =&gt; ShareCount(c.value * 2)) &#13;
 &#13;
 &#13;
  @Benchmark &#13;
  def optOption(): ShareCount = &#13;
    OptOps.fold(optSome)(ShareCount(0))(c =&gt; ShareCount(c.value * 2)) &#13;
 &#13;
} &#13;
 &#13;
object OptionFoldingBenchmarks { &#13;
 &#13;
  case class ShareCount(value: Long) extends AnyVal &#13;
 &#13;
  val scalaSome: Option[ShareCount] = Some(ShareCount(7)) &#13;
  val optSome: ShareCount @@ Opt = OptOps.some(ShareCount(7)) &#13;
} &#13;
</pre><p>This benchmark was run using the same set of parameters as before:</p><pre class="programlisting">
<span class="strong"><strong>jmh:run OptionFoldingBenchmarks  -foe true</strong></span>
</pre><p>The results of this test are summarized in the following table:</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/></colgroup><tbody><tr><td>
<p>
<span class="strong"><strong>Benchmark</strong></span>
</p>
</td><td>
<p>
<span class="strong"><strong>Throughput (ops per second)</strong></span>
</p>
</td><td>
<p>
<span class="strong"><strong>Error as percentage of throughput</strong></span>
</p>
</td></tr><tr><td>
<p>
<code class="literal">optOption</code>
</p>
</td><td>
<p>346,208,759.51</p>
</td><td>
<p>±1.07</p>
</td></tr><tr><td>
<p>
<code class="literal">scalaOption</code>
</p>
</td><td>
<p>306,325,098.74</p>
</td><td>
<p>±0.41</p>
</td></tr></tbody></table></div><p>In this benchmark we are hoping to prove that there is no significant throughput degradation when using the alternative tagged type-inspired implementation over the Scala <code class="literal">Option</code>. A significant degradation in performance would jeopardize the performance wins that we found in the creation benchmark. Fortunately, this benchmark suggests fold throughput actually increases approximately 13% over the Scala <code class="literal">Option</code> fold implementation.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note30"/>Note</h3><p>It is a relief to see benchmarking yield results that confirm your hypothesis. However, it is equally important to understand why favorable results were produced, and to be able to explain this. Without an understanding of how these results happened, you are unlikely to be able to reproduce the results. How would you explain fold throughput improvement of the tagged type-inspired implementation over the Scala <code class="literal">Option</code> implementation? Consider the implementation and memory allocation differences that we covered.</p></div></div><p>The benchmarks suggest that the tagged type-inspired <code class="literal">Option</code> implementation yields qualitative performance improvements over the Scala <code class="literal">Option</code> implementation. If you are faced with a performance issue and profiling reveals the Scala <code class="literal">Option</code> to be the bottleneck, it may make sense to explore this alternative implementation. While the performance improves, realize that a tradeoff exists. When using the alternative implementation, you lose the ability to pattern match. This seems like a small price to pay because you are able to instead use the fold operation. The higher price to pay is integration with the standard library and third-party libraries. If your critical path code interacts heavily with the Scala standard library or a third-party library, you will be forced to rewrite significant chunks of code to use the alternative <code class="literal">Option</code> implementation. In this scenario, if you are under time pressure, it may make sense to reconsider whether or not modeling parts of the domain with <code class="literal">null</code> is sensible. If your critical path code avoids significant interaction with the Scala standard library or third-party libraries, then using the alternative <code class="literal">Option</code> implementation might be an easier decision.</p><p>Our case study is inspired by a novel approach Alexandre Bertails explores in his blog post at <a class="ulink" href="https://bertails.org/2015/02/15/abstract-algebraic-data-type/">https://bertails.org/2015/02/15/abstract-algebraic-data-type/</a>. He solves the same performance issues that we addressed by defining an approach that he refers to as abstract algebraic data types. Both approaches rely on using type constraints to model <code class="literal">Option</code> without instance allocation. By abstracting over the <code class="literal">Option</code> algebraic data type and its operations, he is able to devise an implementation free of allocations and boxing. We encourage you to explore this approach because it is another great example of how to achieve safety while still providing excellent performance.</p></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec25"/>Summary</h1></div></div></div><p>In this chapter, we dived into the bytecode representation and performance considerations of commonly-used Scala language features. In our case study, you saw first-hand how you can combine several areas of knowledge about Scala language features in combination with the excellent Scalaz library to produce an <code class="literal">Option</code> implementation that is better suited for high-performance needs.</p><p>A consistent theme across all our examples is to promote type-safety and correctness while taking into account performance tradeoffs. As functional programmers, we value compile time correctness and referential transparency. Even with the usage of <code class="literal">null</code> in the tagged type <code class="literal">Option</code> implementation, we preserved correctness because the <code class="literal">null</code> value is an internal implementation detail. When you reflect on the strategies that we covered, consider how each one preserves referentially transparent (that is, side-effect-free) code while still enabling you to reach your performance goals.</p><p>At this point, you should feel more confident about the tradeoffs that are introduced by Scala's elegant language features. Through our analysis, you learned how to translate from concise Scala syntax to JVM bytecode. This is an invaluable skill to debug performance issues. As you practice your awareness by studying more examples, you will develop a stronger intuition for where potential problems lie. Over time, you can refer back to this chapter in order to review common remediation strategies to balance the tradeoff between elegance and safety with performance. In the next chapter, we will continue to grow our ability to leverage Scala to write performant, functional code by diving into collections.</p></div></body></html>