<html><head></head><body>
<div class="book" title="Chapter&#xA0;6.&#xA0;Efficient Sorting &#x2013; quicksort and mergesort"><div class="book" id="1565U2-eeeded97b5e248ac807bb1bec4d7c800"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch06" class="calibre1"/>Chapter 6. Efficient Sorting – quicksort and mergesort</h1></div></div></div><p class="calibre8">In the last chapter, we explored a few simple sorting algorithms. The problem with those is that they are not efficient enough. In this chapter, we will cover two efficient sorting algorithms and we will also see how they are efficient.</p><p class="calibre8">In this chapter, you will learn the following topics:</p><div class="book"><ul class="itemizedlist"><li class="listitem">quicksort</li><li class="listitem">mergesort</li><li class="listitem">Optimality of efficiency in sorting algorithms</li></ul></div></div>

<div class="book" title="Chapter&#xA0;6.&#xA0;Efficient Sorting &#x2013; quicksort and mergesort">
<div class="book" title="quicksort"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch06lvl1sec32" class="calibre1"/>quicksort</h1></div></div></div><p class="calibre8">We want to develop an algorithm that sorts an array of elements efficiently. Our strategy will be simple; we <a id="id270" class="calibre1"/>will somehow try to divide the array into two halves in such a way that sorting each half will complete the sorting. If we can achieve this, we can recursively call the sorting algorithm this way. We already know that the number of levels of recursive call will be of the order of <span class="strong"><em class="calibre12">lg n</em></span> where <span class="strong"><em class="calibre12">lg m</em></span> is the logarithm of <span class="strong"><em class="calibre12">m</em></span> with the base <span class="strong"><em class="calibre12">2</em></span>. So, if we can manage to cut the array in a time in the order of <span class="strong"><em class="calibre12">n</em></span>, we will still have a complexity of <span class="strong"><em class="calibre12">O(n lg n)</em></span> This is much better than <span class="strong"><em class="calibre12">O(n</em></span>
<sup class="calibre14">2</sup><span class="strong"><em class="calibre12">)</em></span>, which we saw in the previous chapter. But how do we cut the array that way? Let's try to cut the following array as follows:</p><div class="informalexample"><pre class="programlisting">10, 5, 2, 3, 78, 53, 3,1,1,24,1,35,35,2,67,4,33,30</pre></div><p class="calibre8">If we trivially cut this array, each part will contain all sorts of values. Sorting these individual parts would then not cause the entire array to be sorted. Instead, we have to cut the array in such a way that all the elements in the left part are less than all the elements in the right part. If we can achieve this, sorting the parts will achieve sorting the whole. But, of course, we need to make some swaps for us to be able to cut the array in such a way. So, we use the following trick:</p><div class="mediaobject"><img src="../images/00030.jpeg" alt="quicksort" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">This is an example <a id="id271" class="calibre1"/>of pivot positioning in quicksort. The one headed arrows represent comparison and double headed arrows represent swap.</p><p class="calibre8">We first choose the last element and call it <span class="strong"><em class="calibre12">pivot</em></span>. Our aim is to make all the elements that are less than the pivot to be on its left and all the elements that are greater than the pivot to be on its right. Note that this means that the pivot is already at the correct position of the array. The preceding figure shows how to do it with an example. In the figure, our pivot is <span class="strong"><strong class="calibre2">30</strong></span>. We start comparing with the first element and move on. The moment we find an inversion, we swap the pivot with that element and keep comparing in the opposite direction. We continue this way, swapping every time there is an inversion and reversing the direction of comparison each time. We stop when all the elements have been compared. Note that after this process, all the elements less than the pivot are on its left, and all the elements <a id="id272" class="calibre1"/>greater than the pivot are on its right. Why does this work? Let's take a closer look.</p><p class="calibre8">Suppose we start comparing from the left. After the first swap, the pivot is at the position of the element that was found to be greater than it. All the elements that were on the left of it have already been compared with the pivot and found to be less than it. The previous figure shows the parts that have already been compared. Now it starts comparing from its earlier position in the opposite direction. After the second swap, it sits in the position of the element that it has been swapped with. All the elements on the right have already been compared with it and found to be greater than it. We keep going in the same way, always ensuring that the parts that have already been compared follow the rule that the part on the left of the pivot contains only elements that are less than or equal to it and the part on the right of the pivot contains only elements that are greater than or equal to it. So, when we are done with the comparisons, we still hold this condition, thus achieving the result. Once we know that all the elements on the left of the pivot are less than or equal to all the elements that are on its right, we can sort these parts separately and the entire array will be sorted as a result. Of course, we sort these parts recursively in the same way.</p><p class="calibre8">However, before we dive into the code, I would like to introduce a different interface for comparison. It is called <code class="email">java.util.Comparator</code> and allows us to specify any comparison logic while sorting, thus providing more flexibility. Here is how it looks:</p><div class="informalexample"><pre class="programlisting">@FunctionalInterface 
public interface Comparator&lt;T&gt; { 
     int compare(T o1, T o2); 
}</pre></div><p class="calibre8">This is, of course, a very simplified version of the actual interface but has got all that we care about. As you can see, this is a functional interface and thus can be implemented using a lambda. It should return the same value that is conceptually similar to the value returned by <code class="email">o1.compareTo(o2)</code>, but a different sorting can use a different comparison lambda. The compare method has to follow the same rules that are there for the <code class="email">compareTo</code> method in the <code class="email">java.util.Comparable</code> interface we studied in the previous chapter.</p><p class="calibre8">Now let's jump into the code for quicksort. We know we don't have to sort any more when the array to be processed is empty, which would be our base case. Otherwise, We create two indexes <code class="email">i</code> and <code class="email">j</code>, one storing the current end of the left part and the other storing the current beginning of the right part that has already been compared with the pivot at any given point of time, while the pivot is being placed in its correct position. Both the index variables store the indexes that are to be compared next. At any given point of time, one of these variables holds the position of the pivot and the other stores the current value being compared with it. The variable that currently stores the position of the pivot is flagged by the Boolean variable, <code class="email">movingI</code>. If it is true, it means that we are currently moving <code class="email">i</code> and hence, <code class="email">j</code> is pointing to the pivot. We update the position variables and keep comparing, in a loop, until both indexes point to the pivot, when the comparison suggests that there is an inversion, we swap and reverse the direction of movement. We reverse the direction of movement because the pivot has moved to the position indexed by the opposite variable, marked by <code class="email">movingI</code> switching its value. Otherwise, we just keep updating the<a id="id273" class="calibre1"/> appropriate position variable.</p><p class="calibre8">When <code class="email">movingI</code> is false, it means that <code class="email">i</code> is storing the position of the pivot. And finally, when the pivot is at the correct position and all the elements on its left are less than or equal to all the elements on its right, we recursively call <span class="strong"><strong class="calibre2">quicksort</strong></span> on each part:</p><div class="informalexample"><pre class="programlisting">public static &lt;E&gt; void quicksort(E[] array, int start, int end,
Comparator&lt;E&gt; comparator) {

    if (end - start &lt;= 0) {
        return;
    }

    int i = start;
    int j = end - 1;
    boolean movingI = true;

    while (i &lt; j) {

    if (comparator.compare(array[i], array[j]) &gt; 0) {
        swap(array, i, j);
        movingI = !movingI;
    } else {
        if (movingI) {
            i++;
        } else {
            j--;
            }
        }
    }

    quicksort(array, start, i, comparator);
    quicksort(array, i + 1, end, comparator);
}</pre></div><p class="calibre8">We can wrap this method to avoid having to pass the start and end parameters:</p><div class="informalexample"><pre class="programlisting">public static &lt;E&gt; void quicksort(E[] array, Comparator&lt;E&gt; comparator){
    quicksort(array, 0, array.length, comparator);
}</pre></div><p class="calibre8">We can use this<a id="id274" class="calibre1"/> method to sort an array. Let's see how to sort an integer array:</p><div class="informalexample"><pre class="programlisting">Integer[] array =
new Integer[]{10, 5, 2, 3, 78, 53, 3, 1, 1, 24, 1, 35,
35, 2, 67, 4, 33, 30};

quicksort(array, (a, b) -&gt; a - b);
System.out.println(Arrays.toString(array));</pre></div><p class="calibre8">The following would be the output:</p><div class="informalexample"><pre class="programlisting">[1, 1, 1, 2, 2, 3, 3, 4, 5, 10, 24, 30, 33, 35, 35, 53, 67, 78]</pre></div><p class="calibre8">Note how we passed the simple comparator using a lambda. If we pass a lambda <code class="email">(a,b)-&gt;b-a</code> instead, we will get the array reversed. In fact, this flexibility lets us sort arrays containing complex objects according to any comparison we like. For example, it is easy to sort an array of <code class="email">Person</code> objects by age using the lambda, <code class="email">(p1, p2)-&gt;p1.getAge() - p2.getAge()</code>.</p></div></div>

<div class="book" title="Chapter&#xA0;6.&#xA0;Efficient Sorting &#x2013; quicksort and mergesort">
<div class="book" title="quicksort">
<div class="book" title="Complexity of quicksort"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch06lvl2sec43" class="calibre1"/>Complexity of quicksort</h2></div></div></div><p class="calibre8">Like always, we <a id="id275" class="calibre1"/>will try to figure out the worst case of quicksort. To begin with, we notice that after the pivot has been positioned correctly, it is not positioned in the middle of the array. In fact, its final position depends on what value it has with respect to the other elements of the array. Since it is always positioned as per its rank, its rank determines the final position. We also notice that the worst case for quicksort would be when the pivot does not cut the array at all, that is, when all the other elements are either to its left or to its right. This will happen when the pivot is the largest or the smallest element. This will happen when the highest or the lowest element is at the end of the array. So, for example, if the array is already sorted, the highest element would be at the end of the array in every step, and we will choose this element as our pivot. This gives us the counter intuitive conclusion that an array that is already sorted would be the worst case for the quicksort algorithm. An array that is sorted in the opposite direction is also one of the worst cases.</p><p class="calibre8">So, what is the complexity if the worst case happens? Since it is the worst case where every step is made out of two recursive calls, one of which is with an empty array and thus needing a constant time to process, and another having an array with one less element. Also, in each step, the pivot is compared with every other element, thus taking time proportional to <span class="strong"><em class="calibre12">(n-1)</em></span> for an <span class="strong"><em class="calibre12">n</em></span>-element step. So, we have the recursive equation for the time <code class="email">T(n)</code> as<a id="id276" class="calibre1"/> follows:</p><div class="informalexample"><pre class="programlisting">T(n) = T(n-1) + a(n-1) + b where a and b are some constants.
=&gt; T(n) – T(n-1) = a(n-1) + b</pre></div><p class="calibre8">Since this is valid for all values of <code class="email">n</code>, we have:</p><div class="informalexample"><pre class="programlisting">T(n) – T(n-1) = a(n-1) + b
T(n-1) – T(n-2) = a(n-2) + b
T(n-2) – T(n-3) = a(n-3) + b
...
T(2) – T(1) = a(1) + b</pre></div><p class="calibre8">Summing both sides, we have the following:</p><div class="informalexample"><pre class="programlisting">T(n) – T(1) = a (1+2+3+...+(n-1)) + (n-1)b
=&gt; T(n) – T(1) = an(n-1)/2 + (n-1)b
=&gt; T(n) = an(n-1)/2 + (n-1)b + T(1)
=&gt; T(n) = O(n2)</pre></div><p class="calibre8">This is not very good. It is still <code class="email">O(n<sup class="calibre14">2</sup></code>
<code class="email">).</code> Is it really an efficient algorithm? Well, to answer that, we need to consider the average case. The average case is the probabilistically weighted average of the complexities for all possible inputs. This is quite complicated. So, we will use something that we can call a typical case, which is sort of the complexity of the usual case. So, what would happen in a typical randomly unsorted array, that is, where the input array is arranged quite randomly? The rank of the pivot will be equally likely to be any value from <code class="email">1</code> to <code class="email">n</code>, where <code class="email">n</code> is the length of the array. So, it will sort of split the array near the middle in general. So, what is the complexity if we do manage to cut the array in halves? Let's find out:</p><div class="informalexample"><pre class="programlisting">T(n) = 2T((n-1)/2) + a(n-1) + b</pre></div><p class="calibre8">This is a little difficult to solve, so we take <code class="email">n/2</code> instead of <code class="email">(n-1)/2</code>, which can only increase the estimate of complexity. So, we have the following:</p><div class="informalexample"><pre class="programlisting">T(n) = 2T(n/2) + a(n-1) + b</pre></div><p class="calibre8">Let <code class="email">m = lg n</code> and <code class="email">S(m) = T(n)</code>, and hence, <code class="email">n = 2m</code>. So, we have this:</p><div class="informalexample"><pre class="programlisting">S(m) = 2S(m-1) + a 2<sup class="calibre14">m</sup> + (b-a)</pre></div><p class="calibre8">Since this is valid for all <code class="email">m</code>, we can apply the same formula for <code class="email">S(m-1)</code> as well. So, we have the following:</p><div class="informalexample"><pre class="programlisting">S(m) = 2(2S(m-2) + a 2<sup class="calibre14">m-1</sup> + (b-a)) + a 2<sup class="calibre14">m</sup> + (b-a)
=&gt; S(m) = 4 S(m-2) + a (2<sup class="calibre14">m</sup> + 2<sup class="calibre14">m</sup>) + (b-a)(2+1)</pre></div><p class="calibre8">Proceeding <a id="id277" class="calibre1"/>similarly, we have this:</p><div class="informalexample"><pre class="programlisting">S(m) = 8 S(m-3) + a (2<sup class="calibre14">m</sup> + 2<sup class="calibre14">m</sup>  + 2<sup class="calibre14">m</sup>) + (b-a)(4+2+1)
…
S(m) = 2m S(0) + a (2<sup class="calibre14">m</sup>+ 2<sup class="calibre14">m</sup>  + 2<sup class="calibre14">m</sup>+ 2<sup class="calibre14">m</sup>) + (b-a)(2<sup class="calibre14">m-1</sup>+ 2<sup class="calibre14">m-2</sup>+ … + 2+1)
=&gt;S(m) = 2<sup class="calibre14">m</sup> S(0) + a m . 2<sup class="calibre14">m</sup>+ (b-a) (2<sup class="calibre14">m</sup> – 1)
=&gt; T(n) = nT(1) + a . (lg n) . n + (b-a) (n-1)
=&gt; T(n) =  θ(n lg n)</pre></div><p class="calibre8">This is pretty good. In fact, this is way better than the quadratic complexity we saw in the previous chapter. In fact, <span class="strong"><em class="calibre12">n lg n</em></span> grows so slow that <span class="strong"><em class="calibre12">n lg n = O(na)</em></span> for any <code class="email">a</code> greater than <span class="strong"><em class="calibre12">1</em></span>. That is to say that the function <span class="strong"><em class="calibre12">n1.000000001</em></span> grows faster than <span class="strong"><em class="calibre12">n lg n</em></span>. So, we have found an algorithm that performs quite well in most cases. Remember that the worst case for quicksort is still <span class="strong"><em class="calibre12">O(n<sup class="calibre14">2</sup>)</em></span>. We will try to address this problem in the next subsection.</p></div></div></div>

<div class="book" title="Chapter&#xA0;6.&#xA0;Efficient Sorting &#x2013; quicksort and mergesort">
<div class="book" title="quicksort">
<div class="book" title="Random pivot selection in quicksort"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch06lvl2sec44" class="calibre1"/>Random pivot selection in quicksort</h2></div></div></div><p class="calibre8">The problem <a id="id278" class="calibre1"/>with quicksort is that it performs really badly<a id="id279" class="calibre1"/> if the array is already sorted or sorted in the reverse direction. This is because we would be always choosing the pivot to be the smallest or the largest element of the array. If we can avoid that, we can avoid the worst case time as well. Ideally, we want to select the pivot that is the median of all the elements of the array, that is, the middle element when the array is sorted. But it is not possible to compute the median efficiently enough. One trick is to choose an element randomly among all the elements and use it as a pivot. So, in each step, we randomly choose an element and swap it with the end element. After this, we can perform the quicksort as we did earlier. So, we update the quicksort method as follows:</p><div class="informalexample"><pre class="programlisting">public static &lt;E&gt; void quicksort(E[] array, int start, int end,
Comparator&lt;E&gt; comparator) {
    if (end - start &lt;= 0) {
        return;
    }
<span class="strong"><strong class="calibre2">    int pivotIndex = (int)((end-start)*Math.random()) + start;</strong></span>
<span class="strong"><strong class="calibre2">    swap(array, pivotIndex, end-1);</strong></span>
    //let's find the pivot.
    int i = start;
    int j = end - 1;
    boolean movingI = true;
    while (i &lt; j) {
        if (comparator.compare(array[i], array[j]) &gt; 0) {
            swap(array, i, j);
            movingI = !movingI;
        } else {
            if (movingI) {
                i++;
            } else {
                j--;
            }
        }
    }
    quicksort(array, start, i, comparator);
    quicksort(array, i + 1, end, comparator);
}</pre></div><p class="calibre8">Even now <a id="id280" class="calibre1"/>we can be very unlucky and pick the end element<a id="id281" class="calibre1"/> every time, but it is very unlikely to happen. In this case, we will almost always get an <span class="strong"><em class="calibre12">n lg n</em></span> complexity, as desired.</p></div></div></div>

<div class="book" title="mergesort"><div class="book" id="164MG2-eeeded97b5e248ac807bb1bec4d7c800"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch06lvl1sec33" class="calibre1"/>mergesort</h1></div></div></div><p class="calibre8">In the previous <a id="id282" class="calibre1"/>section, we tried to divide the array in such a way that when we sort each part, the entire array is sorted. We faced the problem that when we try to do that, the two parts are not equal in size causing the algorithm to sometimes take a quadratic amount of time. What if, instead of trying to divide the array in a way that sorting the parts would sort the whole, we just divide the array into two equal halves? Of course then, sorting the parts will not sort the entire array. However, if we have two array parts sorted on their own, can we merge them together to produce a sorted array as a whole? If we can do this efficiently enough, we would have an algorithm guaranteed to be efficient. As it turns out, it is possible. But we need to think about where the merged array will be stored. Since the values are being copied from the source array, the result needs to be stored in a separate place. So, we will need another storage of equal size for mergesort.</p><p class="calibre8">.</p><div class="mediaobject"><img src="../images/00031.jpeg" alt="mergesort" class="calibre9"/><div class="caption"><p class="calibre15">Merge of sorted arrays</p></div></div><p class="calibre10"> </p><p class="calibre8">
</p><p class="calibre8">The preceding figure shows a part of the merging operation. We keep the current position of each of the arrays. In each step, we compare the values in the current positions in both the input sorted arrays.</p><p class="calibre8">We copy <a id="id283" class="calibre1"/>whichever of them is smaller to the target location and increment the corresponding current position. We keep doing this until we finish one of the arrays, after which the elements of the other array can just be copied over. The following shows the code for the merge operation. One thing to note is that, since the merge will be used for a mergesort, it presumes both the input arrays to be the same array with different indexes and the target arrays to have the same size. The source has three indexes: <code class="email">start</code>, <code class="email">mid</code>, and <code class="email">end</code>. It is assumed that the source parts are residing side by side in the source array. The variable <code class="email">start</code> points to the start of the first part. The integer <code class="email">mid</code> stores the index of the start of the second part and also acts as the end of the first part, as the parts are contiguous. Finally, the <code class="email">end</code> variable stores the end of the second array:</p><div class="informalexample"><pre class="programlisting">private static &lt;E&gt; void merge(E[] array, int start, int mid, int end, E[] targetArray, Comparator&lt;E&gt; comparator) {
    int i = start;
    int j = mid;
    int k = start;
    while (k &lt; end) {</pre></div><p class="calibre8">The first two cases are for the time when one of the source arrays has been exhausted:</p><div class="informalexample"><pre class="programlisting">        if (i == mid) {
            targetArray[k] = array[j];
            j++;
        } else if (j == end) {
            targetArray[k] = array[i];
            i++;
        } </pre></div><p class="calibre8">If none of the arrays are exhausted, copy from the correct array:</p><div class="informalexample"><pre class="programlisting">        else if (comparator.compare(array[i], array[j]) &gt; 0) {
            targetArray[k] = array[j];
            j++;
        } else {
            targetArray[k] = array[i];
            i++;
        }</pre></div><p class="calibre8">Finally, the target location must also be incremented:</p><div class="informalexample"><pre class="programlisting">        k++;
    }
}</pre></div><p class="calibre8">With this <code class="email">merge</code> function <a id="id284" class="calibre1"/>available to us, we can now proceed to do the mergesort. It involves the following steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Divide the array into two equal parts.</li><li class="listitem" value="2">Mergesort the parts.</li><li class="listitem" value="3">Merge the sorted parts into a full sorted array.</li></ol><div class="calibre13"/></div><p class="calibre8">Of course, we do not need to do anything for an array with zero or one element. So, that will be our exit case:</p><div class="informalexample"><pre class="programlisting">public static &lt;E&gt; void mergeSort(E[] sourceArray, int start,
int end, E[] tempArray, Comparator&lt;E&gt; comparator) {</pre></div><p class="calibre8">Just return to the calling function for an array of zero or one element. This is our base case:</p><div class="informalexample"><pre class="programlisting">    if (start &gt;= end - 1) {
        return;
    }</pre></div><p class="calibre8">For any array of size bigger than <code class="email">1</code>, divide the array into two halves–start to mid and mid to end. Then merge-sort them separately, and then merge the two sorted subarrays to a combined sorted array in <code class="email">tempArray</code>, which is an auxiliary space that we are using:</p><div class="informalexample"><pre class="programlisting">    int mid = (start + end) / 2;
    mergeSort(sourceArray, start, mid, tempArray, comparator);
    mergeSort(sourceArray, mid, end, tempArray, comparator);
    merge(sourceArray, start, mid, end, tempArray, comparator);</pre></div><p class="calibre8">Finally, copy the contents of <code class="email">tempArray</code> to <code class="email">sourceArray</code> so that the source is now sorted:</p><div class="informalexample"><pre class="programlisting">    System.arraycopy(tempArray, start, sourceArray, start,
        end - start);
}</pre></div></div>

<div class="book" title="mergesort">
<div class="book" title="The complexity of mergesort"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch06lvl2sec45" class="calibre1"/>The complexity of mergesort</h2></div></div></div><p class="calibre8">Let's start from the <a id="id285" class="calibre1"/>complexity of the merge operation. The merge operation is not recursive. In every step, it increments either <code class="email">i</code> or <code class="email">j</code>. When both these variables reach the end of the respective arrays, the merge ends. The comparison happens at most once per any of these increments. This means that there are at most as many comparisons as there are elements in both the sub-arrays combined. The copying of the contents of <code class="email">tempArray</code> to <code class="email">sourceArray</code> also, of course, takes operations proportional to the number of elements in <code class="email">tempArray</code>, which is the same as the number of elements in the <code class="email">sourceArray</code>. So, the number of operations in each step is proportional to <span class="strong"><em class="calibre12">n</em></span>, apart from the recursive call. The recursive call works on both parts of the array, which are themselves half the size of the entire array. Thus, if <span class="strong"><em class="calibre12">T(n)</em></span> is the time taken, we have the following:</p><div class="informalexample"><pre class="programlisting">T(n) = 2T(n/2) + an + b</pre></div><p class="calibre8">Here, <code class="email">a</code> and <code class="email">b</code> are constants.</p><p class="calibre8">This is the same <a id="id286" class="calibre1"/>equation as the one obtained for the typical case of the quicksort algorithm, and we know that the solution gives us <span class="strong"><em class="calibre12">T(n) = θ(n lg n)</em></span>. This is the estimate for the both the average case and the worst  case because, in both cases, the array will always be divided into two equal halves irrespective of the contents of the array. In fact, the worst case is when all the copying also requires a comparison, which is the case we considered.</p><p class="calibre8">In the best case, one of the arrays will have all its elements copied before even the first element of the second array is copied, thus requiring only half as many comparisons. But this case gives the same complexity of <span class="strong"><em class="calibre12">T(n) = θ(n lg n)</em></span>. So, irrespective of the actual contents of the array we started with, mergesort will always have the same asymptotic complexity.</p></div></div>

<div class="book" title="mergesort">
<div class="book" title="Avoiding the copying of tempArray"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch06lvl2sec46" class="calibre1"/>Avoiding the copying of tempArray</h2></div></div></div><p class="calibre8">In our rather<a id="id287" class="calibre1"/> simplistic example, we first merged the subarrays into <code class="email">tempArray</code>, and then we copied it back to <code class="email">sourceArray</code>. Can the copying be avoided? Can we use <code class="email">tempArray</code> itself as the result of the merge? It turns out that we can. In this case, both <code class="email">sourceArray</code> and <code class="email">tempArray</code> would be used rather symmetrically, the only difference being that <code class="email">sourceArray</code> holds the original input array. Otherwise, they are two pre-allocated arrays of the same size. However, the code will get a little more complicated.</p><p class="calibre8">Let us first consider what would happen if we do not copy the contents of <code class="email">tempArray</code> to <code class="email">sourceArray</code> and try to use <code class="email">tempArray</code> itself as the content of the sorted array. Then, in each step, <code class="email">sourceArray</code> and <code class="email">tempArray</code> would need to be swapped, that is, <code class="email">tempArray</code> would become <code class="email">sourceArray</code> and vice versa. Since in each step, <code class="email">tempArray</code> and <code class="email">sourceArray</code> are getting swapped, the actual array that holds the result depends on whether the number of steps required to sort the array is odd or even.</p><p class="calibre8">Now, if the array we started with had a number of elements equal to an exact integral power of 2, the source array could always be divided into two sub-arrays of the exact same size. This means, the number of steps required to sort each of these sub-arrays would be exactly the same. This means that the actual array that holds the sorted result would be the same after sorting either sub-array. However, in reality, the number of elements in the array is not an exact power of 2 most of the time, and hence, one sub-array is a little<a id="id288" class="calibre1"/> bigger than the other. This results in a different number of steps being required to sort either sub-array, causing them to potentially store the resultant sorted array in different arrays. We have to consider these cases as well. So, when the result of sorting either sub-array is stored in the same array, we store the output of the merge in the other array. If not, we always store the output of the merge in the array that holds the result of sorting the second part of the array.</p><p class="calibre8">First, we change the <code class="email">merge</code> function to handle two different arrays holding the contents of two different inputs:</p><div class="informalexample"><pre class="programlisting">    private static &lt;E&gt; void merge(E[] arrayL, E[] arrayR, 
    int start, int mid, int end, E[] targetArray, 
    Comparator&lt;E&gt; comparator) { 
        int i = start; 
        int j = mid; 
        int k = start; 
        while (k &lt; end) { 
            if (i == mid) { 
                targetArray[k] = arrayR[j]; 
                j++; 
            } else if (j == end) { 
                targetArray[k] = arrayL[i]; 
                i++; 
            } else if (comparator.compare(arrayL[i], arrayR[j]) &gt; 0) { 
                targetArray[k] = arrayR[j]; 
                j++; 
            } else { 
                targetArray[k] = arrayL[i]; 
                i++; 
            } 
            k++; 
        } 
}</pre></div><p class="calibre8">With this <code class="email">merge</code> function available, we write our efficient mergesort in the following way. Note that we need some way to inform the calling function about which pre-allocated array<a id="id289" class="calibre1"/> contains the result, so we return that array:</p><div class="informalexample"><pre class="programlisting">public static &lt;E&gt; E[] mergeSortNoCopy(E[] sourceArray, int start,
int end, E[] tempArray, Comparator&lt;E&gt; comparator) {
    if (start &gt;= end - 1) {
        return sourceArray;
    }</pre></div><p class="calibre8">First, split and merge-sort the sub-arrays as usual:</p><div class="informalexample"><pre class="programlisting">    int mid = (start + end) / 2;
    E[] sortedPart1 =
    mergeSortNoCopy(sourceArray, start, mid, tempArray,
                    comparator);
    E[] sortedPart2 =
    mergeSortNoCopy(sourceArray, mid, end, tempArray,
                    comparator);</pre></div><p class="calibre8">If both the sorted sub-arrays are stored in the same pre-allocated array, use the other pre-allocated array to store the result of the merge:</p><div class="informalexample"><pre class="programlisting">    if (sortedPart2 == sortedPart1) {
        if (sortedPart1 == sourceArray) {
            merge(sortedPart1, sortedPart2, start, mid, end,
                  tempArray, comparator);
            return tempArray;
        } else {
            merge(sortedPart1, sortedPart2, start, mid, end,
            sourceArray, comparator);
            return sourceArray;
        }
    } else {</pre></div><p class="calibre8">In this case, we store the result in <code class="email">sortedPart2</code> because it has the first portion empty:</p><div class="informalexample"><pre class="programlisting">        merge(sortedPart1, sortedPart2, start, mid, end,
              sortedPart2, comparator);
        return sortedPart2;
    }
}</pre></div><p class="calibre8">Now we can use this mergesort as follows:</p><div class="informalexample"><pre class="programlisting">Integer[] anotherArray = new Integer[array.length];
array = mergeSortNoCopy(array, 0, array.length, anotherArray,
(a, b)-&gt;a-b);
System.out.println(Arrays.toString(array));</pre></div><p class="calibre8">Here is the output:</p><div class="informalexample"><pre class="programlisting">[1, 1, 1, 2, 2, 3, 3, 4, 5, 10, 24, 30, 33, 35, 35, 53, 67, 78]</pre></div><p class="calibre8">Note that<a id="id290" class="calibre1"/> this time, we had to ensure that we use the output returned by the method as, in some cases, <code class="email">anotherArray</code> may contain the final sorted values. The efficient no-copy version of the mergesort does not have any asymptotic performance improvement, but it improves the time by a constant. This is something worth doing.</p></div></div>
<div class="book" title="Complexity of any comparison-based sorting"><div class="book" id="173722-eeeded97b5e248ac807bb1bec4d7c800"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch06lvl1sec34" class="calibre1"/>Complexity of any comparison-based sorting</h1></div></div></div><p class="calibre8">Now that we have seen two algorithms for sorting that are more efficient than the ones described<a id="id291" class="calibre1"/> in the previous chapter, how do we know that they are as efficient as a sorting can be? Can we make algorithms that are even faster? We will see in this section that we have reached our asymptotic limit of efficiency, that is, a comparison-based  sorting will have a minimum time complexity of <span class="strong"><em class="calibre12">θ(m lg m)</em></span>, where <span class="strong"><em class="calibre12">m</em></span> is the number of elements.</p><p class="calibre8">Suppose we start with an array of <span class="strong"><em class="calibre12">m</em></span> elements. For the time being, let's assume they are all distinct. After all, if such an array is a possible input, we need to consider this case as well. The number of different arrangements possible with these elements is <span class="strong"><em class="calibre12">m!</em></span>. One of these arrangements is the correct sorted one. Any algorithm that will sort this array using comparison will have to be able to distinguish this particular arrangement from all others using only comparison between pairs of elements. Any comparison divides the arrangements into two sets–one that causes an inversion as per the comparison between those two exact values and one that does not. This is to say that given any two values <span class="strong"><em class="calibre12">a</em></span> and <span class="strong"><em class="calibre12">b</em></span> from the arrays, a comparison that returns <span class="strong"><em class="calibre12">a&lt;b</em></span> will divide the set of arrangements into two partitions; the first set will contain all the arrangements where <span class="strong"><em class="calibre12">b</em></span> comes before <span class="strong"><em class="calibre12">a</em></span>, and the second set will contain all the arrangements where <span class="strong"><em class="calibre12">a</em></span> comes before <span class="strong"><em class="calibre12">b</em></span>. The sorted arrangement is, of course, a member of the second set. Any algorithm that sorts based on comparisons will have to do enough of them to pin down on the single correct arrangement, that is, the sorted arrangement. Basically, it will first perform a comparison, choose the correct subset, then perform another comparison and choose the correct subset of the subset, and so on, until it reaches a set of arrangements containing just one arrangement. This particular arrangement is the sorted version of the array. What is the minimum number of comparisons that are required to find one particular arrangement out of <span class="strong"><em class="calibre12">m!</em></span> arrangements? This is the same as asking how many times you have to halve a set of <span class="strong"><em class="calibre12">m!</em></span> elements to reach a set of only one element. It is, of course, <span class="strong"><em class="calibre12">lg (m!)</em></span>. This is a rough estimation; in fact, the number of comparisons required would be a bit more than this because the two subsets that each comparison creates may not be equal in size. But we know that the number of comparisons required is <span class="strong"><em class="calibre12">lg (m!)</em></span> at the minimum.</p><p class="calibre8">Now, how much is <span class="strong"><em class="calibre12">lg m!</em></span>? Well, it is <span class="strong"><em class="calibre12">(ln (m!)) (lg e)</em></span>, where <span class="strong"><em class="calibre12">ln (x)</em></span> is the natural logarithm of <span class="strong"><em class="calibre12">x</em></span>. We will find a simpler asymptotic complexity for the function <span class="strong"><em class="calibre12">ln(m!)</em></span>. It requires a little bit <a id="id292" class="calibre1"/>of calculus.</p><p class="calibre8">Let's look at the following figure:</p><div class="mediaobject"><img src="../images/00032.jpeg" alt="Complexity of any comparison-based sorting" class="calibre9"/><div class="caption"><p class="calibre15">Area under the curve y = ln x.</p></div></div><p class="calibre10"> </p><p class="calibre8">The diagram shows some plots. We know that the integral measures the area under the curve of a function. Now, the area under the curve <span class="strong"><em class="calibre12">y=ln b</em></span> between <span class="strong"><em class="calibre12">a</em></span> and <span class="strong"><em class="calibre12">b</em></span> is <span class="strong"><em class="calibre12">(b-a)ln b</em></span>, and the area under the curve <span class="strong"><em class="calibre12">y=ln a</em></span> is <span class="strong"><em class="calibre12">(b-a) ln a</em></span>. The area under the curve <span class="strong"><em class="calibre12">y=lg x</em></span> in the same interval is as follows:</p><div class="mediaobject"><img src="../images/00033.jpeg" alt="Complexity of any comparison-based sorting" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">From the<a id="id293" class="calibre1"/> graph in the preceding figure, the following is clear:</p><div class="mediaobject"><img src="../images/00034.jpeg" alt="Complexity of any comparison-based sorting" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">In particular, having <span class="strong"><em class="calibre12">b=a+1</em></span>, we get the following:</p><div class="mediaobject"><img src="../images/00035.jpeg" alt="Complexity of any comparison-based sorting" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">So, we set <span class="strong"><em class="calibre12">a = 1</em></span> and move up to <span class="strong"><em class="calibre12">a = m-1</em></span>, to get the following set of inequalities:</p><div class="mediaobject"><img src="../images/00036.jpeg" alt="Complexity of any comparison-based sorting" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">Adding<a id="id294" class="calibre1"/> respective sides, we get the following:</p><div class="mediaobject"><img src="../images/00037.jpeg" alt="Complexity of any comparison-based sorting" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">Now, of course we know the following: </p><div class="mediaobject"><img src="../images/00038.jpeg" alt="Complexity of any comparison-based sorting" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">So, we have the following inequalities:</p><div class="mediaobject"><img src="../images/00039.jpeg" alt="Complexity of any comparison-based sorting" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">In the<a id="id295" class="calibre1"/> left inequality, if we put m instead of <span class="strong"><em class="calibre12">m-1</em></span>, we will have the following:</p><div class="mediaobject"><img src="../images/00040.jpeg" alt="Complexity of any comparison-based sorting" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">This, combined with the right inequality, gives the following relations:</p><div class="mediaobject"><img src="../images/00041.jpeg" alt="Complexity of any comparison-based sorting" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">This gives a pretty good upper bound and lower bound on the value of <span class="strong"><em class="calibre12">ln(m!)</em></span>. Both the upper bound and lower bound are <span class="strong"><em class="calibre12">θ(m ln m)</em></span>. So, we can conclude that <span class="strong"><em class="calibre12">ln(m!) = θ(m ln m)</em></span>. This means that <span class="strong"><em class="calibre12">lg(m!) = (ln (m!))(lg e)</em></span> is also <span class="strong"><em class="calibre12">θ(m ln m) = θ(m lg m)</em></span> because <span class="strong"><em class="calibre12">lg(m) = (ln m )(lg e)</em></span>.</p><p class="calibre8">So, the minimum time complexity of a comparison-based sorting algorithm would have to be at least <span class="strong"><em class="calibre12">θ(m lg m)</em></span> just because of the minimum number of comparisons that would be needed to do this. Therefore, mergesort and the typical case of quicksort are asymptotically optimal.</p></div>
<div class="book" title="The stability of a sorting algorithm" id="181NK1-eeeded97b5e248ac807bb1bec4d7c800"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch06lvl1sec35" class="calibre1"/>The stability of a sorting algorithm</h1></div></div></div><p class="calibre8">The stability of a<a id="id296" class="calibre1"/> sorting algorithm is the property that the elements that compare to be equal preserve their original order after sorting. For example, if we have an array of objects containing the ID number and the age of some people and we want to sort them in increasing order of age, a stable sorting algorithm will preserve the original order of the people with the same age. This can be helpful if we are trying to sort multiple times. For example, if we want the IDs to be in increasing order for people with the same age, we can first sort the array by ID and then sort it again by age. If the sorting algorithm is stable, it will ensure that the final sorted array is in increasing order of age, and for the same age, it is in increasing order of ID. Of course, this effect can also be<a id="id297" class="calibre1"/> achieved by having a more complex comparison with a single sorting operation. Quicksort is not stable, but mergesort is. It is easy to see why mergesort is stable. During merging, we preserve the order, that is, values from the left half precede values from the right half when they compare as equal.</p></div>
<div class="book" title="Summary" id="190861-eeeded97b5e248ac807bb1bec4d7c800"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch06lvl1sec36" class="calibre1"/>Summary</h1></div></div></div><p class="calibre8">In this chapter, we explored two efficient sorting algorithms. The basic principle, in both cases, was to divide the array and to sort the parts separately. If we ensure that sorting the parts will cause the entire array to be sorted by readjusting the elements, it is quicksort. If we just divide the array into two equal parts first and–after sorting each part–merge the results to cause the entire array to be sorted, it is a mergesort. This way of dividing the input into smaller parts, solving the problem for the smaller parts and then combining the results to find the solution for the entire problem is a common pattern in solving computational problems, and it is called the divide and conquer pattern.</p><p class="calibre8">We have also seen an asymptotic lower bound for any sorting algorithm that works using comparisons. Both quicksort and mergesort achieve this lower bound and hence, are asymptotically optimal. In the next chapter, we will move to a different kind of data structures called trees.</p></div></body></html>