<html><head></head><body>
<div class="book" title="Chapter&#xA0;1.&#xA0;Why Bother? &#x2013; Basic"><div class="book" id="E9OE2-eeeded97b5e248ac807bb1bec4d7c800"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch01" class="calibre1"/>Chapter 1. Why Bother? – Basic</h1></div></div></div><p class="calibre8">Since you already know Java, you have of course written a few programs, which means you have written algorithms. "Well then, what is it?" you might ask. An algorithm is a list of well-defined steps that can be followed by a processor mechanically, or without involving any sort of intelligence, which would produce a desired output in a finite amount of time. Well, that's a long sentence. In simpler words, an algorithm is just an unambiguous list of steps to get something done. It kind of sounds like we are talking about a program. Isn't a program also a list of instructions that we give the computer to follow, in order to get a desired result? Yes it is, and that means an algorithm is really just a program. Well not really, but almost. An algorithm is a program without the details of the particular programming language that we are coding it in. It is the basic idea of the program; think of it as an abstraction of a program where you don't need to bother about the program's syntactic details.</p><p class="calibre8">Well, since we already know about programming, and an algorithm is just a program, we are done with it, right? Not really. There is a lot to learn about programs and algorithms, that is, how to write an algorithm to achieve a particular goal. There are, of course, in general, many ways to solve a particular problem and not all ways may be equal. One way may be faster than another, and that is a very important thing about algorithms. When we study algorithms, the time it takes to execute is of utmost importance. In fact, it is the second most important thing about them, the first one being their correctness.</p><p class="calibre8">In this chapter, we will take a deeper look into the following ideas:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Measuring the performance of an algorithm</li><li class="listitem">Asymptotic complexity</li><li class="listitem">Why asymptotic complexity matters</li><li class="listitem">Why an explicit study of algorithms is important</li></ul></div></div>

<div class="book" title="Chapter&#xA0;1.&#xA0;Why Bother? &#x2013; Basic">
<div class="book" title="The performance of an algorithm"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch01lvl1sec08" class="calibre1"/>The performance of an algorithm</h1></div></div></div><p class="calibre8">No one wants to wait <a id="id0" class="calibre1"/>forever to get something done. Making a program run faster surely is important, but how do we know whether a program runs fast? The first logical step would be to measure how many seconds the program takes to run. Suppose we have a program that, given three numbers, <span class="strong"><em class="calibre12">a</em></span>, <span class="strong"><em class="calibre12">b</em></span>, and <span class="strong"><em class="calibre12">c</em></span>, determines the remainder when <span class="strong"><em class="calibre12">a</em></span> raised to the power <span class="strong"><em class="calibre12">b</em></span> is divided by <span class="strong"><em class="calibre12">c</em></span>.</p><p class="calibre8">For example, say <span class="strong"><em class="calibre12">a=2</em></span>, <span class="strong"><em class="calibre12">b=10</em></span>, and <span class="strong"><em class="calibre12">c = 7</em></span>, <span class="strong"><em class="calibre12">a</em></span> raised to the power <span class="strong"><em class="calibre12">b = 2<sup class="calibre14">10</sup> = 1024</em></span>, <span class="strong"><em class="calibre12">1024 % 7 = 2</em></span>. So, given these values, the program needs to output <code class="email">2</code>. The following code snippet shows a simple and obvious way of achieving this:</p><div class="informalexample"><pre class="programlisting">public static long computeRemainder(long base, long power, long divisor){ 
  long baseRaisedToPower = 1;
  for(long i=1;i&lt;=power;i++){ 
    baseRaisedToPower *= base;
  }
  return baseRaisedToPower % divisor;
}</pre></div><p class="calibre8">We can now estimate the time it takes by running the program a billion times and checking how long it took to run it, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">public static void main(String [] args){
  long startTime = System.currentTimeMillis();
  for(int i=0;i&lt;1_000_000_000;i++){
    computeRemainder(2, 10, 7);
  }
  long endTime = System.currentTimeMillis();
  System.out.println(endTime - startTime);
}</pre></div><p class="calibre8">On my computer, it takes 4,393 milliseconds. So the time taken per call is 4,393 divided by a billion, that is, about 4.4 nanoseconds. Looks like a very reasonable time to do any computation. But what happens if the input is different? What if I pass power = <code class="email">1000</code>? Let's check that out. Now it takes about 420,000 milliseconds to run a billion times, or about 420 nanoseconds per run. Clearly, the time taken to do this computation depends on the input, and that means any reasonable way to talk about the performance of a program needs to take into account the input to the program.</p><p class="calibre8">Okay, so we can say that the number of nanoseconds our program takes to run is 0.42 X power, approximately.</p><p class="calibre8">If you run the program with the input (<code class="email">2</code>, <code class="email">1000</code>, and <code class="email">7</code>), you will get an output of <code class="email">0</code>, which is not correct. The correct output is <code class="email">2</code>. So, what is going on here? The answer is that the maximum value that a long type variable can hold is one less than 2 raised to the power 63, or 9223372036854775807L. The value 2 raised to the power 1,000 is, of course, much more than this, causing the value to overflow, which brings us to our next point: how much space does a program need in order to run?</p><p class="calibre8">In general, the memory <a id="id1" class="calibre1"/>space required to run a program can be measured in terms of the bytes required for the program to operate. Of course, it requires the space to at least store the input and the output. It may as well need some additional space to run, which is called auxiliary space. It is quite obvious that just like time, the space required to run a program would, in general, also be dependent on the input.</p><p class="calibre8">In the case of time, apart from the fact that the time depends on the input, it also depends on which computer you are running it on. The program that takes 4 seconds to run on my computer may take 40 seconds on a very old computer from the nineties and may run in 2 seconds in yours. However, the actual computer you run it on only improves the time by a constant multiplier. To avoid getting into too much detail about specifying the details of the hardware the program is running on, instead of saying the program takes 0.42 X power milliseconds approximately, we can say the time taken is a constant times the power, or simply say it is proportional to the power.</p><p class="calibre8">Saying the computation time is proportional to the power actually makes it so non-specific to hardware, or even the language the program is written in, that we can estimate this relationship by just looking at the program and analyzing it. Of course, the running time is sort of proportional to the power because there is a loop that executes power number of times, except, of course, when the power is so small that the other one-time operations outside the loop actually start to matter.</p></div></div>

<div class="book" title="Chapter&#xA0;1.&#xA0;Why Bother? &#x2013; Basic">
<div class="book" title="The performance of an algorithm">
<div class="book" title="Best case, worst case and the average case complexity"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch01lvl2sec07" class="calibre1"/>Best case, worst case and the average case complexity</h2></div></div></div><p class="calibre8">In general, the time or <a id="id2" class="calibre1"/>space required for an algorithm to process a <a id="id3" class="calibre1"/>certain input depends not only on the size of the <a id="id4" class="calibre1"/>input, but also on the actual value of the input. For example, a certain algorithm to arrange a list of values in increasing order may take much less time if the input is already sorted than when it is an arbitrary unordered list. This is why, in general, we must have a different function representing the time or space required in the different cases of input. However, the best case scenario would be where the resources required for a certain size of an input take the least amount of resources. The would also be a worst case scenario, in which the algorithm <a id="id5" class="calibre1"/>needs the maximum amount of resources <a id="id6" class="calibre1"/>for a certain size of input. An average case is <a id="id7" class="calibre1"/>an estimation of the resources taken for a given size of inputs averaged over all values of the input with that size weighted by their probability of occurrence.</p></div></div></div>

<div class="book" title="Chapter&#xA0;1.&#xA0;Why Bother? &#x2013; Basic">
<div class="book" title="The performance of an algorithm">
<div class="book" title="Analysis of asymptotic complexity"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch01lvl2sec08" class="calibre1"/>Analysis of asymptotic complexity</h2></div></div></div><p class="calibre8">We seem to have hit upon an idea, an abstract sense of the running time. Let's spell it out. In an abstract way, we <a id="id8" class="calibre1"/>analyze the running time of and the space required by a program by using what is known as the asymptotic complexity.</p><p class="calibre8">We are only interested in what happens when the input is very large because it really does not matter how long it takes for a small input to be processed; it's going to be small anyway. So, if we have <span class="strong"><em class="calibre12">x<sup class="calibre14">3</sup></em></span>
<span class="strong"><em class="calibre12"> + x<sup class="calibre14">2</sup></em></span>, and if <span class="strong"><em class="calibre12">x</em></span> is very large, it's almost the same as <span class="strong"><em class="calibre12"><sup class="calibre14">x3</sup></em></span>. We also don't want to consider <a id="id9" class="calibre1"/>constant factors of a function, as we have pointed out earlier, because it is dependent on the particular hardware we are running the program on and the particular language we have implemented it in. An algorithm implemented in Java will perform a constant times slower than the same algorithm written in C. The formal way of tackling these abstractions in defining the complexity of an algorithm is called an asymptotic bound. Strictly speaking, an asymptotic bound is for a function and not for an algorithm. The idea is to first express the time or space required for a given algorithm to process an input as a function of the size of the input in bits and then looking for an asymptotic bound of that function.</p><p class="calibre8">We will consider three types of asymptotic bounds—an upper bound, a lower bound and a tight bound. We will discuss these in the following sections.</p><div class="book" title="Asymptotic upper bound of a function"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch01lvl3sec01" class="calibre1"/>Asymptotic upper bound of a function</h3></div></div></div><p class="calibre8">An upper bound, as the name suggests, puts an upper limit of a function's growth. The upper bound is <a id="id10" class="calibre1"/>another function that grows at least as fast as the original function. What is the point of talking about one function in place of another? The function we use is in general a lot more simplified than the actual function for computing running time or space required to process a certain size of input. It is a lot easier to compare simplified functions than to compare complicated functions.</p><p class="calibre8">For a function <span class="strong"><em class="calibre12">f</em></span>, we define the notation <span class="strong"><em class="calibre12">O</em></span>, called <span class="strong"><strong class="calibre2">big O</strong></span>, in the following ways:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1"><span class="strong"><em class="calibre12">f(x) = O(f(x))</em></span>.<div class="book"><ul class="itemizedlist1"><li class="listitem">For example, <span class="strong"><em class="calibre12">x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> = O(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span>.</li></ul></div></li><li class="listitem" value="2">If <span class="strong"><em class="calibre12">f(x) = O(g(x))</em></span>, then <span class="strong"><em class="calibre12">k f(x) = O(g(x))</em></span> for any non-zero constant <span class="strong"><em class="calibre12">k</em></span>.<div class="book"><ul class="itemizedlist1"><li class="listitem">For example, <span class="strong"><em class="calibre12">5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> = O(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span> and <span class="strong"><em class="calibre12">2 log x = O(log x)</em></span> and <span class="strong"><em class="calibre12">-x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> = O(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span> (taking <span class="strong"><em class="calibre12">k= -1</em></span>).</li></ul></div></li><li class="listitem" value="3">If <span class="strong"><em class="calibre12">f(x) = O(g(x))</em></span> and <span class="strong"><em class="calibre12">|h(x)|&lt;|f(x)|</em></span> for all sufficiently large <span class="strong"><em class="calibre12">x</em></span>, then <span class="strong"><em class="calibre12">f(x) + h(x) = O(g(x))</em></span>.<div class="book"><ul class="itemizedlist1"><li class="listitem">For example, <span class="strong"><em class="calibre12">5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> - 25x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12"> + 1 = O(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span> because for a sufficiently large <span class="strong"><em class="calibre12">x</em></span>, <span class="strong"><em class="calibre12">|- 25x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12"> + 1| = 25x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12"> - 1</em></span> is much less that <span class="strong"><em class="calibre12">| 5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">| = 5x<sup class="calibre14">3</sup></em></span>. So, <span class="strong"><em class="calibre12">f(x) + g(x) = 5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> - 25x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12"> + 1 = O(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span> as <span class="strong"><em class="calibre12">f(x) = 5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> = O(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span>.</li><li class="listitem">We can prove by similar logic that <span class="strong"><em class="calibre12">x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> = O( 5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> - 25x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12"> + 1)</em></span>.</li></ul></div></li><li class="listitem" value="4">if <span class="strong"><em class="calibre12">f(x) = O(g(x))</em></span> and <span class="strong"><em class="calibre12">|h(x)| &gt; |g(x)|</em></span> for all sufficiently large <span class="strong"><em class="calibre12">x</em></span>, then <span class="strong"><em class="calibre12">f(x) = O(h(x))</em></span>.<div class="book"><ul class="itemizedlist1"><li class="listitem">For example, <span class="strong"><em class="calibre12">x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> = O(x<sup class="calibre14">4</sup></em></span><span class="strong"><em class="calibre12">)</em></span>, because if <span class="strong"><em class="calibre12">x</em></span> is sufficiently large, <span class="strong"><em class="calibre12">x<sup class="calibre14">4</sup></em></span><span class="strong"><em class="calibre12"> &gt; x<sup class="calibre14">3</sup></em></span>.</li></ul></div></li></ol><div class="calibre13"/></div><p class="calibre8">Note that whenever there is an inequality on functions, we are only interested in what happens when <span class="strong"><em class="calibre12">x</em></span> is large; we don't bother about what happens for small <span class="strong"><em class="calibre12">x</em></span>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note02" class="calibre1"/>Note</h3><p class="calibre8">To summarize the above definition, you can drop constant multipliers (rule 2) and ignore lower order terms (rule 3). You can also overestimate (rule 4). You can also do <a id="id11" class="calibre1"/>all combinations for those because rules can be applied any number of times.</p></div><p class="calibre8">We had to consider the absolute values of the function to cater to the case when values are negative, which never happens in running time, but we still have it for completeness.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note03" class="calibre1"/>Note</h3><p class="calibre8">There is something about the sign <span class="strong"><em class="calibre12">=</em></span> that is not usual. Just because <span class="strong"><em class="calibre12">f(x) = O(g(x))</em></span>, it does not mean, <span class="strong"><em class="calibre12">O(g(x)) = f(x)</em></span>. In fact, the last one does not even mean anything.</p></div><p class="calibre8">It is enough for all purposes to just know the preceding definition of the big O notation. You can read the following formal definition if you are interested. Otherwise you can skip the rest of this subsection.</p><p class="calibre8">The preceding idea can be summarized in a formal way. We say the expression <span class="strong"><em class="calibre12">f(x) = O(g(x))</em></span> means that positive constants <span class="strong"><em class="calibre12">M</em></span> and <span class="strong"><em class="calibre12">x<sup class="calibre14">0</sup></em></span> exist, such that <span class="strong"><em class="calibre12">|f(x)| &lt; M|g(x)|</em></span> whenever <span class="strong"><em class="calibre12">x &gt; x<sup class="calibre14">0</sup></em></span>. Remember that you just have to find one example of <span class="strong"><em class="calibre12">M</em></span> and <span class="strong"><em class="calibre12">x<sup class="calibre14">0</sup></em></span> that satisfy the condition, to make the assertion <span class="strong"><em class="calibre12">f(x) = O(g(x))</em></span>.</p><p class="calibre8">For example, <span class="strong"><em class="calibre12">Figure 1</em></span> shows an example of a function <span class="strong"><em class="calibre12">T(x) = 100x<sup class="calibre14">2</sup></em></span>
<span class="strong"><em class="calibre12">+2000x+200</em></span>. This function is <span class="strong"><em class="calibre12">O(x<sup class="calibre14">2</sup></em></span>
<span class="strong"><em class="calibre12">)</em></span>, with some <span class="strong"><em class="calibre12">x<sup class="calibre14">0</sup></em></span>
<span class="strong"><em class="calibre12">  = 11</em></span> and <span class="strong"><em class="calibre12">M = 300</em></span>. The graph of <span class="strong"><em class="calibre12">300x<sup class="calibre14">2</sup></em></span> overcomes the graph of <span class="strong"><em class="calibre12">T(x)</em></span> at <span class="strong"><em class="calibre12">x=11</em></span> and then stays above <span class="strong"><em class="calibre12">T(x)</em></span> up to infinity. Notice that the function <span class="strong"><em class="calibre12">300x<sup class="calibre14">2</sup></em></span> is <a id="id12" class="calibre1"/>lower than <span class="strong"><em class="calibre12">T(x)</em></span> for smaller values of <span class="strong"><em class="calibre12">x</em></span>, but that does not affect our conclusion.</p><p class="calibre8"> </p><div class="mediaobject"><img src="../images/00002.jpeg" alt="Asymptotic upper bound of a function" class="calibre9"/><div class="caption"><p class="calibre15">Figure 1. Asymptotic upper bound</p></div></div><p class="calibre10"> </p><p class="calibre8">
</p><p class="calibre8">To see that it's the same thing as the previous four points, first think of <span class="strong"><em class="calibre12">x<sup class="calibre14">0</sup></em></span> as the way to ensure that <span class="strong"><em class="calibre12">x</em></span> is sufficiently large. I leave it up to you to prove the above four conditions from the <a id="id13" class="calibre1"/>formal definition.</p><p class="calibre8">I will, however, show some examples of using the formal definition:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><em class="calibre12">5x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12"> = O(x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12">)</em></span> because we can say, for example, <span class="strong"><em class="calibre12">x<sup class="calibre14">0</sup></em></span><span class="strong"><em class="calibre12"> = 10</em></span> and <span class="strong"><em class="calibre12">M = 10</em></span> and thus <span class="strong"><em class="calibre12">f(x) &lt; Mg(x)</em></span> whenever <span class="strong"><em class="calibre12">x &gt; x<sup class="calibre14">0</sup></em></span>, that is, <span class="strong"><em class="calibre12">5x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12"> &lt; 10x<sup class="calibre14">2</sup></em></span> whenever <span class="strong"><em class="calibre12">x &gt; 10</em></span>.</li><li class="listitem">It is also true that <span class="strong"><em class="calibre12">5x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12"> = O(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span> because we can say, for example, <span class="strong"><em class="calibre12">x<sup class="calibre14">0</sup></em></span><span class="strong"><em class="calibre12"> = 10</em></span> and <span class="strong"><em class="calibre12">M = 10</em></span> and thus <span class="strong"><em class="calibre12">f(x) &lt; Mg(x)</em></span> whenever <span class="strong"><em class="calibre12">x &gt; x<sup class="calibre14">0</sup></em></span>, that is, <span class="strong"><em class="calibre12">5x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12"> &lt; 10x<sup class="calibre14">3</sup></em></span> whenever <span class="strong"><em class="calibre12">x &gt; 10</em></span>. This highlights a point that if <span class="strong"><em class="calibre12">f(x) = O(g(x))</em></span>, it is also true that <span class="strong"><em class="calibre12">f(x) = O(h(x))</em></span> if <span class="strong"><em class="calibre12">h(x)</em></span> is some functions that grows at least as fast as <span class="strong"><em class="calibre12">f(x)</em></span>.</li><li class="listitem">How about the function <span class="strong"><em class="calibre12">f(x) = 5x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12"> - 10x + 3</em></span>? We can easily see that when <span class="strong"><em class="calibre12">x</em></span> is sufficiently large, <span class="strong"><em class="calibre12">5x<sup class="calibre14">2</sup></em></span> will far surpass the term <span class="strong"><em class="calibre12">10x</em></span>. To prove my point, I can simply say <span class="strong"><em class="calibre12">x&gt;5, 5x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12">&gt; 10x</em></span>. Every time we increment <span class="strong"><em class="calibre12">x</em></span> by one, the increment in <span class="strong"><em class="calibre12">5x<sup class="calibre14">2</sup></em></span> is <span class="strong"><em class="calibre12">10x + 1</em></span> and the increment in <span class="strong"><em class="calibre12">10x</em></span> is just a constant, <span class="strong"><em class="calibre12">10</em></span>. <span class="strong"><em class="calibre12">10x+1 &gt; 10</em></span> for all positive <span class="strong"><em class="calibre12">x</em></span>, so it is easy to see why <span class="strong"><em class="calibre12">5x<sup class="calibre14">2</sup></em></span> is always going to stay above <span class="strong"><em class="calibre12">10x</em></span> as <span class="strong"><em class="calibre12">x</em></span> goes higher and higher.</li></ul></div><p class="calibre8">In general, any polynomial of the form <span class="strong"><em class="calibre12">a<sub class="calibre16">n</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-1</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-2</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-2</sup></em></span>
<span class="strong"><em class="calibre12"> + … + a<sub class="calibre16">0</sub></em></span>
<span class="strong"><em class="calibre12"> = O(x<sup class="calibre14">n</sup>)</em></span>. To show this, we will first see that <span class="strong"><em class="calibre12">a<sub class="calibre16">0</sub> = O(1)</em></span>. This is true because we can have <span class="strong"><em class="calibre12">x<sup class="calibre14">0</sup> = 1</em></span> and <span class="strong"><em class="calibre12">M = 2|a<sub class="calibre16">0</sub>|</em></span>, and we will have <span class="strong"><em class="calibre12">|a<sub class="calibre16">0</sub></em></span><span class="strong"><em class="calibre12">| &lt; 2|a<sub class="calibre16">0</sub></em></span>
<span class="strong"><em class="calibre12">|</em></span> whenever <span class="strong"><em class="calibre12">x &gt; 1</em></span>.</p><p class="calibre8">Now, let us <a id="id14" class="calibre1"/>assume it is true for some n. Thus, <span class="strong"><em class="calibre12">a<sub class="calibre16">n</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-1</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-2</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-2</sup></em></span>
<span class="strong"><em class="calibre12"> + … + a<sub class="calibre16">0</sub></em></span>
<span class="strong"><em class="calibre12"> = O(x<sup class="calibre14">n</sup>)</em></span>. What it means, of course, is that some <span class="strong"><em class="calibre12">M<sub class="calibre16">n</sub></em></span> and <span class="strong"><em class="calibre12">x<sup class="calibre14">0</sup></em></span> exist, such that <span class="strong"><em class="calibre12">|a<sub class="calibre16">n</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-1</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-2</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-2</sup></em></span>
<span class="strong"><em class="calibre12"> + … + a<sub class="calibre16">0</sub></em></span>
<span class="strong"><em class="calibre12"> | &lt; M<sub class="calibre16">n</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n</sup></em></span> whenever <span class="strong"><em class="calibre12">x&gt;x<sup class="calibre14">0</sup></em></span>. We can safely assume that <span class="strong"><em class="calibre12">x<sup class="calibre14">0</sup></em></span>
<span class="strong"><em class="calibre12"> &gt;2</em></span>, because if it is not so, we can simply add <span class="strong"><em class="calibre12">2</em></span> to it to get a new <span class="strong"><em class="calibre12">x<sup class="calibre14">0</sup></em></span>, which is at least <span class="strong"><em class="calibre12">2</em></span>.</p><p class="calibre8">Now, <span class="strong"><em class="calibre12">|a<sub class="calibre16">n</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-1</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-2</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-2</sup></em></span>
<span class="strong"><em class="calibre12"> + … + a<sub class="calibre16">0</sub></em></span>
<span class="strong"><em class="calibre12">| &lt; M<sub class="calibre16">n</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n</sup></em></span> implies <span class="strong"><em class="calibre12">|a<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n+1</sup> + a<sub class="calibre16">n</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-1</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-2</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-2</sup></em></span>
<span class="strong"><em class="calibre12"> + … + a<sub class="calibre16">0</sub></em></span>
<span class="strong"><em class="calibre12">| ≤ |a<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n+1</sup></em></span>
<span class="strong"><em class="calibre12">| + |a<sub class="calibre16">nxn</sub></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-1</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-2</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-2</sup></em></span>
<span class="strong"><em class="calibre12"> + … + a<sub class="calibre16">0</sub></em></span>
<span class="strong"><em class="calibre12">| &lt; |a<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n+1</sup></em></span>
<span class="strong"><em class="calibre12">| + M<sub class="calibre16">n</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n</sup></em></span>.</p><p class="calibre8">This means <span class="strong"><em class="calibre12">|a<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n+1</sup></em></span>
<span class="strong"><em class="calibre12">| + M<sub class="calibre16">n</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> &gt; |a<sub class="calibre16">n</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-1</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-2</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-2</sup></em></span>
<span class="strong"><em class="calibre12"> + … + a<sub class="calibre16">0</sub></em></span>
<span class="strong"><em class="calibre12">|</em></span>.</p><p class="calibre8">If we take <span class="strong"><em class="calibre12">M<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12">= |a<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12">| + M<sub class="calibre16">n</sub></em></span>, we can see that <span class="strong"><em class="calibre12">M<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12"> x<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12"> = |a<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12">| x<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12"> + M<sub class="calibre16">n</sub></em></span>
<span class="strong"><em class="calibre12"> x<sup class="calibre14">n+1</sup></em></span>
<span class="strong"><em class="calibre12"> =|a<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12"> x<sup class="calibre14">n+1</sup></em></span>
<span class="strong"><em class="calibre12">| + M<sub class="calibre16">n</sub></em></span>
<span class="strong"><em class="calibre12"> x<sup class="calibre14">n+1</sup></em></span>
<span class="strong"><em class="calibre12">&gt; |a<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12"> x<sup class="calibre14">n+1</sup></em></span>
<span class="strong"><em class="calibre12">| + M<sub class="calibre16">n</sub></em></span>
<span class="strong"><em class="calibre12"> x<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> &gt; |a<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12"> x<sup class="calibre14">n+1</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-1</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-2</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-2</sup></em></span>
<span class="strong"><em class="calibre12"> + … + a<sub class="calibre16">0</sub></em></span>
<span class="strong"><em class="calibre12">|</em></span>.</p><p class="calibre8">That is to say, <span class="strong"><em class="calibre12">|a<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12"> x<sup class="calibre14">n+1</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-1</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-2</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-2</sup></em></span>
<span class="strong"><em class="calibre12"> + … + a<sub class="calibre16">0</sub></em></span>
<span class="strong"><em class="calibre12"> |&lt; M<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12"> x<sup class="calibre14">n+1</sup></em></span> for all <span class="strong"><em class="calibre12">x &gt; x<sub class="calibre16">0</sub></em></span>, that is, <span class="strong"><em class="calibre12">a<sub class="calibre16">n+1</sub></em></span>
<span class="strong"><em class="calibre12"> x<sup class="calibre14">n+1</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-1</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">n-2</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-2</sup></em></span>
<span class="strong"><em class="calibre12"> + … + a<sub class="calibre16">0</sub></em></span>
<span class="strong"><em class="calibre12"> = O(x<sup class="calibre14">n+1</sup></em></span>
<span class="strong"><em class="calibre12">)</em></span>.</p><p class="calibre8">Now, we have it true for <span class="strong"><em class="calibre12">n=0</em></span>, that is, <span class="strong"><em class="calibre12">a0 = O(1)</em></span>. This means, by our last conclusion, <span class="strong"><em class="calibre12">a</em></span>
<span class="strong"><em class="calibre12">1<sub class="calibre16">x</sub> + a<sub class="calibre16">0</sub></em></span>
<span class="strong"><em class="calibre12"> = O(x)</em></span>. This means, by the same logic, <span class="strong"><em class="calibre12">a<sub class="calibre16">2</sub></em></span>
<span class="strong"><em class="calibre12"> x<sup class="calibre14">2</sup></em></span>
<span class="strong"><em class="calibre12"> + a<sub class="calibre16">1</sub></em></span>
<span class="strong"><em class="calibre12">x + a<sub class="calibre16">0</sub></em></span>
<span class="strong"><em class="calibre12"> = O(x<sup class="calibre14">2</sup></em></span>
<span class="strong"><em class="calibre12">)</em></span>, and so on. We can easily see that this means it is true for all polynomials of positive integral degrees.</p></div><div class="book" title="Asymptotic upper bound of an algorithm"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch01lvl3sec02" class="calibre1"/>Asymptotic upper bound of an algorithm</h3></div></div></div><p class="calibre8">Okay, so we <a id="id15" class="calibre1"/>figured out a way to sort of abstractly specify an upper bound on a function that has one argument. When we talk about the running time of a program, this argument has to contain information about the input. For example, in our algorithm, we can say, the execution time equals O(power). This scheme of specifying the input directly will work perfectly fine for all programs or algorithms solving the same problem because the input will be the same for all of them. However, we might want to use the same technique to measure the complexity of the problem itself: it is the complexity of the most efficient program or algorithm that can solve the problem. If we try to compare the complexity of different problems, though, we will hit a wall because different problems will have different inputs. We must specify the running time in terms of something that is common among all problems, and that something is the size of the input in bits or bytes. How many bits do we need to express the argument, power, when it's sufficiently large? Approximately <span class="strong"><em class="calibre12">log<sub class="calibre16">2</sub></em></span><span class="strong"><em class="calibre12"> (power)</em></span>. So, in specifying the running time, our function needs to have an input that <a id="id16" class="calibre1"/>is of the size <span class="strong"><em class="calibre12">log<sub class="calibre16">2</sub></em></span><span class="strong"><em class="calibre12"> (power)</em></span> or <span class="strong"><em class="calibre12">lg (power)</em></span>. We have seen that the running time of our algorithm is proportional to the power, that is, constant times power, which is constant times <span class="strong"><em class="calibre12">2 lg(power) = O(2x)</em></span>,where <span class="strong"><em class="calibre12">x= lg(power)</em></span>, which is the the size of the input.</p></div><div class="book" title="Asymptotic lower bound of a function"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch01lvl3sec03" class="calibre1"/>Asymptotic lower bound of a function</h3></div></div></div><p class="calibre8">Sometimes, we <a id="id17" class="calibre1"/>don't want to praise an algorithm, we want to shun it; for example, when the algorithm is written by someone we don't like or when some algorithm is really poorly performing. When we want to shun it for its horrible performance, we may want to talk about how badly it performs even for the best input. An a symptotic lower bound can be defined just like how greater-than-or-equal-to can be defined in terms of less-than-or-equal-to.</p><p class="calibre8">A function <span class="strong"><em class="calibre12">f(x) = Ω(g(x))</em></span> if and only if <span class="strong"><em class="calibre12">g(x) = O(f(x))</em></span>. The following list shows a few examples:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Since <span class="strong"><em class="calibre12">x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> = O(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span>, <span class="strong"><em class="calibre12">x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> = Ω(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span></li><li class="listitem">Since <span class="strong"><em class="calibre12">x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> = O(5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span>, <span class="strong"><em class="calibre12">5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> = Ω(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span></li><li class="listitem">Since <span class="strong"><em class="calibre12">x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> = O(5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> - 25x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12"> + 1)</em></span>, <span class="strong"><em class="calibre12">5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> - 25x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12"> + 1 = Ω(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span></li><li class="listitem">Since <span class="strong"><em class="calibre12">x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> = O(x<sup class="calibre14">4</sup></em></span><span class="strong"><em class="calibre12">)</em></span>, <span class="strong"><em class="calibre12">x<sup class="calibre14">4</sup></em></span><span class="strong"><em class="calibre12"> = O(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span></li></ul></div><p class="calibre8">Again, for those of you who are interested, we say the expression <span class="strong"><em class="calibre12">f(x) = Ω(g(x))</em></span> means there exist positive constants <span class="strong"><em class="calibre12">M</em></span> and <span class="strong"><em class="calibre12">x<sub class="calibre16">0</sub></em></span>, such that <span class="strong"><em class="calibre12">|f(x)| &gt; M|g(x)|</em></span> whenever <span class="strong"><em class="calibre12">x &gt; x<sub class="calibre16">0</sub></em></span>, which is the same as saying <span class="strong"><em class="calibre12">|g(x)| &lt; (1/M)|f(x)|</em></span> whenever <span class="strong"><em class="calibre12">x &gt; x<sub class="calibre16">0</sub></em></span>, that is, <span class="strong"><em class="calibre12">g(x) = O(f(x))</em></span>.</p><p class="calibre8">The preceding definition was introduced by Donald Knuth, which was a stronger and more practical definition to be used in computer science. Earlier, there was a different definition of the lower bound <span class="strong"><em class="calibre12">Ω</em></span> that is more complicated to understand and covers a few more edge cases. We will not talk about edge cases here.</p><p class="calibre8">While talking about how horrible an algorithm is, we can use an asymptotic lower bound of the best case to really make our point. However, even a criticism of the worst case of an algorithm is quite a valid argument. We can use an asymptotic lower bound of the worst case too for this purpose, when we don't want to find out an asymptotic tight bound. In general, the asymptotic lower bound can be used to show a minimum rate of growth of a function <a id="id18" class="calibre1"/>when the input is large enough in size.</p></div><div class="book" title="Asymptotic tight bound of a function"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch01lvl3sec04" class="calibre1"/>Asymptotic tight bound of a function</h3></div></div></div><p class="calibre8">There is another <a id="id19" class="calibre1"/>kind of bound that sort of means equality in terms of asymptotic complexity. A theta bound is specified as <span class="strong"><em class="calibre12">f(x) = </em></span><span class="strong"><em class="calibre12">Ͽ(g(x))</em></span> if and only if <span class="strong"><em class="calibre12">f(x) = O(g(x))</em></span> and <span class="strong"><em class="calibre12">f(x) = Ω(g(x))</em></span>. Let's see some examples to understand this even better:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Since <span class="strong"><em class="calibre12">5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">=O(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span> and also <span class="strong"><em class="calibre12">5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">=Ω(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span>, we have <span class="strong"><em class="calibre12">5</em></span><span class="strong"><em class="calibre12">x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">=</em></span><span class="strong"><em class="calibre12">Ͽ</em></span><span class="strong"><em class="calibre12">(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span></li><li class="listitem">Since <span class="strong"><em class="calibre12">5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> +</em></span><span class="strong"><em class="calibre12"> 4x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12">=O(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span> and <span class="strong"><em class="calibre12">5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> + 4x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12">=</em></span><span class="strong"><em class="calibre12">Ω(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span>, we have <span class="strong"><em class="calibre12">5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> + 4x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12">=O(x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12">)</em></span></li><li class="listitem">However, even though <span class="strong"><em class="calibre12">5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> + 4x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12"> =O(x<sup class="calibre14">4</sup></em></span><span class="strong"><em class="calibre12">)</em></span>, since it is not <span class="strong"><em class="calibre12">Ω(x<sup class="calibre14">4</sup></em></span><span class="strong"><em class="calibre12">)</em></span>, it is also not <span class="strong"><em class="calibre12">Ͽ</em></span><span class="strong"><em class="calibre12">(</em></span><span class="strong"><em class="calibre12">x<sup class="calibre14">4</sup></em></span><span class="strong"><em class="calibre12">)</em></span></li><li class="listitem">Similarly, <span class="strong"><em class="calibre12">5x<sup class="calibre14">3</sup></em></span><span class="strong"><em class="calibre12"> + 4x<sup class="calibre14">2</sup></em></span> is not <span class="strong"><em class="calibre12">Ͽ</em></span><span class="strong"><em class="calibre12">(x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12">)</em></span> because it is not <span class="strong"><em class="calibre12">O(x<sup class="calibre14">2</sup></em></span><span class="strong"><em class="calibre12">)</em></span></li></ul></div><p class="calibre8">In short, you can ignore constant multipliers and lower order terms while determining the tight bound, but you cannot choose a function which grows either faster or slower than the given function. The best way to check whether the bound is right is to check the <span class="strong"><em class="calibre12">O</em></span> and the condition separately, and say it has a theta bound only if they are the same.</p><p class="calibre8">Note that since the complexity of an algorithm depends on the particular input, in general, the tight bound is used when the complexity remains unchanged by the nature of the input.</p><p class="calibre8">In some cases, we try to find the average case complexity, especially when the upper bound really happens only in the case of an extremely pathological input. But since the average must be taken in accordance with the probability distribution of the input, it is not just dependent on the algorithm itself. The bounds themselves are just bounds for particular functions and not for algorithms. However, the total running time of an algorithm can be expressed as a grand function that changes it's formula as per the input, and that function may have different upper and lower bounds. There is no sense in talking about an asymptotic average bound because, as we discussed, the average case is not just dependent on the algorithm itself, but also on the probability distribution of the input. The average case is thus stated as a function that would be a probabilistic average running time for all inputs, and, in general, the asymptotic upper bound of that average function is reported.</p></div></div></div></div>
<div class="book" title="Optimization of our algorithm" id="F8901-eeeded97b5e248ac807bb1bec4d7c800"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch01lvl1sec09" class="calibre1"/>Optimization of our algorithm</h1></div></div></div><p class="calibre8">Before we dive <a id="id20" class="calibre1"/>into actually optimizing algorithms, we need to first correct our algorithm for large powers. We will use some tricks to do so, as described below.</p></div>

<div class="book" title="Fixing the problem with large powers" id="G6PI1-eeeded97b5e248ac807bb1bec4d7c800"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch01lvl1sec10" class="calibre1"/>Fixing the problem with large powers</h1></div></div></div><p class="calibre8">Equipped with all the toolboxes of asymptotic analysis, we will start optimizing our algorithm. However, since <a id="id21" class="calibre1"/>we have already seen that our program does not work properly for even moderately large values of power, let's first fix that. There are two ways of fixing this; one is to actually give the amount of space it requires to store all the intermediate products, and the other is to do a trick to limit all the intermediate steps to be within the range of values that the <code class="email">long</code> datatype can support. We will use binomial theorem to do this part.</p><p class="calibre8">As a reminder, binomial theorem says <span class="strong"><em class="calibre12">(x+y)<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> = x<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> + <sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12">C<sub class="calibre16">1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-1</sup></em></span>
<span class="strong"><em class="calibre12">y + <sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12">C<sub class="calibre16">2</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-2</sup></em></span>
<span class="strong"><em class="calibre12">y<sup class="calibre14">2</sup></em></span>
<span class="strong"><em class="calibre12"> + <sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12">C<sub class="calibre16">3</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-3</sup></em></span>
<span class="strong"><em class="calibre12">y<sup class="calibre14">3</sup></em></span>
<span class="strong"><em class="calibre12"> + <sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12">C<sub class="calibre16">4</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">n-4</sup></em></span>
<span class="strong"><em class="calibre12">y<sup class="calibre14">4</sup></em></span>
<span class="strong"><em class="calibre12"> + … <sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12">C<sub class="calibre16">n-1</sub></em></span>
<span class="strong"><em class="calibre12">x<sup class="calibre14">1</sup></em></span>
<span class="strong"><em class="calibre12">y<sup class="calibre14">n-1</sup></em></span>
<span class="strong"><em class="calibre12"> + y<sup class="calibre14">n</sup></em></span> for positive integral values of <span class="strong"><em class="calibre12">n</em></span>. The important point here is that all the coefficients are integers. Suppose, <span class="strong"><em class="calibre12">r</em></span> is the remainder when we divide a by <span class="strong"><em class="calibre12">b</em></span>. This makes <span class="strong"><em class="calibre12">a = kb + r</em></span> true for some positive integer <span class="strong"><em class="calibre12">k</em></span>. This means <span class="strong"><em class="calibre12">r = a-kb</em></span>, and <span class="strong"><em class="calibre12">r<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> = (a-kb)<sup class="calibre14">n</sup></em></span>.</p><p class="calibre8">If we expand this using binomial theorem, we have <span class="strong"><em class="calibre12">r<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> = a<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> - <sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12">C<sub class="calibre16">1</sub></em></span>
<span class="strong"><em class="calibre12"> a<sup class="calibre14">n-1</sup></em></span>
<span class="strong"><em class="calibre12">.kb + <sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12">C<sub class="calibre16">2</sub></em></span>
<span class="strong"><em class="calibre12">a<sup class="calibre14">n-2</sup></em></span>
<span class="strong"><em class="calibre12">.(kb)<sup class="calibre14">2</sup></em></span>
<span class="strong"><em class="calibre12"> - <sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12">C<sub class="calibre16">3</sub></em></span>
<span class="strong"><em class="calibre12">a<sup class="calibre14">n-3</sup></em></span>
<span class="strong"><em class="calibre12">.(kb)<sup class="calibre14">3</sup></em></span>
<span class="strong"><em class="calibre12"> + <sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12">C<sub class="calibre16">4</sub></em></span>
<span class="strong"><em class="calibre12">a<sup class="calibre14">n-4</sup></em></span>
<span class="strong"><em class="calibre12">.(kb)<sup class="calibre14">4</sup></em></span>
<span class="strong"><em class="calibre12"> + … <sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12">C<sub class="calibre16">n-1</sub></em></span>
<span class="strong"><em class="calibre12">a<sup class="calibre14">1</sup></em></span>
<span class="strong"><em class="calibre12">.(kb)<sup class="calibre14">n-1</sup></em></span>
<span class="strong"><em class="calibre12"> ± (kb)<sup class="calibre14">n</sup></em></span>.</p><p class="calibre8">Note that apart from the first term, all other terms have <span class="strong"><em class="calibre12">b</em></span> as a factor. Which means that we can write <span class="strong"><em class="calibre12">r<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> = a<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> + bM</em></span> for some integer <span class="strong"><em class="calibre12">M</em></span>. If we divide both sides by <span class="strong"><em class="calibre12">b</em></span> now and take the remainder, we have <span class="strong"><em class="calibre12">r<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> % b = a<sup class="calibre14">n</sup></em></span>
<span class="strong"><em class="calibre12"> % b</em></span>, where <span class="strong"><em class="calibre12">%</em></span> is the Java operator for finding the remainder.</p><p class="calibre8">The idea now would be to take the remainder by the divisor every time we raise the power. This way, we will never have to store more than the range of the remainder:</p><div class="informalexample"><pre class="programlisting">public static long computeRemainderCorrected(long base, long power, long divisor){
  long baseRaisedToPower = 1;
  for(long i=1;i&lt;=power;i++){
    baseRaisedToPower *= base;
    baseRaisedToPower %= divisor;
  }
  return baseRaisedToPower;
}</pre></div><p class="calibre8">This program obviously does not change the time complexity of the program; it just fixes the problem with large powers. The program also maintains a constant space complexity.</p></div>

<div class="book" title="Fixing the problem with large powers" id="G6PI1-eeeded97b5e248ac807bb1bec4d7c800">
<div class="book" title="Improving time complexity"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch01lvl2sec09" class="calibre1"/>Improving time complexity</h2></div></div></div><p class="calibre8">The current running time <a id="id22" class="calibre1"/>complexity is <span class="strong"><em class="calibre12">O(2<sup class="calibre14">x</sup></em></span>
<span class="strong"><em class="calibre12">)</em></span>, where <span class="strong"><em class="calibre12">x</em></span> is the size of the input as we have already computed. Can we do better than this? Let's see.</p><p class="calibre8">What we need to compute is <span class="strong"><em class="calibre12">(base<sup class="calibre14">power</sup></em></span>
<span class="strong"><em class="calibre12">) % divisor</em></span>. This is, of course, the same as <span class="strong"><em class="calibre12">(base<sup class="calibre14">2</sup>)<sup class="calibre14">power/2</sup></em></span>
<span class="strong"><em class="calibre12"> % divisor</em></span>. If we have an even <span class="strong"><em class="calibre12">power</em></span>, we have reduced the number of operations by half. If we can keep doing this, we can raise the <span class="strong"><em class="calibre12">power</em></span> of <span class="strong"><em class="calibre12">base</em></span> by <span class="strong"><em class="calibre12">2<sup class="calibre14">n</sup></em></span> in just <span class="strong"><em class="calibre12">n</em></span> steps, which means our loop only has to run <span class="strong"><em class="calibre12">lg(power)</em></span> times, and hence, the complexity is <span class="strong"><em class="calibre12">O(lg(2<sup class="calibre14">x</sup></em></span>
<span class="strong"><em class="calibre12">)) = O(x)</em></span>, where <span class="strong"><em class="calibre12">x</em></span> is the number of bits to store <span class="strong"><em class="calibre12">power</em></span>. This is a substantial reduction in the number of steps to compute the value for large powers.</p><p class="calibre8">However, there is a catch. What happens if the <span class="strong"><em class="calibre12">power</em></span> is not divisible by <span class="strong"><em class="calibre12">2</em></span>? Well, then we can write <span class="strong"><em class="calibre12">(base<sup class="calibre14">power</sup></em></span>
<span class="strong"><em class="calibre12">)% divisor = (base ((base<sup class="calibre14">power-1</sup></em></span>
<span class="strong"><em class="calibre12">))%divisor = (base ((base<sup class="calibre14">2</sup>)<sup class="calibre14">power-1</sup></em></span>
<span class="strong"><em class="calibre12">)%divisor</em></span>, and <span class="strong"><em class="calibre12">power-1</em></span> is, of course, even and the computation can proceed. We will write up this code in a program. The idea is to start from the most significant bit and move towards less and less significant bits. If a bit with <span class="strong"><em class="calibre12">1</em></span> has <span class="strong"><em class="calibre12">n</em></span> bits after it, it represents multiplying the result by the base and then squaring <span class="strong"><em class="calibre12">n</em></span> times after this bit. We accumulate this squaring by squaring for the subsequent steps. If we find a zero, we keep squaring for the sake of accumulating squaring for the earlier bits:</p><div class="informalexample"><pre class="programlisting">public static long computeRemainderUsingEBS(long base, long power, long divisor){
  long baseRaisedToPower = 1;
  long powerBitsReversed = 0;
  int numBits=0;</pre></div><p class="calibre8">First reverse the bits of our <code class="email">power</code> so that it is easier to access them from the least important side, which is more easily accessible. We also count the number of bits for later use:</p><div class="informalexample"><pre class="programlisting">  while(power&gt;0){
    powerBitsReversed &lt;&lt;= 1;
    powerBitsReversed += power &amp; 1;
    power &gt;&gt;&gt;= 1;
    numBits++;
  }</pre></div><p class="calibre8">Now we extract one bit at a time. Since we have already reversed the order of bit, the first one we get is the most significant one. Just to get an intuition on the order, the first bit we collect will eventually be squared the maximum number of times and hence will act like the most significant bit:</p><div class="informalexample"><pre class="programlisting">  while (numBits--&gt;0){
    if(powerBitsReversed%2==1){
      baseRaisedToPower *= baseRaisedToPower * base;
    }else{
      baseRaisedToPower *= baseRaisedToPower;
    }
    baseRaisedToPower %= divisor;
    powerBitsReversed&gt;&gt;&gt;=1;
  }
  return baseRaisedToPower;
}</pre></div><p class="calibre8">We test the performance of the algorithm; we compare the time taken for the same computation with the <a id="id23" class="calibre1"/>earlier and final algorithms with the following code:</p><div class="informalexample"><pre class="programlisting">public static void main(String [] args){
  System.out.println(computeRemainderUsingEBS(13, 10_000_000, 7));

  long startTime = System.currentTimeMillis();
  for(int i=0;i&lt;1000;i++){
    computeRemainderCorrected(13, 10_000_000, 7);
  } 
  long endTime = System.currentTimeMillis();
  System.out.println(endTime - startTime);

  startTime = System.currentTimeMillis();
  for(int i=0;i&lt;1000;i++){
    computeRemainderUsingEBS(13, 10_000_000, 7);
  }
  endTime = System.currentTimeMillis();
  System.out.println(endTime - startTime);
}</pre></div><p class="calibre8">The first algorithm takes 130,190 milliseconds to complete all 1,000 times execution on my computer and the second one takes just 2 milliseconds to do the same. This clearly shows the tremendous gain in performance for a large power like 10 million. The algorithm for squaring the term repeatedly to achieve exponentiation like we did is called... well, exponentiation by squaring. This example should be able to motivate you to study algorithms for the sheer obvious advantage it can give in improving the performance of computer programs.</p></div></div>
<div class="book" title="Summary" id="H5A41-eeeded97b5e248ac807bb1bec4d7c800"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch01lvl1sec11" class="calibre1"/>Summary</h1></div></div></div><p class="calibre8">In this chapter, you saw how we can think about measuring the running time of and the memory required by an algorithm in seconds and bytes, respectively. Since this depends on the particular implementation, the programming platform, and the hardware, we need a notion of talking about running time in an abstract way. Asymptotic complexity is a measure of the growth of a function when the input is very large. We can use it to abstract our discussion on running time. This is not to say that a programmer should not spend any time to make a run a program twice as fast, but that comes only after the program is already running at the minimum asymptotic complexity.</p><p class="calibre8">We also saw that the asymptotic complexity is not just a property of the problem at hand that we are trying to solve, but also a property of the particular way we are solving it, that is, the particular algorithm we are using. We also saw that two programs solving the same problem while running different algorithms with different asymptotic complexities can perform vastly differently for large inputs. This should be enough motivation to study algorithms explicitly.</p><p class="calibre8">In the following chapters, we will study the most used algorithmic tricks and concepts required in daily use. We will start from the very easy ones that are also the building blocks for the more advanced techniques. This book is, of course, by no means comprehensive; the objective is to provide enough background to make you comfortable with the basic concepts and then you can read on.</p></div></body></html>