- en: Graphs, Prime Numbers, and Complexity Classes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Graph problems are very common in computer science, and their applications pervade
    many real-life applications. Everything that can be represented by entities and
    their relationships can ultimately be modeled by a graph. How we connect with
    friends on social media, how route-planning applications are able to find the
    shortest route, and how e-commerce websites are able to provide us with recommendations
    are all examples of problems modeled by graphs.
  prefs: []
  type: TYPE_NORMAL
- en: A graph is a structure composed of a set of objects in which some pairs of objects
    are related. The objects are modeled by the mathematical abstraction of vertices
    (sometimes also called nodes), and the pairwise relationships are modeled by the
    mathematical abstraction of edges (sometimes also called arcs).
  prefs: []
  type: TYPE_NORMAL
- en: Edges can be directed or undirected. A directed edge is an edge which has a
    direction associated with it. A graph that is composed of directed edges is called
    a directed graph. A graph that is composed of undirected edges is called an undirected
    graph. In a directed edge, it is common to call the start of the edge the head
    and the end of the edge the tail. In a directed graph, the out-degree of a vertex
    is the number of edges whose head is adjacent to it. The in-degree of a vertex
    is the number of edges whose tail is adjacent to it.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 6.1* gives an example of a directed graph with six nodes and eight
    edges, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bc8a9fae-e427-4835-a3d5-69a984df089b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.1: A directed graph'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 6.2* gives an example of an undirected graph with five nodes and seven
    edges, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/298ca250-bda8-4e99-972c-3fa860ae7598.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.2: An undirected graph'
  prefs: []
  type: TYPE_NORMAL
- en: Before we dive into how to represent a graph in a computer program, it is important
    to describe how the runtime of graph algorithms is usually characterized. As previously
    stated, a graph, *G*, can be seen as a set of vertices and edges, that is, *G
    = (V, E)*. As such, the size of the input is usually measured in terms of the
    number of vertices (*|V|*) and the number of edges (*|E|*). So, instead of relying
    solely on a single input size, *N*, the runtime of graph algorithms usually refers
    to both *|V|* and *|E|*. In big O notation, it is common to use *V* to denote
    *|V|* and *E* to denote *|E|*. For example, an algorithm that runs in time proportional
    to the number of vertices multiplied by the number of edges is said to run in
    time *O(VE)*.
  prefs: []
  type: TYPE_NORMAL
- en: Representing Graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are usually two standard ways to represent a graph *G = (V, E)* in a
    computer program:'
  prefs: []
  type: TYPE_NORMAL
- en: As a collection of adjacency lists
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As an adjacency matrix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use either way to represent both directed and undirected graphs. We'll
    start by looking at the adjacency list representation.
  prefs: []
  type: TYPE_NORMAL
- en: Adjacency List Representation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The adjacency list representation of a graph consists of an array of *|V|*
    lists, one for each vertex in *V*. For each vertex *u* in *V*, there''s a list
    containing all vertices *v* so that there is an edge connecting *u* and *v* in
    *E*. *Figure 6.3* shows the adjacency list representation of the directed graph
    in *Figure 6.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c6f058c4-8d1a-4696-89bc-6eca0d572fd3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.3: Adjacency list representation of the directed graph in Figure 6.1'
  prefs: []
  type: TYPE_NORMAL
- en: For undirected graphs, we follow a similar strategy and build the adjacency
    list as if it were a directed graph with two edges between each pair of vertices
    *u* and *v*, which are *(u, v)* and *(v, u)*.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 6.4* shows the adjacency list representation of the undirected graph
    in *Figure 6.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cce9c0c2-0290-4236-b3ec-ec499b019aae.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.4: Adjacency list representation of the undirected graph in Figure
    6.2'
  prefs: []
  type: TYPE_NORMAL
- en: If *G* is a directed graph, the sum of the lengths of all the adjacency lists
    is *|E|*, as each edge constitutes a single node in one of the adjacency lists.
  prefs: []
  type: TYPE_NORMAL
- en: If *G* is an undirected graph, the sum of the lengths of all the adjacency lists
    is *2*|E|*, since each edge *(u, v)* appears twice, that is, once in *u*'s and
    once in *v*'s adjacency list.
  prefs: []
  type: TYPE_NORMAL
- en: For both types of graphs, the adjacency list representation has the property
    of requiring an amount of memory equal to *O(V + E)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet shows how to create a graph using the adjacency
    list representation in Java:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 6.1: Implementation of an adjacency list representation of a graph.
    Source class name: Adjacencylistgraph'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/Jrb2jH](https://goo.gl/Jrb2jH) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: It is common for one to have weighted graphs, that is, graphs in which each
    edge has an associated weight. The adjacency list representation is robust enough
    to support different graph variants, since we can store different edge representations
    in the adjacency lists.
  prefs: []
  type: TYPE_NORMAL
- en: We can store different edge representations in adjacency lists because we store
    the edges themselves, thereby allowing customizable representations.
  prefs: []
  type: TYPE_NORMAL
- en: Writing a Java Code to Add Weights to the Directed Graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The aim is to adapt the implementation of the `AdjacencyListGraph` class to
    support weights on edges.
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps should be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Understand *Snippet 6.1* showing how we can implement the adjacency list representation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Adapt the implementation so that the array list can store the weights
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 6.2: Implementation of an adjacency list representation of a weighted
    graph. Source class name: Adjacencylistweightedgraph'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/uoazxy](https://goo.gl/uoazxy) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: Adjacency Matrix Representation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The adjacency list representation of a graph provides a compact way to represent
    sparse graphs, for example, those for which *|E|* is much less than *|V|²*. Even
    though it is a representation that is useful for a lot of algorithms (which we
    will visit later), it does not support some features. For example, one cannot
    quickly tell whether there is an edge connecting two given vertices. In order
    to determine if *u* and *v* are connected, one has to go through the adjacency
    list of *u* to find an edge connecting it to *v*. Since the adjacency list of
    *u* can have at most *E* edges, this procedure runs in *O(E)* time. One alternative
    representation that remedies this disadvantage at the cost of using asymptotically
    more memory is the adjacency matrix representation.
  prefs: []
  type: TYPE_NORMAL
- en: The main disadvantage of adjacency list representation of a weighted graph representation
    is that we can't quickly determine if a given edge *(u, v)* is present in the
    graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this representation, a graph *G = (V, E)* is represented by a *|V| x |V|*
    matrix *A = (a[ij])*, where *a[ij]* equals *1* if there''s an edge *(i, j)* and
    *0* otherwise. The following table shows the adjacency matrix representation of
    the directed graph of *Figure 6.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/190d01d6-1224-455b-b4e8-b88fdaaec6bb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 6.1: Adjacency matrix representation of the directed graph of Figure
    6.1'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table shows the adjacency matrix representation of the undirected graph
    of *Figure 6.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/52459e9a-347f-43b9-98b6-fd7b932b3f5c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 6.2: Adjacency matrix representation of the undirected graph of Figure
    6.2'
  prefs: []
  type: TYPE_NORMAL
- en: The adjacency matrix representation of a graph requires *O(V²)* memory, independent
    of the number of edges in the graph. One thing to note on the adjacency matrix
    representation of undirected graphs is that the matrix is symmetrical along the
    main diagonal, since *(u, v)* and *(v, u)* represent the same edge. As such, the
    adjacency matrix of an undirected graph is its own transpose *(A = A^T)*. Taking
    advantage of this symmetry, one can cut on the memory needed to store the graph
    almost in half, as you don't need the array of each vertex to have size *V*. If
    *i* tracks the index of vertices in *V*, the size of *array[i]* can decrease by
    one as *i* increases by one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows how to create a graph using the adjacency matrix representation
    in Java:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 6.3: Implementation of an adjacency matrix representation of a directed
    graph. Source class name: AdjacencyMatrixGraph'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/EGyZJj](https://goo.gl/EGyZJj) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: The adjacency matrix representation is also robust enough to support different
    graph variants. In order to support weighted graphs, for example, one can store
    the weight of the edge in *a[ij]*, instead of just one. The adjacency list representation
    is asymptotically at least as space-efficient as the adjacency matrix representation,
    but adjacency matrices are simpler, so they might be preferable when the graphs
    are reasonably small or dense. As previously stated, a sparse graph is one in
    which *|E|* is much less than *|V|²*, whereas a dense graph is one in which *|E|*
    is closer to *|V|²*. The adjacency list representation is more memory-efficient
    for sparse graphs. For dense graphs, an adjacency matrix representation is better
    suited, as it possibly takes less memory due to list pointers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity: Building the Adjacency Matrix Representation of a Weighted Undirected
    Graph'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Scenario**'
  prefs: []
  type: TYPE_NORMAL
- en: Creating an adjacency matrix for a weighted undirected graph to be used for
    social networking website.
  prefs: []
  type: TYPE_NORMAL
- en: '**Aim**'
  prefs: []
  type: TYPE_NORMAL
- en: To write a code in Java for implementing the adjacency matrix representation
    of a weighted undirected graph.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prerequisites**'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this activity, you have to implement methods `addEdge()` and `edgeWeight()`
    of class `AdjacencyMatrixWeightedUndirected` available at the following URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson6/activity/weightedundirected/AdjacencyMatrixWeightedUndirected.java](https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson6/activity/weightedundirected/AdjacencyMatrixWeightedUndirected.java)'
  prefs: []
  type: TYPE_NORMAL
- en: The methods should add an edge and return the edge weight between two vertices, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '**Steps for Completion**'
  prefs: []
  type: TYPE_NORMAL
- en: Start storing the weights of edges in each cell of the matrix. Since we're dealing
    with undirected graphs, both *(u, v)* and *(v, u)* refer to the same edge, so
    we need to update both accordingly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is also possible to not repeat the weight assignment. We just have to be
    careful and always choose one of *(u, v)* or *(v, u)* when referring to that edge.
    One possible strategy is to always use *(min(u, v), max(u, v))*. Using that strategy,
    we also don't need to store the full matrix, thereby saving some space.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this first section, we learned two different ways of representing a graph
    in a computer program. We briefly examined the pros and cons of each representation,
    and we will take a look at their usefulness when implementing graph algorithms
    in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Traversing a Graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A common activity on a graph is visiting each vertex of it in a given order.
    We will start by introducing the breadth-first search, and then follow with depth-first
    search. Both of these techniques form the archetype for many important graph algorithms, as
    we will see later with the cycle detection and Dijkstra's algorithm for single-source shortest
    paths.
  prefs: []
  type: TYPE_NORMAL
- en: Breadth-First Search
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Given a graph *G = (V, E)* and a source vertex s, breadth-first search explores
    the edges of *G* systematically to discover every vertex that is reachable from
    *s*. While doing so, it computes the smallest number of edges from *s* to each
    reachable vertex, making it suitable to solve the single-source shortest path
    problem on unweighted graphs, or graphs whose edges all have the same weight.
  prefs: []
  type: TYPE_NORMAL
- en: '**Breadth-First Search** (**BFS**) is named so because it expands the frontier
    between discovered and undiscovered vertices uniformly across the breadth of the
    frontier. In that sense, the algorithm first explores vertices at distance *k*
    from *s* before discovering vertices at distance *k + 1*. To keep track of progress,
    breadth-first search identifies each vertex as undiscovered, discovered, or expanded.
    All vertices start out undiscovered. A vertex is discovered the first time it
    is encountered during search, and is expanded when all the vertices adjacent to
    it have been discovered.'
  prefs: []
  type: TYPE_NORMAL
- en: BFS constructs a breadth-first tree, rooted at source vertex *s*. Whenever the
    search discovers an undiscovered vertex *v* when scanning the outward edges of
    already discovered vertex *u*, the vertex *v* and the edge *(**u, v**)* are added
    to the tree. Therefore, *u* becomes the parent of *v* in the breadth-first tree.
    Since a vertex is discovered at most once, it has at most one parent.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to illustrate this, let''s look at a run of breadth-first searches
    for the directed graph of *Figure 6.1*, starting at node 2, in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bacec7ef-7200-40aa-b815-4b0fd60114cb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 6.3: A Run of BFS on the directed graph of Figure 6.1, starting at node
    2'
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of insights to take from the breadth-first tree. For instance,
    the path from the root to a given node in the tree is the shortest path (in terms
    of edges) from those two vertices. Another thing to note is that vertices that
    are not in the breadth-first tree (as is the case of 0) are unreachable from the
    root vertex.
  prefs: []
  type: TYPE_NORMAL
- en: We previously saw how to perform the breadth-first search on trees. BFS on graphs
    is similar, but we need to keep track of explored nodes so that we don't get stuck
    in cycles. In order to implement breadth-first search, we will assume that our
    graph is represented using adjacency lists.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will attach certain attributes to each vertex in the graph that will allow
    us to guide our search and later construct the breadth-first tree. We will also
    use a first-in, first-out queue (covered in [Chapter 2](ab7975d0-4b38-437d-9ff5-8f6c20199874.xhtml),
    *Sorting Algorithms and Fundamental Data Structures*) to manage the set of discovered
    vertices. The following code snippet illustrates the implementation of breadth-first
    search:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 6.4: Implementation of breadth-first search. Source class name: BFS.Graph'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/VqrQWM](https://goo.gl/VqrQWM) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s focus on the implementation of the BFS function. We will start by initializing
    a couple of auxiliary arrays: `parent` and `visited`. The first one will hold,
    at `parent[i]`, the parent of node `i` in the breadth-first tree. The second one
    will tell us, at `visited[i]`, whether or not vertex `i` has been discovered.
    We start by discovering the starting node and adding it to a queue. The queue
    will keep those vertices that have been discovered but not yet expanded. As such,
    while there are still elements in the queue, we will take its first element, go
    through its adjacent vertices, and discover those that haven''t already been discovered,
    adding them to the queue.'
  prefs: []
  type: TYPE_NORMAL
- en: When the queue becomes empty, we're sure of having expanded all vertices that
    are reachable from the starting vertex.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous implementation, we've returned the array of parent nodes of
    the breadth-first tree in the `bfs()` function, allowing us to reconstruct the
    paths. If not necessary, you could just return the size of paths, or any other
    information we might be interested in extracting from the breadth-first search
    traversal.
  prefs: []
  type: TYPE_NORMAL
- en: In the `bfs()` method, we're sure of enqueuing, and hence dequeuing, each vertex
    at most once. As such, the total time dedicated to queue operations is *O(V)*.
    After dequeuing each vertex, we scan its adjacency list. Since we dequeue each
    vertex at most once, we scan each adjacency list at most once. As the sum of lengths
    of all the adjacency lists is *O(E)*, the total time spent in scanning adjacency
    lists is *O(E)*. Therefore, the BFS procedure has an initialization time of *O(V)*
    and a total running time of *O(V + E)*, running in linear time to the size of
    the adjacency list representation of *G*.
  prefs: []
  type: TYPE_NORMAL
- en: As we will see in later sections, the BFS procedure is the archetype for many
    important graph algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Depth-First Search
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Given a graph *G = (V, E)* and a source vertex s, depth-first search explores
    the edges of the graph by going "deeper" in the graph whenever possible. **Depth-First
    Search** (**DFS**) explores edges adjacent to the most recently discovered vertex
    *v* that still has unexplored edges whose head is adjacent to it. Once all of
    *v*'s edges have been explored, the search "backtracks" to explore edges, leaving
    the vertex from which *v* was discovered. The process continues until all vertices
    that are reachable from the original source vertex have been discovered.
  prefs: []
  type: TYPE_NORMAL
- en: If any undiscovered vertices remain, then DFS selects one of them as a new source,
    and it repeats the search from that source. While it may seem odd that BFS limits
    itself to vertices reachable from a single source whereas DFS considers multiple
    sources, the reason behind it is related to the applications of these searches.
  prefs: []
  type: TYPE_NORMAL
- en: BFS is usually used to find shortest-path distances while DFS is often used
    as a subroutine in another algorithm, which we shall see when we explore the cycle
    detection problem.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to BFS, when we discover a vertex *v* during the scan of the adjacency
    list of an already discovered vertex, we record its parent attribute. Since we
    mentioned that we explore different sources, the parent subgraph produced by DFS
    is, unlike the breadth-first tree, a forest (that is, a set of trees).
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to illustrate this, let''s look  at a run of DFS for the directed
    graph of *Figure 6.1*, starting at *node 2*, in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cf3f6f30-0e1b-496c-98fd-d08a5d877fac.png)![](img/c4409456-7b0c-43ac-b420-25981eed3d0f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 6.4: A run of DFS on the directed graph of Figure 6.1, starting at node
    2'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the results of DFS may depend on the order in which the vertices are examined.
    In the previous case, we started with 2 and always went for the lowest-numbered
    vertex in the adjacency list of a vertex first. If we had started with vertex
    0, we would have a different forest. In practice, we can usually use any DFS result
    with equivalent results.
  prefs: []
  type: TYPE_NORMAL
- en: We previously saw how to perform DFS on trees. DFS on graphs is similar, but
    we need to keep track of explored nodes so that we don't get stuck in cycles.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to implement DFS, we will assume that our graph is represented using
    adjacency lists. We will attach certain attributes to each vertex in the graph,
    which will allow us to guide our search and later construct the depth-first forest.
    The following code snippet illustrates the implementation of depth-first search:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 6.5: Implementation of depth-first search. Source class name:dfs.Graph.'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/saZYQp](https://goo.gl/saZYQp) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: The DFS procedure works by initializing all vertices as not visited, and setting
    their parents to *-1* (meaning that they have no parent). Then, we find the first
    undiscovered vertex and visit it. In each visit, we start by recording the vertex
    as visited and then going through its adjacency list. There, we are looking for
    vertices not yet discovered. Once we find one, we visit it. Looking at the previous
    implementation, we see that the loops inside DFS take time *O(V)*, as they run
    for each vertex in the graph. We can also see that the `dfsVisit()` method is
    called exactly once for each vertex. During the execution of `dfsVisit()`, the
    loop scanning the adjacency list executes in time proportional to the size of
    the vertex's adjacency list. Since we said before that `dfsVisit()` is called
    exactly once for each vertex, the total time spent in the loop is proportional
    to the sum of the sizes of all adjacency lists, that is, *O(E)*. Therefore, the
    total running time of DFS is *O(V + E)*.
  prefs: []
  type: TYPE_NORMAL
- en: In the DFS method, we're returning the parent array, but the return type of
    this routine is usually adapted depending on the larger task that a more general
    algorithm that uses DFS is trying to achieve. We'll see DFS adapted to our specific
    needs in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Cycle Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A useful application of DFS is determining whether or not a graph is acyclic
    (that is, it does not contain cycles). In order to do so, it''s important to define
    four types of edges in terms of the depth-first forest produced by DFS. They are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tree edges**: They are edges in the depth-first forest. An edge can only
    be a tree edge if it was the one explored when first discovering a vertex.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Back edges**: They are edges connecting a vertex to an ancestor in a depth-first
    tree. Self-loops (which may occur in directed graphs) are back edges.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Forward edges**: They are edges that do not belong to a depth-first tree
    but connect a vertex to one of its descendants in a depth-first tree. Forward
    edges are therefore edges that weren''t used when performing the DFS, but connect vertices
    *u* and *v* in a depth-first tree provided that *v* is a descendant of *u* in
    the tree.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cross edges**: They are all other edges. They can go between vertices in
    the same depth-first tree or they can go between vertices in different depth-first trees.
    They are therefore edges that weren''t used when performing the depth-first search,
    but connect vertices that don''t share an ancestor relationship in the same tree
    or vertices in different trees.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having classified edges, it is possible to show that a directed graph is acyclic
    if and only if a DFS does not produce back edges. If a depth-first search produces
    a back edge *(u, v)*, then vertex *v* is an ancestor of vertex *u* in the depth-first
    forest. Therefore, *G* contains a path from *v* to *u*, and *(u, v)* completes
    a cycle. This algorithm is generalizable for undirected graphs. In undirected
    graphs, if we find a back edge *(u, v)* and *v* is not the parent of u in the
    depth-first forest, then we are in the presence of a cycle.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity: Using BFS to Find the Shortest Path Out of a Maze'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Scenario**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our maze is an *H* by *W* rectangle, represented by an array of size *H* of
    *W*-sized strings. Each character in a string can either be ''**#**'' or ''**.**''.
    ''**#**'' represents a wall, which we cannot cross, and ''.'' represents a free
    space, which we can cross. The border of the maze is always filled with ''**#**''
    except for one square, which represents the exit. For example, the following is
    a valid maze:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e1acfab2-ecc2-454a-b528-150e46593c6b.png)'
  prefs: []
  type: TYPE_IMG
- en: Find the total number of steps to exit the maze, when supplied with a starting
    point *(i, j)* (with *(0, 0)* being the upper-left point and *(H, W)* being the
    lower-right point).
  prefs: []
  type: TYPE_NORMAL
- en: '**Aim**'
  prefs: []
  type: TYPE_NORMAL
- en: To use BFS to find the shortest path out of a given maze.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prerequisites**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Implement the `distToExit()` method of the `Maze` class in the source code, which
    returns the integer distance from that point to the exit of the maze. It is available
    at the following URL:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson6/activity/maze/Maze.java](https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson6/activity/maze/Maze.java)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Assume that the points supplied to `distToExit()` are valid (that is, they're not
    inside walls)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember that we can only move in the cardinal directions (North, South,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: East, and West)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Steps for Completion**'
  prefs: []
  type: TYPE_NORMAL
- en: Encode the maze representation to a graph representation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply the BFS implementation shown in the preceding section (with a small modification
    to account for distances), or you can build the graph as you go
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since you know that there are at most four outward edges for a given vertex, compute
    their positions as you go
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this section, we've introduced two different ways to traverse a graph—**breadth-first search**
    (**BFS**) and **depth-first search** (**DFS**). We've seen how to use BFS to find
    the single-source shortest path in unweighted graphs and how to use DFS to find
    cycles in a graph. In the next section, we will be looking at two different algorithms
    to find shortest paths in a graph.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating Shortest Paths
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The shortest path is a path between two vertices so that the sum of the weights
    of the edges that constitute the path is minimized. The shortest path problem
    has many applications in the real world, from finding directions on mapping applications
    to minimizing the moves to solve a puzzle.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we shall look at two different strategies for computing shortest
    paths: one that finds the shortest paths from a single source to every other vertex
    in the graph, and another that finds shortest paths between all pairs of vertices
    in a graph.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Single Source Shortest Path: Dijkstra''s Algorithm'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we explored BFS, we saw that it was able to solve the shortest path problem
    for unweighted graphs, or graphs whose edges have the same (positive) weight.
    What if we are dealing with weighted graphs? Can we do better? We shall see that
    Dijkstra's algorithm provides an improvement over the ideas presented in BFS and
    that it is an efficient algorithm for solving the single-source shortest path
    problem. One restriction for working with Dijkstra's algorithm is that edges'
    weights have to be positive. This is usually not a big issue since most graphs
    represent entities modeled by edges with positive weights. Nonetheless, there
    are algorithms capable of solving the problem for negative weights. Since the
    use case for negative edges is less common, those algorithms are outside the scope
    of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Dijkstra''s algorithm, conceived by Edsger W. Dijkstra in 1956, maintains a
    set *S* of vertices whose final shortest-path weights from the source *s* have
    already been determined. The algorithm repeatedly selects the vertex *u* with
    the minimum shortest-path estimate, adds it to set *S*, and uses the outward edges
    from that vertex to update the estimates from vertices not yet in set *S*. In
    order to see this in action, let''s consider the directed graph of *Figure 6.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/49a7ece1-feb6-4021-82f2-b3215990b169.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.5: A sample weighted directed graph'
  prefs: []
  type: TYPE_NORMAL
- en: 'The graph is composed of five vertices (*A*, *B*, *C*, *D*, and *E*) and 10
    edges. We''re interested in finding the shortest paths, starting at vertex *A*.
    Note that A is already marked as *0*, meaning that the current distance from *A*
    to *A* is zero. The other vertices don''t have distances associated with them
    yet. It is common to use an estimate of infinity as the starting estimate for
    the distance of nodes not yet seen. The following table shows a run of Dijkstra''s
    algorithm for the graph of *Figure 6.5*, identifying the current vertex being
    selected and how it updates the estimates for vertices not yet seen:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Step** | **Explanation** |'
  prefs: []
  type: TYPE_TB
- en: '| ![](img/be27917f-9d33-4854-862c-e55345bfa5f3.png) | Vertex *A* is the vertex
    with the lowest estimate weight, so it is selected as the next vertex whose edges
    are to be considered to improve our current estimates. |'
  prefs: []
  type: TYPE_TB
- en: '| ![](img/f281522a-9f4a-4233-88de-ae382eea15d9.png) | We use the outward edges
    from vertex *A* to update our estimates for vertices *B* and *D*. Afterwards,
    we add *A* to set *S*, avoiding a repeated visit to it. From the edges not yet
    visited, the one with the lowest estimate is now *D*, which shall be selected
    to visit next. Note that we also mark those edges that belong to our estimate
    shortest path in bold. |'
  prefs: []
  type: TYPE_TB
- en: '| ![](img/2cf9e89a-77d0-4d16-8268-421869d67694.png) | By exploring the outward
    edges from vertex *D*, we were able to improve our estimate for vertex *B*, so
    we update it accordingly and now consider a different edge for the shortest path. We
    were also able to discover vertices *C* and *E*, which become potential candidates
    to visit next. Since *E* is the one with the shorter estimate weight, we visit
    it next. |'
  prefs: []
  type: TYPE_TB
- en: '| ![](img/b9a16349-a972-458e-bae1-cb32d60615b2.png) | Using an outward edge
    from vertex *E*, we were able to improve our estimate for vertex *C*, and now
    look at vertex *B* as our next vertex to visit. Note that those vertices that
    belong to set *S* (shown in black in the figure) already have their shortest path
    computed. The value inside them is the weight of the shortest path from *A* to
    them, and you can follow the edges in bold to build the shortest path. |'
  prefs: []
  type: TYPE_TB
- en: '| ![](img/b93ca2a6-5f6e-48d5-ac55-275628ef8363.png) | From vertex *B*, we were
    able to once again improve our estimate for the shortest path to vertex *C*. Since
    vertex *C* is the only vertex not yet in set *S*, it is the one visited next.
    |'
  prefs: []
  type: TYPE_TB
- en: '| ![](img/81e5d6e5-6186-454c-8908-a5c5ff1342f3.png) | Since vertex *C* has
    no outward edges to vertices not yet in *S*, we conclude the run of our algorithm,
    and have successfully computed the shortest paths from *A* to every other vertex
    in the graph. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 6.5: A run of Dijkstra''s algorithm for the weighted directed graph of
    Figure 6.5'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we''ve seen a run of Dijkstra''s algorithm, let''s try to put it in
    code and analyze its runtime performance. We will use an adjacency list representation
    for our graph, as it helps us when trying to explore the outward edges of a given
    vertex. The following code snippet shows a possible implementation of Dijkstra''s
    algorithm as previously described:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 6.6: Implementation of Dijkstra''s algorithm. Source class name: Dijkstra'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/P7p5Ce](https://goo.gl/P7p5Ce) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Dijkstra method starts by initializing two sets:'
  prefs: []
  type: TYPE_NORMAL
- en: One for visited vertices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One for unvisited vertices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The set of visited vertices corresponds to the set we previously named as *S*,
    and we use the one of not visited vertices to keep track of vertices to explore.
  prefs: []
  type: TYPE_NORMAL
- en: We then initialize each vertex with an estimated distance equal to `Integer.MAX_VALUE`,
    representing a value of "infinity" for our use case. We also use a parent array
    to keep track of parent vertices in the shortest path, so that we can later recreate
    the path from the source to each vertex.
  prefs: []
  type: TYPE_NORMAL
- en: The main loop runs for each vertex, while we still have vertices not yet visited.
    For each run, it selects the "best" vertex to explore. In this case, the "best"
    vertex is the one with the smallest distance of the vertices not visited so far
    (the `getBestEstimate()` function simply scans all vertices in the `notVisited()`
    set for the one satisfying the requirement).
  prefs: []
  type: TYPE_NORMAL
- en: Then, it adds the vertex to the set of visited vertices and updates the estimate
    distances for not visited vertices. When we run out of vertices to visit, we build
    our paths by recursively visiting the parent array.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the runtime of the previous implementation, we can see that we have
    an initialization step that's proportional to the number of vertices in the graph,
    hence running in *O(V)*.
  prefs: []
  type: TYPE_NORMAL
- en: The main loop of the algorithm runs once for each vertex, so it is bounded by
    at least *O(V)*. Inside the main loop, we determine the next vertex to visit and
    then scan its adjacency list to update the estimate distances. Updating the distances
    takes time proportional to *O(1)*, and since we scan each vertex's adjacency list
    only once, we take time proportional to *O(E)*, updating estimate distances. We're
    left with the time spent selecting the next vertex to visit. Unfortunately, the
    `getBestEstimate()` method needs to scan through all the unvisited vertices, and
    is therefore bounded by *O(V)*. The total running time of our implementation of
    Dijkstra's algorithm is therefore *O(V²+E)*.
  prefs: []
  type: TYPE_NORMAL
- en: Even though some parts of our implementation seem difficult to optimize, it
    looks like we can do better when selecting the next vertex to visit. If we could
    have access to a data structure that was capable of storing our vertices sorted
    by lower estimated distance and provided efficient insert and remove operations,
    then we could reduce the *O(V)* time spent inside the `getBestEstimate` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Chapter 4](da07fa18-a8ce-4d4c-91eb-9dc893de7273.xhtml), *Algorithm Design
    Paradigms*, we briefly discussed a data structure used in Huffman coding named
    the  priority queue, which is just what we need for this job. The following code
    snippet implements a more efficient version of Dijkstra''s algorithm, using a
    priority queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 6.7: Implementation of Dijkstra''s algorithm using a priority queue.
    Source class name: DijkstraWithPQ'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/3rtZCQ](https://goo.gl/3rtZCQ) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: In this second implementation, we no longer keep sets for visited and not visited
    vertices. Instead, we rely on a priority queue that will be storing our distance
    estimates while we run the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: When we are exploring the outward edges from a given vertex, we therefore add
    a new entry to the priority queue in case we are able to improve our distance
    estimate.
  prefs: []
  type: TYPE_NORMAL
- en: Adding and removing an element from our priority queue takes *O(logN)* time,
    *N* being the number of elements in the queue. Do note that we can have the same
    vertex inserted more than once in the priority queue. That's why we check if we've
    visited it before expanding its edges.
  prefs: []
  type: TYPE_NORMAL
- en: Since we will visit the instance for that vertex with shorter estimate distance,
    it's safe to ignore the ones that come after it. However, that means that operations
    on our priority queue are not bounded by *O(logV)*, but *O(log E)* instead (assuming
    that there's a connected graph).
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the total runtime of this implementation is *O((V + E)logE)*. It's
    still possible to improve this running time by using a priority queue implementation
    with better asymptotic bounds (such as a Fibonacci heap), but its implementation
    is out of the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'One last thing to note about Dijkstra''s algorithm is how it borrows ideas
    from BFS (the algorithm structure is very similar to Dijkstra''s, but we end up
    using a priority queue instead of a normal queue) and that it is a very good example
    of a greedy algorithm: Dijkstra''s algorithm makes the locally optimum choice
    (for example, it chooses the vertex with the minimum estimated distance) in order
    to arrive at a global optimum.'
  prefs: []
  type: TYPE_NORMAL
- en: 'All Pairs Shortest Paths: Floyd-Warshall Algorithm'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, it might be necessary to compute the shortest paths between all pairs
    of vertices. For example, we might be interested in building a table of distances.
    One way to do that is to perform a single source shortest path for every vertex
    of the graph. If you use Dijkstra's algorithm for that, we end up with a runtime
    of *O(V*(V + E)logE)*.
  prefs: []
  type: TYPE_NORMAL
- en: In this subsection, we shall explore an algorithm capable of solving the all
    pairs shortest paths problem in *O(V³)* time, with a remarkably simple and elegant
    implementation.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm we are about to study, more commonly referred to as the Floyd-Warshall
    algorithm, was published in its current form by Robert Floyd in 1962\. However,
    in its essence, it follows the same ideas published by Bernard Roy in 1959 and
    Stephen Warshall in 1962.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm uses the adjacency matrix representation and follows a dynamic
    programming approach. The basic idea behind it is that, when we're trying to compute
    the shortest-path distance between vertex *i* and vertex *j*, we try to use an
    intermediate vertex, *k*. We want to use an intermediate vertex so that doing
    the path from *i* to *k* and then from *k* to *j* shortens the currently computed
    shortest path between *i* and *j*. If we find such a vertex, then the best path
    we're able to compute so far between *i* and *j* must go through *k*. All that
    we need to do is, for each *k*, see if using it improves the shortest path between
    *i* and *j*, for all possible *i* and *j*.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to see that in practice, let''s use the directed graph of *Figure
    6.5* that we used to illustrate Dijkstra''s algorithm. The graph of *Figure 6.5*
    has the adjacency matrix representation of the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **A** | **B** | **C** | **D** | **E** |'
  prefs: []
  type: TYPE_TB
- en: '| **A** | 0 | 10 | ∞ | 5 | ∞ |'
  prefs: []
  type: TYPE_TB
- en: '| **B** | ∞ | 0 | 1 | 2 | ∞ |'
  prefs: []
  type: TYPE_TB
- en: '| **C** | ∞ | ∞ | 0 | ∞ | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| **D** | ∞ | 3 | 9 | 0 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| **E** | ∞ | ∞ | 6 | ∞ | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 6.6: Adjacency matrix representation of the directed graph of Figure
    6.5'
  prefs: []
  type: TYPE_NORMAL
- en: 'The adjacency matrix representation serves as the starting point for the Floyd-Warshall
    algorithm, and we iterate through it until we''re left with a matrix of the weights
    of the shortest paths between each pair of vertices. In order to do so, let''s
    start with vertex *A*, considering it as an intermediate vertex for shortest paths.
    Unfortunately, vertex *A* doesn''t have inward edges, meaning that it can''t be
    used as an intermediate vertex for shortest paths. Using vertex *B*, we can improve
    the distance from *A* to *C (10 + 1 < ∞)*, and we can use it to go from *A* to
    *D*, but not improve the overall distance. We can also use it to improve the distance
    from *D* to *C (3 + 1 < 9)*. Therefore, after considering *B* as an intermediate
    vertex, we''re left with the distance matrix of the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **A** | **B** | **C** | **D** | **E** |'
  prefs: []
  type: TYPE_TB
- en: '| **A** | 0 | 10 | 11 | 5 | ∞ |'
  prefs: []
  type: TYPE_TB
- en: '| **B** | ∞ | 0 | 1 | 2 | ∞ |'
  prefs: []
  type: TYPE_TB
- en: '| **C** | ∞ | ∞ | 0 | ∞ | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| **D** | **∞** | 3 | 4 | 0 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| **E** | ∞ | ∞ | 6 | ∞ | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 6.7: Distance matrix after considering B as an intermediate vertex'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are going to look at vertex *C*. Using vertex *C*, we can improve the
    distance from *A* to *E (11 + 4 < ∞)* and *B* to *E (1 + 4 < ∞)*:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **A** | **B** | **C** | **D** | **E** |'
  prefs: []
  type: TYPE_TB
- en: '| **A** | 0 | 10 | 11 | 5 | 15 |'
  prefs: []
  type: TYPE_TB
- en: '| **B** | ∞ | 0 | 1 | 2 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| **C** | ∞ | ∞ | 0 | ∞ | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| **D** | ∞ | 3 | 4 | 0 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| **E** | ∞ | ∞ | 6 | ∞ | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 6.8: Distance matrix after considering C as an intermediate vertex'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using vertex *D*, we can improve the distance from *A* to *B (5 + 3 < 10)*,
    *A* to *C (5 + 4 < 11)*, *A *to *E (5 + 2 < 15)*, and *B* to *E (2 + 2 < 5)*:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **A** | **B** | **C** | **D** | **E** |'
  prefs: []
  type: TYPE_TB
- en: '| **A** | 0 | 8 | 9 | 5 | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| **B** | ∞ | 0 | 1 | 2 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| **C** | ∞ | ∞ | 0 | ∞ | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| **D** | ∞ | 3 | 4 | 0 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| **E** | ∞ | ∞ | 6 | ∞ | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 6.9: Distance matrix after considering D as an intermediate vertex'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using vertex *E*, we cannot improve any distance, so *Table 6.9* already has
    the weights for the shortest paths between all pairs of vertices. Implementing
    the Floyd-Warshall algorithm is very simple, as the following code snippet demonstrates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 6.8: Implementation of Floyd Warshall''s algorithm. Source class name: FloydWarshall'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/SQxdL2](https://goo.gl/SQxdL2) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the implementation, the runtime of *O(V³)* becomes obvious. One alternative
    to the Floyd-Warshall algorithm is running Dijkstra's algorithm for each vertex
    in the graph (so that we end up with all pairwise shortest paths). Given that
    its complexity is closer to multiple applications of Dijkstra's algorithm for
    dense graphs, the Floyd-Warshall algorithm is frequently used in practice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity: Improving Floyd-Warshall''s Algorithm to Reconstruct the Shortest
    Path'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Scenario**'
  prefs: []
  type: TYPE_NORMAL
- en: Improve Floyd-Warshall's algorithm so that we're able to reconstruct the shortest path
    between two given nodes after running the algorithm, using the predecessor matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '**Aim**'
  prefs: []
  type: TYPE_NORMAL
- en: To construct a shortest path between the two vertices using the predecessor
    matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prerequisite**'
  prefs: []
  type: TYPE_NORMAL
- en: The predecessor matrix is used to compute the shortest path between two given
    vertices. Each cell of the predecessor matrix *P[ij]* should be either empty (meaning
    that there is no path between *i* and *j*), or equal to some index *k* (meaning
    that vertex *k* is the one that precedes *j* in the shortest path between *i*
    and *j*). As such, we need to update our predecessor matrix whenever we use an
    intermediate vertex.
  prefs: []
  type: TYPE_NORMAL
- en: 'Implement the `run()` method of the Floyd-Warshall class that shall compute
    the shortest paths for the current graph and populate the path matrix, used later
    in the `path()` method to return the path between two given vertices. The method
    is available at the following URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson6/activity/floydwarshall/FloydWarshall.java](https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson6/activity/floydwarshall/FloydWarshall.java)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Steps for Completion**'
  prefs: []
  type: TYPE_NORMAL
- en: Adapt the implementation shown in *Snippet 6.8* of the Floyd-Warshall algorithm
    to update the path matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use it to reconstruct the paths similarly to what we have previously shown in the
    implementation of Dijkstra's algorithm
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In this section, we''ve introduced the shortest paths problem and visited two
    different algorithms to solve it: one for single source shortest paths (Dijkstra''s
    algorithm), and another for all pairs shortest paths (Floyd-Warshall). We''ve
    shown how different implementations of Dijkstra''s algorithm can affect its running
    time. For both algorithms, we''ve also shown how to reconstruct shortest paths
    using a parent array and a predecessor matrix, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: Prime Numbers in Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A prime number is a natural number greater than one whose only divisors are
    one and the number itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'Prime numbers play a very important role in the fundamental theorem of arithmetic:
    every natural number greater than one is either a prime or a product of primes.
    Nowadays, number-theoretic algorithms are widely used, mainly due to cryptographic
    schemes based on large prime numbers. Most of those cryptographic schemes are
    based on the fact that we can efficiently find large primes, but we cannot factor
    the product of those large primes efficiently. As seen before, prime numbers play
    an important role in the implementation of hash tables.'
  prefs: []
  type: TYPE_NORMAL
- en: Sieve of Eratosthenes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The sieve of Eratosthenes is a simple and ancient algorithm to find all prime
    numbers up to a given limit. If we want to find all prime numbers up to *N*, we
    start by creating a list of consecutive integers from *2* to *N (2, 3, 4, 5… N)*,
    initially unmarked. Let's use *p* to denote the smallest unmarked number. Then,
    we select the smallest unmarked number *p* that is larger than the last *p*. In
    the first iteration, *p* will be two. Afterwards, by increments of *p*, we mark
    elements in the list from *2p* until *Mp* so that *Mp <= N.*
  prefs: []
  type: TYPE_NORMAL
- en: We repeat this strategy until it is impossible to mark more numbers in the list.
    At the end of the run, all the unmarked numbers are prime numbers. It is easy
    to see that all unmarked numbers will be the ones for which we couldn't find a
    divisor other than the number itself and 1, and are therefore prime numbers.
  prefs: []
  type: TYPE_NORMAL
- en: Prime Factorization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prime factorization is determining the prime factors of a given number. It is
    very difficult to build a general-purpose algorithm for this computationally hard
    problem. A general purpose algorithm that is commonly used to factorize primes
    was introduced in [Chapter 1](52b469c2-7203-4188-9e37-6ab0bf659ca7.xhtml), *Algorithms
    and Complexities*. Its basic idea is to iterate through possible factors attempting
    to divide the number.
  prefs: []
  type: TYPE_NORMAL
- en: Start with 2; while the number is divisible by 2, keep dividing it, and add
    2 to the list of factors. Afterwards, the number must be odd, so start a loop
    that checks for possible factors from 3 to the square root of the number.
  prefs: []
  type: TYPE_NORMAL
- en: Since we've already covered even numbers, you can do increments of 2 in this
    loop (there's no need to check 4, 6, 8, and so on once you've already checked
    2). Once you find a suitable divisor, add the number to the list of factors and
    divide it until it is possible. At the end of this step, if we are left with a
    number greater than 2, then it is a prime number and therefore a prime factor
    of itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity: Implementing the Sieve of Eratosthenes'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Scenario**'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the sieve of Eratosthenes algorithm to find all prime numbers up
    to a given limit.
  prefs: []
  type: TYPE_NORMAL
- en: '**Aim**'
  prefs: []
  type: TYPE_NORMAL
- en: To develop a code in Java for implementing the sieve of Eratosthenes.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prerequisites**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Implement the `isPrime()` method of the `SieveOfEratosthenes` class that should
    return `true` if the number is prime, and `false` otherwise. It is available at
    the following URL:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson7/activity/sieve/SieveOfEratosthenes.java](https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson7/activity/sieve/SieveOfEratosthenes.java)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Consider building the sieve in the class constructor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other Concepts in Graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered ways of representing and traversing a graph and
    looked at shortest path algorithms. Graphs are also an optimal data structure
    for some problems we haven't mentioned yet. This section aims to introduce some
    of them.
  prefs: []
  type: TYPE_NORMAL
- en: Minimum Spanning Trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A minimum spanning tree of a graph is a subset of the set of edges *E* of a
    connected graph that connects all vertices together, without any cycles and with
    the minimum total edge weight. It is a tree because every two vertices in it are
    connected by exactly one path.
  prefs: []
  type: TYPE_NORMAL
- en: In order to understand the applicability of minimum spanning trees, consider
    the problem of a telecommunications company that is moving into a new neighborhood.
    The company wants to connect all the houses, but also wants to minimize the length
    of cable that it uses in order to cut costs. One way to solve the problem is by
    computing the minimum spanning tree of a graph whose vertices are the houses of
    the neighborhood, and the edges between houses are weighted according to the distance
    between them.
  prefs: []
  type: TYPE_NORMAL
- en: There are many algorithms to solve the minimum spanning tree problem. Two of
    the most famous are Prim's and Kruskal's.
  prefs: []
  type: TYPE_NORMAL
- en: Prim's algorithm is a greedy algorithm that repeatedly selects the edge of smaller
    weights that connect some edge not yet in the spanning tree with some edge already
    in the spanning tree. Its runtime depends on the implementation, but it's possible
    to achieve a runtime of *O(VlogE)*. It can be implemented similarly to Dijkstra's
    algorithm. We start with one vertex chosen arbitrarily to be part of the tree.
    All edges that connect to this "starting" vertex are added to a set of candidate
    edges that are sorted according to the edges' weights. While we still have vertices
    to add to the tree, we repeatedly select the edge with the smaller weight from
    the list of candidate edges that connects to a vertex not yet in the tree, and
    repeat the process for the new vertex.
  prefs: []
  type: TYPE_NORMAL
- en: Kruskal's algorithm is also a greedy algorithm that uses a disjoint-set data
    structure. A disjoint-set data structure, or union-find data structure, is a data
    structure that tracks elements that are partitioned into a number of non-overlapping
    subsets. It provides an efficient way to merge two sets and check whether two
    elements belong to the same set.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of Kruskal's algorithm is to reduce a forest (for example, a set of
    trees) to a single tree, using a disjoint-set data structure to keep track of
    trees. We start with one tree for each vertex, including only one vertex. While
    we have more than one tree, we select the edge of the smallest weight that connects
    two different trees (we don't want to produce a cycle), and join the two trees
    together. At the end, the resultant tree will be the one whose total edge weight
    is minimized. The running time of Kruskal's algorithm is also *O(VlogE)*.
  prefs: []
  type: TYPE_NORMAL
- en: A* Search
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *A** search algorithm is a very common algorithm when solving path-finding
    problems. It also solves the shortest path problem, enhancing Dijkstra's algorithm
    with the introduction of a heuristic to guide the search. A heuristic is a practical
    estimate of a given cost, not guaranteed to be optimal or perfect, but sufficient
    for the immediate goals, or to guide a search. Its basic idea is that, when adding
    this heuristic to the estimated distance already computed for a node, one can
    guide the search towards the goal and avoid visiting certain vertices.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if we use the Euclidean distance (for example, the straight line
    distance between two points) from our location to the exit of a given maze, we
    can guide the search towards that and avoid visiting certain unnecessary positions.
  prefs: []
  type: TYPE_NORMAL
- en: Maximum Flow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some directed weighted graphs can be seen as flow networks. In a flow network,
    edge weights represent capacities and each edge receives a flow that can't exceed
    the edge's capacity. The labels on the edges represent the used and total capacity
    of the edge. The maximum flow attempts to find a feasible flow through the network
    that is maximum, considering a single source (where the initial flow starts) and
    single sink (where the flow ends). The maximum flow problem allows one to solve
    related problems like pair wise assignment. There are various algorithms to solve
    the maximum flow problem. Three of the most famous ones are the FordFulkerson
    algorithm, the Edmonds-Karp algorithm, and Dinic's algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind the Ford-Fulkerson algorithm is to repeatedly find augmenting
    paths in the flow network. An augmenting path is a path that still has an available
    capacity. While it is possible to find augmenting paths, one can add a flow through
    the path equal to its capacity and repeat the process. Ford-Fulkerson algorithm
    runs in *O(Ef)*, *f* being the maximum flow of the graph. The Edmonds-Karp algorithm
    improves on the Ford-Fulkerson algorithm by always selecting the augmenting path
    that is shortest. The runtime complexity of the Edmonds-Karp algorithm is *O(VE²)*,
    independent of the maximum flow value. Dinic's algorithm runs in *O(V²E)* time,
    also building on shortest augmenting paths, but uses some concepts that make it
    more suitable for sparse graphs.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Complexity Classes of Problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nearly all of the algorithms introduced so far run in polynomial time (for instance,
    on inputs of size *n*, their worst-case running time is *O(n^k)* for constant
    *k*). However, there are problems that simply cannot be solved or for which a
    polynomial-time algorithm hasn't been found yet.
  prefs: []
  type: TYPE_NORMAL
- en: An example of a problem that cannot be solved is the halting problem. The halting
    problem is the problem of determining, from the description of a computer program
    and an input, whether the program will finish running or continue to run forever.
    Alan Turing proved that a general algorithm to solve the halting problem for all
    pairs of (program, input) cannot exist.
  prefs: []
  type: TYPE_NORMAL
- en: It is common to call problems solvable by polynomial-time algorithms (for instance,
    those whose worst-case running time is *O(n^k)* for constant *k*) as "tractable",
    or "easy", and problems that require a super-polynomial-time algorithm (for instance,
    those whose running time is not bounded above by any polynomial) as "intractable",
    or "hard".
  prefs: []
  type: TYPE_NORMAL
- en: There is a class of problems, called **NP-Complete** (**NPC**) problems, and
    no one has yet found a polynomial-time algorithm to solve them. However, no one
    has yet been able to prove that no polynomial-time algorithm can exist for any
    of them.
  prefs: []
  type: TYPE_NORMAL
- en: There is another class of problems, called **NP** problems, whose solutions
    are verifiable in polynomial time. This means that, given a problem, and a possible
    solution to it, one can verify if the solution is correct in polynomial time.
  prefs: []
  type: TYPE_NORMAL
- en: All problems in P are also in NP. NPC consists of problems that belong to the
    NP class and to the NP-hard class. A problem is NP-hard if an algorithm for solving
    it can be translated into one for solving a NP problem.
  prefs: []
  type: TYPE_NORMAL
- en: One of the deepest open research problems in theoretical computer science is
    whether *P* is really different from NP (for instance, *P != NP*).
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples of NPC problems are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Finding the longest path in the graph
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding a path in a graph that visits all vertices exactly once (known as a Hamiltonian
    path)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A common example of an NP-hard problem is finding the shortest path in a graph that
    visits all vertices exactly once and returns to the starting point. The problem consists
    of finding the Hamiltonian cycle of the smallest weight, and is often described
    as the traveling salesman problem as it models the problem of a salesman that
    needs to visit all cities and return to his hometown.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have introduced graphs, formalized what they are and shown
    two different ways to represent them in computer programs. Afterwards, we took
    a look at ways of traversing graphs, using them as building blocks for building
    more complex algorithms on top. Then, we looked at two different algorithms for
    finding shortest paths in a graph.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of this book, we provide pointers for curious students to study on
    their own. The world of data structures and algorithms is vast and requires a
    type of mathematical reasoning for which some study and practice is required.
    However, one of the most rewarding feelings in the life of a software engineer
    is coming up with a clever algorithms to solve a complex problems.
  prefs: []
  type: TYPE_NORMAL
