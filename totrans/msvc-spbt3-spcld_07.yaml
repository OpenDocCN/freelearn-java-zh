- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Developing Reactive Microservices
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发反应式微服务
- en: In this chapter, we will learn how to develop reactive microservices, that is,
    how to develop non-blocking synchronous REST APIs and asynchronous event-driven
    services. We will also learn how to choose between these two alternatives. Finally,
    we will see how to create and run manual and automated tests of a reactive microservice
    landscape.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何开发反应式微服务，即如何开发非阻塞同步REST API和异步事件驱动服务。我们还将学习如何在这两种选择之间进行选择。最后，我们将看到如何创建和运行反应式微服务景观的手动和自动化测试。
- en: As already described in *Chapter 1*, *Introduction to Microservices*, the foundation
    for reactive systems is that they are message-driven—they use asynchronous communication.
    This enables them to be elastic, in other words, scalable and resilient, meaning
    that they are tolerant of failures. Elasticity and resilience together enable
    a reactive system to be responsive.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如在第1章*微服务简介*中已描述，反应式系统的基石是它们是消息驱动的——它们使用异步通信。这使得它们具有弹性，换句话说，可扩展性和弹性，意味着它们对失败具有容忍度。弹性和弹性共同使反应式系统能够做出响应。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Choosing between non-blocking synchronous APIs and event-driven asynchronous
    services
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在非阻塞同步API和事件驱动的异步服务之间进行选择
- en: Developing non-blocking synchronous REST APIs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发非阻塞同步REST API
- en: Developing event-driven asynchronous services
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发事件驱动的异步服务
- en: Running manual tests of the reactive microservice landscape
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行反应式微服务景观的手动测试
- en: Running automated tests of the reactive microservice landscape
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行反应式微服务景观的自动化测试
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For instructions on how to install the tools used in this book and how to access
    the source code for this book, see:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何安装本书中使用的工具以及如何访问本书源代码的说明，请参阅：
- en: '*Chapter 21*, *Installation Instructions for macOS*'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第21章*，*macOS的安装说明*'
- en: '*Chapter 22*, *Installation Instructions for Microsoft Windows with WSL 2 and
    Ubuntu*'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第22章*，*使用WSL 2和Ubuntu的Microsoft Windows安装说明*'
- en: The code examples in this chapter all come from the source code in `$BOOK_HOME/Chapter07`.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的代码示例均来自 `$BOOK_HOME/Chapter07` 的源代码。
- en: If you want to view the changes applied to the source code in this chapter,
    that is, see what it takes to make the microservices reactive, you can compare
    it with the source code for *Chapter 6*, *Adding Persistence*. You can use your
    favorite `diff` tool and compare the two folders, that is, `$BOOK_HOME/Chapter06`
    and `$BOOK_HOME/Chapter07`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想查看本章源代码中应用的变化，即查看使微服务反应式所需的内容，你可以将其与第6章*添加持久性*的源代码进行比较。你可以使用你喜欢的`diff`工具比较这两个文件夹，即
    `$BOOK_HOME/Chapter06` 和 `$BOOK_HOME/Chapter07`。
- en: Choosing between non-blocking synchronous APIs and event-driven asynchronous
    services
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在非阻塞同步API和事件驱动的异步服务之间进行选择
- en: When developing reactive microservices, it is not always obvious when to use
    non-blocking synchronous APIs and when to use event-driven asynchronous services.
    In general, to make a microservice robust and scalable, it is important to make
    it as autonomous as possible, for example, by minimizing its runtime dependencies.
    This is also known as **loose coupling**. Therefore, the asynchronous message
    passing of events is preferable over synchronous APIs. This is because the microservice
    will only depend on access to the messaging system at runtime, instead of being
    dependent on synchronous access to a number of other microservices.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发反应式微服务时，并不总是明显何时使用非阻塞同步API，何时使用事件驱动的异步服务。一般来说，为了使微服务健壮和可扩展，重要的是尽可能使其具有自主性，例如，通过最小化其运行时依赖。这也被称为**松耦合**。因此，事件的消息异步传递比同步API更可取。这是因为微服务将只依赖于运行时对消息系统的访问，而不是依赖于对多个其他微服务的同步访问。
- en: 'There are, however, a number of cases where synchronous APIs could be favorable.
    For example:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一些情况下同步API可能是首选的。例如：
- en: For read operations where an end user is waiting for a response
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于需要等待响应的读取操作
- en: Where the client platforms are more suitable for consuming synchronous APIs,
    for example, mobile apps or SPA web applications
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当客户端平台更适合消费同步API时，例如，移动应用或SPA网页应用
- en: Where the clients will connect to the service from other organizations – where
    it might be hard to agree on a common messaging system to use across organizations
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当客户端将从其他组织连接到服务时——在这些组织中可能难以就跨组织使用的一个通用消息系统达成一致
- en: 'For the system landscape in this book, we will use the following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本书中的系统景观，我们将使用以下内容：
- en: The create, read, and delete services exposed by the product composite microservice
    will be based on non-blocking synchronous APIs. The composite microservice is
    assumed to have clients on both web and mobile platforms, as well as clients coming
    from other organizations rather than the ones that operate the system landscape.
    Therefore, synchronous APIs seem like a natural match.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品复合微服务公开的创建、读取和删除服务将基于非阻塞同步API。复合微服务假定在Web和移动平台以及来自其他组织的客户端上都有客户端，而不是操作系统景观的客户端。因此，同步API看起来是一个自然的选择。
- en: The read services provided by the core microservices will also be developed
    as non-blocking synchronous APIs since there is an end user waiting for their
    responses.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心微服务提供的读取服务也将被开发为非阻塞同步API，因为最终用户正在等待它们的响应。
- en: The create and delete services provided by the core microservices will be developed
    as event-driven asynchronous services, meaning that they will listen for create
    and delete events on topics dedicated to each microservice.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心微服务提供的创建和删除服务将被开发为事件驱动的异步服务，这意味着它们将监听每个微服务专属主题上的创建和删除事件。
- en: The synchronous APIs provided by the composite microservices to create and delete
    aggregated product information will publish create and delete events on these
    topics. If the publish operation succeeds, it will return with a 202 (Accepted)
    response; otherwise, an error response will be returned. The 202 response differs
    from a normal 200 (OK) response – it indicates that the request has been accepted,
    but not fully processed. Instead, the processing will be completed asynchronously
    and independently of the 202 response.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复合微服务提供的同步API用于创建和删除聚合产品信息，将在这些主题上发布创建和删除事件。如果发布操作成功，它将返回202（已接受）响应；否则，将返回错误响应。202响应与正常的200（OK）响应不同——它表示请求已被接受，但尚未完全处理。相反，处理将在异步和独立于202响应的情况下完成。
- en: 'This is illustrated by the following diagram:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如下图所示：
- en: '![Graphical user interface, diagram  Description automatically generated](img/B19825_07_01.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，图描述自动生成](img/B19825_07_01.png)'
- en: 'Figure 7.1: The microservice landscape'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1：微服务景观
- en: First, let’s learn how we can develop non-blocking synchronous REST APIs, and
    thereafter, we will look at how to develop event-driven asynchronous services.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们学习如何开发非阻塞同步REST API，然后我们将探讨如何开发事件驱动的异步服务。
- en: Developing non-blocking synchronous REST APIs
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发非阻塞同步REST API
- en: 'In this section, we will learn how to develop non-blocking versions of the
    read APIs. The composite service will make reactive, that is, non-blocking, calls
    in parallel to the three core services. When the composite service has received
    responses from all of the core services, it will create a composite response and
    send it back to the caller. This is illustrated in the following diagram:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何开发读取API的非阻塞版本。复合服务将并行地对三个核心服务进行反应性（即非阻塞）调用。当复合服务从所有核心服务收到响应后，它将创建一个组合响应并将其发送回调用者。如下图所示：
- en: '![Diagram  Description automatically generated](img/B19825_07_02.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图描述自动生成](img/B19825_07_02.png)'
- en: 'Figure 7.2: The getCompositeProduct part of the landscape'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2：景观中的getCompositeProduct部分
- en: 'In this section, we will cover the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将涵盖以下内容：
- en: An introduction to Project Reactor
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Project Reactor简介
- en: Non-blocking persistence using Spring Data for MongoDB
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spring Data for MongoDB的非阻塞持久性
- en: Non-blocking REST APIs in the core services, including how to handle blocking
    code for the JPA-based persistence layer
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心服务中的非阻塞REST API，包括如何处理基于JPA的持久层中的阻塞代码
- en: Non-blocking REST APIs in the composite service
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复合服务中的非阻塞REST API
- en: An introduction to Project Reactor
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Project Reactor简介
- en: As we mentioned in the *Spring WebFlux* section in *Chapter 2*, *Introduction
    to Spring Boot*, the reactive support in Spring 5 is based on **Project Reactor**
    ([https://projectreactor.io](https://projectreactor.io)). Project Reactor is based
    on the *Reactive Streams specification* ([http://www.reactive-streams.org](http://www.reactive-streams.org)),
    a standard for building reactive applications. Project Reactor is fundamental
    – it is what Spring WebFlux, Spring WebClient, and Spring Data rely on to provide
    their reactive and non-blocking features.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在 *第 2 章* 中提到的 *Spring WebFlux* 部分，*Spring Boot 简介*，Spring 5 的响应式支持基于 **Project
    Reactor** ([https://projectreactor.io](https://projectreactor.io))。Project Reactor
    基于 *Reactive Streams 规范* ([http://www.reactive-streams.org](http://www.reactive-streams.org))，这是构建响应式应用程序的标准。Project
    Reactor 是基础的——它是 Spring WebFlux、Spring WebClient 和 Spring Data 依赖以提供其响应式和非阻塞功能的基础。
- en: 'The programming model is based on processing streams of data, and the core
    data types in Project Reactor are **Flux** and **Mono**. A `Flux` object is used
    to process a stream of *0...n* elements and a `Mono` object is used to process
    a stream that either is empty or returns at most one element. We will see numerous
    examples of their usage in this chapter. As a short introduction, let’s look at
    the following test:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 编程模型基于处理数据流，Project Reactor 的核心数据类型是 **Flux** 和 **Mono**。一个 `Flux` 对象用于处理 *0...n*
    元素的流，一个 `Mono` 对象用于处理要么为空要么最多返回一个元素的流。我们将在本章中看到它们使用的许多示例。作为一个简短的介绍，让我们看看以下测试：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here is an explanation of the preceding source code:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是对前面源代码的解释：
- en: We initiate the stream with the integers `1`, `2`, `3`, and `4` using the static
    helper method `Flux.just()`.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用静态辅助方法 `Flux.just()` 以整数 `1`、`2`、`3` 和 `4` 初始化流。
- en: Next, we `filter` out the odd numbers – we only allow even numbers to proceed
    through the stream. In this test, these are `2` and `4`.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们 `filter` 出奇数——我们只允许偶数通过流。在这个测试中，这些是 `2` 和 `4`。
- en: Next, we transform (or `map`) the values in the stream by multiplying them by
    `2`, so they become `4` and `8`.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将流中的值通过乘以 `2` 进行转换（或 `map`），因此它们变为 `4` 和 `8`。
- en: Then, we `log` the data that flows through the stream after the `map` operation.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在 `map` 操作之后 `log` 流中流动的数据。
- en: We use the `collectList` method to collect all items from the stream into a
    `List`, emitted once the stream completes.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 `collectList` 方法将流中的所有项目收集到一个 `List` 中，一旦流完成，就会发出一次。
- en: So far, we have only declared the processing of a stream. To actually get the
    stream processed, we need someone to subscribe to it. The final call to the `block`
    method will register a subscriber that waits for the processing to complete.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 到目前为止，我们只声明了流的处理。要实际获取处理的流，我们需要有人订阅它。对 `block` 方法的最终调用将注册一个等待处理完成的订阅者。
- en: The resulting list is saved in a member variable named `list`.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果列表被保存在名为 `list` 的成员变量中。
- en: We can now wrap up the test by using the `assertThat` method to assert that
    `list` after the processing of the stream contains the expected result – the integers
    `4` and `8`.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以使用 `assertThat` 方法来总结测试，断言流处理后的 `list` 包含预期的结果——整数 `4` 和 `8`。
- en: 'The log output will look like the following:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 日志输出将如下所示：
- en: '![Text  Description automatically generated](img/B19825_07_03.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![文本描述自动生成](img/B19825_07_03.png)'
- en: 'Figure 7.3: Log output for the code above'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3：上述代码的日志输出
- en: 'From the preceding log output, we can see that:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的日志输出中，我们可以看到：
- en: The processing of the stream is started by a subscriber that subscribes to the
    stream and requests its content.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 流的处理由一个订阅流并请求其内容的订阅者启动。
- en: Next, the integers `4` and `8` pass through the `log` operation.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，整数 `4` 和 `8` 通过 `log` 操作。
- en: The processing concludes with a call to the `onComplete` method on the subscriber,
    notifying it that the stream has come to an end.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理通过在订阅者上调用 `onComplete` 方法结束，通知它流已结束。
- en: For the full source code, see the `ReactorTests` test class in the `util` project.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看完整的源代码，请参阅 `util` 项目中的 `ReactorTests` 测试类。
- en: Normally, we don’t initiate the processing of the stream. Instead, we only define
    how it will be processed, and it will be the responsibility of an infrastructure
    component to initiate the processing. For example, Spring WebFlux will do this
    as a response to an incoming HTTP request. An exception to this rule of thumb
    is the case where blocking code needs a response from a reactive stream. In these
    cases, the blocking code can call the `block()` method on the `Flux` or `Mono`
    object to get the response in a blocking way.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们不启动流处理。相反，我们只定义它将如何被处理，并且将由基础设施组件负责启动处理。例如，Spring WebFlux 将作为对传入 HTTP 请求的响应来执行此操作。这个规则的一个例外是，当阻塞代码需要从反应式流中获取响应时。在这些情况下，阻塞代码可以在
    `Flux` 或 `Mono` 对象上调用 `block()` 方法以阻塞方式获取响应。
- en: Non-blocking persistence using Spring Data for MongoDB
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Spring Data 为 MongoDB 实现非阻塞持久化
- en: 'Making the MongoDB-based repositories for the `product` and `recommendation`
    services reactive is very simple:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使 `product` 和 `recommendation` 服务的 MongoDB 基础仓库反应式化非常简单：
- en: Change the base class for the repositories to `ReactiveCrudRepository`
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将仓库的基类更改为 `ReactiveCrudRepository`
- en: Change the custom finder methods to return either a `Mono` or a `Flux` object
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将自定义查找方法更改为返回 `Mono` 或 `Flux` 对象
- en: '`ProductRepository` and `RecommendationRepository` look like the following
    after the change:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 修改后的 `ProductRepository` 和 `RecommendationRepository` 如下所示：
- en: '[PRE1]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: No changes are applied to the persistence code for the `review` service; it
    will remain blocking using the JPA repository. See the following section, *Dealing
    with blocking code*, for how to handle the blocking code in the persistence layer
    of the `review` service.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 `review` 服务的持久化代码没有应用任何更改；它将继续使用 JPA 仓库进行阻塞。有关如何在 `review` 服务的持久化层中处理阻塞代码的详细信息，请参阅以下部分，*处理阻塞代码*。
- en: 'For the full source code, take a look at the following classes:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整源代码，请查看以下类：
- en: '`ProductRepository` in the `product` project'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ProductRepository` 在 `product` 项目中'
- en: '`RecommendationRepository` in the `recommendation` project'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RecommendationRepository` 在 `recommendation` 项目中'
- en: Changes in the test code
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试代码的更改
- en: When it comes to testing the persistence layer, we have to make some changes.
    Since our persistence methods now return a `Mono` or `Flux` object, the test methods
    have to wait for the response to be available in the returned reactive objects.
    The test methods can either use an explicit call to the `block()` method on the
    `Mono`/`Flux` object to wait until a response is available, or they can use the
    `StepVerifier` helper class from Project Reactor to declare a verifiable sequence
    of asynchronous events.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到测试持久化层时，我们必须进行一些更改。由于我们的持久化方法现在返回一个 `Mono` 或 `Flux` 对象，测试方法必须等待返回的反应式对象中响应可用。测试方法可以使用对
    `Mono`/`Flux` 对象上的 `block()` 方法的显式调用等待响应可用，或者它们可以使用来自 Project Reactor 的 `StepVerifier`
    辅助类声明一个可验证的异步事件序列。
- en: 'Let’s see how we can change the following test code to work for the reactive
    version of the repository:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何将以下测试代码更改为适用于仓库的反应式版本：
- en: '[PRE2]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can use the `block()` method on the `Mono` object returned by the `repository.findById()`
    method and keep the imperative programming style, as shown here:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 `repository.findById()` 方法返回的 `Mono` 对象上使用 `block()` 方法，并保持命令式编程风格，如下所示：
- en: '[PRE3]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Alternatively, we can use the `StepVerifier` class to set up a sequence of
    processing steps that both executes the repository find operation and also verifies
    the result. The sequence is initialized by the final call to the `verifyComplete()`
    method like this:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以使用 `StepVerifier` 类来设置一系列处理步骤，这些步骤既执行仓库查找操作，也验证结果。序列通过调用 `verifyComplete()`
    方法初始化，如下所示：
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: For examples of tests that use the `StepVerifier` class, see the `PersistenceTests`
    test class in the `product` project.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用 `StepVerifier` 类的测试示例，请参阅 `product` 项目的 `PersistenceTests` 测试类。
- en: For corresponding examples of tests that use the `block()` method, see the `PersistenceTests`
    test class in the `recommendation` project.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用 `block()` 方法的测试的相应示例，请参阅 `recommendation` 项目的 `PersistenceTests` 测试类。
- en: Non-blocking REST APIs in the core services
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 核心服务中的非阻塞 REST API
- en: 'With a non-blocking persistence layer in place, it’s time to make the APIs
    in the core services non-blocking as well. We need to make the following changes:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在非阻塞持久化层就绪后，是时候使核心服务的 API 也非阻塞了。我们需要进行以下更改：
- en: Change the APIs so that they only return reactive data types
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改 API 以使其仅返回反应式数据类型
- en: Change the service implementations so they don’t contain any blocking code
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改服务实现，使其不包含任何阻塞代码
- en: Change our tests so that they can test the reactive services
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改我们的测试，以便它们可以测试反应式服务
- en: Deal with blocking code – isolate the code that still needs to be blocking from
    the non-blocking code
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理阻塞代码 - 将仍然需要阻塞的代码与非阻塞代码隔离
- en: Changes in the APIs
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: API的更改
- en: To make the APIs of the core services reactive, we need to update their methods
    so that they return either a `Mono` or `Flux` object.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使核心服务的API反应式，我们需要更新它们的方法，使它们返回`Mono`或`Flux`对象。
- en: 'For example, `getProduct()` in the `product` service now returns `Mono<Product>`
    instead of a `Product` object:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`product`服务中的`getProduct()`现在返回`Mono<Product>`而不是`Product`对象：
- en: '[PRE5]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'For the full source code, take a look at the following `core` interfaces in
    the `api` project:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请查看`api`项目中的以下`core`接口：
- en: '`ProductService`'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ProductService`'
- en: '`RecommendationService`'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RecommendationService`'
- en: '`ReviewService`'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ReviewService`'
- en: Changes in the service implementations
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务实现中的更改
- en: 'For the implementations of the services in the `product` and `recommendation`
    projects, which use a reactive persistence layer, we can use the fluent API in
    Project Reactor. For example, the implementation of the `getProduct()` method
    looks like the following code:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`product`和`recommendation`项目中使用反应式持久化层的服务的实现，我们可以使用Project Reactor的流畅API。例如，`getProduct()`方法的实现如下所示：
- en: '[PRE6]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let’s examine what the code does:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看代码做了什么：
- en: The method will return a `Mono` object; the processing is only declared here.
    The processing is triggered by the web framework, Spring WebFlux, subscribing
    to the `Mono` object once it receives a request to this service!
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此方法将返回一个`Mono`对象；处理在这里仅声明。处理由接收此服务请求的Web框架Spring WebFlux在订阅`Mono`对象时触发！
- en: A product will be retrieved using its `productId` from the underlying database
    using the `findByProductId()` method in the persistence repository.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将使用持久化存储库中的`findByProductId()`方法从底层数据库中通过`productId`检索产品。
- en: If no product is found for the given `productId`, a `NotFoundException` will
    be thrown.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果对于给定的`productId`没有找到产品，将抛出`NotFoundException`。
- en: The `log` method will produce log output.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`log`方法将生成日志输出。'
- en: The `mapper.entityToApi()` method will be called to transform the returned entity
    from the persistence layer into an API model object.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将调用`mapper.entityToApi()`方法将持久化层返回的实体转换为API模型对象。
- en: The final `map` method will use a helper method, `setServiceAddress()`, to set
    the DNS name and IP address of the microservices that processed the request in
    the `serviceAddress` field of the model object.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终的`map`方法将使用辅助方法`setServiceAddress()`来设置处理请求的微服务的DNS名称和IP地址，并将其存储在模型对象的`serviceAddress`字段中。
- en: 'Some example log output for successful processing is as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 成功处理的一些示例日志输出如下：
- en: '![Text  Description automatically generated](img/B19825_07_04.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![文本描述自动生成](img/B19825_07_04.png)'
- en: 'Figure 7.4: Log output when processing is successful'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4：处理成功时的日志输出
- en: 'The following is an example log output of a failed processing (throwing a `NotFoundException`):'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个失败处理（抛出`NotFoundException`）的示例日志输出：
- en: '![Text  Description automatically generated](img/B19825_07_05.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![文本描述自动生成](img/B19825_07_05.png)'
- en: 'Figure 7.5: Log output when processing fails'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5：处理失败时的日志输出
- en: 'For the full source code, see the following classes:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请查看以下类：
- en: '`ProductServiceImpl` in the `product` project'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`product`项目中的`ProductServiceImpl`'
- en: '`RecommendationServiceImpl` in the `recommendation` project'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recommendation`项目中的`RecommendationServiceImpl`'
- en: Changes in the test code
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试代码的更改
- en: The test code for service implementations has been changed in the same way as
    the tests for the persistence layer we described previously. To handle the asynchronous
    behavior of the reactive return types, `Mono` and `Flux`, the tests use a mix
    of calling the `block()` method and using the `StepVerifier` helper class.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 服务实现的测试代码已经按照我们之前描述的持久化层测试的方式进行了更改。为了处理反应式返回类型`Mono`和`Flux`的异步行为，测试使用了调用`block()`方法和使用`StepVerifier`辅助类的方法组合。
- en: 'For the full source code, see the following test classes:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请查看以下测试类：
- en: '`ProductServiceApplicationTests` in the `product` project'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`product`项目中的`ProductServiceApplicationTests`'
- en: '`RecommendationServiceApplicationTests` in the `recommendation` project'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recommendation`项目中的`RecommendationServiceApplicationTests`'
- en: Dealing with blocking code
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理阻塞代码
- en: In the case of the `review` service, which uses JPA to access its data in a
    relational database, we don’t have support for a non-blocking programming model.
    Instead, we can run the blocking code using a `Scheduler`, which is capable of
    running the blocking code on a thread from a dedicated thread pool with a limited
    number of threads. Using a thread pool for the blocking code avoids draining the
    available threads in the microservice and avoids affecting concurrent non-blocking
    processing in the microservice, if there is any.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在`review`服务的情况下，该服务使用JPA从关系型数据库中访问其数据，我们并没有支持非阻塞编程模型。相反，我们可以使用`Scheduler`来运行阻塞代码，这个`Scheduler`能够在一个具有有限线程数的专用线程池上运行阻塞代码。使用线程池来运行阻塞代码可以避免耗尽微服务中的可用线程，并且如果有的话，还可以避免影响微服务中的并发非阻塞处理。
- en: 'Let’s see how this can be set up in the following steps:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下步骤如何设置：
- en: 'First, we configure a scheduler bean and its thread pool in the main class
    `ReviewServiceApplication`, as follows:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们在主类`ReviewServiceApplication`中配置一个调度器bean及其线程池，如下所示：
- en: '[PRE7]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'From the preceding code, we can see that the scheduler bean is named `jdbcScheduler`
    and that we can configure its thread pool using the following properties:'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从前面的代码中，我们可以看到调度器bean的名称是`jdbcScheduler`，并且我们可以使用以下属性来配置其线程池：
- en: '`app.threadPoolSize`, specifying the max number of threads in the pool; defaults
    to `10`'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`app.threadPoolSize`，指定池中线程的最大数量；默认为`10`'
- en: '`app.taskQueueSize`, specifying the max number of tasks that are allowed to
    be placed in a queue waiting for available threads; defaults to `100`'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`app.taskQueueSize`，指定允许放置在队列中等待可用线程的最大任务数；默认为`100`'
- en: 'Next, we inject the scheduler named `jdbcScheduler` into the `review` service
    implementation class, as shown here:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将名为`jdbcScheduler`的调度器注入到`review`服务实现类中，如下所示：
- en: '[PRE8]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, we use the scheduler’s thread pool in the reactive implementation
    of the `getReviews()` method, like so:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们在`getReviews()`方法的响应式实现中使用调度器的线程池，如下所示：
- en: '[PRE9]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Here, the blocking code is placed in the `internalGetReviews()` method and is
    wrapped in a `Mono` object using the `Mono.fromCallable()` method. The `getReviews()`
    method uses the `subscribeOn()` method to run the blocking code in a thread from
    the thread pool of `jdbcScheduler`.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，阻塞代码被放置在`internalGetReviews()`方法中，并使用`Mono.fromCallable()`方法包装在一个`Mono`对象中。`getReviews()`方法使用`subscribeOn()`方法在`jdbcScheduler`的线程池中的一个线程上运行阻塞代码。
- en: 'When we run tests later on in this chapter, we can look at the log output from
    the `review` service and see proof that SQL statements are run in threads from
    the scheduler’s dedicated pool. We will be able to see log output like this:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在本章后面运行测试时，我们可以查看`review`服务的日志输出，并看到SQL语句是在调度器的专用池中的线程上运行的证据。我们将能够看到如下日志输出：
- en: '![Text  Description automatically generated](img/B19825_07_06.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![文本描述自动生成](img/B19825_07_06.png)'
- en: 'Figure 7.6: Log output from the review service'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6：`review`服务的日志输出
- en: 'From the preceding log output, we can see the following:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的日志输出中，我们可以看到以下内容：
- en: The first log output is from the `LOG.info()` call in the `getReviews()` method
    and it is executed on an HTTP thread, named `ctor-http-nio-4`, a thread used by
    WebFlux.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一条日志输出来自`getReviews()`方法中的`LOG.info()`调用，它在名为`ctor-http-nio-4`的HTTP线程上执行，这是WebFlux使用的线程。
- en: In the second log output, we can see the SQL statement generated by Spring Data
    JPA, using Hibernate under the hood. The SQL statement corresponds to the method
    call `repository.findByProductId()`. It is executed on a thread named `jdbc-pool-1`,
    meaning it is executed in a thread from the dedicated thread pool for blocking
    code, as expected!
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第二条日志输出中，我们可以看到由Spring Data JPA生成的SQL语句，底层使用Hibernate。该SQL语句对应于`repository.findByProductId()`方法调用。它在名为`jdbc-pool-1`的线程上执行，这意味着它是在预期中的阻塞代码专用线程池中的线程上执行的！
- en: For the full source code, see the `ReviewServiceApplication` and `ReviewServiceImpl`
    classes in the `review` project.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请参阅`review`项目中的`ReviewServiceApplication`和`ReviewServiceImpl`类。
- en: With the logic for handling blocking code in place, we are done with implementing
    the non-blocking REST APIs in the core services. Let’s move on and see how to
    also make the REST APIs in the composite services non-blocking.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理阻塞代码的逻辑就绪后，我们就完成了核心服务中非阻塞REST API的实现。让我们继续看看如何也将组合服务中的REST API变为非阻塞。
- en: Non-blocking REST APIs in the composite services
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组合服务中的非阻塞REST API
- en: 'To make our REST API in the composite service non-blocking, we need to do the
    following:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 要使组合服务中的REST API非阻塞，我们需要做以下操作：
- en: Change the API so that its operations only return reactive data types
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改API，使其操作仅返回反应式数据类型
- en: Change the service implementation so it calls the coreata services’ APIs in
    parallel and in a non-blocking way
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改服务实现，使其以并行和非阻塞的方式调用核心服务的API
- en: Change the integration layer so it uses a non-blocking HTTP client
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改集成层，使其使用非阻塞HTTP客户端
- en: Change our tests so that they can test the reactive service
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改我们的测试，以便它们可以测试反应式服务
- en: Changes in the API
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: API的变更
- en: To make the API of the composite service reactive, we need to apply the same
    type of change that we applied for the APIs of the core services we described
    previously. This means that the return type of the `getProduct()` method, `ProductAggregate`,
    needs to be replaced with `Mono<ProductAggregate>`.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 要使组合服务的API反应式，我们需要应用与之前应用于核心服务API相同的类型变更。这意味着`getProduct()`方法的返回类型`ProductAggregate`需要替换为`Mono<ProductAggregate>`。
- en: The `createProduct()` and `deleteProduct()` methods need to be updated to return
    a `Mono<Void>` instead of a `void`; otherwise, we can’t propagate any error responses
    back to the callers of the API.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '`createProduct()`和`deleteProduct()`方法需要更新为返回`Mono<Void>`而不是`void`；否则，我们无法将任何错误响应传播回API的调用者。'
- en: For the full source code, see the `ProductCompositeService` interface in the
    `api` project.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请参阅`api`项目中的`ProductCompositeService`接口。
- en: Changes in the service implementation
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务实现的变更
- en: 'To be able to call the three APIs in parallel, the service implementation uses
    the static `zip()` method on the `Mono` class. The `zip` method is capable of
    handling a number of parallel reactive requests and zipping them together once
    they all are complete. The code looks like this:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够并行调用三个API，服务实现使用了`Mono`类的静态`zip()`方法。`zip`方法能够处理多个并发的反应式请求，并在所有请求都完成后将它们压缩在一起。代码如下：
- en: '[PRE10]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let’s take a closer look:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看：
- en: The first parameter of the `zip` method is a lambda function that will receive
    the responses in an array, named `values`. The array will contain a product, a
    list of recommendations, and a list of reviews. The actual aggregation of the
    responses from the three API calls is handled by the same helper method as before,
    `createProductAggregate()`, without any changes.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`zip`方法的第一个参数是一个lambda函数，它将接收一个名为`values`的数组中的响应。该数组将包含一个产品、一个推荐列表和一个评论列表。从三个API调用中收集响应的实际聚合操作由与之前相同的辅助方法`createProductAggregate()`处理，没有任何变化。'
- en: The parameters after the lambda function are a list of the requests that the
    `zip` method will call in parallel, one `Mono` object per request. In our case,
    we send in three `Mono` objects that were created by the methods in the integration
    class, one for each request that is sent to each core microservice.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: lambda函数后面的参数是`zip`方法将并行调用的请求列表，每个请求一个`Mono`对象。在我们的情况下，我们发送了三个由集成类中的方法创建的`Mono`对象，每个对象对应于发送到每个核心微服务的每个请求。
- en: For the full source code, see the `ProductCompositeServiceImpl` class in the
    `product-composite` project.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的源代码，请参阅`product-composite`项目中的`ProductCompositeServiceImpl`类。
- en: For information on how the `createProduct` and `deleteProduct` API operations
    are implemented in the `product-composite` service, see the *Publishing events
    in the composite service* section later on.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何在`product-composite`服务中实现`createProduct`和`deleteProduct` API操作的信息，请参阅后面的*在组合服务中发布事件*部分。
- en: Changes in the integration layer
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集成层的变更
- en: In the `ProductCompositeIntegration` integration class, we have replaced the
    blocking HTTP client, `RestTemplate`, with a non-blocking HTTP client, `WebClient`,
    that comes with Spring 5.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ProductCompositeIntegration`集成类中，我们将阻塞的HTTP客户端`RestTemplate`替换为Spring 5提供的非阻塞HTTP客户端`WebClient`。
- en: To create a `WebClient` instance, a **builder pattern** is used. If customization
    is required, for example, setting up common headers or filters, it can be done
    using the builder. For the available configuration options, see [https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-client-builder](https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-client-builder).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建`WebClient`实例，使用的是**建造者模式**。如果需要定制，例如设置公共头或过滤器，可以使用建造者来完成。有关可用的配置选项，请参阅[https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-client-builder](https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-client-builder)。
- en: 'The `WebClient` is used as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '`WebClient`的使用方式如下：'
- en: 'In the constructor, the `WebClient` is auto-injected. We build the `WebClient`
    instance without any configuration:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在构造函数中，`WebClient`是自动注入的。我们构建`WebClient`实例而不进行任何配置：
- en: '[PRE11]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next, we use the `webClient` instance to make our non-blocking requests for
    calling the `product` service:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们使用`webClient`实例来对我们的`product`服务进行非阻塞请求：
- en: '[PRE12]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: If the API call to the `product` service fails with an HTTP error response,
    the whole API request will fail. The `onErrorMap()` method in `WebClient` will
    call our `handleException(ex)` method, which maps the HTTP exceptions thrown by
    the HTTP layer to our own exceptions, for example, a `NotFoundException` or a
    `InvalidInputException`.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如果对`product`服务的API调用失败并返回HTTP错误响应，整个API请求将失败。`WebClient`中的`onErrorMap()`方法将调用我们的`handleException(ex)`方法，该方法将HTTP层抛出的HTTP异常映射到我们自己的异常，例如`NotFoundException`或`InvalidInputException`。
- en: 'However, if calls to the `product` service succeed but the call to either the
    `recommendation` or `review` API fails, we don’t want to let the whole request
    fail. Instead, we want to return as much information as is available back to the
    caller. Therefore, instead of propagating an exception in these cases, we will
    instead return an empty list of recommendations or reviews. To suppress the error,
    we will make the call `onErrorResume(error -> empty())`. For this, the code looks
    like the following:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果对`product`服务的调用成功，但对`recommendation`或`review` API的调用失败，我们不想让整个请求失败。相反，我们希望将尽可能多的信息返回给调用者。因此，在这些情况下，我们不会传播异常，而是返回一个空的推荐或评论列表。为了抑制错误，我们将调用`onErrorResume(error
    -> empty())`。为此，代码如下所示：
- en: '[PRE13]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The `GlobalControllerExceptionHandler` class, from the `util` project, will,
    as previously, catch exceptions and transform them into proper HTTP error responses
    that are sent back to the caller of the composite API. This way we can decide
    if a specific HTTP error response from the underlying API calls will result in
    an HTTP error response or just a partly empty response.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 来自`util`项目的`GlobalControllerExceptionHandler`类，将像之前一样捕获异常并将它们转换为适当的HTTP错误响应，这些响应将发送回复合API的调用者。这样我们就可以决定来自底层API调用的特定HTTP错误响应是否会引发HTTP错误响应或只是一个部分为空的响应。
- en: For the full source code, see the `ProductCompositeIntegration` class in the
    `product-composite` project.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看完整的源代码，请参阅`product-composite`项目中的`ProductCompositeIntegration`类。
- en: Changes in the test code
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试代码中的更改
- en: 'The only change that’s required in the test classes is to update the setup
    of Mockito and its mock of the integration class. The mock needs to return `Mono`
    and `Flux` objects. The `setup()` method uses the helper methods `Mono.just()`
    and `Flux.fromIterable()`, as shown in the following code:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试类中需要做的唯一更改是更新Mockito及其对集成类的模拟的设置。模拟需要返回`Mono`和`Flux`对象。`setup()`方法使用辅助方法`Mono.just()`和`Flux.fromIterable()`，如下面的代码所示：
- en: '[PRE14]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: For the full source code, see the `ProductCompositeServiceApplicationTests`
    test class in the `product-composite` project.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看完整的源代码，请参阅`product-composite`项目中的`ProductCompositeServiceApplicationTests`测试类。
- en: This completes the implementation of our non-blocking synchronous REST APIs.
    Now it is time to develop our event-driven asynchronous services.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了我们非阻塞同步REST API的实现。现在，是时候开发我们的事件驱动异步服务了。
- en: Developing event-driven asynchronous services
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发事件驱动的异步服务
- en: 'In this section, we will learn how to develop event-driven and asynchronous
    versions of the create and delete services. The composite service will publish
    create and delete events on each core service topic and then return an OK response
    back to the caller without waiting for processing to take place in the core services.
    This is illustrated in the following diagram:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B19825_07_07.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.7: The createCompositeProduct and deleteCompositeProduct parts of
    the landscape'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Handling challenges with messaging
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining topics and events
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changes in Gradle build files
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consuming events in the core services
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Publishing events in the composite service
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling challenges with messaging
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To implement the event-driven create and delete services, we will use Spring
    Cloud Stream. In *Chapter 2*, *Introduction to Spring Boot*, we have already seen
    how easy it is to publish and consume messages on a topic using Spring Cloud Stream.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: The programming model is based on a functional paradigm, where functions implementing
    one of the functional interfaces `Supplier`, `Function`, or `Consumer` in the
    `java.util.function` package can be chained together to perform decoupled event-based
    processing. To trigger such functional-based processing externally, from non-functional
    code, the helper class `StreamBridge` can be used.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to publish the body of an HTTP request to a topic, we only have
    to write the following:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The helper class `StreamBridge` is used to trigger the processing. It will
    publish a message on a topic. A function that consumes events from a topic (not
    creating new events) can be defined by implementing the functional interface `java.util.function.Consumer`
    as:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: To tie the various functions together, we use configuration. We will see examples
    of such configuration below in the sections *Adding configuration for publishing
    events* and *Adding configuration for consuming events*.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: This programming model can be used independently of the messaging system used,
    for example, RabbitMQ or Apache Kafka!
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'Even though sending asynchronous messages is preferred over synchronous API
    calls, it comes with challenges of its own. We will see how we can use Spring
    Cloud Stream to handle some of them. The following features in Spring Cloud Stream
    will be covered:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: Consumer groups
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retries and dead-letter queues
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guaranteed orders and partitions
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll study each of these in the following sections.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Consumer groups
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The problem here is, if we scale up the number of instances of a message consumer,
    for example, if we start two instances of the `product` microservice, both instances
    of the `product` microservice will consume the same messages, as illustrated by
    the following diagram:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B19825_07_08.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.8: Products #1 and #2 consuming the same messages'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: 'This could result in one message being processed two times, potentially leading
    to duplicates or other undesired inconsistencies in the database. Therefore, we
    only want one instance per consumer to process each message. This can be solved
    by introducing a **consumer group**, as illustrated by the following diagram:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B19825_07_09.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.9: Consumer group'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: 'In Spring Cloud Stream, a consumer group can be configured on the consumer
    side. For example, for the `product` microservice, it will look like this:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'From this configuration, we can learn the following:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: 'Spring Cloud Stream applies, by default, a naming convention for binding a
    configuration to a function. For messages sent to a function, the binding name
    is `<functionName>-in-<index>`:'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`functionName` is the name of the function, `messageProcessor` in the preceding
    example.'
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`index` is set to `0`, unless the function requires multiple input or output
    arguments. We will not use multi-argument functions, so `index` will always be
    set to `0` in our examples.'
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For outgoing messages, the binding name convention is `<functionName>-out-<index>`.
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The `destination` property specifies the name of the topic that messages will
    be consumed from, `products` in this case.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `group` property specifies what consumer group to add instances of the `product`
    microservice to, `productsGroup` in this example. This means that messages sent
    to the `products` topic will only be delivered by Spring Cloud Stream to one of
    the instances of the `product` microservice.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retries and dead-letter queues
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If a consumer fails to process a message, it may be re-queued for the failing
    consumer until it is successfully processed. If the content of the message is
    invalid, also known as a **poisoned message**, the message will block the consumer
    from processing other messages until it is manually removed. If the failure is
    due to a temporary problem, for example, the database can’t be reached due to
    a temporary network error, the processing will probably succeed after a number
    of retries.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: It must be possible to specify the number of retries until a message is moved
    to another storage for fault analysis and correction. A failing message is typically
    moved to a dedicated queue called a dead-letter queue. To avoid overloading the
    infrastructure during temporary failure, for example, a network error, it must
    be possible to configure how often retries are performed, preferably with an increasing
    length of time between each retry.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: 'In Spring Cloud Stream, this can be configured on the consumer side, for example,
    for the `product` microservice, as shown here:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In the preceding example, we specify that Spring Cloud Stream should perform
    `3` retries before placing a message on the dead-letter queue. The first retry
    will be attempted after `500` ms and the two other attempts after `1000` ms.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Enabling the use of dead-letter queues is binding-specific; therefore, we have
    one configuration for RabbitMQ and one for Kafka.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Guaranteed order and partitions
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If the business logic requires that messages are consumed and processed in the
    same order as they were sent, we cannot use multiple instances per consumer to
    increase processing performance; for example, we cannot use consumer groups. This
    might, in some cases, lead to an unacceptable latency in the processing of incoming
    messages.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: We can use **partitions** to ensure that messages are delivered in the same
    order as they were sent but without losing performance and scalability.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, strict order in the processing of messages is only required for
    messages that affect the same business entities. For example, messages affecting
    the product with product ID `1` can, in many cases, be processed independently
    of messages that affect the product with product ID `2`. This means that the order
    only needs to be guaranteed for messages that have the same product ID.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: The solution to this is to make it possible to specify a **key** for each message,
    which the messaging system can use to guarantee that the order is kept between
    messages with the same key. This can be solved by introducing sub-topics, also
    known as **partitions**, in a topic. The messaging system places messages in a
    specific partition based on its key.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: 'Messages with the same key are always placed in the same partition. The messaging
    system only needs to guarantee the delivery order for messages in the same partition.
    To ensure the order of the messages, we configure one consumer instance per partition
    within a consumer group. By increasing the number of partitions, we can allow
    a consumer to increase its number of instances. This increases its message-processing
    performance without losing the delivery order. This is illustrated in the following
    diagram:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B19825_07_10.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.10: Specifying keys for messages'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: As seen in the preceding diagram, all messages with the `Key` set to `123` always
    go to the `Products-1`, partition while messages with the `Key` set to `456` go
    to the `Products-2` partition.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: 'In Spring Cloud Stream, this needs to be configured on both the publisher and
    consumer sides. On the publisher side, the key and number of partitions must be
    specified. For example, for the `product-composite` service, we have the following:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This configuration means that the key will be taken from the message header
    with the name `partitionKey` and that two partitions will be used.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: 'Each consumer can specify which partition it wants to consume messages from.
    For example, for the `product` microservice, we have the following:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This configuration tells Spring Cloud Stream that this consumer will only consume
    messages from partition number `0`, that is, the first partition.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: Defining topics and events
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we already mentioned in the *Spring Cloud Stream* section in *Chapter 2*,
    *Introduction to Spring Boot*, Spring Cloud Stream is based on the publish and
    subscribe pattern, where a publisher publishes messages to topics and subscribers
    subscribe to topics they are interested in receiving messages from.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use one **topic** per type of entity: `products`, `recommendations`,
    and `reviews`.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: Messaging systems handle **messages** that typically consist of headers and
    a body. An **event** is a message that describes something that has happened.
    For events, the message body can be used to describe the type of event, the event
    data, and a timestamp for when the event occurred.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: 'An event is, for the scope of this book, defined by the following:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: The **type** of event, for example, a create or delete event
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **key** that identifies the data, for example, a product ID
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **data** element, that is, the actual data in the event
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **timestamp**, which describes when the event occurred
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The event class we will use looks as follows:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let’s explain the preceding source code in detail:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: The `Event` class is a generic class parameterized over the types of its `key`
    and `data` fields, `K` and `T`
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The event type is declared as an enumerator with the allowed values, that is,
    `CREATE` and `DELETE`
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The class defines two constructors, one empty and one that can be used to initialize
    the type, key, and value members
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the class defines getter methods for its member variables
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the full source code, see the `Event` class in the `api` project.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the Gradle build files
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To bring in Spring Cloud Stream and its binders for RabbitMQ and Kafka, we
    need to add the two starter dependencies known as `spring-cloud-starter-stream-rabbit`
    and `spring-cloud-starter-stream-kafka`. We also need a test dependency in the
    `product-composite` project, `spring-cloud-stream::test-binder`, to bring in test
    support. The following code shows this:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To specify what version of Spring Cloud we want to use, we first declare a
    variable for the version:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Next, we use the variable to set up dependency management for the specified
    Spring Cloud version, as seen here:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: For the full source code, see the `build.gradle` build file in each of the microservices
    projects.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: With the required dependencies added to the Gradle build files, we can start
    to learn how to consume events in the core services.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Consuming events in the core services
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To be able to consume events in the core services, we need to do the following:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Declare message processors that consume events published on the core service’s
    topic
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change our service implementations to use the reactive persistence layer
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add configuration required for consuming events
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change our tests so that they can test the asynchronous processing of the events
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The source code for consuming events is structured in the same way in all three
    core services, so we will only go through the source code for the `product` service.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: Declaring message processors
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The REST APIs for creating and deleting entities have been replaced with a **message
    processor** in each core microservice that consumes create and delete events on
    each entity’s topic. To be able to consume messages that have been published to
    a topic, we need to declare a Spring Bean that implements the functional interface
    `java.util.function.Consumer`.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: 'The message processor for the `product` service is declared as:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'From the preceding code, we can see that:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: The class is annotated with `@Configuration`, telling Spring to look for Spring
    beans in the class.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We inject an implementation of the `ProductService` interface in the constructor.
    The `productService` bean contains the business logic to perform the actual creation
    and deletions of the product entities.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We declare the message processor as a Spring bean that implements the functional
    interface `Consumer`, accepting an event as an input parameter of type `Event<Integer,Product>`.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The implementation of the `Consumer` function looks like this:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The preceding implementation does the following:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: It takes an event of type `Event<Integer,Product>` as an input parameter
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a `switch` statement, based on the event type, it will either create or
    delete a product entity
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It uses the injected `productService` bean to perform the actual create and
    delete operation
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the event type is neither create nor delete, an exception will be thrown
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To ensure that we can propagate exceptions thrown by the `productService` bean
    back to the messaging system, we call the `block()` method on the responses we
    get back from the `productService` bean. This ensures that the message processor
    waits for the `productService` bean to complete its creation or deletion in the
    underlying database. Without calling the `block()` method, we would not be able
    to propagate exceptions and the messaging system would not be able to re-queue
    a failed attempt or possibly move the message to a dead-letter queue; instead,
    the message would silently be dropped.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: Calling a `block()` method is, in general, considered a bad practice from a
    performance and scalability perspective. But in this case, we will only handle
    a few incoming messages in parallel, one per partition, as described above. This
    means that we will only have a few threads blocked concurrently, which will not
    negatively impact the performance or the scalability.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: For the full source code, see the `MessageProcessorConfig` classes in the `product`,
    `recommendation`, and `review` projects.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the service implementations
  id: totrans-290
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The service implementations of the create and delete methods for the `product`
    and `recommendation` service have been rewritten to use the non-blocking reactive
    persistence layer for MongoDB. For example, creating product entities is done
    as follows:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Note from the preceding code that the `onErrorMap()` method is used to map the
    `DuplicateKeyException` persistence exception to our own `InvalidInputException`
    exception.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: For the `review` service, which uses the blocking persistence layer for JPA,
    the create and delete methods have been updated in the same way as described in
    the *Dealing with blocking code section*.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: 'For the full source code, see the following classes:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '`ProductServiceImpl` in the `product` project'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RecommendationServiceImpl` in the `recommendation` project'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ReviewServiceImpl` in the `review` project'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding configuration for consuming events
  id: totrans-299
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We also need to set up a configuration for the messaging system to be able
    to consume events. To do this, we need to complete the following steps:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: 'We declare that RabbitMQ is the default messaging system and that the default
    content type is JSON:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Next, we bind the input to the message processors to specific topic names,
    as follows:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Finally, we declare connectivity information for both Kafka and RabbitMQ:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: In the default Spring profile, we specify hostnames to be used when we run our
    system landscape without Docker on `localhost` with the IP address `127.0.0.1`.
    In the `docker` Spring profile, we specify the hostnames we will use when running
    in Docker and using Docker Compose, that is, `rabbitmq` and `kafka`.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: Added to this configuration, the consumer configuration also specifies consumer
    groups, retry handling, dead-letter queues, and partitions as they were described
    earlier in the *Handling challenges with messaging* section.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: For the full source code, see the `application.yml` configuration files in the
    `product`, `recommendation`, and `review` projects.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the test code
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since the core services now receive events for creating and deleting their
    entities, the tests need to be updated so that they send events instead of calling
    REST APIs, as they did in the previous chapters. To be able to call the message
    processor from the test class, we inject the message processor bean into a member
    variable:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: From the preceding code, we can see that we not only inject any `Consumer` function
    but also use the `@Qualifier` annotation to specify that we want to inject the
    `Consumer` function that has the name `messageProcessor`.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: 'To send create and delete events to the message processor, we add two helper
    methods, `sendCreateProductEvent` and `sendDeleteProductEvent`, in the test class:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Note that we use the `accept()` method in the `Consumer` function interface
    declaration to invoke the message processor. This means that we skip the messaging
    system in the tests and call the message processor directly.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: The tests for creating and deleting entities are updated to use these helper
    methods.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: 'For the full source code, see the following test classes:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '`ProductServiceApplicationTests` in the `product` project'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RecommendationServiceApplicationTests` in the `recommendation` project'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ReviewServiceApplicationTests` in the `review` project'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have seen what is required to consume events in the core microservices. Now
    let’s see how we can publish events in the composite microservice.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: Publishing events in the composite service
  id: totrans-323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When the composite service receives HTTP requests for the creation and deletion
    of composite products, it will publish the corresponding events to the core services
    on their topics. To be able to publish events in the composite service, we need
    to perform the following steps:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: Publish events in the integration layer
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add configuration for publishing events
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change tests so that they can test the publishing of events
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that no changes are required in the composite service implementation class
    – it is taken care of by the integration layer!
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: Publishing events in the integration layer
  id: totrans-329
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To publish an event in the integration layer, we need to:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: Create an `Event` object based on the body in the HTTP request
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a `Message` object where the `Event` object is used as the payload and
    the key field in the `Event` object is used as the partition key in the header
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the helper class `StreamBridge` to publish the event on the desired topic
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The code for sending create product events looks like this:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'In the preceding code, we can see:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: The integration layer implements the `createProduct()` method in the `ProductService`
    interface by using a helper method, `sendMessage()`. The helper method takes the
    name of an output binding and an event object. The binding name `products-out-0`
    will be bound to the topic of the `product` service in the configuration below.
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since the `sendMessage()` uses blocking code, when calling `streamBridge`, it
    is executed on a thread provided by a dedicated scheduler, `publishEventScheduler`.
    This is the same approach as for handling blocking JPA code in the `review` microservice.
    See the section on *Dealing with blocking code* for details.
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The helper method, `sendMessage()`, creates a `Message` object and sets the
    `payload` and the `partitionKey` header as described above. Finally, it uses the
    `streamBridge` object to send the event to the messaging system, which will publish
    it on the topic defined in the configuration.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the full source code, see the `ProductCompositeIntegration` class in the
    `product-composite` project.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: Adding configuration for publishing events
  id: totrans-341
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We also need to set up the configuration for the messaging system, to be able
    to publish events; this is similar to what we did for the consumers. Declaring
    RabbitMQ as the default messaging system, JSON as the default content type, and
    Kafka and RabbitMQ for connectivity information is the same as for the consumers.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: 'To declare what topics should be used for the output binding names, we have
    the following configuration:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'When using partitions, we also need to specify the partition key and the number
    of partitions that will be used:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'In the preceding configuration, we can see that:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: The configuration applies for the binding name `products-out-0`
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The partition key used will be taken from the message header `partitionKey`
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two partitions will be used
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the full source code, see the `application.yml` configuration file in the
    `product-composite` project.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the test code
  id: totrans-352
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Testing asynchronous event-driven microservices is, by its nature, difficult.
    Tests typically need to synchronize on the asynchronous background processing
    in some way to be able to verify the result. Spring Cloud Stream comes with support,
    in the form of a test binder, that can be used to verify what messages have been
    sent without using any messaging system during the tests!
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: See the *Changes in the Gradle build files* section earlier for how the test
    support is included in the `product-composite` project.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: 'The test support includes an `OutputDestination` helper class, which can be
    used to get the messages that were sent during a test. A new test class, `MessagingTests`,
    has been added to run tests that verify that the expected messages are sent. Let’s
    go through the most important parts of the test class:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: 'To be able to inject an `OutputDestination` bean in the test class, we also
    need to bring in its configuration from the class `TestChannelBinderConfiguration`.
    This is done with the following code:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Next, we declare a couple of helper methods for reading messages and also to
    be able to purge a topic. The code looks like this:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'From the preceding code, we can see that:'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `getMessage()` method returns a message from a specified topic using the
    `OutputDestination` bean, named `target`
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `getMessages()` method uses the `getMessage()` method to return all messages
    in a topic
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `purgeMessages()` method uses the `getMessages()` method to purge a topic
    from all current messages
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each test starts with purging all topics involved in the tests using a `setup()`
    method annotated with `@BeforeEach`:'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'An actual test can verify the messages in a topic using the `getMessages()`
    method. For example, see the following test for the creation of a composite product:'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'From the preceding code, we can see an example where a test:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: First makes an HTTP POST request, requesting the creation of a composite product.
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, gets all messages from the three topics, one for each underlying core
    service.
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For these tests, the specific timestamp for when an event was created is irrelevant.
    To be able to compare an actual event with an expected event, ignoring differences
    in the `eventCreatedAt` field, a helper class called `IsSameEvent` can be used.
    The `sameEventExceptCreatedAt()` method is a static method in the `IsSameEvent`
    class that compares `Event` objects and treats them as equal if all the fields
    are equal, except for the `eventCreatedAt` field.
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, it verifies that the expected events can be found, and no others.
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the full source code, see the test classes `MessagingTests` and `IsSameEvent`
    in the `product-composite` project.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: Running manual tests of the reactive microservice landscape
  id: totrans-374
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we have fully reactive microservices, both in terms of non-blocking synchronous
    REST APIs and event-driven asynchronous services. Let’s try them out!
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: 'We will learn how to run tests using both RabbitMQ and Kafka as the message
    broker. Since RabbitMQ can be used both with and without partitions, we will test
    both cases. Three different configurations will be used, each defined in a separate
    Docker Compose file:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: Using RabbitMQ without the use of partitions
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using RabbitMQ with two partitions per topic
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Kafka with two partitions per topic
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, before testing these three configurations, we need to add two features
    to be able to test the asynchronous processing:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: Saving events for later inspection when using RabbitMQ
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A health API that can be used to monitor the state of the microservice landscape
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saving events
  id: totrans-383
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After running some tests on event-driven asynchronous services, it might be
    of interest to see what events were actually sent. When using Spring Cloud Stream
    with Kafka, events are retained in the topics, even after consumers have processed
    them. However, when using Spring Cloud Stream with RabbitMQ, the events are removed
    after they have been processed successfully.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: 'To be able to see what events have been published on each topic, Spring Cloud
    Stream is configured to save published events in a separate consumer group, `auditGroup`,
    per topic. For the `products` topic, the configuration looks like the following:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: When using RabbitMQ, this will result in extra queues being created where the
    events are stored for later inspection.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: For the full source code, see the `application.yml` configuration file in the
    `product-composite` project.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: Adding a health API
  id: totrans-389
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Testing a system landscape of microservices that uses a combination of synchronous
    APIs and asynchronous messaging is challenging.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: For example, how do we know when a newly started landscape of microservices,
    together with their databases and messaging system, are ready to process requests
    and messages?
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: To make it easier to know when all the microservices are ready, we have added
    health APIs to the microservices. The health APIs are based on the support for
    **health endpoints** that comes with the Spring Boot module **Actuator**. By default,
    an Actuator-based health endpoint responds with `UP` (and gives 200 as the HTTP
    return status) if the microservice itself and all the dependencies Spring Boot
    knows about are available. Dependencies Spring Boot knows about include databases
    and messaging systems. If the microservice itself or any of its dependencies are
    not available, the health endpoint responds with `DOWN` (and returns 500 as the
    HTTP return status).
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: We can also extend health endpoints to cover dependencies that Spring Boot is
    not aware of. We will use this feature to extend to the product composite’s `health`
    endpoint, so it also includes the health of the three core services. This means
    that the product composite `health` endpoint will only respond with `UP` if itself
    and the three core microservices are healthy. This can be used either manually
    or automatically by the `test-em-all.bash` script to find out when all the microservices
    and their dependencies are up and running.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `ProductCompositeIntegration` class, we have added helper methods for
    checking the health of the three core microservices, as follows:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This code is similar to the code we used previously to call the core services
    to read APIs. Note that the health endpoint is, by default, set to `/actuator/health`.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: For the full source code, see the `ProductCompositeIntegration` class in the
    `product-composite` project.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: 'In the configuration class, `HealthCheckConfiguration`, we use these helper
    methods to register a composite health check using the Spring Actuator class `CompositeReactiveHealthContributor`:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: For the full source code, see the `HealthCheckConfiguration` class in the `product-composite`
    project.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, in the `application.yml` configuration file of all four microservices,
    we configure the Spring Boot Actuator so that it does the following:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: Shows details about the state of health, which not only includes `UP` or `DOWN`,
    but also information about its dependencies
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exposes all its endpoints over HTTP
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The configuration for these two settings looks as follows:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: For an example of the full source code, see the `application.yml` configuration
    file in the `product-composite` project.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: '**WARNING**: These configuration settings are helpful during development, but
    it can be a security issue to reveal too much information in actuator endpoints
    in production systems. Therefore, plan to minimize the information exposed by
    the actuator endpoints in production!'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: This can be done by replacing `"*"` with, for example, `health,info` in the
    setting of the `management.endpoints.web.exposure.include` property above.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: For details regarding the endpoints that are exposed by Spring Boot Actuator,
    see [https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-endpoints.html](https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-endpoints.html).
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: 'The health endpoint can be used manually with the following command (don’t
    try it yet, wait until we have started up the microservice landscape below!):'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'This will result in a response containing:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: '![Text  Description automatically generated](img/B19825_07_11.png)'
  id: totrans-413
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.11: Health endpoint response'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding output, we can see that the composite service reports that
    it is healthy; that is, its status is `UP`. At the end of the response, we can
    see that all three core microservices are also reported as healthy.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: With a health API in place, we are ready to test our reactive microservices.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: Using RabbitMQ without using partitions
  id: totrans-417
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will test the reactive microservices together with RabbitMQ
    but without using partitions.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: 'The default `docker-compose.yml` Docker Compose file is used for this configuration.
    The following changes have been added to the file:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: 'RabbitMQ has been added, as shown here:'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'From the declaration of RabbitMQ above, we can see that:'
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We use a Docker image for RabbitMQ v3.11.8 including the management plugin and
    Admin Web UI
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We expose the standard ports for connecting to RabbitMQ and the Admin Web UI,
    `5672` and `15672`
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We add a health check so that Docker can find out when RabbitMQ is ready to
    accept connections
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The microservices now have a dependency declared on the RabbitMQ service. This
    means that Docker will not start the microservice containers until the RabbitMQ
    service is reported to be healthy:'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'To run manual tests, perform the following steps:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: 'Build and start the system landscape with the following commands:'
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Now, we have to wait for the microservice landscape to be up and running. Try
    running the following command a few times:'
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: When it returns `UP`, we are ready to run our tests!
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'First, create a composite product with the following commands:'
  id: totrans-434
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: When using Spring Cloud Stream together with RabbitMQ, it will create one RabbitMQ
    exchange per topic and a set of queues, depending on our configuration. Let’s
    see what queues Spring Cloud Stream has created for us!
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Open the following URL in a web browser: `http://localhost:15672/#/queues`.
    Log in with the default username/password `guest`/`guest`. You should see the
    following queues:![Graphical user interface, application, table  Description automatically
    generated](img/B19825_07_12.png)Figure 7.12: List of queues'
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each topic, we can see one queue for the **auditGroup**, one queue for the
    consumer group that’s used by the corresponding core microservice, and one dead-letter
    queue. We can also see that the **auditGroup** queues contain messages, as expected!
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Click on the **products.auditGroup** queue and scroll down to the **Get messages**
    section, expand it, and click on the button named **Get Message(s)** to see the
    message in the queue:![Graphical user interface, text, application, email  Description
    automatically generated](img/B19825_07_13.png)Figure 7.13: Viewing the message
    in the queue'
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the preceding screenshot, note the **Payload** but also the header **partitionKey**,
    which we will use in the next section where we try out RabbitMQ with partitions.
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, try to get the product composite using the following code:'
  id: totrans-441
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Finally, delete it with the following command:'
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Try to get the deleted product again. It should result in a `404 - "NotFound"`
    response!
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you look in the RabbitMQ audit queues again, you should be able to find new
    messages containing delete events.
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Wrap up the test by bringing down the microservice landscape with the following
    command:'
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: This completes the tests where we use RabbitMQ without partitions. Now, let’s
    move on and test RabbitMQ with partitions.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: Using RabbitMQ with partitions
  id: totrans-450
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, let’s try out the partitioning support in Spring Cloud Stream!
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: 'We have a separate Docker Compose file prepared for using RabbitMQ with two
    partitions per topic: `docker-compose-partitions.yml`. It will also start two
    instances per core microservice, one for each partition. For example, a second
    `product` instance is configured as follows:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Here is an explanation of the preceding configuration:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: We use the same source code and Dockerfile that we did for the first `product`
    instance but configure them differently.
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To make all microservice instances aware that they will use partitions, we have
    added the Spring profile `streaming_partitioned` to their environment variable
    `SPRING_PROFILES_ACTIVE`.
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We assign the two `product` instances to different partitions using different
    Spring profiles. The Spring profile `streaming_instance_0` is used by the first
    product instance and `streaming_instance_1` is used by the second instance, `product-p1`.
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second `product` instance will only process asynchronous events; it will
    not respond to API calls. Since it has a different name, `product-p1` (also used
    as its DNS name), it will not respond to calls to a URL starting with `http://product:8080`.
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Start up the microservice landscape with the following command:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Create a composite product in the same way as for the tests in the previous
    section but also create a composite product with the product ID set to `2`. If
    you take a look at the queues set up by Spring Cloud Stream, you will see one
    queue per partition and that the product audit queues now contain one message
    each; the event for product ID `1` was placed in one partition and the event for
    product ID `2` was placed in the other partition.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: 'If you go back to `http://localhost:15672/#/queues` in your web browser, you
    should see something like the following:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B19825_07_14.png)'
  id: totrans-463
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.14: List of queues'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: 'To end the test with RabbitMQ using partitions, bring down the microservice
    landscape with the following command:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: We are now done with tests using RabbitMQ, both with and without partitions.
    The final test configuration we shall try out is testing the microservices together
    with Kafka.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
- en: Using Kafka with two partitions per topic
  id: totrans-468
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, we shall try out a very cool feature of Spring Cloud Stream: changing
    the messaging system from RabbitMQ to Apache Kafka!'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be done simply by changing the value of the `spring.cloud.stream.defaultBinder`
    property from `rabbit` to `kafka`. This is handled by the `docker-compose-kafka.yml`
    Docker Compose file, which has also replaced RabbitMQ with Kafka and ZooKeeper.
    The configuration of Kafka and ZooKeeper looks as follows:'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-471
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Kafka is also configured to use two partitions per topic, and like before, we
    start up two instances per core microservice, one for each partition. See the
    Docker Compose file, `docker-compose-kafka.yml`, for details!
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: 'Start up the microservice landscape with the following command:'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Repeat the tests from the previous section: create two products, one with the
    product ID set to `1` and one with the product ID set to `2`.'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, Kafka doesn’t come with any graphical tools that can be used
    to inspect topics, partitions, and the messages that are placed within them. Instead,
    we can run CLI commands in the Kafka Docker container.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
- en: 'To see a list of topics, run the following command:'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-478
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Expect an output like the one shown here:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B19825_07_15.png)'
  id: totrans-480
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.15: Viewing a list of topics'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what we see in the preceding output:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: The topics prefixed with `error` are the topics corresponding to dead-letter
    queues.
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will not find any `auditGroup` groups as in the case of RabbitMQ. Since
    events are retained in the topics by Kafka, even after consumers have processed
    them, there is no need for an extra `auditGroup` group.
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To see the partitions in a specific topic, for example, the `products` topic,
    run the following command:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-486
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Expect an output like the one shown here:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text  Description automatically generated](img/B19825_07_16.png)'
  id: totrans-488
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.16: Viewing partitions in the products topic'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
- en: 'To see all the messages in a specific partition, for example, partition `1`
    in the `products` topic, run the following command:'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-491
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Expect an output like the one shown here:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text  Description automatically generated](img/B19825_07_17.png)'
  id: totrans-493
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.17: Viewing all messages in partition 1 in the products topic'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: The output will end with a timeout exception since we stop the command by specifying
    a timeout for the command of `1000` ms.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: 'Bring down the microservice landscape with the following command:'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-497
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Now, we have learned how Spring Cloud Stream can be used to switch a message
    broker from RabbitMQ to Kafka without requiring any changes in the source code.
    It just requires a few changes in the Docker Compose file.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
- en: Let’s move on to the last section of this chapter, learning how to run these
    tests automatically!
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
- en: Running automated tests of the reactive microservice landscape
  id: totrans-500
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To be able to run tests of the reactive microservice landscape automatically
    instead of manually, the automated `test-em-all.bash` test script has been enhanced.
    The most important changes are as follows:'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
- en: 'The script uses the new `health` endpoint to know when the microservice landscape
    is operational, as shown here:'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-503
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: The script has a new `waitForMessageProcessing()` function, which is called
    after the test data is set up. Its purpose is simply to wait for the creation
    of the test data to be completed by the asynchronous create services.
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To use the test script to automatically run the tests with RabbitMQ and Kafka,
    perform the following steps:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the tests using the default Docker Compose file, that is, with RabbitMQ
    without partitions, with the following commands:'
  id: totrans-506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-507
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Run the tests for RabbitMQ with two partitions per topic using the Docker Compose
    `docker-compose-partitions.yml` file with the following commands:'
  id: totrans-508
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-509
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Finally, run the tests with Kafka and two partitions per topic using the Docker
    Compose `docker-compose-kafka.yml` file with the following commands:'
  id: totrans-510
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-511
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: In this section, we have learned how to use the `test-em-all.bash` test script
    to automatically run tests of the reactive microservice landscape, which has been
    configured to use either RabbitMQ or Kafka as its message broker.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-513
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have seen how we can develop reactive microservices!
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
- en: Using Spring WebFlux and Spring WebClient, we can develop non-blocking synchronous
    APIs that can handle incoming HTTP requests and send outgoing HTTP requests without
    blocking any threads. Using Spring Data’s reactive support for MongoDB, we can
    also access MongoDB databases in a non-blocking way, that is, without blocking
    any threads while waiting for responses from the database. Spring WebFlux, Spring
    WebClient, and Spring Data rely on Project Reactor to provide their reactive and
    non-blocking features. When we must use blocking code, for example, when using
    Spring Data for JPA, we can encapsulate the processing of the blocking code by
    scheduling the processing of it in a dedicated thread pool.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
- en: We have also seen how Spring Data Stream can be used to develop event-driven
    asynchronous services that work on both RabbitMQ and Kafka as messaging systems
    without requiring any changes in the code. By doing some configuration, we can
    use features in Spring Cloud Stream such as consumer groups, retries, dead-letter
    queues, and partitions to handle the various challenges of asynchronous messaging.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
- en: We have also learned how to manually and automatically test a system landscape
    consisting of reactive microservices.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
- en: This was the final chapter on how to use fundamental features in Spring Boot
    and Spring Framework.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
- en: Next up is an introduction to Spring Cloud and how it can be used to make our
    services production-ready, scalable, robust, configurable, secure, and resilient!
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-520
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why is it important to know how to develop reactive microservices?
  id: totrans-521
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do you choose between non-blocking synchronous APIs and event-/message-driven
    asynchronous services?
  id: totrans-522
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What makes an event different from a message?
  id: totrans-523
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name some challenges with message-driven asynchronous services. How do we handle
    them?
  id: totrans-524
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is the following test not failing?
  id: totrans-525
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-526
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: First, ensure that the test fails. Next, correct the test so that it succeeds.
  id: totrans-527
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: What are the challenges of writing tests with reactive code using JUnit, and
    how can we handle them?
  id: totrans-528
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
