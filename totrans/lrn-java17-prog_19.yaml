- en: '*Chapter 16*: Java Microbenchmark Harness'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will learn about a **Java Microbenchmark Harness** (**JMH**)
    project that allows measuring various code performance characteristics. If performance
    is an important issue for your application, this tool can help you to identify
    bottlenecks with precision—up to the method level.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to theoretical knowledge, you will have a chance to run JMH using practical
    demo examples and recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: What is JMH?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a JMH benchmark
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running the benchmark
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the IDE plugin
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JMH benchmark parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JMH usage examples
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of the chapter, you will be able to not only measure the average
    execution time of an application and other performance values (such as throughput,
    for example) but also to do it in a controlled manner—with or without the JVM optimizations,
    warm-up runs, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To be able to execute the code examples provided in this chapter, you will
    need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A computer with a Microsoft Windows, Apple macOS, or Linux operating system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Java SE version 17 or later
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The IDE or code editor you prefer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The instructions for how to set up a Java SE and IntelliJ IDEA editor were provided
    in [*Chapter 1*](B18388_01_ePub.xhtml#_idTextAnchor015), *Getting Started with
    Java 17*. The files with the code examples for this chapter are available on GitHub
    in the [https://github.com/PacktPublishing/Learn-Java-17-Programming.git](https://github.com/PacktPublishing/Learn-Java-17-Programming.git)
    repository in the `examples/src/main/java/com/packt/learnjava/ch16_microbenchmark`
    folder.
  prefs: []
  type: TYPE_NORMAL
- en: What is JMH?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: According to the Oxford English Dictionary, a **benchmark** is *a standard or
    point of reference against which things may be compared or assessed*. In programming, it
    is the way to compare the performance of applications, or just methods. The **micro
    preface** is focused on the latter—smaller code fragments rather than an application
    as a whole. JMH is a framework for measuring the performance of a single method.
  prefs: []
  type: TYPE_NORMAL
- en: That may appear to be very useful. Can we not just run a method 1,000 or 100,000
    times in a loop, measure how long it took, and then calculate the average of the
    method’s performance? We can. The problem is that JVM is a much more complicated
    program than just a code-executing machine. It has optimization algorithms focused
    on making the application code run as fast as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let’s look at the following class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We filled the `someMethod()` method with code that does not make much sense but
    keeps the method busy. To test the performance of this method, it is tempting
    to copy the code into a test method and run it in a loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: However, JVM will see that the `res` result is never used and qualify the calculations
    as **dead code** (a code section that is never executed). So, why bother executing
    this code at all?
  prefs: []
  type: TYPE_NORMAL
- en: You may be surprised to see that the significant complication or simplification of
    the algorithm does not affect the performance. That is because, in every case,
    the code is not actually executed.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may change the test method and pretend that the result is used by returning
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: This may convince JVM to execute the code every time, but it is not guaranteed.
    JVM may notice that the input into the calculations does not change and this algorithm produces
    the same result every run. Since the code is based on constant input, this optimization is
    called **constant folding**. The result of this optimization is that this code
    may be executed only once and the same result is assumed for every run, without
    actually executing the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'In practice though, the benchmark is often built around a method, not a block
    of code. For example, the test code may look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: But even this code is susceptible to the same JVM optimization we have just
    described.
  prefs: []
  type: TYPE_NORMAL
- en: JMH was created to help to avoid this and similar pitfalls. In the *JMH usage
    examples* section, we will show you how to use JMH to work around the dead code
    and constant folding optimization, using the `@State` annotation and the `Blackhole` object.
  prefs: []
  type: TYPE_NORMAL
- en: Besides, JMH allows for measuring not only average execution time but also throughput
    and other performance characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a JMH benchmark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To start using JMH, the following dependencies have to be added to the `pom.xml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The name of the second `.jar` file, `annprocess`, provides a hint that JMH
    uses annotations. If you guessed so, you were correct. Here is an example of a
    benchmark created for testing the performance of an algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Please notice the `@Benchmark` annotation. It tells the framework that this
    method’s performance has to be measured. If you run the preceding `main()` method,
    you will see an output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_16.1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This is only one segment of an extensive output that includes multiple iterations
    under different conditions with the goal being to avoid or offset the JVM optimization.
    It also takes into account the difference between running the code once and running
    it multiple times. In the latter case, JVM starts using the just-in-time compiler,
    which compiles the often-used bytecodes’ code into native binary code and does
    not even read the bytecodes. The warm-up cycles serve this purpose—the code is
    executed without measuring its performance as a dry run that *warms up* the JVM.
  prefs: []
  type: TYPE_NORMAL
- en: There are also ways to tell the JVM which method to compile and use as binary
    directly, which method to compile every time, and to provide similar instructions
    to disable certain optimization. We will talk about this shortly.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now see how to run the benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: Running the benchmark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you have probably guessed, one way to run a benchmark is just to execute
    the `main()` method. It can be done using the `java` command directly or using
    the IDE. We talked about it in [*Chapter 1*](B18388_01_ePub.xhtml#_idTextAnchor015), *Getting
    Started with Java 17*. Yet there is an easier and more convenient way to run a
    benchmark: by using an IDE plugin.'
  prefs: []
  type: TYPE_NORMAL
- en: Using an IDE plugin
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All major Java-supporting IDEs have such a plugin. We will demonstrate how to
    use the plugin for IntelliJ installed on a macOS computer, but it is equally applicable
    to Windows systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the steps to follow:'
  prefs: []
  type: TYPE_NORMAL
- en: To start installing the plugin, press the *command* key and comma (*,*) together,
    or just click the wrench symbol (with the hover text **Preferences**) in the top
    horizontal menu:![](img/B18388_Figure_16.2.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'It will open a window with the following menu in the left pane:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_16.3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Select **Plugins**, as shown in the preceding screenshot, and observe the window
    with the following top horizontal menu:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_16.4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Select `JMH` in the **Search plugins in marketplace** input field, and press *Enter*.
    If you have an internet connection, it will show you a **JMH plugin** symbol,
    similar to the one shown in the following screenshot:![](img/B18388_Figure_16.5.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click the **Install** button and then, after it turns into **Restart IDE**, click
    it again:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_16.6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After the IDE restarts, the plugin is ready to be used. Now you can not only
    run the `main()` method but you can also pick and choose which of the benchmark
    methods to execute if you have several methods with the `@Benchmark` annotation.
    To do this, select **Run...** from the **Run** drop-down menu:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_16.7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'It will bring up a window with a selection of methods you can run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_16.8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Select the one you would like to run and it will be executed. After you have run
    a method at least once, you can just right-click on it and execute it from the
    pop-up menu:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_16.9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You can also use the shortcuts shown to the right of each menu item.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now let’s review the parameters that can be passed to the benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: JMH benchmark parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many benchmark parameters that allow for fine-tuning the measurements for
    the particular needs of the task at hand. We are going to present only the major
    ones.
  prefs: []
  type: TYPE_NORMAL
- en: Mode
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first set of parameters defines the performance aspect (mode) the particular
    benchmark has to measure:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Mode.AverageTime`: Measures the average execution time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Mode.Throughput`: Measures the throughput by calling the benchmark method
    in an iteration'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Mode.SampleTime`: Samples the execution time, instead of averaging it; allows
    us to infer the distributions, percentiles, and so on'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Mode.SingleShotTime`: Measures the single method invocation time; allows for
    the testing of a cold startup without calling the benchmark method continuously'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These parameters can be specified in the annotation `@BenchmarkMode`, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'It is possible to combine several modes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'It is also possible to request all of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: The described parameters and all the parameters we are going to discuss later
    in this chapter can be set at the method and/or class level. The method-level
    set value overrides the class-level value.
  prefs: []
  type: TYPE_NORMAL
- en: Output time unit
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The unit of time used for presenting the results can be specified using the `@OutputTimeUnit` annotation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: The possible time units come from the `java.util.concurrent.TimeUnit` enum.
  prefs: []
  type: TYPE_NORMAL
- en: Iterations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another group of parameters defines the iterations used for the warm-ups and
    measurements, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: Forking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While running several tests, the `@Fork` annotation allows you to set each
    test to be run in a separate process, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: The passed-in parameter value indicates how many times the JVM can be forked into
    independent processes. The default value is `-1`. Without it, the test’s performance
    can be mixed if you use several classes implementing the same interface in tests and
    they affect each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `warmups` parameter is another one that can be set to indicate how many
    times the benchmark has to execute without collecting measurements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'It also allows you to add Java options to the java command line, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: The full list of JMH parameters and examples of how to use them can be found
    in the `openjdk` project ([http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples](http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples)).
    For example, we did not mention `@Group`, `@GroupThreads`, `@Measurement`, `@Setup`, `@Threads`, `@Timeout`, `@TearDown`,
    or `@Warmup`.
  prefs: []
  type: TYPE_NORMAL
- en: JMH usage examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s now run a few tests and compare them. First, we run the following test
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, we have requested to measure all the performance characteristics
    and to use nanoseconds while presenting the results. On our system, the test execution
    took around 20 minutes and the final result summary looked like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_16.10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let’s now change the test as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run the `testTheMethod1()` now, the results will be slightly different:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_16.11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The results are mostly different around sampling and single-shot running. You
    can play with these methods and change the forking and number of warm-ups.
  prefs: []
  type: TYPE_NORMAL
- en: Using the @State annotation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This JMH feature allows you to hide the source of the data from JVM, thus preventing
    dead code optimization. You can add a class as the source of the input data as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: The `Scope` value is used for sharing data between tests. In our case, with
    only one test using the `TestCase` class object, we do not have a need for sharing.
    Otherwise, the value can be set to `Scope.Group` or `Scope.Benchmark`, which means
    we could add setters to the `TestState` class and read/modify it in other tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we ran this version of the test, we got the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_16.12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The data has changed again. Notice that the average time for execution has increased
    three-fold, which indicates that more JVM optimization was not applied.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Blackhole object
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This JMH feature allows for simulating result usage, thus preventing JVM from
    implementing folding constants optimization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we have just added a parameter `Blackhole` object and called
    the `consume()` method on it, thus pretending that the result of the tested method
    is used.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we ran this version of the test, we got the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_16.13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This time, the results look not that different. Apparently, the constant folding
    optimization was neutralized even before the `Blackhole` usage was added.
  prefs: []
  type: TYPE_NORMAL
- en: Using the @CompilerControl annotation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another way to tune up the benchmark is to tell the compiler to compile, inline
    (or not), and exclude (or not) a particular method from the code. For example,
    consider the following class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: 'Assuming we are interested in how the method `anotherMethod()` compilation/inlining
    affects the performance, we can set the `CompilerControl` mode on it to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Mode.INLINE`: To force method inlining'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Mode.DONT_INLINE`: To avoid method inlining'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Mode.EXCLUDE`: To avoid method compiling'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the @Param annotation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes, it is necessary to run the same benchmark for a different set of
    input data. In such a case, the `@Param` annotation is very useful.
  prefs: []
  type: TYPE_NORMAL
- en: '`@Param` is a standard Java annotation used by various frameworks, for example,
    JUnit. It identifies an array of parameter values. The test with the `@Param` annotation
    will be run as many times as there are values in the array. Each test execution
    picks up a different value from the array.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE156]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE157]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE158]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE159]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE160]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE161]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE162]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE163]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE164]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE165]'
  prefs: []
  type: TYPE_PRE
- en: The `testTheMethod6()` benchmark is going to be used with each of the listed
    values of the parameter `m`.
  prefs: []
  type: TYPE_NORMAL
- en: A word of caution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The described harness takes away most of the worries of the programmer who
    measures the performance. And yet, it is virtually impossible to cover all the
    cases of JVM optimization, profile sharing, and similar aspects of JVM implementation,
    especially if we take into account that JVM code evolves and differs from one
    implementation to another. The authors of JMH acknowledge this fact by printing
    the following warning along with the test results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18388_Figure_16.14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The description of the profilers and their usage can be found in the `openjdk` project
    ([http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples](http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples)).
    Among the same samples, you will encounter a description of the code generated
    by JMH, based on the annotations.
  prefs: []
  type: TYPE_NORMAL
- en: If you would like to get really deep into the details of your code execution
    and testing, there is no better way to do it than to study the generated code.
    It describes all the steps and decisions JMH makes in order to run the requested
    benchmark. You can find the generated code in `target/generated-sources/annotations`.
  prefs: []
  type: TYPE_NORMAL
- en: The scope of this book does not allow for going into too many details on how
    to read it, but it is not very difficult, especially if you start with a simple
    case of testing one method only. We wish you all the best in this endeavor.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you have learned about the JMH tool and were able to use it
    for your applications. You have learned how to create and run a benchmark, how
    to set the benchmark parameters, and how to install IDE plugins if needed. We
    have also provided practical recommendations and references for further reading.
  prefs: []
  type: TYPE_NORMAL
- en: Now you are able to not only measure the average execution time of an application
    and other performance values (such as throughput, for example) but to do it in
    a controlled manner—with or without JVM optimizations, warm-up runs, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn useful practices for designing and writing
    application code. We will talk about Java idioms, their implementation and usage,
    and provide recommendations for implementing `equals()`, `hashCode()`, `compareTo()`,
    and `clone()` methods. We will also discuss the difference between the usage of
    the `StringBuffer` and `StringBuilder` classes, how to catch exceptions, best
    design practices, and other proven programming practices.
  prefs: []
  type: TYPE_NORMAL
- en: Quiz
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Select all the correct statements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: JMH is useless since it runs methods outside the production context.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: JMH is able to work around some JVM optimizations.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: JMH allows for measuring not only average performance time but other performance
    characteristics too.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: JMH can be used to measure the performance of small applications too.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Name two steps necessary to start using JMH.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name four ways JMH can be run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name two modes (performance characteristics) that can be used (measured) with
    JMH.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name two of the time units that can be used to present JMH test results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can data (results, state) be shared between JMH benchmarks?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do you tell JMH to run the benchmark for the parameter with the enumerated
    list of values?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can the compilation of a method be forced or turned off?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can the JVM's constant folding optimization be turned off?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can Java command options be provided programmatically for running a particular
    benchmark?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
