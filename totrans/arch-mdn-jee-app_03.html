<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Implementing Modern Java Enterprise Applications</h1>
                </header>
            
            <article>
                
<p>Now after we saw what components are contained in projects and modules and how to find and construct reasonably sized modules and packages, let's get more down to earth and discuss the topic of Java EE. It certainly makes sense to think about the business concerns first and follow the practices of Domain-Driven Design to identify bounded context and modules with all the contents of our domain.</p>
<p>Let's see how to realize the identified business modules and use cases.</p>
<p>This chapter will cover:</p>
<ul>
<li>How to implement application use case boundaries</li>
<li>What the Java EE core domain components are</li>
<li>Design patterns and Domain-Driven Design with Java EE</li>
<li>Application communication</li>
<li>How to integrate persistence</li>
<li>Technical cross-cutting concerns and asynchronous behavior</li>
<li>Concepts and principles of Java EE</li>
<li>How to achieve maintainable code</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Use case boundaries</h1>
                </header>
            
            <article>
                
<p>Organizing packages after domain concerns leads us to an architectural structure, where the actual business, rather than technical details are reflected.</p>
<p>The business use cases handle all logic required to fulfill the business purpose, using all our module contents. They act as a starting point into the application's domain. The use cases are exposed and invoked via the system boundaries. The enterprise systems offers communication interfaces to the outside world, mostly via web services or web-based frontends, that invoke the business functionalities.</p>
<p>When starting a new project, it makes sense to start with the domain logic first, indifferent to system boundaries or any technical implementation details. This contains constructing all contents of the domain, designing types, dependencies and responsibilities, and prototyping these into code. As we will see in this chapter, the actual domain logic is implemented primarily in plain Java. The initial model can be self-sufficient and tested solely using code level tests. After a sufficiently matured domain model has been found, we target the remaining technical concerns that are outside of the domain module, such as accessing databases or external systems, as well as system endpoints.</p>
<p>In a Java EE application, a boundary is implemented using managed beans, that is, <strong>Enterprise JavaBeans</strong> (<strong>EJB</strong>) or <strong>Contexts and Dependency Injection for Java</strong> (<strong>CDI</strong>) managed beans. The topic <em>EJB and CDI - differenciation and integration</em> will show the differences and significance of these technologies.</p>
<p>Depending on the complexity of the individual use cases, we introduce <em>delegates</em> which are realized as CDI managed beans or EJBs, as well, depending on the requirements. These delegates reside in the control package. Entities are realized as POJOs, optionally annotated to integrate technical functionality such as specifying the database mapping or serialization.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Core domain components of modern Java EE</h1>
                </header>
            
            <article>
                
<p>Plain Java together with CDI and EJB form the core domain components of a modern Java EE application. Why is it called core domain? As mentioned, we want to pay attention to the actual business. There are aspects, components, and functionality that serve the business purpose at their core, whereas others just <em>support</em>, make the business domain accessible, or fulfill other technical requirements.</p>
<p>Java EE ships with many APIs that support realizing dozens of technical requirements. Most of them are technically motivated though. The biggest advantage of the Java EE platform, however, is that clean Java business logic can be implemented with minimal code impact of the technology. The APIs required for that are mainly CDI and EJB. Other APIs, that are required for technical motivations, such as JPA, JAX-RS, JSON-P, and many others, are introduced with a secondary priority.</p>
<p>Managed beans, no matter whether CDI or EJB, are implemented as annotated Java classes, without any technical super classes or interfaces required. In the past, this was called the no-interface view. Nowadays this is the default case. Extending classes obscure the picture on the domain and also come with other shortcomings when it comes to testability. A modern framework integrates itself as simply and as lean as possible.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">EJB and CDI - differentiation and integration</h1>
                </header>
            
            <article>
                
<p>Now the question is, whether to use EJBs or CDI managed beans.</p>
<p>In general, EJBs ship more functionality that is already usable out of the box. CDI managed beans offer a somewhat lighter alternative. What are the main differences between these technologies and how does it affect the developer's work?</p>
<p>The first difference are the scopes. EJB session beans are either stateless, that is, active during the duration of the client request, stateful, that is, active during the lifespan of a client's HTTP session, or singletons. CDI managed beans come with similar scopes plus more possibilities, such as adding custom scopes and the default dependent scope which is active depending on the lifespan of its injection point. The topic <em>Scopes</em> will handle bean scopes more detailed.</p>
<p>Another difference between EJBs and CDI beans is that EJBs implicitly comprise certain cross-cutting concerns, such as monitoring, transactions, exception handling, and managing concurrency for singleton beans. For example, calling an EJB business method implicitly starts a technical transaction, which is active during the method execution and which integrates datasources or external systems.</p>
<p>Also, stateless EJBs are pooled after usage. This means that after a stateless session bean's business method has been invoked, the bean instance can and will be reused from the container. Due to this fact, EJBs perform a little better than CDI beans, which are instantiated every time their scope requires it.</p>
<p>Practically, the technical differences don't impact the developer's work too much. Besides using different annotations, both technologies can be used in the same look and feel. The direction of Java EE moves toward a more open choice of these two; for instance, since Java EE 8 it's possible to handle asynchronous events solely with CDI, not just EJB.</p>
<p>The integration of functionality that CDI provides is, however, one of the biggest features of the Java EE APIs. Just alone dependency injection, CDI producers, and events are effective means to tackle various situations.</p>
<p>The single most used CDI feature is dependency injection using the <kbd>@Inject</kbd> annotation. The injection is built in such a way that no matter which Java EE technology manages the beans, it <em>just works</em> for developers. You can mix and match CDI beans and EJBs with all scopes; the framework will take care of which beans are instantiated or used in which scope, respectively. This enables a flexible usage, such as cases when beans with a shorter scope are injected into longer scoped beans; for example, when a session scoped bean is injected into a singleton.</p>
<p>This feature supports the business domain in such a way that boundaries and controls can just inject required dependencies without worrying about instantiating or managing them.</p>
<p>The following code demonstrates how a boundary implemented as stateless session bean injects the required controls.</p>
<pre>import javax.ejb.Stateless;
import javax.inject.Inject;

@Stateless
public class CarManufacturer {

    <strong>@Inject
    CarFactory carFactory;</strong>

    <strong>@Inject
    CarStorage carStorage;</strong>

    public Car manufactureCar(Specification spec) {
        Car car = carFactory.createCar(spec);
        carStorage.store(car);
        return car;
    }
}</pre>
<p>The <kbd>CarManufacturer</kbd> class represents a stateless EJB. The injected <kbd>CarFactory</kbd> and <kbd>CarStorage</kbd> beans are realized as dependent scoped CDI beans that will be instantiated and injected into the EJB. The Java EE platforms simplifies dependency resolution by enabling to use <kbd>@Inject</kbd> to inject any project-specific beans. This was not always the case; In the past, the <kbd>@EJB</kbd> annotation was used to inject EJBs. <kbd>@Inject</kbd> simplifies the usage within Java EE.</p>
<p>Attentive readers may have noticed the field-based injection with package-private Java scopes. Field-based injection has the least impact on the contents of a class - since a custom constructor can be avoided. Package-private visibility enables developers to set and inject dependencies in a test scope. We will cover this topic and potential alternatives in <a href="">Chapter 7</a>, <em>Testing</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">CDI producers</h1>
                </header>
            
            <article>
                
<p>CDI producers are another Java EE feature that is especially helpful to realize factories of all kinds of sorts. The producers, mostly realized as producer methods, provide the object that can be injected in other managed beans. This decouples creation and configuration logic from the usage. Producers are helpful when custom types other than managed bean types need to be injected.</p>
<p>The following shows the definition of a CDI producer method:</p>
<pre>import javax.enterprise.inject.Produces;

public class CarFactoryProducer {

    <strong>@Produces</strong>
    public CarFactory exposeCarFactory() {
        CarFactory factory = new BMWCarFactory();
        // use custom logic
        return factory;
    }
}</pre>
<p>The exposed <kbd>CarFactory</kbd> type can simply be injected using <kbd>@Inject</kbd>, as seen previously in the <kbd>CarManufacturer</kbd> example. CDI invokes the <kbd>exposeCarFactory()</kbd> method once a <kbd>CarFactory</kbd> instance is required and inserts the returned object into the injection point.</p>
<p>These techniques already cover most of the requirements for the core domain logic use cases.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Emitting domain events</h1>
                </header>
            
            <article>
                
<p>CDI provides an eventing feature for cases where business functionality needs to be decoupled even more. Beans can fire event objects, which act as payloads and which are handled in event observers. By emitting and handling CDI events, we decouple the main business logic from side aspects of handling the event. This idea particularly matches use cases, where the business domain already comprises the concept of events. By default, CDI events are handled in a synchronous way; interrupting the execution at the point where they are fired. CDI events can also be handled asynchronously or at specific points in the life cycle of the technical transaction.</p>
<p>The following code demonstrates how to define and fire CDI events as part of a business use case:</p>
<pre>import javax.enterprise.event.Event;

@Stateless
public class CarManufacturer {

    @Inject
    CarFactory carFactory;

    <strong>@Inject
    Event&lt;CarCreated&gt; carCreated;</strong>

    public Car manufactureCar(Specification spec) {
        Car car = carFactory.createCar(spec);
        <strong>carCreated.fire(new CarCreated(spec));</strong>
        return car;
    }
}</pre>
<p>The <kbd>CarCreated</kbd> event is immutable and contains information that is relevant to the domain event, such as the car specification. The event is handled in the <kbd>CreatedCarListener</kbd> class, which resides in the control package:</p>
<pre>import javax.enterprise.event.Observes;

public class CreatedCarListener {

    public void onCarCreated(<strong>@Observes CarCreated event</strong>) {
        Specification spec = event.getSpecification();
        // handle event
    }
}</pre>
<p><span>The listener is therefore decoupled from the main business logic.</span> The CDI container will take care of connecting the event handling functionality and synchronously calling the <kbd>onCarCreated()</kbd> method.</p>
<p>The topic <em>Flow of execution</em>, shows how events can be fired and handled asynchronously or alternatively at specific points in the life cycle of the transaction.</p>
<p>CDI events are a way how to decouple the definition of domain events from handling them. The event handler logic can be changed or enhanced without touching the car manufacturer component.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Scopes</h1>
                </header>
            
            <article>
                
<p>Bean scopes are quite important for the cases when state is kept in the application for longer than the duration of a single request.</p>
<p>If the whole business process can be implemented in a stateless way, by just executing some logic and discarding all state afterwards, scope definitions are pretty straightforward. Stateless session beans with dependent scoped CDI beans already fulfill a lot of these cases.</p>
<p>The EJB singleton scope and the CDI application scope, respectively, are used quite frequently as well. Single instances of a bean type are a straightforward way to store or cache information that have a long lifespan. Besides all the sophisticated caching technology, a singleton containing simple collections or maps with managed concurrency is still the most simple way to design application-specific, volatile stores. Singletons also provide a single point of responsibility for functionality that for some reason needs to be accessed in a restricted way.</p>
<p>The last scope of both EJBs and CDI beans is the session scope, which is bound to the client's HTTP session. Beans of this scope will be active and reused with all their states as long as the user's session is active. However, storing session data in stateful beans introduces the challenge that clients need to reconnect to the same application server again. This is certainly possible but prevents designing stateless applications which are easier to manage. If the application becomes unavailable, all temporary session data is lost as well. In modern enterprise applications, state is typically kept in the database or in caches for optimization purposes. Therefore, session scoped beans aren't used too much anymore.</p>
<p>CDI managed beans come with more built-in scopes, namely the conversation scope or the default dependent scope. There are also possibilities for adding custom scopes for special requirements. However, experience shows that the built-in scopes are usually sufficient for the majority of enterprise applications. The CDI specification provides further information how to extend the platform and develop custom scopes.</p>
<p>As you have seen, we can already achieve a lot with these Java EE core components. Before looking into integration technologies, such as HTTP communication or database access, let's have a closer look into design patterns used in our core domain.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Patterns in Java EE</h1>
                </header>
            
            <article>
                
<p>A lot has been written about design patterns. The most prominent and always recited example is the well-known book <em>Design Patterns</em> by the <em>Gang of Four</em> (GoF). It describes common situations in software design that are solved using specific implementation patterns.</p>
<p>Whereas the design and motivation for specific patterns are still valid today, the actual implementation may have changed, especially in the enterprise area. Besides the well-known design patterns which are applicable for all kind of applications, there are also a lot of enterprise-related patterns that have emerged. In particular, a variety of J2EE-related enterprise patterns came up in the past. Since we are in the age of Java EE 8, not J2EE anymore, there are now easier ways to implement various patterns which tackle specific situations.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Design patterns revisited</h1>
                </header>
            
            <article>
                
<p>The design patterns described in the GoF book are categorized into creational, structural, and behavioral patterns. Each of the patterns describe a typical challenge in software and shows a way to tackle and solve those situations. They represent implementation blueprints and are not dependent on any specific technology. That is why the idea of each of these patterns can be realized without precisely matching the described implementation. In the modern world of Java SE 8 and EE 8, we have more language features available than was the case in the past. I want to show some of the Gang of Four design patterns, their motivations, and how they can be realized in Java EE.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Singleton</h1>
                </header>
            
            <article>
                
<p>The singleton pattern is a well-known pattern or, as some would argue, anti-pattern. Singletons have only one single instance per class within the whole application. The motivation for this pattern is the capability of storing states as well as being able to coordinate actions at a central place. Singletons definitely have their right to exist. If a certain state needs to be shared reliably among several consumers, a single point of entry is definitely the simplest solution.</p>
<p>However, there are some points to be aware of. Having a single point of responsibility also introduces concurrency that needs to be managed. Therefore, singletons need to be thread-safe. That said, we should keep in mind that singletons naturally don't scale, since there's only one instance. The more synchronization we introduce due to the contained data structure, the less our class will scale for concurrent access. However, depending on the use case, this might or might not be a issue.</p>
<p>The GoF book describes a static singleton instance that is managed in the singleton class. In Java EE the concept of singletons is directly built into EJBs with singleton session beans and CDIs with the application scope. These definitions will create one managed bean that is used in all clients.</p>
<p>The following demonstrates an example of a singleton EJB:</p>
<pre>import javax.ejb.Singleton;

<strong>@Singleton</strong>
public class CarStorage {

    private final Map&lt;String, Car&gt; cars = new HashMap&lt;&gt;();

    public void store(Car car) {
        cars.put(car.getId(), car);
    }
}</pre>
<p>There is some difference in whether we implement singletons using EJB singleton sessions beans or CDI application scoped beans.</p>
<p>By default, the container manages the concurrency of EJB singletons. This ensures that only one public business method is executed at a time. The behavior can be changed by providing the <kbd>@Lock</kbd> annotation which declares methods either as write-lock or read-lock, respectively, where the beans acts as a read-write lock. All EJB singleton business methods are implicitly write-locked. <span>The following shows an example of using an EJB with container managed concurrency and lock annotations:</span></p>
<pre style="padding-left: 60px">import javax.ejb.Lock;
import javax.ejb.LockType;

@Singleton
public class CarStorage {

    private final Map&lt;String, Car&gt; cars = new HashMap&lt;&gt;();

    <strong>@Lock</strong>
    public void store(Car car) {
        cars.put(car.getId(), car);
    }

    <strong>@Lock(LockType.READ)</strong>
    public Car retrieve(String id) {
        return cars.get(id);
    }
}</pre>
<p>The concurrency can also switched off using bean managed concurrency. Then the bean will be called concurrently and the implementation itself has to ensure thread-safety. Using a thread-safe data structure, for example, doesn't require the EJB singleton to manage concurrent accesses. The business methods of the EJB instance will then be called in parallel, similarly to CDI application scoped beans:</p>
<pre>import javax.ejb.ConcurrencyManagement;
import javax.ejb.ConcurrencyManagementType;

@Singleton
<strong>@ConcurrencyManagement(ConcurrencyManagementType.BEAN)</strong>
public class CarStorage {

    private final Map&lt;String, Car&gt; cars = <strong>new ConcurrentHashMap&lt;&gt;();</strong>

    public void store(Car car) {
        cars.put(car.getId(), car);
    }

    public Car retrieve(String id) {
        return cars.get(id);
    }
}</pre>
<p><span>CDI application scoped beans don't restrict concurrent access and the implementation always has to deal with concurrency itself.</span></p>
<p>These solutions tackle situations where a singleton is required; for example, a state that needs to be shared in-memory in the whole application.</p>
<p>CDI application scoped beans or EJB singletons with bean managed concurrency and thread-safe data structures provide an application-wide, non-clustered in-memory cache that scale really well. If distribution is not required this is a simplest yet elegant solution.</p>
<p>Another widely used scenario for EJB singletons is the ability to invoke a single process at application startup. By declaring the <kbd>@Startup</kbd> annotation, the bean will be instantiated and prepared at application startup, invoking the <kbd>@PostConstruct</kbd> method. Startup processes can be defined for all EJBs, but using singletons we can realize processes that need to be set up exactly once.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Abstract factory</h1>
                </header>
            
            <article>
                
<p>The GoF abstract factory pattern aims to separate the creation of objects from their usage. Creating complex objects may involve knowledge about certain prerequisites, implementation details, or which implementation class to be used. Factories help us creating these objects without deep knowledge about the internals. Later in this chapter, we will talk about Domain-Driven Design factories, which are closely related to this pattern. The motivations are the same. Abstract factories aim toward having several implementations of an abstract type where the factory itself is also an abstract type. The users of the functionality develop against interfaces, whereas the concrete factory will produce and return the concrete instances.</p>
<p>There may be an abstract <kbd>GermanCarFactory</kbd> with concrete implementations as <kbd>BMWFactory</kbd> and <kbd>PorscheFactory</kbd>. Both car factories may produce some implementation of <kbd>GermanCar</kbd>, be it a <kbd>BMWCar</kbd> or <kbd>PorscheCar</kbd>, respectively. The client that just wants to have some German car won't care about which actual implementation class the factory will use.</p>
<p>In the Java EE world, we already have a powerful functionality that is in fact a factory framework, namely CDI. CDI provides tons of features to create and inject instances of certain types. Whereas the motivations and outcome are the same, the implementation differs in detail. In fact, there are many ways to realize abstract factories, depending on the use case. Let's have a look at a few of them.</p>
<p>A managed bean can inject instances that are concrete or abstract and even parameterized types. If we want to have only one instance in our current bean, we directly inject a <kbd>GermanCar</kbd>:</p>
<pre>@Stateless
public class CarEnthusiast {

    <strong>@Inject
    GermanCar car;</strong>

    ...
}</pre>
<p>Having multiple implementations of the <kbd>GermanCar</kbd> <span>type</span> would lead to a dependency resolving exception at this point since the container cannot know which actual car to inject. To resolve this issue, we can introduce qualifiers that explicitly ask for a specific type. We could use the available <kbd>@Named</kbd> qualifier with defined string values; however, doing so won't introduce typesafety. CDI gives us the possibility to specify our own typesafe qualifiers that will match our use case:</p>
<pre><strong>@BMW</strong>
public class BMWCar implements GermanCar {
    ...
}

<strong>@Porsche</strong>
public class PorscheCar implements GermanCar {
    ...
}</pre>
<p>Qualifiers are custom runtime-retention annotations, themselves annotated with <kbd>@Qualifier</kbd> and typically <kbd>@Documented</kbd>:</p>
<pre>import javax.inject.Qualifier;
import java.lang.annotation.Documented;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;

<strong>@Qualifier
@Documented</strong>
@Retention(RetentionPolicy.RUNTIME)
public @interface BMW {
}</pre>
<p>The qualifiers are specified at the injection point. They qualify the injected type and decouple the injection from the actual type being used:</p>
<pre>@Stateless
public class CarEnthusiast {

    @Inject
    <strong>@BMW</strong>
    GermanCar car;

    ...
}</pre>
<p>Obtaining an instance of <kbd>CarEnthusiast</kbd> will now create and inject a dependent-scoped <kbd>BMWCar</kbd>, since this type matches the injection point.</p>
<p>We could now even define a sub-type of a BMW car, that will be used without changing the injection point. This is realized by <em>specializing</em> the <kbd>BMWCar</kbd> type with a different implementation. The <kbd>ElectricBMWCar</kbd> type sub-classes <kbd>BMWCar</kbd> and specifies the <kbd>@Specializes</kbd> annotation:</p>
<p class="mce-root"/>
<pre>import javax.enterprise.inject.Specializes;

<strong>@Specializes</strong>
public class ElectricBMWCar extends BMWCar {
    ...
}</pre>
<p>Specialized beans inherit the types and qualifiers of their parent type and will be transparently used instead of the parent type. In this example, injecting a <kbd>GermanCar</kbd> with <kbd>@BMW</kbd> qualifier will provide you an instance of <kbd>ElectricBMWCar</kbd>.</p>
<p>However, to be closer to the design pattern described in the book, we could also define a car factory type used to create several cars as desired:</p>
<pre>public interface GermanCarManufacturer {
    GermanCar manufactureCar();
}</pre>
<p>This car factory is implemented with different specifics:</p>
<pre style="padding-left: 30px">@BMW
public class BMWCarManufacturer implements GermanCarManufacturer {

    @Override
    public GermanCar manufactureCar() {
        return new BMWCar();
    }
}

@Porsche
public class PorscheCarManufacturer implements GermanCarManufacturer {

    @Override
    public GermanCar manufactureCar() {
        return new PorscheCar();
    }
}</pre>
<p>Doing so, the client would now inject and use a manufacturer directly to create new German cars:</p>
<pre>@Stateless
public class CarEnthusiast {

    @Inject<strong>
    @BMW
    GermanCarManufacturer carManufacturer;</strong>

    // create German cars
}</pre>
<p>Injecting types that are explicitly defined and qualified, such as our two German cars, provides a lot of flexibility for implementations.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Factory method</h1>
                </header>
            
            <article>
                
<p>To understand the factory method, let's look into another pattern that has similar motivations, but which is realized differently. Factory methods define factories that are implemented as methods on specific types. There is no single class responsible for creating certain instances; rather, the creation becomes the responsibility of the factory method which is defined as part of a domain class.</p>
<p>For example, let's consider a car that uses its recorded trips to generate a driver's logbook. It perfectly makes sense to include a <kbd>createDriverLog()</kbd> method in the car type which returns a logbook value type, since the class itself can provide the logic in a self-sufficient manner. These solutions would be implemented purely in Java without any frameworks or annotations required:</p>
<pre>public class Car {

    ...

    <strong>public LogBook createDriverLog() {
        // create logbook statement
    }</strong>
}</pre>
<p>As we will see later in this chapter, Domain-Driven Design factories don't distinguish between abstract factories and factory methods. They are more directed toward the motivations of the domain. In some cases, it makes sense to encapsulate factories as methods together with other responsibilities of a class. In other cases, where creation logic is that particular, single points of responsibility in form of separate classes are more appropriate. Generally speaking, putting the creation logic into domain types is desirable since it may make use of other functionalities and properties of that domain class.</p>
<p>Let's have a look at CDI producers. Producers are defined as methods or fields that are used dynamically to look up and inject instances of certain types. We have full flexibility of what values a field contains or a method returns, respectively. We can equally specify qualifiers to ensure that the producers don't collide with other potentially produced types. The beans that defines the producer method can also contain further properties that is used in the producer:</p>
<pre>import javax.enterprise.inject.Produces;

public class BMWCarManufacturer {<br/><br/>    ...

    <strong>@Produces</strong>
    @BMW
    public GermanCar manufactureCar() {<br/>        // use properties
        ...
    }
}</pre>
<p>This matches the idea of factory methods implemented as CDI producers.</p>
<p>The scope of the produced instances needs to be considered. As any other CDI managed bean, the producers are by default dependent scoped. The scope defines the life cycle of managed beans and how they are injected. It affects how often the producer method will be invoked. For the default scope, the method is invoked once per injected instance when the calling managed bean is instantiated. Every time the bean that injects the produced value is injected, the producer method will be called. If that bean has a longer lifetime, the producer method won't be invoked again for that duration.</p>
<p>Later in this chapter, we will see more sophisticated usages of CDI producers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Object pool</h1>
                </header>
            
            <article>
                
<p>The object pool design pattern was designed for performance optimization. The motivation behind pools is to avoid to constantly create new instances of required objects and dependencies, by retaining them in a pool of objects for a longer period of time. A required instance is retrieved from this pool of objects and released after usage.</p>
<p>This concept is already built into Java EE containers in different forms. As mentioned earlier, stateless session beans are pooled. This is the reason why they perform exceptionally well. However, developers have to be aware of the fact that instances are being reused; instances must not retain any state after they have been used. The container keeps a pool of these instances.</p>
<p>Another example is the pooling of database connections. Database connections are rather expensive to initiate and it makes sense to keep a few of them alive for later use. Depending on the persistence implementation, these connections are reused once a new query is requested.</p>
<p>Threads are also pooled in enterprise applications. In a Java server environment, a client request typically results in a Java thread that handles the logic. After handling the request, the threads will be reused again. Thread pool configuration as well as having different pools is an important topic for further performance optimization. We will cover this topic in <a href="">Chapter 9</a>, <em>Monitoring, Performance, and Logging</em>.</p>
<p>Developers won't typically implement the object pool pattern themselves. The container already includes this pattern for instances, threads, and databases. The application developer implicitly uses these available features.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Decorator</h1>
                </header>
            
            <article>
                
<p>Another well-known design pattern is the decorator pattern. This pattern allows us to add behavior to an object without affecting other objects of that class. Quite often this behavior is composable with several subtypes.</p>
<p>A good example is food. Everybody has their own preferences in tastes and compositions. Let's take coffee as an example. We can drink just plain black coffee, with milk, with sugar, with both milk and sugar, or even with syrup, cream, or whatever will be popular in the future. And that's not taking into account the different ways of how to brew coffee.</p>
<p>The following shows a realization of the decorator pattern using plain Java.</p>
<p>We specify the following <kbd>Coffee</kbd> <span>type</span> which can be decorated using the sub-type <kbd>CoffeeGarnish</kbd>:</p>
<pre>public interface Coffee {

    double getCaffeine();
    double getCalories();
}

public class CoffeeGarnish implements Coffee {

    private final Coffee coffee;

    protected CoffeeGarnish(Coffee coffee) {
        this.coffee = coffee;
    }

    @Override
    public double getCaffeine() {
        return coffee.getCaffeine();
    }

    @Override
    public double getCalories() {
        return coffee.getCalories();
    }
}</pre>
<p>The default coffee garnish just delegates to its parent coffee. There may be several implementations of a coffee:</p>
<pre>public class BlackCoffee implements Coffee {

    @Override
    public double getCaffeine() {
        return 100.0;
    }

    @Override
    public double getCalories() {
        return 0;
    }
}</pre>
<p>Besides regular black coffee, we also specify some garnishes:</p>
<pre>public class MilkCoffee extends CoffeeGarnish {

    protected MilkCoffee(Coffee coffee) {
        super(coffee);
    }

    @Override
    public double getCalories() {
        return super.getCalories() + 20.0;
    }
}

public class SugarCoffee extends CoffeeGarnish {

    protected SugarCoffee(Coffee coffee) {
        super(coffee);
    }

    @Override
    public double getCalories() {
        return super.getCalories() + 30.0;
    }
}

public class CreamCoffee extends CoffeeGarnish {

    protected CreamCoffee(Coffee coffee) {
        super(coffee);
    }

    @Override
    public double getCalories() {
        return super.getCalories() + 100.0;
    }
}</pre>
<p>Using the coffee types, we can compose our desired coffee with its specific behavior:</p>
<pre>Coffee coffee = new CreamCoffee(new SugarCoffee(new BlackCoffee()));
coffee.getCaffeine(); // 100.0
coffee.getCalories(); // 130.0</pre>
<p>An example for the decorator pattern in the JDK is the <kbd>InputStream</kbd> class with the possibility to add specific behavior for files, byte arrays, and so on.</p>
<p>In Java EE, we again make use of CDI which ships with a decorator functionality. Decorators add specific behavior to a bean. Invocations on an injected bean call the decorator instead of the actual bean; the decorator adds specific behavior and delegates to the bean instance. The original bean type becomes a so-called delegate of the decorator:</p>
<pre>public interface CoffeeMaker {
    void makeCoffee();
}

public class FilterCoffeeMaker implements CoffeeMaker {

    @Override
    public void makeCoffee() {
        // brew coffee
    }
}</pre>
<p>The delegate type must be an interface. The <kbd>CountingCoffeeMaker</kbd> decorates the existing coffee maker functionality:</p>
<pre>import javax.decorator.Decorator;<br/>import javax.decorator.Delegate;<br/>import javax.enterprise.inject.Any;<br/><br/><strong>@Decorator</strong>
public class CountingCoffeeMaker implements CoffeeMaker {

    private static final int MAX_COFFEES = 3;
    private int count;

    <strong>@Inject
    @Any
    @Delegate
    CoffeeMaker coffeeMaker;</strong>

    @Override
    public void makeCoffee() {
        if (count &gt;= MAX_COFFEES)
            throw new IllegalStateException("Reached maximum coffee limit.");
        count++;

        coffeeMaker.makeCoffee();
    }
}</pre>
<p>The decorator functionality is activated via the <kbd>beans.xml</kbd> descriptor.</p>
<pre>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans 
        
        xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee
        http://xmlns.jcp.org/xml/ns/javaee/beans_1_1.xsd"
        bean-discovery-mode="all"&gt;
    <strong>&lt;decorators&gt;
        &lt;class&gt;com.example.coffee.CountingCoffeeMaker&lt;/class&gt;
    &lt;/decorators&gt;</strong>
&lt;/beans&gt;</pre>
<p>After activating the decorator, injected instances of the <kbd>CoffeeMaker</kbd> type use the decorated functionality instead. This happens without changing the original implementation:</p>
<pre>public class CoffeeConsumer {

    @Inject
    CoffeeMaker coffeeMaker;

    ...
}</pre>
<p>Managed beans can have several decorators. If necessary, ordering can be specified on the decorators using the Java EE <kbd>@Priority</kbd> annotation.</p>
<p>This CDI functionality applies to managed beans. Depending on whether we want to add additional behavior to our domain model classes or the services involved, we will use the pattern either with plain Java, as described first, or by using CDI decorators.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Facade</h1>
                </header>
            
            <article>
                
<p>The facade design pattern is used to provide a clean and simple interface to certain functionalities. Encapsulation and abstraction layers are certainly among the most important principles for writing code. We introduce facades which encapsulate complex functionality or legacy components that are cumbersome to use, into simpler interfaces. A facade is therefore a prime example for abstraction.</p>
<p>Let's consider a rather complex setup in a coffee shop. There are grinders, coffee machines, scales, and various tools in use that all need to be configured accordingly:</p>
<pre>public class BaristaCoffeeShop {

    private BeanStore beanStore;
    private Grinder grinder;
    private EspressoMachine espressoMachine;
    private Scale scale;
    private Thermometer thermometer;
    private Hygrometer hygrometer;

    public GroundBeans grindBeans(Beans beans, double weight) { ... }

    public Beans fetchBeans(BeanType type) { ... }

    public double getTemperature() { ... }

    public double getHumidity() { ... }

    public Coffee makeEspresso(GroundBeans beans, Settings settings) { ... }
}</pre>
<p>One could certainly argue that this class already needs refactoring. However, legacy classes may not be changeable easily. We will introduce a barista that acts as a facade:</p>
<pre>@Stateless
public class Barista {

    @Inject
    BaristaCoffeeShop coffeeShop;

    public Coffee makeCoffee() {
        // check temperature &amp; humidity
        // calculate amount of beans &amp; machine settings
        // fetch &amp; grind beans
        // operate espresso machine
    }
}</pre>
<p>In the Java EE world, the most prominent example of facades are boundaries implemented with EJBs. They provide the facade to the business use cases that are part of our business domain. Besides that, facades can be implemented using all kinds of managed beans. Facades delegate and orchestrate complex logic appropriately. Well-chosen abstractions improve the software design and are an aim to strive for.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Proxy</h1>
                </header>
            
            <article>
                
<p>The proxy design pattern is probably the most obvious one that is included in Java EE. Injected bean references contain in almost all cases not a reference to the actual instance, but a proxy. Proxies are thin wrappers around instances that can add certain functionalities. The client doesn't even notice that it interacts with a proxy instead of the actual object.</p>
<p>Proxies enable the cross-cutting functionality which is required in an enterprise environment, such as interceptors, transactions, logging, or monitoring. They are also required to perform dependency injection in the first place.</p>
<p>Application developers typically don't use the proxy pattern directly. However, it is recommended to understand how the proxy pattern works in general and how it's used in the Java EE platform in particular.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Observer</h1>
                </header>
            
            <article>
                
<p>The observer design pattern describes how an object manages and notifies observers in case of change in the overall state. Observers register themselves at the subject and will be notified later on. The notification of observers can happen in a synchronous or asynchronous way.</p>
<p>As seen before, CDI includes an eventing functionality, which implements the observer pattern. Developers do not need to handle the registration and notification logic themselves; they just declare the loose coupling using annotation. As shown in the topic <em>Core domain components of modern Java EE,</em> the <kbd>Event&lt;T&gt;</kbd> type and <kbd>@Observes</kbd> annotations declare the event publishing and observation. In the topic <em>Flow of execution</em>, we will cover asynchronous CDI events.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Strategy</h1>
                </header>
            
            <article>
                
<p>The strategy design pattern is used to dynamically choose an implementation algorithm, a strategy, at runtime. The pattern is used, for example, to select different business algorithms depending on the circumstances.</p>
<p>We have several possibilities to make use of the strategy pattern, depending on the situation. We can define different implementations of an algorithm as separate classes. Java SE 8 includes the functionality of lambda methods and method references that can be used as a lightweight strategy implementation:</p>
<pre>import java.util.function.Function;

public class Greeter {

    <strong>private Function&lt;String, String&gt; strategy;</strong>

    String greet(String name) {
        return <strong>strategy.apply(name)</strong> + ", my name is Duke";
    }

    public static void main(String[] args) {
        Greeter greeter = new Greeter();

        <strong>Function&lt;String, String&gt; formalGreeting = name -&gt; "Dear " + name;
        Function&lt;String, String&gt; informalGreeting = name -&gt; "Hey " + name;</strong>

        greeter.strategy = formalGreeting;
        String greeting = greeter.greet("Java");

        System.out.println(greeting);
    }

}</pre>
<p>The example shows that functional interfaces can be used to dynamically define strategies that are applied and chosen at runtime.</p>
<p>In a Java EE environment, we can again make use of CDI dependency injection. <span>To showcase that CDI supports any Java type, we will use the same example with a strategy that is represented by a functional interface. The greeting strategy is represented by the</span> <kbd>Function</kbd> <span>type:</span></p>
<pre>public class Greeter {

    <strong>@Inject
    Function&lt;String, String&gt; greetingStrategy;</strong>

    public String greet(String name) {
        return <strong>greetingStrategy.apply(name);</strong>
    }
}</pre>
<p>A CDI producer method dynamically selects the greeting strategy:</p>
<pre>public class GreetingStrategyExposer {

    <strong>private Function&lt;String, String&gt; formalGreeting = name -&gt; "Dear " + name;
    private Function&lt;String, String&gt; informalGreeting = name -&gt; "Hey " + name;</strong>

    @Produces
    public <strong>Function&lt;String, String&gt;</strong> exposeStrategy() {
        // select a strategy
        ...
        return strategy;
    }
}</pre>
<p>In order to complete the example, let's introduce specific classes for the algorithm implementations. CDI is able to inject all instances of a certain type that can dynamically be selected.</p>
<p>The <kbd>GreetingStrategy</kbd> type is selectable after daytime appropriateness:</p>
<pre>public interface GreetingStrategy {
    boolean isAppropriate(LocalTime localTime);
    String greet(String name);
}


public class MorningGreetingStrategy implements GreetingStrategy {
    @Override
    public boolean isAppropriate(LocalTime localTime) {
        ...
    }

    @Override
    public String greet(String name) {
        return "Good morning, " + name;
    }
}

public class AfternoonGreetingStrategy implements GreetingStrategy { ... }
public class EveningGreetingStrategy implements GreetingStrategy { ... }</pre>
<p>The CDI producer can inject all possible <kbd>GreetingStrategy</kbd> instances and select based on their specification:</p>
<pre>public class GreetingStrategySelector {

    <strong>@Inject
    @Any
    Instance&lt;GreetingStrategy&gt; strategies;</strong>

    @Produces
    public Function&lt;String, String&gt; exposeStrategy() {
        <strong>for (GreetingStrategy strategy : strategies) {
            if (strategy.isAppropriate(LocalTime.now()))
                return strategy::greet;
        }</strong>
        throw new IllegalStateException("Couldn't find an appropriate greeting");
    }
}</pre>
<p>The <kbd>@Any</kbd> qualifier implicitly exists on any managed bean. Injection points with the <kbd>Instance</kbd> type and this qualifier inject all instances that match the corresponding type, here <kbd>GreetingStrategy</kbd>. The <kbd>Instance</kbd> <span>type</span> allows us to dynamically obtain and qualify instances of a certain type. It implements an iterator over all eligible types.</p>
<p>By providing custom selection logic, we chose an appropriate strategy that is then injected into the greeter.</p>
<p>CDI allows several ways to specify and choose different strategies. Depending on the situation, dependency injection can be used to separate the selection logic from the usage.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further patterns</h1>
                </header>
            
            <article>
                
<p>Besides the mentioned patterns that are implemented with specific Java EE functionalities, there are other design patterns that still are implemented with pure Java, as described in the GoF book. The presented list is certainly not complete, but includes design patterns that are usually being used in enterprise projects.</p>
<p>There are some design patterns that are at the core of Java EE, such as the proxy pattern. Another example is the mediator pattern that encapsulates communication between a set of objects. For example, to design loosely coupled communication, we would not implement this pattern ourselves rather than use API functionality that implements it internally, such as CDI events.</p>
<p>There are many other patterns that aren't used much by the Java EE API, but would be implemented using plain Java. Depending on the actual case, CDI could be used to support the creation and instantiation of objects. Examples for these patterns are prototype, builder, adapter, bridge, composite, flyweight, chain of responsibility, state, and visitor.</p>
<p>Again if we look into the Enterprise API, we will find, for example, the builder pattern being heavily used in the JSON-P API. I refer to the <em>Design Patterns</em> book by the Gang of Four, for further usage and patterns.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Domain-Driven Design</h1>
                </header>
            
            <article>
                
<p>Now we have seen how the GoF design patterns are implemented in the age of Java EE. Besides that, I want to point out some patterns and concepts that are applied in our core domain before continuing to more purely technical concerns. The book <em>Domain-Driven Design</em> by Eric Evans, extensively describes these patterns and concepts that support constructing software models that match the actual business domain as accurately as possible. In particular, the importance of communicating with domain experts, sharing a common, <em>ubiquitous</em> domain language, deeply understanding the underlying domain model, and gradually refactoring it, is pointed out. Domain-Driven Design also introduces certain concepts in the software world, such as repositories, services, factories, or aggregates.</p>
<p>Now the question arises as to whether and how these concepts are realizable with Java Enterprise? Domain-Driven Design always aims to include important aspects of the application directly into the domain model rather than just <em>outside</em> as part of a service or transaction script. We will see how this fact plays well with EJBs or CDI managed beans.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Services</h1>
                </header>
            
            <article>
                
<p>The Domain-Driven Design language defines the concept of a service. Services are responsible for orchestrating various business logic processes. Typically, they are an entry point for use cases and create or manage objects of the domain model. Services hold the single business process steps together.</p>
<p>If you map this concept with the idea and contents of the Entity Control Boundary packaging, you will see that it fulfills the same purpose as boundaries or controls, respectively. In Java EE, these services would therefore be implemented as EJBs or CDI managed beans. Services that represent the entry point of a use case are implemented as boundaries; whereas services that orchestrate further business logic, access databases or external systems represent controls.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Entities</h1>
                </header>
            
            <article>
                
<p>Domain-Driven Design also defines so-called entities. As the name already suggests, an entity represents a business domain entity in essence. These entities are identifiable instances of a concept deeply contained in the specific domain. Users, articles, and cars are examples of such entities. It is important to the domain that the entities can be separately identified. It makes a difference whether user <em>John Doe</em> or user <em>John Smith</em> invoked some use case. This aspect distinguishes entities from value objects.</p>
<p>Entities, as well as other model objects, are implemented as plain Java classes. For the sole business domain to function, there is no framework support required. Ideally, entities already encapsulate certain business logic that is self-contained within the entity type. That means that we will not only model simple POJOs with properties plus getter and setter methods but also business relevant methods that operate on that entity. Integrating business logic directly at the core of the business entities increases cohesion, understanding, and embraces the single responsibility principle.</p>
<p>Typically, entities as well as other domain model types, are persisted in a database. Java EE does support object-relational mapping with JPA which is used to persist and retrieve objects and object hierarchies. In fact, the JPA annotation used to declare entity types is called <kbd>@Entity</kbd>. In a later sub-chapter, we will see in detail how JPA supports to persist domain model types with minimal disruption on the model classes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Value objects</h1>
                </header>
            
            <article>
                
<p>Types of the business domain that do not form identifiable entities but only specific <em>values</em> are called value objects. Value objects are preferably immutable and therefore reusable, since the content can't change. Java enumerations are a good example of this. Any objects where identity doesn't matter will be realized as value objects. For example, for Java enumerations it doesn't matter which instance of <kbd>Status.ACCEPTED</kbd> is returned, here there is even only one enum instance which is used in all places. The same is true for a lot of types in the domain, such as addresses. As long as the value of the address pointing to <em>42 Wallaby Way, Sydney</em> remains the same, it doesn't matter which address instance we refer to.</p>
<p>Depending on whether the set of values is finite, value objects are either modeled as enumerations or POJOs, ideally immutable. Immutability represents the concept of value objects and reduces the probability of potential errors. Changing a mutable object that is shared by multiple locations can lead to unplanned side effects.</p>
<p>As value objects are not identified directly they also won't be persisted and managed directly in a database. They certainly can be persisted indirectly, as part of a graph of objects, referenced from an entity or aggregate. JPA supports managing persistence of objects that are not entities or aggregates.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Aggregates</h1>
                </header>
            
            <article>
                
<p>Aggregates represent a concept in the Domain-Driven Design language, which is sometimes confusing to developers. Aggregates are complex models that consist of several entities or value objects, respectively, which form a whole. For consistency reasons, this conglomerate of objects should be accessed and managed as a whole as well. Accessing methods of some contained objects directly could lead to inconsistencies and potential errors. The idea behind aggregates it to represent a root objects for all operations. A good example is a car consisting of four wheels, an engine, a chassis, and so on. Whenever some operation, such as <em>drive</em> is required, it will be invoked on the whole car, potentially involving several objects at once.</p>
<p>Aggregates are entities that also define the root of an object hierarchy. They are implemented as plain Java classes containing business domain functionality and holding reference onto entities and value objects, respectively.</p>
<p>Therefore, aggregates can be persisted using JPA as well. All persistence operations are invoked on the aggregate, the root object, and cascaded to its contained objects. JPA supports persistence of complex object hierarchies, as we will see in later sub-chapters.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Repositories</h1>
                </header>
            
            <article>
                
<p>Speaking of database access Domain-Driven Design defines repositories that will manage persistence and consistency of entities. The motivation behind repositories was to have a single point of responsibility that enables the domain model to be persistent with consistency in mind. Defining these functionalities should not clutter the domain model code with persistence implementation details. Therefore, Domain-Driven Design defines the concept of repositories which encapsulate these operations in a self-sufficient and consistent way.</p>
<p>The repositories are the entry point for persistence operations for a specific entity type. Since only instances of aggregates and entities need to be identified, only these types require repositories.</p>
<p>In Java EE and JPA, there is already a functionality that matches the idea of repositories well, JPA's <kbd>EntityManager</kbd>. The entity manager is used to persist, retrieve, and manage objects that are defined as entities or potential object hierarchies thereof. The fact that the JPA managed objects need to be identifiable entities perfectly fits the constraints set by the Domain-Driven Design idea of entities.</p>
<p>The entity manager is injected and used in managed beans. This matches the idea that services, either as boundaries or controls, are meant to orchestrate the business use case, here by invoking the entity manager to provide the persistence of the entities.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Factories</h1>
                </header>
            
            <article>
                
<p>The motivation behind Domain-Driven Design factories is that creating domain objects can require logic and constraints that are more complex than just calling a constructor. Creation of consistent domain objects may need to perform validations or complex processes. Therefore, we define the creation logic in specific methods or classes that encapsulate this logic from the rest of the domain.</p>
<p>This is the same motivation behind the abstract factory and factory method design patterns discussed earlier. Therefore, the same realization using CDI features hold true here as well. The CDI specification is in fact a factory functionality.</p>
<p>Domain object factories can also be implemented as methods being part of another domain model class such as an entity. These solutions would be implemented purely in Java without any frameworks or annotations required. The car driver's logbook functionality discussed in the factory method design pattern is a good example for a factory method being included in a domain entity. If the domain class itself can provide the logic in a self-sufficient manner it perfectly makes sense to include the factory logic there as well.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Domain event</h1>
                </header>
            
            <article>
                
<p>Domain events represent events that are relevant to the business domain. They usually emerge from business use cases and have specific domain semantics. Examples for domain events are <kbd>UserLoggedIn</kbd>, <kbd>ActiclePurchased</kbd>, or <kbd>CoffeeBrewFinished</kbd>.</p>
<p>Domain events are typically implemented as value objects containing the required information. In Java, we realize events as immutable POJOs. Events happened in the past and can't be changed later on, so it is highly recommended to make them immutable. As seen before, we can use the CDI events functionality to publish and observe events with loose coupling. In CDI, all Java types can be used to be published as events. The concept of domain events is therefore a business definition rather than a technical one.</p>
<p>Domain events are particularly important for event sourcing and event-driven architectures, which we will extensively discuss in <a href="">Chapter 8</a>, <em>Microservices and System Architecture</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">External and cross-cutting concerns in enterprise applications</h1>
                </header>
            
            <article>
                
<p>Now we have seen the concepts and implementations necessary to realize domain logic in our application. In theory it's already sufficient to implement standalone business logic; however, the use cases won't provide much value to the customer if they can't be accessed from outside of the system.</p>
<p>Therefore, let's have a look at technically motivated external and cross-cutting concerns. These are functionalities that are not at the core of the business domain, but that need to be fulfilled as well. Examples for technically motivated concerns are accessing external systems or databases, configuring the application, or caching.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Communication with external systems</h1>
                </header>
            
            <article>
                
<p><span>Communicating to the outside world is o</span>ne of the most important technical aspects of an enterprise application. Without that communication, the application will hardly bring any value to the customer.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to choose communication technology</h1>
                </header>
            
            <article>
                
<p>When enterprise systems require communication, the question of which communication protocols and technologies to use arises. There are many forms of synchronous and asynchronous communications to choose from. There are some considerations to make upfront.</p>
<p>Which communication technology is supported by the chosen languages and frameworks? Are there any existing systems that require a certain form of communication? Do the systems exchange information in a synchronous or asynchronous way? What solution is the team of engineers familiar with? Does the system reside in an environment where high performance is crucial?</p>
<p>Looking from a business perspective again, communication between systems is necessary and should not <em>get in the way</em> of implementing a business use case. That said, exchanging information should at first be implemented in a straightforward way, matching the specific domain, regardless of whether the communication is performed synchronously or asynchronously. These considerations have a big impact not only on the actual implementation, but also as to whether the whole use case matches the chosen solution. Therefore, this is one of the first questions to be asked, whether the communication happens in a synchronous or asynchronous way. Synchronous communication ensures consistency and ordering of the exchanged information. However, it also comes with less performance compared to asynchronous calls and will not scale infinitely. Asynchronous communication leads to looser coupling of the systems involved, increases the overall performance as well as overhead and enables scenarios where systems are not reliably available all the time. For reasons of simplicity enterprise applications typically use synchronous communication, and also in regard to consistency.</p>
<p>The chosen way of communication needs to be supported not only by the language and frameworks, but also the environments and tools being used. Does the environment and network setup make any constraints on the communication? In fact, this was one of the reasons why the SOAP protocol was widely chosen in the past; being able to be transmitted over network port <kbd>80</kbd>, which was permitted by the majority of network configurations. Tool support, especially during development and for debugging purposes is another important aspect. This is the reason why HTTP in general is widely used.</p>
<p>In the Java world, arguably most of the communication solutions out there are supported, either natively, such as HTTP, or by third-party libraries. This is certainly not the case with other technologies. This was, for example, one of the issues with the SOAP protocol. Implementation of the SOAP protocol was effectively only seen in Java and .NET applications. Other technologies typically chose different forms of communication.</p>
<p>Performance of the communication technology is an issue to consider, not only in high performance environments. Exchanging information over the network always introduces a huge overhead compared to both inter- or intra-process communication. The question is how big that overhead is. This essentially regards the density of information and the performance of processing messages or payloads. Is the information exchanged in a binary or plain text format? Which format does the content type represent? Generally speaking, binary formats with high information density and low verbosity perform better and transmit less data sizes, but are also harder to debug and comprehend.</p>
<p>Another important aspect is the flexibility of the communication solution. The chosen technology should not constrain the exchange of information too much. Ideally, the protocol supports different ways of communicating; for example, both synchronous and asynchronous communication, binary formats, or Hypermedia. Since our application's main concerns is the business logic, the chosen technology can ideally adapt to the overall requirements.</p>
<p>In today's systems, the communication protocol with the greatest usage is HTTP. There are several reasons for this. HTTP is well supported by all kinds of language platforms, frameworks, and libraries. The variety of tool choices is extremely high and the protocol is well known to most software engineers. HTTP does not make many constraints on how it is used and can therefore be applied to all kinds of information exchange. It can be used to realize both synchronous or asynchronous communication, Hypermedia, or straightforward invocations of remote functionality, such as remote procedure calls. However, HTTP does encourage certain usage. We will discuss semantic HTTP, remote procedure calls and REST in the next topic.</p>
<p>There are communication protocols that are, not necessarily, but typically, built on top of HTTP. The most prominent example from the past was SOAP; a more recent example is gRPC. Both protocols implement a remote procedure call approach. Remote procedure calls represent a straightforward form of calling a function of another system over the wire. The function needs to be specified with input and output values. SOAP realized these remote procedure calls in the XML format whereas gRPC uses binary protocol buffers to serialize data structures.</p>
<p>Depending on what the business requirements are in terms of synchronous or asynchronous behavior of the communication, it is highly recommended to implement the behavior consistently. In general, you should avoid mixing synchronous or asynchronous behavior. Wrapping services that contain asynchronous logic in a synchronous way doesn't make sense. The caller will be blocked until the asynchronous process is completed and the whole functionality will not scale. On the contrary, it sometimes makes sense to use asynchronous communication in order to encapsulate long-running synchronous processes. This includes external systems which cannot be changed or legacy applications. The client component will connect to the system in a separate thread, allowing the calling thread to continue immediately. The client thread either blocks until the synchronous process has finished or makes use of polling. However, it is preferred to model the systems and the style of communication after what makes sense for the business requirements.</p>
<p>There are quite a few protocols and formats of communications to choose from, a lot of them are proprietary. It is advisable for engineers to be aware of the different concepts and ways of communicating in general. Communication technology changes but the principles of exchanging data are timeless. As of writing this book, HTTP is the most widespread communication protocol being used. This is arguably one of the most important technologies to implement, it is well-understood, and has a great tooling support.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Synchronous HTTP communication</h1>
                </header>
            
            <article>
                
<p>Most of today's synchronous communication within enterprise systems is realized via HTTP. Enterprise applications expose HTTP endpoints that are accessed by the clients. These endpoints are typically in the form of web services or web frontends as HTML over HTTP.</p>
<p>Web services can be designed and specified in various ways. In the simplest form, we just want to call a function of another system over the wire. That function needs to be specified with input and output values. These functions or <strong>remote procedure calls</strong> (<strong>RPC</strong>) are in this case realized over HTTP, typically using an XML format that specifies the parameter arguments. In the age of J2EE, these types of web services were pretty common. The most prominent example for this was the SOAP protocol which is implemented with the JAX-WS standard. However, the SOAP protocol and its XML format was quite cumbersome to use and not well supported by other languages other than Java and .NET.</p>
<p>In today's system, the REST architectural style with its concept and constraints is used far more often.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Representational State Transfer</h1>
                </header>
            
            <article>
                
<p>The ideas and constraints of <strong>Representational State Transfer</strong> (<strong>REST</strong>), as initiated by Roy T. Fielding, provide an architectural style of web services that in many ways suit the needs of enterprise applications better. The ideas lead to systems that are coupled more loosely with interfaces that are accessed from various clients in a uniform and straightforward way.</p>
<p>The REST constraint of a <em>uniform interface</em> requires the resources to be identified in requests using the URI in web-based systems. The resources represent our domain entities; for example, users or articles which are individually identified by URLs of the enterprise application. That said, the URLs no longer represent RPC methods, but actual domain entities. These representations are modified in a uniform way, in HTTP using the HTTP methods such as GET, POST, DELETE, PATCH, or PUT. The entities may be represented in different formats that are requested by the client, such as XML or JSON. If supported by the server, clients are free to choose whether they access the specific user in its XML or JSON representation.</p>
<p>Another aspect of the uniform interface constraint is to make use of Hypermedia as the engine of the application state. Hypermedia means linking resources that are related together using hyperlinks. REST resources that are transferred to the client can include links to other resources with semantic link relations. If some user includes information about their manager, that information can be serialized using a link to the resource of the second user, the manager.</p>
<p>The following shows an example for a book representation with Hypermedia links included in a JSON response:</p>
<pre style="padding-left: 30px">{
     "name": "Java",
     "author": "Duke",
     "isbn": "123-2-34-456789-0",
     "_links": {
         "self": "https://api.example.com/books/12345",
         "author": "https://api.example.com/authors/2345",
         "related-books": "https://api.example.com/books/12345/related"
    }
}</pre>
<p>In websites designed for humans, these links are one of the main aspects. In a Hypermedia API, these links are used by the REST clients to navigate through the API. The concept of discoverability decreases coupling and increases evolvability of the systems involved. If this concept is fully embraced, clients only need to know an entry point of the API and discover the available resources using semantic link relations, such as <kbd>related-books</kbd>. They will follow the known relations using the provided URLs.</p>
<p>In most REST APIs, it's not sufficient for clients to only follow links and fetch resource representation using the HTTP GET method. Information is exchanged using HTTP methods that change state such as POST or PUT and request bodies which contain the payload. Hypermedia supports these so-called actions as well, using Hypermedia controls. Actions describe not only the target URL, but also the HTTP method and required information to send.</p>
<p>The following demonstrates a more sophisticated Hypermedia example using the concept of actions. This example shows the Siren content type and is meant to give you an idea of potential contents of Hypermedia responses:</p>
<pre>{
    "class": [ "book" ],
    "<strong>properties</strong>": {
        "isbn": "123-2-34-456789-0",
        "name": "Java",
        "author": "Duke",
        "availability": "IN_STOCK",
        "price": 29.99
    }
    "<strong>actions</strong>": [
        {
            "name": "add-to-cart",
            "title": "Add Book to cart",
            "method": "POST",
            "href": "http://api.example.com/shopping-cart",
            "type": "application/json",
            "fields": [
                { "name": "isbn", "type": "text" },
                { "name": "quantity", "type": "number" }
            ]
        }
    ],
    "<strong>links</strong>": [
        { "rel": [ "self" ], "href": "http://api.example.com/books/1234" }
    ]
}</pre>
<p>This is one example of a content type that enables Hypermedia controls. At the time of writing this book, none of the hypermedia-enabled content type such as Siren, HAL, or JSON-LD has emerged as a standard or de facto standard yet. However, this Siren content type should sufficiently communicate the concepts of links and actions.</p>
<p>Using Hypermedia decouples the client from the server. First of all, the responsibility of URLs solely reside on the server side. Clients cannot make any assumption how the URLs are created; for example, that the book resource resides under <kbd>/books/1234</kbd>, which is constructed from the path <kbd>/books/</kbd> plus the book ID. We have seen many of these assumption that duplicate URL logic into the clients in real-world projects.</p>
<p>The next aspect that is decoupled is how state is changed on the server. For example, the instruction that clients need to POST a JSON content type to <kbd>/shopping-cart</kbd> with a certain JSON structure is no longer baked into the client, but retrieved dynamically. The client will only refer to the Hypermedia action using its relation or name, here <kbd>add-to-cart</kbd>, and the information provided in the action. By using this approach, the client only needs to know the business meaning of the <em>add-to-cart</em> action and the origin of the required ISBN and quantity field. This is certainly client logic. The field values could be retrieved from the resource representation itself or from a client process. For example, the quantity of books could be presented as a drop-down field in the UI.</p>
<p>Another potential of using Hypermedia is to decouple business logic from the client. By using links and actions to direct the client to available resources, the information contained in the available links and actions is used to implicitly tell clients which use cases are possible with the current state of the system. For example, assuming that only books which have a certain availability can be added to the shopping cart. Clients that implement this behavior, that is, only showing an <em>add-to-cart</em> button for these situations, need to be aware of this logic. The client functionality then will check whether the book availability meets the criteria, and so on. Technically, this business logic should reside on the server-side only. By dynamically providing links and actions to available resources, the server dictates which functionality is possible under the current state. The <em>add-to-cart</em> action would then only be included if the book can actually be added to the cart. The client logic therefore is simplified to checking whether links and actions with known relations or names, respectively, are included. Therefore, the client only displays an active <em>add-to-cart</em> button if the corresponding action is provided in the response.</p>
<p>Together with the advent of Java EE, the REST architectural style gained more and more attention. While most web services out there don't implement all of the constraints that the REST architectural style defines, especially Hypermedia, they are mostly considered as REST services.</p>
<p>For more information about REST constraints, I refer you to the dissertation of Roy T. Fielding's <em>Architectural Styles and the Design of Network-based Software Architectures</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Java API for RESTful web services</h1>
                </header>
            
            <article>
                
<p>In Java EE, the <strong>Java API for RESTful web services</strong> (<strong>JAX-RS</strong>) is used to both define and access REST services. JAX-RS is widely used in the Java ecosystem, even by other enterprise technologies. Developers especially like the declarative development model that makes it easy to develop REST services in a productive way.</p>
<p>So-called JAX-RS resources specify REST resources which will be available under a certain URL. The JAX-RS resources are methods in a resource class that implement the business logic once the URL is accessed with a specific HTTP method. The following shows an example of a JAX-RS resource class for users:</p>
<pre>import javax.ws.rs.Path;
import javax.ws.rs.GET;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;

<strong>@Path("users")
@Produces(MediaType.APPLICATION_JSON)</strong>
public class UsersResource {

    @Inject
    UserStore userStore;

    <strong>@GET</strong>
    public List&lt;User&gt; getUsers() {
        return userStore.getUsers();
    }
}</pre>
<p>The <kbd>getUsers()</kbd> method is the JAX-RS resource method that will be invoked by the container once the HTTP call <kbd>GET .../users</kbd> is performed by a client. The list of users is then returned to the client in the JSON format, that is, as a JSON array containing JSON objects for each of the users. That is specified via the <kbd>@Produces</kbd> annotation that will here implicitly use the <strong>Java API for JSON Binding</strong> (<strong>JSON-B</strong>) to map Java types to their corresponding JSON representation.</p>
<p>Here you can see the inversion of control principle at work. We don't have to wire up or register the URL ourselves, the declaration using the <kbd>@Path</kbd> annotation is sufficient. The same is true for mapping Java types into representations such as JSON. We specify in a declarative way which representation formats we want to provide. The rest is handled by the container. The JAX-RS implementation also takes care of the required HTTP communication. By returning an object, here the list of users, JAX-RS implicitly assumes the HTTP status code <kbd>200 OK</kbd>, which is returned to the client together with our JSON representation.</p>
<p>In order to register JAX-RS resources to the container, the application can ship a sub-class of <kbd>Application</kbd> which bootstraps the JAX-RS runtime. Annotating this class with <kbd>@ApplicationPath</kbd> automatically registers the provided path as Servlet. The following shows a JAX-RS configuration class which is sufficient for the vast majority of use cases:</p>
<pre>import javax.ws.rs.ApplicationPath;
import javax.ws.rs.core.Application;

<strong>@ApplicationPath("resources")</strong>
public class JAXRSConfiguration extends <strong>Application</strong> {
    // no configuration required
}</pre>
<p>JAX-RS, as well as the other standards in the Java EE umbrella, make use of the convention over configuration principle. The default behavior of this REST resource is plausibly sufficient for most of the use cases. If not, then the default behavior can always be overridden with custom logic. This is the reason why JAX-RS, among others, provides a productive programming model. The default cases are realizable very quickly with the option to enhance further.</p>
<p>Let's look at a more comprehensive example. Assuming we want to create a new user in the system that is provided by a client using our REST service. Following HTTP semantics, that action would be a POST request to the user's resource, since we are creating a new resource that may not be identified yet. The difference between the POST and the PUT method is that the latter is omnipotent, only changing the accessed resource with the provided representation, whereas POST will create new resources in the form of new URLs. This is the case here. We are creating a new user that will be identifiable with a new, generated URL. If the resource for the new user is created, the client should be directed toward that URL. For creating resources, this is typically realized with the <kbd>201 Created</kbd> status code, which indicates that a new resource has been created successfully, and the <kbd>Location</kbd> header, which contains the URL where the resource will be found.</p>
<p>In order to fulfill that requirement, we have to provide more information in our JAX-RS resource. The following demonstrates how this is accomplished in the <kbd>createUser()</kbd> method:</p>
<pre>import javax.ws.rs.Consumes;
import javax.ws.rs.PathParam;
import javax.ws.rs.POST;
import javax.ws.rs.core.Context;
import javax.ws.rs.core.Response;
import javax.ws.rs.core.UriInfo;

@Path("users")
@Produces(MediaType.APPLICATION_JSON)
@Consumes(MediaType.APPLICATION_JSON)
public class UsersResource {

    @Inject
    UserStore userStore;

    <strong>@Context
    UriInfo uriInfo;</strong>

    @GET
    public List&lt;User&gt; getUsers() {
        return userStore.getUsers();
    }

    @GET
    @Path("{id}")
    public User getUser(@PathParam("id") long id) {
        return userStore.getUser(id);
    }

    <strong>@POST</strong>
    public Response createUser(User user) {
        long id = userStore.create(user);

        <strong>URI userUri = uriInfo.getBaseUriBuilder()
                .path(UsersResource.class)
                .path(UsersResource.class, "getUser")
                .build(id);</strong>

        return<strong> Response.created(userUri).build();</strong>
    }

}</pre>
<p>We make use of the <kbd>UriInfo</kbd> feature included in JAX-RS, so that we don't need to repeat ourselves when constructing the new URL. That feature uses the path information which is already present in the annotations of our resource class. The <kbd>Response</kbd> method is used to specify the actual HTTP response using a builder pattern approach. JAX-RS notices that the return type of our method is now a response specification and will respond to the client appropriately. By this approach, we have full control and flexibility as to what the response to the client looks like.</p>
<p>As you can see, these methods are the entry point to our business use cases. We inject the <kbd>UserStore</kbd> <span>boundary</span> which in our case is implemented as EJB, providing the logic to return the list of users and creating new users, respectively.</p>
<p>JAX-RS provides a productive and straightforward way to expose business functionality with RESTful web services. Developers don't have to write any low-level HTTP <em>plumbing</em> if the default behavior is sufficient.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Mapping HTTP content types</h1>
                </header>
            
            <article>
                
<p>With the same mindset of giving developers as much productivity as possible, Java EE includes standards to transparently map POJOs to JSON or XML. The example you saw with JAX-RS implicitly used JSON-B to map our <kbd>User</kbd> types to JSON objects and arrays, respectively.</p>
<p>This again uses the principle of convention over configuration. If nothing is else specified JSON-B assumes to map the POJO properties directly as JSON object key-value pairs. The user's <em>id</em> was present in the JSON output as well.</p>
<p>The same holds true for the <strong>Java Architecture for XML Binding</strong> (<strong>JAXB</strong>) and its XML binding, which was included in Java EE much earlier than JSON-B. Both standards support a declarative configuration approach using annotations that are placed on the mapped Java types. If we're about to change the JSON representation of the type, we annotate the corresponding fields:</p>
<pre>import javax.json.bind.annotation.JsonbProperty;
import javax.json.bind.annotation.JsonbTransient;

public class User {

    <strong>@JsonbTransient</strong>
    private long id;

    <strong>@JsonbProperty("username")</strong>
    private String name;

    ...
}</pre>
<p>If we want to implement more sophisticated resource mapping, such as in the Hypermedia book examples shown before, we can do so using the declarative mapping approach. For instance, to map the links into the books resource, we can use a map containing links and link relations:</p>
<pre>public class Book {

    @JsonbTransient
    private long id;

    private String name;
    private String author;
    private String isbn;

    <strong>@JsonbProperty("_links")
    private Map&lt;String, URI&gt; links;</strong>

    ...
}</pre>
<p>These links are set in the JAX-RS resource appropriately:</p>
<pre>@Path("books")
@Produces(MediaType.APPLICATION_JSON)
public class BooksResource {

    @Inject
    BookStore bookStore;

    @Context
    UriInfo uriInfo;

    @GET
    public List&lt;Book&gt; getBooks() {
        List&lt;Book&gt; books = bookStore.getBooks();
        <strong>books.forEach(this::addLinks);</strong>
        return books;
    }

    @GET
    @Path("{id}")
    public Book getBook(@PathParam("id") long id) {
        Book book = bookStore.getBook(id);
        <strong>addLinks(book);</strong>
        return book;
    }

    private void addLinks(Book book) {
        URI selfUri = uriInfo.getBaseUriBuilder()
                .path(BooksResource.class)
                .path(BooksResource.class, "getBook")
                .build(book.getId());

        <strong>book.getLinks().put("self", selfUri);</strong>
        // other links
    }
}</pre>
<p>The output of the list of books will look similar to the following:</p>
<pre>[
    {
         "name": "Java",
         "author": "Duke",
         "isbn": "123-2-34-456789-0",
         "_links": {
             "self": "https://api.example.com/books/12345",
             "author": "https://api.example.com/authors/2345",
             "related-books": "https://api.example.com/books/12345/related"
        }
    },
    ...
]</pre>
<p>Using this approach, we can now programmatically introduce links with relations that are used and being followed within the client. However, using a Hypermedia approach pretty quickly reaches the point where a declarative mapping introduces too much overhead on the model. The map of links and relations already is not part of the business domain, but a technical necessity and should therefore be questioned. We could introduce transfer object types that separate the technical mapping from the domain model. But this would certainly introduce a lot of duplication and clutter our project with a number of classes that serve no value to the business.</p>
<p>Another challenge to be faced is the flexibility that Hypermedia requires. Even for simpler examples that make use of Hypermedia controls, we want to specify and include links and actions depending on the current state of the system. It's in the nature of Hypermedia to control the flow of clients and direct them to certain resources. For example, a client response should only include the action to place an order if a book is in stock or certain credit is on their account. This requires the response mapping to be changeable on demand. Since a declarative mapping can't be changed easily at runtime, we would need a more flexible approach.</p>
<p>Since Java EE 7, there is the <strong>Java API for JSON Processing</strong> (<strong>JSON-P</strong>) standard which provides programmatic mapping of JSON structures in a builder pattern-like fashion. We can simply invoke the builder types <kbd>JsonObjectBuilder</kbd> or <kbd>JsonArrayBuilder</kbd> to create arbitrary complex structures:</p>
<pre>import javax.json.Json;
import javax.json.JsonObject;
...

<strong>JsonObject object = Json.createObjectBuilder()
    .add("hello", Json.createArrayBuilder()
        .add("hello")
        .build())
    .add("key", "value")
    .build();</strong></pre>
<p>The resulting JSON object looks as follows:</p>
<pre>{
    "hello": [
        "hello"
    ],
    "key": "value"
}</pre>
<p>Especially in situations where we need a lot of flexibility such as in Hypermedia this approach is quite helpful. The JSON-P standard, as well as JSON-B or JAXB, seamlessly integrates with JAX-RS. JAX-RS resource methods that return JSON-P types, such as <kbd>JsonObject</kbd>, will automatically return the JSON content type together with the corresponding response. No further configuration is required. Let's have a look how the example containing resource links is implemented using JSON-P.</p>
<pre>import javax.json.JsonArray;
import javax.json.stream.JsonCollectors;

@Path("books")
public class BooksResource {

    @Inject
    BookStore bookStore;

    @Context
    UriInfo uriInfo;

    @GET
    public <strong>JsonArray</strong> getBooks() {
        return <strong>bookStore.getBooks().stream()
                .map(this::buildBookJson)
                .collect(JsonCollectors.toJsonArray());</strong>
    }

    @GET
    @Path("{id}")
    public <strong>JsonObject</strong> getBook(@PathParam("id") long id) {
        Book book = bookStore.getBook(id);
        return <strong>buildBookJson(book);</strong>
    }

    private <strong>JsonObject</strong> buildBookJson(Book book) {
        URI selfUri = uriInfo.getBaseUriBuilder()
                .path(BooksResource.class)
                .path(BooksResource.class, "getBook")
                .build(book.getId());

        URI authorUri = ...

        return Json.createObjectBuilder()
                .add("name", book.getName())
                .add("author", book.getName())
                .add("isbn", book.getName())
                .add("_links", Json.createObjectBuilder()
                        .add("self", selfUri.toString())
                        .add("author", authorUri.toString()))
                .build();
    }
}</pre>
<p>The JSON-P objects are created dynamically using a builder pattern approach. We have full flexibility over the desired output. This approach of using JSON-P is also advisable if a communication needs a representation of an entity different to the current model. In the past, projects always introduced transfer objects or DTOs for this purpose. Here the JSON-P objects are in fact transfer objects. By using this approach, we eliminate the need for another class that also duplicates the majority of structures of the model entity.</p>
<p>However, there is also some duplication in this example. The property names of the resulting JSON objects are now provided by strings. To refactor that example a little bit, we would introduce a single point of responsibility, such as a managed bean responsible for creating the JSON-P objects from the model entities.</p>
<p>This bean, for example <kbd>EntityBuilder</kbd>, would be injected in this and other JAX-RS resource classes. Then the duplication is still existent, but encapsulated in that single point of responsibility and reused from multiple resource classes. The following code shows an example <kbd>EntityBuilder</kbd> for books and potentially other objects to be mapped to JSON.</p>
<pre>public class EntityBuilder {

    public JsonObject buildForBook(Book book, URI selfUri) {
        return Json.createObjectBuilder()
                ...
    }
}</pre>
<p>If the representation to some endpoint or external system differs from our model, we won't be able to fully avoid duplication without other downsides. By using this approach, we decouple the mapping logic from the model and have full flexibility. The mapping of the POJO properties happens in the builder pattern invocations. Compared to introducing separate transfer object classes and mapping them in another functionality, this results in less obfuscation and ultimately less code.</p>
<p>Let's take up on the Hypermedia example using the <em>add-to-cart</em> Siren actions again. This example gave an idea of the potential content of Hypermedia responses. For responses like these, the output needs to be dynamic and flexible, depending on the application's state. Now we can imagine the flexibility and strength of a programmatic mapping approach such as JSON-P. This output is not really feasible using declarative POJO mapping, which would introduce a quite complex graph of objects. In Java EE, it is advisable to either use JSON-P in a single responsibility or a third-party dependency for the desired content type.</p>
<p>For mapping Java objects into JSON or XML payloads, JAXB, JSON-B, and JSON-P offers seamless integration into other Java EE standards, such as JAX-RS. Besides the integration into JAX-RS that we just saw we can also integrate CDI injection; this interoperability holds true as for all modern Java EE standards.</p>
<p>JSON-B type adapters enable to map custom Java types that are unknown to JSON-B. They transform custom Java types into known and mappable types. A typical example is serializing references to objects as identifiers:</p>
<pre>import javax.json.bind.annotation.JsonbTypeAdapter;

public class Employee {

    @JsonbTransient
    private long id;
    private String name;
    private String email;

    <strong>@JsonbTypeAdapter(value = OrganizationTypeAdapter.class)
    private Organization organization;</strong>

    ...
}</pre>
<p>The type adapter specified on the <kbd>organization</kbd> field is used to represent the reference as the organization's ID. To resolve that reference, we need to look up valid organizations. This functionality can be simply injected into the JSON-B type adapter:</p>
<pre>import javax.json.bind.adapter.JsonbAdapter;

public class OrganizationTypeAdapter implements JsonbAdapter&lt;Organization, String&gt; {

    <strong>@Inject
    OrganizationStore organizationStore;</strong>

    @Override
    public String adaptToJson(Organization organization) {
        return String.valueOf(organization.getId());
    }

    @Override
    public Organization adaptFromJson(String string) {
        long id = Long.parseLong(string);
        <strong>Organization organization = organizationStore.getOrganization(id);</strong>

        if (organization == null)
            throw new IllegalArgumentException("Could not find organization for ID " + string);

        return organization;
    }
}</pre>
<p>This example already shows the benefit of having several standards that work well with each other. Developers can simply use and integrate the functionalities without spending time on configuration and <em>plumbing</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Validating requests</h1>
                </header>
            
            <article>
                
<p>JAX-RS offers an integration of HTTP endpoints into our system. This includes mapping of requests and responses into Java types of our application. However, the client requests need to be validated in order to prevent misuse of the system.</p>
<p>The <strong>Bean Validation</strong> standard provides validation of all kind of sorts. The idea is to declare validation constraints, such as <em>this field must not be null</em>, <em>this integer must not be negative</em> or <em>this salary raise must align with the company policies</em>, to Java types and properties. The standard already ships the typically required technically motivated constraints. Custom constraints, especially those that are motivated by the business functionality and validation, can be added as well. This becomes interesting not only from a technical, but a domain perspective. Validation logic that is motivated by the domain can be implemented using this standard.</p>
<p>The validation is activated by annotating method parameters, return types, or properties with <kbd>@Valid</kbd>. Whereas validation can be applied in many points in the application, it is particularly important to endpoints. Annotating a JAX-RS resource method parameter with <kbd>@Valid</kbd> will validate the request body or parameter, respectively. If the validation fails, JAX-RS automatically responds to the HTTP request with a status code indicating a client error.</p>
<p>The following demonstrates the integration of a user validation:</p>
<pre>import javax.validation.Valid;
import javax.validation.constraints.NotNull;

@Path("users")
@Produces(MediaType.APPLICATION_JSON)
@Consumes(MediaType.APPLICATION_JSON)
public class UsersResource {

    ...

    @POST
    public Response createUser(<strong>@Valid @NotNull User user</strong>) {
        ...
    }
}</pre>
<p>The user type is annotated with validation constraints:</p>
<pre>import javax.validation.constraints.Email;
import javax.validation.constraints.NotBlank;

public class User {

    @JsonbTransient
    private long id;

    <strong>@NotBlank</strong>
    private String name;

    <strong>@Email</strong>
    private String email;

    ...
}</pre>
<p>The annotations placed on the JAX-RS method tell the implementation to validate the request body as soon as a client request arrives. The request body must be available, not <kbd>null</kbd>, and valid following the configuration of the user type. The user's name property is constrained to not be blank; that is, it should not be <kbd>null</kbd> or not just containing whitespace, respectively. The user's email property has to comply with a valid email address format. These constraints are enforced when validating a user object.</p>
<p>Internally, a <kbd>Validator</kbd> included in Bean Validation validates the objects. The validator will throw <kbd>ConstraintViolationException</kbd>s if the validation fails. This validator functionality can also be obtained by dependency injection and called programmatically. JAX-RS automatically calls the validator and sends an appropriate response to the client if the validation fails.</p>
<p>This example would fail on illegal HTTP POST invocations to the <kbd>/users/</kbd> <span>resource</span>, such as providing user representations without a name. This results in <kbd>400 Bad Request</kbd> status codes, the JAX-RS default behavior for failed client validations.</p>
<p>If the clients need more information about why a request was declined, the default behavior can be extended. The violation exceptions which are thrown by the validator can be mapped to HTTP responses with the JAX-RS exception mapper functionality. Exception mappers handle exceptions that are thrown from JAX-RS resource methods to appropriate client responses. The following demonstrates an example of such an <kbd>ExceptionMapper</kbd> for <kbd>ConstraintViolationExceptions</kbd>:</p>
<pre>import javax.validation.ConstraintViolationException;
import javax.ws.rs.ext.ExceptionMapper;
import javax.ws.rs.ext.Provider;

<strong>@Provider</strong>
public class ValidationExceptionMapper implements <strong>ExceptionMapper&lt;ConstraintViolationException&gt;</strong> {

    @Override
    public <strong>Response toResponse(ConstraintViolationException exception)</strong> {
        Response.ResponseBuilder builder = Response.status(Response.Status.BAD_REQUEST);

        exception.getConstraintViolations()
                .forEach(v -&gt; {
                    builder.header("Error-Description", ...);
                });
        return builder.build();
    }
}</pre>
<p>Exception mappers are providers for the JAX-RS runtime. Providers are either configured programmatically in the JAX-RS base application class or, as shown here, in a declarative way using the <kbd>@Provider</kbd> annotation. The JAX-RS runtime will scan the classes for providers and apply them automatically.</p>
<p>The exception mapper is registered for the given exception type and sub-types. All the constraint violation exceptions thrown by a JAX-RS resource method here are mapped to a client response including a basic description of which fields caused the validation to fail. The violation messages are a functionality of Bean Validation providing human readable, global messages.</p>
<p>If the built-in validation constraints are not sufficient for the validation, custom validation constraints can be used. This is especially required for validation rules that are specific to the domain. For example, usernames could need more sophisticated validation based on the current state of the system. In this example, the usernames must not be taken when creating new users. Other constraints on the format or allowed characters could be set as well, obviously:</p>
<pre>public class User {

    @JsonbTransient
    private long id;

    @NotBlank
    <strong>@UserNameNotTaken</strong>
    private String name;

    @Email
    private String email;
    ...
}</pre>
<p>The <kbd>@UserNameNotTaken</kbd> annotation is a custom validation constraint defined by our application. Validation constraints delegate to a constraint validator, the actual class that performs the validation. Constraint validators have access to the annotated object, such as the class or field in this case. The custom functionality checks whether the provided object is valid. The validation method can use the <kbd>ConstraintValidatorContext</kbd> to control custom violations including messages and further information.</p>
<p>The following shows the custom constraint definition:</p>
<pre>import javax.validation.Constraint;
import javax.validation.Payload;

<strong>@Constraint(validatedBy = UserNameNotTakenValidator.class)</strong>
@Documented
@Retention(RUNTIME)
@Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE})
public @interface UserNameNotTaken {

    String message() default "";

    Class&lt;?&gt;[] groups() default {};
    Class&lt;? extends Payload&gt;[] payload() default {};
}</pre>
<p>Our constraint is validated by the <kbd>UserNameNotTakenValidator</kbd> class:</p>
<pre>import javax.validation.ConstraintValidator;
import javax.validation.ConstraintValidatorContext;

public class UserNameNotTakenValidator implements <strong>ConstraintValidator&lt;UserNameNotTaken, String&gt;</strong> {

    <strong>@Inject
    UserStore userStore;</strong>

    public void initialize(UserNameNotTaken constraint) {
        // nothing to do
    }

    public <strong>boolean isValid(String string, ConstraintValidatorContext context)</strong> {
        return !userStore.isNameTaken(string);
    }
}</pre>
<p>As with other standards, constraint validators can use dependency injection to use managed beans. This is very often required for custom validation logic that makes calls to controls. In this example, the validator injects the <kbd>UserStore</kbd>. Once again, we can reuse different standards within the Java EE umbrella.</p>
<p>Custom validation constraints are very often motivated by the business domain. It can make sense to encapsulate complex, composed validation logic into such custom constraints. When applied, this approach also leverages the single responsibility principle, separating the validation logic into a single validator rather than spreading them in atomic constraints.</p>
<p>Bean Validation offers more complex functionality for scenarios where different ways of validation are required for the same types. Therefore, the concept of groups is used to group certain constraints together into groups which can possibly be validated individually. For more information on this, I refer the reader to the Bean Validation specification.</p>
<p>As shown previously, HTTP JSON payloads can also be mapped in JAX-RS using the JSON-P standard. This is also true for HTTP request bodies. The request bodies parameters can be provided as JSON-P types containing JSON structures that are read dynamically. As well as for response bodies, it makes sense to represent request bodies using JSON-P types if the object structure differs from the model types or needs more flexibility, respectively. For this scenario, validation of the provided objects is even more important, since the JSON-P structures can be arbitrary. To rely on certain JSON properties being existent on the request object, these objects are validated using a custom validation constraint.</p>
<p>Since JSON-P objects are built programmatically and there are no pre-defined types, programmers have no way of annotating fields in the same way as for Java types. Therefore, custom validation constraints are used on the request body parameters that are bound to a custom validator. The custom constraints define the structure of a valid JSON object for the specific request bodies. The following code shows the integration of a validated JSON-P type in a JAX-RS resource method:</p>
<pre>@Path("users")
@Produces(MediaType.APPLICATION_JSON)
@Consumes(MediaType.APPLICATION_JSON)
public class UsersResource {

    ...

    @POST
    public Response createUser(<strong>@Valid @ValidUser JsonObject json</strong>) {

        <strong>User user = readUser(json);</strong>
        long id = userStore.create(user);
        ...
    }

    private User readUser(JsonObject object) {
        ...
    }
}</pre>
<p>The custom validation constraint <kbd>ValidUser</kbd> references the used constraint validator. Since the structure of the provided JSON-P objects is arbitrary, the validator has to check for the presence and type of properties:</p>
<pre><strong>@Constraint(validatedBy = ValidUserValidator.class)</strong>
@Documented
@Retention(RUNTIME)
@Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE})
public @interface ValidUser {

    String message() default "";

    Class&lt;?&gt;[] groups() default {};

    Class&lt;? extends Payload&gt;[] payload() default {};
}</pre>
<p>The custom constraint validator is applicable on JSON-P types, as well:</p>
<pre>public class ValidUserValidator implements <strong>ConstraintValidator&lt;ValidUser, JsonObject&gt;</strong> {

    public void initialize(ValidUser constraint) {
        // nothing to do
    }

    public <strong>boolean isValid(JsonObject json, ConstraintValidatorContext context)</strong> {
        ...
    }
}</pre>
<p>After the provided JSON-P object has been validated, the defined properties can safely be extracted. This example showcases how the flexible, programmatic types are integrated and validated in JAX-RS methods. The resource class extracts the request body into a domain entity type and uses the boundary to invoke the business use case.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Mapping errors</h1>
                </header>
            
            <article>
                
<p>As we have seen in the last examples, JAX-RS provides the ability to map exceptions to custom responses. This is a helpful functionality to implement transparent custom error handling without impacting the production code workflow.</p>
<p>A common issue when dealing with EJBs is that any thrown exception will be wrapped in an <kbd>EJBException</kbd> when accessed by any non-EJB context; for example, a request scoped JAX-RS resource. This makes exception handling quite cumbersome, as the <kbd>EJBException</kbd> would have to be unwrapped to inspect the cause.</p>
<p>By annotating custom exception types with <kbd>@ApplicationException</kbd>, the cause will not be wrapped:</p>
<pre>import javax.ejb.ApplicationException;

<strong>@ApplicationException</strong>
public class GreetingException extends RuntimeException {

    public GreetingException(String message) {
        super(message);
    }
}</pre>
<p>Calling an EJB that throws the <kbd>GreetingException</kbd> will not result in a wrapped <kbd>EJBException</kbd> and produce the exception type directly. The application can then define a JAX-RS exception mapper for the actual <kbd>GreetingException</kbd> type, similar to the one mapping constraint violations.</p>
<p><span>Specifying</span> <kbd>@ApplicationException(rollback = true)</kbd> <span>will furthermore cause the container to roll back an active transaction when the exception occurs.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Accessing external systems</h1>
                </header>
            
            <article>
                
<p>We have now seen how our business domain is accessed from the outside via HTTP.</p>
<p>In order to perform the business logic, the majority of enterprise applications need to access other external systems as well. External systems don't include databases that are owned by our application. Usually external systems are external to the application's domain. They reside in another bounded context.</p>
<p>In order to access external HTTP services, we integrate a client component into our project, usually as a separate control. This control class encapsulates the functionality required to communicate with the external system. It is advisable to carefully construct the interface and not to mix domain concerns with communication implementation details. These details include potential payload mappings, the communication protocol, HTTP information if HTTP is being used, and any other aspect not relevant to the core domain.</p>
<p>JAX-RS ships with a sophisticated client feature that accesses HTTP services in a productive way. It provides the same type mapping functionalities as it does for resource classes. The following code represents a control that accesses an external system to order coffee beans:</p>
<pre>import javax.annotation.PostConstruct;
import javax.annotation.PreDestroy;
import javax.enterprise.context.ApplicationScoped;
import javax.ws.rs.client.*;
import java.util.concurrent.TimeUnit;

@ApplicationScoped
public class CoffeePurchaser {

    <strong>private Client client;
    private WebTarget target;</strong>

    @PostConstruct
    private void initClient() {
        <strong>client = ClientBuilder.newClient();
        target = client.target("http://coffee.example.com/beans/purchases/");</strong>
    }

    public OrderId purchaseBeans(BeanType type) {
        // construct purchase payload from type
        Purchase purchase = ...

        BeanOrder beanOrder = <strong>target
                .request(MediaType.APPLICATION_JSON_TYPE)
                .post(Entity.json(purchase))
                .readEntity(BeanOrder.class)</strong>;

        return beanOrder.getId();
    }

    @PreDestroy
    public void closeClient() {
        <strong>client.close();</strong>
    }
}</pre>
<p>The JAX-RS client is built and configured by the client builder and uses web targets to access URLs. These targets can be modified using a URI builder functionality, similar to the one in the JAX-RS resources. Targets are used to build new invocations that represent the actual HTTP invocations. The invocations can be configured in regard to HTTP information, such as content types, headers, as well as specifics of mapped Java types.</p>
<p>In this example, the target that points to the external URL builds a new request for the JSON content type with a HTTP POST method. The returned JSON structure is expected to be mappable to a <kbd>BeanOrder</kbd> object. The client performs further logic to extract the necessary information.</p>
<p>The client instance will be closed properly on container shutdown in the <kbd>@PreDestroy</kbd>-method to prevent resource leaks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Stability when consuming HTTP</h1>
                </header>
            
            <article>
                
<p>This example, however, lacks some aspects in regard to resilience. Calling this client control without further consideration could lead to unwanted behavior.</p>
<p>The client request blocks until the HTTP invocation either returned successfully or the connection timed-out. The HTTP connection timeout configuration depends on the JAX-RS implementation, which is set to infinite blocking in some technologies. For resilient clients, this is obviously not acceptable. A connection could wait forever, blocking the thread and, in a worst-case scenario, could block the whole application if all available threads are stuck at that location, waiting for their individual HTTP connection to finish. To prevent this scenario, we configure the client to use custom connection timeouts.</p>
<p>The timeout values depend on the application, especially the network configuration to the external system. It varies what are reasonable values for HTTP timeouts. To get sensible timeout values, it is advisable to gather statistics about the latency to the external system. For systems where load and network latency vary a lot, for example e-commerce systems with selective high utilization during certain seasons, the nature of variations should be considered.</p>
<p>The HTTP connect timeout is the maximum time allowed until a connection has been established. Its value should be small. The HTTP read timeout specifies how long to wait to read data. Its value depends on the nature of the external service being consumed. Following the gathered statistics, a good starting point for configuring the read timeout is to calculate the mean response times plus three times the standard deviation. We will cover the topic of performance and service backpressure in <a href="">Chapter 9</a>, <em>Monitoring, Performance, and Logging</em>.</p>
<p>The following shows how to configure both the HTTP connect and read timeout:</p>
<pre>@ApplicationScoped
public class CoffeePurchaser {

    ...

    @PostConstruct
    private void initClient() {
        client = ClientBuilder.newBuilder()
                <strong>.connectTimeout(100, TimeUnit.MILLISECONDS)
                .readTimeout(2, TimeUnit.SECONDS)</strong>
                .build();
        target = client.target("http://coffee.example.com/beans/purchases/");
    }

    ...
}</pre>
<p>Client invocations can result in potential errors. The external service could respond with an unexpected status code, an unexpected response, or no response at all.<span>This needs to be considered when implementing client components.</span></p>
<p>The <kbd>readResponse()</kbd> client call expects the response to be of the HTTP status code <kbd>SUCCESSFUL</kbd> family and the response body to be mappable into the given Java type from the requested content type. If something goes wrong, a <kbd>RuntimeException</kbd> is thrown. Runtime exceptions enable engineers to write code without obfuscating try-catch blocks, but also require them to be aware of the potential errors.</p>
<p>The client method could catch the runtime exceptions in order to prevent them from being thrown to the calling domain service. There is also another, leaner possibility using interceptors. Interceptors provide cross-cutting functionalities that are applied without being tightly coupled to the decorated functionality. For example, this client method should intentionally return <kbd>null</kbd> when the external system could not deliver a reasonable response.</p>
<p>The following demonstrates an interceptor that intercepts method invocations and applies this behavior on occurred exceptions. This interceptor is integrated by annotating the method of the <kbd>CoffeePurchaser</kbd> control:</p>
<pre>import javax.interceptor.AroundInvoke;
import javax.interceptor.Interceptor;
import javax.interceptor.InvocationContext;

<strong>@Interceptor</strong>
public class FailureToNullInterceptor {

    <strong>@AroundInvoke</strong>
    public <strong>Object aroundInvoke(InvocationContext context)</strong> {
        try {
            return context.proceed();
        } catch (Exception e) {
            ...
            return null;
        }
    }
}</pre>
<p>The <kbd>purchaseBean()</kbd> method is annotated with <kbd>@Interceptors(FailureToNullInterceptor.class)</kbd>. This activates the cross-cutting concerns for that method.</p>
<p>In regard to resilience, the client functionality could include further logic. If several systems are available, the client can retry failed invocations on a different system. Then, only as a last resort, the invocation would fail without a result.</p>
<p>In the topic, <em>Cross-cutting concerns</em>, we will see how to implement further cross-cutting concerns.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Accessing Hypermedia REST services</h1>
                </header>
            
            <article>
                
<p>HTTP web services that apply REST constraints, especially in regard to Hypermedia, need more sophisticated logic on the client side. Services direct clients to corresponding resources that need to be accessed in certain ways. Hypermedia decouples services and enables API features such as evolvability and discovery, but also require more dynamic and logic on the client side.</p>
<p>The Siren content type example earlier gives an impression of how service responses direct REST clients to available subsequent calls. Assume the client retrieves the response of an order and wants to follow the <kbd>add-to-cart</kbd> action:</p>
<pre>{
    ... example as shown before
    ... properties of book resource
    "actions": [
        {
            "name": "<strong>add-to-cart</strong>",
            "title": "Add Book to cart",
            "method": "POST",
            "href": "http://api.example.com/shopping-cart",
            "type": "application/json",
            "fields": [
                { "name": "isbn", "type": "text" },
                { "name": "quantity", "type": "number" }
            ]
        }
    ],
    "links": ...
}</pre>
<p>The client is only coupled to the knowledge of what business meaning the <em>add-to-cart</em> action has and how to provide the field value information for ISBN and quantity. This is certainly client domain logic that needs to be implemented. The information on how the subsequent resource, the shopping cart, is accessed, using which HTTP method, and what content type is now dynamic and not baked into the client.</p>
<p>In order to add a book to the shopping cart, the client will first access the book's resource. The <em>add-to-cart</em> use case is called subsequently, extracting the information of the specified Hypermedia action. The information for the required fields needs to be provided by the invocation. The client then accesses the second resource, using the information provided both by the REST service and the invocation by the control:</p>
<pre>public class BookClient {

    @Inject
    EntityMapper entityMapper;

    public <strong>Book retrieveBook(URI uri)</strong> {
        Entity book = retrieveEntity(uri);
        return entityMapper.decodeBook(uri, book.getProperties());
    }

    public <strong>void addToCart(Book book, int quantity)</strong> {
        Entity bookEntity = retrieveEntity(book.getUri());

        JsonObjectBuilder properties = Json.createObjectBuilder();
        properties.add("quantity", quantity);

        Entity entity = entityMapper.encodeBook(book);
        entity.getProperties().forEach(properties::add);

        performAction(bookEntity, "add-to-cart", properties.build());
    }

    private Entity retrieveEntity(URI uri) {
        ...
    }

    private void performAction(Entity entity, String actionName,
            JsonObject properties) {
        ...
    }
}</pre>
<p>The <kbd>Entity</kbd> type encapsulates information of the Hypermedia entity types. The <kbd>EntityMapper</kbd> is responsible for mapping the content type into domain models and vice versa. In this example, all the required fields for the action result from the properties of the resource plus the provided <kbd>quantity</kbd> parameter. To enable a certain dynamic, all entity properties are added into a map and are provided to the <kbd>performAction()</kbd> method. Depending on the action specified by the server, the required fields are extracted from this map. If more fields are required, the client logic obviously has to change.</p>
<p>It certainly makes sense to encapsulate logic for accessing Hypermedia services as well as mapping domain models to a content types into separate delegates. Functionality for accessing REST services could also sensibly be replaced by a library.</p>
<p>You might notice how the URI has now leaked into the public interface of the client class. This was not accidental, but required to identify resources over several use case calls. That said, the URIs move into the business domain as general identifier of resources. Since the logic of how URLs are created from technical IDs reside on the client side, the whole URL of an entity resource becomes the <em>identifier</em>. However, when designing client controls, engineers should take care of the public interface. In particular, no information about the communication to the external system should leak into the domain. Using Hypermedia supports this approach well. All the required transport information is retrieved and used dynamically. The navigation logic that follows Hypermedia responses resides in the client control.</p>
<p>This example aims to give the reader an idea how a client uses Hypermedia REST services.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Asynchronous communication and messaging</h1>
                </header>
            
            <article>
                
<p>Asynchronous communication leads to looser coupling of the systems. It generally increases the overall responsiveness as well as overhead and enables scenarios where systems are not reliably available all the time. There exist many forms of how to design asynchronous communication, on a conceptual or technical level. Asynchronous communication doesn't imply that there can't be synchronous calls on a technical level. The business process can be built in an asynchronous way that models one or several synchronous invocations that are not performed or handled immediately. For example, an API can offer synchronous methods to create long-running processes that are frequently polled for updates later on.</p>
<p>On a technical level, asynchronous communication is usually designed in a message-oriented way implemented using message queues or the publish-subscribe pattern. Applications only directly communicate with a message queue or a broker, respectively, and messages are not directly passed to a specific receiver.</p>
<p>Let's have a look at the various ways to accomplish asynchronous communication.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Asynchronous HTTP communication</h1>
                </header>
            
            <article>
                
<p>The request response model of HTTP communication usually involves synchronous communication. A client requests a resource at a server and blocks until the response has been transmitted. Asynchronous communication using HTTP is therefore typically archived on a conceptual basis. The synchronous HTTP invocations can trigger long-running business processes. The external system can then either notify the caller by another mechanism later on or offer functionality for polling for updates.</p>
<p>For example, a sophisticated user management system offers methods to create users. Assume users need to be registered and legitimized in external systems as part of a longer-running, asynchronous business process. The application would then offer an HTTP functionality, such as <kbd>POST /users/</kbd>, which starts the process to create new users. However, invoking that use case does not guarantee that the user will be created and registered successfully. The response of that HTTP endpoint would only acknowledge the attempt to create a new user; for example, by the <kbd>202 Accepted</kbd> status code. This indicates that the request has been accepted, but has not necessarily been processed completely. The <kbd>Location</kbd> header field could be used to direct to the resource where the client can poll for updates on the partly-finished user.</p>
<p>On a technical level, HTTP does not only support synchronous invocations. In Sub-chapter <em>Server-sent events</em>, we will have a look at server-sent events as an example of a HTTP standard using asynchronous message-oriented communication.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Message-oriented communication</h1>
                </header>
            
            <article>
                
<p>Message-oriented communication exchanges information in asynchronously sent messages, usually implemented using message queues or the publish-subscribe pattern. It offers the advantage of decoupling systems since applications only directly communicate with the message queue or the broker, respectively. The decoupling not only affects dependencies on systems and used technology, but also the nature of communication by decoupling business processes by the asynchronous messages.</p>
<p>Message queues are queues where messages are sent to that are consumed later by one consumer at a time. In enterprise systems, message queues are typically realized in a <strong>message-oriented middleware</strong> (<strong>MOM</strong>). We have seen these MOM solutions quite regularly in the past with message queue systems such as ActiveMQ, RabbitMQ, or WebSphere MQ.</p>
<p>The publish-subscribe pattern describes consumers that subscribe to a topic and receive messages that are published to the topic. The subscribers register for the topic and receives messages that are sent by the publisher. This concept scales well for a bigger number of peers involved. Message-oriented middleware typically can be used to take advantages of both message queuing and publish-subscribe approaches.</p>
<p>However, as well as for asynchronous communication in general, message-oriented solutions also have certain shortcomings. The reliable delivery of messages is a <span>first aspect to be aware of is</span>. Producers send the messages in an asynchronous, <em>fire and forget</em> fashion. Engineers have to be aware of the defined and supported semantics of message delivery, whether a message will be received <em>at most once</em>, <em>at least once,</em> or <em>exactly once</em>. Choosing technology that supports certain delivery semantics, especially <em>exactly once</em> semantics, will have an impact on scalability and throughput. In <a href="">Chapter 8</a>, <em>Microservices and System Architecture</em> we will cover that topic in detail when discussing event-driven applications.</p>
<p>For Java EE applications, the <strong>Java Message Service</strong> (<strong>JMS</strong>) API can be used to integrate message-oriented middleware solutions. The JMS API supports solutions for both message queuing and publish-subscribe approaches. It only defines interfaces and is implemented with the actual message-oriented middleware solutions.</p>
<p>However, the JMS API does not have a high developer acceptance and, at the time of writing, is arguably not used that much in current systems. Compared to other standards, the programming model is not that straightforward and productive. Another trend in message-oriented communication is that instead of traditional MOM solutions, more lightweight solutions are gaining popularity. As of today, a lot of these message-oriented solutions are integrated using proprietary APIs. An example of such a solution is Apache Kafka, which utilizes both message queuing and the publish-subscribe model. <a href="">Chapter 8</a>, <em>Microservices and System Architecture</em> shows the integration of Apache Kafka as an example of a MOM solution into Java EE applications.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Server-sent events</h1>
                </header>
            
            <article>
                
<p><strong>Server-sent events</strong> (<strong>SSE</strong>) is an example of an asynchronous, HTTP-based, publish-subscribe technology. It offers an easy-to-use one-way streaming communication protocol. Clients can register for a topic by requesting a HTTP resource that leaves an open connection. The server sends messages to connected clients over these active HTTP connections. Clients cannot directly communicate back, but can only open and close connections to the streaming endpoint. This lightweight solution fits use cases with broadcast updates, such as social media updates, stock prices, or news feeds.</p>
<p>The server pushes UTF-8 text-based data as content type <kbd>text/event-stream</kbd> to clients who previously registered for the topics. The following shows the format of the events:</p>
<pre>data: This is a message

event: namedmessage
data: This message has an event name

id: 10
data: This message has an id which will be sent as
 'last event ID' if the client reconnects</pre>
<p>The fact that server-sent events are based on HTTP makes them easy to integrate in existing networks or developer tools. SSE natively support event IDs and reconnects. Clients that reconnect to a streaming endpoint provide the last received event ID to continue subscribing where they left off.</p>
<p>JAX-RS supports server-sent events on both the server-side and client-side. SSE streaming endpoints are defined using JAX-RS resources as follows:</p>
<pre>import javax.ws.rs.DefaultValue;
import javax.ws.rs.HeaderParam;
import javax.ws.rs.InternalServerErrorException;
import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.sse.*;

@Path("events-examples")
@Singleton
public class EventsResource {

    <strong>@Context
    Sse sse;</strong>

    <strong>private SseBroadcaster sseBroadcaster;</strong>
    private int lastEventId;
    private List&lt;String&gt; messages = new ArrayList&lt;&gt;();

    @PostConstruct
    public void initSse() {
        <strong>sseBroadcaster = sse.newBroadcaster();

        sseBroadcaster.onError((o, e) -&gt; {
            ...
        });</strong>
    }

    @GET
    @Lock(READ)
    @Produces(MediaType.SERVER_SENT_EVENTS)
    public void itemEvents(@HeaderParam(HttpHeaders.LAST_EVENT_ID_HEADER)
                           @DefaultValue("-1") int lastEventId,
                           <strong>@Context SseEventSink eventSink</strong>) {

        if (lastEventId &gt;= 0)
            replayLastMessages(lastEventId, eventSink);

        <strong>sseBroadcaster.register(eventSink);</strong>
    }

    private void replayLastMessages(int lastEventId, SseEventSink eventSink) {
        try {
            for (int i = lastEventId; i &lt; messages.size(); i++) {
                <strong>eventSink.send(createEvent(messages.get(i), i + 1));</strong>
            }
        } catch (Exception e) {
            throw new InternalServerErrorException("Could not replay messages ", e);
        }
    }

    private OutboundSseEvent createEvent(String message, int id) {
        return <strong>sse.newEventBuilder().id(String.valueOf(id)).data(message).build()</strong>;
    }

    @Lock(WRITE)
    public void onEvent(@Observes DomainEvent domainEvent) {
        String message = domainEvent.getContents();
        messages.add(message);

        OutboundSseEvent event = createEvent(message, ++lastEventId);

        <strong>sseBroadcaster.broadcast(event);</strong>
    }
}</pre>
<p>The <kbd>text/event-stream</kbd> content type is used for Server-sent events. The registered <kbd>SseEventSink</kbd> instructs JAX-RS to keep the client connection open for future events sent through the broadcaster. The SSE standard defines that the <kbd>Last-Event-ID</kbd> header controls where the event stream will continue. In this example, the server will resend the messages that have been published while clients were disconnected.</p>
<p>The <kbd>itemEvents()</kbd> method implements the streaming registration and immediately resends missing events to that client if required. After the output is registered the client, together will all other active clients, will receive future messages that are created using <kbd>Sse</kbd>.</p>
<p>The asynchronous integration into our enterprise application happens via the observed <kbd>DomainEvent</kbd>. Every time a CDI event of this type is fired somewhere in the application, active SSE clients will receive a message.</p>
<p>JAX-RS also supports the ability to consume SSE. <kbd>SseEventSource</kbd> offers a functionality to open a connection to an SSE endpoint. It registers an event listener that is called as soon as a message arrives:</p>
<pre>import java.util.function.Consumer;

public class SseClient {

    private final WebTarget target = ClientBuilder.newClient().target("...");
    <strong>private SseEventSource eventSource;</strong>

    public void connect(Consumer&lt;String&gt; dataConsumer) {
        <strong>eventSource = SseEventSource.target(target).build();</strong>

        <strong>eventSource.register(</strong>
                item -&gt; dataConsumer.accept(item.readData()),
                Throwable::printStackTrace,
                () -&gt; System.out.println("completed")<strong>);</strong>

        <strong>eventSource.open();</strong>
    }

    public void disconnect() {
        if (eventSource != null)
            <strong>eventSource.close();</strong>
    }
}</pre>
<p>After the <kbd>SseEventSource</kbd> successfully opens the connection, the current thread continues. The listener, in this case, <kbd>dataConsumer#accept</kbd>, will be called as soon as events arrive. <kbd>SseEventSource</kbd> will handle all required handling defined by the SSE standard. This includes, for example, reconnecting after connection loss and sending a <kbd>Last-Event-ID</kbd> header.</p>
<p>Clients also have the possibility for more sophisticated solutions with manually controlling headers and reconnects. Therefore the <kbd>SseEventInput</kbd> type is requested with the <kbd>text/event-stream</kbd> content type from a conventional web target. For more information, please refer to the JAX-RS specification.</p>
<p>Server-sent events offer an easy-to-use one-way streaming solution over HTTP that integrates itself well into the Java EE technology.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">WebSocket</h1>
                </header>
            
            <article>
                
<p>Server-sent events compete with the more powerful <strong>WebSocket</strong> technology which supports bi-directional communication. WebSocket which has been standardized by the IETF is another example for message-oriented, publish-subscribe communication. It was intended to be used in browser-based applications, but can be used for any client-server exchange of messages. WebSocket usually uses the same ports as the HTTP endpoints, but with its own TCP-based protocol.</p>
<p>WebSocket is supported in Java EE as part of the <strong>Java API for WebSocket</strong>. It includes server, and client-side support.</p>
<p>The programming model for server-side endpoint definitions again matches the overall Java EE picture. Endpoints can be defined using a programmatic or declarative, annotation-driven approach. The latter defines annotations that are added on endpoint classes, similar to the programming model of JAX-RS resources:</p>
<pre>import javax.websocket.*;
import javax.websocket.server.ServerEndpoint;

<strong>@ServerEndpoint</strong>(value = "/chat", decoders = ChatMessageDecoder.class, encoders = ChatMessageEncoder.class)
public class ChatServer {

    @Inject
    ChatHandler chatHandler;

    <strong>@OnOpen</strong>
    public void openSession(Session session) {
        ...
    }

    <strong>@OnMessage</strong>
    public void onMessage(ChatMessage message, Session session) {
        chatHandler.store(message);
    }

    <strong>@OnClose</strong>
    public void closeSession(Session session) {
        ...
    }
}</pre>
<p>The annotated methods of the server endpoint class will be called on initiated sessions, arriving messages and closing connections, respectively. The sessions represent the conversation between two endpoints.</p>
<p>WebSocket endpoints can define decoders and encoders, respectively, in order to map custom Java types to binary or plain text data and vice versa. This example specifies a custom type for chat messages which is mapped using custom decoders and encoders. Similar to JAX-RS, WebSocket ships with default serialization capabilities for usual serializable Java types such as strings. The following code demonstrates an encoder for our custom domain type:</p>
<pre>import javax.websocket.EncodeException;
import javax.websocket.Encoder;
import javax.websocket.EndpointConfig;

public class ChatMessageEncoder implements <strong>Encoder.Binary&lt;ChatMessage&gt;</strong> {

    @Override
    public <strong>ByteBuffer encode(ChatMessage object)</strong> throws EncodeException {
        ...
    }

    ...
}</pre>
<p>These types correspond to the <kbd>MessageBodyWriter</kbd> and <kbd>MessageBodyReader</kbd> types in the JAX-RS standard. The following shows the corresponding message decoder:</p>
<pre>import javax.websocket.DecodeException;
import javax.websocket.Decoder;
import javax.websocket.EndpointConfig;

public class ChatMessageDecoder implements <strong>Decoder.Binary&lt;ChatMessage&gt;</strong> {

    @Override
    public <strong>ChatMessage decode(ByteBuffer bytes)</strong> throws DecodeException {
        ...
    }

    ...
}</pre>
<p>Client endpoints are defined similarly to server endpoints. The difference is that only WebSocket servers listen to new connection on a path.</p>
<p>The client functionality of the WebSocket API can not only be used in an enterprise environment, but also in Java SE applications. The same is true for JAX-RS on the client-side. Implementing a WebSocket client endpoint is left as an exercise to the reader.</p>
<p>WebSocket, as well as server-sent events, offers well-integrated, message-oriented technologies. What applications choose to use, of course, highly depends on the business requirements, existing environments, and the nature of the communication.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Connecting enterprise technology</h1>
                </header>
            
            <article>
                
<p>Some external enterprise systems that need to be integrated from an application don't offer standard interfaces or Java APIs. Legacy systems as well as other systems being used within the organization may fall under this category. The <strong>Java EE Connector Architecture</strong> (<strong>JCA</strong>) API can integrate these so-called <strong>Enterprise Information Systems</strong> (<strong>EIS</strong>) into Java EE applications. Examples of EISs include transaction processing systems, messaging systems, or proprietary databases.</p>
<p>JCA resource adapters are deployable EE components that integrate information systems into the application. They include contracts such as connections, transactions, security, or life cycle management. The information system can be integrated better into the application compared to other connection technologies. Resource adapters are packaged as <strong>Resource Adapter Archives</strong> (<strong>RAR</strong>) and can be accessed within the application using the functionality of the <kbd>javax.resource</kbd> package and its sub-packages. Some EIS vendors provide resource adapters for their systems. For developing and deploying resource adapters, refer to the JCA specification.</p>
<p>JCA offers a variety of integration possibilities for external information systems. However, the standard is not widely used and has not a high acceptance by enterprise engineers. Developing resource adapters is quite cumbersome, the JCA API is not well known among developers, and companies usually choose to integrate systems in other ways. In fact, it should be considered whether the effort of writing resource adapters is preferred over integrating information systems using other integration technology. Other solutions include integration frameworks such as Apache Camel or Mule ESB.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Database systems</h1>
                </header>
            
            <article>
                
<p>The majority of enterprise applications use database systems as their persistence. Databases are at the core of the enterprise system, containing the application's data. As of today, data is already one the most important commodities. Companies spend a lot of time and effort gathering, securing, and using data.</p>
<p>There are several ways in which a state is represented in enterprise systems; however, relational databases are still the most popular. The concepts and usages are well understood and well integrated in enterprise technology.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Integrating RDBMS systems</h1>
                </header>
            
            <article>
                
<p>The <strong>Java Persistence API</strong> (<strong>JPA</strong>) is used to integrate relational database systems into enterprise applications. Compared to outdated approaches of the J2EE era, JPA integrates well with domain models built after the concepts of Domain-Driven Design. Persisting entities does not introduce much overhead and does not set many constraints on the model. This enables constructing the domain model first, focusing on business aspects, and integrating the persistence layer afterwards.</p>
<p>Persistence is integrated into the domain as a necessary part of handling the business use case. Depending on the complexity of use cases, the persistence functionality is invoked either in dedicated controls or directly in the boundary. Domain-Driven Design defines the concept of repositories which, as mentioned before, matches the responsibilities of JPA's entity manager well. The entity manager is used to obtain, manage, and persist entities and to perform queries. Its interface was abstracted with the intention to be used in a general way.</p>
<p>In the J2EE era, the <strong>data access object</strong> (<strong>DAO</strong>) pattern was used heavily. The motivation behind this pattern was to abstract and encapsulate functionality to access data. This includes the type of the accessed storage system, such as RDBMSs, object-oriented databases, LDAP systems, or files. Whereas the reasoning certainly makes sense, following the pattern in times of Java EE is not required for the majority of use cases.</p>
<p>Most enterprise applications use relational databases that support both SQL and JDBC. JPA already abstracts RDBMS systems so that engineers usually don't deal with vendor specifics. Changing the nature of the used storage system to something other than a RDBMS will impact the application's code anyway. Mapping domain entity types into storage does not require the use of transfer objects anymore, since JPA integrates well into domain models. Directly mapping domain entity types is a productive approach to integrate persistence without much overhead. For straightforward use cases, such as persisting and retrieving entities, a DAO approach is therefore not required. However, for complex database queries involved, it does make sense to encapsulate that functionality into separate controls. These repositories then contain the whole persistence for the specific entity types. It is advisable though to start with a straightforward approach and only refactor the persistence into a single point of responsibility if the complexity increases.</p>
<p>Boundaries or controls, respectively, obtain an entity manager to manage the persistence of entities. The following shows how to integrate an entity manager into a boundary:</p>
<pre>import javax.persistence.EntityManager;
import javax.persistence.PersistenceContext;

@Stateless
public class PersonAdministration {

    <strong>@PersistenceContext
    EntityManager entityManager;</strong>

    public void createPerson(Person person) {
        <strong>entityManager.persist(person);</strong>
    }

    public void updateAddress(long personId, Address newAddress) {
        <strong>Person person = entityManager.find(Person.class, personId);</strong>

        if (person == null)
            throw new IllegalArgumentException("Could not find person with ID " + personId);

        person.setAddress(newAddress);
    }
}</pre>
<p>The <kbd>persist()</kbd> operation on creating new persons makes the person a managed entity. It will be added into the database once the transaction commits and can be obtained later using its assigned ID. The <kbd>updateAddress()</kbd> method showcases this. A person entity is retrieved using its ID into a managed entity. All changes in the entity; for example, changing its address will be synchronized into the database at transaction commit time.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Mapping domain models</h1>
                </header>
            
            <article>
                
<p>As mentioned before, entities, aggregates, and value objects are integrated with JPA without introducing many constraints on the model. Entities as well as aggregates, are represented as JPA entities:</p>
<pre>import javax.persistence.*;

<strong>@Entity
@Table(name = "persons")</strong>
public class Person {

    <strong>@Id
    @GeneratedValue</strong>
    private long id;

    <strong>@Basic(optional = false)</strong>
    private String name;

    <strong>@Embedded</strong>
    private Address address;

    ...
}

<strong>@Embeddable</strong>
public class Address {

    <strong>@Basic(optional = false)</strong>
    private String streetName;

    <strong>@Basic(optional = false)</strong>
    private String postalCode;

    <strong>@Basic(optional = false)</strong>
    private String city;

    ...
}</pre>
<p>The person type is an entity. It needs to be identifiable using an ID that will be the primary key in the <kbd>persons</kbd> table. Every property is mapped into the database in a certain way, depending on the nature of the type and relation. The person's name is a simple text-based column.</p>
<p>The address is a value object that is not identifiable. From a domain perspective, it does not matter <em>which</em> address we refer to, as long as the values match. Therefore the address is not an entity and thus is not mapped into JPA as such. Value objects can be implemented via JPA embeddable types. The properties of these types will be mapped to additional columns in the table of the entity that refers to them. Since the person entity includes a specific address value, the address properties will be part of the persons table.</p>
<p>Root aggregates that consist of several entities can be realized by configuring the relations to be mapped in appropriate database columns and tables, respectively. For example, a car consists of an engine, one or more seats, a chassis, and many other parts. Some of them are entities that potentially can be identified and accessed as individual objects. The car manufacturer can identify the whole car or just the engine and repair or replace it accordingly. The database mapping can be placed on top of this existing domain model as well.</p>
<p>The following code snippets show the car domain entity, including JPA mapping:</p>
<pre>import javax.persistence.CascadeType;
import javax.persistence.OneToMany;
import javax.persistence.OneToOne;

<strong>@Entity
@Table(name = "cars")</strong>
public class Car {

    <strong>@Id
    @GeneratedValue</strong>
    private long id;

    <strong>@OneToOne(optional = false, cascade = CascadeType.ALL)</strong>
    private Engine engine;

    <strong>@OneToMany(cascade = CascadeType.ALL)</strong>
    private Set&lt;Seat&gt; seats = new HashSet&lt;&gt;();

    ...
}</pre>
<p>The seats are included in a collection. The <kbd>HashSet</kbd> is instantiated for new <kbd>Car</kbd> instances; Java collections that are <kbd>null</kbd> should be avoided.</p>
<p>The engine represents another entity in our domain:</p>
<pre>import javax.persistence.EnumType;
import javax.persistence.Enumerated;

<strong>@Entity
@Table(name = "engines")</strong>
public class Engine {

    <strong>@Id
    @GeneratedValue</strong>
    private long id;

    <strong>@Basic(optional = false)
    @Enumerated(EnumType.STRING)</strong>
    private EngineType type;

    private double ccm;

    ...
}</pre>
<p>The car seats represent entities as well, identifiable by their ID:</p>
<pre><strong>@Entity
@Table(name = "seats")</strong>
public class Seat {

    <strong>@Id
    @GeneratedValue</strong>
    private long id;

    <strong>@Basic(optional = false)
    @Enumerated(EnumType.STRING)</strong>
    private SeatMaterial material;

    <strong>@Basic(optional = false)
    @Enumerated(EnumType.STRING)</strong>
    private SeatShape shape;

    ...
}</pre>
<p>All entities, referenced from other entities or standalone, need to be managed in the persistence context. If the engine of a car is replaced by a new entity, this needs to be persisted separately as well. The persist operations are either called explicitly on the individual entities or cascaded from object hierarchies. The cascades are specified on the entity relations. The following code shows the two approaches of persisting a new car engine from a service:</p>
<pre>public void replaceEngine(long carIdentifier, Engine engine) {
    <strong>Car car = entityManager.find(Car.class, carIdentifier);</strong>
    car.replaceEngine(engine);

    // car is already managed, engine needs to be persisted
    <strong>entityManager.persist(engine);</strong>
}</pre>
<p>After loading the car from its identifier, it is a managed entity. The engine still needs to be persisted. The first approach persists the engine explicitly in the service.</p>
<p>The second approach cascades a merge operation, that also handles new entities, from the car aggregate:</p>
<pre>public void replaceEngine(long carIdentifier, Engine engine) {
    Car car = entityManager.find(Car.class, carIdentifier);
    car.replaceEngine(engine);

    // merge operation is applied on the car and all cascading relations
    <strong>entityManager.merge(car);</strong>
}</pre>
<p>It is highly advisable to apply the latter approach. Aggregate roots are responsible to maintain an integer and consistent state of the overall state. The integrity is achieved more reliably when all operations are initiated and cascaded from the root entity.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Integrating database systems</h1>
                </header>
            
            <article>
                
<p>An entity manager manages persistent entities within a persistence context. It uses a single persistence unit that corresponds to a database instance. Persistence units include all managed entities, entity managers, and mapping configurations. If only one database instance is accessed then the entity manager can be obtained directly, as shown in the previous example. The persistence context annotation then refers to the sole persistence unit.</p>
<p>Persistence units are specified in the <kbd>persistence.xml</kbd> descriptor file, which resides under the <kbd>META-INF</kbd> directory. This is one of the few cases in modern Java EE where XML-based configuration is used. The persistence descriptor defines the persistence unit and optional configuration. T<span>he datasource is referenced only by its JNDI name i</span>n order to separate the configuration for accessing the database instance from the application. The actual configuration of the datasource is specified in the application server. If the application server contains only one application that uses a single database, developers can use the application server's default datasource. In that case, the datasource name can be omitted.</p>
<p>The following snippet shows an example <kbd>persistence.xml</kbd> file showing a single persistence unit using the default datasource:</p>
<pre style="padding-left: 30px">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;persistence version="2.2" 
        
        xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/persistence
        http://xmlns.jcp.org/xml/ns/persistence/persistence_2_2.xsd"&gt;
    <strong>&lt;persistence-unit name="vehicle" transaction-type="JTA"&gt;
    &lt;/persistence-unit&gt;</strong>
&lt;/persistence&gt;</pre>
<p>This example is already sufficient for a majority of enterprise applications.</p>
<p>The next snippet demonstrates a <kbd>persistence.xml</kbd> file containing several persistence unit definitions for multiple datasources:</p>
<pre>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;persistence version="2.2" 
        
        xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/persistence
        http://xmlns.jcp.org/xml/ns/persistence/persistence_2_2.xsd"&gt;

    &lt;persistence-unit name="<strong>vehicle</strong>" transaction-type="JTA"&gt;
        <strong>&lt;jta-data-source&gt;jdbc/VehicleDB&lt;/jta-data-source&gt;</strong>
    &lt;/persistence-unit&gt;
    &lt;persistence-unit name="<strong>order</strong>" transaction-type="JTA"&gt;
        <strong>&lt;jta-data-source&gt;jdbc/OrderDB&lt;/jta-data-source&gt;</strong>
    &lt;/persistence-unit&gt;
&lt;/persistence&gt;</pre>
<p>Injecting entity managers need to reference the desired persistence unit by its name. Entity managers always correspond to a single persistence context that uses a single persistence unit. The following <kbd>CarManagement</kbd> definition shows the previous example in an environment of several persistence units:</p>
<pre>@Stateless
public class CarManagement {

    <strong>@PersistenceContext(unitName = "vehicle")
    EntityManager entityManager;</strong>

    public void replaceEngine(long carIdentifier, Engine engine) {
        Car car = entityManager.find(Car.class, carIdentifier);
        car.replaceEngine(engine);

        // merge operation is applied on the car and all cascading relations
        entityManager.merge(car);
    }
}</pre>
<p>Optionally, injection of specific entity managers can be simplified by using CDI producer fields. By explicitly emitting entity managers using custom qualifiers, injection can be implemented in a typesafe way:</p>
<pre>public class EntityManagerExposer {

    @Produces
    <strong>@VehicleDB</strong>
    @PersistenceContext(unitName = "<strong>vehicle</strong>")
    private EntityManager vehicleEntityManager;

    @Produces
    <strong>@OrderDB</strong>
    @PersistenceContext(unitName = "<strong>order</strong>")
    private EntityManager orderEntityManager;

}</pre>
<p>The emitted entity managers can be injected, now using <kbd>@Inject</kbd> and the typesafe qualifier:</p>
<pre>public class CarManagement {

    <strong>@Inject
    @VehicleDB</strong>
    EntityManager entityManager;

    ...
}</pre>
<p>This approach can simplify usage in environments where different entity managers are injected in many locations.</p>
<p>There are also other possible approaches to map domain models to databases. Database mapping can also be defined in XML files. However, past approaches in J2EE, have shown that declarative configuration using annotations allows a more productive usage. Annotating domain models also provides a better overview.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Transactions</h1>
                </header>
            
            <article>
                
<p>Persistence operations need to be performed in a transaction context. Managed entities that are modified are synchronized into the datasource at transaction commit time. Therefore, a transaction spans the modifying action, and typically the whole business use case.</p>
<p>If the boundary is implemented as EJB, a transaction is active during the business method execution by default. This matches the typical scenarios for JPA persistence being involved in the application.</p>
<p>The same behavior is realized with CDI managed beans that annotate their methods with <kbd>@Transactional</kbd>. Transactional boundaries specify a specific behavior once the business method is entered. By default, this behavior defines that a transaction is <kbd>REQUIRED</kbd>; that is, a transaction is either created or reused if the calling context is already executed within an active transaction.</p>
<p><kbd>REQUIRES_NEW</kbd> behavior will always start a new transaction that is executed individually and resumes a potential previous transaction once the method and the new transaction has completed. This is useful for longer-running business processes that handle a great amount of data that can be processed in several, individual transactions.</p>
<p>Other transaction behavior is possible as well, such as enforcing an already active transaction or not supporting transactions at all. This is configured by annotating business methods with <kbd>@Transactional</kbd>. EJBs implicitly define <kbd>REQUIRED</kbd> transactions.</p>
<p>RDBMS systems integrate well into Java EE applications. Following convention over configuration, the typical use cases are implemented in a productive way.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Relational databases versus NoSQL</h1>
                </header>
            
            <article>
                
<p>In the past years, a lot has happened in database technology, especially with regard to distribution. Traditional relational databases are, however, still the most used choice as of today. Their most significant characteristics are the table-based data schemas and the transactional behavior.</p>
<p><strong>NoSQL</strong> (<strong>non SQL</strong> or <strong>not only SQL</strong>) database systems provide data in other forms than relational tables. These forms include document stores, key-value stores, column-oriented stores, and graph databases. Most of them compromise consistency in favor of availability, scalability, and network partition tolerance. The idea behind NoSQL not making use of full support of relational table structures, <strong>ACID</strong> transactions (<strong>Atomicity, Consistency, Isolation, Durability</strong>), and foreign keys as well as table joins, was to support horizontal scalability. This goes back to the well-known CAP theorem. The <strong>CAP</strong> theorem (<strong>Consistency, Availability, Partition tolerance</strong>) claims that it is impossible for distributed datastores to guarantee at most two of the three specified constraints. Since distributed networks do not operate reliably (partition tolerance), systems can basically choose whether they want to guarantee consistency or horizontal scalability. Most NoSQL databases choose scalability over consistency. This fact needs to be considered when choosing a datastore technology.</p>
<p>The reason behind NoSQL systems lays in the shortcomings of relational databases. The biggest issue is that relational databases supporting ACID don't scale well horizontally. Database systems are at the core of the enterprise system, usually accessed by multiple application servers. Data that needs to be updated consistently needs to be synchronized in a central place. This synchronization happens in the technical transaction of the business use case. Database systems that are replicated and should both retain consistency would need to maintain distributed transactions in-between themselves. However, distributed transactions do not scale and arguably do not reliably work in every solution.</p>
<p>Still, relational database systems scale well enough for the majority of enterprise applications. If horizontal scalability becomes an issue so that a centralized database is not an option anymore, one solution is to split up persistence using approaches such as event-driven architectures. We will cover that topic in detail in <a href="">Chapter 8</a>, <em>Microservices and System Architecture</em>.</p>
<p>NoSQL databases also have some shortcomings, especially with regard to transactional behavior. It highly depends on the business requirements of the application as to whether data needs to be persistent in a transactional approach. Experience shows that in almost all enterprise systems at least some parts of persistence demand reliability; that is, transactions. However, sometimes there are different categories of data. Whereas certain domain models are more crucial and require transactional handling, other data may be recalculated or regenerated; for example, statistics, recommendations, or cached data. For the latter type of data, NoSQL datastores may be a good choice.</p>
<p>At the time of writing, no NoSQL system has emerged as a standard or de facto standard yet. Many of them also vary widely in their concepts and usages. There is also no standard targeting NoSQL included in Java EE 8.</p>
<p>Therefore, accessing NoSQL systems is usually realized using the Java APIs provided by the vendors. These make use of lower level standards such as JDBC or their proprietary APIs.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Cross-cutting concerns</h1>
                </header>
            
            <article>
                
<p>Enterprise applications require some technically motivated cross-cutting concerns. Examples of these are transactions, logging, caching, resilience, monitoring, security, and other non-functional requirements. Even for systems that solely target business, use cases need some amount of <em>technical plumbing</em>.</p>
<p>We just saw in the handling of transactions, an example of a non-functional cross-cutting concern. Java EE doesn't require much time and effort spent by engineers to integrate transactional behavior. The same is true for other cross-cutting concerns.</p>
<p>Java EE interceptors is a prime example for cross-cutting concerns. Following the concept of aspect-oriented programming, the implementation of the cross-cutting concern is separated from the decorated functionality. Methods of managed beans can be decorated to define interceptors, which interrupt the execution and perform the desired task. Interceptors have full control over the execution of the intercepted method including returned values and thrown exceptions. To match the idea of other APIs, interceptors are integrated in a lightweight fashion, not setting many constraints on the decorated functionality.</p>
<p>The previous example of transparently handling errors in a HTTP client class showed the usage of an interceptor. Business methods also can be decorated using custom interceptor bindings. The following demonstrates a business motivated process tracking aspect realized via custom annotations:</p>
<pre>@Stateless
public class CarManufacturer {

    ...

    <strong>@Tracked(ProcessTracker.Category.MANUFACTURER)</strong>
    public Car manufactureCar(Specification spec) {
        ...
    }
}</pre>
<p>The <kbd>Tracked</kbd> annotation defines a so-called interceptor binding. The annotation parameter represents a non-binding value that configures the interceptor:</p>
<pre>import javax.enterprise.util.Nonbinding;
import javax.interceptor.InterceptorBinding;

<strong>@InterceptorBinding</strong>
@Inherited
@Documented
@Target({TYPE, METHOD})
@Retention(RUNTIME)
public @interface Tracked {

    <strong>@Nonbinding
    ProcessTracker.Category value();</strong>
}</pre>
<p>The interceptor is activated via the binding annotation:</p>
<pre>import javax.annotation.Priority;

<strong>@Tracked(ProcessTracker.Category.UNUSED)
@Interceptor
@Priority(Interceptor.Priority.APPLICATION)</strong>
public class TrackingInterceptor {

    @Inject
    ProcessTracker processTracker;

    <strong>@AroundInvoke</strong>
    public <strong>Object aroundInvoke(InvocationContext context)</strong> throws Exception {
        Tracked tracked = resolveAnnotation(context);

        if (tracked != null) {
            ProcessTracker.Category category = tracked.value();
            processTracker.track(category);
        }

        return <strong>context.proceed()</strong>;
    }

    private Tracked resolveAnnotation(InvocationContext context) {
        Function&lt;AnnotatedElement, Tracked&gt; extractor = c -&gt; c.getAnnotation(Tracked.class);
        Method method = context.getMethod();

        Tracked tracked = extractor.apply(method);
        return tracked != null ? tracked : extractor.apply(method.getDeclaringClass());
    }
}</pre>
<p>By default, interceptors bound via interceptor bindings are not enabled. An interceptor must either be explicitly enabled via specifying a priority via <kbd>@Priority</kbd>, like demonstrated in this example. Another possibility is to activate it in the <kbd>beans.xml</kbd> descriptor.</p>
<pre>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans 
        
        xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee
        http://xmlns.jcp.org/xml/ns/javaee/beans_1_1.xsd"
        bean-discovery-mode="all"&gt;
    <strong>&lt;interceptors&gt;
        &lt;class&gt;com.example.cars.processes.TrackingInterceptor&lt;/class&gt;
    &lt;/interceptors&gt;</strong>
&lt;/beans&gt;</pre>
<p>Interceptors can use reflection to retrieve potential annotation parameters, such as the process tracking category in the example. Interceptor bindings can be placed either on method or class level.</p>
<p>Interceptors decorate behavior on methods without tightly coupling them. They especially make sense for scenarios where the cross-cutting aspects need to be added to a lot of functionality.</p>
<p>Interceptors are similar to CDI decorators. Both concepts decorate managed beans with custom behavior that is encapsulated in a different place. The difference is that decorators are meant to be used for decorating business logic, which is also mostly specific to the decorated bean. Interceptors, however, are mostly used for technical concerns. They offer a broader usage, making it possible to annotate all kind of beans. Both concepts are a helpful functionality to realize cross-cutting aspects.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Configuring applications</h1>
                </header>
            
            <article>
                
<p>Application behavior that cannot be hardcoded but needs to be defined dynamically is realized via configuration. It depends on the application and the nature of the dynamic behavior how the configuration is implemented.</p>
<p>What aspects need to be configurable? Is it sufficient to define configuration files that are already part of the shipped artifact? Does the packaged application need to be configurable from the outside? Is there a requirement for changing behavior during runtime?</p>
<p>Configuration that does not need to change after the application has been built can easily be implemented in the project itself, that is, in the source code. Assuming we require more flexibility.</p>
<p>In a Java environment, the arguably most straightforward way is to provide property files that contain key-value pairs of configuration values. The configured values need to be retrieved in order to be used in the code. It certainly is possible to write Java components that programmatically provide property values. In a Java EE environment, dependency injection will be used to retrieve such components. At the time of writing, no Java EE standard supports out-of-the-box configuration yet. However, using CDI features provide this functionality in a few lines of code. The following shows a possible solution, that enables to inject configuration values identified by keys:</p>
<pre>@Stateless
public class CarManufacturer {

    @Inject
    <strong>@Config("car.default.color")</strong>
    String defaultColor;

    public Car manufactureCar(Specification spec) {
        // use defaultColor
    }
}</pre>
<p>In order to unambiguously inject configuration values, for example, provided as strings, qualifier such as <kbd>@Config</kbd> are required. This custom qualifier is defined in our application. The goal is to inject values identified by the provided key:</p>
<pre><strong>@Qualifier</strong>
@Documented
@Retention(RUNTIME)
public @interface Config {

    <strong>@Nonbinding</strong>
    <strong>String value();</strong>
}</pre>
<p>A CDI producer is responsible for retrieving and providing specific configuration values:</p>
<pre>import javax.enterprise.inject.spi.InjectionPoint;
import java.io.*;
import java.util.Properties;

@ApplicationScoped
public class ConfigurationExposer {

    private final Properties properties = new Properties();

    @PostConstruct
    private void initProperties() {
        try (InputStream inputStream = ConfigurationExposer.class
                .getResourceAsStream("/application.properties")) {
            properties.load(inputStream);
        } catch (IOException e) {
            throw new IllegalStateException("Could not init configuration", e);
        }
    }

    @Produces
    <strong>@Config("")</strong>
    public String exposeConfig(<strong>InjectionPoint injectionPoint</strong>) {
        Config config = injectionPoint.getAnnotated().getAnnotation(Config.class);
        if (config != null)
            return properties.getProperty(config.value());
        return null;
    }
}</pre>
<p>The reference key in the <kbd>@Config</kbd> annotation is a non-binding attribute since all injected values are handled by our CDI producer method. The <kbd>InjectionPoint</kbd> provided by CDI contains information about the location where the dependency injection is specified. The producer retrieves the annotation with the actual configuration key and uses it to look up the configured property. The properties file <kbd>application.properties</kbd> is expected to reside in the classpath. This approach comprises configuration values that need to be available at runtime. Since the properties map is initiated once, the values will not change after they have been loaded. The configuration exposer bean is application-scoped to only load the required values into the properties map once.</p>
<p>If a scenario requires changing the configuration at runtime, the producer method would have to reload the configuration file. The scope of the producer method defines the life cycle of the configured value, how often the method will be called.</p>
<p>This example implements configuration using plain Java EE. There are some third-party CDI extensions available that provide similar, as well as more sophisticated, functionality. At the time of writing, an often used example for such a solution is Apache Deltaspike.</p>
<p>Besides the enterprise technology, an important aspect to consider, as well, is the environment in which the container runs; especially, as container technologies set certain constraint on the runtime environment. <a href="a24f88d4-1af2-4746-91c9-9717d077dd27.xhtml">Chapter 5</a>, <em>Container and Cloud Environments with Java EE</em> covers the topic of modern environments and their impact on the Java EE runtime, including how to design dynamic configuration.</p>
<p>The power of CDI producers lays in their flexibility. Any source of configuration can easily be attached to expose configured values.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Caching</h1>
                </header>
            
            <article>
                
<p>Caching is a technically motivated cross-cutting concern that becomes interesting once applications face issues in performance, such as slow external systems, expensive and cachable calculations, or huge amount of data. In general, caching aims to lower response times by storing data that is costly to retrieve in a potentially faster cache. A typical example is to hold responses of external systems or databases in memory.</p>
<p>Before implementing caching, a question that needs to be asked is whether a cache is required or even possible. Some data doesn't qualify for being cached, such as data that needs to be calculated on demand. If the situation and data is potentially eligible for caching, it depends on the situation if another solution other than caching is possible. Caching introduces duplication and the possibility of receiving outdated information and, generally speaking, for the majority of enterprise applications, should be avoided. For example, if database operations are too slow, it is advisable to consider whether other means, such as indexing, can help.</p>
<p>It depends a lot on the situation and what caching solutions are required. In general, caching directly in memory in the application already solves a lot of scenarios.</p>
<p>The most straightforward way of caching information is in a single place in the application. Singleton beans perfectly fit this scenario. A data structure that naturally fits the purpose of a cache is a Java <kbd>Map</kbd> type.</p>
<p>The <kbd>CarStorage</kbd> code snippet presented earlier, represents a singleton EJB with bean-managed concurrency containing a thread-safe map to store data. This storage is injected and used in other managed beans:</p>
<pre>@Singleton
@ConcurrencyManagement(ConcurrencyManagementType.BEAN)
public class CarStorage {

    private final Map&lt;String, Car&gt; cars = new ConcurrentHashMap&lt;&gt;();

    public void store(Car car) {
        cars.put(car.getId(), car);
    }

    public Car retrieve(String id) {
        return cars.get(id);
    }
}</pre>
<p>If more flexibility is required, for example pre-loading cache contents from a file, the bean can control the life cycle using post-construct and pre-destroy methods. To guarantee functionality to be executed during application startup time, the EJB is annotated using <kbd>@Startup</kbd>:</p>
<pre>@Singleton
<strong>@Startup</strong>
@ConcurrencyManagement(ConcurrencyManagementType.BEAN)
public class CarStorage {

    ...

    <strong>@PostConstruct</strong>
    private void loadStorage() {
        // load contents from file
    }

    <strong>@PreDestroy</strong>
    private void writeStorage() {
        // write contents to file
    }
}</pre>
<p>Interceptor can be used for adding cache in a transparent way, without needing to programmatically inject and use a cache. The interceptor interrupts the execution before a business method is being called and will return cached values instead. The most prominent example for this is the <kbd>CacheResult</kbd> functionality of the <strong>Java Temporary Caching API</strong> (<strong>JCache</strong>). JCache is a standard that is targeted for Java EE but, as of writing this book, not included in the umbrella specification. For applications that add the JCache functionality, the eligible business methods are annotated with <kbd>@CacheResult</kbd> and transparently being served by a specific cache.</p>
<p>JCache, in general, provides sophisticated caching capabilities for scenarios where simple Java EE solutions are not sufficient. This includes distributed caching provided by JCache implementations. As of today, caching solutions typically being used are <strong>Hazelcast</strong>, <strong>Infinispan</strong>, or <strong>Ehcache</strong>. This is especially the case when several caches need to be integrated with specific concerns, such as cache eviction. JCache, and its implementations, provide powerful solutions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Flow of execution</h1>
                </header>
            
            <article>
                
<p>Business processes that run in enterprise applications describe certain flows of process executions. For use cases that are triggered, this either includes a synchronous request-response approach or asynchronous handling of the triggered process.</p>
<p>Use case invocations run in a separate thread, one thread per request or invocation, respectively. The threads are created by the container and pooled for reuse once the invocation has been handled successfully. By default, the business processes defined in the application classes, as well as cross-cutting concerns, such as transactions, run sequentially.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Synchronous execution</h1>
                </header>
            
            <article>
                
<p>For a typical use case triggered by a HTTP request and involving a database query this works as follows. The request thread handles the request that goes into the boundary; for example, a JAX-RS <kbd>UsersResource</kbd>, by the inversion of control principle, the JAX-RS resource method is called by the container. The resource injects and uses a <kbd>UserManagement</kbd> EJB, which is also invoked indirectly by the container. All operations executed by the proxies happen in synchronous terms. The EJB will use an entity manager to store a new <kbd>User</kbd> entity and as soon as the business method that initiated the currently active transaction returns, the container will try to commit the transaction to the database. Depending on the transaction result, the boundary resource method resumes and constructs the client response. All this happens synchronously while the client call blocks and waits for the response.</p>
<p>Synchronous execution includes the handling of synchronous CDI events. Events decouple firing domain events from handling them; however, the event handling is performed synchronously. There are several kinds of transactional observer methods. By specifying the transaction phase, the event will be handled at transaction commit time, either before completion, after completion, only after a failed transaction, or after a successful transaction, respectively. By default, or when no transaction is active, CDI events are handled immediately when they are fired. This enables engineers to implement sophisticated solutions; for example, involving events that happen only after entities have been added to the database successfully. Again, in all cases, this handling is executed synchronously.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Asynchronous execution</h1>
                </header>
            
            <article>
                
<p>Whereas the synchronous flow of execution fulfills a lot of business use cases, other scenarios need asynchronous behavior. The Java EE environment sets a few constraints to the application in regard to threading. The container manages and pools resources and threads. External concurrency utilities outside of the container are not aware of these threads. Therefore, the application's code is not supposed to start and manage own threads, but to use Java EE functionality to do so. There are several APIs that natively support asynchronicity.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Asynchronous EJB methods</h1>
                </header>
            
            <article>
                
<p>A straightforward way to invoke asynchronous behavior is to annotate an EJB business method, or the EJB class, with <kbd>@Asynchronous</kbd>. Invocations to these methods immediately return, optionally with a <kbd>Future</kbd> response type. They are executed in a separate, container-managed thread. This usage works well for simple scenarios but is limited to EJBs:</p>
<pre>import javax.ejb.Asynchronous;

<strong>@Asynchronous</strong>
@Stateless
public class Calculator {

    public void calculatePi(long decimalPlaces) {
        // this may run for a long time
    }
}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Managed Executor Service</h1>
                </header>
            
            <article>
                
<p>For asynchronous execution in CDI managed beans or by using Java SE concurrency utilities, Java EE includes container-managed versions of <kbd>ExecutorService</kbd> and <kbd>ScheduledExecutorService</kbd> functionality. These are used to execute asynchronous tasks in container-managed threads. Instances of <kbd>ManagedExecutorService</kbd> and <kbd>ManagedScheduledExecutorService</kbd> are injected into the application's code. These instances can be used to execute their own runnable logic; however, they shine when combined together with Java SE concurrency utilities such as completable futures. The following shows the creation of completable futures using container-managed threads:</p>
<pre>import javax.annotation.Resource;
import javax.enterprise.concurrent.ManagedExecutorService;
import java.util.Random;
import java.util.concurrent.CompletableFuture;

@Stateless
public class Calculator {

    <strong>@Resource
    ManagedExecutorService mes;</strong>

    public CompletableFuture&lt;Double&gt; calculateRandomPi(int maxDecimalPlaces) {
        return CompletableFuture.supplyAsync(() -&gt; new Random().nextInt(maxDecimalPlaces) + 1, <strong>mes</strong>)
                .thenApply(this::calculatePi);
    }

    private double calculatePi(long decimalPlaces) {
        ...
    }
}</pre>
<p>The calculator bean returns a value of type <em>completable future of double</em> that may still be calculated while the calling context resumes. The future can be asked whether the calculation has finished. It can also be combined into subsequent executions. No matter where new threads are required in an enterprise application, Java EE functionality should be used to manage them.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Asynchronous CDI events</h1>
                </header>
            
            <article>
                
<p>CDI events can also be handled in an asynchronous way. The same holds true that the container will provide a thread for executing the event handling. To define asynchronous event handlers, the method is annotated with <kbd>@ObservesAsync</kbd> and the event is fired using the <kbd>fireAsync()</kbd> method. The next code snippets demonstrate asynchronous CDI events:</p>
<pre>@Stateless
public class CarManufacturer {

    @Inject
    CarFactory carFactory;

    @Inject
    Event&lt;CarCreated&gt; carCreated;

    public Car manufactureCar(Specification spec) {
        Car car = carFactory.createCar(spec);
        <strong>carCreated.fireAsync(new CarCreated(spec));</strong>
        return car;
    }
}</pre>
<p>The event handler is called in an own, container-managed thread:</p>
<pre>import javax.enterprise.event.ObservesAsync;

public class CreatedCarListener {

    public void onCarCreated(<strong>@ObservesAsync CarCreated event</strong>) {
        // handle event asynchronously
    }
}</pre>
<p>For backwards compatibility reasons, synchronous CDI events can also be handled in an EJB asynchronous method. Therefore, the events and handlers are defined in a synchronous way, but the handler method is an EJB business method annotated with <kbd>@Asynchronous</kbd>. Before asynchronous events were added to the CDI standard in Java EE 8, this was the only way to provide this feature. To avoid confusion, this implementation should be avoided in Java EE 8 and newer.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Scopes in asynchronicity</h1>
                </header>
            
            <article>
                
<p>Since the container cannot make any assumption on how long asynchronous tasks may run, usage of scopes is limited. Request-scoped or session-scoped beans that were available as the asynchronous task started are not guaranteed to be active during the whole execution; the request and session may have ended a long time ago. Threads that are running asynchronous tasks, for example, provided by a managed executor service or asynchronous events, can therefore not access the request-scoped or session-scoped bean instances that were active during the originating invocation. This also includes accessing references to injected instances, for example, in lambda methods that are part of the originating synchronous execution.</p>
<p>This has to be taken into account when modeling asynchronous tasks. All invocation-specific information needs to be provided at task start time. An asynchronous task can, however, have its own instances of scoped beans.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Timed execution</h1>
                </header>
            
            <article>
                
<p>Business use cases cannot only be invoked from the outside, for example, by a HTTP request, but also emerge from the inside of the application, by a job that runs at a defined time.</p>
<p>In the Unix world, cron jobs are a well-known functionality to trigger periodic jobs. EJBs provide similar possibilities using EJB timers. Timers invoke business methods based on a recurring pattern or after a specific time. The following shows the definition of a scheduled timer that times out every 10 minutes:</p>
<pre>import javax.ejb.Schedule;
import javax.ejb.Startup;

@Singleton
<strong>@Startup</strong>
public class PeriodicJob {

    <strong>@Schedule(minute = "*/10", hour = "*", persistent = false)</strong>
    public void executeJob() {
        // this is executed every 10 minutes
    }
}</pre>
<p>All EJBs, singleton, stateful, or stateless beans can define timers. However, in the majority of use cases it makes sense to define timers on singleton beans. The timeout is invoked on all active beans and it usually is desired to invoke the scheduled job reliably; that is, on a singleton bean. For the same reason this example defines the EJB to be active during application startup. This guarantees that the timer is executed from the beginning.</p>
<p>Timers can be defined as persistent, which extends their lifetime beyond the JVM life cycle. The container is responsible for keeping timers persistent, usually in a database. Persistent timers that would have been executed while an application is unavailable are triggered at startup. This also enables the possibility to share timers across multiple instances. Persistent timers together with corresponding server configuration are a straightforward solution for business processes that need to be executed exactly once across multiple servers.</p>
<p>The timers that are automatically created using the <kbd>@Schedule</kbd> annotation are specified using Unix-like cron expressions. For more flexibility, EJB timers are defined programmatically using the container-provided timer service that creates <kbd>Timers</kbd> and <kbd>@Timeout</kbd> callback methods.</p>
<p>Periodic or delayed jobs can also be defined outside EJB beans using the container-managed scheduled executor service. A <kbd>ManagedScheduledExecutorService</kbd> instance that executes tasks after a specified delay or periodically is injectable into managed beans. Executing these tasks will happen using container-managed threads:</p>
<pre>@ApplicationScoped
public class Periodic {

    <strong>@Resource
    ManagedScheduledExecutorService mses;</strong>

    public void startAsyncJobs() {
        <strong>mses.schedule(this::execute, 10, TimeUnit.SECONDS);
        mses.scheduleAtFixedRate(this::execute, 60, 10, TimeUnit.SECONDS);</strong>
    }

    private void execute() {
        ...
    }
}</pre>
<p>Invoking <kbd>startAsyncJobs()</kbd> will cause <kbd>execute()</kbd> to run in a managed thread, 10 seconds after the invocation and continuously, every 10 seconds, after an initial minute has passed.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Asynchronous and reactive JAX-RS</h1>
                </header>
            
            <article>
                
<p>JAX-RS supports asynchronous behavior to not unnecessarily block request threads on the server-side. Even if an HTTP connection is currently waiting for a response, the request thread could potentially handle other requests while the long-running process on the server is handled. Request threads are pooled by the container and this pool only has a certain size. In order to not unnecessarily occupy a request thread, JAX-RS asynchronous resource methods submit tasks that are executed while the request thread returns and is free to be reused again. The HTTP connection is being resumed and responded after the asynchronous task has been finished or when a timeout occurs. The following code shows an asynchronous JAX-RS resource method:</p>
<pre>@Path("users")
@Consumes(MediaType.APPLICATION_JSON)
public class UsersResource {

    <strong>@Resource
    ManagedExecutorService mes;</strong>

    ...

    @POST
    public <strong>CompletionStage&lt;Response&gt;</strong> createUserAsync(User user) {
        return CompletableFuture.supplyAsync(() -&gt; createUser(user), <strong>mes</strong>);
    }

    private Response createUser(User user) {
        userStore.create(user);

        return Response.accepted().build();
    }
}</pre>
<p>For the request thread not to be occupied for too long, the JAX-RS method needs to return fast. This is due to the resource method being called from the container using inversion of control. The completion stage's result will be used to resume the client connection once processing has finished.</p>
<p>Returning completion stages is a fairly recent approach in the JAX-RS API. If a timeout declaration, together with more flexibility on the asynchronous response, is required, the <kbd>AsyncResponse</kbd> type can be injected into the method. The following code snippet demonstrates this approach.</p>
<pre>import javax.ws.rs.container.AsyncResponse;
import javax.ws.rs.container.Suspended;

@Path("users")
@Consumes(MediaType.APPLICATION_JSON)
public class UsersResource {

    @Resource
    ManagedExecutorService mes;

    ...

    @POST
    public void createUserAsync(User user, <strong>@Suspended AsyncResponse response</strong>) {

        <strong>response.setTimeout(5, TimeUnit.SECONDS);
        response.setTimeoutHandler(r -&gt;
                r.resume(</strong>Response.status(Response.Status.SERVICE_UNAVAILABLE).build()<strong>));</strong>

        mes.execute(() -&gt; <strong>response.resume(createUser(user))</strong>);
    }
}</pre>
<p>Using custom timeouts, the client request will not wait infinitely, only until either the result is completed or the invocation timed out. The calculation, however, will continue since it's executed asynchronously.</p>
<p>For JAX-RS resources being implemented as EJBs, <kbd>@Asynchronous</kbd> business methods can be used to omit the asynchronous invocation using an executor service.</p>
<p>The JAX-RS client also supports asynchronous behavior. Depending on the requirements, it makes sense to not block during HTTP invocations. A previous example showed how to set timeouts on client requests. For long running and especially parallel external system calls, asynchronous and <em>reactive</em> behavior provides benefits.</p>
<p>Imagine several backends that provide weather information. The client component accesses all of them and provides the average weather forecast. Accessing the systems ideally happens in parallel.</p>
<pre>import java.util.stream.Collectors;

@ApplicationScoped
public class WeatherForecast {

    private Client client;
    private List&lt;WebTarget&gt; targets;

    <strong>@Resource
    ManagedExecutorService mes;</strong>

    @PostConstruct
    private void initClient() {
        client = ClientBuilder.newClient();
        targets = ...
    }

    public Forecast getAverageForecast() {
        return invokeTargetsAsync()
                .stream()
                .map(<strong>CompletableFuture::join</strong>)
                .reduce(this::calculateAverage)
                .orElseThrow(() -&gt; new IllegalStateException("No weather service available"));
    }

    private <strong>List&lt;CompletableFuture&lt;Forecast&gt;&gt;</strong> invokeTargetsAsync() {
        return targets.stream()
                .map(t -&gt; CompletableFuture.supplyAsync(() -&gt; t
                        .request(MediaType.APPLICATION_JSON_TYPE)
                        .get(Forecast.class), <strong>mes</strong>))
                .collect(Collectors.toList());
    }

    private Forecast calculateAverage(Forecast first, Forecast second) {
        ...
    }

    @PreDestroy
    public void closeClient() {
        client.close();
    }
}</pre>
<p>The <kbd>invokeTargetsAsync()</kbd> method invokes the available targets asynchronously, using the managed executor service. The <kbd>CompletableFuture</kbd> handles are returned and used to calculate the average results. Calling the <kbd>join()</kbd> method will block until the invocation has finished and will deliver the individual results.</p>
<p>By invoking the available targets asynchronously, they call and wait for the potentially slow resource in parallel. Waiting for the weather service resources then only takes as long as the slowest response, not the sum of all responses.</p>
<p>The latest version of JAX-RS natively supports completion stages, which reduces boilerplate code in the applications. Similar to using completable futures, the invocation immediately returns a completion stage instance for further usage. The following demonstrates reactive JAX-RS client functionality using the <kbd>rx()</kbd> invocation:</p>
<pre>public Forecast getAverageForecast() {
    return invokeTargetsAsync()
            .stream()
            .reduce((l, r) -&gt; l.thenCombine(r, this::calculateAverage))
            .map(s -&gt; <strong>s.toCompletableFuture().join()</strong>)
            .orElseThrow(() -&gt; new IllegalStateException("No weather service available"));
}

private <strong>List&lt;CompletionStage&lt;Forecast&gt;&gt;</strong> invokeTargetsAsync() {
    return targets.stream()
            .map(t -&gt; t
                    .request(MediaType.APPLICATION_JSON_TYPE)
                    <strong>.rx()</strong>
                    .get(Forecast.class))
            .collect(Collectors.toList());
}</pre>
<p>The preceding example doesn't require to lookup the managed executor service. The JAX-RS client will manage this internally.</p>
<p>Before the <kbd>rx()</kbd> method was introduced, the client contained an explicit <kbd>async()</kbd> invocation that behaves similarly, but only returns <kbd>Future</kbd>s. The reactive client approach usually fits the need in projects better.</p>
<p>As seen before, we are using the container-managed executor service since we're in a Java EE environment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Concepts and design principles of modern Java EE</h1>
                </header>
            
            <article>
                
<p>The Java EE API is built around conventions and design principles that are present throughout the whole set of standards. Software engineers will find familiar API patterns and approaches while developing applications. Java EE aims to maintain consistent API usage.</p>
<p>For applications that focus on business use cases first, the most important principle of the technology is <em>not getting in the way</em>. As mentioned earlier, engineers should be able to focus on solving business problems, not spending the majority of their time dealing with technology or framework concerns. Ideally, the domain logic is implemented using plain Java and <em>enhanced</em> with annotations and aspects that enable enterprise environments without affecting or obfuscating the domain code. This implies that the technology doesn't need much engineer attention by enforcing overly complex constraints. In the past, J2EE required many of these overly-complex solutions. Managed beans as well as persistent beans needed to implement interfaces or extend base classes. This obfuscates the domain logic and complicates testability.</p>
<p>In the age of Java EE, the domain logic is implemented in plain Java classes annotated with annotations that tell the container runtime how to apply the enterprise concerns. Clean code practices often suggest writing code for delectability, not reusability. Java EE supports this approach. If for some reason the technology needs to be replaced and the domain logic extracted, this is possible by simply removing the corresponding annotations.</p>
<p>As we will see in <a href="">Chapter 7</a>, <em>Testing</em> the programming approach highly supports testability, since for the developers, the majority of Java EE specifics are not more than annotations.</p>
<p>A design principle that is existent throughout the whole API is <strong>inversion of control</strong> (<strong>IoC</strong>), in other words, <em>don't call us, we'll call you</em>. We see this especially in application boundaries such as JAX-RS resources. The resource methods are defined by annotation Java methods that are later invoked by the container in the correct context. The same holds true for dependency injection that needs to resolve producers or include cross-cutting concerns such as interceptors. Application developers can focus on implementing the logic and defining relationships and leave the actual plumbing to the container. Another, not that obvious example, is declaring the mapping of Java objects to JSON and back via JSON-B annotations. The objects are mapped implicitly in a declarative approach, not necessarily in an explicit, programmatic way.</p>
<p>Another principle that enables engineers to use the technology in a productive way is <strong>convention over configuration</strong>. By default, Java EE defines specific behavior that matches the majority of use cases. If that is not sufficient or doesn't match the requirements, behavior can be overridden, often at several levels.</p>
<p>There are countless examples of convention over configuration. JAX-RS resource methods mapping Java functionality into HTTP responses is one such method. If JAX-RS's default behavior regarding responses is not adequate, the <kbd>Response</kbd> return type can be used. Another example is the specification of managed beans that is usually realized using annotations. To override this behavior, the <kbd>beans.xml</kbd> XML descriptor can be used. The welcoming aspect for developers is that in a modern Java EE world, enterprise applications are developed in a pragmatic and highly productive way that does not usually require at lot of XML usage like in the past.</p>
<p>In terms of developer productivity, another important design principle of Java EE is that the platform requires the container to integrate the different standards. As soon as containers support a specific set of APIs, which is the case if the whole Java EE API is supported, it is also required that implementations of the APIs enable straightforward integration of other APIs. A good example is that JAX-RS resources are able to use JSON-B mapping and Bean Validation without explicit configuration other than annotations. In previous examples, we saw how functionalities that are defined in separate standards can be used together without additional effort required. This is also one of the biggest advantages of the Java EE platform. The umbrella specification ensures that the specific standards play well together. Developers can rely on certain features and implementation being provided by the application server.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Preserving maintainable code with high quality</h1>
                </header>
            
            <article>
                
<p>Developers generally agree that code quality is a goal to strive for. Yet not all technology supports this ambition equally well.</p>
<p>As mentioned from the start, the business logic should be the main focus of applications. If changes in the business logic or new knowledge after working in the domain emerge, the domain model, as well as the source code, needs to be refactored. Iterative refactoring is a necessity to achieve and maintain high quality of the modeled domain as well as the source code in general. Domain-Driven Design describes this effort of deepening the understanding of the business knowledge.</p>
<p>A lot has been written on refactoring at the code level. After the business logic has initially been represented into the code and verified by tests, developers should spend some time and effort to rethink and improve the first attempt. This includes identifier names, methods, and classes. Especially, <strong>naming</strong>, <strong>layers of abstractions</strong> and <strong>single points of responsibility</strong> are important aspects.</p>
<p>Following the reasoning of Domain-Driven Design, the business domain should fit its code representations as much as possible. This includes, especially, the language of the domain; that is, how developers and business experts talk about certain features. The goal of the whole team is to find a uniform, <em>ubiquitous language</em> that is used and well represented not only in discussions and presentation slides, but also in the code. Refinement of business knowledge will happen in an iterative approach. As well as refactoring at the code level, this approach implies that an initial model won't perfectly match all the requirements from the beginning.</p>
<p>Therefore, the technology being used should support changes in the model and code. Too many restrictions become hard to change later on.</p>
<p>For application development in general, but especially for refactoring, it is crucial to have a sufficient coverage of automated software tests. As soon as the code is changed, regression tests ensure that no business functionality has accidentally been damaged. Sufficient test cases thus support refactoring attempts, giving engineers clarity as to whether functionality still works as expected after it has been touched. The technology should ideally support testability by not constraining code structures. <a href="">Chapter 7</a>, <em>Testing</em> will cover that topic in detail.</p>
<p>In order to achieve <em>refactorability</em>, loose coupling is favored over tight coupling. All functionality that explicitly invokes or requires other components needs to be touched if either of those change. Java EE supports loose coupling in several aspects; for example, dependency injection, eventing, or cross-cutting concerns, such as interceptors. All of these simplify code changes.</p>
<p>There are some tools and methods that measure the quality. Especially, static code analysis can gather information about complexity, coupling, relationships of classes and packages, and implementation in general. These means can help engineers to identify potential issues and provide an overall picture of the software project. <a href="599c6821-8971-4489-931c-9e11b5e23afd.xhtml">Chapter 6</a>, <em>Application Development Workflows</em> covers how to verify code quality in an automated way.</p>
<p>In general, it is advisable to refactor and improve the code quality constantly. Software projects are often driven to implement new functionality that generates revenue instead of improving existing functionality. The issue with that is that refactoring and improving quality is often seen to not provide any benefit from the business perspective. This is, of course, not true. In order to achieve a steady velocity and to integrate new features with satisfying quality, it is absolutely necessary to reconsider existing features. Ideally periodical refactor cycles are already built into the project schedule. Experience shows that project managers are often not aware of this issue. However, it is a responsibility of the software engineer team to address the relevance of quality.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Engineers are advised to focus on the domain and business logic first, by starting from the use case boundaries and stepping down the abstraction layers. Java EE core domain components, namely EJBs, CDI, CDI producers and events, are used to implement the plain business logic. Other Java EE APIs are mainly used to support the business logic in technical necessities. As we have seen, Java EE implements and encourages numerous software design patterns as well as the approaches of Domain-Driven Design in modern ways.</p>
<p>We have seen how to choose and implement communication, in both synchronous and asynchronous ways. The communication technology depends on the business requirements. Especially HTTP is widely used and well-supported in Java EE via JAX-RS. REST is a prime example of an communication protocol architectural style that supports to loosely couple system.</p>
<p>Java EE ships with functionality that implements and enables technical cross-cutting concerns such as managed persistence, configuration, or caching. Especially the use of CDI realizes various technically-motivated use cases. Required asynchronous behavior can be implemented in different ways. Applications should not manage own threading or concurrency management, rather than use Java EE features. Container-managed executor services, asynchronous CDI events, or EJB timers are examples that should be used instead.</p>
<p>The concepts and principles of the Java EE platform support developing enterprise applications with focusing on business logic. Especially the lean integration of different standards, inversion of control, convention over configuration, and the principle of <em>not getting in the way</em>, support this aspect. Engineers should aim to maintain high code quality, not only by code level refactoring, but also by refining the business logic and the <em>ubiquitous language</em> the teams share. Refining code quality as well as suitability of the domain model happens in iterative steps.</p>
<p>Therefore, technology should support changes in model and code and not putting too many restrictions onto solutions. Java EE supports this by minimizing the framework impact on the business code and by enabling to loosely couple functionality. Teams should be aware of refactoring together with automated testing being a necessity of high quality software.</p>
<p>The following chapter will cover what other aspects make the Java EE a modern and suitable platform for developing enterprise applications. We will see what deployment approaches are advisable and how to lay the foundation for productive development workflows.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </body></html>