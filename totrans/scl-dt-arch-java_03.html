<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer053">
<h1 class="chapter-number" id="_idParaDest-44"><a id="_idTextAnchor043"/>3</h1>
<h1 id="_idParaDest-45"><a id="_idTextAnchor044"/>Identifying the Right Data Platform</h1>
<p>In the previous chapter, we discussed the various data types, their formats, and their storage. We also covered different databases and provided an overview of them. Then, we understood the factors and features we should compare when choosing a data format, storage type, or database for any use case to solve a data engineering problem effectively.</p>
<p>In this chapter, we will look at the various kinds of popular platforms that are available to run data engineering solutions. You will also learn about the considerations you should make as an architect to choose one of them. To do so, we will discuss the finer details of each platform and the alternatives these platforms provide. Finally, you will learn how to make the most of these platforms to architect an efficient, robust, and cost-effective solution for a business problem.</p>
<p>In this chapter, we’re going to cover the following main topics:</p>
<ul>
<li>Virtualization and containerization platforms</li>
<li>Hadoop platforms</li>
<li>Cloud platforms</li>
<li>Choosing the correct platform</li>
</ul>
<h1 id="_idParaDest-46"><a id="_idTextAnchor045"/>Technical requirements</h1>
<p>To complete this chapter, you’ll need the following:</p>
<ul>
<li>JDK 1.8 or above</li>
<li>Apache Maven 3.3 or above</li>
</ul>
<p>The code for this chapter can be found in this book’s GitHub repository: <a href="https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter03">https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/tree/main/Chapter03</a></p>
<h1 id="_idParaDest-47"><a id="_idTextAnchor046"/>Virtualization and containerization platforms</h1>
<p>With the spread of <strong class="bold">information technology</strong> (<strong class="bold">IT</strong>) in all spheres of life, the dependency and reliability on IT<a id="_idIndexMarker307"/> infrastructure have increased manifold. Now, IT runs so many critical and real-time businesses. This means that there can be zero or negligible downtime for maintenance or failure. Also, rapid real-time demands have grown. For example, during the holiday season, there’s a huge amount of traffic on online shopping websites. So, now, IT needs to be highly available, elastic, flexible, and quick. These were the reasons that motivated the creation of virtual platforms such as virtualization and <a id="_idIndexMarker308"/>containerization. For example, Barclays, a multinational financial firm based in the UK, was facing a hard time from competitors due to their slow pace of innovation and project deliveries. One of its major roadblocks was the time it took to provision new servers. So, they decided to use Red Hat OpenShift to containerize their application. This reduced the provisioning time dramatically from weeks to hours. As a result, time to market became super fast, which helped Barclays stay ahead of its competitors.</p>
<p><strong class="bold">Virtualization</strong> abstracts<a id="_idIndexMarker309"/> the hardware and allows you to run multiple operating systems on a single server or piece of hardware. It uses software to create a virtual abstraction over the hardware resources so that multiple <strong class="bold">virtual machines</strong> (<strong class="bold">VMs</strong>) can <a id="_idIndexMarker310"/>run over <a id="_idIndexMarker311"/>the physical hardware with<a id="_idIndexMarker312"/> their <em class="italic">virtual OS</em>, <strong class="bold">virtual CPU</strong> (<strong class="bold">vCPU</strong>), virtual storage, and virtual networking. The following diagram shows how virtualization <a id="_idIndexMarker313"/>works:</p>
<div>
<div class="IMG---Figure" id="_idContainer028">
<img alt="Figure 3.1 – Virtualization  " height="641" src="image/B17084_03_001.jpg" width="900"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.1 – Virtualization </p>
<p>As <a id="_idIndexMarker314"/>shown in the preceding diagram, VMs run on a host machine with the help of a hypervisor. A hypervisor<a id="_idIndexMarker315"/> is a piece of software or firmware that can host a VM on physical hardware such as a server or a computer. The physical machine where hypervisors create VMs are called host machines<a id="_idIndexMarker316"/> and the VMs are called<a id="_idIndexMarker317"/> guest machines. The operating system in the host machine is called the <a id="_idIndexMarker318"/>host OS, while the operating system in the VMs is called the<a id="_idIndexMarker319"/> guest OS.</p>
<h2 id="_idParaDest-48"><a id="_idTextAnchor047"/>Benefits of virtualization</h2>
<p>The following are the<a id="_idIndexMarker320"/> benefits of virtualization:</p>
<ul>
<li><strong class="bold">Better resource utilization</strong>: As multiple VMs run on the same hardware, hardware resources such as storage/memory and network can be more efficiently used to serve more applications that might have high loads at different times. Since spawning a VM is much quicker than spawning a new server. VMs can be spawned during high demand load cycles and switched off when the load on the application comes down.</li>
<li><strong class="bold">Less downtime/higher availability</strong>: When physical servers have issues or go down, need routine maintenance, or require upgrades, it results in costly downtime. With virtual servers, applications can readily move between guest hosts to make sure there is minimal downtime in the order of minutes rather than hours or days.</li>
<li><strong class="bold">Quicker to market and scalability</strong>: Since provisioning a VM takes minutes rather than weeks or months, the overall software delivery cycles have reduced substantially. This enables quicker testing since you can mock up production environment using VMs.</li>
<li><strong class="bold">Faster disaster recovery (DR)</strong>: Unlike<a id="_idIndexMarker321"/> physical servers, whose DR takes hours or days, VMs can recover within minutes. Hence, VMs enable us to have faster DR.</li>
</ul>
<p>The following are a few <a id="_idIndexMarker322"/>examples of popular VMs:</p>
<ul>
<li>Microsoft’s Hyper-V</li>
<li>VMware’s vSphere</li>
<li>Oracle’s VirtualBox</li>
</ul>
<p>Let’s see how a VM works. We will<a id="_idIndexMarker323"/> start this exercise by downloading <a id="_idIndexMarker324"/>and installing Oracle VirtualBox: </p>
<ol>
<li>Based on your<a id="_idIndexMarker325"/> host operating system, you can download the appropriate installer of Oracle VirtualBox<a id="_idIndexMarker326"/> from <a href="https://www.virtualbox.org/">https://www.virtualbox.org/</a>.</li>
</ol>
<p>Then, install <a id="_idIndexMarker327"/>VirtualBox using the installation instructions at <a href="https://www.virtualbox.org/manual/ch02.xhtml">https://www.virtualbox.org/manual/ch02.xhtml</a>. These instructions are likely to vary by OS. </p>
<ol>
<li value="2">Once it has been installed, open Oracle VirtualBox. You will see the <strong class="bold">Oracle VM VirtualBox Manager</strong> home page, as shown here:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer029">
<img alt="Figure 3.2 – The Oracle VirtualBox Manager home page " height="667" src="image/B17084_03_002.jpg" width="1430"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.2 – The Oracle VirtualBox Manager home page</p>
<ol>
<li value="3">Then, click<a id="_idIndexMarker328"/> the <strong class="bold">New</strong> button to create a new VM on your machine (here, this serves as a guest OS). The following screenshot shows the <strong class="bold">Create Virtual Machine</strong> dialog screen popup (which appears upon clicking the <strong class="bold">New</strong> button):</li>
</ol>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">  </p>
<div>
<div class="IMG---Figure" id="_idContainer030">
<img alt="Figure 3.3 – Configuring the guest VM using Oracle VirtualBox  " height="871" src="image/B17084_03_003.jpg" width="1500"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.3 – Configuring the guest VM using Oracle VirtualBox </p>
<p>In the preceding<a id="_idIndexMarker329"/> screenshot, you can see that you need to provide a unique name for the VM. You can also select the OS type and its version, as well as configure the memory (RAM) size. Finally, you can choose to configure or add a new virtual hard disk. If you choose to add a new hard disk, then a popup similar to the following will appear:</p>
<div>
<div class="IMG---Figure" id="_idContainer031">
<img alt="Figure 3.4 – Creating a virtual hard disk using Oracle VirtualBox " height="814" src="image/B17084_03_004.jpg" width="1450"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.4 – Creating a virtual hard disk using Oracle VirtualBox</p>
<p>As shown in the <a id="_idIndexMarker330"/>preceding screenshot, when configuring a virtual hard disk, you can choose from various kinds of available virtual hard disk drives. The major popular virtual hard disks<a id="_idIndexMarker331"/> are as follows:</p>
<ul>
<li><strong class="bold">VirtualBox Disk Image</strong> (<strong class="bold">VDI</strong>)</li>
<li><strong class="bold">Virtual Hard Disk</strong> (<strong class="bold">VHD</strong>)</li>
<li><strong class="bold">Virtual Machine Disk</strong> (<strong class="bold">VMDK</strong>)</li>
</ul>
<p>Once you have configured your desired virtual hard disk configuration, you can create the VM by clicking the <strong class="bold">Create</strong> button.</p>
<ol>
<li value="4">Once a VM has been created, it will be listed on the <strong class="bold">Oracle VM VirtualBox Manager</strong> screen, as shown in the following screenshot. You can start the virtual machine by selecting the appropriate VM and clicking the <strong class="bold">Start</strong> button: </li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer032">
<img alt="Figure 3.5 – Guest VM created and listed in Oracle VirtualBox " height="799" src="image/B17084_03_005.jpg" width="1493"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.5 – Guest VM created and listed in Oracle VirtualBox</p>
<p>Although VMs simplify our<a id="_idIndexMarker332"/> delivery and make the platform more available and quicker than traditional servers, they have some limitations:</p>
<ul>
<li><strong class="bold">VMs are heavyweight components</strong>: This means that every time you are doing a disaster recovery, you need to acquire all the resources and boot the guest operating system so that you can run your application. It takes a few minutes to reboot. Also, it is resource-heavy to boot a new guest OS.</li>
<li><strong class="bold">They slow down the performance of the OS</strong>: Since there are only a few resources in VMs, and they can only be thick provisioned, this slows down the performance of the host OS, which, in turn, affects the performance of the guest OS.</li>
<li><strong class="bold">Limited portability</strong>: Since the applications running on the VMs are tightly coupled to the guest OS, there<a id="_idIndexMarker333"/> will always be a portability issue when moving to a different guest OS with a different type or configuration.</li>
</ul>
<p>Containerization can help us overcome these shortcomings. We’ll take a look at containerization in the next section.</p>
<h2 id="_idParaDest-49"><a id="_idTextAnchor048"/>Containerization</h2>
<p>Containerization is a<a id="_idIndexMarker334"/> technique that abstracts the OS (instead of the hardware) and lets applications run on top of it directly. Containerization is more efficient than virtualization as applications don’t need a guest OS to run. Applications use the same kernel of the host OS to run multiple applications targeted for different types of OS. The following diagram shows how containerization works:</p>
<div>
<div class="IMG---Figure" id="_idContainer033">
<img alt="Figure 3.6 – Containerization  " height="519" src="image/B17084_03_006.jpg" width="849"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.6 – Containerization </p>
<p>In containerization, a piece of software<a id="_idIndexMarker335"/> called a <strong class="bold">container engine</strong> runs on the host OS. This allows applications to run on top of the container engine, without any need to create a separate guest OS. Each running instance of the application, along with its dependencies, is called a container. Here, the application, along with its dependencies, can be bundled into a portable package called an image. </p>
<h2 id="_idParaDest-50"><a id="_idTextAnchor049"/>Benefits of containerization</h2>
<p>The following are the advantages<a id="_idIndexMarker336"/> of containerization over virtualization:</p>
<ul>
<li><strong class="bold">Lightweight</strong>: Containers use dependencies and binaries to run applications directly on a container engine. Containers don’t need to create VMs, so they don’t need to initialize a dedicated virtual memory/hard disk to run the application. Containers boot significantly faster than VMs. While VMs take minutes to boot, containers can boot in seconds. </li>
<li><strong class="bold">Portable</strong>: Applications, along with their dependencies and base container, can be bundled in a package called an image that can easily be ported across any container engine run on any kind of host.</li>
<li><strong class="bold">Reduces single points of failure</strong>: Due to the easy portability and lightweight nature of containers, testing, deploying, and scaling applications has become easier. This has led to the development of microservices, which ensures reduced single points of failure.</li>
<li><strong class="bold">Increased development velocity</strong>: In containerization, containers can be seamlessly migrated from one environment to another, enabling seamless continuous deployments. It also enables on-the-fly testing while building and packaging, hence improving continuous integration workflows. Application scaling becomes super fast if the application is run on containers. These features have made development easier and faster, enabling businesses to deliver solutions to the market quickly.</li>
</ul>
<p>Docker<a id="_idIndexMarker337"/> is the most popular container engine. Let’s look at some of the most important and common terms related to Docker:</p>
<ul>
<li><strong class="bold">Docker image</strong>: A Docker image<a id="_idIndexMarker338"/> is a blueprint or template with instructions to create a Docker container. We can create a Docker image by bundling an already existing image with an application and its dependencies.</li>
<li><strong class="bold">Docker container</strong>: A Docker container<a id="_idIndexMarker339"/> is a running instance of a Docker image. A Docker container contains a write layer on top of one or more read layers. The writable layer allows us to write anything on the container, as well as execute commands.</li>
<li><strong class="bold">Docker registry</strong>: This is a<a id="_idIndexMarker340"/> repository that stores Docker images developed and uploaded by developers to be leveraged by other developers. Container repositories are physical locations where your Docker images are stored. Related images with the same name can be also stored, but each image will be uniquely identified by a tag. Maven repositories are to Java artifacts what Docker registries are to Docker images. Just like a Maven repository supports multiple versions of the related JAR files with the same name, a Docker registry supports multiple tags for images with the same name. Docker Hub is the official cloud-based public Docker registry.</li>
<li><strong class="bold">Docker networking</strong>: Docker networking<a id="_idIndexMarker341"/> is responsible for communication between the Docker host and Docker applications. It is also responsible for basic inter-container communication. External applications and developers can access applications running in a Docker container on the port exposed to the external world. </li>
<li><strong class="bold">Docker storage</strong>: Docker has multiple storage<a id="_idIndexMarker342"/> drivers that allow you to work with the underlying storage devices, such as Device Mapper, AUFS, and Overlay. Data volumes can be shared across multiple Docker containers. This enables shared resources to be stored in such data volumes. However, there is no way to share memory between Docker containers.</li>
</ul>
<p>Now that we have learned about the important terminologies related to Docker, let’s learn how to set up Docker in a local machine using Docker Desktop. We will also show you how to deploy an image and start a Docker container:</p>
<ol>
<li value="1">First, you <a id="_idIndexMarker343"/>must install Docker Desktop on our local machine. You can download the appropriate Docker Desktop version<a id="_idIndexMarker344"/> from the following link based on your OS type and version: <a href="https://www.docker.com/products/docker-desktop">https://www.docker.com/products/docker-desktop</a>.</li>
</ol>
<p>Based on your <a id="_idIndexMarker345"/>operating system, you can follow the installation instructions at <a href="https://docs.docker.com/desktop/mac/install/">https://docs.docker.com/desktop/mac/install/</a> (for Mac) or <a href="https://docs.docker.com/desktop/windows/install/">https://docs.docker.com/desktop/windows/install/</a> (for Windows).</p>
<p>If you don’t have Maven installed in your system, please download and install it (instruction<a href="https://maven.apache.org/install.xhtml">s for installing Maven can be found a</a>t <a href="https://maven.apache.org/install.xhtml">https://maven.apache.org/install.xhtml</a>).</p>
<ol>
<li value="2">Once you<a id="_idIndexMarker346"/> have installed Docker Desktop, open it. You will be asked to accept an agreement. Please read and accept it. Once you have done this and the application opens, you will see the following home page:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer034">
<img alt="Figure 3.7 – Docker Desktop home page " height="645" src="image/B17084_03_007.jpg" width="1425"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.7 – Docker Desktop home page</p>
<ol>
<li value="3">Next, you must create a Docker Hub personal account to make use of Docker Desktop efficiently. Please sign up to create a personal Docker account at <a href="https://hub.docker.com/signup">https://hub.docker.com/signup</a>.</li>
</ol>
<p>Once you have successfully created your account, click the <strong class="bold">Sign In</strong> button and enter your Docker ID and password to log in, as shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer035">
<img alt="Figure 3.8 – Logging into Docker Desktop " height="571" src="image/B17084_03_008.jpg" width="900"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.8 – Logging into Docker Desktop</p>
<ol>
<li value="4">Now, let’s<a id="_idIndexMarker347"/> build our own Docker file. To build a Docker file, we need to know basic Docker <strong class="source-inline">build</strong> commands. The following table lists a few important Docker <strong class="source-inline">build</strong> commands:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer036">
<img alt="Figure 3.9 – Docker build commands " height="386" src="image/B17084_03_009.jpg" width="1375"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.9 – Docker build commands</p>
<p>To build the Docker file, first, download the code from <a href="https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/blob/main/Chapter03/sourcecode/DockerExample">https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/blob/main/Chapter03/sourcecode/DockerExample</a>. In this project, we will create a simple REST API using Spring Boot and deploy and run this application using our Docker environment locally. The artifact that will be generated when we build this project is <strong class="source-inline">DockerExample-1.0-SNAPSHOT.jar</strong>. The Docker file will look as follows:</p>
<p class="source-code"># Each step creates a read-only layer of the image.</p>
<p class="source-code"># For Java 8</p>
<p class="source-code">FROM openjdk:8-jdk-alpine</p>
<p class="source-code"># cd /opt/app</p>
<p class="source-code">WORKDIR /opt/app</p>
<p class="source-code"># cp target/DockerExample-1.0-SNAPSHOT.jar /opt/app/app.jar</p>
<p class="source-code">COPY target/DockerExample-1.0-SNAPSHOT.jar app.jar</p>
<p class="source-code"># exposing the port on which application runs</p>
<p class="source-code">EXPOSE 8080</p>
<p class="source-code"># java -jar /opt/app/app.jar</p>
<p class="source-code">ENTRYPOINT ["java","-jar","/app.jar"]</p>
<p>In <em class="italic">step 1</em> of the <a id="_idIndexMarker348"/>Docker file’s source code, we import a base image from Docker Hub. In <em class="italic">step 2</em>, we set the working directory inside the Docker container as <strong class="source-inline">/opt/app</strong>. In the next step, we copy our artifact to the working directory on Docker. After that, we expose port <strong class="source-inline">8080</strong> from Docker. Finally, we execute the Java app using the <strong class="source-inline">java -jar</strong> command.</p>
<ol>
<li value="5">Next, we will build the JAR file using Maven. First, using the command line (Windows) or a Terminal (Mac), go to the root folder of the <strong class="source-inline">DockerExample</strong> project. Run the following command to build the JAR file from the root folder of the project:<p class="source-code"><strong class="bold">&gt; mvn clean install</strong></p></li>
<li>Then, run the following command to create a customized Docker image named <strong class="source-inline">hello-docker</strong> from the Docker file we just created:<p class="source-code"><strong class="bold">&gt; docker build --tag=hello-docker:latest .</strong></p></li>
</ol>
<p>Once you run <a id="_idIndexMarker349"/>this command, you will be able to see the Docker image in Docker Desktop, in the <strong class="bold">Images</strong> tab, as shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer037">
<img alt="Figure 3.10 – Docker container created successfully and listed " height="481" src="image/B17084_03_010.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.10 – Docker container created successfully and listed</p>
<ol>
<li value="7">Now, you can start the<a id="_idIndexMarker350"/> container by clicking the <strong class="bold">RUN</strong> button, as follows:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer038">
<img alt="Figure 3.11 – Running a Docker container " height="462" src="image/B17084_03_011.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.11 – Running a Docker container</p>
<p>Provide a container <a id="_idIndexMarker351"/>name and a host port value and click <strong class="bold">Run</strong> in the popup dialog to start the container, as shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer039">
<img alt="Figure 3.12 – Setting up Docker Run configurations " height="995" src="image/B17084_03_012.jpg" width="1076"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.12 – Setting up Docker Run configurations</p>
<p>Once you click <strong class="bold">Run</strong>, the container will be instantiated and you will be able to see the container listed (with its status set to <strong class="bold">RUNNING</strong>) in the <strong class="bold">Containers / Apps</strong> tab of Docker Desktop, as shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer040">
<img alt="Figure 3.13 – Running instance on Docker Desktop " height="336" src="image/B17084_03_013.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.13 – Running instance on Docker Desktop</p>
<ol>
<li value="8">Now, you can validate the <a id="_idIndexMarker352"/>app by testing it in a browser. Please make sure you are using the host port (configured during container creation) in the HTTP address while validating the application. For our example, you can validate the application using port <strong class="source-inline">8887</strong> (which you mapped earlier), as follows:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer041">
<img alt="Figure 3.14 – Testing the app deployed on Docker " height="332" src="image/B17084_03_014.jpg" width="1249"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.14 – Testing the app deployed on Docker</p>
<p>You can log into <a id="_idIndexMarker353"/>the Docker CLI using the <strong class="bold">CLI</strong> button in Docker Desktop, as follows:</p>
<div>
<div class="IMG---Figure" id="_idContainer042">
<img alt="Figure 3.15 – Opening the Docker CLI from Docker Desktop " height="337" src="image/B17084_03_015.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.15 – Opening the Docker CLI from Docker Desktop</p>
<p>In this section, we learned about Docker. While Docker makes our lives easy and makes development and deployment considerably faster, it comes with the following set of challenges:</p>
<ul>
<li>Inter-container<a id="_idIndexMarker354"/> communication is usually not possible or very complex to set up</li>
<li>There is no incoming traffic distribution mechanism, which might cause a skewed distribution of incoming traffic to a set of containers</li>
<li>Container management is overhead to manage the cluster manually</li>
<li>Auto-scaling<a id="_idIndexMarker355"/> is not possible</li>
</ul>
<p>In a production environment, we need to solve these shortcomings if we want to run a robust, efficient, scalable, and cost-effective solution. Here, container orchestrators come to the rescue. There are many container orchestrators on the market. However, Kubernetes, which was developed and open-sourced by Google, is one of the most popular and widely used container orchestrators. In the next section, we will discuss Kubernetes in more detail.</p>
<h2 id="_idParaDest-51"><a id="_idTextAnchor050"/>Kubernetes</h2>
<p>Kubernetes<a id="_idIndexMarker356"/> is an open source container orchestrator that effectively manages containerized applications and their inter-container communication. It also automates how containers are deployed and scaled. Each Kubernetes cluster has <a id="_idIndexMarker357"/>multiple components:</p>
<ul>
<li>Master</li>
<li>Nodes</li>
<li>Kubernetes objects (namespaces, pods, containers, volumes, deployments, and services)</li>
</ul>
<p>The following diagram shows the various components of a Kubernetes cluster:</p>
<div>
<div class="IMG---Figure" id="_idContainer043">
<img alt="Figure 3.16 – A Kubernetes cluster and its components " height="599" src="image/B17084_03_016.jpg" width="1400"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.16 – A Kubernetes cluster and its components</p>
<p>Now, let’s briefly describe each of the components shown in the preceding diagram:</p>
<ul>
<li><strong class="bold">Kubernetes namespace</strong>: This<a id="_idIndexMarker358"/> provides logical segregation between different applications for different teams that are built for different purposes. <strong class="bold">Kube-System</strong>, <strong class="bold">Kube-public</strong>, and <strong class="bold">Kube-node-release</strong> are namespaces that are used by Kubernetes internal systems to manage the cluster, such as reading heartbeats, and to store publicly accessible data, such as <strong class="source-inline">configMap</strong>. Apart from this, there is a default namespace.</li>
<li><strong class="bold">User namespace</strong>: Users/teams<a id="_idIndexMarker359"/> can create a<a id="_idIndexMarker360"/> namespace inside the default namespace.</li>
<li><strong class="bold">Master nodes</strong>: The <a id="_idIndexMarker361"/>master node<a id="_idIndexMarker362"/> is the cluster orchestrator. It scales and allocates app containers whenever a new request for a deployment comes into the Kubernetes cluster.</li>
<li><strong class="bold">Worker nodes</strong>: These <a id="_idIndexMarker363"/>are the nodes where the <a id="_idIndexMarker364"/>pods are deployed and the applications run.</li>
<li><strong class="bold">Pod</strong>: A pod<a id="_idIndexMarker365"/> is<a id="_idIndexMarker366"/> an abstraction on top of a container that helps it become easily portable between different runtimes, auto-detects the available ports in a cluster, and gives it a unique IP address. A pod can consist of multiple containers in which multiple helper containers can communicate seamlessly and assist the primary application. These multiple containers in a single pod not only share volumes but also share memory <a id="_idIndexMarker367"/>spaces such as <strong class="bold">Portable Operating System Interface</strong> (<strong class="bold">POSIX</strong>) shared memory.</li>
<li><strong class="bold">Agents</strong>: There are two <a id="_idIndexMarker368"/>types of agents, as follows:<ul><li><strong class="bold">Kubelet agent</strong>: This is a<a id="_idIndexMarker369"/> service that runs in each node. It ensures all the<a id="_idIndexMarker370"/> containers within that node are up and running.</li>
<li><strong class="bold">Docker agent</strong>: This is <a id="_idIndexMarker371"/>a <a id="_idIndexMarker372"/>service that is used to run a container.</li>
</ul></li>
</ul>
<p>Now that we have briefly seen the components of Kubernetes and its role in containerization, let’s try to deploy the Docker image we created in the previous section in a Kubernetes cluster locally. To do that, we must install <strong class="bold">minikube</strong> (a Kubernetes cluster for running Kubernetes on your local machine):</p>
<ol>
<li value="1">You can install the<a id="_idIndexMarker373"/> appropriate version of <strong class="source-inline">minikube</strong> by following the instructions at <a href="https://minikube.sigs.k8s.io/docs/start/">https://minikube.sigs.k8s.io/docs/start/</a>.</li>
<li>Once <strong class="source-inline">minikube</strong> has been installed, you can start <strong class="source-inline">minikube</strong> using the following command:<p class="source-code"><strong class="bold">&gt; minikube start</strong></p></li>
</ol>
<p>A <a id="_idIndexMarker374"/>successful <strong class="source-inline">minikube start</strong> looks as follows:</p>
<div>
<div class="IMG---Figure" id="_idContainer044">
<img alt="Figure 3.17 – Starting minikube " height="486" src="image/B17084_03_017.jpg" width="1460"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.17 – Starting minikube</p>
<ol>
<li value="3">Now, just <a id="_idIndexMarker375"/>like we have to create a Dockerfile to create a Docker image, we have to create a <strong class="source-inline">YAML</strong> file to give deployment instructions to the Kubernetes cluster. In our project, we will name this <strong class="source-inline">YAML</strong> file <strong class="source-inline">deployment.yaml</strong>. The following is the code in the <strong class="source-inline">deployment.yaml</strong> file:<p class="source-code"><strong class="bold">apiVersion: v1</strong></p><p class="source-code"><strong class="bold">kind: Service</strong></p><p class="source-code"><strong class="bold">metadata:</strong></p><p class="source-code"><strong class="bold">  name: hello-docker-service</strong></p><p class="source-code"><strong class="bold">spec:</strong></p><p class="source-code"><strong class="bold">  selector:</strong></p><p class="source-code"><strong class="bold">    app: hello-docker-app</strong></p><p class="source-code"><strong class="bold">  ports:</strong></p><p class="source-code"><strong class="bold">    - protocol: "TCP"</strong></p><p class="source-code"><strong class="bold">      port: 8080</strong></p><p class="source-code"><strong class="bold">      targetPort: 8080</strong></p><p class="source-code"><strong class="bold">      nodePort: 30036</strong></p><p class="source-code"><strong class="bold">  type: LoadBalancer</strong></p><p class="source-code"><strong class="bold">---</strong></p><p class="source-code"><strong class="bold">apiVersion: apps/v1</strong></p><p class="source-code"><strong class="bold">kind: Deployment</strong></p><p class="source-code"><strong class="bold">metadata:</strong></p><p class="source-code"><strong class="bold">  name: hello-docker-app</strong></p><p class="source-code"><strong class="bold">spec:</strong></p><p class="source-code"><strong class="bold">  selector:</strong></p><p class="source-code"><strong class="bold">    matchLabels:</strong></p><p class="source-code"><strong class="bold">      app: hello-docker-app</strong></p><p class="source-code"><strong class="bold">  replicas: 5</strong></p><p class="source-code"><strong class="bold">  template:</strong></p><p class="source-code"><strong class="bold">    metadata:</strong></p><p class="source-code"><strong class="bold">      labels:</strong></p><p class="source-code"><strong class="bold">        app: hello-docker-app</strong></p><p class="source-code"><strong class="bold">    </strong><strong class="bold">spec:</strong></p><p class="source-code"><strong class="bold">      containers:</strong></p><p class="source-code"><strong class="bold">        - name: hello-docker-app</strong></p><p class="source-code"><strong class="bold">          image: hello-docker-app</strong></p><p class="source-code"><strong class="bold">          imagePullPolicy: Never</strong></p><p class="source-code"><strong class="bold">          ports:</strong></p><p class="source-code"><strong class="bold">            - containerPort: 8080</strong></p></li>
</ol>
<p>The <strong class="source-inline">deployment.yaml</strong> file<a id="_idIndexMarker376"/> contains two types of configuration: one for <strong class="source-inline">Service</strong> and one for <strong class="source-inline">Deployment</strong>. Each Kubernetes component configuration consists of mainly three parts:</p>
<ul>
<li><strong class="source-inline">metadata</strong> consists of the name and any other meta information. </li>
<li><strong class="source-inline">spec</strong> contains the specification. This is directly dependent on the kind of component that is being configured. </li>
<li><strong class="source-inline">status</strong> is not something we have to configure. The Kubernetes cluster adds that part and keeps updating it after the deployment is done. </li>
</ul>
<ol>
<li value="4">First, you have to <a id="_idIndexMarker377"/>build the <strong class="source-inline">hello-docker-app</strong> image and expose it to the <strong class="source-inline">minikube</strong> Docker environment. You can do that by executing the following commands:<p class="source-code"><strong class="bold">&gt; eval $(minikube docker-env)</strong></p><p class="source-code"><strong class="bold">&gt; docker build --tag hello-docker-app:latest .</strong></p></li>
<li>Now, you can deploy this application in a Kubernetes cluster using the following command from the project root folder:<p class="source-code"><strong class="bold">&gt; kubectl apply -f deployment.yaml</strong></p></li>
</ol>
<p>After executing this command, you should be able to see that <strong class="source-inline">hello-docker-service</strong> and <strong class="source-inline">hello-docker-app</strong> were created successfully, as shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer045">
<img alt="Figure 3.18 – Applications created in Kubernetes cluster  " height="205" src="image/B17084_03_018.jpg" width="1307"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.18 – Applications created in Kubernetes cluster </p>
<ol>
<li value="6">You can also check the deployments and their status in the minikube dashboard by executing the following command:<p class="source-code"><strong class="bold">&gt; minikube dashboard</strong></p></li>
</ol>
<p>Once executed, you should see the dashboard appear in your default browser. Here, you will be able to see the status of your deployment, as well as other monitoring information:</p>
<div>
<div class="IMG---Figure" id="_idContainer046">
<img alt="Figure 3.19 – The minikube dashboard " height="812" src="image/B17084_03_019.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.19 – The minikube dashboard</p>
<ol>
<li value="7">Now, you can access <a id="_idIndexMarker378"/>the deployed application and start its services using the following command:<p class="source-code"><strong class="bold">&gt; minikube start service: hello-docker-service</strong></p></li>
</ol>
<p>Once you have started the service, you can check the base URL that’s been exposed by the Docker service linked to your application by executing the following command:</p>
<p class="source-code"><strong class="bold">&gt; minikube service --url hello-docker-service</strong></p>
<p>This command will show an output similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer047">
<img alt="Figure 3.20 – Checking the base URL " height="230" src="image/B17084_03_020.jpg" width="1288"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.20 – Checking the base URL</p>
<ol>
<li value="8">You can verify the <a id="_idIndexMarker379"/>running application from your browser by using the <strong class="source-inline">http://127.0.0.1:63883/hello</strong> URL for this example, as follows:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer048">
<img alt="Figure 3.21 – Testing app deployed using Kubernetes " height="265" src="image/B17084_03_021.jpg" width="1049"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.21 – Testing app deployed using Kubernetes</p>
<p>In this section, we discussed how virtualization and containerization can help you manage, deploy, and develop an application in more effective, faster, and cost-optimized ways. General web applications, backend applications, and other processing applications work extremely well on scalable virtual platforms such as containers and VMs. However, big data, which amounts to terabytes and petabytes of data, requires a platform with a different kind of architecture to perform well. From the next section onwards, we will discuss platforms that are apt for big data processing.</p>
<h1 id="_idParaDest-52"><a id="_idTextAnchor051"/>Hadoop platforms</h1>
<p>With the advent of <a id="_idIndexMarker380"/>search engines, social networks, and online marketplaces, data volumes grew exponentially. Searching and processing such data volumes needed a different approach to meet the <strong class="bold">service-level agreements</strong> (<strong class="bold">SLAs</strong>) and <a id="_idIndexMarker381"/>customer expectations. Both Google and Nutch used a new technology paradigm to solve this problem, thus storing and processing data in a distributed way automatically. As a result of this approach, Hadoop was born in 2008 and has proved to be a lifesaver for storing and processing huge volumes (in the order of terabytes or more) of data efficiently and quickly.</p>
<p>Apache Hadoop<a id="_idIndexMarker382"/> is an open source framework that enables distributed storage and processing of large datasets across a cluster of computers. It is designed to scale from a single server to thousands of machines easily. It provides high availability by having strong node failover and recovery features, which enables a Hadoop cluster to run on cheap commodity hardware.</p>
<h2 id="_idParaDest-53"><a id="_idTextAnchor052"/>Hadoop architecture</h2>
<p>In this section, we will discuss the <a id="_idIndexMarker383"/>architecture and various components of a Hadoop cluster. The following diagram provides a top-level overview of the Hadoop ecosystem:</p>
<div>
<div class="IMG---Figure" id="_idContainer049">
<img alt="Figure 3.22 – Hadoop ecosystem overview " height="601" src="image/B17084_03_022.jpg" width="711"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.22 – Hadoop ecosystem overview</p>
<p>As shown in the preceding diagram, the Hadoop ecosystem consists of three separate layers, as discussed here:</p>
<ul>
<li><strong class="bold">Storage layer</strong>: The storage layer<a id="_idIndexMarker384"/> in Hadoop is known as <strong class="bold">Hadoop Distributed File System</strong> (<strong class="bold">HDFS</strong>). HDFS <a id="_idIndexMarker385"/>supports distributed and replicated storage of large datasets, which provides high availability and high-performance access to data. The following diagram provides an overview of the HDFS architecture:</li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer050">
<img alt="Figure 3.23 – HDFS architecture " height="675" src="image/B17084_03_023.jpg" width="1299"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.23 – HDFS architecture</p>
<p>HDFS has a <a id="_idIndexMarker386"/>master-slave architecture where the <strong class="bold">NameNode</strong> is the master and all <strong class="bold">DataNodes</strong> are the slaves. The <strong class="bold">NameNode</strong> is responsible for storing metadata about all the files and directories in HDFS. It is also responsible for storing a mapping of which blocks are stored in which <strong class="bold">DataNode</strong>. There is a secondary <strong class="bold">NameNode</strong> that is responsible for the housekeeping jobs of the <strong class="bold">NameNode</strong> such as compaction. DataNodes are the real horsepower in an HDFS system. They are responsible for storing block-level data and performing all the necessary block-level operations on it. The <strong class="bold">DataNode</strong> sends periodical signals called heartbeats to the <strong class="bold">NameNode</strong> to specify that they are up and running. It also sends a block report to the <strong class="bold">NameNode</strong> every tenth heartbeat. </p>
<p>When the client makes a read request, it gets the metadata information about the files and blocks from the <strong class="bold">NameNode</strong>. Then, it fetches the required blocks from the correct <strong class="bold">DataNode</strong>(s) using this metadata. When a client makes a write call, the data gets written into distributed blocks across various DataNodes. These blocks are then replicated across the nodes (on a different rack) for high availability in case there is an outage in the current rack.</p>
<ul>
<li><strong class="bold">Resource manager layer</strong>: The <a id="_idIndexMarker387"/>resource manager is a framework that manages cluster resources and is also responsible for scheduling Hadoop jobs. The following diagram shows how the resource manager works:</li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer051">
<img alt="Figure 3.24 – How resource manager works " height="948" src="image/B17084_03_024.jpg" width="1575"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.24 – How resource manager works</p>
<p>As we can see, each client sends a request to the <strong class="bold">Resource Manager</strong> when they submit a processing job in Hadoop. The <strong class="bold">Resource Manager</strong> consists of a <strong class="bold">Scheduler</strong> and an <strong class="bold">Application Manager</strong>. Here, the <strong class="bold">Application Manager</strong> is responsible for negotiating with the application’s master container by communicating with node managers in different data nodes. Each application master is responsible for executing a single application. Then, the <strong class="bold">Scheduler</strong> in the <strong class="bold">Resource Manager</strong> is responsible for negotiating other container resources by interacting with the <a id="_idIndexMarker388"/>node managers based on the resource requests from the ApplicationMaster. Two of the most popular resource <a id="_idIndexMarker389"/>managers in Hadoop<a id="_idIndexMarker390"/> are <strong class="bold">Apache YARN</strong> and <strong class="bold">Apache Mesos</strong>.</p>
<ul>
<li><strong class="bold">Processing layer</strong>: The processing layer<a id="_idIndexMarker391"/> is responsible for the parallel processing of distributed datasets in the Hadoop ecosystem. Two <a id="_idIndexMarker392"/>of the most popular Hadoop processing engines are <strong class="bold">MapReduce</strong> and <strong class="bold">Apache Spark</strong>. MapReduce programs are tightly coupled to the <a id="_idIndexMarker393"/>Hadoop environment. It primarily processes data using two mandatory phases – the map phase and the reduce phase – and uses several optional data processing phases. It writes intermediate data back to HDFS between these phases. On the other hand, Spark reads the distributed data in a <a id="_idIndexMarker394"/>logically distributed dataset called <strong class="bold">Resilient Distributed Dataset</strong> (<strong class="bold">RDD</strong>) and creates a <strong class="bold">Directed Acyclic Graph</strong> (<strong class="bold">DAG</strong>) consisting of stages and tasks to process the data. Since it doesn’t <a id="_idIndexMarker395"/>write the intermediate data to disk (unless shuffling is explicitly required), it usually works 10 times faster than MapReduce.</li>
</ul>
<p>Although these three layers are interdependent, the design is such that the layers are decoupled from each other. This decoupled layer architecture makes Hadoop more flexible, powerful, and extendable. This is why Hadoop processing has improved and evolved, even though the sizes of datasets have grown at a tremendous rate and expected SLAs to process data have reduced over time.</p>
<p>Although Hadoop is an open source<a id="_idIndexMarker396"/> framework, all production Hadoop clusters run in one of the following distributions:</p>
<ul>
<li><strong class="bold">Hortonworks Data Platform</strong> or <strong class="bold">HDP</strong> (discontinued)</li>
<li><strong class="bold">Cloudera Distribution of Hadoop</strong> or <strong class="bold">CDH</strong> (discontinued)</li>
<li><strong class="bold">Cloudera Data Platform</strong> (both HDP and CDH can migrate to this platform after the Hortonworks and Cloudera merger)</li>
<li><strong class="bold">MapR Distributions</strong></li>
</ul>
<p>Apart from these distributions, which are meant for on-premise Hadoop deployments, some popular cloud distributions<a id="_idIndexMarker397"/> for Hadoop are available:</p>
<ul>
<li><strong class="bold">CDP Public cloud</strong> from Cloudera</li>
<li><strong class="bold">Elastic MapReduce</strong> (<strong class="bold">EMR</strong>) from <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>)</li>
<li><strong class="bold">HDInsight</strong> from Microsoft Azure</li>
<li><strong class="bold">Cloud Dataproc</strong> from <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>)</li>
</ul>
<p>In this section, we briefly discussed Hadoop distributions and how they work. We also covered the various Hadoop distributions that are available from various vendors for running Hadoop in a production environment.</p>
<p>As data keeps growing, there is a need to grow the on-premise infrastructure. Such infrastructure capacities need to be planned to support the maximum load. This creates either underutilization of resources or overutilization of resources if an unexpected load occurs. The answer to this problem is cloud computing. In the next section, we will discuss various cloud platforms and the benefit they bring to data engineering solutions.</p>
<h1 id="_idParaDest-54"><a id="_idTextAnchor053"/>Cloud platforms</h1>
<p>Cloud computing involves <a id="_idIndexMarker398"/>delivering computing services such as storage, compute, networking, and intelligence over the internet. It offers a pay-as-you-go model, which means you only pay for the service you use. This helps cut down on your operating costs, as well<a id="_idIndexMarker399"/> as <strong class="bold">capital expenditure</strong> (<strong class="bold">CapEx</strong>) costs. Cloud enables optimal resource utilization, instant scalability, agility, and ease of maintenance, enabling faster innovation and economies of scale. For example, Canva<a id="_idIndexMarker400"/> is a design tool that anyone can access via its simple user interface. In 2019, it had 55 million users. At the time of writing, it has 85 million users worldwide, creating 100+ designs per second. To accommodate this exponential customer and data volume growth seamlessly with similar or better performance, Canva uses the AWS platform.</p>
<p>The following cloud computing distributions<a id="_idIndexMarker401"/> are the market leaders in cloud computing and are often referred to as the Big 3 of cloud computing:</p>
<ul>
<li>AWS by Amazon</li>
<li>Microsoft Azure by Microsoft</li>
<li>GCP by Google</li>
</ul>
<p>Apart from the Big 3, there are other smaller or lesser-known cloud distributions such as Red Hat OpenShift, HPE GreenLake, and IBM Cloud.</p>
<h2 id="_idParaDest-55"><a id="_idTextAnchor054"/>Benefits of cloud computing</h2>
<p>The following are the <a id="_idIndexMarker402"/>benefits of cloud computing:</p>
<ul>
<li><strong class="bold">Cost-effective</strong>: Cloud computing reduces the CapEx cost by eliminating the huge costs involved in the infrastructure setup. It also reduces cost by applying a pay-as-you-go model.</li>
<li><strong class="bold">Scalable</strong>: Since cloud services are all virtualized, they can be spun up within minutes or seconds, enabling extremely fast scalability.</li>
<li><strong class="bold">Elastic</strong>: Cloud services can be easily scaled up or down based on the resource and compute demand.</li>
<li><strong class="bold">Reliable</strong>: Since each service is replicated across availability zones as well as regions, the services are highly reliable and guarantee minimum downtime.</li>
<li><strong class="bold">Global</strong>: Since the cloud service is on the internet, the computation power can be delivered across the globe, from the right geographic location.</li>
<li><strong class="bold">Increased productivity</strong>: Since provisioning, managing, and deploying resources and services are no longer headaches for developers, they can focus on business functionality and deliver solutions much faster and effectively.</li>
<li><strong class="bold">Secure</strong>: Along with<a id="_idIndexMarker403"/> the other benefits, the cloud has a lot of security layers and services, making the cloud a secure infrastructure.</li>
</ul>
<p>There are three types of cloud computing, as follows:</p>
<ul>
<li><strong class="bold">Public cloud</strong>: Public clouds<a id="_idIndexMarker404"/> are owned and operated by <a id="_idIndexMarker405"/>third-party vendors who deliver computing resources and services over the internet. Here, as a user of the public cloud, you must pay for what you use.</li>
<li><strong class="bold">Private cloud</strong>: A private cloud<a id="_idIndexMarker406"/> is a form of cloud computing where <a id="_idIndexMarker407"/>the computing resources are owned by the customer, usually in a private on-premise data center. The cloud provider only provides the cloud software and its support. Usually, this is used by big enterprises where security and compliance are constraints for moving toward the public cloud. Here, the customers are responsible for managing and monitoring cloud resources.</li>
<li><strong class="bold">Hybrid cloud</strong>: Hybrid clouds<a id="_idIndexMarker408"/> combine both public and <a id="_idIndexMarker409"/>private clouds, bound together by technology through which data and applications can communicate and move seamlessly between private and public clouds. This provides higher flexibility when it comes to security, compliance, and agility.</li>
</ul>
<p>Now that we have discussed the different types of cloud computing, let’s try to understand the <a id="_idIndexMarker410"/>various types of cloud services available in a public <a id="_idIndexMarker411"/>cloud distribution. The various types of <a id="_idIndexMarker412"/>cloud services<a id="_idIndexMarker413"/> are as follows:</p>
<ul>
<li><strong class="bold">Infrastructure as a Service</strong> (<strong class="bold">IaaS</strong>)</li>
<li><strong class="bold">Platform as a Service</strong> (<strong class="bold">PaaS</strong>)</li>
<li><strong class="bold">Software as a Service</strong> (<strong class="bold">SaaS</strong>)</li>
</ul>
<p>In the cloud, the responsibility of owning various stacks in application development is shared between cloud vendors and the customers. The following diagram shows the shared responsibility <a id="_idIndexMarker414"/>model for these kinds <a id="_idIndexMarker415"/>of cloud computing services:</p>
<div>
<div class="IMG---Figure" id="_idContainer052">
<img alt="Figure 3.25 – Shared responsibility model " height="495" src="image/B17084_03_025.jpg" width="1096"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.25 – Shared responsibility model</p>
<p>As we can see, if the<a id="_idIndexMarker416"/> customer is running a<a id="_idIndexMarker417"/> private cloud, all the resources, services, applications, and data are the customer’s responsibility. However, if you opt for a public cloud, then you can choose between IaaS, PaaS, and SaaS. Cloud vendors promise to manage and own infrastructure services such as compute, storage, and networking in an IaaS model. If you go for a PaaS model, apart from what you get in IaaS, cloud providers also manage the OS, VMs, and runtime so that you can own, develop, and manage your applications, data, and access. In SaaS, everything except data and access is managed by your cloud vendor. Even the application or software is managed by the cloud provider. Although this might be costlier if you take a single unit compared to the other two models, based on your business, it might be cheaper and more hassle-free.</p>
<p>With that, we have discussed the various platforms where data engineering applications may be deployed. Now, let’s discuss the various design choices that an architect needs to know to choose the correct platform for them.</p>
<h1 id="_idParaDest-56"><a id="_idTextAnchor055"/>Choosing the correct platform</h1>
<p>In this section, we will look at one of the most important decisions architects have to make – <em class="italic">how to choose the most suitable platform for a use case</em>. Here, we will understand when to choose between virtualization versus containerization and on-premise versus the cloud when considering various cloud data platforms.</p>
<h2 id="_idParaDest-57"><a id="_idTextAnchor056"/>When to choose virtualization versus containerization</h2>
<p>Although both<a id="_idIndexMarker418"/> these technologies ensure that we can use resources to the best of our ability by provisioning virtual resources, each has its advantages based on the type of application.</p>
<p>Microservices is<a id="_idIndexMarker419"/> a variant of the service-oriented architecture where an application is perceived as a collection of loosely coupled services. Each service is fine-grained and lightweight. Microservices are best suited for container-based platforms. For example, a REST service can be easily deployed using containers. Since microservices consist of loosely coupled services, they should be easily deployable and scalable. Since each service can be independently consumed and reused by other services and stacks, they need to be portable so that they can quickly migrate to any containerized platform.</p>
<p>On the other hand, monolithic applications<a id="_idIndexMarker420"/> are designed to perform multiple related tasks, but it is built as a tightly coupled single application. Such applications are more suited for small teams<a id="_idIndexMarker421"/> or <strong class="bold">Proof of Concept</strong> (<strong class="bold">POC</strong>) purposes. Another use case where such monolithic architectures are used is in legacy applications. Such monolithic applications are best suited for virtualization. Another use case where virtualized platforms are preferred over containerization is in any application that is dependent on an OS or talks directly to a specific OS.</p>
<p>However, in the cloud, all <a id="_idIndexMarker422"/>the servers that are provisioned are VMs. Containerized platforms such as Amazon <strong class="bold">Elastic Container Service</strong> (<strong class="bold">ECS</strong>) and Amazon <strong class="bold">Elastic Kubernetes Service</strong> (<strong class="bold">EKS</strong>) run<a id="_idIndexMarker423"/> on top of virtual servers such as Amazon <strong class="bold">Elastic Compute Cloud</strong> (<strong class="bold">EC2</strong>). So, in <a id="_idIndexMarker424"/>modern architectures, especially in the cloud, the question is not choosing between containerization and virtualization – it is choosing between containerization along with virtualization versus virtualization. </p>
<h2 id="_idParaDest-58"><a id="_idTextAnchor057"/>When to use big data</h2>
<p>If we are<a id="_idIndexMarker425"/> handling data that is terabytes or petabytes in size, big data is a good choice. As <strong class="bold">artificial intelligence</strong> (<strong class="bold">AI</strong>) and <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) applications are <a id="_idIndexMarker426"/>growing in popularity, we need to deal with huge <a id="_idIndexMarker427"/>volumes of data – the larger the data, more accurate will be the AI models. These volumes of data run into the terabytes. Processing such data in a scalable fashion can be done by big data applications. There are use cases where, due to processing complexity, processing hundreds of gigabytes of data takes an unnecessarily long time. In such<a id="_idIndexMarker428"/> scenarios, big data may be a good solution. Most big data use cases are for analytics, <strong class="bold">Online Analytical Processing</strong> (<strong class="bold">OLAP</strong>), AI, and ML.</p>
<h2 id="_idParaDest-59"><a id="_idTextAnchor058"/>Choosing between on-premise versus cloud-based solutions</h2>
<p>This is an obvious <a id="_idIndexMarker429"/>question that architects face today. In this section, we will try to see what factors affect this decision, as well as recommend a few general criteria to help you decide on one over the other. The factors that will help you decide between on-premise versus cloud solutions are as follows:</p>
<ul>
<li><strong class="bold">Cost</strong>: Enterprises are responsible for all infrastructure and maintenance costs, including human resources for on-premise environments. Costs also include migration costs from <a id="_idIndexMarker430"/>on-premise to the cloud. Another important cost metric is about CapEx<a id="_idIndexMarker431"/> versus <strong class="bold">operating expenses</strong> (<strong class="bold">OpEx</strong>) and how cost-efficient OpEx will be versus CapEx for the enterprise. All these factors determine the total cost of ownership, which ultimately determines what is best for your business.</li>
<li><strong class="bold">Control</strong>: Enterprises are completely in control of the data, its storage, and all hardware related to the on-premise infrastructure. However, although enterprises own the data, the storage and its hardware are managed by the cloud provider. </li>
<li><strong class="bold">Resource demand pattern</strong>: If the demand for resources is elastic and infrastructure demand is seasonal, then the cloud may be the correct choice. On the other hand, if resource demand is static, then opting for on-premise may be the correct option.</li>
<li><strong class="bold">Agility and scalability</strong>: If your company is a start-up and growing exponentially, which means your demand scales up and down based on the feedback you receive and your volatile customer base, then the cloud will be a better choice for you.</li>
<li><strong class="bold">Security</strong>: Security is a big concern for a few industries, such as finance and healthcare. Although there have been many advances in cloud security and they have a strong robust security model, since the data is stored in hardware managed by a public cloud provider, many such businesses with very sensitive data choose on-premise over the cloud for security reasons.</li>
<li><strong class="bold">Compliance</strong>: Several<a id="_idIndexMarker432"/> industries have very strict regulatory controls and policies, such as federal agencies and healthcare. In such businesses, having complete control over the data and its storage makes more sense. Hence, on-premise options are more suitable. </li>
</ul>
<p>Based on these factors, here are some broad guidelines that you can use to make this decision. However, note that these are only recommendations – the actual choice will depend on your specific business needs and context.</p>
<p>You should choose <a id="_idIndexMarker433"/>on-premise architectures in the following circumstances:</p>
<ul>
<li>Security is a major concern and you don’t want to take the chance of any data risks occurring</li>
<li>Regulatory policies and controls are stringent, stipulating that control of data and its storage should remain within the organization</li>
<li>Legacy systems can’t easily be moved or replicated</li>
<li>The time, effort, and cost involved are not justifiable to migrate data and processing<a id="_idIndexMarker434"/> from on-premise to the cloud</li>
</ul>
<p>You should choose cloud architectures<a id="_idIndexMarker435"/> in the following circumstances:</p>
<ul>
<li>Flexibility and agility to scale and grow are needed</li>
<li>You are a start-up and you have a limited client base and limited CapEx, but you have high growth potential</li>
<li>You want dynamic configurations of the environment that can easily be modified on demand</li>
<li>You do not want to do a CapEx investment on infrastructure and prefer a pay-as-you-go model</li>
<li>You are uncertain about the business demand, and you need to scale your resources up and down frequently</li>
<li>You do not want to expend resources and time to maintain your infrastructure and the cost associated with it</li>
<li>You want an agile<a id="_idIndexMarker436"/> setup, quicker deliveries, and a faster turnaround time for operations</li>
</ul>
<p>Finally, let’s compare the Big 3 cloud vendors to decide which provider is a best fit for your business.</p>
<h2 id="_idParaDest-60"><a id="_idTextAnchor059"/>Choosing between various cloud vendors</h2>
<p>In this section, we will <a id="_idIndexMarker437"/>compare the Big 3 public cloud vendors and how they perform in various categories, even though there is no clear answer to the question, <em class="italic">Which cloud vendor is best for my business?</em> The following table provides a comparison between the Big 3 cloud providers and throws light on their strengths and weaknesses:</p>
<table class="No-Table-Style _idGenTablePara-1" id="table001-1">
<colgroup>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><strong class="bold">AWS</strong></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">Azure</strong></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">GCP</strong></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Services</p>
</td>
<td class="No-Table-Style">
<p>Huge range of services</p>
</td>
<td class="No-Table-Style">
<p>Good range of services available. Exceptional services in AI/ML.</p>
</td>
<td class="No-Table-Style">
<p>Limited services are available.</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Maturity</p>
</td>
<td class="No-Table-Style">
<p>Most mature</p>
</td>
<td class="No-Table-Style">
<p>Catching up with AWS.</p>
</td>
<td class="No-Table-Style">
<p>Still relatively less mature than the other two.</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Marketplace</p>
</td>
<td class="No-Table-Style">
<p>All vendors make their products available</p>
</td>
<td class="No-Table-Style">
<p>Good vendor support but less than AWS.</p>
</td>
<td class="No-Table-Style"/>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Reliability</p>
</td>
<td class="No-Table-Style">
<p>Excellent</p>
</td>
<td class="No-Table-Style">
<p>Excellent.</p>
</td>
<td class="No-Table-Style">
<p>Excellent.</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Security</p>
</td>
<td class="No-Table-Style">
<p>Excellent</p>
</td>
<td class="No-Table-Style">
<p>Excellent.</p>
</td>
<td class="No-Table-Style">
<p>Fewer notches than AWS and Azure.</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Cost</p>
</td>
<td class="No-Table-Style">
<p>Varies</p>
</td>
<td class="No-Table-Style">
<p>Most cost-efficient.</p>
</td>
<td class="No-Table-Style">
<p>Varies.</p>
</td>
</tr>
</tbody>
</table>
<table class="No-Table-Style _idGenTablePara-1" id="table002-1">
<colgroup>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><strong class="bold">AWS</strong></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">Azure</strong></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">GCP</strong></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Support</p>
</td>
<td class="No-Table-Style">
<p>Paid dev/enterprise support</p>
</td>
<td class="No-Table-Style">
<p>Paid dev/enterprise support. More support options than AWS.</p>
</td>
<td class="No-Table-Style">
<p>Paid dev/premium support. Costlier support than the other two.</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Hybrid Cloud Support</p>
</td>
<td class="No-Table-Style">
<p>Limited</p>
</td>
<td class="No-Table-Style">
<p>Excellent.</p>
</td>
<td class="No-Table-Style">
<p>Good.</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Special Notes</p>
</td>
<td class="No-Table-Style">
<p>More compute capacity versus Azure and GCP</p>
</td>
<td class="No-Table-Style">
<p>Easy integration and migrations for existing Microsoft services.</p>
</td>
<td class="No-Table-Style">
<p>Excellent support for containerized workloads.</p>
<p>Global fiber network.</p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.26 – Comparison of the Big 3 cloud vendors</p>
<p>In short, AWS is the market leader but both Azure and GCP are catching up. If you are looking for the maximum number of services available across the globe, AWS will be your obvious choice, but it comes with a higher learning curve.</p>
<p>If your use case revolves only around AI/ML and you have a Microsoft on-premise infrastructure, Azure may be the correct choice. They have excellent enterprise support and hybrid cloud support. If you need a robust hybrid cloud infrastructure, Microsoft Azure is your go-to option.</p>
<p>GCP <a id="_idIndexMarker438"/>entered the race late, but they have excellent integration and support for open source and third-party services.</p>
<p>But in the end, it boils down to your specific use case. As the market is growing, most enterprises are looking for multi-cloud strategies to leverage the best of each vendor.</p>
<p>Now, let’s summarize this chapter.</p>
<h1 id="_idParaDest-61"><a id="_idTextAnchor060"/>Summary</h1>
<p>In this chapter, we discussed various virtualization platforms. First, we briefly covered the architectures of the virtualization, containerization, and container orchestration frameworks. Then, we deployed VMs, Docker containers, and Kubernetes containers and ran an application on top of them. In doing so, we learned how to configure Dockerfiles and Kubernetes deployment scripts. After that, we discussed the Hadoop architecture and the various Hadoop distributions that are available on the market. Then, we briefly discussed cloud computing and its basic concepts. Finally, we covered the decisions that every data architect has to make: <em class="italic">containers or VMs?</em> <em class="italic">Do I need big data processing?</em> <em class="italic">Cloud or on-premise?</em> <em class="italic">If the cloud, which cloud?</em></p>
<p>With that, we have a good understanding of some of the basic concepts and nuances of data architecting, including the basic concepts, databases, data storage, and the various platforms these solutions run on in production. In the next chapter, we will dive deeper into how to architect various data processing and data ingestion pipelines.</p>
</div>
</div>


<div id="sbo-rt-content"><div class="Content" id="_idContainer054">
<h1 id="_idParaDest-62"><a id="_idTextAnchor061"/>Section 2 – Building Data Processing Pipelines</h1>
<p>This section focuses on guiding you to learn how to architect and develop batch processing and stream processing solutions using various technologies in the Java stack. Finally, it will also help you to understand and apply data governance and security to a solution practically.</p>
<p>This section comprises the following chapters:</p>
<ul>
<li><a href="B17084_04.xhtml#_idTextAnchor062"><em class="italic">Chapter 4</em></a><em class="italic">, ETL Data Load – A Batch-Based Solution to Ingest Data in a Data Warehouse</em> </li>
<li><a href="B17084_05.xhtml#_idTextAnchor074"><em class="italic">Chapter 5</em></a><em class="italic">, Architecting a Batch Processing Pipeline</em> </li>
<li><a href="B17084_06.xhtml#_idTextAnchor092"><em class="italic">Chapter 6</em></a><em class="italic">, Architecting a Real-Time Processing Pipeline</em></li>
<li><a href="B17084_07.xhtml#_idTextAnchor110"><em class="italic">Chapter 7</em></a><em class="italic">, Core Architectural Design Patterns</em> </li>
<li><a href="B17084_08.xhtml#_idTextAnchor130"><em class="italic">Chapter 8</em></a><em class="italic">, Enabling Data security and Governance</em> </li>
</ul>
</div>
<div>
<div id="_idContainer055">
</div>
</div>
</div>
</body></html>