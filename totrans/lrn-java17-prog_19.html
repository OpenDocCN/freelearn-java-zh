<html><head></head><body>
		<div id="_idContainer197">
			<h1 id="_idParaDest-338"><em class="italic"><a id="_idTextAnchor337"/>Chapter 16</em>: Java Microbenchmark Harness</h1>
			<p>In this chapter, you will learn<a id="_idIndexMarker1890"/> about a <strong class="bold">Java Microbenchmark Harness</strong> (<strong class="bold">JMH</strong>) project that allows measuring various code performance characteristics. If performance is an important issue for your application, this tool can help you to identify bottlenecks with precision—up to the method level. </p>
			<p>In addition to theoretical knowledge, you will have a chance to run JMH using practical demo examples and recommendations.</p>
			<p>The following topics will be covered in this chapter:</p>
			<ul>
				<li>What is JMH?</li>
				<li>Creating a JMH benchmark</li>
				<li>Running the benchmark</li>
				<li>Using the IDE plugin</li>
				<li>JMH benchmark parameters</li>
				<li>JMH usage examples</li>
			</ul>
			<p>By the end of the chapter, you will be able to not only measure the average execution time of an application and other performance values (such as throughput, for example) but also to do it in a controlled manner—with or without the JVM optimizations, warm-up runs, and so on.</p>
			<h1 id="_idParaDest-339"><a id="_idTextAnchor338"/>Technical requirements</h1>
			<p>To be able to execute the code examples provided in this chapter, you will need the following:</p>
			<ul>
				<li>A computer with a Microsoft Windows, Apple macOS, or Linux operating system </li>
				<li>Java SE version 17 or later</li>
				<li>The IDE or code editor you prefer</li>
			</ul>
			<p>The instructions for how to set up a Java SE and IntelliJ IDEA editor were provided in <a href="B18388_01_ePub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Getting Started with Java 17</em>. The files with the code examples for this chapter are available on GitHub in the <a href="https://github.com/PacktPublishing/Learn-Java-17-Programming.git">https://github.com/PacktPublishing/Learn-Java-17-Programming.git</a> repository in the <strong class="source-inline">examples/src/main/java/com/packt/learnjava/ch16_microbenchmark</strong> folder.</p>
			<h1 id="_idParaDest-340"><a id="_idTextAnchor339"/>What is JMH?</h1>
			<p>According to<a id="_idIndexMarker1891"/> the Oxford English Dictionary, a <strong class="bold">benchmark</strong> is <em class="italic">a standard or point of reference against which things may be compared or assessed</em>. In programming, it is the way to compare the performance of <a id="_idIndexMarker1892"/>applications, or just methods. The <strong class="bold">micro preface</strong> is focused <a id="_idIndexMarker1893"/>on the latter—smaller code fragments rather than an application as a whole. JMH is a framework for measuring the performance of a single method.</p>
			<p>That may appear to be very useful. Can we not just run a method 1,000 or 100,000 times in a loop, measure how long it took, and then calculate the average of the method’s performance? We can. The problem is that JVM is a much more complicated program than just a code-executing machine. It has optimization algorithms focused on making the application code run as fast as possible.</p>
			<p>For example, let’s look at the following class:</p>
			<pre class="source-code">class SomeClass {</pre>
			<pre class="source-code">    public int someMethod(int m, int s) {</pre>
			<pre class="source-code">        int res = 0;</pre>
			<pre class="source-code">        for(int i = 0; i &lt; m; i++){</pre>
			<pre class="source-code">            int n = i * i;</pre>
			<pre class="source-code">            if (n != 0 &amp;&amp; n % s == 0) {</pre>
			<pre class="source-code">                res =+ n;</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">        }</pre>
			<pre class="source-code">        return res;</pre>
			<pre class="source-code">    }</pre>
			<pre class="source-code">}</pre>
			<p>We filled the <strong class="source-inline">someMethod()</strong> method with code that does not make much sense but keeps the method busy. To test the performance of this method, it is tempting to copy the code into a test <a id="_idIndexMarker1894"/>method and run it in a loop:</p>
			<pre class="source-code">public void testCode() {</pre>
			<pre class="source-code">   StopWatch stopWatch = new StopWatch();</pre>
			<pre class="source-code">   stopWatch.start();</pre>
			<pre class="source-code">   int xN = 100_000;</pre>
			<pre class="source-code">   int m = 1000;</pre>
			<pre class="source-code">   for(int x = 0; i &lt; xN; x++) {</pre>
			<pre class="source-code">        int res = 0;</pre>
			<pre class="source-code">        for(int i = 0; i &lt; m; i++){</pre>
			<pre class="source-code">            int n = i * i;</pre>
			<pre class="source-code">            if (n != 0 &amp;&amp; n % 250_000 == 0) {</pre>
			<pre class="source-code">                res += n;</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">        }</pre>
			<pre class="source-code">    }</pre>
			<pre class="source-code">    System.out.println("Average time = " + </pre>
			<pre class="source-code">           (stopWatch.getTime() / xN /m) + "ms");</pre>
			<pre class="source-code">}</pre>
			<p>However, JVM will see that the <strong class="source-inline">res</strong> result is never used and qualify the calculations as <strong class="bold">dead code</strong> (a code<a id="_idIndexMarker1895"/> section that is never executed). So, why bother executing this code at all?</p>
			<p>You may be surprised to see that the significant complication or simplification of the algorithm does not affect the performance. That is because, in every case, the code is not actually executed. </p>
			<p>You may<a id="_idIndexMarker1896"/> change the test method and pretend that the result is used by returning it:</p>
			<pre class="source-code">public int testCode() {</pre>
			<pre class="source-code">   StopWatch stopWatch = new StopWatch();</pre>
			<pre class="source-code">   stopWatch.start();</pre>
			<pre class="source-code">   int xN = 100_000;</pre>
			<pre class="source-code">   int m = 1000;</pre>
			<pre class="source-code">   int res = 0;</pre>
			<pre class="source-code">   for(int x = 0; i &lt; xN; x++) {</pre>
			<pre class="source-code">        for(int i = 0; i &lt; m; i++){</pre>
			<pre class="source-code">            int n = i * i;</pre>
			<pre class="source-code">            if (n != 0 &amp;&amp; n % 250_000 == 0) {</pre>
			<pre class="source-code">                res += n;</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">        }</pre>
			<pre class="source-code">   }</pre>
			<pre class="source-code">   System.out.println("Average time = " + </pre>
			<pre class="source-code">          (stopWatch.getTime() / xN / m) + "ms");</pre>
			<pre class="source-code">   return res;</pre>
			<pre class="source-code">}</pre>
			<p>This may convince JVM to execute the code every time, but it is not guaranteed. JVM may notice that the input into the calculations does not change and this algorithm produces the same result every run. Since the code is based on constant input, this optimization is <a id="_idIndexMarker1897"/>called <strong class="bold">constant folding</strong>. The result of this optimization is that this code may be executed only once and the same result is assumed for every run, without actually executing the code.</p>
			<p>In practice though, the benchmark is often built around a method, not a block of code. For example, the <a id="_idIndexMarker1898"/>test code may look as follows:</p>
			<pre class="source-code">public void testCode() {</pre>
			<pre class="source-code">   StopWatch stopWatch = new StopWatch();</pre>
			<pre class="source-code">   stopWatch.start();</pre>
			<pre class="source-code">   int xN = 100_000;</pre>
			<pre class="source-code">   int m = 1000;</pre>
			<pre class="source-code">   SomeClass someClass = new SomeClass();</pre>
			<pre class="source-code">   for(int x = 0; i &lt; xN; x++) {</pre>
			<pre class="source-code">        someClass.someMethod(m, 250_000);</pre>
			<pre class="source-code">    }</pre>
			<pre class="source-code">    System.out.println("Average time = " + </pre>
			<pre class="source-code">          (stopWatch.getTime() / xN / m) + "ms");</pre>
			<pre class="source-code">}</pre>
			<p>But even this code is susceptible to the same JVM optimization we have just described.</p>
			<p>JMH was created to help to avoid this and similar pitfalls. In the <em class="italic">JMH usage examples</em> section, we will show you how to use JMH to work around the dead code and constant folding optimization, using the <strong class="source-inline">@State</strong> annotation and the <strong class="source-inline">Blackhole</strong> object.</p>
			<p>Besides, JMH <a id="_idIndexMarker1899"/>allows for measuring not only average execution time but also throughput and other performance characteristics.</p>
			<h1 id="_idParaDest-341"><a id="_idTextAnchor340"/>Creating a JMH benchmark</h1>
			<p>To start using<a id="_idIndexMarker1900"/> JMH, the following dependencies have to be added to the <strong class="source-inline">pom.xml</strong> file:</p>
			<pre class="source-code">&lt;dependency&gt;</pre>
			<pre class="source-code">    &lt;groupId&gt;org.openjdk.jmh&lt;/groupId&gt;</pre>
			<pre class="source-code">    &lt;artifactId&gt;jmh-core&lt;/artifactId&gt;</pre>
			<pre class="source-code">    &lt;version&gt;1.21&lt;/version&gt;</pre>
			<pre class="source-code">&lt;/dependency&gt;</pre>
			<pre class="source-code">&lt;dependency&gt;</pre>
			<pre class="source-code">    &lt;groupId&gt;org.openjdk.jmh&lt;/groupId&gt;</pre>
			<pre class="source-code">    &lt;artifactId&gt;jmh-generator-annprocess&lt;/artifactId&gt;</pre>
			<pre class="source-code">    &lt;version&gt;1.21&lt;/version&gt;</pre>
			<pre class="source-code">&lt;/dependency&gt;</pre>
			<p>The name of the second <strong class="source-inline">.jar</strong> file, <strong class="source-inline">annprocess</strong>, provides a hint that JMH uses annotations. If you guessed so, you were correct. Here is an example of a benchmark created for testing the performance of an algorithm:</p>
			<pre class="source-code">public class BenchmarkDemo {</pre>
			<pre class="source-code">    public static void main(String... args) throws Exception{</pre>
			<pre class="source-code">        org.openjdk.jmh.Main.main(args);</pre>
			<pre class="source-code">    }</pre>
			<pre class="source-code">    @Benchmark</pre>
			<pre class="source-code">    public void testTheMethod() {</pre>
			<pre class="source-code">        int res = 0;</pre>
			<pre class="source-code">        for(int i = 0; i &lt; 1000; i++){</pre>
			<pre class="source-code">            int n = i * i;</pre>
			<pre class="source-code">            if (n != 0 &amp;&amp; n % 250_000 == 0) {</pre>
			<pre class="source-code">                res += n;</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">        }</pre>
			<pre class="source-code">    }</pre>
			<pre class="source-code">}</pre>
			<p>Please notice the <strong class="source-inline">@Benchmark</strong> annotation. It tells the framework that this method’s performance has to be measured. If you run the preceding <strong class="source-inline">main()</strong> method, you will see an output similar to the following:</p>
			<div>
				<div id="_idContainer183" class="IMG---Figure">
					<img src="image/B18388_Figure_16.1.jpg" alt=""/>
				</div>
			</div>
			<p>This is only <a id="_idIndexMarker1901"/>one segment of an extensive output that includes multiple iterations under different conditions with the goal being to avoid or offset the JVM optimization. It also takes into account the difference between running the code once and running it multiple times. In the latter case, JVM starts using the just-in-time compiler, which compiles the often-used bytecodes’ code into native binary code and does not even read the bytecodes. The warm-up cycles serve this purpose—the code is executed without measuring its performance as a dry run that <em class="italic">warms up</em> the JVM.</p>
			<p>There are also ways to tell the JVM which method to compile and use as binary directly, which method to compile every time, and to provide similar instructions to disable certain optimization. We will talk about this shortly.</p>
			<p>Let’s now see how to run the benchmark.</p>
			<h1 id="_idParaDest-342"><a id="_idTextAnchor341"/>Running the benchmark</h1>
			<p>As you have <a id="_idIndexMarker1902"/>probably guessed, one way to run a benchmark is just to execute the <strong class="source-inline">main()</strong> method. It can be done using the <strong class="source-inline">java</strong> command directly or using the IDE. We talked about it in <a href="B18388_01_ePub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Getting Started with Java 17</em>. Yet there is an easier and more convenient way to run a benchmark: by using an IDE plugin.</p>
			<h2 id="_idParaDest-343"><a id="_idTextAnchor342"/>Using an IDE plugin</h2>
			<p>All major Java-<a id="_idIndexMarker1903"/>supporting<a id="_idIndexMarker1904"/> IDEs have such a plugin. We will demonstrate how to use the plugin for IntelliJ installed on a macOS computer, but it is equally applicable to Windows systems.</p>
			<p>Here are the steps to follow:</p>
			<ol>
				<li>To start installing the plugin, press the <em class="italic">command</em> key and comma (<em class="italic">,</em>) together, or just click the wrench symbol (with the hover text <strong class="bold">Preferences</strong>) in the top horizontal menu:<div id="_idContainer184" class="IMG---Figure"><img src="image/B18388_Figure_16.2.jpg" alt=""/></div></li>
			</ol>
			<ol>
				<li value="2">It will open a window with the following menu in the left pane:</li>
			</ol>
			<div>
				<div id="_idContainer185" class="IMG---Figure">
					<img src="image/B18388_Figure_16.3.jpg" alt=""/>
				</div>
			</div>
			<ol>
				<li value="3">Select <strong class="bold">Plugins</strong>, as <a id="_idIndexMarker1905"/>shown in the preceding <a id="_idIndexMarker1906"/>screenshot, and observe the window with the following top horizontal menu:</li>
			</ol>
			<div>
				<div id="_idContainer186" class="IMG---Figure">
					<img src="image/B18388_Figure_16.4.jpg" alt=""/>
				</div>
			</div>
			<ol>
				<li value="4">Select <strong class="bold">Marketplace</strong>, type <strong class="source-inline">JMH</strong> in the <strong class="bold">Search plugins in marketplace</strong> input field, and press <em class="italic">Enter</em>. If you have an internet connection, it will show you a <strong class="bold">JMH plugin</strong> symbol, similar to the one shown in the following screenshot:<div id="_idContainer187" class="IMG---Figure"><img src="image/B18388_Figure_16.5.jpg" alt=""/></div></li>
			</ol>
			<ol>
				<li value="5">Click the <strong class="bold">Install</strong> button and <a id="_idIndexMarker1907"/>then, after it turns into <strong class="bold">Restart IDE</strong>, click<a id="_idIndexMarker1908"/> it again:</li>
			</ol>
			<div>
				<div id="_idContainer188" class="IMG---Figure">
					<img src="image/B18388_Figure_16.6.jpg" alt=""/>
				</div>
			</div>
			<ol>
				<li value="6">After the IDE restarts, the plugin is ready to be used. Now you can not only run the <strong class="source-inline">main()</strong> method but you can also pick and choose which of the benchmark methods to execute if you have several methods with the <strong class="source-inline">@Benchmark</strong> annotation. To do this, select <strong class="bold">Run...</strong> from the <strong class="bold">Run</strong> drop-down menu: </li>
			</ol>
			<div>
				<div id="_idContainer189" class="IMG---Figure">
					<img src="image/B18388_Figure_16.7.jpg" alt=""/>
				</div>
			</div>
			<ol>
				<li value="7">It will bring <a id="_idIndexMarker1909"/>up <a id="_idIndexMarker1910"/>a window with a selection of methods you can run:</li>
			</ol>
			<div>
				<div id="_idContainer190" class="IMG---Figure">
					<img src="image/B18388_Figure_16.8.jpg" alt=""/>
				</div>
			</div>
			<ol>
				<li value="8">Select the one you would like to run and it will be executed. After you have run a method at least once, you can just right-click on it and execute it from the pop-up menu:</li>
			</ol>
			<div>
				<div id="_idContainer191" class="IMG---Figure">
					<img src="image/B18388_Figure_16.9.jpg" alt=""/>
				</div>
			</div>
			<ol>
				<li value="9">You can also use the shortcuts shown to the right of each menu item.</li>
			</ol>
			<p>Now let’s <a id="_idIndexMarker1911"/>review<a id="_idIndexMarker1912"/> the parameters that can be passed to the benchmark.</p>
			<h1 id="_idParaDest-344"><a id="_idTextAnchor343"/>JMH benchmark parameters</h1>
			<p>There are <a id="_idIndexMarker1913"/>many benchmark parameters that allow for fine-tuning the measurements for the particular needs of the task at hand. We are going to present only the major ones.</p>
			<h2 id="_idParaDest-345"><a id="_idTextAnchor344"/>Mode</h2>
			<p>The first set of<a id="_idIndexMarker1914"/> parameters defines the performance aspect (mode) the particular benchmark has to measure:</p>
			<ul>
				<li><strong class="source-inline">Mode.AverageTime</strong>: Measures the average execution time</li>
				<li><strong class="source-inline">Mode.Throughput</strong>: Measures the throughput by calling the benchmark method in an iteration</li>
				<li><strong class="source-inline">Mode.SampleTime</strong>: Samples the execution time, instead of averaging it; allows us to infer the distributions, percentiles, and so on</li>
				<li><strong class="source-inline">Mode.SingleShotTime</strong>: Measures the single method invocation time; allows for the testing of a cold startup without calling the benchmark method continuously</li>
			</ul>
			<p>These parameters can be specified in the annotation <strong class="source-inline">@BenchmarkMode</strong>, for example:</p>
			<pre class="source-code">@BenchmarkMode(Mode.AverageTime)</pre>
			<p>It is possible to combine several modes:</p>
			<pre class="source-code">@BenchmarkMode({Mode.Throughput, Mode.AverageTime, Mode.SampleTime, Mode.SingleShotTime}</pre>
			<p>It is also possible to request all of them:</p>
			<pre class="source-code">@BenchmarkMode(Mode.All)</pre>
			<p>The described parameters and all the parameters we are going to discuss later in this chapter can be <a id="_idIndexMarker1915"/>set at the method and/or class level. The method-level set value overrides the class-level value.</p>
			<h2 id="_idParaDest-346"><a id="_idTextAnchor345"/>Output time unit</h2>
			<p>The unit <a id="_idIndexMarker1916"/>of time used for presenting the results can be specified using the <strong class="source-inline">@OutputTimeUnit</strong> annotation:</p>
			<pre class="source-code">@OutputTimeUnit(TimeUnit.NANOSECONDS)</pre>
			<p>The possible time units come from the <strong class="source-inline">java.util.concurrent.TimeUnit</strong> enum.</p>
			<h2 id="_idParaDest-347"><a id="_idTextAnchor346"/>Iterations</h2>
			<p>Another group of parameters defines<a id="_idIndexMarker1917"/> the iterations used for the warm-ups and measurements, for example: </p>
			<pre class="source-code">@Warmup(iterations = 5, time = 100, </pre>
			<pre class="source-code">                          timeUnit =  TimeUnit.MILLISECONDS)</pre>
			<pre class="source-code">@Measurement(iterations = 5, time = 100, </pre>
			<pre class="source-code">                           timeUnit = TimeUnit.MILLISECONDS)</pre>
			<h2 id="_idParaDest-348"><a id="_idTextAnchor347"/>Forking</h2>
			<p>While running<a id="_idIndexMarker1918"/> several tests, the <strong class="source-inline">@Fork</strong> annotation allows you to set each test to be run in a separate process, for example:</p>
			<pre class="source-code">@Fork(10)</pre>
			<p>The passed-in parameter value indicates how many times the JVM can be forked into independent processes. The default value is <strong class="source-inline">-1</strong>. Without it, the test’s performance can be mixed if you use several classes implementing the same interface in tests and they affect each other.</p>
			<p>The <strong class="source-inline">warmups</strong> parameter is another one that can be set to indicate how many times the benchmark has to execute without collecting measurements:</p>
			<pre class="source-code">@Fork(value = 10, warmups = 5)</pre>
			<p>It also allows you to add Java options to the java command line, for example:</p>
			<pre class="source-code">@Fork(value = 10, jvmArgs = {"-Xms2G", "-Xmx2G"})</pre>
			<p>The full list of JMH parameters and examples of how to use them can be found in the <strong class="source-inline">openjdk</strong> project (<a href="http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples">http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples</a>). For example, we did not mention <strong class="source-inline">@Group</strong>, <strong class="source-inline">@GroupThreads</strong>, <strong class="source-inline">@Measurement</strong>, <strong class="source-inline">@Setup</strong>, <strong class="source-inline">@Threads</strong>, <strong class="source-inline">@Timeout</strong>, <strong class="source-inline">@TearDown</strong>, or <strong class="source-inline">@Warmup</strong>.</p>
			<h1 id="_idParaDest-349"><a id="_idTextAnchor348"/>JMH usage examples</h1>
			<p>Let’s now run<a id="_idIndexMarker1919"/> a few tests and compare them. First, we run the following test method:</p>
			<pre class="source-code">@Benchmark</pre>
			<pre class="source-code">@BenchmarkMode(Mode.All)</pre>
			<pre class="source-code">@OutputTimeUnit(TimeUnit.NANOSECONDS)</pre>
			<pre class="source-code">public void testTheMethod0() {</pre>
			<pre class="source-code">    int res = 0;</pre>
			<pre class="source-code">    for(int i = 0; i &lt; 1000; i++){</pre>
			<pre class="source-code">        int n = i * i;</pre>
			<pre class="source-code">        if (n != 0 &amp;&amp; n % 250_000 == 0) {</pre>
			<pre class="source-code">            res += n;</pre>
			<pre class="source-code">        }</pre>
			<pre class="source-code">    }</pre>
			<pre class="source-code">}</pre>
			<p>As you can see, we have requested to measure all the performance characteristics and to use nanoseconds while presenting the results. On our system, the test execution took around 20 minutes <a id="_idIndexMarker1920"/>and the final result summary looked like this:</p>
			<div>
				<div id="_idContainer192" class="IMG---Figure">
					<img src="image/B18388_Figure_16.10.jpg" alt=""/>
				</div>
			</div>
			<p>Let’s now change the test as follows:</p>
			<pre class="source-code">@Benchmark</pre>
			<pre class="source-code">@BenchmarkMode(Mode.All)</pre>
			<pre class="source-code">@OutputTimeUnit(TimeUnit.NANOSECONDS)</pre>
			<pre class="source-code">public void testTheMethod1() {</pre>
			<pre class="source-code">    SomeClass someClass = new SomeClass();</pre>
			<pre class="source-code">    int i = 1000;</pre>
			<pre class="source-code">    int s = 250_000;</pre>
			<pre class="source-code">    someClass.someMethod(i, s);</pre>
			<pre class="source-code">}</pre>
			<p>If we run the <strong class="source-inline">testTheMethod1()</strong> now, the results will be slightly different:</p>
			<div>
				<div id="_idContainer193" class="IMG---Figure">
					<img src="image/B18388_Figure_16.11.jpg" alt=""/>
				</div>
			</div>
			<p>The results are<a id="_idIndexMarker1921"/> mostly different around sampling and single-shot running. You can play with these methods and change the forking and number of warm-ups. </p>
			<h2 id="_idParaDest-350"><a id="_idTextAnchor349"/>Using the @State annotation</h2>
			<p>This JMH<a id="_idIndexMarker1922"/> feature<a id="_idIndexMarker1923"/> allows you to hide the source of the data from JVM, thus preventing dead code optimization. You can add a class as the source of the input data as follows:</p>
			<pre class="source-code">@State(Scope.Thread)</pre>
			<pre class="source-code">public static class TestState {</pre>
			<pre class="source-code">    public int m = 1000;</pre>
			<pre class="source-code">    public int s = 250_000;</pre>
			<pre class="source-code">}</pre>
			<pre class="source-code">@Benchmark</pre>
			<pre class="source-code">@BenchmarkMode(Mode.All)</pre>
			<pre class="source-code">@OutputTimeUnit(TimeUnit.NANOSECONDS)</pre>
			<pre class="source-code">public int testTheMethod3(TestState state) {</pre>
			<pre class="source-code">    SomeClass someClass = new SomeClass();</pre>
			<pre class="source-code">    return someClass.someMethod(state.m, state.s);</pre>
			<pre class="source-code">}</pre>
			<p>The <strong class="source-inline">Scope</strong> value is used for sharing data between tests. In our case, with only one test using the <strong class="source-inline">TestCase</strong> class object, we do not have a need for sharing. Otherwise, the value can be set to <strong class="source-inline">Scope.Group</strong> or <strong class="source-inline">Scope.Benchmark</strong>, which means we could add setters to the <strong class="source-inline">TestState</strong> class and read/modify it in other tests.</p>
			<p>When we ran this version of the test, we got the following results:</p>
			<div>
				<div id="_idContainer194" class="IMG---Figure">
					<img src="image/B18388_Figure_16.12.jpg" alt=""/>
				</div>
			</div>
			<p>The data <a id="_idIndexMarker1924"/>has <a id="_idIndexMarker1925"/>changed again. Notice that the average time for execution has increased three-fold, which indicates that more JVM optimization was not applied.</p>
			<h2 id="_idParaDest-351"><a id="_idTextAnchor350"/>Using the Blackhole object</h2>
			<p>This JMH<a id="_idIndexMarker1926"/> feature<a id="_idIndexMarker1927"/> allows for simulating result usage, thus preventing JVM from implementing folding constants optimization:</p>
			<pre class="source-code">@Benchmark</pre>
			<pre class="source-code">@BenchmarkMode(Mode.All)</pre>
			<pre class="source-code">@OutputTimeUnit(TimeUnit.NANOSECONDS)</pre>
			<pre class="source-code">public void testTheMethod4(TestState state, </pre>
			<pre class="source-code">                                       Blackhole blackhole){</pre>
			<pre class="source-code">  SomeClass someClass = new SomeClass();</pre>
			<pre class="source-code">  blackhole.consume(someClass.someMethod(state.m, state.s));</pre>
			<pre class="source-code">}</pre>
			<p>As you can see, we have just added a parameter <strong class="source-inline">Blackhole</strong> object and called the <strong class="source-inline">consume()</strong> method on it, thus pretending that the result of the tested method is used.</p>
			<p>When we ran this version of the test, we got the following results:</p>
			<div>
				<div id="_idContainer195" class="IMG---Figure">
					<img src="image/B18388_Figure_16.13.jpg" alt=""/>
				</div>
			</div>
			<p>This time, the results look not that different. Apparently, the constant folding optimization was neutralized even before the <strong class="source-inline">Blackhole</strong> usage was added. </p>
			<h2 id="_idParaDest-352"><a id="_idTextAnchor351"/>Using the @CompilerControl annotation</h2>
			<p>Another way<a id="_idIndexMarker1928"/> to tune up the benchmark is to tell the compiler to <a id="_idIndexMarker1929"/>compile, inline (or not), and exclude (or not) a particular method from the code. For example, consider the following class:</p>
			<pre class="source-code">class SomeClass{</pre>
			<pre class="source-code">     public int oneMethod(int m, int s) {</pre>
			<pre class="source-code">        int res = 0;</pre>
			<pre class="source-code">        for(int i = 0; i &lt; m; i++){</pre>
			<pre class="source-code">            int n = i * i;</pre>
			<pre class="source-code">            if (n != 0 &amp;&amp; n % s == 0) {</pre>
			<pre class="source-code">                res = anotherMethod(res, n);</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">        }</pre>
			<pre class="source-code">        return res;</pre>
			<pre class="source-code">    }</pre>
			<pre class="source-code">    <strong class="bold">@CompilerControl(CompilerControl.Mode.EXCLUDE)</strong></pre>
			<pre class="source-code">    private int anotherMethod(int res, int n){</pre>
			<pre class="source-code">        return res +=n;</pre>
			<pre class="source-code">    }</pre>
			<pre class="source-code">}</pre>
			<p>Assuming we are interested in how the method <strong class="source-inline">anotherMethod()</strong> compilation/inlining affects the performance, we can set the <strong class="source-inline">CompilerControl</strong> mode on it to the following:</p>
			<ul>
				<li><strong class="source-inline">Mode.INLINE</strong>: To force method inlining</li>
				<li><strong class="source-inline">Mode.DONT_INLINE</strong>: To avoid method inlining</li>
				<li><strong class="source-inline">Mode.EXCLUDE</strong>: To<a id="_idIndexMarker1930"/> avoid<a id="_idIndexMarker1931"/> method compiling</li>
			</ul>
			<h2 id="_idParaDest-353"><a id="_idTextAnchor352"/>Using the @Param annotation</h2>
			<p>Sometimes, it <a id="_idIndexMarker1932"/>is necessary<a id="_idIndexMarker1933"/> to run the same benchmark for a different set of input data. In such a case, the <strong class="source-inline">@Param</strong> annotation is very useful.</p>
			<p><strong class="source-inline">@Param</strong> is a standard Java annotation used by various frameworks, for example, JUnit. It identifies an array of parameter values. The test with the <strong class="source-inline">@Param</strong> annotation will be run as many times as there are values in the array. Each test execution picks up a different value from the array.</p>
			<p>Here is an example:</p>
			<pre class="source-code">@State(Scope.Benchmark)</pre>
			<pre class="source-code">public static class TestState1 {</pre>
			<pre class="source-code">    @Param({"100", "1000", "10000"})</pre>
			<pre class="source-code">    public int m;</pre>
			<pre class="source-code">    public int s = 250_000;</pre>
			<pre class="source-code">}</pre>
			<pre class="source-code">@Benchmark</pre>
			<pre class="source-code">@BenchmarkMode(Mode.All)</pre>
			<pre class="source-code">@OutputTimeUnit(TimeUnit.NANOSECONDS)</pre>
			<pre class="source-code">public void testTheMethod6(TestState1 state, </pre>
			<pre class="source-code">                                       Blackhole blackhole){</pre>
			<pre class="source-code">  SomeClass someClass = new SomeClass();</pre>
			<pre class="source-code">  blackhole.consume(someClass.someMethod(state.m, state.s));</pre>
			<pre class="source-code">}</pre>
			<p>The <strong class="source-inline">testTheMethod6()</strong> benchmark is <a id="_idIndexMarker1934"/>going<a id="_idIndexMarker1935"/> to be used with each of the listed values of the parameter <strong class="source-inline">m</strong>.</p>
			<h1 id="_idParaDest-354"><a id="_idTextAnchor353"/>A word of caution</h1>
			<p>The described harness takes away most of the worries of the programmer who measures the performance. And yet, it is virtually impossible to cover all the cases of JVM optimization, profile sharing, and similar aspects of JVM implementation, especially if we take into account that JVM code evolves and differs from one implementation to another. The authors of JMH acknowledge this fact by printing the following warning along with the test results:</p>
			<div>
				<div id="_idContainer196" class="IMG---Figure">
					<img src="image/B18388_Figure_16.14.jpg" alt=""/>
				</div>
			</div>
			<p>The description of the profilers and their usage can be found in the <strong class="source-inline">openjdk</strong> project (<a href="http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples">http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples</a>). Among the same samples, you will encounter a description of the code generated by JMH, based on the annotations.</p>
			<p>If you would like to get really deep into the details of your code execution and testing, there is no better way to do it than to study the generated code. It describes all the steps and decisions JMH makes in order to run the requested benchmark. You can find the generated code in <strong class="source-inline">target/generated-sources/annotations</strong>.</p>
			<p>The scope of this book does not allow for going into too many details on how to read it, but it is not very difficult, especially if you start with a simple case of testing one method only. We wish you all the best in this endeavor.</p>
			<h1 id="_idParaDest-355"><a id="_idTextAnchor354"/>Summary</h1>
			<p>In this chapter, you have learned about the JMH tool and were able to use it for your applications. You have learned how to create and run a benchmark, how to set the benchmark parameters, and how to install IDE plugins if needed. We have also provided practical recommendations and references for further reading.</p>
			<p>Now you are able to not only measure the average execution time of an application and other performance values (such as throughput, for example) but to do it in a controlled manner—with or without JVM optimizations, warm-up runs, and so on.</p>
			<p>In the next chapter, you will learn useful practices for designing and writing application code. We will talk about Java idioms, their implementation and usage, and provide recommendations for implementing <strong class="source-inline">equals()</strong>, <strong class="source-inline">hashCode()</strong>, <strong class="source-inline">compareTo()</strong>, and <strong class="source-inline">clone()</strong> methods. We will also discuss the difference between the usage of the <strong class="source-inline">StringBuffer</strong> and <strong class="source-inline">StringBuilder</strong> classes, how to catch exceptions, best design practices, and other proven programming practices.</p>
			<h1 id="_idParaDest-356"><a id="_idTextAnchor355"/>Quiz</h1>
			<ol>
				<li value="1">Select all the correct statements:<ol><li>JMH is useless since it runs methods outside the production context.</li><li>JMH is able to work around some JVM optimizations.</li><li>JMH allows for measuring not only average performance time but other performance characteristics too.</li><li>JMH can be used to measure the performance of small applications too.</li></ol></li>
				<li>Name two steps necessary to start using JMH.</li>
				<li>Name four ways JMH can be run.</li>
				<li>Name two modes (performance characteristics) that can be used (measured) with JMH.</li>
				<li>Name two of the time units that can be used to present JMH test results.</li>
				<li>How can data (results, state) be shared between JMH benchmarks?</li>
				<li>How do you tell JMH to run the benchmark for the parameter with the enumerated list of values?</li>
				<li>How can the compilation of a method be forced or turned off?</li>
				<li>How can the JVM's constant folding optimization be turned off?</li>
				<li>How can Java command options be provided programmatically for running a particular benchmark?</li>
			</ol>
		</div>
	</body></html>