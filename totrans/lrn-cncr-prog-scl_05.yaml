- en: Chapter 5. Data-Parallel Collections
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章 数据并行集合
- en: '|   | *"Premature optimization is the root of all evil."* |   |'
  id: totrans-1
  prefs: []
  type: TYPE_TB
  zh: '|   | *"过早优化是万恶之源。"* |   |'
- en: '|   | --*Donald Knuth* |'
  id: totrans-2
  prefs: []
  type: TYPE_TB
  zh: '|   | --*唐纳德·克努特* |'
- en: So far, we have been composing multiple threads of computation into safe concurrent
    programs. In doing so, we focused on ensuring their correctness. We saw how to
    avoid blocking in concurrent programs, react to the completion of asynchronous
    computations, and how to use concurrent data structures to communicate information
    between threads. All these tools made organizing the structure of concurrent programs
    easier. In this chapter, we will focus mainly on achieving good performance. We
    require minimal or no changes in the organization of existing programs, but we
    will study how to reduce their running time using multiple processors. Futures
    from the previous chapter allowed doing this to a certain extent, but they are
    relatively heavyweight and inefficient when the asynchronous computation in each
    future is short.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在将多个计算线程组合成安全的并发程序。在这样做的时候，我们专注于确保它们的正确性。我们看到了如何避免在并发程序中阻塞，如何对异步计算的完成做出反应，以及如何使用并发数据结构在线程之间传递信息。所有这些工具使组织并发程序的结构变得更加容易。在本章中，我们将主要关注实现良好的性能。我们要求对现有程序的组织进行最小或没有更改，但我们将研究如何使用多个处理器来减少它们的运行时间。前一章中的Futures允许在一定程度上做到这一点，但它们在异步计算较短时相对较重且效率低下。
- en: '**Data parallelism** is a form of computation where the same computation proceeds
    in parallel on different data elements. Rather than having concurrent computation
    tasks that communicate through the use of synchronization, in data-parallel programming,
    independent computations produce values that are eventually merged together in
    some way. An input to a data-parallel operation is usually a dataset such as a
    collection, and the output can be a value or another dataset.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据并行**是一种计算形式，其中相同的计算在不同的数据元素上并行进行。在数据并行编程中，独立的计算产生值，这些值最终以某种方式合并在一起，而不是通过同步使用并发计算任务进行通信。数据并行操作的一个输入通常是一个数据集，如集合，输出可以是一个值或另一个数据集。'
- en: 'In this chapter, we will study the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将研究以下主题：
- en: Starting a data-parallel operation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动数据并行操作
- en: Configuring the parallelism level of a data-parallel collection
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置数据并行集合的并行级别
- en: Measuring performance and why it is important
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能测量及其重要性
- en: Differences between using sequential and parallel collections
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用顺序集合和并行集合之间的差异
- en: Using parallel collections together with concurrent collections
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将并行集合与并发集合一起使用
- en: Implementing a custom parallel collection, such as a parallel string
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现自定义并行集合，例如并行字符串
- en: Alternative data-parallel frameworks
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的数据并行框架
- en: In Scala, data-parallel programming was applied to the standard collection framework
    to accelerate bulk operations that are, by their nature, declarative and fit data
    parallelism well. Before studying data-parallel collections, we will present a
    brief overview of the Scala collection framework.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在Scala中，数据并行编程被应用于标准集合框架，以加速本质上声明性且非常适合数据并行的批量操作。在学习数据并行集合之前，我们将简要介绍Scala集合框架。
- en: Scala collections in a nutshell
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scala集合概述
- en: 'The Scala collections module is a package in the Scala standard library that
    contains a variety of general-purpose collection types. Scala collections provide
    a general and easy-to-use way of declaratively manipulating data using functional
    combinators. For example, in the following program, we use the `filter` combinator
    on a range of numbers to return a sequence of palindromes between 0 and 100,000;
    that is, numbers that are read in the same way in both the forward and reverse
    direction:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Scala集合模块是Scala标准库中的一个包，其中包含各种通用集合类型。Scala集合提供了一种通用且易于使用的方法，通过函数组合器声明性地操作数据。例如，在以下程序中，我们使用`filter`组合器对一系列数字进行操作，以返回0到100,000之间的回文数序列；即正向和反向读取方式相同的数字：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Scala collections define three basic types of collections: **sequences**, **maps**,
    and **sets**. Elements stored in sequences are ordered and can be retrieved using
    the `apply` method and an integer index. Maps store key-value pairs and can be
    used to retrieve a value associated with a specific key. Sets can be used to test
    the element membership with the `apply` method.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 集合定义了三种基本的集合类型：**序列**、**映射**和**集合**。存储在序列中的元素是有序的，可以使用 `apply` 方法和整数索引来检索。映射存储键值对，可以用来检索与特定键关联的值。集合可以使用
    `apply` 方法来测试元素成员资格。
- en: The Scala collection library makes a distinction between immutable collections,
    which cannot be modified after they are created, and mutable collections which
    can be updated after they are created. Commonly used immutable sequences are `List`
    and `Vector`, while `ArrayBuffer` is the mutable sequence of choice in most situations.
    Mutable `HashMap` and `HashSet` collections are maps and sets implemented using
    hash tables, while immutable `HashMap` and `HashSet` collections are based on
    the less widely known hash trie data structure.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 集合库在不可变集合和可变集合之间做出了区分，不可变集合在创建后不能被修改，而可变集合在创建后可以被更新。常用的不可变序列有 `List` 和
    `Vector`，而 `ArrayBuffer` 是大多数情况下选择的可变序列。可变的 `HashMap` 和 `HashSet` 集合是使用哈希表实现的映射和集合，而不可变的
    `HashMap` 和 `HashSet` 集合基于不太为人所知的哈希 trie 数据结构。
- en: 'Scala collections can be transformed into their parallel counterparts by calling
    the `par` method. The resulting collection is called a **parallel collection**,
    and its operations are accelerated by using multiple processors simultaneously.
    The previous example can run in parallel, as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 集合可以通过调用 `par` 方法转换为它们的并行对应物。得到的集合被称为**并行集合**，其操作通过同时使用多个处理器来加速。前面的例子可以并行运行，如下所示：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the preceding code line, the filter combinator is a data-parallel operation.
    In this chapter, we will study parallel collections in more detail. We will see
    when and how to create parallel collections, study how they can be used together
    with sequential collections, and conclude by implementing a custom parallel collection
    class.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码行中，过滤器组合器是一个数据并行操作。在本章中，我们将更详细地研究并行集合。我们将看到何时以及如何创建并行集合，研究它们如何与顺序集合一起使用，并以实现一个自定义并行集合类作为结论。
- en: Using parallel collections
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用并行集合
- en: 'Most of the concurrent programming utilities we have studied so far are used
    in order to enable different threads of computation to exchange information. Atomic
    variables, the `synchronized` statement, concurrent queues, futures, and promises
    are focused on ensuring the correctness of a concurrent program. On the other
    hand, the parallel collection programming model is designed to be largely identical
    to that of sequential Scala collections; parallel collections exist solely in
    order to improve the running time of the program. In this chapter, we will measure
    the relative speedup of programs using parallel collections. To make this task
    easier, we will introduce the `timed` method to the package object used for the
    examples in this chapter. This method takes a block of code body, and returns
    the running time of the executing block of code `body`. It starts by recording
    the current time with the `nanoTime` method from the JDK `System` class. It then
    runs the body, records the time after the body executes, and computes the time
    difference:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们迄今为止研究的大多数并发编程工具都是为了使不同的计算线程能够交换信息。原子变量、`synchronized` 语句、并发队列、未来和承诺都专注于确保并发程序的正确性。另一方面，并行集合编程模型被设计成与顺序
    Scala 集合在很大程度上相同；并行集合的存在只是为了提高程序的运行时间。在本章中，我们将测量使用并行集合的程序相对加速速度。为了使这项任务更容易，我们将向本章中用于示例的包对象引入
    `timed` 方法。此方法接受一个代码块，并返回执行代码块 `body` 的运行时间。它首先使用 JDK `System` 类的 `nanoTime` 方法记录当前时间。然后运行代码块，记录代码块执行后的时间，并计算时间差：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Certain runtime optimizations in the JVM, such as dead-code elimination, can
    potentially remove the invocation of the `body` block, causing us to measure an
    incorrect running time. To prevent this, we assign the return value of the `body`
    block to a volatile field named `dummy`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: JVM 中的一些运行时优化，如死代码消除，可能会删除 `body` 块的调用，导致我们测量到不正确的运行时间。为了防止这种情况，我们将 `body` 块的返回值赋给一个名为
    `dummy` 的易变字段。
- en: 'Program performance is subject to many factors, and it is very hard to predict
    in practice. Whenever you can, you should validate your performance assumptions
    with measurements. In the following example, we use the Scala `Vector` class to
    create a vector with five million numbers and then shuffle that vector using the
    `Random` class from the `scala.util` package. We then compare the running time
    of the sequential and parallel `max` methods, which both find the greatest integer
    in the `numbers` collection:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 程序性能受许多因素影响，在实践中很难预测。只要可能，你应该通过测量来验证你的性能假设。在以下示例中，我们使用Scala的`Vector`类创建一个包含五百万个数字的向量，然后使用`scala.util`包中的`Random`类来打乱该向量。然后我们比较顺序和并行`max`方法的运行时间，这两个方法都在`numbers`集合中找到最大的整数：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Running this program on an Intel i7-4900MQ quad-core processor with hyper-threading
    and Oracle JVM Version 1.7.0_51, we find that the sequential `max` method takes
    244 milliseconds, while its parallel version takes 35 milliseconds. This is partly
    because parallel collections are optimized better than their sequential counterparts,
    and partly because they use multiple processors. However, on different processors
    and JVM implementations, results will vary.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在配备英特尔i7-4900MQ四核处理器和超线程技术以及Oracle JVM版本1.7.0_51的机器上运行此程序，我们发现顺序`max`方法需要244毫秒，而其并行版本只需要35毫秒。这主要是因为并行集合比它们的顺序版本优化得更好，部分原因是它们使用了多个处理器。然而，在不同的处理器和JVM实现中，结果可能会有所不同。
- en: Tip
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Always validate assumptions about performance by measuring the execution time.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 总是通过测量执行时间来验证关于性能的假设。
- en: The `max` method is particularly well-suited for parallelization. Worker threads
    can independently scan subsets of the collection, such as `numbers`. When a worker
    thread finds the greatest integer in its own subset, it notifies the other processors
    and they agree on the greatest result. This final step takes much less time than
    searching for the greatest integer in a collection subset. We say that the `max`
    method is **trivially parallelizable**.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`max`方法非常适合并行化。工作线程可以独立地扫描集合的子集，例如`numbers`。当一个工作线程在其子集中找到最大的整数时，它会通知其他处理器，并就最大结果达成一致。这一步比在集合子集中搜索最大整数所需的时间要少得多。我们说`max`方法是**易于并行化**的。'
- en: 'In general, data-parallel operations require more inter-processor communication
    than the `max` method. Consider the `incrementAndGet` method on atomic variables
    from [Chapter 3](ch03.html "Chapter 3. Traditional Building Blocks of Concurrency"),
    *Traditional Building Blocks of Concurrency*. We can use this method once again
    to compute unique identifiers. This time, we will use parallel collections to
    compute a large number of unique identifiers:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，数据并行操作比`max`方法需要更多的处理器间通信。考虑[第3章](ch03.html "第3章。并发传统的构建块")中原子变量的`incrementAndGet`方法。我们可以再次使用此方法来计算唯一标识符。这次，我们将使用并行集合来计算大量唯一标识符：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This time, we use parallel collections in a `for` loop; recall that every occurrence
    of a `for` loop is desugared into the `foreach` call by the compiler. The parallel
    `for` loop from the preceding code is equivalent to the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们在`for`循环中使用并行集合；回想一下，编译器会将每个`for`循环的出现转换为`foreach`调用。前面代码中的并行`for`循环等同于以下代码：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: When the `foreach` method is called on a parallel collection, collection elements
    are processed concurrently. This means that separate worker threads simultaneously
    invoke the specified function, so proper synchronization must be applied. In our
    case, this synchronization is ensured by the atomic variable, as explained in
    [Chapter 3](ch03.html "Chapter 3. Traditional Building Blocks of Concurrency"),
    *Traditional Building Blocks of Concurrency*.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当在并行集合上调用`foreach`方法时，集合元素会并发处理。这意味着不同的工作线程会同时调用指定的函数，因此必须应用适当的同步。在我们的例子中，这种同步是通过原子变量来保证的，如[第3章](ch03.html
    "第3章。并发传统的构建块")中所述，*并发传统的构建块*。
- en: Running this program on our machine reveals that there is no increase in speed.
    In fact, the parallel version of the program is even slower; our program prints
    320 milliseconds for the sequential `foreach` call, and 1,041 milliseconds for
    the parallel `foreach` call.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的机器上运行此程序显示，速度没有增加。事实上，程序的并行版本甚至更慢；我们的程序为顺序`foreach`调用打印了320毫秒，为并行`foreach`调用打印了1,041毫秒。
- en: You might be surprised to see this; shouldn't a program be running at least
    four times faster on a quad-core processor with hyper-threading? As shown by the
    preceding example, this is not always the case. The parallel `foreach` call is
    slower because the worker threads simultaneously invoke the `incrementAndGet`
    method on the atomic variable, `uid`, and write to the same memory location at
    once.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会感到惊讶看到这一点；程序在具有超线程的四核处理器上至少应该运行四倍快，对吧？正如前面的例子所示，这并不总是如此。并行`foreach`调用较慢，因为工作线程同时调用原子变量`uid`上的`incrementAndGet`方法，并一次性写入相同的内存位置。
- en: 'Memory writes do not go directly to **Random Access Memory** (**RAM**) in modern
    architectures, as this would be too slow. Instead, modern computer architectures
    separate the CPU from the RAM with multiple levels of caches: smaller, more expensive,
    and much faster memory units that hold copies of parts of the RAM that the processor
    is currently using. The cache level closest to the CPU is called the L1 cache.
    The L1 cache is divided into short contiguous parts called **cache lines**. Typically,
    a cache-line size is 64 bytes. Although multiple cores can read the same cache
    line simultaneously, in standard multicore processors, the cache line needs to
    be in exclusive ownership when a core writes to it. When another core requests
    to write to the same cache line, the cache line needs to be copied to that core''s
    L1 cache. The cache coherence protocol that enables this is called **Modified
    Exclusive Shared Invalid** (**MESI**), and its specifics are beyond the scope
    of this book. All you need to know is that exchanging cache-line ownership can
    be relatively expensive in terms of the processor''s time scale.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代架构中，内存写入不会直接写入**随机存取存储器**（**RAM**），因为这会太慢。相反，现代计算机架构通过多级缓存将CPU与RAM分开：更小、更昂贵且速度更快的内存单元，这些单元保存了处理器当前正在使用的RAM部分。最接近CPU的缓存级别称为L1缓存。L1缓存被划分为称为**缓存行**的短连续部分。通常，缓存行大小为64字节。尽管多个核心可以同时读取相同的缓存行，但在标准多核处理器中，当核心写入时，缓存行需要处于独占所有者状态。当另一个核心请求写入相同的缓存行时，需要将该缓存行复制到该核心的L1缓存。使这成为可能的缓存一致性协议称为**修改独占共享无效**（**MESI**），其具体内容超出了本书的范围。你需要知道的是，在处理器的时间尺度上，交换缓存行所有者可能相对昂贵。
- en: 'Since the `uid` variable is atomic, the JVM needs to ensure a happens-before
    relationship between the writes and reads of the `uid` variable, as we know from
    [Chapter 2](ch02.html "Chapter 2. Concurrency on the JVM and the Java Memory Model"),
    *Concurrency on the JVM and the Java Memory Model*. To ensure the happens-before
    relationship, memory writes have to be visible to other processors. The only way
    to ensure this is to obtain the cache line in exclusive mode before writing to
    it. In our example, different processor cores repetitively exchange the ownership
    of the cache line in which the `uid` variable is allocated, and the resulting
    program becomes much slower than its sequential version. This is shown in the
    following diagram:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`uid`变量是原子的，JVM需要确保`uid`变量的写入和读取之间存在happens-before关系，正如我们从[第二章](ch02.html
    "第二章. JVM和Java内存模型中的并发")，*JVM和Java内存模型中的并发*中得知。为了确保happens-before关系，内存写入必须对其他处理器可见。确保这一点的唯一方法是写入之前以独占模式获取缓存行。在我们的例子中，不同的处理器核心反复交换`uid`变量分配的缓存行的所有权，导致程序比其顺序版本慢得多。这在下图中显示：
- en: '![Using parallel collections](img/image_05_001.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![使用并行集合](img/image_05_001.jpg)'
- en: If different processors only read a shared memory location, then there is no
    slowdown. Writing to the same memory location is, on the other hand, an obstacle
    to scalability.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不同的处理器只读取共享内存位置，则不会出现减速。另一方面，写入相同的内存位置是可扩展性的障碍。
- en: Tip
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Writing to the same memory location with proper synchronization leads to performance
    bottlenecks and contention; avoid this in data-parallel operations.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 使用适当的同步写入相同的内存位置会导致性能瓶颈和竞争；在数据并行操作中避免这种情况。
- en: Parallel programs share other resources in addition to computing power. When
    different parallel computations request more resources than are currently available,
    an effect known as **resource contention** occurs. The specific kind of resource
    contention that occurs in our example is called a **memory contention**, a conflict
    over exclusive rights to write to a specific part of memory.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 除了计算能力之外，并行程序还共享其他资源。当不同的并行计算请求的资源超过当前可用资源时，就会发生一种称为**资源竞争**的现象。在我们示例中发生的特定类型的资源竞争被称为**内存竞争**，即对写入特定内存部分的排他权的冲突。
- en: We can expect the same kind of performance degradation when using multiple threads
    to concurrently start the `synchronized` statement on the same object, repetitively
    modifying the same key in a concurrent map or simultaneously enqueueing elements
    to a concurrent queue; all these actions require writes to the same memory location.
    Nonetheless, this does not mean that threads should never write to the same memory
    locations. In some applications, concurrent writes occur very infrequently; the
    ratio between the time spent writing to contended memory locations and the time
    spent doing other work determines whether parallelization is beneficial or not.
    It is difficult to predict this ratio by just looking at the program; the `ParUid`
    example serves to illustrate that we should always measure in order to see the
    impact of contention.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以预期，当使用多个线程并发地对同一对象上的`synchronized`语句进行重复修改，或在并发映射中同时修改相同的键，或在并发队列中同时入队元素时，会出现相同类型的性能下降；所有这些操作都需要写入相同的内存位置。尽管如此，这并不意味着线程永远不会写入相同的内存位置。在某些应用程序中，并发写入非常罕见；写入竞争内存位置所花费的时间与执行其他工作所花费的时间之间的比率决定了并行化是否有益。仅通过查看程序很难预测这个比率；`ParUid`示例旨在说明我们应该始终进行测量，以了解竞争的影响。
- en: Parallel collection class hierarchy
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行集合类层次结构
- en: As we saw, parallel collection operations execute on different worker threads
    simultaneously. At any point during the execution of a parallel operation, an
    element in a parallel collection can be processed by at most one worker thread
    executing that operation. The block of code associated with the parallel operation
    is executed on each of the elements separately; in the `ParUid` example, the `incrementAndGet`
    method is called concurrently many times. Whenever a parallel operation executes
    any side-effects, it must take care to use proper synchronization; the naive approach
    of using `var` to store `uid` causes data races as it did in [Chapter 2](ch02.html
    "Chapter 2. Concurrency on the JVM and the Java Memory Model"), *Concurrency on
    the JVM and the Java Memory Model*. This is not the case with sequential Scala
    collections.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，并行集合操作是在不同的工作线程上同时执行的。在并行操作执行过程中的任何时刻，并行集合中的一个元素最多只能被一个执行该操作的工作线程处理。与并行操作相关的代码块是分别在每个元素上执行的；在`ParUid`示例中，`incrementAndGet`方法被并发多次调用。每当并行操作执行任何副作用时，它必须注意使用适当的同步；使用`var`来存储`uid`的简单方法会导致数据竞争，就像在[第2章](ch02.html
    "第2章。JVM和Java内存模型上的并发")中发生的那样，*JVM和Java内存模型上的并发*。这与顺序Scala集合的情况不同。
- en: The consequence is that a parallel collection cannot be a subtype of a sequential
    collection. If it were, then the *Liskov substitution principle* would be violated.
    The Liskov substitution principle states that if type `S` is a subtype of `T`,
    then the object of type `T` can be replaced with objects of type `S` without affecting
    the correctness of the program.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，并行集合不能成为顺序集合的子类型。如果是这样，那么就会违反**Liskov替换原则**。Liskov替换原则指出，如果类型`S`是类型`T`的子类型，那么类型`T`的对象可以被类型`S`的对象替换，而不会影响程序的正确性。
- en: 'In our case, if parallel collections are subtypes of sequential collections,
    then some methods can return a sequential sequence collection with the static
    type `Seq[Int]`, where the sequence object is a parallel sequence collection at
    runtime. Clients can call methods such as `foreach` on the collection without
    knowing that the body of the `foreach` method needs synchronization, and their
    programs would not work correctly. For these reasons, parallel collections form
    a hierarchy that is separate from the sequential collections, as shown in the
    following diagram:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，如果并行集合是顺序集合的子类型，那么某些方法可以返回具有静态类型`Seq[Int]`的顺序序列集合，其中序列对象在运行时是并行序列集合。客户端可以在不知道`foreach`方法体需要同步的情况下调用集合上的方法，而他们的程序将无法正确运行。出于这些原因，并行集合形成了一个与顺序集合分开的层次结构，如下面的图所示：
- en: '![Parallel collection class hierarchy](img/image_05_002.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![并行集合类层次结构](img/image_05_002.jpg)'
- en: Scala collection hierarchy
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Scala集合层次结构
- en: 'The preceding diagram shows the simplified Scala collection hierarchy with
    sequential collections on the left. The most general collection type is called
    `Traversable`. Different collection operations such as `find`, `map`, `filter`,
    or `reduceLeft` are implemented in terms of its abstract `foreach` method. Its
    `Iterable[T]` subtype offers additional operations such as `zip`, `grouped`, `sliding`,
    and `sameElements`, implemented using its `iterator` method. The `Seq`, `Map`,
    and `Set` traits are iterable collections that represent Scala sequences, maps,
    and sets, respectively. These traits are used to write code that is generic in
    the type of the concrete Scala collection. The following `nonNull` method copies
    elements from an `xs` collection that are different from `null`. Here, the `xs`
    collection can be a `Vector[T]`, `List[T]`, or some other sequence:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图显示了简化的Scala集合层次结构，其中顺序集合位于左侧。最一般的集合类型称为`Traversable`。不同的集合操作，如`find`、`map`、`filter`或`reduceLeft`，都是基于其抽象的`foreach`方法实现的。其`Iterable[T]`子类型提供了额外的操作，如`zip`、`grouped`、`sliding`和`sameElements`，这些操作使用其`iterator`方法实现。`Seq`、`Map`和`Set`特质是可迭代的集合，分别代表Scala的序列、映射和集合。这些特质用于编写针对具体Scala集合类型的通用代码。下面的`nonNull`方法从`xs`集合中复制与`null`不同的元素。在这里，`xs`集合可以是`Vector[T]`、`List[T]`或其他序列：
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Parallel collections form a separate hierarchy. The most general parallel collection
    type is called `ParIterable`. Methods such as `foreach`, `map`, or `reduce` on
    a `ParIterable` object execute in parallel. The `ParSeq`, `ParMap`, and `ParSet`
    collections are parallel collections that correspond to `Seq`, `Map`, and `Set`,
    but are not their subtypes. We can rewrite the `nonNull` method to use parallel
    collections:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 并行集合形成了一个单独的层次结构。最一般的并行集合类型称为`ParIterable`。在`ParIterable`对象上执行的方法，如`foreach`、`map`或`reduce`，将并行执行。`ParSeq`、`ParMap`和`ParSet`集合是并行集合，对应于`Seq`、`Map`和`Set`，但不是它们的子类型。我们可以将`nonNull`方法重写为使用并行集合：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Although the implementation is identical, we can no longer pass a sequential
    collection to the `nonNull` method. We can call `.par` on the sequential `xs`
    collection before passing it to the `nonNull` method, but then the `filter` method
    will execute in parallel. Can we instead write code that is agnostic in the type
    of the collection? The generic collection types: `GenTraversable`, `GenIterable`,
    `GenSeq`, `GenMap`, and `GenSet` exist for this purpose. Each of them represents
    a supertype of the corresponding sequential or parallel collection type. For example,
    the `GenSeq` generic sequence type allows us to rewrite the `nonNull` method as
    follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然实现相同，但我们不能再将顺序集合传递给`nonNull`方法。我们可以在将集合传递给`nonNull`方法之前，对顺序的`xs`集合调用`.par`，但这样`filter`方法将并行执行。我们能否编写对集合类型无知的代码？存在用于此目的的通用集合类型：`GenTraversable`、`GenIterable`、`GenSeq`、`GenMap`和`GenSet`。每个都代表相应顺序或并行集合类型的超类型。例如，`GenSeq`通用序列类型允许我们将`nonNull`方法重写如下：
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: When using generic collection types, we need to remember that they might be
    implemented either as a sequential collection or as a parallel collection. Thus,
    as a precaution, if operations invoked on a generic collection execute any side
    effects, you should use synchronization.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用通用集合类型时，我们需要记住它们可能被实现为顺序集合或并行集合。因此，作为预防措施，如果在通用集合上执行的操作有任何副作用，您应该使用同步。
- en: Tip
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Treat operations invoked on a generic collection type as if they are parallel.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 将在通用集合类型上执行的操作视为并行操作。
- en: Configuring the parallelism level
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置并行级别
- en: Parallel collections use all the processors by default; their underlying executor
    has as many workers as there are processors. We can change this default behavior
    by changing the `TaskSupport` object of the parallel collection. The basic `TaskSupport`
    implementation is the `ForkJoinTaskSupport` class. It takes a `ForkJoinPool` collection
    and uses it to schedule parallel operations.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 并行集合默认使用所有处理器；其底层执行器的工作者数量与处理器数量相同。我们可以通过更改并行集合的`TaskSupport`对象来改变这种默认行为。基本的`TaskSupport`实现是`ForkJoinTaskSupport`类。它接受一个`ForkJoinPool`集合，并使用它来调度并行操作。
- en: 'Therefore, to change the parallelism level of a parallel collection, we instantiate
    a `ForkJoinPool` collection with the desired parallelism level:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，要改变并行集合的并行级别，我们需要实例化一个具有所需并行级别的`ForkJoinPool`集合：
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Once a `TaskSupport` object is created, we can use it with different parallel
    collections. Every parallel collection has a `tasksupport` field that we use to
    assign the `TaskSupport` object to it.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了一个`TaskSupport`对象，我们就可以使用它与不同的并行集合一起使用。每个并行集合都有一个`tasksupport`字段，我们使用它将`TaskSupport`对象分配给它。
- en: Measuring the performance on the JVM
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在JVM上测量性能
- en: To correctly measure the running time on the JVM is not an easy task. Under
    the hood, the JVM does a lot more than meets the eye. The Scala compiler does
    not produce machine code directly runnable on the CPU. Instead, the Scala compiler
    produces a special intermediate instruction code called **Java bytecode**. When
    bytecode from the Scala compiler gets run inside the JVM, at first it executes
    in so-called **interpreted mode**; the JVM interprets each bytecode instruction
    and simulates the execution of the program. Only when the JVM decides that the
    bytecode in a certain method was run often enough does it compile the bytecode
    to machine code, which can be executed directly on the processor. This process
    is called **just-in-time compilation**.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在JVM上正确测量运行时间不是一项容易的任务。在底层，JVM做了很多超出我们视线的工作。Scala编译器不会直接产生可在CPU上运行的机器码。相反，Scala编译器产生一种特殊的中间指令代码，称为**Java字节码**。当Scala编译器的字节码在JVM内部运行时，最初它以所谓的**解释模式**执行；JVM解释每个字节码指令并模拟程序的执行。只有当JVM决定某个方法中的字节码已经运行足够频繁时，它才会将字节码编译成机器码，这可以直接在处理器上执行。这个过程称为**即时编译**。
- en: The JVM needs standardized bytecode to be cross-platform; the same bytecode
    can be run on any processor or operating system that supports the JVM. However,
    the entire bytecode of a program cannot be translated to the machine code as soon
    as the program runs; this would be too slow. Instead, the JVM translates parts
    of the programs, such as specific methods, incrementally, in short compiler runs.
    In addition, the JVM can decide to additionally optimize certain parts of the
    program that execute very frequently. As a result, programs running on the JVM
    are usually slow immediately after they start, and eventually reach their optimal
    performance. Once this happens, we say that the JVM reached its steady state.
    When evaluating the performance on the JVM, we are usually interested in the **steady
    state**; most programs run long enough to achieve it.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: JVM需要标准化的字节码以实现跨平台；相同的字节码可以在支持JVM的任何处理器或操作系统上运行。然而，程序的全部字节码并不能在程序运行时立即转换为机器码；这将太慢。相反，JVM会增量地将程序的某些部分，如特定方法，在短暂的编译运行中转换。此外，JVM还可以决定额外优化程序中执行非常频繁的部分。因此，在JVM上运行的程序通常在启动后速度较慢，最终达到最佳性能。一旦发生这种情况，我们就说JVM达到了稳定状态。在评估JVM上的性能时，我们通常对**稳定状态**感兴趣；大多数程序运行足够长的时间以达到这一状态。
- en: 'To witness this effect, assume that you want to find out what the `TEXTAREA`
    tag means in HTML. You write the program that downloads the HTML specification
    and searches for the first occurrence of the `TEXTAREA` string. Having mastered
    asynchronous programming in [Chapter 4](ch04.html "Chapter 4.  Asynchronous Programming
    with Futures and Promises"), *Asynchronous Programming with Futures and Promises*,
    you can implement the `getHtmlSpec` method, which starts an asynchronous computation
    to download the HTML specification and returns a future value with the lines of
    the HTML specification. You then install a callback; once the HTML specification
    is available, you can call the `indexWhere` method on the lines to find the line
    that matches the regular expression `.*TEXTAREA.*`:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了见证这种效果，假设你想找出 HTML 中的 `TEXTAREA` 标签代表什么。你编写了一个程序，下载 HTML 规范并搜索 `TEXTAREA`
    字符串的第一个出现。在掌握了 [第 4 章](ch04.html "第 4 章。使用 Future 和 Promise 进行异步编程") 中的异步编程后，*使用
    Future 和 Promise 进行异步编程*，你可以实现 `getHtmlSpec` 方法，该方法启动一个异步计算以下载 HTML 规范，并返回一个包含
    HTML 规范行的 future 值。然后你安装一个回调；一旦 HTML 规范可用，你就可以在行上调用 `indexWhere` 方法来找到匹配正则表达式
    `.*TEXTAREA.*` 的行：
- en: '[PRE10]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Running this example several times from SBT shows that the times vary. At first,
    the sequential and parallel versions execute for 45 and 16 milliseconds, respectively.
    Next time, they take 36 and 10 milliseconds, and subsequently 10 and 4 milliseconds.
    Note that we only observe this effect when running the examples inside the same
    JVM process as SBT itself.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 从 SBT 运行此示例多次表明，运行时间会有所不同。最初，顺序版本和并行版本分别执行了 45 毫秒和 16 毫秒。下一次，它们分别需要 36 毫秒和 10
    毫秒，随后是 10 毫秒和 4 毫秒。请注意，我们只有在将示例运行在与 SBT 本身相同的 JVM 进程内时才会观察到这种效果。
- en: 'We can draw a false conclusion that the steady state was reached at this point.
    In truth, we should run this program many more times before the JVM properly optimizes
    it. Therefore, we add the `warmedTimed` method to our package object. This method
    runs the block of code `n` times before measuring its running time. We set the
    default value for the `n` variable to `200`; although there is no way to be sure
    that the JVM will reach a steady state after executing the block of code 200 times,
    this is a reasonable default:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会得出一个错误的结论，认为此时已经达到了稳定状态。实际上，我们应该在 JVM 正确优化程序之前运行这个程序许多次。因此，我们将 `warmedTimed`
    方法添加到我们的包对象中。此方法在测量运行时间之前运行代码块 `n` 次。我们将 `n` 变量的默认值设置为 `200`；尽管无法保证 JVM 在执行代码块
    200 次后将达到稳定状态，但这是一个合理的默认值：
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can now call the `warmedTimed` method instead of the `timed` method in the
    `ParHtmlSearch` example:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以调用 `ParHtmlSearch` 示例中的 `warmedTimed` 方法，而不是 `timed` 方法：
- en: '[PRE12]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Doing so changes the running times on our machine to 1.5 and 0.5 milliseconds
    for the sequential and parallel versions of the program, respectively.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做将我们的机器上程序的顺序版本和并行版本的运行时间分别改变为 1.5 毫秒和 0.5 毫秒。
- en: Tip
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Make sure that the JVM is in the steady state before drawing any premature conclusions
    about the running time of a program.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在对程序运行时间做出任何过早的结论之前，请确保 JVM 处于稳定状态。
- en: There are other reasons why measuring performance on the JVM is hard. Even if
    the JVM reached a steady state for the part of the program we measure, the **Just-In-Time**
    (**JIT**) compiler can at any point pause the execution and translate some other
    part of the program, effectively slowing down our measurement. Then, the JVM provides
    automatic memory management. In languages such as C++, an invocation of the `new`
    keyword, which is used to allocate an object, must be accompanied by the corresponding
    `delete` call that frees the memory occupied by the object so that it can be reused
    later. In languages such as Scala and Java, however, there is no `delete` statement;
    objects are eventually freed automatically during the process called **Garbage
    Collection** (**GC**). Periodically, the JVM stops the execution, scans the heap
    for all objects no longer used in the program, and frees the memory they occupy.
    If we measure the running time of code that frequently causes GC cycles, the chances
    are that GC will skew the measurements. In some cases, the performance of the
    same program can vary from one JVM process to the other because the objects get
    allocated in a way that causes a particular memory access pattern, impacting the
    program's performance.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在 JVM 上测量性能之所以困难，还有其他原因。即使 JVM 达到了我们测量的程序部分的稳定状态，**即时编译器**（**JIT**）也可以在任何时候暂停执行并将程序的其他部分转换为机器码，从而有效地减慢我们的测量速度。然后，JVM
    提供了自动内存管理。在 C++ 等语言中，用于分配对象的 `new` 关键字的调用必须伴随着释放对象占用的内存的相应 `delete` 调用，以便以后可以重用。然而，在
    Scala 和 Java 等语言中，没有 `delete` 语句；对象最终在称为 **垃圾回收**（**GC**）的过程中自动释放。定期地，JVM 停止执行，扫描堆以查找程序中不再使用的所有对象，并释放它们占用的内存。如果我们测量频繁引起
    GC 周期的代码的运行时间，GC 很可能会扭曲测量结果。在某些情况下，同一程序的性能可能会因 JVM 进程的不同而有所不同，因为对象的分配方式会导致特定的内存访问模式，从而影响程序的性能。
- en: To get really reliable running time values, we need to run the code many times
    by starting separate JVM processes, making sure that the JVM reached a steady
    state, and taking the average of all the measurements. Frameworks such as **ScalaMeter**,
    introduced in [Chapter 9](ch09.html "Chapter 9. Concurrency in Practice"), *Concurrency
    in Practice*, go a long way toward automating this process.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得真正可靠的运行时间值，我们需要多次运行代码，通过启动单独的 JVM 进程，确保 JVM 达到稳定状态，并取所有测量的平均值。例如，在 [第 9 章](ch09.html
    "第 9 章。实践中的并发") 中介绍的 **ScalaMeter** 等框架，在 *实践中的并发* 中，大大简化了这一过程。
- en: Caveats with parallel collections
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行集合的注意事项
- en: Parallel collections were designed to provide a programming API similar to sequential
    Scala collections. Every sequential collection has a parallel counterpart and
    most operations have the same signature in both sequential and parallel collections.
    Still, there are some caveats when using parallel collections, and we will study
    them in this section.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 并行集合被设计成提供与顺序 Scala 集合类似的编程 API。每个顺序集合都有一个并行对应物，并且大多数操作在顺序和并行集合中都有相同的签名。尽管如此，在使用并行集合时仍有一些注意事项，我们将在本节中研究它们。
- en: Non-parallelizable collections
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不可并行化的集合
- en: 'Parallel collections use **splitters**, represented with the `Splitter[T]`
    type, in order to provide parallel operations. A splitter is a more advanced form
    of an iterator; in addition to the iterator''s `next` and `hasNext` methods, splitters
    define the `split` method, which divides the splitter `S` into a sequence of splitters
    that traverse parts of the `S` splitter:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 并行集合使用 **拆分器**（**splitters**），用 `Splitter[T]` 类型表示，以提供并行操作。拆分器是迭代器的一种更高级形式；除了迭代器的
    `next` 和 `hasNext` 方法外，拆分器还定义了 `split` 方法，该方法将拆分器 `S` 划分为一系列拆分器，这些拆分器遍历 `S` 拆分器的一部分：
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This method allows separate processors to traverse separate parts of the input
    collection. The `split` method must be implemented efficiently, as this method
    is invoked many times during the execution of a parallel operation. In the vocabulary
    of computational complexity theory, the allowed asymptotic running time of the
    `split` method is **O**(log (*N*)), where *N* is the number of elements in the
    splitter. Splitters can be implemented for flat data structures such as arrays
    and hash tables, and tree-like data structures such as immutable hash maps and
    vectors. Linear data structures such as the Scala `List` and `Stream` collections
    cannot efficiently implement the `split` method. Dividing a long linked list of
    nodes into two parts requires traversing these nodes, which takes a time that
    is proportionate to the size of the collection.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法允许不同的处理器遍历输入集合的不同部分。`split`方法必须高效实现，因为此方法在并行操作的执行过程中会被多次调用。在计算复杂度理论的词汇中，`split`方法允许的渐近运行时间是**O**(log
    (*N*))，其中*N*是分割器中的元素数量。分割器可以用于扁平数据结构，如数组哈希表，以及树形数据结构，如不可变哈希图和向量。线性数据结构，如Scala的`List`和`Stream`集合，无法有效地实现`split`方法。将长链表节点分成两部分需要遍历这些节点，这需要的时间与集合的大小成比例。
- en: Operations on Scala collections such as `Array`, `ArrayBuffer`, mutable `HashMap`
    and `HashSet`, `Range`, `Vector`, immutable `HashMap` and `HashSet`, and concurrent
    `TrieMap` can be parallelized. We call these collections *parallelizable*. Calling
    the `par` method on these collections creates a parallel collection that shares
    the same underlying dataset as the original collection. No elements are copied
    and the conversion is fast.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Scala集合上的操作，如`Array`、`ArrayBuffer`、可变的`HashMap`和`HashSet`、`Range`、`Vector`、不可变的`HashMap`和`HashSet`以及并发`TrieMap`可以并行化。我们称这些集合为*可并行化集合*。在这些集合上调用`par`方法会创建一个与原始集合具有相同底层数据集的并行集合。没有元素被复制，转换速度快。
- en: 'Other Scala collections need to be converted to their parallel counterparts
    upon calling `par`. We can refer to them as *non-parallelizable collections*.
    Calling the `par` method on non-parallelizable collections entails copying their
    elements into a new collection. For example, the `List` collection needs to be
    copied to a `Vector` collection when the `par` method is called, as shown in the
    following code snippet:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 其他Scala集合在调用`par`时需要转换为它们的并行对应物。我们可以将它们称为*不可并行化集合*。在不可并行化集合上调用`par`方法意味着将它们的元素复制到一个新的集合中。例如，当调用`par`方法时，`List`集合需要复制到`Vector`集合中，如下面的代码片段所示：
- en: '[PRE14]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Calling `par` on `List` takes 55 milliseconds on our machine, whereas calling
    `par` on `Vector` takes 0.025 milliseconds. Importantly, the conversion from a
    sequential collection to a parallel one is not itself parallelized, and is a possible
    sequential bottleneck.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的机器上，对`List`调用`par`需要55毫秒，而对`Vector`调用`par`只需要0.025毫秒。重要的是，从顺序集合到并行集合的转换本身并不是并行化的，并且可能是一个可能的顺序瓶颈。
- en: Tip
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Converting a non-parallelizable sequential collection to a parallel collection
    is not a parallel operation; it executes on the caller thread.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 将不可并行化顺序集合转换为并行集合不是并行操作；它在调用线程上执行。
- en: Sometimes, the cost of converting a non-parallelizable collection to a parallel
    one is acceptable. If the amount of work in the parallel operation far exceeds
    the cost of converting the collection, then we can bite the bullet and pay the
    cost of the conversion. Otherwise, it is more prudent to keep the program data
    in parallelizable collections and benefit from fast conversions. When in doubt,
    measure!
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，将非并行化集合转换为并行集合的成本是可以接受的。如果并行操作中的工作量远超过转换集合的成本，那么我们可以咬紧牙关，承担转换的成本。否则，更谨慎的做法是将程序数据保持在可并行化集合中，并从快速转换中受益。如有疑问，请测量！
- en: Non-parallelizable operations
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不可并行化操作
- en: 'While most parallel collection operations achieve superior performance by executing
    on several processors, some operations are inherently sequential, and their semantics
    do not allow them to execute in parallel. Consider the `foldLeft` method from
    the Scala collections API:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然大多数并行集合操作通过在多个处理器上执行而实现更优的性能，但某些操作本质上是顺序的，它们的语义不允许它们并行执行。考虑Scala集合API中的`foldLeft`方法：
- en: '[PRE15]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This method visits elements of the collection going from left to right and
    adds them to the accumulator of type `S`. The accumulator is initially equal to
    the zero value `z`, and is updated with the function `f` that uses the accumulator
    and a collection element of type `T` to produce a new accumulator. For example,
    given a list of integers `List(1, 2, 3)`, we can compute the sum of its integers
    with the following expression:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法从左到右遍历集合的元素，并将它们添加到类型为`S`的累加器中。累加器最初等于零值`z`，并使用累加器和类型为`T`的集合元素来更新函数`f`，以产生一个新的累加器。例如，给定一个整数列表`List(1,
    2, 3)`，我们可以使用以下表达式来计算其整数的总和：
- en: '[PRE16]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This `foldLeft` method starts by assigning `0` to `acc`. It then takes the first
    element in the list `1` and calls the function `f` to evaluate `0 + 1`. The `acc`
    accumulator then becomes `1`. This process continues until the entire list of
    elements is visited, and the `foldLeft` method eventually returns the result `6`.
    In this example, the `S` type of the accumulator is set to the `Int` type. In
    general, the accumulator can have any type. When converting a list of elements
    to a string, the zero value is an empty string and the function `f` concatenates
    a string and a number.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`foldLeft`方法首先将`acc`赋值为`0`。然后它取列表中的第一个元素`1`，并调用函数`f`来评估`0 + 1`。此时，累加器`acc`变为`1`。这个过程一直持续到访问完列表中的所有元素，`foldLeft`方法最终返回结果`6`。在这个例子中，累加器的`S`类型被设置为`Int`类型。一般来说，累加器可以有任何类型。当将元素列表转换为字符串时，零值是一个空字符串，函数`f`将字符串和数字连接起来。
- en: 'The crucial property of the `foldLeft` operation is that it traverses the elements
    of the list by going from left to right. This is reflected in the type of the
    function `f`; it accepts an accumulator of type `S` and a list value of type `T`.
    The function `f` cannot take two values of the accumulator type `S` and merge
    them into a new accumulator of type `S`. As a consequence, computing the accumulator
    cannot be implemented in parallel; the `foldLeft` method cannot merge two accumulators
    from two different processors. We can confirm this by running the following program:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`foldLeft`操作的关键属性是它从左到右遍历列表的元素。这反映在函数`f`的类型上；它接受类型为`S`的累加器和类型为`T`的列表值。函数`f`不能接受两个累加器类型的值并将它们合并成一个新的累加器类型`S`。因此，累加器的计算不能并行实现；`foldLeft`方法不能将来自两个不同处理器的两个累加器合并。我们可以通过运行以下程序来验证这一点：'
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In the preceding program, we use the `getHtmlSpec` method introduced earlier
    to obtain the lines of the HTML specification. We install a callback using the
    `foreach` call to process the HTML specification once it arrives; the `allMatches`
    method calls the `foldLeft` operation to accumulate the lines of the specification
    that contain the `TEXTAREA` string. Running the program reveals that both the
    sequential and parallel `foldLeft` operations take 5.6 milliseconds.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的程序中，我们使用之前引入的`getHtmlSpec`方法来获取HTML规范中的行。我们使用`foreach`调用安装一个回调，以便在HTML规范到达后进行处理；`allMatches`方法调用`foldLeft`操作来累加包含`TEXTAREA`字符串的规范行。运行程序显示，顺序和并行`foldLeft`操作都花费了5.6毫秒。
- en: 'To specify how the accumulators produced by different processors should be
    merged together, we need to use the `aggregate` method. The `aggregate` method
    is similar to the `foldLeft` operation, but it does not specify that the elements
    are traversed from left to right. Instead, it only specifies that subsets of elements
    are visited going from left to right; each of these subsets can produce a separate
    accumulator. The `aggregate` method takes an additional function of type `(S,
    S) => S`, which is used to merge multiple accumulators:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 要指定不同处理器产生的累加器应该如何合并在一起，我们需要使用`aggregate`方法。`aggregate`方法与`foldLeft`操作类似，但它没有指定元素是从左到右遍历的。相反，它只指定了从左到右遍历的元素子集；每个子集都可以产生一个单独的累加器。`aggregate`方法接受一个额外的函数类型`(S,
    S) => S`，用于合并多个累加器：
- en: '[PRE18]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Running the example again shows the difference between the sequential and parallel
    versions of the program; the parallel `aggregate` method takes 1.4 milliseconds
    to complete on our machine.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 再次运行示例程序显示了程序顺序和并行版本之间的差异；在机器上，并行`aggregate`方法完成所需时间为1.4毫秒。
- en: When doing these kinds of reduction operation in parallel, we can alternatively
    use the `reduce` or `fold` methods, which do not guarantee going from left to
    right. The `aggregate` method is more expressive, as it allows the accumulator
    type to be different from the type of the elements in the collection.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 当在并行执行这些类型的归约操作时，我们可以使用`reduce`或`fold`方法作为替代，这些方法不保证从左到右执行。`aggregate`方法更具有表达性，因为它允许累加器的类型与集合中元素的类型不同。
- en: Tip
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Use the `aggregate` method to execute parallel reduction operations.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`aggregate`方法来执行并行归约操作。
- en: Other inherently sequential operations include `foldRight`, `reduceLeft`, `reduceRight`,
    `reduceLeftOption`, `reduceRightOption`, `scanLeft`, `scanRight`, and methods
    that produce non-parallelizable collections such as the `toList` method.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 其他固有的顺序操作包括`foldRight`、`reduceLeft`、`reduceRight`、`reduceLeftOption`、`reduceRightOption`、`scanLeft`、`scanRight`以及产生不可并行化集合的方法，如`toList`方法。
- en: Side effects in parallel operations
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行操作中的副作用
- en: 'As their name implies, parallel collections execute on multiple threads concurrently.
    We have already learned in [Chapter 2](ch02.html "Chapter 2. Concurrency on the
    JVM and the Java Memory Model"), *Concurrency on the JVM and the Java Memory Model*,
    that multiple threads cannot correctly modify shared memory locations without
    the use of synchronization. Assigning to a mutable variable from a parallel collection
    operation may be tempting, but it is almost certainly incorrect. This is best
    illustrated by the following example, in which we construct two sets, `a` and
    `b`, where `b` is the subset of the elements in `a`, and then uses the `total`
    mutable variable to count the size of the intersection:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 正如它们的名称所暗示的，并行集合会在多个线程上并发执行。我们已经在[第2章](ch02.html "第2章. JVM和Java内存模型中的并发")中学习了，*JVM和Java内存模型中的并发*，多个线程在没有同步的情况下无法正确修改共享内存位置。从并行集合操作中向可变变量赋值可能很有吸引力，但几乎肯定是不正确的。以下示例最好地说明了这一点，其中我们构建了两个集合，`a`和`b`，其中`b`是`a`中元素的子集，然后使用`total`可变变量来计算交集的大小：
- en: '[PRE19]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Instead of returning `250`, the parallel version nondeterministically returns
    various wrong results. Note that you might have to change the sizes of the sets
    `a` and `b` to witness this:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 与返回`250`不同，并行版本非确定性返回各种错误的结果。请注意，你可能需要更改集合`a`和`b`的大小才能观察到这一点：
- en: '[PRE20]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To ensure that the parallel version returns the correct results, we can use
    an atomic variable and its `incrementAndGet` method. However, this leads to the
    same scalability problems we had before. A better alternative is to use the parallel
    `count` method:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保并行版本返回正确的结果，我们可以使用原子变量及其`incrementAndGet`方法。然而，这会导致我们之前遇到的可伸缩性问题。更好的替代方案是使用并行`count`方法：
- en: '[PRE21]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: If the amount of work executed per element is low and the matches are frequent,
    the parallel `count` method will result in better performance than the `foreach`
    method with an atomic variable.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果每个元素执行的工作量低且匹配频繁，并行`count`方法将比使用原子变量的`foreach`方法有更好的性能。
- en: Tip
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: To avoid the need for synchronization and ensure better scalability, favor declarative-style
    parallel operations instead of the side effects in parallel `for` loops.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免同步的需要并确保更好的可伸缩性，优先使用声明式并行操作，而不是并行`for`循环中的副作用。
- en: Similarly, we must ensure that the memory locations read by a parallel operation
    are protected from concurrent writes. In the last example, the `b` set should
    not be concurrently mutated by some thread while the parallel operation is executing;
    this leads to the same incorrect results as using mutable variables from within
    the parallel operation.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们必须确保并行操作读取的内存位置在并行操作执行期间受到并发写入的保护。在上一个示例中，当并行操作执行时，不应有某个线程并发修改`b`集合；这会导致与在并行操作中使用可变变量相同的不正确结果。
- en: Nondeterministic parallel operations
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非确定性并行操作
- en: 'In [Chapter 2](ch02.html "Chapter 2. Concurrency on the JVM and the Java Memory
    Model"), *Concurrency on the JVM and the Java Memory Model*, we saw that multithreaded
    programs can be nondeterministic; given the same inputs, they can produce different
    outputs depending on the execution schedule. The `find` collection operation returns
    an element matching a given predicate. The parallel `find` operation returns whichever
    element was found first by some processor. In the following example, we use `find`
    to search the HTML specification for occurrences of the `TEXTAREA` string; running
    the example several times gives different results, because the `TEXTAREA` string
    occurs in many different places in the HTML specification:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](ch02.html "第2章。JVM和Java内存模型上的并发")中，*JVM和Java内存模型上的并发*，我们看到了多线程程序可以是非确定性的；给定相同的输入，它们可以产生不同的输出，这取决于执行计划。`find`集合操作返回匹配给定谓词的元素。并行的`find`操作返回某个处理器首先找到的元素。在以下示例中，我们使用`find`来搜索HTML规范中`TEXTAREA`字符串的出现；运行示例几次会得到不同的结果，因为`TEXTAREA`字符串在HTML规范中出现的位置很多：
- en: '[PRE22]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'If we want to retrieve the first occurrence of the `TEXTAREA` string, we need
    to use `indexWhere` instead:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要检索`TEXTAREA`字符串的第一个出现，我们需要使用`indexWhere`：
- en: '[PRE23]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Parallel collection operations other than `find` are deterministic as long
    as their operators are **pure functions**. A pure function is always evaluated
    to the same value, given the same inputs, and does not have any side effects.
    For example, the function `(x: Int) => x + 1` is a pure function. By contrast,
    the following function `f` is not pure, because it changes the state of the `uid`
    value:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '除了`find`之外的并行集合操作只要它们的运算符是**纯函数**就是确定性的。纯函数总是对相同的输入评估为相同的值，并且没有副作用。例如，函数`(x:
    Int) => x + 1`是一个纯函数。相比之下，以下函数`f`不是纯函数，因为它改变了`uid`值的状态：'
- en: '[PRE24]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Even if a function does not modify any memory locations, it is not pure if
    it reads memory locations that might change. For example, the following `g` function
    is not pure:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 即使一个函数没有修改任何内存位置，如果它读取可能会改变的内存位置，它也不是纯函数。例如，以下`g`函数不是纯函数：
- en: '[PRE25]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'When used with a non-pure function, any parallel operation can become nondeterministic.
    Mapping the range of values to unique identifiers in parallel gives a nondeterministic
    result, as illustrated by the following call:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 当与非纯函数一起使用时，任何并行操作都可能变得非确定性。并行地将值范围映射到唯一标识符会产生非确定性结果，如下面的调用所示：
- en: '[PRE26]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The resulting sequence, `uids`, is different in separate executions. The parallel
    `map` operation retains the relative order of elements from the range `0 until
    10000`, so the tuples in `uids` are ordered by their first elements from 0 until
    10,000\. On the other hand, the second element in each tuple is assigned nondeterministically;
    in one execution, the `uids` sequence can start with the `(0, 0), (1, 2), (2,
    3), ...` and in another, with `(0, 0), (1, 4), (2, 9), ...`.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 结果序列`uids`在不同的执行中是不同的。并行的`map`操作保留了从`0`到`10000`范围的元素相对顺序，因此`uids`中的元组按其第一个元素从`0`到`10,000`排序。另一方面，每个元组的第二个元素被非确定性地分配；在一个执行中，`uids`序列可以以`(0,
    0), (1, 2), (2, 3), ...`开始，而在另一个执行中，以`(0, 0), (1, 4), (2, 9), ...`开始。
- en: Commutative and associative operators
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交换律和结合律运算符
- en: Parallel collection operations such as `reduce`, `fold`, `aggregate`, and `scan`
    take binary operators as part of their input. A binary operator is a function  `op`
    that takes two arguments, `a` and `b`. We can say that the binary operator `op`
    is **commutative** if changing the order of its arguments returns the same result,
    that is, `op(a, b) == op(b, a)`. For example, adding two numbers together is a
    commutative operation. Concatenating two strings is not a commutative operation;
    we get different strings depending on the concatenation order.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于`reduce`、`fold`、`aggregate`和`scan`的并行集合操作将二元运算符作为其输入的一部分。二元运算符是一个函数`op`，它接受两个参数，`a`和`b`。我们可以说，如果改变其参数的顺序会返回相同的结果，即`op(a,
    b) == op(b, a)`，那么二元运算符`op`是**交换律**的。例如，两个数相加是一个交换律操作。两个字符串连接不是一个交换律操作；我们得到不同的字符串，这取决于连接的顺序。
- en: Binary operators for the parallel `reduce`, `fold`, `aggregate`, and `scan`
    operations never need to be commutative. Parallel collection operations always
    respect the relative order of the elements when applying binary operators, provided
    that the underlying collections have any ordering. Elements in sequence collections,
    such as `ArrayBuffer` collections, are always ordered. Other collection types
    can order their elements but are not required to do so.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 并行 `reduce`、`fold`、`aggregate` 和 `scan` 操作的二元运算符永远不需要是交换的。当底层集合具有任何排序时，并行集合操作在应用二元运算符时始终尊重元素的相对顺序。例如，序列集合（如
    `ArrayBuffer` 集合）中的元素始终是有序的。其他集合类型可以对其元素进行排序，但不是必须这样做。
- en: 'In the following example, we can concatenate the strings inside an `ArrayBuffer`
    collection into one long string by using the sequential `reduceLeft` operation
    and the parallel `reduce` operation. We then convert the `ArrayBuffer` collection
    into a set, which does not have an ordering:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们可以通过使用顺序的 `reduceLeft` 操作和并行 `reduce` 操作将 `ArrayBuffer` 集合内的字符串连接成一个长字符串。然后，我们将
    `ArrayBuffer` 集合转换为集合，该集合没有排序：
- en: '[PRE27]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: We can see that the string is concatenated correctly when the parallel `reduce`
    operation is invoked on a parallel array, but the order of the pages is mangled
    both for the `reduceLeft` and `reduce` operations when invoked on a set; the default
    Scala set implementation does not order the elements.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，当在并行数组上调用并行 `reduce` 操作时，字符串可以正确地连接，但当在集合上调用 `reduceLeft` 和 `reduce`
    操作时，页面的顺序会被打乱；默认的 Scala 集合实现不排序元素。
- en: Note
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Binary operators used in parallel operations do not need to be commutative.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在并行操作中使用的二元运算符不需要是交换的。
- en: An `op` binary operator is **associative** if applying `op` consecutively to
    a sequence of values `a`, `b`, and `c` gives the same result regardless of the
    order in which the operator is applied, that is, `op(a, op(b, c)) == op(op(a,
    b), c)`. Adding two numbers together or computing the larger of the two numbers
    is an associative operation. Subtraction is not associative, as `1 - (2 - 3)`
    is different from `(1 - 2) - 3`.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将二元运算符 `op` 连续应用于值序列 `a`、`b` 和 `c`，无论运算符应用的顺序如何，都得到相同的结果，则 `op` 二元运算符是 **结合的**，即
    `op(a, op(b, c)) == op(op(a, b), c)`。将两个数字相加或计算两个数字中较大的一个是结合操作。减法不是结合的，因为 `1 -
    (2 - 3)` 与 `(1 - 2) - 3` 是不同的。
- en: 'Parallel collection operations usually require associative binary operators.
    While using subtraction with the `reduceLeft` operation means that all the numbers
    in the collection should be subtracted from the first number, using subtraction
    in the `reduce`, `fold`, or `scan` methods gives nondeterministic and incorrect
    results, as illustrated by the following code snippet:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 并行集合操作通常需要结合的二元运算符。虽然使用 `reduceLeft` 操作中的减法意味着集合中的所有数字都应该从第一个数字中减去，但在 `reduce`、`fold`
    或 `scan` 方法中使用减法会给出非确定性和错误的结果，如下面的代码片段所示：
- en: '[PRE28]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: While the `reduceLeft` operation consistently returns `-435`, the `reduce` operation
    returns meaningless results at random.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 `reduceLeft` 操作始终返回 `-435`，但 `reduce` 操作随机返回无意义的结果。
- en: Tip
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Make sure that binary operators used in parallel operations are associative.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 确保在并行操作中使用的二元运算符是结合的。
- en: 'Parallel operations such as `aggregate` require the multiple binary operators,
    `sop` and `cop`:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 需要 `sop` 和 `cop` 多个二元运算符的并行操作，如 `aggregate`：
- en: '[PRE29]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The `sop` operator is of the same type as the operator required by the `reduceLeft`
    operation. It takes an accumulator and the collection element. The `sop` operator
    is used to fold elements within a subset assigned to a specific processor. The
    `cop` operator is used to merge the subsets together and is of the same type as
    the operators for `reduce` and `fold`. The `aggregate` operation requires that
    `cop` is associative and that `z` is the **zero element** for the accumulator,
    that is, `cop(z, a) == a`. Additionally, the `sop` and `cop` operators must give
    the same result irrespective of the order in which element subsets are assigned
    to processors, that is, `cop(sop(z, a), sop(z, b)) == cop(z, sop(sop(z, a), b))`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`sop` 运算符与 `reduceLeft` 操作所需的运算符类型相同。它接受一个累加器和集合元素。`sop` 运算符用于折叠分配给特定处理器的子集中的元素。`cop`
    运算符用于合并子集，并且与 `reduce` 和 `fold` 的运算符类型相同。`aggregate` 操作要求 `cop` 是结合的，且 `z` 是累加器的
    **零元素**，即 `cop(z, a) == a`。此外，`sop` 和 `cop` 运算符必须在不考虑元素子集分配给处理器的顺序的情况下给出相同的结果，即
    `cop(sop(z, a), sop(z, b)) == cop(z, sop(sop(z, a), b))`。'
- en: Using parallel and concurrent collections together
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结合使用并行和并发集合
- en: 'We have already seen that parallel collection operations are not allowed to
    access mutable states without the use of synchronization. This includes modifying
    sequential Scala collections from within a parallel operation. Recall that we
    used a mutable variable in the section on side effects to count the size of the
    intersection. In the following example, we will download the URL and HTML specifications,
    convert them to sets of words, and try to find an intersection of their words.
    In the `intersection` method, we use a `HashSet` collection and update it in parallel.
    Collections in the `scala.collection.mutable` package are not thread-safe. The
    following example nondeterministically drops elements, corrupts the buffer state,
    or throws exceptions:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，并行集合操作不允许在不使用同步的情况下访问可变状态。这包括在并行操作中修改顺序Scala集合。回想一下，我们在关于副作用的部分使用了一个可变变量来计算交集的大小。在下面的例子中，我们将下载URL和HTML规范，将它们转换为单词集合，并尝试找到它们的单词交集。在`intersection`方法中，我们使用`HashSet`集合并在并行中更新它。`scala.collection.mutable`包中的集合不是线程安全的。以下例子中，元素可能会非确定性地丢失，损坏缓冲区状态，或者抛出异常：
- en: '[PRE30]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We learned in [Chapter 3](ch03.html "Chapter 3. Traditional Building Blocks
    of Concurrency"), *Traditional Building Blocks of Concurrency*, that concurrent
    collections can be safely modified by multiple threads without the risk of data
    corruption. We use the concurrent skip list collection from the JDK to accumulate
    words that appear in both specifications. The `decorateAsScala` object is used
    to add the `asScala` method to Java collections:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第3章](ch03.html "第3章. 并发的基础构件")*并发的基石*中了解到，并发集合可以在不风险数据损坏的情况下被多个线程安全地修改。我们使用JDK中的并发跳表集合来累积出现在两个规范中的单词。`decorateAsScala`对象被用来给Java集合添加`asScala`方法：
- en: '[PRE31]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Weakly consistent iterators
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 弱一致性迭代器
- en: As we saw in [Chapter 3](ch03.html "Chapter 3. Traditional Building Blocks of
    Concurrency"), *Traditional Building Blocks of Concurrency*, iterators on most
    concurrent collections are weakly consistent. This means that they are not guaranteed
    to correctly traverse the data structure if some thread concurrently updates the
    collection during traversal.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第3章](ch03.html "第3章. 并发的基石")*并发的基石*中看到的，大多数并发集合的迭代器是弱一致的。这意味着如果某个线程在遍历期间并发更新集合，则不能保证它们能正确遍历数据结构。
- en: 'When executing a parallel operation on a concurrent collection, the same limitation
    applies; the traversal is weakly consistent and might not reflect the state of
    the data structure at the point when the operation started. The Scala `TrieMap`
    collection is an exception to this rule. In the following example, we will create
    a `TrieMap` collection called `cache` containing numbers between 0 and 100, mapped
    to their string representation. We will then start a parallel operation that traverses
    these numbers and adds the mappings for their negative values to the map:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 当在并发集合上执行并行操作时，同样的限制也适用；遍历是弱一致的，可能不会反映操作开始时的数据结构状态。Scala的`TrieMap`集合是这一规则的例外。在下面的例子中，我们将创建一个名为`cache`的`TrieMap`集合，包含从0到100的数字，映射到它们的字符串表示。然后我们将启动一个并行操作，遍历这些数字，并将它们的负值映射添加到映射中：
- en: '[PRE32]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The parallel `foreach` operation does not traverse entries added after the parallel
    operation started; only positive numbers are reflected in the traversal. The `TrieMap`
    collection is implemented using the Ctrie concurrent data structure, which atomically
    creates a snapshot of the collection when the parallel operation starts. Snapshot
    creation is efficient and does not require you to copy the elements; subsequent
    update operations incrementally rebuild parts of the `TrieMap` collection.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 并行的`foreach`操作不会遍历在并行操作开始后添加的条目；只有正数会在遍历中反映出来。`TrieMap`集合使用Ctrie并发数据结构实现，当并行操作开始时，它会原子性地创建集合的快照。快照创建是高效的，并且不需要你复制元素；后续的更新操作会增量地重建`TrieMap`集合的部分。
- en: Tip
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Whenever program data needs to be simultaneously modified and traversed in parallel,
    use the `TrieMap` collection.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 当程序数据需要同时并行修改和遍历时，请使用`TrieMap`集合。
- en: Implementing custom parallel collections
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现自定义并行集合
- en: Parallel collections in the Scala standard library are sufficient for most tasks,
    but in some cases we want to add parallel operations to our own collections. The
    Java `String` class does not have a direct parallel counterpart in the parallel
    collections framework. In this section, we will study how to implement a custom
    `ParString` class that supports parallel operations. We will then use our custom
    parallel collection class in several example programs.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Scala标准库中的并行集合对于大多数任务来说已经足够了，但在某些情况下，我们希望向自己的集合中添加并行操作。Java的`String`类在并行集合框架中没有直接的并行对应物。在本节中，我们将研究如何实现一个支持并行操作的定制`ParString`类。然后，我们将使用我们的定制并行集合类在几个示例程序中。
- en: 'The first step in implementing a custom parallel collection is to extend the
    correct parallel collection trait. A parallel string is a sequence of characters,
    so we need to extend the `ParSeq` trait with the `Char` type argument. Once a
    string is created, it can no longer be modified; we say that the string is an
    immutable collection. For this reason, we extend a subtype of the `scala.collection.parallel.ParSeq`
    trait, the `ParSeq` trait from the `scala.collection.parallel.immutable` package:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 实现自定义并行集合的第一步是扩展正确的并行集合特质。并行字符串是一系列字符，因此我们需要使用`Char`类型参数扩展`ParSeq`特质。一旦字符串被创建，它就不再可以被修改；我们说字符串是一个不可变集合。因此，我们扩展了`scala.collection.parallel.ParSeq`特质的子类型，即来自`scala.collection.parallel.immutable`包的`ParSeq`特质：
- en: '[PRE33]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: When we extend a parallel collection, we need to implement its `apply`, `length`,
    `splitter`, and `seq` methods. The `apply` method returns an element at position
    `i` in the sequence, and the `length` method returns the total number of elements
    in the sequence. These methods are equivalent to the methods on sequential collections,
    so we use the `String` class's `charAt` and `length` methods to implement them.
    Where defining a custom regular sequence requires implementing its `iterator`
    method, custom parallel collections need a `splitter` method. Calling `splitter`
    returns an object of the `Splitter[T]` type, a special iterator that can be split
    into subsets. We implement the `splitter` method to return a `ParStringSplitter`
    object, which we will show you shortly. Finally, parallel collections need a `seq`
    method, which returns a sequential Scala collection. Since `String` itself comes
    from Java and is not a Scala collection, we will use its `WrappedString` wrapper
    class from the Scala collections library.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们扩展并行集合时，我们需要实现其`apply`、`length`、`splitter`和`seq`方法。`apply`方法返回序列中的第`i`个位置的元素，而`length`方法返回序列中的元素总数。这些方法与顺序集合上的方法等效，因此我们使用`String`类的`charAt`和`length`方法来实现它们。在定义自定义常规序列需要实现其`iterator`方法时，自定义并行集合需要一个`splitter`方法。调用`splitter`返回一个`Splitter[T]`类型的对象，这是一个特殊的迭代器，可以被分割成子集。我们实现`splitter`方法以返回一个`ParStringSplitter`对象，我们将在稍后向您展示。最后，并行集合需要一个`seq`方法，它返回一个顺序Scala集合。由于`String`本身来自Java，并且不是Scala集合，我们将使用Scala集合库中的`WrappedString`包装类。
- en: Our custom parallel collection class is almost complete; we only need to provide
    the implementation for the `ParStringSplitter` object. We will study how to do
    this next.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的定制并行集合类几乎完成了；我们只需要提供`ParStringSplitter`对象的实现。我们将在下一节研究如何实现这一点。
- en: Splitters
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分割器
- en: A splitter is an iterator that can be efficiently split into disjoint subsets.
    Here, efficient means that the splitter's `split` method must have **O**(*log*(*N*))
    running time, where *N* is the number of elements in the splitter. Stated informally,
    a splitter is not allowed to copy large parts of the collection when split; if
    it did, the computational overhead from splitting would overcome any benefits
    from parallelization and become a serial bottleneck.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 分割器是一个可以高效分割成不相交子集的迭代器。在这里，高效意味着分割器的`split`方法必须具有**O**(*log*(*N*))的运行时间，其中*N*是分割器中的元素数量。非正式地说，分割器在分割时不允许复制集合的大部分；如果它这样做，分割的计算开销将超过并行化的任何好处，并成为串行瓶颈。
- en: 'The easiest way to define a new `Splitter` class for the Scala parallel collection
    framework is to extend the `IterableSplitter[T]` trait, which has the following
    simplified interface:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为Scala并行集合框架定义一个新的`Splitter`类最简单的方法是扩展`IterableSplitter[T]`特质，它具有以下简化接口：
- en: '[PRE34]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The splitter interface declares the `dup` method which duplicates the current
    splitter. This method simply returns a new splitter pointing to the same subset
    of the collection. Splitters also define the `remaining` method, which returns
    the number of elements that the splitter can traverse by calling `next` before
    the `hasNext` method returns `false`. The `remaining` method does not change the
    state of the splitter and can be called as many times as necessary.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 分割器接口声明了`dup`方法，该方法复制当前的分割器。此方法简单地返回一个新的分割器，指向集合的相同子集。分割器还定义了`remaining`方法，该方法通过在`hasNext`方法返回`false`之前调用`next`方法，返回分割器可以遍历的元素数量。`remaining`方法不会改变分割器的状态，可以按需多次调用。
- en: However, the `split` method can be called only once and it invalidates the splitter;
    none of the splitter's methods should be called after calling the `split` method.
    The `split` method returns a sequence of splitters that iterate over the disjoint
    subsets of the original splitter. If the original splitter has two or more elements
    remaining, then none of the resulting splitters should be empty, and the `split`
    method should return at least two splitters. If the original splitter has a single
    element or no elements remaining, then `split` is allowed to return empty splitters.
    Importantly, the splitters returned by `split` should be approximately equal in
    size; this helps the parallel collection scheduler achieve good performance.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，`split`方法只能调用一次，并且会使分割器失效；在调用`split`方法之后，不应调用分割器的任何方法。`split`方法返回一个分割器序列，这些分割器遍历原始分割器的非重叠子集。如果原始分割器有两个或更多剩余元素，则结果分割器中不应有任何一个是空的，并且`split`方法应返回至少两个分割器。如果原始分割器只有一个元素或没有剩余元素，则允许`split`返回空分割器。重要的是，`split`方法返回的分割器大小应大致相等；这有助于并行集合调度器实现良好的性能。
- en: 'To allow sequence-specific operations such as `zip`, `sameElements`, and `corresponds`,
    parallel sequence collections use a more refined subtype of the `IterableSplitter`
    trait, called the `SeqSplitter` trait:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 为了允许特定的序列操作，如`zip`、`sameElements`和`corresponds`，并行序列集合使用`IterableSplitter`特质的更精细子类型，称为`SeqSplitter`特质：
- en: '[PRE35]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Sequence splitters declare an additional method, `psplit`, which takes the list
    of sizes for the splitter partitions and returns as many splitters and elements
    as specified by the `sizes` parameter. If `sizes` specifies more elements than
    there are available in the splitter, additional empty splitters are returned at
    the end of the resulting sequence. For example, calling `s.psplit(10, 20, 15)`
    on a splitter with only 15 elements yields three splitters with sizes 10, five,
    and zero.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 序列分割器声明了一个额外的`psplit`方法，该方法接受分割器分区的大小列表，并返回由`sizes`参数指定的那么多分割器和元素。如果`sizes`指定的元素数量超过分割器中可用的元素数量，则结果序列的末尾将返回额外的空分割器。例如，对一个只有15个元素的分割器调用`s.psplit(10,
    20, 15)`将产生三个大小分别为10、5和0的分割器。
- en: Similarly, if the `sizes` parameter specifies fewer elements than there are
    in the splitter, an additional splitter with the remaining elements is appended
    at the end.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，如果`sizes`参数指定的元素数量少于分割器中的元素数量，则将在末尾附加一个包含剩余元素的额外分割器。
- en: 'Our parallel string class is a parallel sequence, so we need to implement a
    sequence splitter. We can start by extending the `SeqSplitter` class with the
    `Char` type parameter:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的并行字符串类是一个并行序列，因此我们需要实现一个序列分割器。我们可以通过扩展带有`Char`类型参数的`SeqSplitter`类来开始：
- en: '[PRE36]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We add the `s` field pointing to the underlying `String` object in the `ParStringSplitter`
    constructor. A parallel string splitter must represent a subset of the elements
    in the string, so we add an `i` field to represent the position of the next character
    that will be traversed by the splitter. Note that `i` does not need to be synchronized;
    the splitter is only used by one processor at a time. The `limit` field contains
    the position after the last character in the splitter. This way, our splitter
    class represents substrings of the original string.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`ParStringSplitter`构造函数中添加了一个指向底层`String`对象的`s`字段。并行字符串分割器必须表示字符串中元素的一个子集，因此我们添加了一个`i`字段来表示分割器将要遍历的下一个字符的位置。请注意，`i`不需要同步；分割器一次只被一个处理器使用。`limit`字段包含分割器中最后一个字符之后的位位置。这样，我们的分割器类表示原始字符串的子字符串。
- en: 'Implementing methods inherited from the `Iterator` trait is easy. As long as
    `i` is less than `limit`, `hasNext` must return `true`. The `next` method uses
    `i` to read the character at that position, increment `i`, and return the character:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 实现 `Iterator` 特质继承的方法很简单。只要 `i` 小于 `limit`，`hasNext` 必须返回 `true`。`next` 方法使用
    `i` 读取该位置的字符，增加 `i`，并返回该字符：
- en: '[PRE37]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The `dup` and `remaining` methods are straightforward; the `dup` method creates
    a new parallel string splitter using the state of the current splitter, and the
    `remaining` method uses `limit` and `i` to compute the number of remaining elements:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`dup` 和 `remaining` 方法很简单；`dup` 方法使用当前分割器的状态创建一个新的并行字符串分割器，而 `remaining` 方法使用
    `limit` 和 `i` 来计算剩余元素的数量：'
- en: '[PRE38]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The main parts of a splitter are its `split` and `psplit` methods. Luckily,
    `split` can be implemented in terms of `psplit`. If there is more than one element
    remaining, we call the `psplit` method. Otherwise, if there are no elements to
    split, we return the `this` splitter:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 分割器的主要部分是其 `split` 和 `psplit` 方法。幸运的是，`split` 可以通过 `psplit` 来实现。如果有多个元素剩余，我们调用
    `psplit` 方法。如果没有元素要分割，我们返回 `this` 分割器：
- en: '[PRE39]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The `psplit` method uses `sizes` to peel off parts of the original splitter.
    It does so by incrementing the `i` variable and creating a new splitter for each
    size `sz` in the `sizes` parameter. Recall that the current splitter is considered
    invalidated after calling the `split` or `psplit` method, so we are allowed to
    mutate its `i` field:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '`psplit` 方法使用 `sizes` 来剥离原始分割器的一部分。它是通过增加 `i` 变量并为 `sizes` 参数中的每个大小 `sz` 创建一个新的分割器来实现的。回想一下，在调用
    `split` 或 `psplit` 方法后，当前分割器被认为是无效的，因此我们可以修改其 `i` 字段：'
- en: '[PRE40]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Note that we never copy the string underlying the splitter; instead, we update
    the indices that mark the beginning and the end of the splitter.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们从不复制分割器底层的字符串；相反，我们更新标记分割器开始和结束的索引。
- en: 'We have now completed our `ParString` class; we can use it to execute parallel
    operations on strings. We can also use it to count the number of uppercase characters
    in the string as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经完成了 `ParString` 类；我们可以用它来执行字符串上的并行操作。我们还可以用它来计算字符串中大写字母的数量，如下所示：
- en: '[PRE41]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: On our machine, the sequential `foldLeft` call takes 57 milliseconds, and the
    parallel `aggregate` call takes 19 milliseconds. This is a good indication that
    we have implemented parallel strings efficiently.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的机器上，顺序的 `foldLeft` 调用耗时 57 毫秒，而并行的 `aggregate` 调用耗时 19 毫秒。这表明我们高效地实现了并行字符串。
- en: Combiners
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组合器
- en: 'Collection methods in the Scala standard library are divided into two major
    groups: **accessor** and **transformer** methods. Accessor methods, such as `foldLeft`,
    `find`, or `exists`, return a single value from the collection. By contrast, transformer
    methods, such as `map`, `filter`, or `groupBy`, create new collections and return
    them as results.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 标准库中的集合方法分为两大类：**访问器**和**转换器**方法。访问器方法，如 `foldLeft`、`find` 或 `exists`，从集合中返回单个值。相比之下，转换器方法，如
    `map`、`filter` 或 `groupBy`，创建新的集合并将它们作为结果返回。
- en: 'To generically implement transformer operations, the Scala collection framework
    uses an abstraction called a **builder**, which has roughly the following interface:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 为了通用地实现变压器操作，Scala 集合框架使用了一个名为 **builder** 的抽象，其接口大致如下：
- en: '[PRE42]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Here, the `Repr` type is of a collection that a specific builder can produce,
    and `T` is the type of its elements. A builder is used by repetitively calling
    its `+=` method to add more elements, and eventually calling the `result` method
    to obtain the collection. After the `result` method is called, the contents of
    the builder are undefined. The `clear` method can be used to reset the state of
    the builder.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`Repr` 类型是特定构建器可以生成的集合类型，而 `T` 是其元素的类型。构建器通过重复调用其 `+=` 方法来添加更多元素，并最终调用 `result`
    方法来获取集合。在调用 `result` 方法之后，构建器的内容未定义。可以使用 `clear` 方法来重置构建器的状态。
- en: 'Every collection defines a custom builder used in various transformer operations.
    For example, the `filter` operation is defined in the `Traversable` trait, roughly
    as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 每个集合都定义了一个用于各种变压器操作的定制构建器。例如，`filter` 操作在 `Traversable` 特质中定义，大致如下：
- en: '[PRE43]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: In the preceding example, the `filter` implementation relies on the abstract
    `newBuilder` method, which is implemented in subclasses of the `Traversable` trait.
    This design allows defining all collection methods once, and only provide the
    `foreach` method (or the iterator) and the `newBuilder` method when declaring
    a new collection type.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，`filter` 实现依赖于抽象的 `newBuilder` 方法，该方法在 `Traversable` 特质的子类中实现。这种设计允许一次性定义所有集合方法，并在声明新的集合类型时仅提供
    `foreach` 方法（或迭代器）和 `newBuilder` 方法。
- en: '**Combiners** are a parallel counterpart of standard builders, and are represented
    with the `Combiner[T, Repr]` type, which subtypes the `Builder[T, Repr]` type:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '**组合器**是标准构建器的并行对应物，用 `Combiner[T, Repr]` 类型表示，它是 `Builder[T, Repr]` 类型的子类型：'
- en: '[PRE44]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The `size` method is self-explanatory. The `combine` method takes another combiner
    called `that`, and produces a third combiner that contains the elements of the
    `this` and `that` combiners. After the `combine` method returns, the contents
    of both the `this` and `that` combiners are undefined, and should not be used
    again. This constraint allows reusing the `this` or `that` combiner object as
    the resulting combiner. Importantly, if that combiner is the same runtime object
    as the `this` combiner, the `combine` method should just return the `this` combiner.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`size` 方法是自解释的。`combine` 方法接受另一个名为 `that` 的组合器，并生成一个包含 `this` 和 `that` 组合器元素的第三个组合器。在
    `combine` 方法返回后，`this` 和 `that` 组合器的内容都是未定义的，不应再次使用。这个约束允许重用 `this` 或 `that` 组合器对象作为结果组合器。重要的是，如果
    `that` 组合器与 `this` 组合器是相同的运行时对象，则 `combine` 方法应仅返回 `this` 组合器。'
- en: 'There are three ways to implement a custom combiner, as follows:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 实现自定义组合器有三种方式，如下所示：
- en: '**Merging**: Some data structures have an efficient merge operation that can
    be used to implement the `combine` method.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合并**：一些数据结构具有高效的合并操作，可以用来实现 `combine` 方法。'
- en: '**Two-phase evaluation**: Here, elements are first partially sorted into buckets
    that can be efficiently concatenated, and placed into the final data structure
    once it is allocated.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**两阶段评估**：在这里，元素首先被部分排序到可以高效连接的桶中，并在分配最终数据结构后放入其中。'
- en: '**Concurrent data structure**: The `+=` method is implemented by modifying
    a concurrent data structure shared between different combiners, and the `combine`
    method does not do anything.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并发数据结构**：`+=` 方法通过修改不同组合器之间共享的并发数据结构来实现，而 `combine` 方法不执行任何操作。'
- en: 'Most data structures do not have an efficient merge operation, so we usually
    have to use two-phase evaluation in the combiner implementation. In the following
    example, we implement the combiners for parallel strings using two-phase evaluation.
    The `ParStringCombiner` class contains a resizable array, called `chunks`, containing
    `StringBuilder` objects. Invoking the `+=` method adds a character to the rightmost
    `StringBuilder` object in this array:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据结构没有高效的合并操作，因此我们通常必须在组合器实现中使用两阶段评估。在下面的示例中，我们使用两阶段评估来实现并行字符串的组合器。`ParStringCombiner`
    类包含一个可调整大小的数组，称为 `chunks`，其中包含 `StringBuilder` 对象。调用 `+=` 方法将一个字符添加到该数组中右边的 `StringBuilder`
    对象：
- en: '[PRE45]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The `combine` method takes the `StringBuilder` objects of the `that` combiner,
    and adds them to the `chunks` array of the `this` combiner. It then returns a
    reference to the `this` combiner:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '`combine` 方法接受 `that` 组合器的 `StringBuilder` 对象，并将它们添加到 `this` 组合器的 `chunks`
    数组中。然后它返回对 `this` 组合器的引用：'
- en: '[PRE46]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Finally, the `result` method allocates a new `StringBuilder` object and adds
    the characters from all the chunks into the resulting string:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`result` 方法分配一个新的 `StringBuilder` 对象，并将所有块中的字符添加到结果字符串中：
- en: '[PRE47]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We test the performance of the parallel `filter` method with the following
    snippet:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下代码片段测试并行 `filter` 方法的性能：
- en: '[PRE48]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Running this snippet on our machine takes 11 milliseconds for the sequential
    version, and 6 milliseconds for the parallel one.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的机器上运行此代码片段，顺序版本需要 11 毫秒，而并行版本需要 6 毫秒。
- en: Summary
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, we learned how to use parallel collections to improve program
    performance. We have seen that sequential operations on large collections can
    be easily parallelized and learned the difference between parallelizable and non-parallelizable
    collections. We investigated how mutability and side effects impact correctness
    and determinism of parallel operations and saw the importance of using associative
    operators for parallel operations. Finally, we studied how to implement our custom
    parallel collection class.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用并行集合来提高程序性能。我们了解到，对大型集合的顺序操作可以轻松并行化，并学习了可并行化和不可并行化集合之间的区别。我们研究了可变性和副作用如何影响并行操作的正确性和确定性，并看到了使用关联运算符进行并行操作的重要性。最后，我们研究了如何实现自定义并行集合类。
- en: We also found, however, that tuning program performance is tricky. Effects such
    as memory contention, garbage collection, and dynamic compilation may impact the
    performance of the program in ways that are hard to predict by looking at the
    source code. Throughout this section, we urged you to confirm suspicions and claims
    about program performance by experimentally validating them. Understanding the
    performance characteristics of your program is the first step toward optimizing
    it.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们也发现，调整程序性能是棘手的。内存竞争、垃圾回收和动态编译等效果可能会以难以通过查看源代码预测的方式影响程序性能。在本节中，我们一直敦促您通过实验验证对程序性能的怀疑和主张。了解您程序的性能特征是优化程序的第一步。
- en: Even when you are sure that parallel collections improve program performance,
    you should think twice before using them. Donald Knuth once coined the phrase
    *Premature optimization is the root of all evil*. It is neither desirable nor
    necessary to use parallel collections wherever possible. In some cases, parallel
    collections give negligible or no increase in speed. In other situations, they
    could be speeding up a part of the program that is not the real bottleneck. Before
    using parallel collections, make sure to investigate which part of the program
    takes the most time, and whether it is worth parallelizing. The only practical
    way of doing so is by correctly measuring the running time of the parts of your
    application. In [Chapter 9](ch09.html "Chapter 9. Concurrency in Practice"), *Concurrency
    in Practice*, we will introduce a framework called ScalaMeter, which offers a
    more robust way to measure program performance than what we saw in this chapter.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您确信并行集合可以提高程序性能，在使用它们之前也应该三思。Donald Knuth曾说过，“过早优化是万恶之源”。在可能的情况下使用并行集合既不理想也不必要。在某些情况下，并行集合可能只会带来微不足道的或没有速度上的提升。在其他情况下，它们可能会加快程序中不是真正瓶颈的部分。在使用并行集合之前，请确保调查程序中耗时最长的部分，以及它是否值得并行化。这样做唯一实际的方法是正确测量应用程序各部分的运行时间。在《实践并发》的第9章中，我们将介绍一个名为ScalaMeter的框架，它提供了一种比本章中看到的方法更稳健的方式来测量程序性能。
- en: This chapter briefly introduced concepts such as Random Access Memory, cache
    lines, and the MESI protocol. If you would like to learn more about this, you
    should read the article, *What Every Programmer Should Know About Memory*, by
    Ulrich Drepper. To gain a more in-depth knowledge about the Scala collections
    hierarchy, we recommend you to search for the document entitled *The Architecture
    of Scala Collections*, by Martin Odersky and Lex Spoon, or the paper *Fighting
    Bit Rot with Types*, by Martin Odersky and Adriaan Moors. To understand how data-parallel
    frameworks work under the hood, consider reading the doctoral thesis entitled
    *Data Structures and Algorithms for Data-Parallel Computing in a Managed Runtime*,
    by Aleksandar Prokopec.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 本章简要介绍了随机存取存储器、缓存行和MESI协议等概念。如果您想了解更多关于这方面的内容，应该阅读Ulrich Drepper撰写的文章《每个程序员都应该知道的关于内存的知识》。为了更深入地了解Scala集合层次结构，我们建议您搜索名为《Scala集合架构》的文档，由Martin
    Odersky和Lex Spoon撰写，或者阅读Martin Odersky和Adriaan Moors撰写的论文《使用类型对抗位腐化》。为了了解数据并行框架在底层是如何工作的，可以考虑阅读Aleksandar
    Prokopec撰写的博士论文《在托管运行时中进行数据并行计算的数据结构和算法》。
- en: So far, we've assumed that all the collection elements are available when the
    data-parallel operation starts. A collection does not change its contents during
    the data-parallel operation. This makes parallel collections ideal in situations
    where we already have the dataset, and we want to process it in bulk. In other
    applications, data elements are not immediately available, but arrive asynchronously.
    In the next chapter, we will learn about an abstraction called an event stream,
    which is used when asynchronous computations produce multiple intermediate results.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们假设在数据并行操作开始时所有集合元素都是可用的。在数据并行操作期间，集合不会改变其内容。这使得并行集合在已经拥有数据集且希望批量处理的情况下非常理想。在其他应用中，数据元素不是立即可用的，而是异步到达。在下一章中，我们将学习一个称为事件流的概念，当异步计算产生多个中间结果时使用。
- en: Exercises
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'In the following exercises, you will use data-parallel collections in several
    concrete parallel collection use cases, and implement custom parallel collections.
    In all examples, a special emphasis is put on measuring the performance gains
    from parallelization. Even when it is not asked for explicitly, you should ensure
    that your program is not only correct but also faster than a corresponding sequential
    program:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下练习中，你将使用数据并行集合在几个具体的并行集合用例中，并实现自定义并行集合。在所有示例中，特别强调测量并行化带来的性能提升。即使没有明确要求，你也应该确保你的程序不仅正确，而且比相应的顺序程序更快：
- en: Measure the average running time for allocating a simple object on the JVM.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测量在 JVM 上分配简单对象的平均运行时间。
- en: Count the occurrences of the whitespace character in a randomly generated string,
    where the probability of a whitespace at each position is determined by a `p`
    parameter. Use the parallel `foreach` method. Plot a graph that correlates the
    running time of this operation with the `p` parameter.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算随机生成的字符串中空白字符的出现次数，其中每个位置出现空白字符的概率由 `p` 参数确定。使用并行的 `foreach` 方法。绘制一个与该操作的运行时间相关的
    `p` 参数的图表。
- en: Implement a program that renders the Mandelbrot set in parallel.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个并行渲染曼德布罗集的程序。
- en: Implement a program that simulates a cellular automaton in parallel.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个并行模拟细胞自动机的程序。
- en: Implement a parallel *Barnes-Hut N-body* simulation algorithm.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个并行 *Barnes-Hut N-body* 模拟算法。
- en: Explain how you can improve the performance of the `result` method in the `ParStringCombiner`
    class, as shown in this chapter. Can you parallelize this method?
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释如何改进本章中 `ParStringCombiner` 类的 `result` 方法的性能。你能并行化这个方法吗？
- en: Implement a custom splitter for the binary heap data structure.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为二叉堆数据结构实现一个自定义拆分器。
- en: 'The binomial heap, described in the doctoral thesis of Chris Okasaki entitled
    *Purely Functional Data Structures*, is an immutable data structure that efficiently
    implements a priority queue with four basic operations: insert the element, find
    the smallest element, remove the smallest element, and merge two binomial heaps:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Chris Okasaki 的博士论文《纯函数式数据结构》中描述的二项堆，是一个不可变的数据结构，它有效地实现了具有四个基本操作的优先队列：插入元素、查找最小元素、移除最小元素和合并两个二项堆：
- en: '[PRE49]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Implement the `BinomialHeap` class. Then, implement splitters and combiners
    for the binomial heap, and override the `par` operation.
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实现 `BinomialHeap` 类。然后，为二项堆实现拆分器和合并器，并重写 `par` 操作。
- en: Implement the `Combiner` trait for the Red-Black tree from the Scala standard
    library. Use it to provide a parallel version of the `SortedSet` trait.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为 Scala 标准库中的红黑树实现 `Combiner` 特质。使用它来提供 `SortedSet` 特质的并行版本。
- en: Implement a `parallelBalanceParentheses` method, which returns `true` if the
    parentheses in a string are properly balanced, or `false` otherwise. Parentheses
    are balanced if, going from left to right, the count of left parenthesis occurrences
    is always larger than, or equal to, the count of right parenthesis occurrences,
    and the total count of the left parentheses is equal to the total count of the
    right parentheses. For example, string `0(1)(2(3))4` is balanced, but strings
    `0)2(1(3)` and `0((1)2` are not. You should use the `aggregate` method.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个 `parallelBalanceParentheses` 方法，如果字符串中的括号正确平衡则返回 `true`，否则返回 `false`。括号平衡是指，从左到右，左括号出现的次数始终大于或等于右括号出现的次数，并且左括号的总数等于右括号的总数。例如，字符串
    `0(1)(2(3))4` 是平衡的，但字符串 `0)2(1(3)` 和 `0((1)2` 则不是。你应该使用 `aggregate` 方法。
