- en: '*Chapter 5*: Integrating Microservices Using Event-Driven Architecture'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第五章*: 使用事件驱动架构集成微服务'
- en: The essence of microservice architecture is breaking a monolith down into decoupled
    or loosely coupled microservices. As a result of such a decomposition into microservices,
    we separate the user and/or business concerns owned by each microservice. However,
    for an application as a whole, all the microservices need to work together by
    interacting with each other in executing and serving the user requests. Event-driven
    architecture has gained popularity in addressing these inter-microservices interactions.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构的本质是将单体分解为解耦或松耦合的微服务。这种分解成微服务的结果是，我们将每个微服务拥有的用户和/或业务关注点分开。然而，对于整个应用程序来说，所有微服务需要通过相互交互来执行和响应用户请求，共同工作。事件驱动架构在解决这些微服务间的交互方面越来越受欢迎。
- en: 'In this chapter, we will explore how we can implement an event-driven architecture
    in the Micronaut framework. We will dive into the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨如何在 Micronaut 框架中实现事件驱动架构。我们将深入研究以下主题：
- en: Understanding event-driven architecture
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解事件驱动架构
- en: Event streaming with the Apache Kafka ecosystem
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Apache Kafka 生态系统进行事件流
- en: Integrating microservices using event streaming
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用事件流集成微服务
- en: By the end of this chapter, readers will have a nifty knowledge of event-driven
    architecture and how to implement an event-streaming broker to integrate app microservices
    in the Micronaut framework.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，读者将掌握关于事件驱动架构以及如何在 Micronaut 框架中实现事件流代理以集成应用程序微服务的高级知识。
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All the commands and technical instructions in this chapter are run on Windows
    10 and macOS. Code examples covered in this chapter are available in the book's
    GitHub repository at https://github.com/PacktPublishing/Building-Microservices-with-Micronaut/tree/master/Chapter05.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的所有命令和技术说明都是在 Windows 10 和 macOS 上运行的。本章涵盖的代码示例可在书籍的 GitHub 仓库 https://github.com/PacktPublishing/Building-Microservices-with-Micronaut/tree/master/Chapter05
    中找到。
- en: 'The following tools need to be installed and set up in the development environment:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 以下工具需要在开发环境中安装和设置：
- en: '**Java SDK**: Java SDK version 13 or above (we used Java 14).'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Java SDK**: Java SDK 版本 13 或更高（我们使用了 Java 14）。'
- en: '**Maven**: This is optional and only required if you would like to use Maven
    as the build system. However, we recommend having Maven set up on any development
    machine. Instructions regarding the downloading and installation of Maven can
    be found at [https://maven.apache.org/download.cgi](https://maven.apache.org/download.cgi).'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Maven**: 这不是必需的，只有当您想使用 Maven 作为构建系统时才需要。然而，我们建议在所有开发机器上设置 Maven。有关下载和安装
    Maven 的说明可以在 [https://maven.apache.org/download.cgi](https://maven.apache.org/download.cgi)
    找到。'
- en: '**Development IDE**: Based on your preferences, any Java-based IDE can be used,
    but for purposes of this chapter, IntelliJ was used.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开发 IDE**: 根据您的偏好，可以使用任何基于 Java 的 IDE，但为了本章节的目的，使用了 IntelliJ。'
- en: '**Git**: Instructions regarding the downloading and installation of Git can
    be found at [https://git-scm.com/downloads](https://git-scm.com/downloads).'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Git**: 有关下载和安装 Git 的说明可以在 [https://git-scm.com/downloads](https://git-scm.com/downloads)
    找到。'
- en: '**PostgreSQL**: Instructions regarding downloading and installation can be
    found at [https://www.postgresql.org/download/](https://www.postgresql.org/download/).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PostgreSQL**: 有关下载和安装的说明可以在 [https://www.postgresql.org/download/](https://www.postgresql.org/download/)
    找到。'
- en: '**MongoDB**: MongoDB Atlas provides a free online database-as-a-service up
    to 512 MB storage. However, if a local database is preferred, then instructions
    regarding downloading and installation can be found at [https://docs.mongodb.com/manual/administration/install-community/](https://docs.mongodb.com/manual/administration/install-community/).
    We used a local installation while writing this chapter.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MongoDB**: MongoDB Atlas 提供了高达 512 MB 存储空间的免费在线数据库即服务。然而，如果您更喜欢本地数据库，则可以在
    [https://docs.mongodb.com/manual/administration/install-community/](https://docs.mongodb.com/manual/administration/install-community/)
    找到有关下载和安装的说明。在编写本章节时，我们使用了本地安装。'
- en: '**REST client**: Any HTTP REST client can be used. We used the **Advanced REST
    Client** (**ARC**) Chrome plugin.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**REST 客户端**: 可以使用任何 HTTP REST 客户端。我们使用了 **高级 REST 客户端**（**ARC**）Chrome 插件。'
- en: '**Docker**: Instructions regarding the downloading and installation of Docker
    can be found at https://docs.docker.com/get-docker/.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Docker**: 有关下载和安装 Docker 的说明可以在 https://docs.docker.com/get-docker/ 找到。'
- en: Understanding event-driven architecture
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解事件驱动架构
- en: Event-driven architecture is pivotal in connecting different microservices.
    Before we dive into how to implement an event-driven interaction system, let's
    understand its fundamentals.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 事件驱动架构在连接不同的微服务中起着至关重要的作用。在我们深入了解如何实现事件驱动交互系统之前，让我们先了解其基本原理。
- en: 'The following are the key components at the core of any event-driven architecture
    implementation:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在任何事件驱动架构实现中的核心关键组件：
- en: '**Event**: An event is simply a change in the state of the system that needs
    to be traced. In a microservice architecture, a microservice may make or detect
    a change in the data''s state that might be worth noticing by other services.
    This state change is communicated as an event.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件**：事件仅仅是系统状态的变化，需要被追踪。在微服务架构中，一个微服务可能会创建或检测数据状态的变化，这可能值得其他服务注意。这种状态变化以事件的形式进行沟通。'
- en: '**Event producer**: An event producer is any microservice or component that
    is making or detecting a state change and generating an event for other components/services
    in the system.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件生产者**：事件生产者是任何正在创建或检测状态变化并为系统中的其他组件/服务生成事件的微服务或组件。'
- en: '**Event consumer**: An event consumer is any microservice or component that
    is consuming an event. Interestingly, this event consumption might trigger this
    component to produce another event.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件消费者**：事件消费者是任何消费事件的微服务或组件。有趣的是，这种事件消费可能会触发该组件生成另一个事件。'
- en: '**Event broker**: The event broker acts as a go-between between all the producer
    and consumer parties. It maintains a metadata quorum to keep track of events.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件代理**：事件代理在所有生产者和消费者之间充当中间人。它维护一个元数据共识以跟踪事件。'
- en: These key components come together to realize an event-driven architecture.
    Broadly speaking, there are two implementation strategies – **pub/sub** (also
    called event messaging) and **event streaming**. To learn more about these strategies,
    let's dive into the following sections.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这些关键组件共同实现了一个事件驱动架构。广义上讲，有两种实现策略——**发布/订阅**（也称为事件消息）和**事件流**。要了解更多关于这些策略的信息，让我们深入了解以下章节。
- en: Event messaging or a pub/sub model in an event-driven architecture
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事件驱动架构中的事件消息或发布/订阅模型
- en: 'A **pub/sub** model is a *push-based* model. In a push-based model, event publishing
    is owned by the event producer, and events are pushed from the producer and sent
    to consumers. The following are the key components in a pub/sub implementation:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**发布/订阅**模型是一个**基于推送**的模型。在基于推送的模型中，事件发布由事件生产者拥有，事件从生产者推送并发送到消费者。以下是在发布/订阅实现中的关键组件：'
- en: '**Event producer**: Any component that is making or detecting a state change
    will generate an event and publish it to the event broker.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件生产者**：任何正在创建或检测状态变化的组件都会生成一个事件并将其发布到事件代理。'
- en: '**Event broker**: The event broker will receive the generated event and push
    the event to all the required event queues. These event queues are subscribed
    to by event consumers. Therefore, events are pushed down to the event consumers
    by the broker.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件代理**：事件代理将接收生成的事件并将其推送到所有必需的事件队列。这些事件队列由事件消费者订阅。因此，事件通过代理被推送到事件消费者。'
- en: '**Event consumer**: The event consumer will receive the event and do what is
    required. It may also generate a new event(s).'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件消费者**：事件消费者将接收事件并执行所需操作。它也可能生成一个新的事件（或多个事件）。'
- en: 'This is depicted in the following diagram:'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这在以下图中表示：
- en: '![Figure 5.1 – Pub/sub model'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.1 – 发布/订阅模型'
- en: '](img/Figure_5.1_B16585_Fixed.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.1_B16585_Fixed.jpg)'
- en: Figure 5.1 – Pub/sub model
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 – 发布/订阅模型
- en: As shown in the preceding diagram, when **Event Producer 1** generates the **Event
    Foo**, it is pushed to the **Event Broker**. The **Event Broker** further pushes
    this event to **Event Consumer 1** and **Event Consumer 2**.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，当**事件生产者1**生成**事件Foo**时，它被推送到**事件代理**。**事件代理**进一步将此事件推送到**事件消费者1**和**事件消费者2**。
- en: So, overall, for **Event Bar** (which is generated by **Event Producer n**),
    **Event Broker** pushes it to **Event Consumer k**.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，总的来说，对于由**事件生产者n**生成的**事件Bar**，**事件代理**将其推送到**事件消费者k**。
- en: In a pub/sub model, once the event is produced and communicated to the consumer
    via the event broker, the event consumer must do the necessary immediately, as
    once an event is consumed, it perishes. The event consumer can never go back to
    historic events. This model is also sometimes referred to as the **event messaging
    model**.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在发布/订阅模型中，一旦事件被产生并通过事件代理传达给消费者，事件消费者必须立即执行必要的操作，因为一旦事件被消费，它就会消失。事件消费者永远无法回到历史事件。这种模型有时也被称为**事件消息模型**。
- en: Event streaming in event-driven architecture
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事件驱动架构中的事件流
- en: 'An **event streaming** model is a *pull-based* model. In a pull-based model,
    the onus lies on the event consumer to fetch the event. In an event streaming
    implementation, the key components will act as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**事件流**模型是一个基于**拉取**的模型。在拉取模型中，事件消费者负责获取事件。在事件流实现中，关键组件将如下操作：
- en: '**Event producer**: Any component that is making or detecting a state change
    will generate the event and send it to the event broker.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件生产者**：任何创建或检测状态变化的组件都会生成事件并将其发送到事件代理。'
- en: '**Event broker**: The event broker will receive the generated event and broadcast
    the event by putting the event in an event stream.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件代理**：事件代理将接收生成的事件，并通过将事件放入事件流来广播事件。'
- en: '**Event consumer**: The event consumer continuously monitors one or more event
    streams on the event broker. When a new event is pushed to the event stream, the
    consumer fetches the event and does what is required.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件消费者**：事件消费者持续监控事件代理上的一个或多个事件流。当新事件被推送到事件流时，消费者获取事件并执行所需的操作。'
- en: 'Refer to the following diagram:'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 参考以下图表：
- en: '![Figure 5.2 – Event streaming model'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.2 – 事件流模型'
- en: '](img/Figure_5.2_B16585_Fixed.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 5.2](img/Figure_5.2_B16585_Fixed.jpg)'
- en: Figure 5.2 – Event streaming model
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2 – 事件流模型
- en: As shown in the preceding diagram, when **Event Producer 1** generates the **Event
    Foo**, it pushes the event to **Event Broker** and **Event Broker** puts it in
    the **Foo Stream**. **Event Consumer 1** and **Event Consumer 2** fetch the event
    from the **Foo Stream**. **Event Bar** is fetched from **Bar Stream** by **Event
    Consumer k**.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，当**事件生产者 1**生成**事件 Foo**时，它将事件推送到**事件代理**，并将它放入**Foo 流**。**事件消费者 1**和**事件消费者
    2**从**Foo 流**中获取事件。**事件 Bar**由**事件消费者 k**从**Bar 流**中获取。
- en: In an event-streaming model, as event consumers fetch the data from an event
    stream, they can fetch any offset of the event stream. This even enables event
    consumers to access historic events. It especially comes in handy if you have
    a new consumer added to the system that might not be in touch with the recent
    state of the system and may start processing historic events first. For these
    reasons, event streaming is usually preferred over event messaging.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在事件流模型中，当事件消费者从事件流中获取数据时，他们可以获取事件流的任何偏移量。这甚至使事件消费者能够访问历史事件。如果你向系统中添加了一个新的消费者，它可能还没有接触过系统的最新状态，并且可能首先开始处理历史事件，这尤其有用。出于这些原因，事件流通常比事件消息更受欢迎。
- en: In the next section, we will get started with hands-on event streaming using
    a popular event-streaming stack.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将开始使用流行的事件流堆栈进行实际的事件流操作。
- en: Event streaming with the Apache Kafka ecosystem
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Kafka 生态系统中的事件流
- en: 'Apache Kafka is an industry-leading event streaming system. In the Apache Kafka
    ecosystem, the following are some of the key components:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Kafka 是业界领先的事件流系统。在 Apache Kafka 生态系统中，以下是一些关键组件：
- en: '**Event topic**: An event topic consists of a stream of immutable, ordered
    messages belonging to a particular category. Each event topic may have one or
    more partitions. A partition is indexed storage that supports multi-concurrency
    in Apache. Apache Kafka keeps at least one partition per topic and may add more
    partitions as specified (at the time of topic creation) or required. When a new
    message is published to the topic, Apache Kafka decides which topic partition
    will be used to append the message. Each topic appends the most recent message
    at the end. This is shown in the following diagram:'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件主题**：事件主题由属于特定类别的不可变、有序消息流组成。每个事件主题可能有一个或多个分区。分区是支持 Apache 中多并发索引存储。Apache
    Kafka 每个主题至少保留一个分区，并根据指定（在主题创建时）或需求添加更多分区。当新消息发布到主题时，Apache Kafka 决定将使用哪个主题分区来附加消息。每个主题将最新消息附加到末尾。这在下图中显示：'
- en: '![Figure 5.3 – Apache Kafka topic anatomy'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.3 – Apache Kafka 主题结构'
- en: '](img/Figure_5.3_B16585.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 5.3](img/Figure_5.3_B16585.jpg)'
- en: Figure 5.3 – Apache Kafka topic anatomy
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 – Apache Kafka主题结构
- en: As shown in the preceding diagram, when a new message is published to the steam,
    it is appended at the end. Event consumers can freely choose which topic offset
    to read. While **Consumer 1** reads at the first offset, **Consumer 2** reads
    from the sixth offset.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，当新消息发布到流中时，它被附加到末尾。事件消费者可以自由选择读取哪个主题偏移量。当**消费者1**从第一个偏移量读取时，**消费者2**从第六个偏移量读取。
- en: '**Event broker**: An event broker is a façade that provides an interface to
    write or read from event topic(s). Apache Kafka usually has the leader and follower
    brokers. The leader broker (for a topic) will serve all the write requests. If
    a leader broker fails, then the follower broker chimes in as leader.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件代理**：事件代理是一个门面，提供了写入或读取事件主题（s）的接口。Apache Kafka通常有主代理和从代理。对于主题，主代理将服务所有写入请求。如果主代理失败，那么从代理将作为主代理介入。'
- en: '**Kafka cluster**: If Apache Kafka has a quorum consisting of more than one
    event broker, then it''s called a cluster. In a cluster, each broker will usually
    lead a distinct topic and may substitute as a follower for other topics.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kafka集群**：如果Apache Kafka的法定多数由多个事件代理组成，那么它被称为集群。在集群中，每个代理通常会领导一个不同的主题，并且可能作为其他主题的从属代理。'
- en: '**Event producer**: Producers publish an event message to the topic stream.
    A producer interacts with the Apache Kafka ecosystem to know which broker should
    be used for writing an event message to a topic stream. If a broker fails or a
    new broker is added, Apache Kafka notifies the required producers of this.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件生产者**：生产者将事件消息发布到主题流。生产者将与Apache Kafka生态系统交互，以了解应使用哪个代理将事件消息写入主题流。如果代理失败或添加了新的代理，Apache
    Kafka将通知所需的生产者。'
- en: '**Event consumer**: A consumer reads the event messages from the topic stream.
    An event consumer will interact with the Apache Kafka ecosystem to know which
    broker should be used to read from a topic stream. Furthermore, Apache Kafka keeps
    track of the topic offset for each event consumer to resume event consumption
    properly.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件消费者**：消费者从主题流中读取事件消息。事件消费者将与Apache Kafka生态系统交互，以了解应使用哪个代理从主题流中读取。此外，Apache
    Kafka会跟踪每个事件消费者的主题偏移量，以便正确地恢复事件消费。'
- en: '**Zookeeper**: Zookeeper maintains the metadata quorum for the Apache Kafka
    ecosystem. It essentially maintains information about all brokers for event producers
    and consumers. It also keeps track of the topic offset for each event consumer.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Zookeeper**：Zookeeper维护Apache Kafka生态系统的元数据法定多数。它本质上维护了所有代理的信息，包括事件生产者和消费者。它还跟踪每个事件消费者的主题偏移量。'
- en: 'In the following diagram, we can see the various components in the Apache Kafka
    ecosystem and how they interact with each other in event streaming:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图中，我们可以看到Apache Kafka生态系统中的各种组件以及它们在事件流中的交互方式：
- en: '![Figure 5.4 – Apache Kafka ecosystem'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.4 – Apache Kafka生态系统'
- en: '](img/Figure_5.4_B16585.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.4_B16585.jpg)'
- en: Figure 5.4 – Apache Kafka ecosystem
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4 – Apache Kafka生态系统
- en: In the preceding diagram, the Apache Kafka ecosystem is shown at a glance. For
    each event topic, there will be at least one leader event broker and one or more
    follower event brokers. Information about leaders and followers is maintained
    in Zookeeper. When an event producer pushes a message, a broker will write the
    message to the required topic stream. Similarly, when an event consumer pulls
    a message, an event broker will fetch the message from the required topic stream.
    Zookeeper maintains the offset information for each topic for all the event consumers.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，Apache Kafka生态系统一览无余。对于每个事件主题，至少将有一个主事件代理和一个或多个从事件代理。领导者（主）和从属代理的信息由Zookeeper维护。当事件生产者推送消息时，代理会将消息写入所需的主题流。同样，当事件消费者拉取消息时，事件代理将从所需的主题流中检索消息。Zookeeper为所有事件消费者维护每个主题的偏移量信息。
- en: In the next section, we will dive into how to use the Apache Kafka ecosystem
    for event streaming in the pet clinic application.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将深入了解如何在宠物诊所应用程序中使用Apache Kafka生态系统进行事件流。
- en: Integrating microservices using event streaming
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用事件流集成微服务
- en: 'To learn and perform hands-on exercises, we will implement a simple scenario
    of event streaming in the pet clinic application. Consider the following diagram:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了学习和进行动手练习，我们将在宠物诊所应用程序中实现一个简单的事件流场景。考虑以下图：
- en: '![Figure 5.5 – Event streaming in the pet clinic application'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.5 – 宠物诊所应用程序中的事件流'
- en: '](img/Figure_5.5_B16585_Fixed.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.5_B16585_Fixed.jpg)'
- en: Figure 5.5 – Event streaming in the pet clinic application
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5 – 宠物诊所应用程序中的事件流
- en: In the aforementioned diagram, whenever there is a new vet review, the **pet-clinic-reviews**
    microservice will send the review to **Apache Kafka Streaming**. Apache Kafka
    appends the review to the **vet-reviews** topic stream. And, as the **pet-clinic**
    microservice is continuously monitoring the **vet-reviews** topic stream, it will
    fetch any new reviews appended to the topic and update the average rating accordingly.
    This is a simpleton diagram but will help to focus on the key learning objectives.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述图中，每当有新的兽医审查时，**pet-clinic-reviews** 微服务将审查发送到 **Apache Kafka Streaming**。Apache
    Kafka 将审查追加到 **vet-reviews** 主题流。而且，由于 **pet-clinic** 微服务正在持续监控 **vet-reviews**
    主题流，它将获取追加到主题的任何新审查并相应地更新平均评分。这是一个简单的图，但有助于集中学习关键目标。
- en: In the next section, we will begin by setting up the Apache Kafka ecosystem
    locally inside Docker to learn more about Apache Kafka streaming.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将开始设置本地 Docker 中的 Apache Kafka 生态系统，以了解更多关于 Apache Kafka 流的信息。
- en: Setting up the Apache Kafka ecosystem locally
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本地设置 Apache Kafka 生态系统
- en: 'To set up the Apache Kafka ecosystem locally, we will use Docker. The `docker-compose`
    file for all the required components and configurations can be found in the chapter''s
    GitHub workspace under `resources`: [https://github.com/PacktPublishing/Building-Microservices-with-Micronaut/blob/master/Chapter05/micronaut-petclinic/pet-clinic-reviews/src/main/resources/kafka-zookeeper-kafdrop-docker/docker-compose.yml](https://github.com/PacktPublishing/Building-Microservices-with-Micronaut/blob/master/Chapter05/micronaut-petclinic/pet-clinic-reviews/src/main/resources/kafka-zookeeper-kafdrop-docker/docker-compose.yml).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 要本地设置 Apache Kafka 生态系统，我们将使用 Docker。所有必需组件和配置的 `docker-compose` 文件可以在章节的 GitHub
    工作空间下的 `resources` 中找到：[https://github.com/PacktPublishing/Building-Microservices-with-Micronaut/blob/master/Chapter05/micronaut-petclinic/pet-clinic-reviews/src/main/resources/kafka-zookeeper-kafdrop-docker/docker-compose.yml](https://github.com/PacktPublishing/Building-Microservices-with-Micronaut/blob/master/Chapter05/micronaut-petclinic/pet-clinic-reviews/src/main/resources/kafka-zookeeper-kafdrop-docker/docker-compose.yml)。
- en: 'Perform the following steps to install and set up Apache Kafka:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以安装和设置 Apache Kafka：
- en: Download the `docker-compose` file from the aforementioned URL.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从上述网址下载 `docker-compose` 文件。
- en: Open the GitBash terminal.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 GitBash 终端。
- en: Change the directory to where you have placed the `docker-compose` file.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将目录更改到您放置 `docker-compose` 文件的位置。
- en: Run the `docker-compose up` command in the GitBash terminal.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 GitBash 终端中运行 `docker-compose up` 命令。
- en: As a result of following these instructions, Docker will install Zookeeper,
    Apache Kafka, and Kafdrop. Kafdrop is an intuitive admin GUI for managing Apache
    Kafka. In the following section, we will verify their installation.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下说明操作后，Docker 将安装 Zookeeper、Apache Kafka 和 Kafdrop。Kafdrop 是一个直观的 Apache
    Kafka 管理GUI。在下一节中，我们将验证它们的安装。
- en: Testing the Apache Kafka ecosystem setup
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试 Apache Kafka 生态系统设置
- en: 'To test whether the Apache Kafka ecosystem is installed successfully, perform
    the following steps:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试 Apache Kafka 生态系统是否成功安装，请执行以下步骤：
- en: 'Open the GitBash terminal and run the following command:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 GitBash 终端并运行以下命令：
- en: '[PRE0]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Change the directory to **opt/bitnami/kafka/bin/**.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将目录更改到 **opt/bitnami/kafka/bin/**。
- en: 'Add a topic stream by running the following in the GitBash terminal:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 GitBash 终端中运行以下命令以添加一个主题流：
- en: '[PRE1]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To add a message to the topic, run the following in the GitBash terminal:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要向主题添加消息，请在 GitBash 终端中运行以下命令：
- en: '[PRE2]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: A terminal prompt will appear, type `hello-world!`, and then hit *Enter*.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将出现一个终端提示符，输入 `hello-world!`，然后按 *Enter*。
- en: Press *Ctrl* + *D*, which should successfully add the event to the topic.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按 *Ctrl* + *D*，这将成功将事件添加到主题。
- en: 'By following these instructions, we added a `foo-stream` topic and added a
    message to this topic. To see this topic stream, we can open Kafdrop by opening
    `http://localhost:9100/` in a browser window. Refer to the following screenshot:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遵循这些说明，我们添加了一个 `foo-stream` 主题并向此主题添加了一条消息。要查看此主题流，我们可以在浏览器窗口中打开 `http://localhost:9100/`。请参阅以下屏幕截图：
- en: '![Figure 5.6 – Kafdrop showing foo-stream topic messages'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.6 – Kafdrop 显示 foo-stream 主题消息'
- en: '](img/Figure_5.6_B16585_Fixed.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_5.6_B16585_Fixed.jpg)'
- en: Figure 5.6 – Kafdrop showing foo-stream topic messages
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6 – Kafdrop 显示 foo-stream 主题消息
- en: Kafdrop provides an intuitive GUI for viewing and managing all the Apache Kafka
    streams. In the previous screenshot, we can see the messages inside the just created
    **foo-stream**.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Kafdrop 提供了一个直观的 GUI，用于查看和管理所有 Apache Kafka 流。在上一张屏幕截图中，我们可以看到刚刚创建的 **foo-stream**
    中的消息。
- en: Hitherto, we set up the Apache Kafka ecosystem locally in a Dockerized environment,
    and in the next section, we will use this setup for hands-on event streaming in
    the `pet-clinic-reviews` and `pet-clinic` microservices. We will begin by making
    the required changes in the `pet-clinic-reviews` microservice.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经在 Docker 化的环境中本地设置了 Apache Kafka 生态系统，在下一节中，我们将使用此设置在 `pet-clinic-reviews`
    和 `pet-clinic` 微服务中进行实际的事件流处理。我们将首先在 `pet-clinic-reviews` 微服务中进行必要的更改。
- en: Implementing an event-producer client in the pet-clinic-reviews microservice
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 pet-clinic-reviews 微服务中实现事件生产者客户端
- en: We will begin making the required changes to the `pet-clinic-reviews` microservices
    so that it can stream out the vet reviews to Apache Kafka. For this hands-on exercise,
    we will keep things simple. Therefore, we will skip the security setup and resume
    the code base from [*Chapter 3*](B16585_03_Final_VK_ePub.xhtml#_idTextAnchor065),
    *Working on the RESTful Web Services*.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将开始对 `pet-clinic-reviews` 微服务进行必要的更改，以便它可以将兽医评论流式传输到 Apache Kafka。对于这个实际练习，我们将保持简单。因此，我们将跳过安全设置，并从
    [*第 3 章*](B16585_03_Final_VK_ePub.xhtml#_idTextAnchor065) *在 RESTful Web 服务上工作*
    的代码库继续。
- en: 'Perform the following steps to see how this goes:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以查看结果：
- en: 'To begin, we will need to add a Kafka dependency to the `pom.xml` project:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要在 `pom.xml` 项目中添加 Kafka 依赖项：
- en: '[PRE3]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: By importing the `micronaut-kafka` dependency, we can leverage the Kafka toolkit
    in the `pet-clinic-reviews` microservice.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过导入 `micronaut-kafka` 依赖项，我们可以在 `pet-clinic-reviews` 微服务中利用 Kafka 工具包。
- en: 'Once the dependency has been imported, we will then need to configure `application.properties`
    as follows:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦导入依赖项，我们接下来需要按照以下方式配置 `application.properties`：
- en: '[PRE4]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As mentioned in preceding `application.properties`, we will fix port `8083`
    for the `pet-clinic-reviews` microservice and configure the Kafka connection by
    providing Bootstrap server details.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如前所述的 `application.properties` 中提到的，我们将为 `pet-clinic-reviews` 微服务修复端口 `8083`
    并通过提供 Bootstrap 服务器详细信息来配置 Kafka 连接。
- en: 'Next, we will create a Kafka client in the `pet-clinic-reviews` microservice,
    which can send messages to the `vet-reviews` topic. Begin by creating a package,
    `com.packtpub.micronaut.integration.client`. This package will contain the required
    client and, in the future, may contain more artifacts related to service integration.
    We now add `VetReviewClient` to this package:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将在 `pet-clinic-reviews` 微服务中创建一个 Kafka 客户端，该客户端可以向 `vet-reviews` 主题发送消息。首先创建一个包，`com.packtpub.micronaut.integration.client`。此包将包含所需的客户端，并且在未来可能包含更多与服务集成相关的工件。我们现在将
    `VetReviewClient` 添加到这个包中：
- en: '[PRE5]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '`VetReviewClient` is annotated with `@KafkaClient`. Using the `@KafkaClient`
    annotation, we can inject `VetReviewClient` as a Kafka client. Furthermore, just
    by simply using `@Topic("vet-reviews")`, we can send the messages (no need to
    even create the topic) to the `vet-reviews` topic stream.'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`VetReviewClient` 被注解为 `@KafkaClient`。使用 `@KafkaClient` 注解，我们可以将 `VetReviewClient`
    注入为 Kafka 客户端。此外，只需简单地使用 `@Topic("vet-reviews")`，我们就可以将消息（甚至不需要创建主题）发送到 `vet-reviews`
    主题流。'
- en: 'Hitherto, we have configured application properties and created a simple Kafka
    client. In the following code, we will make changes to `createVetReview()` in
    `VetReviewResource` so it can send messages to the topic stream when a new vet
    review is posted:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经配置了应用程序属性并创建了一个简单的 Kafka 客户端。在下面的代码中，我们将对 `VetReviewResource` 中的 `createVetReview()`
    进行修改，以便在发布新的兽医评论时向主题流发送消息：
- en: '[PRE6]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: From the preceding code, we can see that we can simply inject `VetReviewClient`
    into `VetReviewResource`. In `createVetReview()`, when a vet review is successfully
    inserted, we can send the message to the `vet-reviews` stream using `VetReviewClient`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码中，我们可以看到我们可以简单地注入 `VetReviewClient` 到 `VetReviewResource`。在 `createVetReview()`
    中，当兽医评论成功插入时，我们可以使用 `VetReviewClient` 将消息发送到 `vet-reviews` 流。
- en: In this section, we introduced the event producer in the `pet-clinic-reviews`
    microservice. In the following section, we will verify this event producer by
    invoking the HTTP `POST` endpoint to create a new vet review.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了 `pet-clinic-reviews` 微服务中的事件生产者。在下一节中，我们将通过调用 HTTP `POST` 端点来创建新的兽医评论来验证此事件生产者。
- en: Testing the event producer in the pet-clinic-reviews microservice
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 pet-clinic-reviews 微服务中测试事件生产者
- en: 'To test the event producer that has just been created, boot up the `pet-clinic-reviews`
    microservice locally and access the HTTP `POST` endpoint. In the following screenshot,
    we are using a REST client to invoke the `vet-reviews` HTTP `POST` endpoint to
    create a vet review:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试刚刚创建的事件生产者，请在本地上启动 `pet-clinic-reviews` 微服务并访问 HTTP `POST` 端点。在下面的屏幕截图中，我们使用
    REST 客户端调用 `vet-reviews` HTTP `POST` 端点以创建审查：
- en: '![Figure 5.7 – Creating a vet review for testing the event producer'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.7 – 为测试事件生产者创建审查]'
- en: '](img/Figure_5.7_B16585_Fixed.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_5.7_B16585_Fixed.jpg]'
- en: Figure 5.7 – Creating a vet review for testing the event producer
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7 – 为测试事件生产者创建审查
- en: 'As shown in the preceding screenshot, when we submit a request to create a
    new vet review, it will persist the vet review and also stream out the review
    to Apache Kafka. This event message can be verified by accessing Kafdrop at `http://localhost:9100/`.
    This is what the screen outputs:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一个屏幕截图所示，当我们提交一个创建新审查的请求时，它将持久化审查并将审查流出到 Apache Kafka。可以通过访问 `http://localhost:9100/`
    上的 Kafdrop 来验证此事件消息。这是屏幕输出的内容：
- en: '![Figure 5.8 – A newly added review to the vet-reviews stream'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.8 – 新增的 vet-reviews 流审查]'
- en: '](img/Figure_5.8_B16585_Fixed.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_5.8_B16585_Fixed.jpg]'
- en: Figure 5.8 – A newly added review to the vet-reviews stream
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8 – 新增的 vet-reviews 流审查
- en: As viewed in Kafdrop, we can verify that the event from the `pet-clinic-reviews`
    microservice is streamed out and added to the `vet-reviews` topic.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如在 Kafdrop 中所见，我们可以验证来自 `pet-clinic-reviews` 微服务的事件被流出到并添加到 `vet-reviews` 主题中。
- en: In this section, we verified the event producer in the `pet-clinic-reviews`
    microservice. In the following section, we will explore how to implement an event
    consumer in the Micronaut framework.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们验证了 `pet-clinic-reviews` 微服务中的事件生产者。在下一节中，我们将探讨如何在 Micronaut 框架中实现事件消费者。
- en: Implementing an event consumer client in the pet-clinic microservice
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 pet-clinic 微服务中实现事件消费者客户端
- en: In this section, we will implement an event consumer in the `pet-clinic` microservice
    so that it can consume messages streamed in the `vet-reviews` topic.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将在 `pet-clinic` 微服务中实现一个事件消费者，以便它可以消费 `vet-reviews` 主题中的流消息。
- en: 'To begin, we will need to add a Kafka dependency to the `pom.xml` project.
    This is shown with the following code:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要在 `pom.xml` 项目中添加一个 Kafka 依赖。这可以通过以下代码展示：
- en: '[PRE7]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Importing `micronaut-kafka` will enable us to leverage the Kafka consumer toolkit.
    Once the dependency has been imported, we will then need to configure `application.properties`
    as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 `micronaut-kafka` 将使我们能够利用 Kafka 消费者工具包。一旦导入依赖项，我们还需要按照以下方式配置 `application.properties`：
- en: '[PRE8]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As mentioned in the preceding code, we will fix port `8082` for the `pet-clinic`
    microservice and configure the Kafka connection by providing Bootstrap server
    details.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述代码所述，我们将为 `pet-clinic` 微服务固定端口 `8082` 并通过提供 Bootstrap 服务器详细信息来配置 Kafka 连接。
- en: Next, to contain all the Kafka integration artifacts, we will create a `com.packtpub.micronaut.integration`
    package. Since we will be consuming from the `vet-reviews` topic stream, we will
    add `VetReviewDTO` to the `com.packtpub.micronaut.integration.domain` package.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，为了包含所有 Kafka 集成工件，我们将创建一个 `com.packtpub.micronaut.integration` 包。由于我们将从
    `vet-reviews` 主题流中消费，我们将 `VetReviewDTO` 添加到 `com.packtpub.micronaut.integration.domain`
    包中。
- en: Some developers advocate keeping the DTOs in a shared repository that can be
    re-used in all microservices. However, keeping all the DTOs under an owning microservice
    is good for better encapsulation. Furthermore, there could be cases where a DTO
    such as `VetReviewDTO` could assume the desired object definition in one microservice
    and a different one in another microservice.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 一些开发者提倡将 DTOs 保留在共享仓库中，以便在所有微服务中重用。然而，将所有 DTOs 放在拥有微服务下有利于更好的封装。此外，可能存在某些情况下，如
    `VetReviewDTO`，可以在一个微服务中假定所需的对象定义，而在另一个微服务中则不同。
- en: 'We will create a Kafka listener in the `com.packtpub.micronaut.integration.client`
    package to leverage the `micronaut-kafka` toolkit. Refer to the following code
    block:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 `com.packtpub.micronaut.integration.client` 包中创建一个 Kafka 监听器，以利用 `micronaut-kafka`
    工具包。请参考以下代码块：
- en: '[PRE9]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'From the preceding code, we see that we created the `VetReviewListener` using
    the `@KafkaListener` annotation. In the `@KafkaListener` annotation, we passed
    `groupId`. Assigning a group ID to a Kafka listener adds the listener to a consumer
    group. This may be required when there are multiple consumer services for a topic
    stream so that the Kafka ecosystem can maintain an isolated offset for each consumer.
    Using `@Topic("vet-reviews")` allows `VetReviewListener` to receive any streamed
    out messages from the `vet-reviews` stream. When `VetReviewListener` receives
    any message, it invokes `updateVetAverageRating()` in `VetService`. In the following
    code snippet, we added this method in `VetService` to update the average rating
    for a vet when a new review is added to the `pet-clinic-reviews` microservice:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码中，我们可以看到我们使用 `@KafkaListener` 注解创建了 `VetReviewListener`。在 `@KafkaListener`
    注解中，我们传递了 `groupId`。为 Kafka 监听器分配一个组 ID 将其添加到消费者组中。当存在多个针对主题流的消费者服务时，这可能是必需的，以便
    Kafka 生态系统可以为每个消费者维护一个隔离的偏移量。使用 `@Topic("vet-reviews")` 允许 `VetReviewListener`
    接收来自 `vet-reviews` 流的任何流式输出消息。当 `VetReviewListener` 接收到任何消息时，它会在 `VetService`
    中调用 `updateVetAverageRating()`。在以下代码片段中，我们在 `VetService` 中添加了此方法，以便在向 `pet-clinic-reviews`
    微服务添加新的评论时更新兽医的平均评分：
- en: '[PRE10]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: From the preceding code, we see that the `updateVetAverageRating()` method retrieves
    the last stored rating. If the last stored rating is `null`, it assumes it to
    be `0`. In any case, it will add on the new rating and determine a new average
    rating. Once the average rating has been determined, rating information is persisted
    in the database by making a call to the repository.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码中，我们可以看到 `updateVetAverageRating()` 方法检索最后存储的评分。如果最后存储的评分是 `null`，它假定其为
    `0`。在任何情况下，它都会添加新的评分并确定新的平均评分。一旦确定了平均评分，就会通过调用存储库来将评分信息持久化到数据库中。
- en: In this section, we explored how we can implement an event consumer in the `pet-clinic`
    microservice. In the following section, we will verify this event consumer by
    creating a new vet review.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了如何在 `pet-clinic` 微服务中实现事件消费者。在下一节中，我们将通过创建一个新的兽医评论来验证此事件消费者。
- en: Testing the event consumer in the pet-clinic microservice
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 pet-clinic 微服务中测试事件消费者
- en: 'To test the event consumer that has just been created, we can boot up the `pet-clinic`
    (event consumer) and `pet-clinic-reviews` (event producer) microservices. Once
    the `pet-clinic-reviews` microservice is running, add a new vet review. In the
    following screenshot, you can see that we are using an HTTP REST client to post
    a vet review:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试刚刚创建的事件消费者，我们可以启动 `pet-clinic`（事件消费者）和 `pet-clinic-reviews`（事件生产者）微服务。一旦
    `pet-clinic-reviews` 微服务启动，添加一个新的兽医评论。在以下屏幕截图中，您可以看到我们正在使用 HTTP REST 客户端发布兽医评论：
- en: '![Figure 5.9 – Adding a new vet review to test the event consumer'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.9 – 添加新的兽医评论以测试事件消费者'
- en: '](img/Figure_5.9_B16585_Fixed.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.9_B16585_Fixed.jpg)'
- en: Figure 5.9 – Adding a new vet review to test the event consumer
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9 – 添加新的兽医评论以测试事件消费者
- en: In the `POST` request to the `vet-reviews` resource, we are adding an abysmal
    rating. The `pet-clinic-reviews` microservice successfully executed the request
    and responded with an `HTTP 201` response, assigning a review ID to the review
    submitted.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在对 `vet-reviews` 资源的 `POST` 请求中，我们添加了一个极低的评分。`pet-clinic-reviews` 微服务成功执行了请求，并返回了一个
    `HTTP 201` 响应，为提交的评论分配了一个评论 ID。
- en: 'As shown in the following screenshot, in the `pet-clinic` microservice, if
    we put a debug point in `VetReviewListener`, we can verify that the Kafka topic
    stream is sending out the message for a new vet review:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下屏幕截图所示，在 `pet-clinic` 微服务中，如果我们向 `VetReviewListener` 中设置一个调试点，我们可以验证 Kafka
    主题流正在发送新的兽医评论的消息：
- en: '![Figure 5.10 – Event message received by the event consumer'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.10 – 事件消费者接收的事件消息'
- en: '](img/Figure_5.10_B16585_Fixed_edited.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.10_B16585_Fixed_edited.jpg)'
- en: Figure 5.10 – Event message received by the event consumer
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 – 事件消费者接收的事件消息
- en: As shown in the preceding screenshot, when the `pet-clinic-reviews` microservice
    produces an event message, it is received by the `pet-clinic` microservice. This
    is the magic that integrates these two microservices using event-driven architecture.
    And this pattern can be extended to integrate microservices in a variety of different
    scenarios, such as a service sending out a message to multiple microservices or
    chained event messages, or choreographing complex microservice integrations.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一张截图所示，当 `pet-clinic-reviews` 微服务产生一个事件消息时，它被 `pet-clinic` 微服务接收。这是使用事件驱动架构将这些两个微服务集成的魔力。并且这种模式可以扩展到各种不同的场景中集成微服务，例如一个服务向多个微服务发送消息或链式事件消息，或者编排复杂的微服务集成。
- en: In this section, we verified the event consumer in the `pet-clinic` microservice
    such that when a new vet review is added to `pet-clinic-reviews`, `pet-clinic`
    receives the review information from the `vet-reviews` topic stream.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们验证了 `pet-clinic` 微服务中的事件消费者，以确保当新的兽医评论添加到 `pet-clinic-reviews` 时，`pet-clinic`
    从 `vet-reviews` 主题流中接收评论信息。
- en: Summary
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we started things off with some fundamentals of event-driven
    architecture, discussing two different kinds of event publishing models, which
    are pub/sub and event streaming. We discussed the core components of each model,
    as well as the pros/cons of using each model.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先介绍了事件驱动架构的一些基础知识，讨论了两种不同的事件发布模型，即 pub/sub 和事件流。我们讨论了每个模型的核心组件，以及使用每个模型的优缺点。
- en: Since event streaming was better suited for the pet-clinic application, we dived
    into event streaming using the Apache Kafka ecosystem. For hands-on exercises,
    we integrated the `pet-clinic-reviews` and the `pet-clinic` microservices using
    an Apache Kafka topic stream. We verified the integration by creating a new vet
    review and received the rating in the `pet-clinic` microservice to update the
    average rating for a vet.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 由于事件流更适合宠物诊所应用程序，我们深入探讨了使用 Apache Kafka 生态系统的事件流。为了实际操作练习，我们使用 Apache Kafka
    主题流集成了 `pet-clinic-reviews` 和 `pet-clinic` 微服务。我们通过创建一个新的兽医评论并接收 `pet-clinic`
    微服务中的评分来验证集成，以更新兽医的平均评分。
- en: This chapter has provided you with a solid understanding of event-driven architecture
    and a practical skillset in implementing an event-streaming system in the Micronaut
    framework.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 本章为您提供了对事件驱动架构的坚实基础理解，以及如何在 Micronaut 框架中实现事件流系统的实用技能集。
- en: In the next chapter, we will explore how we can automate quality testing using
    built-in as well as third-party tools in the Micronaut framework.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨如何使用 Micronaut 框架中的内置以及第三方工具来自动化质量测试。
- en: Questions
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is event-driven architecture?
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是事件驱动架构？
- en: What is the pub/sub model in event-driven architecture?
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 事件驱动架构中的 pub/sub 模型是什么？
- en: What is event streaming?
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是事件流？
- en: Describe the various components that make up the Apache Kafka ecosystem.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述构成 Apache Kafka 生态系统的各种组件。
- en: How is the Apache ecosystem set up in Docker?
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何在 Docker 中设置 Apache 生态系统？
- en: How are microservices integrated in the Micronaut framework using event streaming?
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何使用事件流在 Micronaut 框架中集成微服务？
- en: How is an event consumer implemented in the Micronaut framework?
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Micronaut 框架中如何实现事件消费者？
- en: How is an event producer implemented in the Micronaut framework?
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Micronaut 框架中如何实现事件生产者？
