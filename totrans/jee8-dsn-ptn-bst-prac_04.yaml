- en: Integration Patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to explain some integration patterns and look
    at how they work on the integration tier of Java EE. After reading this chapter,
    you will be able to implement these patterns and use them to solve integration problems
    between resources or systems. You will also be able to work on the integration
    tier and become familiar with the concepts associated with integration patterns.
    The topics in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Explaining the concept of the integration tier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explaining the concept of the data-access object pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the data-access object pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explaining the concept of the domain-store pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the domain-store pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explaining the concept of the service-activator pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the service-activator pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explaining the concept of the integration tier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed in previous chapters, Java EE is divided into three well-known
    tiers—the presentation tier, the business tier, and the integration tier. These
    tiers work together to promote solutions with a high level of decoupling.
  prefs: []
  type: TYPE_NORMAL
- en: In a business environment, software development is very difficult as we need
    to think about the whole ecosystem of the enterprise. An ecosystem includes its
    data source, software, data politics, security, and devices. Consequently, the
    developer needs to think about how to read and write data in these data sources,
    how the software communicates between with each other, how the data policies are
    implemented on the systems, how the security works on the business environment,
    and so on. In this case, it would be beneficial to create a tier to resolve all
    integration and communication problems, because their solutions will be decoupled
    from business logic. This is the thought process that gave birth to the integration
    tier.
  prefs: []
  type: TYPE_NORMAL
- en: The integration tier is the tier responsible for decoupling the business logic
    from the integration logic throughout the whole application. This tier has the
    logic of communication with an external resource or system, and this stays separate
    from the business logic. This tier will make it possible to read and write data
    from external sources, making communication between applications and components
    of the business ecosystem feasible. Furthermore, this tier will hide all communication
    complexity from the business tier. The business tier will then receive the data
    without knowing the complexity of the communication between the components and
    how they are structured.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, it is extremely rare to develop an application with integration but
    without some kind of integration with an external resource. This is because the
    application always needs to read data from a source, and this source is generally outside
    of the application in databases or filesystems. If the application has an external
    data source as its dependency, then this application needs to be integrated to
    access the data from the external data source. The simpler application will then
    have an integration tier.
  prefs: []
  type: TYPE_NORMAL
- en: Over time, the complexity of integration between resources or systems grew,
    because more and more business logic needs to be integrated to promote a good
    response to businesses. With this, there emerged a necessity to create a common
    solution to integration problems that occur over and over, and with this, the
    integration patterns were created.
  prefs: []
  type: TYPE_NORMAL
- en: Explaining the concept of the data-access object pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the business world, the application always needs to be integrated with the
    data source in order to read, write, delete, or update data. This data source
    could be a relational database, NoSQL database, **LDAP** (**Lightweight Directory
    Access Protocol**), or filesystem, for example. Each type of data source has its
    structure and has a complexity to connect to, read, and write data. These complexities
    shouldn't be exposed to business logic and instead should be decoupled from it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data-access object pattern is a pattern used to abstract and hides all
    access to data sources from the business tier. This pattern encapsulates all data-source
    access logic and its complexities from the business tier, decoupling all data-source
    access logic from it. If we then want to substitute the data source with another,
    we will only need to modify the code of the data-access object pattern, and this
    modification will not be visible on the business tier. The following diagram displays
    the data-access object pattern model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2ca072fb-cb1b-463e-9c5c-661952bda28a.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, we have **BusinessObject**, which has the business
    logic; DAO, which has the data access logic; **TransferObject**, which is the
    object used to transfer; and data source, which is the external local where the
    data resides. When **BusinessObject** needs to access the data, it requests data
    from DAO. The DAO accesses the data source and reads the data, then returns the
    data to **BusinessObject** as **TransferObject**. Some developers and professionals
    think this pattern is only supposed to be used with relational databases and `NoSql`,
    but when our data source is a filesystem or another type of data persistence,
    we should also use DAO in order to promote the decoupling between business logic
    and persistence logic as well as to organize our code.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the data-access object pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To implement this pattern using the best practices of Java EE 8, we will use
    a relational database and implement the data read and write using a JPA specification.
    In this example, we will have one table named *employee*, which contains the employee
    data. We will also create a class called `EmployeeDao` which will have four methods –
    `save(employee)`, `findByName(name)`, `findAll()`, and `delete(employee)`. The
    `save` method will receive one employee and save them on the database, `findByName`
    will receive the name as a parameter and will find the employee by name on the
    database, and `delete` will receive an employee and delete them from the database.
    Also, we are going to create a transfer object called `Employee`, a class that
    is a JPA entity and has the mapping to a database table.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the entity with JPA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The JPA entity is a class that represents some table or view of a database.
    The entity needs to have an attribute that identifies only one entity, needs to
    have a constructor with non-arguments and each object of a class that is a JPA
    entity identify only one row of table or view.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we have an interface, called `Entity`, that all JPA
    entities will implement according to the following method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following code, we have the transfer object, called `Employee`, which
    is a JPA entity. This class has the mapping table, called `Employee`, as well
    as its column used by applications. The business tier only needs to know the transfer
    objects, the DAOs, and the parameters to send to the DAOs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Implementing DAO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to reuse a lot of code and promote best practices to implement DAO,
    we will create an abstract DAO, called `AbstractDao`, which is the superclass
    of all DAOs, that has methods with the generic logic that can be used by all DAOs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To prevent the user from instantiating `AbstractDao`, we created the class
    in the preceding code as an abstract class. Another `AbstractDao` characteristic
    is the return of methods, which only return `Entity` or a list of `Entity`. This
    is a good practice, because we know the object type that is returned by this method
    and it organizes our code, because we know what type of value our method could
    return:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that we have the `EmployeeDao` class, which is the DAO that reads
    and writes data about `Employee`. This class is an EJB, meaning that it can control
    all transactions with the JTA specification—assuming that transactions are managed
    by the Java EE container—and make the transaction control transparent to the application.
    To read employee data, we can call the `findAll`, `findByName`, and `findById`
    methods; to write employee data, we can call the `persist` and `update` methods;
    and to remove (delete) employee data, we can call the `delete` method. Note that
    the business class—a class that acts on the business tier—doesn''t know about
    the process of reading and writing data; it only knows the parameters of the method
    to call as well as its returns. Therefore, we can substitute the data source without
    impacting the business logic. We have `EmployeeBusiness` using the DAO to read
    and write data, which we will see here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This is a good pattern; its use is very broad and most applications implement
    it. When implementing this pattern, be careful not to expose data-source characteristics,
    for example, by sending a SQL query as a parameter to DAO's execution or by sending
    a path of the file system as a parameter to DAO's execution.
  prefs: []
  type: TYPE_NORMAL
- en: Explaining the concept of the domain-store pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We covered the data-access object pattern in the previous section and looked
    at how this pattern makes an abstraction of the data access logic from the business
    tier. However, the data-access object pattern is a stateless pattern that does
    not save states and intelligence inside them. Some problems have a complex relationship
    between data, and the data persistence needs to be done through an intelligent
    process. To promote this feature, the data-access object pattern does not attend.
    This is because DAO shouldn't maintain states, shouldn't contain any intelligent
    processes, and need only contain a process for saving or updating. To solve this
    problem, the domain-store pattern was created—a pattern that can add functionalities
    to DAO.
  prefs: []
  type: TYPE_NORMAL
- en: 'The domain-store pattern is a pattern that makes the object-model persistence
    transparent, separating the persistence logic from the object model, making it
    possible for the application to select the persistence logic according to the
    object state. Inside this pattern exists a DAO, designed to communicate and manipulate
    data with the data source, but this DAO is hidden from the application. This pattern
    is rarely implemented by developers because JPA already works as a domain-store
    pattern. This is because the JPA implements some intelligent processes to define
    when and how to save the data and its intelligent processes are oriented by the
    mapping made on JPA entities. However, when we decide to implement persistence
    in another type of data source, we may want to implement this pattern and use
    it in our application. In the following diagram, we can see the domain-store pattern model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e624879-dbda-4431-a000-abb42017c613.png)'
  prefs: []
  type: TYPE_IMG
- en: Many developers believe that the DAO is dead after JPA. This is because the
    JPA works with the domain store pattern and already has an internal DAO. However,
    to us, the DAO is a good pattern to use on Java EE projects. This is because JPA
    has a stronger relationship with relational databases, and if we substitute the
    relational database for another type of data source, we will possibly need to
    remove the JPA and use another mechanism instead. If all JPA calls are inside
    DAO, the application will only see DAO, and the JPA implementation will be hidden from
    the application. This makes the business tier more decoupled from the integration
    tier and the persistence logic.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the domain-store pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is a very long pattern. To implement and facilitate this implementation,
    we will save all the data on HashMap. This is an important step, because the focus
    of this subsection is to demonstrate how to implement domain-store patterns. To
    facilitate our understanding, we will look at the same scenario covered in the *Implementing
    the data-access object pattern* subsection. Here, we have the transfer object,
    called `Employee`, and we will also read and write data on the data source. However,
    persistence will be oriented by object state and will have an intelligence in
    its logic.. In this implementation, we have the following classes, interfaces,
    and annotations:'
  prefs: []
  type: TYPE_NORMAL
- en: '`PersistenceManagerFactory`: This works as a factory pattern and is responsible
    for creating instances of the `PersistenceManager` class. `PersistenceManagerFactory`
    is a singleton and has only one instance on the entire application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PersistenceManager`: This manages the persistence and queries the data. This
    data is an object model that works as a *Unit of Work. *'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Persistence`: This is an annotation used as the *qualify* of CDI. This qualify
    is used to define a method of `PersistenceManagerFactory`, which is responsible
    for creating a `PersistenceManager` instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`EmployeeStoreManager`: This works as a **Data-Access Object** (**DAO**), interacting
    with the data source and encapsulating all the data source complexity. DAO is
    responsible for reading and writing employee data on the data source.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`StageManager`: This is an interface used to create all the `StageManager`
    implementations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`EmployeeStageManager`: This coordinates the read and writes operations of
    data according to its states and rules.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TransactionFactory`**:** This works as a factory pattern and is responsible
    for creating `Transaction` instances. `TransactionFactory` is a singleton and
    has only one instance in the entire application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Transaction`**:** This is used to create transaction-oriented policies. This
    class controls the life cycle of transactions and defines the transaction limits.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Transaction` (annotation): Annotation used as the *q**ualify* of CDI. This
    *qualify* is used to define a method of `TransactionFactory` that is responsible
    for creating a `Transaction` instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To implement this pattern, we will begin with the `PesistenceManagerFactory`
    class, which is a factory of `PersistenceManager`.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the PersistenceManagerFactory class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following code, we have the qualify used to inject the `PersistenceManager`
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Looking at the following code, we can see that we have the `PersistenceManagerFactory` class,
    which is responsible for creating new instances of `PersistenceManager`. This
    class uses the `@Singleton` annotation, which is an EJB annotation used to create
    a singleton pattern with the Java EE mechanism. The `getPersistenceManager` method has
    the `@Produces` annotation, which is used to define a method responsible for creating
    a new instance. It also has the `@Persistence` annotation, which is used as a *qualify*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Implementing the PersistenceManager class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We need to manage all processes of persistence and query data. For this, we
    need to create a class.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `PersistenceManager` class is responsible for managing all persistence
    processes and query processes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we have the `PersistenceManager` class. This class has
    the `stateManagers` attribute, which is a set of `StateManager` used to control
    the read and write of each object model. It also has the `Transaction` attribute,
    which is used to control the transaction lifecycle. This class also has the `persist`
    method, which is used to write the data represented by the object model; the `begin`
    method, used to begin the transaction; the `load` method, used to read an object
    model's data; the `commit` method, used to commit the transaction; and finally,
    the `rollback` method, which is used to roll back the transaction.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the EmployeeStoreManager class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `EmployeeStoreManager` class is responsible for connecting with the data
    source as well as reading and writing employee data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, we have the `EmployeeStoreManager` class, which
    is responsible for connecting with the data source and reading and writing employee
    data. This class works as a DAO and encapsulates all the data source complexity.
    It also has the `dataSource` attribute, which is a map that represents a data
    source. Furthermore, this class has the `storeNew` method, which is used to write
    new employee data represented by the object model. It also has the `update` method,
    used to write existing employee data represented by an object model. This method
    is used to update stored data. The `delete` method is also used to delete existing
    employee data, and the load method is used to read employee data in an object
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the StageManager interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`StageManager` is an interface that is implemented by `EmployeeStageManager`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code block, we have the `StageManager` interface. This interface
    is implemented by `EmployeeStageManager`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, we have the `isNew` attribute, which is used to
    define whether or not the object model is a new write (new data will be created
    on data source). The code also contains the `employee` attribute, which is the
    object model used to represent employee data. We can also see the `flush` method,
    used to execute the process for writing data on the data source; the `load` method,
    used to read data from the data source; the `updateEmployee` method, which is
    the private method used to update the `employee` attribute; and the `getEntity`
    method, which is used to return the `employee` attribute.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the TransactionFactory class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following code, we have the `Transactional` annotation, which is a `Qualifier` used
    to inject the `Transaction` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code block, we have the `TransactionFactory` class, which
    is responsible for creating new instances of the `Transaction` class. This class
    uses the `@Singleton` annotation, which is an EJB annotation used to create a
    singleton pattern with the Java EE mechanism. The `getTransaction` method has
    the `@Produces` annotation, used to define a method responsible for creating a
    new instance, and the `@Transactional` annotation, used as a qualify:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Implementing the Transaction class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Transaction` class is responsible for controlling the transaction lifecycle
    and defining the transaction delimit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, we have the `Transaction` class, which is responsible
    for controlling the transaction lifecycle and defining the transaction delimit.
    This class has the `init()` method, annotated with `@PostConstruct`, which configures
    this method to be called after the constructor is executed. Furthermore, this
    class has the `commit` method, which is used when the user needs to confirm the
    transaction; the `rollback` method, used to undo all transactions; the `begin` method, used
    to open a transaction; and the `isOpened` method, which is used to verify whether
    a transaction is open or not.
  prefs: []
  type: TYPE_NORMAL
- en: The transaction is closed if the `begin` method was not called or if the `commit`
    or `rollback` methods were called and a new call to the `begin` method was not
    made.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the EmployeeBusiness class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `EmployeeBusiness` class has the employee business logic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, we have the `EmployeeBusiness` class, which has
    the employee business logic. This class has the `save(Employee)` method, which
    is used to save employee data, and `findById(Employee )`, which is used to find
    an employee according to their ID. Note that, on the `save` method, we call the
    `begin()` method as well as `commit()` from the `PersistenceManager` class. These
    calls define the delimiting of a transaction and only the data is saved at the
    data source when the `commit()` method is called.
  prefs: []
  type: TYPE_NORMAL
- en: Explaining the concept of the service-activator pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Suppose a client needs to request a business service, which is a process that
    takes a long time. In this case, the client should not wait in a synchronous way
    until the end of the process. Instead, there must be a way to make an asynchronous
    service call that does not block the client or user. This service can then be
    activated at some point in the future. There may be several reasons for the delay
    of a process. For example, there may be a database query that consumes a lot of
    time, or an access to a legacy system that is beyond the control of the current
    application. The pattern of asynchronously performing the required task is known
    as the service activator.
  prefs: []
  type: TYPE_NORMAL
- en: So, the service activator pattern is always used when the client needs to call
    a service asynchronously. This means that the client makes the request and does
    not wait for the response.
  prefs: []
  type: TYPE_NORMAL
- en: We can imagine some alternative solutions to this problem. One method would
    be to send the request to a queue, while another service would read the request
    from this queue and execute the task within it. Alternatively, when the client
    requests a service, this service could be placed in a database, and there could
    be a listener or a job that would check the tasks that had not yet been performed.
    If a task had not yet been performed, it would be executed.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, the JEE specification gives us very good solutions that are used to
    implement the service-activator pattern. These solutions are described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Java Message Service** (**JMS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EJB asynchronous methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Asynchronous events: producers and observers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These three solutions were offered in the given order within the evolution of
    the JEE specification. We'll look at each of these solutions in more detail in
    the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Java Message Service (JMS)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **message-driven middleware** (**MOM**) is an architecture that uses message
    exchanges, which refers to sending and receiving messages, between the modules
    of an application or between distributed systems. The MOM provides some good services,
    such as message persistence or message-delivery guarantees. A message broker is
    based on a MOM, for instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Java Message Service (JMS) is an application programming interface (API) that provides
    a MOM interface for clients who want an asynchronous process. JMS became part
    of the EJB technology in the EJB 2.0 specification and a new session bean was
    then introduced: the message-driven bean (MDB).'
  prefs: []
  type: TYPE_NORMAL
- en: An MDB bean is a stateless session bean that is used to listen to requests or
    objects arriving in a JMS queue. It is important to note that an MDB can implement
    any type of message, but it is more commonly used to handle JMS messages.
  prefs: []
  type: TYPE_NORMAL
- en: A message-driven bean listens to messages that have been sent to a queue or
    to a topic. However, we will only see the example of messages sent to a queue.
    Messages can be sent by any JEE component or by another application outside the
    JEE context.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the trajectory of a message, from being sent to
    being received by an MDB:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9efb5305-626c-4b53-bc16-2c914ac468b4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Later in this chapter, we''ll see an example of the implementation of message
    producers and a message receiver. The receiver of the message will be implemented
    with an MDB. For now, we will quote some important items about the MDB. The MDB
    implementation has the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The `@MessageDriven` annotation sets the bean to be message-driven. In addition,
    the bean class must be public but cannot be abstract or final, and the class must
    contain a public constructor with no arguments.
  prefs: []
  type: TYPE_NORMAL
- en: The `mappedName` attribute specifies the JNDI name of the JMS that will receive
    the message to be consumed. There are other attributes in the `@MessageDriven`
    annotation that are used to configure the bean. For example, the `activationConfig` attribute
    may contain an `@ActivationConfigProperty` annotation array that contains a key/value
    pair used to improve the bean's configuration.
  prefs: []
  type: TYPE_NORMAL
- en: The bean must implement the `MessageListener` interface, which has only one
    method, known as `onMessage`. This method is called by the container whenever
    the message is consumed by the MDB.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can identify the following characteristics of an MDB:'
  prefs: []
  type: TYPE_NORMAL
- en: It is not in the same transaction context as the message sender
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is not called directly by another session bean
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can invoke other session beans
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can send JMS messages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It does not have remote or local interfaces related to client access
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EJB asynchronous methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The EJB 3.1 specification incorporated asynchronous methods to session beans
    with the use of an `@javax.ejb.Asynchronous` annotation. Consequently, we can
    have asynchronous processing from a simple call to an EJB method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `@javax.ejb.Asynchronous` annotation can be applied to a class of a session
    bean or applied to individual methods of this class. If applied to the entire
    class, all business methods of this bean are called asynchronously. Otherwise,
    only the methods with the annotation will be called asynchronously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The second method returns an instance of `java.util.concurrent.Future`. With
    this object, the client can check whether the result has already arrived, or can
    even abort the task. However, the method returns immediately to the client thread
    and does not block the process.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous events – producers and observers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another alternative that appeared on the evolutionary scale of the JEE platform
    was the event mechanism that is a part of the CDI specification. The mechanism
    is composed of producers and consumers of events, meaning that one component fires
    an event and another component of the application receives the event, acting as
    a listener or observer.
  prefs: []
  type: TYPE_NORMAL
- en: Up to the JEE8 specification, this event mechanism was done synchronously. With
    the introduction of CDI 2.0 in the JEE8 specification, the events API included
    improvements such as asynchronous use.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the asynchronous mechanism for sending and receiving
    events:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d21d7a33-a943-4dbe-8ff5-11dd5852efde.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we will see the basics of how to implement the codes of a *producer* and
    an *observer* of an asynchronous event:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The `someEvent` event is injected into the `SomeProducer` class, and the `Event.fireAsync()`
    method is responsible for the asynchronous event-firing. After some time, observers also receive
    the event asynchronously. The observer methods have parameters annotated with
    `@ObservesAsync`.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous observers are called in a new transaction context. However, they
    belong to the same security context as the invocation of `Event.fireAsync`.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the service-activator pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are now going to show code examples of the three solutions offered by the
    Java EE platform.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing sending and receiving messages with JMS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following is an example of a JMS message sender. This is a CDI bean that
    is responsible for sending messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The `@JMSConnectionFactory` annotation indicates which `ConnectionFactory`
    should be used to create the `JMSContext`. The following code block shows an MDB
    that receives the message generated by the producer described earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'As previously mentioned, the `@MessageDriven` annotation converts a simple
    bean into an MDB. This annotation has many activation configuration properties,
    defined by the JMS specification. The two important properties shown in the example
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`destinationLookup`: The JNDI lookup name of the queue or topic'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`destinationType`: The queue type, `javax.jms.Queue` or `javax.jms.Topic`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similar to a stateless session bean, the container can make an instance pool
    to handle multiple messages. The `onMessage` method belongs to a single transaction
    context, and this context is propagated to the other methods invoked within `onMessage`.
  prefs: []
  type: TYPE_NORMAL
- en: A `MessageDrivenContext` object can be injected into an MDB. This object provides
    access to the MDB context at runtime. We can, for example, roll back a transaction
    using the `setRollbackOnly()` method shown in the earlier mentioned example.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the EJB asynchronous methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following code shows an example of a stateless EJB asynchronous method.
    Suppose there is a method responsible for approving and scheduling student test
    reviews and we want to call this method in an asynchronous way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We will look at a bean client that requests a test review service, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Asynchronous methods can return `void`, or as an instance of `java.util.concurrent.Future
    <T>`. In the preceding example, the return is an instance of `Future <TestReview>`.
    The result of invoking the asynchronous method is returned immediately and there
    is no lock on the client thread. However, the client can consult this instance
    of `Future` at any time in order to check the result. The `TestReview` object
    contains information such as the Boolean type, whether or not the test review
    was approved, and the test review schedule date.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing asynchronous events – producers and observers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Suppose a client wants to send emails to college students, inviting them to
    a science and technology seminar. And suppose that the emails that were sent generate
    statistical information for later analysis. In this case, the client does not
    need to wait for the answer immediately. We can make an event producer and two
    event observers: an observer responsible for sending the email itself and an observer
    responsible for statistical control. The two processes are independent of each
    other. The following code shows the producer and the two observers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the `SeminarProducer` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'These are the two observers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about the integration tier, as well as integration
    patterns and how they are implemented. The integration patterns that we learned
    about included the data-access object pattern, the domain-store pattern, and the
    service-activator pattern. We also learned about the implementations of these
    patterns. Furthermore, we learned about the concept of the data-access object
    pattern, as well as when and how to implement it using the best practices of Java
    EE 8\. We also learned about domain-store pattern concepts, the differences between
    the domain-store pattern and the data-access object pattern, and when and how
    to implement domain-store patterns. Finally, we learned about service-activator
    pattern concepts and when and how to implement this using JMS, EJB asynchronous
    methods, asynchronous event mechanisms, and the best practices of Java EE 8.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will cover reactive patterns, focusing on when to use
    them and how to implement them using best practices of Java EE 8.
  prefs: []
  type: TYPE_NORMAL
