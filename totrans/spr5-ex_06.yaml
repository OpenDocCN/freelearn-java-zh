- en: Playing with Server-Sent Events
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 4](4286f9d7-1fe5-49c7-9201-49f9c9bdddf6.xhtml), Kotlin Basics and
    Spring Data Redis and [Chapter 5](eb1d7de5-c93b-49c2-a1a5-2c5e8b65cddc.xhtml),
    *Reactive Web Clients*, we created two microservices. The first one is responsible
    for keeping tracked data on Redis and triggering the second microservice which
    one will consume the Twitter stream. This process happens asynchronously.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will create another microservice which will consume the
    data produced by Twitter Gathering and expose it via a REST API. It will be possible
    to filter Tweets by text content.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: We have consumed the Twitter stream using the **Server-Sent Events** (**SSE**);
    we created a reactive REST client to consume that. Now, it is time to create our
    implementation for SSE. We will consume the RabbitMQ queue and push the data to
    our connected clients.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: We will take a look at the SSE and understand why this solution fits well for
    our couple of microservices.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: At the end of the chapter, we will be confident about using SSE in the Spring
    ecosystem.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Implementation of SSE endpoints with the Spring Framework
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consuming RabbitMQ using the Reactor Rabbit client
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating the Tweet Dispatcher project
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we will create our last microservice. It will push the Tweets filtered
    by Twitter Gathering for our connected clients, in this case, consumers.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will use the Spring Initializr page to help us create our
    pretty new project. Let's create.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Using Spring Initializr once again
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you can see, the Spring Initializr page is a kind of partner for creating
    Spring projects. Let''s use it one more time and create a project:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to [https://start.spring.io](https://start.spring.io) and fill in the data
    using the following screenshot:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/57bc2578-b33b-401b-8b6d-aa0e113e2c8e.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
- en: We have selected the Reactive Web dependencies; we will also keep using Kotlin
    as a programming language. Finally, click on the Generate Project button. Good,
    it is enough for us.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: There are some missing dependencies which are not displayed in the Spring Initializr.
    We need to set these dependencies manually. We will do that task in the next section.
    Let's go there.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Additional dependencies
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We need to use the Jackson Kotlin Module as a dependency to handle JSON properly
    in our new microservice. Also, we will use the Reactor RabbitMQ dependency, which
    allows us to interact in the reactive paradigm with the RabbitMQ Broker.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'To add these dependencies, we need to add the following snippet to `pom.xml`:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Awesome. Our dependencies are configured. Our project is ready to start.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Before we start, we need to understand, in depth, the concept of SSE. We will
    learn this in the next section.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Server-Sent Events
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Server-Sent Events (SSE) is a standard way to send data streams from a server
    to clients. In this next section, we will learn how to implement it using the
    Spring Framework.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Also, we will understand the main differences between SSE and WebSockets.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还将了解SSE和WebSockets之间的主要区别。
- en: A few words about the HTTP protocol
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于HTTP协议的一些话
- en: HTTP is an application layer protocol in the OSI model. The application layer
    is the last layer represented in the OSI model. It means this layer is closer
    to the user interface. The main purpose of this layer is to send and receive the
    data input by the user. In general, it happens by the user interface, also known
    as applications, such as file transfer and sending an email.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP是OSI模型中的应用层协议。应用层是OSI模型中最后表示的一层。这意味着这一层更接近用户界面。这一层的主要目的是发送和接收用户输入的数据。通常，这通过用户界面，也称为应用程序，如文件传输和发送电子邮件来实现。
- en: There are several protocols on the application layer such as Domain Name Service (DNS), which
    translates the domain names to IP address, or SMTP, whose main purpose is to deliver
    an email to a mail manager application.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 应用层有几种协议，例如域名系统（DNS），它将域名转换为IP地址，或者SMTP，其主要目的是将电子邮件发送到邮件管理应用程序。
- en: The application layer interacts directly with software such as email clients,
    for instance; there are no interactions with the hardware parts. It is the last
    layer of the OSI model and the closest to the end user as well.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 应用层直接与电子邮件客户端等软件交互，例如；与硬件部分没有交互。它是OSI模型的最后一层，也是离最终用户最近的一层。
- en: All these layers deal with software, which means there are no concerns about
    the physical parts represented in the OSI model.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些层都处理软件，这意味着没有关于OSI模型中代表的物理部分的担忧。
- en: A more detailed explanation of the OSI model can be found at: [https://support.microsoft.com/en-us/help/103884/the-osi-model-s-seven-layers-defined-and-functions-explained](https://support.microsoft.com/en-us/help/103884/the-osi-model-s-seven-layers-defined-and-functions-explained).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在以下链接找到OSI模型的更详细解释：[https://support.microsoft.com/en-us/help/103884/the-osi-model-s-seven-layers-defined-and-functions-explained](https://support.microsoft.com/en-us/help/103884/the-osi-model-s-seven-layers-defined-and-functions-explained)。
- en: 'The following is an OSI model representation:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个OSI模型的表示：
- en: '![](img/ea0ff23f-16c7-4bd9-835f-e196d6d8487d.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ea0ff23f-16c7-4bd9-835f-e196d6d8487d.png)'
- en: The HTTP protocol uses the TCP protocol as a transportation channel. Then, it
    will establish a connection and start to flow the data on the channel.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP协议使用TCP协议作为传输通道。然后，它将建立连接并开始在通道上传输数据。
- en: The TCP protocol is a stream protocol and a full duplex channel. This means
    the server and clients can send data across the connection.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: TCP协议是一种流协议和全双工通道。这意味着服务器和客户端可以通过连接发送数据。
- en: HTTP and persistent connections
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HTTP和持久连接
- en: The HTTP protocol is a request-response model, where the client submits the
    message (HTTP Request) and the server processes this message and sends the response
    (HTTP Response) to the client. The connection will be closed after the response
    is sent.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP协议是一种请求-响应模型，其中客户端提交消息（HTTP请求）并处理此消息，然后将响应（HTTP响应）发送给客户端。在发送响应后，连接将被关闭。
- en: 'Look at the following diagram:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 看看以下图表：
- en: '![](img/677329f9-078d-4ff4-b3d4-fc042251f6aa.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/677329f9-078d-4ff4-b3d4-fc042251f6aa.png)'
- en: It's pretty simple to understand. The client will send the request, and in this
    case, the connection will be opened. After that, the server will receive the request
    to process something and it will send the answer to the client. The connection
    will be closed after the whole process. If the client needs to send a new request,
    the connection should be opened again and the flow happens in the same order.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 理解起来相当简单。客户端将发送请求，在这种情况下，连接将被打开。之后，服务器将接收请求以处理某些内容，并将答案发送给客户端。在整个过程完成后，连接将被关闭。如果客户端需要发送新的请求，则应再次打开连接，并且流程按照相同的顺序发生。
- en: There is a perceived drawback here, the clients need to open the new connection
    per-request. From the server's eyes, the server needs to process a lot of new
    connections simultaneously. This consumes a lot of CPU and memory.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个明显的缺点，客户端需要为每个请求打开新的连接。从服务器的角度来看，服务器需要同时处理大量的新连接。这消耗了大量的CPU和内存。
- en: 'On HTTP''s 1.0 version, the connections are not persistent. To enable it, the
    `keep-alive` header should be included on the request. The header should look
    like this:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在HTTP的1.0版本中，连接不是持久的。为了启用它，请求中应包含`keep-alive`头。头应如下所示：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This is the only way to make an HTTP connection persistent on the 1.0 version,
    as described previously; when it happens, the connection will not be dropped by
    the server and the client is able to reuse the opened connection.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: On HTTP 1.1, the connections are persistent by default; in this case, as opposed
    to the first version, the connection is kept opened and the client can use it
    normally.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: There is a perceived improvement here and it can bring some advantages. The
    server needs to manage fewer connections, and it reduces a lot of CPU time. The
    HTTP Requests and Responses can be pipelined in the same connection.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: As we know, *there is no such thing as a free lunch*. There are some disadvantages
    to this as well; the server needs to keep the connection opened and the server
    will reserve the required connection for the client. This may cause server unavailability
    in some scenarios.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Persistent connections can be useful to maintain a stream between the server
    and clients.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: WebSockets
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the HTTP protocol, the communication supports full-duplex, which means the
    client and server can send data through the channel. The standard way to support
    this kind of communication is WebSockets. In this specification, both client and
    server can send data to each other in the persistent connection. Look at the following
    diagram:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1d3d89ff-2d73-426b-ad8d-95d5bfb0448a.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: As we can see, the data can be sent and received by the two actors, client,
    and server—this is how WebSockets works.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we do not need to send any data to the server during the connection.
    Because of this characteristic, we will choose SSE. We will learn about them in
    the following section.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Server-Sent Events
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As opposed to the full-duplex communication implemented by WebSockets, the SSE
    uses a half-duplex communication.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: 'The client sends a request to the server, and when necessary, the server will
    push the data to the client. Remember the active actor here is the server; the
    data can be sent only by the server. This is a half-duplex behavior. Look at the
    following diagram:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/92b99972-42e9-4a44-9346-60df700f5518.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
- en: A piece of cake. It is the base of the SSE technology. SSE is self-explanatory.
    We will use it with the Spring Framework. However, before we do that, let's look
    at a Reactor RabbitMQ project.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Reactor RabbitMQ
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our solution is fully reactive, so we need to use Reactor RabbitMQ, which allows us
    to interact with the RabbitMQ broker using the reactive paradigm.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: On this new microservice, we do not need to send messages through the message
    broker. Our solution will listen to the RabbitMQ queues and push the received
    Tweets for the connected clients.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the Reactor RabbitMQ
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Reactor RabbitMQ tries to provide a reactive library to interact with the
    RabbitMQ rboker. It enables developers to create non-blocking applications based
    on the reactive stream, using RabbitMQ as a message-broker solution.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: As we learned before, this kind of solution, in general, does not use a lot
    of memory. The project was based on the RabbitMQ Java client and has similar functionalities,
    if we compare it to the blocking solution.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所学的，这种解决方案通常不会占用很多内存。该项目基于RabbitMQ Java客户端，并且与阻塞解决方案具有相似的功能。
- en: We are not using the `spring-amqp-starter`, so the magic will not happen. We
    will need to code the beans declarations for the Spring context and we will do
    that in the following section.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有使用`spring-amqp-starter`，所以魔法不会发生。我们需要为Spring上下文编写bean声明，我们将在下一节中完成这项工作。
- en: Configuring RabbitMQ Reactor beans
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置RabbitMQ Reactor beans
- en: In this section, we will configure the RabbitMQ infrastructure classes in the
    Spring context. We will use a `@Configuration` class to declare it.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将配置Spring上下文中的RabbitMQ基础设施类。我们将使用一个`@Configuration`类来声明它。
- en: 'The configuration class should look like the following:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 配置类应该看起来像以下这样：
- en: '[PRE2]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: There are two important things here. The first one is that we configured the
    Jackson support for Kotlin. It allows us to inject the `ObjectMapper` into our
    Spring beans. The next important thing is related to the RabbitMQ connections'
    configuration.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两个重要的事情。第一个是我们为Kotlin配置了Jackson支持。它允许我们将`ObjectMapper`注入到我们的Spring beans中。下一个重要的事情与RabbitMQ连接的配置有关。
- en: We have declared a `ConnectionFactory` bean for the Spring Context. We injected
    the configurations with `@Value` annotations and received the values on the constructor.
    We can set the value directly in the attributes, in the Kotlin language; look
    at the `ConnectionFactory` attributes assignments.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为Spring上下文声明了一个`ConnectionFactory` bean。我们使用`@Value`注解注入配置，并在构造函数中接收这些值。在Kotlin语言中，我们可以直接在属性中设置值；看看`ConnectionFactory`属性分配。
- en: After the `ConnectionFactory` configuration, we are able to declare a receiver,
    which is a `Reactive` abstraction to consume the queues, using reactive programming.
    We receive the `ConnectionFactory` previously created and set it as the `ReceiverOptions`.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置`ConnectionFactory`之后，我们能够声明一个接收器，这是一个用于消费队列的`Reactive`抽象，使用响应式编程。我们接收之前创建的`ConnectionFactory`并将其设置为`ReceiverOptions`。
- en: That is all for the Reactor RabbitMQ configuration.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是Reactor RabbitMQ配置的全部内容。
- en: Consuming the RabbitMQ queues reactively
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 响应式地消费RabbitMQ队列
- en: Now, we will consume the RabbitMQ queues. The implementation is quite similar
    to what we have seen in the blocking implementation, and the names of the functions
    are similar as well.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将消费RabbitMQ队列。实现与我们在阻塞实现中看到的方法非常相似，函数的名称也相似。
- en: We have consumed some RabbitMQ messages in the previous chapters, but this solution
    is quite different. Now, we will use the Reactive RabbitMQ implementation. The
    main idea here is to consume the stream of events; these events represent the
    messages that have arrived in the broker. These messages arrive and the Reactor
    RabbitMQ converts these messages to Flux, to enable us to consume in the reactive
    paradigm.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在之前的章节中消费了一些RabbitMQ消息，但这个解决方案相当不同。现在，我们将使用响应式RabbitMQ实现。主要思想是消费事件流；这些事件代表到达代理的消息。这些消息到达，Reactor
    RabbitMQ将这些消息转换为`Flux`，以便我们能够在响应式范式下消费。
- en: In the reactive paradigm, the representation of a stream of events (we can think
    of messages in the queue), is the `Flux`.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在响应式范式下，事件流（我们可以将队列中的消息视为事件）的表示是`Flux`。
- en: Then our function, which is listening to the RabbitMQ, should return `Flux`,
    an infinite representation of events. The Receiver implementation returns the
    `Flux` of messages, which is enough for us and fits well with our needs.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们监听RabbitMQ的功能应该返回`Flux`，这是事件的无限表示。接收器实现返回消息的`Flux`，这对我们来说足够了，并且很好地符合我们的需求。
- en: 'Our implementation should look like the following:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实现应该看起来像以下这样：
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Let's understand a little bit more. We received the `Receiver` as an injection
    in our constructor. When someone invokes the `dispatch()` function, the `Receiver`
    will start to consume the queue, which was injected in the constructor as well.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地了解一下。我们在构造函数中接收了`Receiver`作为注入。当有人调用`dispatch()`函数时，`Receiver`将开始消费队列，这个队列也作为构造函数中的注入。
- en: The `Receiver` produces `Flux<Delivery>`. Now, we need to convert the instance
    of `Flux<Delivery>`, which represents a message abstraction,  to our domain model
    Tweet. The `flatMap()` function can do it for us, but first, we will convert the
    `message.body` to string and then we have used Jackson to read JSON and convert
    to our Tweet domain model.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Take a look at how simple the code is to read; the API is fluent and really
    readable.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: The consumer will not terminate until the connected client disconnects. We will
    be able to see this behavior soon.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Filtering streams
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are receiving the messages from RabbitMQ. Now, we need to return the messages
    to the connected customer.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: For that, we will use SSE with Spring WebFlux. The solution is a good fit for
    us because we will produce a `Flux<Tweet>` and start to push the Tweets for our
    clients. The clients will send a query to filter the desired Tweets.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: 'The application will be fully reactive. Let''s take a look at our code:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Pretty easy and simple to understand. We have declared the `tweets()` function;
    this function is mapped to a GET HTTP Request and produces a `MediaType.TEXT_EVENT_STREAM_VALUE`.
    When the client connects to the endpoint, the server will start to send Tweets
    accordingly with the desired argument.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: When the client disconnects, the Reactor RabbitMQ will close the requested RabbitMQ
    connection.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Dockerizing the whole solution
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, it is time to wrap the whole solution and create a Docker image for all
    projects. It is useful to run the projects anywhere we want.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: We will configure all the projects step by step and then run the solution in
    Docker containers. As a challenge, we can use `docker-compose` to orchestrate
    the whole solution in a single `yaml` file.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: For the Tracked Hashtag Service, we have created the docker image. Then, we
    will start to configure the Tweet Gathering, and the last one is Tweet Dispatcher.
    Let's do that right now.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: You can find more `docker-compose` project details at: [https://docs.docker.com/compose/](https://docs.docker.com/compose/).
    Also, in the new versions, `docker-compose` supports Docker Swarm to orchestrate
    the stack between cluster nodes. It can be really useful to deploy Docker containers
    in production.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Tweet Gathering
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's configure our `pom.xml` for the Tweet Gathering project.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: 'The build node should look like the following:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Take a look at the port configuration; it should be the same as what we have
    configured in the `application.yaml`. The configuration is done, so let''s create
    our Docker image:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The command output should look like the following screenshot:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/066d006d-c69c-43aa-a631-fca3b0b82cdc.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
- en: There is an image recently created and tagged as a latest; the image is ready
    to run. Let's do the same thing for our Tweet Dispatcher project.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Tweet Dispatcher
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our new plugin entry should look like this:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Take a look at the port configuration, one more time. It will be used by Docker
    to expose the correct port. Now, we can run the image creation command:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then, we can see the command''s output, as shown in the following screenshot:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8e56bd22-6248-48d4-8e60-d489613bec65.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
- en: Awesome, all images are ready. Let's run it.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: We need to create Docker images for all the projects. The process is the same;
    configure the maven Docker plugin and then use `mvn clean install docker:build`
    on the project. The full source code can be found at GitHub. The Tracked Hashtag
    Service can be found here ([https://github.com/PacktPublishing/Spring-5.0-By-Example/tree/master/Chapter04](https://github.com/PacktPublishing/Spring-5.0-By-Example/tree/master/Chapter04)),
    the Tweet Gathering can be found here ([https://github.com/PacktPublishing/Spring-5.0-By-Example/tree/master/Chapter05](https://github.com/PacktPublishing/Spring-5.0-By-Example/tree/master/Chapter05))
    and finally, the Tweet Dispatcher can be found here ([https://github.com/PacktPublishing/Spring-5.0-By-Example/tree/master/Chapter06](https://github.com/PacktPublishing/Spring-5.0-By-Example/tree/master/Chapter06)).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Running the containerized solution
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are ready to run the solution in Docker containers. We have been running
    the solution with the IDE or command line, but now we will spin up some container
    and test the solution and Spring profiles as well.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 'Before that, let''s do a quick recap of the solution:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/149f2c98-e8b7-409e-89db-dd70f590dd30.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
- en: The first operation, the **Tracked Hashtag Service**, will persist the hashtag
    in the **Redis** database.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After that, the **Tracked Hashtag Service** will send the newly tracked hashtag
    to a queue in the **RabbitMQ** Broker.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tweet Gathering** is listening to the queue to track Tweets and trigger the
    event and starts by listening to the **Twitter stream**.'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tweet Gathering** starts to get Tweets from the **Twitter stream.**'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tweet Gathering** publishes Tweets to a queue in the **RabbitMQ broker**.'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tweet Dispatcher** consumes the message.'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tweet Dispatcher** sends the message to the **Client** using SSE.'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we have understood the solution, let's starts the containers.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Running the Tracked Hashtag Service container
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The image has been created in the previous section, so now we are able to spin
    up the container. The command to start the container should look like this:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Let's explain the instruction. `-d` tells the Docker engine to run the container
    in background mode or detached.  The other important parameter is `--net`, which
    attaches the container to the desired network.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the following command to tail the container logs at runtime:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This command is like the `tail -f` command on Linux, which looks at the last
    part of the log stream. We can remove the flag `-f` to see the last lines of the
    log.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of docker logs should look like this:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4bb29b84-2014-4993-8b77-d956cc33554b.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
- en: 'Look at the profile selected, in the logs:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Remember, we have parameterized it in the `pom.xml` file from the Tracked Hash
    Tag Service. Let''s look at the following snippet:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Awesome job. Our first service is running properly. Let's run Tweet Gathering;
    there is some interesting configuration here.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 干得漂亮。我们的第一个服务正在正常运行。让我们运行Tweet Gathering；这里有一些有趣的配置。
- en: We have created the Twitter network in [chapter 4](4286f9d7-1fe5-49c7-9201-49f9c9bdddf6.xhtml), *Kotlin
    Basics and Spring Data Redis*, and we need to use this network to enable the containers
    to see each other by container name in our custom network.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第4章](4286f9d7-1fe5-49c7-9201-49f9c9bdddf6.xhtml)创建了Twitter网络，*Kotlin基础和Spring
    Data Redis*，我们需要使用这个网络来使容器能够通过容器名称在我们的自定义网络中相互看到。
- en: Running the Tweet Gathering container
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行Tweet Gathering容器
- en: 'To run the **Tweet Gathering** application is slightly different. This container
    needs environment variables which are used to interact with the Twitter API. We
    can use the `-e` argument on the `docker run` command. Let''s do that:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行**Tweet Gathering**应用程序略有不同。这个容器需要环境变量，这些变量用于与Twitter API交互。我们可以在`docker
    run`命令中使用`-e`参数。让我们这么做：
- en: '[PRE13]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Take a look at the environment variables we have configured in the `application.yaml`
    file. The Docker run command will inject these variables into the system and then
    we can use them in our Java application.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 查看我们在`application.yaml`文件中配置的环境变量。Docker运行命令会将这些变量注入到系统中，然后我们可以在Java应用程序中使用它们。
- en: 'Let''s inspect our container logs. We can do that using the following command:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查我们的容器日志。我们可以使用以下命令：
- en: '![](img/95db63ca-5835-4b1b-abf9-15be39543f26.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/95db63ca-5835-4b1b-abf9-15be39543f26.png)'
- en: Awesome, our application is up and running. As you can see, the application
    is connected to the RabbitMQ Broker.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了，我们的应用程序正在运行。如您所见，应用程序已连接到RabbitMQ代理。
- en: '**RabbitMQ** and **Redis** should be running to enable you to run Tweet Gathering.
    We can check it using the `docker ps` command; it will list the running containers,
    RabbitMQ and Redis need to be on this list.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**RabbitMQ**和**Redis**应该运行，以便您能够运行Tweet Gathering。我们可以使用`docker ps`命令来检查它；它将列出正在运行的容器，RabbitMQ和Redis需要在这个列表上。'
- en: Now, we can run the Dispatcher application to complete the whole solution. Let's
    do that.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以运行Dispatcher应用程序来完成整个解决方案。让我们这么做。
- en: Running the Tweet Dispatcher container
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行Tweet Dispatcher容器
- en: 'There is no secret to running the Tweet Dispatcher container. We can use the
    following command to run it:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 运行Tweet Dispatcher容器没有秘密。我们可以使用以下命令来运行它：
- en: '[PRE14]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'It will spin up the container, it is a good idea to name the container during
    the run. It can help us manage the container with command-line tools, such as `docker
    container ls` or `docker ps`, because it shows the container name in the last
    column. Then, let''s check if our container is running, so type the following
    command:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 它将启动容器，在运行过程中命名容器是个好主意。这可以帮助我们使用命令行工具（如`docker container ls`或`docker ps`）管理容器，因为它会在最后一列显示容器名称。然后，让我们检查我们的容器是否正在运行，所以输入以下命令：
- en: '[PRE15]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Or, you can run the following command:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您也可以运行以下命令：
- en: '[PRE16]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We should be able to see the Gathering container running, like in the following
    output:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该能够看到Gathering容器正在运行，如下所示：
- en: '![](img/b4171847-c894-4bc1-a929-c35cbd234983.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b4171847-c894-4bc1-a929-c35cbd234983.png)'
- en: There are five containers, three applications, and two infrastructure services, **RabbitMQ**
    and **Redis**.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 有五个容器，三个应用程序，以及两个基础设施服务，**RabbitMQ**和**Redis**。
- en: 'At any time, we can stop the desired container using the following command:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何时候，我们都可以使用以下命令停止所需的容器：
- en: '[PRE17]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `docker stop` will only stop the container; the information will be kept
    in the container volume. We can use the container name or container ID as well,
    we named it before. It is easy for us. If we use the `docker ps` command, the
    image recently stopped will never appear on the list. To show all the containers,
    we can use `docker ps -a` or `docker container ls -a`.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker stop`只会停止容器；信息将保留在容器卷中。我们也可以使用容器名称或容器ID，我们之前已经命名了。这对我们来说很容易。如果我们使用`docker
    ps`命令，最近停止的镜像永远不会出现在列表中。要显示所有容器，我们可以使用`docker ps -a`或`docker container ls -a`。'
- en: 'Now, we will start the container again; the command is self-explanatory:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将再次启动容器；命令是自解释的：
- en: '[PRE18]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The container is running again. We have practiced more with Docker.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 容器再次运行。我们已经在Docker上练习得更多了。
- en: Awesome job, guys. The whole application is containerized. Well done.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 伙计们，干得漂亮。整个应用程序已经容器化了。做得好。
- en: We can use the Linux instruction and execute some batch instructions. For instance,
    we can use `docker stop $(docker ps -q)` — it will stop all containers running.
    The `docker ps -q` command will bring only the container's IDs.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: The docker-compose tool
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the microservices architectural style, the whole solution is decoupled in
    small and well-defined services. Usually, when we adopt these styles, we have
    more than one artifact to deploy.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Let's analyze our solution; we have three components to deploy. We have used
    the Docker containers and we have run these containers using the `docker run`
    command. One by one, we have used `docker run` three times. It is quite complex
    and very hard to do in the development routine.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '`docker-compose` can help us in this scenario. It is a tool which helps to
    orchestrate Docker containers in complex scenarios like ours.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Let's imagine our application is growing fast and we need to build four more
    microservices to achieve the desired business case, it will implicate on four
    more `docker run` commands and will probably be painful to maintain, especially
    during the development life cycle. Sometimes, we need to promote the artifacts
    to test the environment and we probably need to modify our command line to achieve
    this.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '`docker-compose` enables us to deploy multiple containers with a single `yaml`
    file. This `yaml` file has a defined structure which allows us to define and configure
    several containers in the same file. Moreover, we can run the solution configured
    in this `yaml` file with a single command, it makes development life easy.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: The tool can work on the local machine or we can integrate it with the Docker
    Swarm tool which can manage clusters of Docker hosts.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Docker Swarm is a native tool to manage docker clusters. It makes it easy to
    deploy a container on the Docker cluster. In the new version, `docker-compose`
    is fully integrated with Docker Swarm. We can define it from Docker Swarm properties
    in `docker-compose.yaml`. The Docker Swarm documentation can be found at: [https://docs.docker.com/engine/swarm/](https://docs.docker.com/engine/swarm/).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: 'The `docker-compose` `yaml` has a defined structure to follow; the documentation
    can be found here: [https://docs.docker.com/compose/compose-file/#compose-and-docker-compatibility-matrix.](https://docs.docker.com/compose/compose-file/#compose-and-docker-compatibility-matrix) We
    will create a simple file to understand the `docker-compose` behaviors. Let''s
    create our simple `yaml`— the `yaml` should look like this:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The `yaml` in the preceding code will create the structure detailed in the
    following diagram:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6aaa3300-e91e-4e0e-b96a-00849ed0f940.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
- en: It simplifies the development time. Now, we will learn how to install `docker-compose`.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Installing docker-compose
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `docker-compose` installation is pretty simple and well-documented. We are
    using Linux, so we will use the Linux instructions.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the terminal and use the following command:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Wait for the download and then we can execute the following instructions to
    give executable permissions for the program. Let''s do this by executing the following
    command:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'As you may know, you may be asked for the administrator password. Our `docker-compose`
    is now installed. Let''s check it:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The prompt will display the installed version, like the following screenshot:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/777e6b4a-0f3e-400b-9859-eb04c5b5172b.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
- en: '`docker-compose` is up and running, so let''s jump to the next section and
    start to create our `yaml` file and deploy the whole stack with one single command.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: For different operating systems, the instructions can be found here: [https://docs.docker.com/compose/install/#install-compose](https://docs.docker.com/compose/install/#install-compose).
    Then, you can navigate around the instructions and click on the desired operating
    system.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Creating a docker-compose file
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we have `docker-compose` installed and we can try to work with the tool.
    We want to run the whole stack with a single command. We will create the `yaml`
    file to represent the stack. Our `yaml` file should have the Redis container,
    the RabbitMQ container, the Tracked Hashtag application, the Gathering application,
    and finally, the Dispatcher application.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: We can create a `docker-compose.yaml` file wherever we want, there is no restriction
    for that.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'Our `docker-compose.yaml` file should look like the following:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: As you can see, we have defined the whole stack in the `yaml`. Something to
    note is that we can find some similarities with the `docker run` command, in fact,
    it will use the Docker engine to run. The `environment` node in yaml has the same
    behavior as `-e` in the Docker run command.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: We have defined the application ports, docker images, and have also connected
    the containers to the same network. This is really important because when we use
    the `docker-compose` file name on the network, it can find that the container
    name has a kind of DNS behavior.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: For instance, inside the defined network `solution`, the container can find
    the Redis container instance by the name `redis`.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: Running the solution
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`docker-compose` simplifies the process to run the whole stack. Our `yaml`
    file was configured and defined properly.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start the solution. Run the following command:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The command is pretty simple, the `-d` parameter instructs Docker to run the
    command in the background. As we did on the Docker run command.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of this command should be the following:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c8203e6b-2c71-488d-973b-8a4117d43d28.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
- en: Take a look, `docker-compose` has created a network for our stack. In our case,
    the network driver is a bridge, after the network creation, the containers are
    started.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Testing the network
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's test it, find the Gathering container – the container name in `docker-compose`
    is prefixed by the folder name, where `docker-compose` was started.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: For instance, I have started my `docker-compose` stack in the compose folder.
    My container name will be `compose_gathering_1` because of the folder name.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we will connect the Gathering container. It can be achieved using the
    following command:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The `docker exec` command allows us to execute something inside the container.
    In our case, we will execute the `/bin/bash` program.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: 'The command structure is like this:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Awesome, pay attention to the command line. It should be changed because now
    we are in the container command line:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f34083e9-fde1-47af-af2a-945b3d067aa3.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
- en: We are not connected as a root on our host, but now we are a root on the container.
    This container is on the same network as the Redis container instance, which is
    called `redis`.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s test with the `ping` command; we should be able to find the `redis`
    container by the name `redis`, let''s do it. Type the following:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The command output should be the following:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/150fa99d-cf12-40d7-9162-a7eb0e640f09.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
- en: Awesome, our container can find the Redis container by the name. The `yaml`
    file is fully working.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we completed our second solution. We were introduced to the
    RabbitMQ Reactor library, which enables us to connect to RabbitMQ, using the reactive
    paradigm.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: We have prepared the whole solution in Docker containers and connected it to
    the same network to enable the applications to talk to each other.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: We also learned the important pattern for pushing data from server to client
    through the HTTP persistent connection, and we learned the difference between
    WebSockets and Server-Sent Events, as well.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we learned how `docker-compose` helps us to create the stack and run
    the whole solution with a couple of commands.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapters, we will build a fully microservice solution, using
    some important patterns such as Service Discovery, API Gateway, Circuit Breakers,
    and much more.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
