- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Concurrency Strategies and Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Today’s computing world consists of distributed systems, cloud-based architectures,
    and hardware accelerated by multi-core processors. These characteristics necessitate
    concurrency strategies. This chapter provides foundational information on concurrency
    concepts and provides hands-on opportunities to implement concurrency in Java
    programs. The underlying goal is to harness the benefits and advantages of concurrency
    to improve the performance of our Java applications.
  prefs: []
  type: TYPE_NORMAL
- en: The chapter starts with a review of different concurrency models and their practical
    uses. Concepts include the thread-based memory model and the message-passing model.
    Then, we will explore multithreading from both a theoretical perspective and a
    hands-on practical aspect. The thread life cycle, thread pools, and other related
    topics will be covered. Synchronization will also be covered to include how to
    ensure thread safety and strategies to avoid common pitfalls. Finally, the chapter
    introduces non-blocking algorithms, an advanced concurrency strategy, to improve
    application performance through atomic variables and specific data structures.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multithreading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synchronization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-blocking algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you should have a thorough understanding of concurrency
    and related strategies and models. You should be prepared to implement concurrency
    in your Java applications, ensuring they perform at a high level.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To follow the examples and instructions in this chapter, you will need the ability
    to load, edit, and run Java code. If you have not set up your development environment,
    refer to [*Chapter 1*](B21942_01.xhtml#_idTextAnchor014).
  prefs: []
  type: TYPE_NORMAL
- en: 'The finished code for this chapter can be found here: [https://github.com/PacktPublishing/High-Performance-with-Java/tree/main/Chapter09](https://github.com/PacktPublishing/High-Performance-with-Java/tree/main/Chapter09).'
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most exciting aspects of the Java programming language is its robustness.
    When addressing parallel execution challenges, Java supports multiple models,
    so the approach we take is up to us. Usually, there is not just one way of doing
    things, with each possible solution presenting both advantages and trade-offs.
    Our goal is to create Java applications that run efficiently and are scalable
    and maintainable. To that end, we will use the thread-based concurrency approach
    (detailed later in this chapter). Our selection is based on its straightforward
    nature.
  prefs: []
  type: TYPE_NORMAL
- en: '**Concurrency**, in the context of computer science, is the simultaneous execution
    of instructions. This is achieved through multithreading (think of multitasking).
    This programming paradigm includes the ability to access Java objects and other
    resources from multiple threads. Let’s look at three specific models (thread-based,
    message passing, and reactive) and then compare them to see which model might
    be more ideal, given a specific scenario, than others.'
  prefs: []
  type: TYPE_NORMAL
- en: Thread-based model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `Thread` class and `Callable` and `Runnable` interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at a simple implementation example. We will implement the `increment`
    method and mark it with the `synchronized` keyword. This tells Java to only execute
    one thread at any given time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This next section of code contains our `main()` method. In this method, we
    create two threads; both will increment our counter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The next two lines of code start the threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next two lines of code, we wait for both threads to finish:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we output the final results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The straightforward nature of thread-based model implementation represents a
    tremendous advantage. This approach is typical for smaller applications. There
    are potential disadvantages to using this model, as **deadlocks** and **race conditions**
    can be introduced when multiple threads attempt to access shared, mutable data.
  prefs: []
  type: TYPE_NORMAL
- en: Deadlocks and race conditions
  prefs: []
  type: TYPE_NORMAL
- en: Deadlocks occur when two threads wait for the other to release a needed resource.
    Race conditions occur when the sequence of the thread execution is required.
  prefs: []
  type: TYPE_NORMAL
- en: Both deadlocks and race conditions should be avoided as much as possible in
    our applications.
  prefs: []
  type: TYPE_NORMAL
- en: The message passing model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **message passing model** is an interesting one in that it avoids **shared
    states**. This model requires threads to intercommunicate by sending messages.
  prefs: []
  type: TYPE_NORMAL
- en: Shared states
  prefs: []
  type: TYPE_NORMAL
- en: A shared state exists when more than one thread in an application can simultaneously
    access data.
  prefs: []
  type: TYPE_NORMAL
- en: The message passing model offers assurances against deadlocks and race conditions.
    A benefit of this model is that it promotes scalability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at how we can implement the message passing model. Our example includes
    a simple sender and receiver scenario. We start with our `import` statements and
    then create a `Message` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will have our `Sender` class implement the `Runnable` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will have our `Receiver` class implement the `Runnable` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The last step is to create our `main()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Our example implemented `Sender` and `Receiver` as `Runnable` classes. They
    communicated using `BlockingQueue`. The queue is used for `Sender` to add messages
    and `Receiver` to take and process them. `Sender` sends `Done` to the queue so
    that `Receiver` knows when it can stop processing. The message passing model is
    often used in distributed systems, due to its support of highly scalable systems.
  prefs: []
  type: TYPE_NORMAL
- en: The Reactive model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **Reactive model** is newer than the last two models we covered. Its focus
    is on **non-blocking**, **event-driven programming**. This model is usually evident
    in large-scale systems that process extensive input/output operations, especially
    when high scalability is needed. There are external libraries that we can use
    to implement this model, including **Project Reactor** and **RxJava**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at a simple implementation example using **Project Reactor**. We
    start by adding the Project Reactor **dependency** to our project. Here is how
    that looks using **Maven** as the build tool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The following example demonstrates how to create a reactive stream to process
    a sequence of events:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The Reactive model offers efficient resource use, blocking operation avoidance,
    and a unique approach to asynchronous programming. However, it can be more difficult
    to implement compared to the other models we covered.
  prefs: []
  type: TYPE_NORMAL
- en: Comparative analysis
  prefs: []
  type: TYPE_NORMAL
- en: Each of the three concurrency models offers different benefits, and understanding
    their individuality and differences can help you make an informed decision regarding
    which model to adopt.
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Multithreading** is simply the **synchronous execution**, or **concurrent
    execution**, of two or more parts of a program, and it is a fundamental aspect
    of Java’s concurrent programming mechanism. We execute multiple parts of our programs,
    taking advantage of multi-core **Central Processing Unit** (**CPU**) resources
    to optimize the performance of our applications.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we get too far into multithreads, let’s focus on a single `Thread` class
    to create and start threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The next code snippet demonstrates how to implement the `Runnable` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Now that you understand how easy it is to create and start threads, let’s examine
    their life cycles.
  prefs: []
  type: TYPE_NORMAL
- en: Thread life cycles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Java threads have a definitive start and end state. They have additional states,
    as indicated in the following diagram.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – A Java thread life cycle](img/B21942_09_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – A Java thread life cycle
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important to understand each of these states so that we can effectively
    manage our threads. Let’s briefly look at each state within the Java thread life
    cycle:'
  prefs: []
  type: TYPE_NORMAL
- en: '**New**: Threads have this state when we create them but have not started them.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Runnable**: This state exists when a thread is being executed. Threads that
    have started and are waiting for CPU time also have this state.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Blocked**: A thread is blocked from accessing a resource.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Waiting/Timed Waiting**: Threads can wait on other threads. Sometimes, there
    can be a specific waiting time, while at other times, the wait might be indefinite.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Terminated**: A thread has this state after execution completes.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is important to understand these states, especially with applications that
    rely on thread communication and synchronization.
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading best practices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When working with multithreading, there are a few things we should keep in mind
    to ensure that our application performs as expected and that our threads are safe.
  prefs: []
  type: TYPE_NORMAL
- en: First, we want to ensure that each resource is only accessed by one thread at
    a time, using `java.util.concurrent` package, which includes concurrent data structures
    and methods we can use for synchronization. Utilizing this package can help us
    implement thread safety.
  prefs: []
  type: TYPE_NORMAL
- en: 'Java’s `Object` class includes the `wait()`, `notify()`, and `notifyAll()`
    methods, which can be used to empower Java threads to communicate with each other.
    The following example application demonstrates how those methods can be used.
    Our example contains a `Producer` thread that creates a value for consumption
    by a `Consumer` thread. We do not want both operations to take place at the same
    time; in fact, we want `Consumer` to wait for `Producer` to create the value.
    Further, `Producer` must wait for `Consumer` to receive the last value before
    creating a new one. The first section defines our `WaitNotifyExample` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to create our `Consumer` class and implement the `Runnable` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The last part of our application is the `main()` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Our application’s output is provided here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: When we adhere to the best practices provided in this section, we increase the
    chances of having efficient multithreading, contributing to a high-performing
    Java application.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Synchronization** is another critical Java concept that we should grasp as
    we seek to fully understand concurrency. As we indicated earlier, we employ synchronization
    to avoid **race conditions**.'
  prefs: []
  type: TYPE_NORMAL
- en: Race conditions
  prefs: []
  type: TYPE_NORMAL
- en: The condition when multiple threads attempt to modify a shared resource at the
    same time. The results of this situation are unpredictable and should be avoided.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at how we can implement synchronization in our Java applications
    by looking at several code snippets. First, we demonstrated adding the `synchronized`
    keyword to a method’s declaration. This is how we can ensure that only one thread
    at a time can execute the method on a specific object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also implement **synchronized blocks**, which are a subset of a method.
    This level of granularity allows us to synchronize a block without having to lock
    out the entire method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Java also includes a `Lock` interface that can be used for a more refined approach
    to locking resources. Here’s how we can implement it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Java also includes the `volatile` keyword, which we can use to tell Java that
    a specific variable is subject to modification by multiple threads. When we declare
    our variables with this keyword, Java places the variable’s value in a memory
    location accessible by all threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: As you undoubtedly will come to understand, synchronization is key for successful
    concurrency programming in Java.
  prefs: []
  type: TYPE_NORMAL
- en: Non-blocking algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a final concept of concurrent programming, let’s look at `synchronized` methods
    and synchronized blocks. There are three types of non-blocking algorithms – **lock-free**,
    **wait-free**, and **obstruction-free**. Although their names are self-describing,
    let’s take a closer look.
  prefs: []
  type: TYPE_NORMAL
- en: Modern CPUs support atomic operations, and Java includes several atomic classes
    that we can use when implementing non-blocking algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Atomic operations
  prefs: []
  type: TYPE_NORMAL
- en: These are operations that are executed by modern CPUs as a single, finite step
    that ensures consistency without the need for locks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a code snippet that illustrates how to use `AtomicInteger`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The following example demonstrates how to implement a non-blocking stack. As
    you will see, our stack uses atomic references, which ensures thread safety:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We can gain performance advantages when we use non-blocking algorithms, especially
    when our application deals with high concurrency. The advantages are counterbalanced
    by code complexity, which can result in errors and code that is more difficult
    to maintain.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter focused on concurrency strategies and models, with the goal of
    providing insights into the concept of concurrency, the different models and strategies,
    and some implementation examples. We explored theoretical concepts and practical
    examples. The concepts covered included concurrency models, synchronization, and
    non-blocking algorithms. You should now have sufficient knowledge to start experimenting
    with code.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore connection pooling with a specific look
    at concepts, implementation, and best practices. You will have the opportunity
    to learn how to create and maintain a cache of database connection objects to
    help increase the performance of your Java applications.
  prefs: []
  type: TYPE_NORMAL
