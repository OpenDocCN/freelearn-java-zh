["```java\n <downloadPath>/zeppelin-0.8.0-bin-all/bin/zeppelin-daemon.sh start\n```", "```java\n<downloadPath>/zeppelin-0.8.0-bin-all/bin/zepplin.cmd start\n```", "```java\nval dsString = Seq(\"1\", \"2\", \"3\").toDS()\ndsString.show()\n```", "```java\nspark.version\n```", "```java\ncase class Demo(id: String, data: Int)\nval data = List(\n   Demo(\"a\",1),\n   Demo(\"a\",2),\n   Demo(\"b\",8),\n   Demo(\"c\",4))\nval dataDS = data.toDS()\ndataDS.createOrReplaceTempView(\"demoView\")\n```", "```java\n%sql\nselect * from demoView\n```", "```java\nval transactions = spark.read.parquet(\"<rootProjectPath>/Scala-Programming-Projects/bitcoin-analyser/data/transactions\")\nz.show(transactions.sort($\"timestamp\"))\n```", "```java\nval group = transactions.groupBy(window($\"timestamp\", \"20 minutes\"))\n\nval tmpAgg = group.agg(\n  count(\"tid\").as(\"count\"), \n  avg(\"price\").as(\"avgPrice\"),\n  stddev(\"price\").as(\"stddevPrice\"),\n  last(\"price\").as(\"lastPrice\"),\n  sum(\"amount\").as(\"sumAmount\"))\n\nval aggregate = tmpAgg.select(\"window.start\", \"count\", \"avgPrice\", \"lastPrice\", \"stddevPrice\", \"sumAmount\").sort(\"start\").cache()\n\nz.show(aggregate)\n```", "```java\ngroup: org.apache.spark.sql.RelationalGroupedDataset = RelationalGroupedDataset: [grouping expressions: [window: struct<start: timestamp, end: timestamp>], value: [timestamp: timestamp, tid: int ... 4 more fields], type: GroupBy] \n\ntmpAgg: org.apache.spark.sql.DataFrame = [window: struct<start: timestamp, end: timestamp>, count: bigint ... 4 more fields] \n\naggregate: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [start: timestamp, count: bigint ... 4 more fields]\n```", "```java\n%spark\nz.show(aggregate)\n```", "```java\nimport com.pusher.client.Pusher\nimport com.pusher.client.channel.SubscriptionEventListener\n\nval pusher = new Pusher(\"de504dc5763aeef9ff52\")\npusher.connect()\nval channel = pusher.subscribe(\"live_trades\")\n\nchannel.bind(\"trade\", new SubscriptionEventListener() {\n  override def onEvent(channel: String, event: String, data: String): \n    Unit = {\n      println(s\"Received event: $event with data: $data\")\n  }\n})\n```", "```java\nReceived event: trade with data: {\"amount\": 0.001, \"buy_order_id\": 2165113017, \"sell_order_id\": 2165112803, \"amount_str\": \"0.00100000\", \"price_str\": \"6433.53\", \"timestamp\": \"1537390248\", \"price\": 6433.5299999999997, \"type\": 0, \"id\": 74263342}\nReceived event: trade with data: {\"amount\": 0.0089460000000000008, \"buy_order_id\": 2165113493, \"sell_order_id\": 2165113459, \"amount_str\": \"0.00894600\", \"price_str\": \"6433.42\", \"timestamp\": \"1537390255\", \"price\": 6433.4200000000001, \"type\": 0, \"id\": 74263344}\n(...)\n```", "```java\npackage coinyser\n\nimport java.sql.Timestamp\nimport java.text.SimpleDateFormat\nimport java.util.TimeZone\n\nimport cats.effect.IO\nimport com.fasterxml.jackson.databind.ObjectMapper\nimport com.fasterxml.jackson.module.scala.DefaultScalaModule\nimport com.pusher.client.Client\nimport com.pusher.client.channel.SubscriptionEventListener\nimport com.typesafe.scalalogging.StrictLogging\n\nobject StreamingProducer extends StrictLogging {\n\n  def subscribe(pusher: Client)(onTradeReceived: String => Unit):   \n   IO[Unit] =\n      for {\n        _ <- IO(pusher.connect())\n        channel <- IO(pusher.subscribe(\"live_trades\"))\n\n        _ <- IO(channel.bind(\"trade\", new SubscriptionEventListener() {\n          override def onEvent(channel: String, event: String, data: \n            String): Unit = {\n              logger.info(s\"Received event: $event with data: $data\")\n                onTradeReceived(data)\n           }\n         }))\n      } yield ()\n}\n```", "```java\npackage coinyser\n\ncase class WebsocketTransaction(amount: Double,\n                                buy_order_id: Long,\n                                sell_order_id: Long,\n                                amount_str: String,\n                                price_str: String,\n                                timestamp: String,\n                                price: Double,\n                                `type`: Int,\n                                id: Int)\n```", "```java\npackage coinyser\n\nimport java.sql.Timestamp\nimport coinyser.StreamingProducerSpec._\nimport org.scalactic.TypeCheckedTripleEquals\nimport org.scalatest.{Matchers, WordSpec}\n\nclass StreamingProducerSpec extends WordSpec with Matchers with TypeCheckedTripleEquals {\n  \"StreamingProducer.deserializeWebsocketTransaction\" should {\n    \"deserialize a valid String to a WebsocketTransaction\" in {\n      val str =\n        \"\"\"{\"amount\": 0.045318270000000001, \"buy_order_id\": 1969499130,\n          |\"sell_order_id\": 1969495276, \"amount_str\": \"0.04531827\",\n          |\"price_str\": \"6339.73\", \"timestamp\": \"1533797395\",\n          |\"price\": 6339.7299999999996, \"type\": 0, \"id\": \n          71826763}\"\"\".stripMargin\n      StreamingProducer.deserializeWebsocketTransaction(str) should\n        ===(SampleWebsocketTransaction)\n    }\n  }\n}\n\nobject StreamingProducerSpec {\n  val SampleWebsocketTransaction = WebsocketTransaction(\n    amount = 0.04531827, buy_order_id = 1969499130, sell_order_id = \n    1969495276, amount_str = \"0.04531827\", price_str = \"6339.73\",     \n    timestamp = \"1533797395\", price = 6339.73, `type` = 0, id =     \n    71826763)\n}\n```", "```java\npackage coinyser\n\nimport java.sql.Timestamp\nimport java.text.SimpleDateFormat\nimport java.util.TimeZone\n\nimport cats.effect.IO\nimport com.fasterxml.jackson.databind.ObjectMapper\nimport com.fasterxml.jackson.module.scala.DefaultScalaModule\nimport com.pusher.client.Client\nimport com.pusher.client.channel.SubscriptionEventListener\nimport com.typesafe.scalalogging.StrictLogging\n\nobject StreamingProducer extends StrictLogging {\n\n  def subscribe(pusher: Client)(onTradeReceived: String => Unit): \n  IO[Unit] =\n    ...\n\n  val mapper: ObjectMapper = {\n    val m = new ObjectMapper()\n    m.registerModule(DefaultScalaModule)\n    val sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\")\n    sdf.setTimeZone(TimeZone.getTimeZone(\"UTC\"))\n    m.setDateFormat(sdf)\n  }\n\n  def deserializeWebsocketTransaction(s: String): WebsocketTransaction \n   = {\n        mapper.readValue(s, classOf[WebsocketTransaction])\n  }\n}\n```", "```java\nclass StreamingProducerSpec extends WordSpec with Matchers with TypeCheckedTripleEquals {\n\n  \"StreamingProducer.deserializeWebsocketTransaction\" should {...}\n\n  \"StreamingProducer.convertTransaction\" should {\n    \"convert a WebSocketTransaction to a Transaction\" in {  \n      StreamingProducer.convertWsTransaction\n      (SampleWebsocketTransaction) should\n        ===(SampleTransaction)\n    }\n  }\n\n  \"StreamingProducer.serializeTransaction\" should {\n    \"serialize a Transaction to a String\" in {\n      StreamingProducer.serializeTransaction(SampleTransaction) should\n        ===(SampleJsonTransaction)\n    }\n  }\n}\n\nobject StreamingProducerSpec {\n  val SampleWebsocketTransaction = WebsocketTransaction(...)\n\n  val SampleTransaction = Transaction(\n    timestamp = new Timestamp(1533797395000L), tid = 71826763,\n    price = 6339.73, sell = false, amount = 0.04531827)\n\n  val SampleJsonTransaction =\n    \"\"\"{\"timestamp\":\"2018-08-09 06:49:55\",\n      |\"date\":\"2018-08-09\",\"tid\":71826763,\"price\":6339.73,\"sell\":false,\n      |\"amount\":0.04531827}\"\"\".stripMargin\n}\n```", "```java\nobject StreamingProducer extends StrictLogging {\n\n  def subscribe(pusher: Client)(onTradeReceived: String => Unit): \n    IO[Unit] = ...\n\n  val mapper: ObjectMapper = {...}\n\n  def deserializeWebsocketTransaction(s: String): WebsocketTransaction \n   = {...}\n\n  def convertWsTransaction(wsTx: WebsocketTransaction): Transaction =\n    Transaction(\n      timestamp = new Timestamp(wsTx.timestamp.toLong * 1000), tid = \n        wsTx.id, price = wsTx.price, sell = wsTx.`type` == 1, amount = \n        wsTx.amount)\n\n  def serializeTransaction(tx: Transaction): String = \n    mapper.writeValueAsString(tx)\n}\n```", "```java\npackage coinyser\n\nimport cats.effect.{ExitCode, IO, IOApp}\nimport com.pusher.client.Pusher\nimport StreamingProducer._\nimport org.apache.kafka.clients.producer.{KafkaProducer, ProducerRecord}\nimport scala.collection.JavaConversions._\n\nobject StreamingProducerApp extends IOApp {\n  val topic = \"transactions\"\n\n  val pusher = new Pusher(\"de504dc5763aeef9ff52\")\n\n  val props = Map(\n    \"bootstrap.servers\" -> \"localhost:9092\",\n    \"key.serializer\" -> \n    \"org.apache.kafka.common.serialization.IntegerSerializer\",\n    \"value.serializer\" -> \n    \"org.apache.kafka.common.serialization.StringSerializer\")\n\n  def run(args: List[String]): IO[ExitCode] = {\n    val kafkaProducer = new KafkaProducer[Int, String](props)\n\n    subscribe(pusher) { wsTx =>\n      val tx = convertWsTransaction(deserializeWebsocket\n      Transaction(wsTx))\n      val jsonTx = serializeTransaction(tx)\n      kafkaProducer.send(new ProducerRecord(topic, tx.tid, jsonTx))\n    }.flatMap(_ => IO.never)\n  }\n}\n```", "```java\ncd kafka_2.11-1.1.1\nbin/zookeeper-server-start.sh config/zookeeper.properties\n```", "```java\ncd kafka_2.11-1.1.1\nbin/kafka-server-start.sh config/server.properties\n```", "```java\ncd kafka_2.11-1.1.1\nbin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic transactions â€“from-beginning\n```", "```java\n18/09/22 17:30:41 INFO StreamingProducer$: Received event: trade with data: {\"amount\": 0.019958119999999999, \"buy_order_id\": 2180038294, \"sell_order_id\": 2180031836, \"amount_str\": \"0.01995812\", \"price_str\": \"6673.66\", \"timestamp\": \"1537633840\", \"price\": 6673.6599999999999, \"type\": 0, \"id\": 74611373}\n```", "```java\n{\"timestamp\":\"2018-09-22 16:30:40\",\"date\":\"2018-09-22\",\"tid\":74611373,\"price\":6673.66,\"sell\":false,\"amount\":0.01995812}\n```", "```java\ncase class Transaction(timestamp: java.sql.Timestamp,\n                       date: String,\n                       tid: Int,\n                       price: Double,\n                       sell: Boolean,\n                       amount: Double)\nval schema = Seq.empty[Transaction].toDS().schema\n```", "```java\nval dfStream = {\n  spark.readStream.format(\"kafka\")\n  .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n  .option(\"startingoffsets\", \"latest\")\n  .option(\"subscribe\", \"transactions\")\n  .load()\n  .select(\n    from_json(col(\"value\").cast(\"string\"), schema)\n      .alias(\"v\")).select(\"v.*\").as[Transaction]\n}\n```", "```java\ndfStream: org.apache.spark.sql.DataFrame = [timestamp: timestamp, date: string ... 4 more fields]\n```", "```java\nz.show(dfStream)\n```", "```java\njava.lang.RuntimeException: java.lang.reflect.InvocationTargetException at org.apache.zeppelin.spark.SparkZeppelinContext.showData(SparkZeppelinContext.java:112) at org.apache.zeppelin.interpreter.BaseZeppelinContext.show(BaseZeppelinContext.java:238) at org.apache.zeppelin.interpreter.BaseZeppelinContext.show(BaseZeppelinContext.java:224) ... 52 elided Caused by: java.lang.reflect.InvocationTargetException: org.apache.spark.sql.AnalysisException: Queries with streaming sources must be executed with writeStream.start();;\n```", "```java\nval query = {\n  dfStream\n    .writeStream\n    .format(\"memory\")        \n    .queryName(\"transactionsStream\")\n    .outputMode(\"append\")\n    .start()\n}\n```", "```java\nquery: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@3d9dc86a\n```", "```java\nz.show(spark.table(\"transactionsStream\").sort(\"timestamp\"))\n```", "```java\nval aggDfStream = { \n  dfStream\n    .withWatermark(\"timestamp\", \"1 second\")\n    .groupBy(window($\"timestamp\", \"10 seconds\").as(\"window\"))\n    .agg(\n      count($\"tid\").as(\"count\"), \n      avg(\"price\").as(\"avgPrice\"),\n      stddev(\"price\").as(\"stddevPrice\"),\n      last(\"price\").as(\"lastPrice\"),\n      sum(\"amount\").as(\"sumAmount\")\n    )\n    .select(\"window.start\", \"count\", \"avgPrice\", \"lastPrice\", \n    \"stddevPrice\", \"sumAmount\")\n}\n```", "```java\nval aggQuery = {\n  aggDfStream\n    .writeStream\n    .format(\"memory\")\n    .queryName(\"aggregateStream\")\n    .outputMode(\"append\")\n    .start()\n}\n```", "```java\nz.show(spark.table(\"aggregateStream\").sort(\"start\")\n```"]