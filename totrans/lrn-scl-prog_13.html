<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Basics of Akka Streams</h1>
                </header>
            
            <article>
                
<p class="p1">In this chapter, we’ll take a closer look at Akka Streams. We will start with a basic description of streams in general, and Reactive Streams in particular. We'll touch on the concept of back pressure and provide some motivation for you to use Akka Streams as a concrete implementation of the<span> Reactive Streams standard</span>. We'll reimplement our bakery yet again, this time using streams as a design abstraction. This will allow us to examine in detail the basics of Akka Streams, such as flows and graphs, error handling, and testing.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>Reactive Streams</li>
<li>Back pressure</li>
<li>Akka Streams philosophy</li>
<li>Akka Streams essential concepts</li>
<li>Sources and sinks</li>
<li>Flows</li>
<li>Graphs</li>
<li>Logging</li>
<li>Materialization</li>
<li>Failure handling</li>
<li>Testing</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<ul>
<li>Installed Scala</li>
<li>Installed SBT</li>
</ul>
<p>Source code for this chapter is available on <span>GitHub</span><span>: <a href="https://github.com/PacktPublishing/Learn-Scala-Programming/tree/master/Chapter13">https://github.com/PacktPublishing/Learn-Scala-Programming/tree/master/Chapter13</a>.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Introduction to Akka Streams</h1>
                </header>
            
            <article>
                
<p>The word <em>stream</em> is vastly overloaded in meaning in modern computing. It carries many different meanings depending on the context. For instance, in Java, in different times streaming meant an abstraction over blocking IO, non-blocking IO, and later, a way to express data processing queries.</p>
<p>In essence, a stream in computing is just a flow of data or instructions. Usually, the content of a stream is not loaded into memory fully. This possibility to process basically unlimited amounts of information on devices with limited memory capacity is a motivating factor for the rise of streams, popularity that has been happening recently.</p>
<p>The definition of the stream as a flow implies that it should have some source and a destination of data elements. In computing, these concepts are naturally expressed in the code in a way that on one side of the flow the code emits data and on another side other code consumes this data. The emitting side is usually called the <strong>producer</strong> and the receiving side is respectively a <strong>consumer</strong>. Usually, there will be a portion of data in the memory which was already issued by the producer but not yet ingested by the consumer. </p>
<p>This aspect of the stream brings up the next idea: it should be possible to manipulate data in-flight by code in-between, the same way a water heater is plugged in between the inlet and a water tap and <em>changes</em> cold water into hot water. Interestingly, the presence of a water heater in this scenario is not known to the producer or to the consumer. If the scenario is that the water flow increases in intensity, we could easily imagine having another heater plugged in or replacing the existing one with a more powerful model. The water heater becomes the property of the flow in the sense that the quantity of the water received by the consumer depends on the amounts emitted by the producer, but the temperature depends on properties of the pipe system, or in essence, of the flow.</p>
<p>This is the basic idea behind using streams: a stream is usually seen as a combination of producer, consumer, and transformation steps in between. In a streaming scenario, the producer and consumer become less interesting and the main focus shifts to the transformation steps in the middle. For the sake of modularity and code reuse, defining many tiny transformations is usually considered to be a preferable approach.</p>
<p>Depending on the art of transferring data between the parts of the stream, we distinguish between pushing and pulling elements of the stream.</p>
<p>With the push, it is the producer who controls the process. The data is pushed to the stream as soon as it becomes available and the rest of the stream is supposed to be able to absorb it. Naturally, it is not always possible to consume data which is produced at an unpredictable rate. In the case of streaming, it is dealt with by dropping data or using buffers. Dropping data is sometimes appropriate but more often is undesired. Buffers have limited size and thus can become full if data is produced faster than it is consumed for a long period of time. A full buffer yet again leads to memory overflow or the need to drop data. Visibly, with the push model, a combination of a fast producer and a slow consumer is a problem.</p>
<p>With the pull model, it is the consumer who drives the process. It tries to read the data from the stream as soon as it needs it. If there is some data, it is taken. If there is no data, the consumer has a choice between waiting for it or trying again at a later moment. Usually, both possibilities are less than ideal. Waiting for the data is usually done by blocking and polling data, which means excessive consumption of resources and delays between the moment the data becomes available and its consumption. Evidently, the pull model is not optimal in the case of a slow producer and fast consumer.</p>
<p>This dichotomy led to the creation of the dynamic pull-push concept named Reactive Streams and an initiative of the same name in 2013 by engineers <span>at Lightbend, Netflix, and Pivotal.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Reactive Streams and backpressure</h1>
                </header>
            
            <article>
                
<p><span>Reactive Streams (<a href="http://www.reactive-streams.org">http://www.reactive-streams.org</a>) </span><span>is an initiative to provide a standard for asynchronous stream processing with non-blocking backpressure. </span></p>
<p>The non-blocking back pressure is a mechanism to deal with deficiencies of both pull and push semantics in the streaming environment. It is better explained by an example.</p>
<p>Imagine a building site with a foreman responsible for timely delivery of building materials among other duties. The site can only accommodate as much as 100 tons of materials. The foreman can order materials from another company but the orders are taken by one of the truck drivers as soon as one is in the company's office and not bringing materials to the customer.</p>
<p>The pull behavior for the foreman would be to call a contractor and wait until a truck driver is in the office and answers the call (blocking pull) or make calls periodically with the hope that this time somebody will pick up the phone (polling). In our case, the foreman sends a voice message to the contractor asking for 100 tons of materials and returns to his daily work instead. This is a non-blocking pull. </p>
<p>The contractor accepts the order as soon as they have the capacity to do so. They are about to send a couple of trucks with the capacity of 32 tons each but realize they cannot send more than 100 tons because the building site won't be able to receive such volume. Therefore, only three trucks and 96 tons of materials are sent.</p>
<p>After 30 tons of materials are consumed, the foreman realizes that they can order more from the contractor to avoid the building site becoming idle later if the rest of materials are quickly consumed. They order another 30 tons. But the contractor remembers that there are still another 4 tons remaining from the previous order so it is safe to send another full truck with 32 tons which can fit in the single truck. We reflect the fact that some demand in the first request was satisfied later by consecutive delivery and saying that requests are additive.</p>
<p>And this is basically how the backpressure concept of Reactive Streams works. It is arguable that in reality the approach would be better reflected by the name <em>forward ease</em> but probably this name wouldn't take off as <em>back-pressure</em> did.</p>
<p>The Reactive Stream specification strives to define a low-level API which can be implemented by different libraries in order to achieve interoperability between implementation. The standard defines the API and the <strong>Technology Compatibility Kit</strong><span> (</span><strong><span>TCK</span></strong><span>) </span>which is a standard test suite for the API implementations.</p>
<div class="packt_infobox">TCK purpose is to help library authors to validate that their implementations adhere to the standard.</div>
<p>The API contains the following components:</p>
<ul>
<li>Publisher</li>
<li>Subscriber</li>
<li>Subscription</li>
<li>Processor</li>
</ul>
<p>The <kbd>Publisher</kbd> represents the source, the <kbd>Subscriber</kbd> relates to the consumer, the Processor is a processing stage of the stream, and the <kbd>Subscription</kbd> is a representation of the back-pressure.</p>
<p>All of the methods defined in the API return <kbd>void</kbd> which means they are intended to be executed without the caller waiting for the result, hence the <em><span>async</span></em><span><em>hronous stream processing</em> in the definition of the Reactive Streams standard.</span></p>
<p>Reactive Streams is a library standard and defines how libraries are expected to communicate with each other in order to be able to interoperate. It is expected that libraries will offer different, higher-level APIs to the user, likely reflecting some aspects of the implementation details. </p>
<p>Akka Streams is one of such libraries built using Akka actors as the underlying technology. It implements the Reactive Streams standard and has a rich, high-level API which allows you to describe streams using high-level DSL and also exhibits the underlying Akka machinery. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Akka Streams</h1>
                </header>
            
            <article>
                
<p><span>The purpose of Akka Streams (<a href="https://doc.akka.io/docs/akka/2.5.13/stream/stream-introduction.html">https://doc.akka.io/docs/akka/2.5.13/stream/stream-introduction.html</a>) is to offer an intuitive and safe way to formulate stream processing setups such that we can execute them efficiently and with bounded resource usage.</span></p>
<p>Akka Streams fully implements a Reactive Stream standard in order to interoperate with another compliant Reactive Streams library, but this fact is usually considered to be an implementation detail.</p>
<p>The initial motivation for Akka Streams was the fact that all Akka actor systems share the same sets of technical problems, which adds accidental complexity and needs to be solved for almost every single project separately over and over again. For example, Akka does not have any general flow control mechanism, and in order to prevent an actor's mailboxes from overflowing, it needs to be implemented as a home-grown solution within every application. Another common pain point is the at-most-once messaging semantics, which is less than ideal in most cases, but also dealt with on an individual basis. Yet another inconvenience Akka is criticized for is its untyped nature. The absence of types makes it impossible to check the soundness of possible interactions between actors at the compile time.</p>
<p>Akka Streams aim to solve this problem by placing a streaming layer on top of the actor system. This layer adheres to the small set of architectural principles to provide a consistent user experience. These principles are a comprehensive domain model for stream processing and compositionally. <span>The focus of the library lies in modular data transformation. In this sense, Reactive Streams are just an implementation detail for how data is passed between steps of the flow and Akka actors are the implementation detail for individual steps.</span></p>
<p>The principle of the completeness of the domain model for distributed bounded stream processing means that Akka Streams has a rich DSL that allows you to express all aspects of the domain, such as single processing and <span>transformation</span> steps and their interconnections, streams with complex graph topologies, back-pressure, error and failure handling, buffering and so on.</p>
<p>The modularity principle means that the definition of single transformations, multiple transformations connected in specific ways, or even whole graphs must be freely shareable. This principle leads to the design decision to make the description of the stream separate from the execution of the stream. Therefore, a user of Akka Streams has to go over the following three steps to execute a stream:</p>
<ol>
<li>Describe the stream in the form of building blocks and connections between them. The result of this step is usually called a <em>blueprint</em> in Akka documentation.</li>
<li>Materialize the blueprint which creates an instance of the flow. The materialization is done by providing a materializer which in Akka takes the form of using an actor system or an actor context to create actors for each processing stage.</li>
<li>Execute a materialized stream using one of the <kbd>run</kbd> methods.</li>
</ol>
<p>In practice, usually the last two steps are combined and the materializer is provided as an implicit parameter.</p>
<p>With this theory in mind, let's take a look at what building and executing streams with Akka Streams looks like in practice.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Setup and dependency</h1>
                </header>
            
            <article>
                
<p>In order to make Akka Streams available in our project, we need to put the following dependency into the <kbd>build.sbt</kbd> file:</p>
<pre>lazy val akkaVersion = "2.5.14"<br/>libraryDependencies += "com.typesafe.akka" %% "akka-stream" % akkaVersion</pre>
<p>This gives us the possibility to import related classes<span> in our examples </span>using the following import statements:</p>
<pre>import akka.stream._<br/>import akka.stream.scaladsl._</pre>
<p>These import statements are assumed to be present in every example later in this chapter.</p>
<p>We will also need a wrapper which would provide an actor system in order for us to be able to create materializers for our streams. The wrapper will need to terminate the actor system as soon as stream processing is finished:</p>
<pre><span>package </span>ch13<br/><br/><span>import </span>akka.actor.ActorSystem<br/><span>import </span>akka.stream._<br/><br/><span>object </span>Bakery <span>extends </span>App {<br/>  <span>implicit val </span><span>bakery</span>: ActorSystem = <span>ActorSystem</span>(<span>"Bakery"</span>)<br/>  <span>implicit val </span><span>materializer</span>: Materializer = <span>ActorMaterializer</span>()<br/><br/>  // stream processing happens here<br/><br/>  <span>private def </span>afterAll = <span>bakery</span>.terminate()<br/>}</pre>
<p>Now, before we dive into the code, we need some vocabulary to be able to describe what we are doing in our examples.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Essential concepts</h1>
                </header>
            
            <article>
                
<p>Let's take a look at the vocabulary Akka Streams uses to describe streams and their elements.</p>
<p>As described earlier, every stream has producer, consumer, and transformation steps. In Akka Streams they are named <kbd>Source</kbd>, <kbd>Sink</kbd>, and <kbd>Flow</kbd> respectively.</p>
<p>More formally, in Akka Streams any building block of a stream is named a <strong>processing stage</strong>. A processing stage with a single output is a <kbd>Source</kbd>, a single input is a <kbd>Sink</kbd> and with one input, and one output is a <kbd>Flow</kbd>. By connecting a source and a sink to the flow we build a <em>Runnable Graph</em> which can be executed.</p>
<p>There are also special processing stages:</p>
<ul>
<li>Fan-in with two or more inputs and one output</li>
<li>Fan-out with one input and two or more outputs</li>
<li>Bidiflow with two inputs and two outputs pointing in opposite directions</li>
</ul>
<p>We made up the following diagram with all processing stages interconnected to simplify grasping the concept. The dotted lines represent the backpressure we mentioned earlier: </p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/5c4245c1-3382-4c1f-b4ba-2979973eee88.png" width="1500" height="600"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 1. Different processing stages interconnected in runnable graph</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Structure of the example</h1>
                </header>
            
            <article>
                
<p>Let's see how the streaming implementation changes the shape of our bakery app we've built <a href="87c2e446-3730-49ae-b86b-fc8269678399.xhtml">Chapter 11</a>, <em>An Introduction to the Akka and Actor Models</em>, and <a href="caabef7a-c854-4b39-b8fb-ac17b8ba6eee.xhtml">Chapter 12</a>, <em>Building Reactive Applications with Akka Typed</em>. To recap, this is the design of the bakery represented with actors:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/d52ca074-5c4e-4cc6-9483-44fc2e9966af.png" style="width:38.75em;height:12.50em;" width="785" height="253"/></p>
<p>Actors in this hierarchy had the following responsibilities:</p>
<ul>
<li>The <strong>Manager</strong> initiated new baking rounds and performed the transfer of work packages between subordinates and supervised them.</li>
<li>The <strong>Boy</strong> was given a shopping list and acquired groceries from the remote system.</li>
<li>The <strong>Chef</strong> created and used a number of mixers of limited capacity in order to convert given groceries into dough.</li>
<li>The <strong>Cook</strong> formed a number of raw cookies from the given dough.</li>
<li>The <strong>Baker</strong> baked raw cookies in the <strong>Oven</strong> of fixed size. It maintained an internal queue of raw cookies in case the rest of the bakery was making them quicker than the <strong>Oven</strong> was able to bake them.</li>
<li>The <strong>Oven</strong> and <strong>Mixers</strong> represent hardware resources. They convert raw cookies into edible cookies and groceries into dough respectively but do so after some delay and with possible failures.</li>
</ul>
<p>Now we have the possibility of defining relationships between participants in a more static way, so we will only keep initiating the behavior of the <strong>Manager</strong> and organize the work transfer at the flow level by connecting involved transformation steps <span>directly together.</span></p>
<p>This is what the structure of our bakery will look like, represented in processing stages:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/44f816ea-b937-4c20-bb97-a0d330b85555.png" style="width:61.08em;height:5.25em;" width="1142" height="99"/> </p>
<p>The hierarchical structure of the actor system has transformed into the flat data flow. Obviously, there are no <kbd>Mixers</kbd> and <kbd>Oven</kbd> anymore in this diagram. What happened to them? Well, we're cheating a bit by hiding the internal details of transformation steps here. In reality, some of these steps are composite blocks constructed from smaller components. Let's describe how it looks in detail.</p>
<p>The <strong>Manager</strong> only kept his initiating behavior. This will be represented by a timer source which will tick every now and then and push others to bake some cookies. The <strong>Boy</strong> can't work with just the <strong>Manager</strong>'s desire so we need the <strong>Manager</strong> to give a proper shopping list to it. Thus we'll have to convert the ticking urge into the <strong>Shopping List</strong> as represented in the next diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/607a425b-dd5f-4dd2-b1e6-27e99fedde2a.png" style="width:22.08em;height:3.42em;" width="394" height="62"/></p>
<p>This composite block has exactly one output and no inputs and therefore it is clearly a <kbd>Source[ShoppingList]</kbd>.</p>
<div class="packt_infobox">The real type of the source is <kbd>Source[+Out, +Mat]</kbd> as it is also taken into the account the materialization aspect. The materialization is non-essential for us for now so we'll talk about simplified pseudo-types as we describe the structure of the flow.</div>
<p>The <kbd>Boy</kbd> and the <kbd>Cook</kbd> are simple steps; both of them can be seen as a transformation of input into the output, and we'll look at the details of this transformation in a moment. From this description, we can conclude that the <kbd>Boy</kbd> is a <kbd>Flow[ShoppingList, Groceries]</kbd> and a <kbd>Cook</kbd> is just a <kbd>Flow[Dough, RawCookies].</kbd></p>
<p>The <kbd>Chef</kbd> is clearly not as simple as his siblings. It needs to create a number of <strong>Mixer</strong> corresponding to the amount of groceries, use them in parallel to mix the dough, and combine the results together before sending them further. We'll represent this with the following structure: </p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/c939d6b8-f579-4a1c-bb76-6e1d6781e2e7.png" width="1028" height="140"/></p>
<p>There is more going on in this diagram than we described before. This is because we combine the flow from building blocks with a single responsibility and we need to do transformations:</p>
<ol>
<li>We need to divide incoming groceries into portions suitable for a single mixer; this is the <strong>Divide</strong> step.</li>
<li>Next, we need to be sure that work is evenly distributed among the mixers to avoid the situation where we need to wait for one of the mixers because it got multiple work packages. This is where <strong>Balance</strong> comes in play.</li>
<li>The involvement of multiple mixers is obvious.</li>
<li>The <strong>Merge</strong> step's responsibility is to be a fan-in block; it merges multiple streams of small portions of dough into a single stream of the same pieces.</li>
<li>Finally we <strong>Combine</strong> small pieces into one big bowl before we give it further to process.</li>
</ol>
<p>The kinds of internal sub-flows are as following the <strong>Divide</strong>, <strong>Combine</strong> and all of the <strong>Mixer</strong>s are just Flows, the <strong>Balance</strong> is fan-out and the <strong>Merge</strong> is fan-in. The resulting type is the <kbd>Flow[Groceries, Dough]</kbd>.</p>
<p>The Baker is also not as simple as it appears in the previous diagram because it hides an oven and the interactions with it:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/e11fc87c-6ccb-487b-8f62-4cc3c052b5b5.png" style="width:13.25em;height:8.25em;" width="253" height="158"/></p>
<p>The <strong>Oven</strong> in this diagram has one input and one output so this is just a <kbd>Flow[RawCookies,ReadyCookies]</kbd>. The <strong>Baker</strong> has two inputs and two outputs and its shape is a <kbd>BidiFlow[RawCookies, RawCookies, ReadyCookies, ReadyCookies]</kbd>.</p>
<p>The resulting type of combination is <span><kbd>Flow[RawCookies,ReadyCookies]</kbd>.</span></p>
<p>In the example built earlier, with an actor system the <strong>Baker</strong> maintained an internal queue of raw cookies as they arrived if the oven was not empty. This has a disadvantage that in the case of a really eager <kbd>Manager</kbd> the baking process could be initiated quite often and the raw cookies could arrive at the baker at much quicker pace than the oven can possibly bake them. The queue of the raw cookies can thus grow indefinitely large until it occupies all available space, and we'll need to either throw away raw cookies to free some space or close the bakery because there is no place for other actors to work.</p>
<p>In this version of the bakery we decided not to implement any queue but rely on the back pressure instead. We would expect the <kbd>Oven</kbd> to communicate with the <kbd>Baker</kbd> if it can't accept more work. The <kbd>Baker</kbd> will do the same, all the way back to the <kbd>Manger</kbd>, so that it won't be possible to even express the desire to have more cookies baked until there is more oven capacity available. With different buffering strategies, it is possible to manage how much work in progress there is at the bakery at any moment. For the purpose of the example, we'll set this limit low to demonstrate back pressure in action.</p>
<p>The last step of our flow is a <kbd>Customer</kbd>, which is of type <kbd>Sink[ReadyCookies]</kbd>.</p>
<p>Now let's switch gears and set in the code the structure we came up with.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Basics of Akka Streams</h1>
                </header>
            
            <article>
                
<p>Elements of the Akka Streams flow are usually defined using constructors of the appropriate type. We'll implement building blocks which constitute our diagram one by one, starting with the simplest and moving on to the increasingly complex as we go over them.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Sources and sinks</h1>
                </header>
            
            <article>
                
<p>The simplest component of our flow is possibly the <kbd>Consumer</kbd>. It is just a sink which is supposed to print out information about incoming data. To construct it, we'll use the <kbd>Sink</kbd> factory, as follows:</p>
<pre><span>val </span><span>consumer</span>: Sink[ReadyCookies, Future[Done]] =<br/>  Sink.<span>foreach</span>(cookie =&gt; <span>println</span>(<span>s"</span><span>$cookie</span><span>, yummi..."</span>))</pre>
<p> The <kbd>Sink</kbd> factory offers more than two dozens different constructors to define a sink. We're utilizing one of the simplest, which invokes a provided function for each element of the stream.</p>
<p>Here we see that the real type of it is the <kbd>Sink[ReadyCookies, Future[Done]]</kbd>. This reflects the type <kbd>ReadyCookies</kbd> elements and the type the <kbd>Sink</kbd> is materialized to. In this case, it is materialized into <kbd>Success</kbd> if stream ends by reaching its end and to the <kbd>Failure</kbd> if there is a failure in the stream.</p>
<p>Now we'll take a look at the opposite end of the stream and define a source.  The <kbd>Source</kbd> factory similarly provides almost three dozens of different methods to create a source. We don't want to overwhelm our bakery's team with work so we decided to use a timed source of data:</p>
<pre><span>private val </span><span>delay </span>= <span>1 </span>second<br/><span>private val </span><span>interval </span>= <span>1 </span>second<br/><br/><span>val </span><span>manager1</span>: Source[NotUsed, Cancellable] =<br/>  Source.<span>tick</span>(<span>delay</span>, <span>interval</span>, NotUsed)</pre>
<p>This represents the first block in our composite <kbd>Source</kbd> and its type is no-fit for our <kbd>Boy</kbd>, so we need to implement the second block of the diagram, the generator, and connect both together. This is more easily done than explained:</p>
<pre><span>val </span><span>manager</span>: Source[ShoppingList, Cancellable] =<br/>  Source.<span>tick</span>(<span>delay</span>, <span>interval</span>, NotUsed).map { _ =&gt;<br/>    <span>shoppingList<br/></span><span>  </span>}</pre>
<p>We basically just map over the input but ignore it and return a <kbd>shoppingList</kbd> instead. Now our <kbd>Source</kbd> has a proper type so that we can connect a <kbd>Boy</kbd> to it later.</p>
<p>There is a subtle aspect of this implementation which we didn't take into the account. We have a predefined interval with the intention that the rest of the flow is not overwhelmed with requests. But at the same time, we're about to rely on the back pressure from the <kbd>Oven</kbd> for the same purpose. This is not optimal because if we pick too big an interval, our bakery will be under-utilized and if we pick too small an interval, this will be the back pressure which will manage the flow. We can simplify our source to the form that will just produce shopping lists and put them into the pipeline as soon as there is some downstream capacity available:</p>
<pre><span>val </span><span>manager</span>: Source[ShoppingList, NotUsed] =<br/>  Source.<span>repeat</span>(NotUsed).map(_ =&gt; <span>shoppingList</span>)</pre>
<p>Here, we just repeat the <kbd>NotUsed</kbd> element (which provides a nice syntax) and then replace it with the random shopping list as before. The difference is that the manager will generate a shopping list every time there is a demand for that without potentially waiting too long because of the timer settings.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Flows </h1>
                </header>
            
            <article>
                
<p>Now that we have the source and the sink, let's implement the flow itself. Again, we will start with the simplest parts and switch to the more complex as we progress.</p>
<p>The easiest flow building block is surely the <kbd>Cook</kbd>. It could be implemented as a map function called on the preceding flow definition but for composing reasons, we'd like to define it separately.</p>
<p>The approach of the flow definition is consistent with the previous two—the <kbd>Flow</kbd> constructor is the way to go. The flow is defined in terms of operations on the input but the definition itself is decoupled from this input. Again there are lots of methods to choose from; for our purposes, we pick the simple <kbd>map</kbd>: </p>
<pre><span>object </span>Cook {<br/>  <span>def </span>formFlow: Flow[Dough, RawCookies, NotUsed] =<br/>    <span>Flow</span>[Dough].map { dough =&gt;<br/>      <span>print</span>(<span>s"Forming </span><span>$</span>dough<span> - "</span>)<br/>      <span>val </span>result = <span>RawCookies</span>(<span>makeCookies</span>(dough.weight))<br/>      <span>println</span>(result)<br/>      result<br/>    }<br/>  <span>private val </span><span>cookieWeight </span>= <span>50<br/></span><span>  </span><span>private def </span>makeCookies(weight: Int): Int = weight / <span>cookieWeight<br/></span>}</pre>
<p>The <kbd>cook</kbd>'s flow is just mapping over the input dough and converting it to the output, raw cookies, as it represented by the type annotation.</p>
<p>The Boy is quite similar to the <kbd>Cook</kbd> in the sense that it is a simple building block which transforms its input into the output. There is one caveat though—our <kbd>Boy</kbd> needs to communicate with the remote actor in order to do this. </p>
<p>Akka Streams is built upon Akka and thus offers some possibilities to utilize and communicate with actors at different stages; for instance, it is possible to use an <kbd>ActorRef</kbd> as a source or sink. The remoting aspect in this situation turns out to be just an implementation and configuration detail because of Akka's location transparency.</p>
<p>In our use case, the most appropriate way to communicate with a Seller deployed in the remote shop system will be an ask pattern. Let's do this step by step. First, we'll look up a remote actor in order to be able to communicate with it:</p>
<pre><span>def </span>lookupSeller(<span>implicit </span>as: ActorSystem): Future[ActorRef] = {<br/>  <span>val </span>store = <span>"akka.tcp://Store@127.0.0.1:2553"<br/></span><span>  </span><span>val </span>seller = as.actorSelection(<span>s"</span><span>$</span>store<span>/user/Seller"</span>)<br/>  seller.resolveOne()<br/>}</pre>
<p>Given an <kbd>ActorSystem</kbd>, we look up an actor using an address of the remote system and an actor path. We know there should be exactly one actor, therefore we resolve one reference. Depending on the result of the lookup it will return either <kbd>Success</kbd> with the reference we need or a <kbd>Failure[ActorNotFound]</kbd>. The failure will be propagated via the error flow and will lead to the termination of the stream because we don't define how to handle it. Let's call this the desired behavior because without a seller we won't be able to convert a shopping list into groceries.</p>
<p>We can use a <kbd>Future[ActorRef]</kbd> to talk to the actor: </p>
<pre><span>def </span>goShopping(<span>implicit </span>as: ActorSystem, ec: ExecutionContext):<br/>  Future[Flow[ShoppingList, Groceries, NotUsed]] =<br/>  <span>lookupSeller</span>.map { ref =&gt; <br/>    <span>Flow</span>[ShoppingList].ask[Groceries](ref) <br/>}</pre>
<p>Here, we not only need an <kbd>ActorSystem</kbd> but also an <kbd>ExecutionContext</kbd> in order to be able to map over the <kbd>Future</kbd> we acquire from the <kbd>lookupSeller</kbd>. We're using the actor reference (if there is one) as a parameter to call <kbd>Flow.ask</kbd>.  The type of the <kbd>Flow</kbd> corresponds to the expected input type and the type of the <kbd>ask</kbd>—to the expected output type.</p>
<p>Now we can use another <kbd>Flow</kbd> constructor to convert a <kbd>Future[Flow]</kbd> to the <kbd>Flow</kbd>: </p>
<pre><span>def </span>shopFlow(<span>implicit </span>as: ActorSystem, ec: ExecutionContext): Flow[ShoppingList, Groceries, Future[Option[NotUsed]]] =<br/>  Flow.<span>lazyInitAsync </span>{ () =&gt; <span>goShopping </span>}</pre>
<p>The <kbd>lazyInitAsync</kbd> translates an internal <kbd>Flow</kbd> of the <kbd>Future</kbd> into the normal <kbd>Flow</kbd>. This sub-flow has a proper type of input and output and thus we can plug it into our flow definition later.</p>
<p>It is important to extend the configuration in the <kbd>application.conf</kbd> with properties, needed for the Akka remoting as described in <a href="87c2e446-3730-49ae-b86b-fc8269678399.xhtml">Chapter 11</a>, <em>An Introduction to the Akka and Actor Models</em>. </p>
<p>The next composite step we're going to implement is a <kbd>Baker</kbd>, including its constituent <kbd>Oven</kbd>.</p>
<p>The <kbd>Oven</kbd> needs to spend some time turning raw cookies into edible cookies and we could implement this by introducing a bit of blocking behavior. But doing so will affect the rest of the system by needlessly consuming available threads. Because of this, we'll use another feature of Akka Streams, <kbd>Flow.delay</kbd>, which allows us to shift the emission of elements in time:</p>
<pre><span>def </span>bakeFlow: Flow[RawCookies, ReadyCookies, NotUsed] =<br/>  <span>Flow</span>[RawCookies]<br/>    .delay(<span>bakingTime</span>, DelayOverflowStrategy.<span>backpressure</span>)<br/>    .addAttributes(Attributes.<span>inputBuffer</span>(1, <span>1</span>))<br/>    .map(<span>bake</span>)</pre>
<p>As we only have one <kbd>Oven</kbd>, we define a buffer size to be of the initial and maximum size of 1. We also don't want to drop arriving raw cookies or release cookies which are not ready yet, therefore we define an overflow strategy to be a back pressure.</p>
<p>The <kbd>bake</kbd> method is a trivial conversion once again:</p>
<pre><span>private def </span>bake(c: RawCookies): ReadyCookies = {<br/>  <span>assert</span>(c.count == <span>ovenSize</span>)<br/>  <span>ReadyCookies</span>(c.count)<br/>}</pre>
<p>Now, with this <kbd>Oven</kbd> we can define a <kbd>Baker</kbd> which we planned to give a type of <kbd>BidiFlow</kbd>:</p>
<pre><span>def </span>bakeFlow = BidiFlow.<span>fromFlows</span>(<span>inFlow</span>, <span>outFlow</span>)</pre>
<p>In order to do this, we need to separately define the <kbd>inFlow</kbd> and <kbd>outFlow</kbd> for both flow directions.</p>
<p>The <kbd>outFlow</kbd> is just passing cookies that are ready to the consumer and we already know how to do that:</p>
<pre><span>private def </span>outFlow = <span>Flow</span>[ReadyCookies]</pre>
<p>The <kbd>inFlow</kbd> is a bit more involving because we need to regroup incoming raw cookies from groups of some random quantity to groups with the size of the oven. We'll do this by defining a sub-source of single cookies and then grouping them as desired. Here is the first step:</p>
<pre><span>def </span>extractFromBox(c: RawCookies) = <span>Source</span>(<span>List</span>.fill(c.count)(<span>RawCookies</span>(<span>1</span>)))</pre>
<p>We're creating a source: the number of single cookies. The regrouping logic looks like this:</p>
<pre><span>val </span><span>inFlow </span>= <span>Flow</span>[RawCookies]<br/>  .flatMapConcat(<span>extractFromBox</span>)<br/>  .grouped(Oven.<span>ovenSize</span>)<br/>  .map(_.reduce(_ + _))</pre>
<p>The <kbd>flatMapConcat</kbd> consumes one source after another and concatenates the results. We then group the stream of single cookies to the stream of <kbd>List[RawCookie]</kbd> of <kbd>ovenSize</kbd>. Lastly, we reduce this list of single cookies into <kbd>RawCookie(ovenSize)</kbd> as <kbd>Oven</kbd> expects it.</p>
<p>Now we can combine a baker's <kbd>BidiFlow</kbd> and oven's Flow into the composite Flow by joining them:</p>
<pre><span>val </span><span>bakerFlow</span>: Flow[RawCookies, ReadyCookies, NotUsed] = <br/>  Baker.<span>bakeFlow</span>.join(Oven.<span>bakeFlow</span>)</pre>
<p>The <kbd>join</kbd> method adds a given <kbd>Flow</kbd> as a final transformation to the stack of <kbd>BidiFlows</kbd>. In our case, the size of the stack is one and the type of the resulting flow is <kbd>Flow[RawCookies, ReadyCookies, NotUsed]</kbd>. The resulting sub-flow hides all of the details of regrouping the cookies and waiting for their readiness, leaving us with a nice definition.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Graphs</h1>
                </header>
            
            <article>
                
<p>The final piece of our flow is a <kbd>Chef</kbd>. It incorporates work management across Mixers. Let's implement <kbd>Mixers</kbd> first.</p>
<p>The mixing behavior itself is straightforward but to mimic real hardware we include a block for the time of mixing:</p>
<pre><span>def </span>mix(g: Groceries) = {<br/>  Thread.<span>sleep</span>(<span>mixTime</span>.toMillis)<br/>  <span>import </span>g._<br/>  <span>Dough</span>(eggs * <span>50 </span>+ flour + sugar + chocolate)<br/>}</pre>
<p>Because of the mixing behavior, we need to use a special async flow constructor to start a separate thread for every mixer. In order to better control how threads are assigned, we'll put into the configuration a definition of the separate pinned thread dispatcher which assigns one thread per sub-flow:</p>
<pre>mixers-dispatcher {<br/>  executor = <span>"thread-pool-executor"<br/></span><span>  </span>type = PinnedDispatcher<br/>}</pre>
<p>With this definition in place, we are now able to define the blocking mixing behavior:</p>
<pre><span>private def </span>subMixFlow: Flow[Groceries, Dough, NotUsed] =<br/>  <span>Flow</span>[Groceries].async(<span>"mixers-dispatcher"</span>, <span>1</span>).map(<span>mix</span>)</pre>
<p>The <kbd>async</kbd> constructor takes a buffer size as a parameter and we want our mixers not to have any large buffers assigned to them.</p>
<p>The work management can be implemented as a separate concept which closely resembles one of the recipes from the Akka Streams documentation cookbook—the Balancer. It takes a worker <kbd>subFlow</kbd> and a count of workers and constructs a graph with the given number of workers:</p>
<pre><span>import </span>akka.stream.scaladsl.GraphDSL<br/><span>import </span>GraphDSL.Implicits._<br/><br/><span>def </span>createGraph[<span>Out</span>, <span>In</span>](subFlow: Flow[<span>In</span>, <span>Out</span>, Any], count: Int) = {<br/>  <span>val </span>balanceBlock  = <span>Balance</span>[<span>In</span>](count, waitForAllDownstreams = <span>false</span>)<br/>  <span>val </span>mergeBlock = <span>Merge</span>[<span>Out</span>](count, eagerComplete = false)<br/>  GraphDSL.create() { <span>implicit builder</span> ⇒<br/>    <span>val </span>balancer = builder.add(balanceBlock)<br/>    <span>val </span>merge = builder.add(mergeBlock)<br/><br/>    <span>for </span>(_ ← <span>1 </span>to count) balancer ~&gt; subFlow ~&gt; merge<br/><br/>    FlowShape(balancer.in, merge.out)<br/>  }<br/>}</pre>
<p>The <kbd>Balance</kbd> block is a fan-out flow with several outputs. It distributes stream elements evenly between the workers. With <kbd>waitForAllDownstreams = false</kbd> we specify that the distribution can start as soon as at least one of the workers demands a job. With <kbd>false</kbd> we change the behavior to wait for all of the workers to demand a job before it will be distributed. The <kbd>Merge</kbd> is a fan-in block with a specified number of inputs. By specifying <kbd>eagerComplete = false</kbd> we tell it to wait for all down streams to complete as compared to completing as soon as one of the workers is done.</p>
<p>Then we construct a graph using <kbd>GraphDSL.create()</kbd> and provide actual graph building logic as a parameter. First, we convert <kbd>balanceBlock</kbd> and <kbd>mergeBlock</kbd> into Shapes by adding them to the <kbd>builder</kbd>. Then we connect as many sub-flows as needed to the balancer and merge using the <kbd>~&gt;</kbd> syntax provided by the <kbd>import GraphDSL.Implicits._</kbd>. The <kbd>for</kbd> comprehension for five workers would be equivalent to the following plain definition:</p>
<pre>balancer ~&gt; subFlow ~&gt; merge<br/>balancer ~&gt; subFlow ~&gt; merge<br/>balancer ~&gt; subFlow ~&gt; merge<br/>balancer ~&gt; subFlow ~&gt; merge</pre>
<p>Having this graph defined, we can specify the rest of the <kbd>Balancer</kbd> flow using another <kbd>Flow</kbd> constructor:</p>
<pre><span>def </span>apply[<span>In</span>, <span>Out</span>](subFlow: Flow[<span>In</span>, <span>Out</span>, Any],<br/>                   count: Int): Flow[<span>In</span>, <span>Out</span>, NotUsed] =<br/>  Flow.<span>fromGraph</span>(<span>createGraph</span>(subFlow, count))</pre>
<p>We can use it to construct our <kbd>Chef</kbd> sub-flow:</p>
<pre><span>def </span>mixFlow: Flow[Groceries, Dough, NotUsed] =<br/>  <span>Flow</span>[Groceries]<br/>    .map(<span>splitByMixer</span>)<br/>    .flatMapConcat(<span>mixInParallel</span>)<br/><span><br/>def </span>splitByMixer(g: Groceries) = {<br/>  <span>import </span>g._<br/>  <span>val </span>single = <span>Groceries</span>(<span>1</span>, flour / eggs, sugar / eggs, chocolate / eggs)<br/>  <span>List</span>.fill(g.eggs)(single)<br/>}<br/><br/><span>def </span>mixInParallel(list: <span>List</span>[Groceries]) =<br/>  <span>Source</span>(list)<br/>    .via(<span>Balancer</span>(<span>subMixFlow</span>, list.size))<br/>    .grouped(list.size)<br/>    .map(_.reduce(_ + _))</pre>
<p>Here, again we split <kbd>Groceries</kbd> into a stream of smaller portions, mix each of these portions using a dedicated mixer in parallel, and combine them using the same technique we used before with the <kbd>Baker</kbd> and <kbd>Oven</kbd>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Logging</h1>
                </header>
            
            <article>
                
<p>In <kbd>Cook</kbd>'s flow, we used two <kbd>print</kbd> statements in order to see how the <kbd>Cook</kbd> was doing. It's OK for our example but we would be better off with proper logging. Let's improve on that.</p>
<p>Akka provides a <kbd>log</kbd> method which takes a logger name as a parameter and can be called on any processing stage in the flow. Let's use it instead of our <kbd>print</kbd> statements:</p>
<pre><span>def </span>formFlow: Flow[Dough, RawCookies, NotUsed] =<br/>  <span>Flow</span>[Dough]<br/>    .log(<span>"Cook[Before Map]"</span>)<br/>    .map { dough =&gt;<br/>      <span>RawCookies</span>(<span>makeCookies</span>(dough.weight))<br/>    }<br/>    .log(<span>"Cook[After Map]"</span>)<br/>    .withAttributes(<br/>      Attributes.<span>logLevels</span>(<br/>        onElement = Logging.<span>InfoLevel</span>,<br/>        onFinish = Logging.<span>DebugLevel</span>,<br/>        onFailure = Logging.<span>WarningLevel<br/></span><span>      </span>)<br/>    )</pre>
<p>Here, we're writing into the log elements of the flow before and after transformation and also providing an optional logging configuration in order to specify log levels for different types of events.</p>
<p>To see the effect of these changes we need to extend the<span> </span><kbd>application.conf</kbd>:</p>
<pre>akka {<br/>  loggers = [<span>"akka.event.Logging$DefaultLogger"</span>]<br/>  <span># Options: OFF, ERROR, WARNING, INFO, DEBUG<br/></span><span>  </span>loglevel = <span>"INFO"<br/></span>}</pre>
<p>Now, after starting our example, we'll see the following entries in the log:</p>
<pre><strong>[INFO] [Bakery-akka.actor.default-dispatcher-14] [akka.stream.Log(akka://Bakery/system/StreamSupervisor-0)] [Cook[Before Map]] Element: Dough(575)</strong><br/><strong> ...</strong><br/><strong> [INFO] [Bakery-akka.actor.default-dispatcher-14] [akka.stream.Log(akka://Bakery/system/StreamSupervisor-0)] [Cook[After Map]] Element: RawCookies(11)</strong><br/><strong> ...</strong><br/><strong> [INFO] [Bakery-akka.actor.default-dispatcher-14] [akka.stream.Log(akka://Bakery/system/StreamSupervisor-0)] [Cook[Before Map]] Element: Dough(1380)</strong><br/><strong> [INFO] [Bakery-akka.actor.default-dispatcher-14] [akka.stream.Log(akka://Bakery/system/StreamSupervisor-0)] [Cook[After Map]] Element: RawCookies(27)</strong></pre>
<p>With logging in place, we have finished defining all of the parts of our flow and can try to bring them together.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Materialization</h1>
                </header>
            
            <article>
                
<p>Now we can specify the whole flow for our bakery:</p>
<pre><span>val </span><span>flow </span>= Boy.<span>shopFlow<br/></span><span>  </span>.via(Chef.<span>mixFlow</span>)<br/>  .via(Cook.<span>formFlow</span>)<br/>  .via(<span>bakerFlow</span>)<br/><br/>val graph: RunnableGraph[Future[Done]] = manager.via(flow).toMat(consumer)(Keep.right)<br/><br/>implicit val materializer: Materializer = ActorMaterializer()<br/><br/><span>graph</span>.run().onComplete(_ =&gt; afterAll)</pre>
<p>Here, we first construct the full flow by combining sub-flows we defined before. Then we convert the flow to runnable graph by attaching the <kbd>manager</kbd> Source and the <kbd>consumer</kbd> Sink.</p>
<p>We also specify that we want to keep the right materialized value. The left materialized value would be the result of the stream, which is <kbd>NotUsed</kbd> in our case because we just writing produced cookies to the console. The right value is a future which is completed when the flow has finished running and we want to use it to shut down our actor system as soon is it happens.</p>
<p>Finally, we run the graph by bringing an <kbd>ActorMaterializer</kbd> in scope and calling the corresponding <kbd>run</kbd> method.</p>
<p>Our system runs and bakes tasty cookies, but unfortunately, we forgot to take an important aspect into account: Mixers in our setup are liable to hardware failure.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Handling failure</h1>
                </header>
            
            <article>
                
<p>In order to make the mixing step more realistic we'll add a couple of exceptions and throw them in randomly at the mixing stage. This will simulate hardware failures appearing at unpredicted times. The mixer can throw one of the three exceptions the same way it did before in the actor-based examples in the previous two chapters:</p>
<pre><span>object </span>MotorOverheatException <span>extends </span>Exception<br/><span>object </span>SlowRotationSpeedException <span>extends </span>Exception<br/><span>object </span>StrongVibrationException <span>extends </span>Exception<br/><br/><span>val </span><span>exceptions </span>= <span>Seq</span>(MotorOverheatException,<br/>                     SlowRotationSpeedException,<br/>                     StrongVibrationException)</pre>
<p>The realistic <kbd>mix</kbd> method could look like this:</p>
<pre><span>private def </span>mix(g: Groceries) = {<br/>  <span>if </span>(Random.nextBoolean()) <span>throw </span><span>exceptions</span>(Random.nextInt(<span>exceptions</span>.size))<br/>  Thread.<span>sleep</span>(<span>mixTime</span>.toMillis)<br/>  <span>import </span>g._<br/>  <span>Dough</span>(eggs * <span>50 </span>+ flour + sugar + chocolate)<br/>}</pre>
<p>There are a couple of different ways the exceptions can be dealt with. The most straightforward approach would be to catch them directly in the logic: </p>
<pre><span>private def </span>mix(g: Groceries) = <span>try </span>{<br/>  <span>if </span>(Random.nextBoolean()) <span>throw </span><span>exceptions</span>(Random.nextInt(<span>exceptions</span>.size))<br/>  Thread.<span>sleep</span>(<span>mixTime</span>.toMillis)<br/>  <span>import </span>g._<br/>  <span>Dough</span>(eggs * <span>50 </span>+ flour + sugar + chocolate)<br/>} <span>catch </span>{<br/>  <span>case </span>SlowRotationSpeedException =&gt;<br/>    Thread.<span>sleep</span>(<span>mixTime</span>.toMillis * 2)<br/>    <span>import </span>g._<br/>    <span>Dough</span>(eggs * <span>50 </span>+ flour + sugar + chocolate)<br/>}</pre>
<p>In the case of slow rotation, we decide to ignore the issue, keep the mixed stuff, and just give the mixer double the time to finish the mixing.</p>
<p>This works but it has an obvious disadvantage that we tangle our business and error-handling implementations. More often then not this is undesirable because the code for both aspects usually have different natures. The happy path contains business-related code and error handling is of a technical essence. Therefore it is usually preferred to separate these code paths. In our case, it is justified to handle the failure at the stage level because we don't want to drop the element of the stream.</p>
<p>Akka offers alternative ways to specify failure handling. One of them is recovery logic which can be defined for the stage so that failure is converted into the final element of the stream:</p>
<pre><span>def </span>subMixFlow: Flow[Groceries, Dough, NotUsed] =<br/>  <span>Flow</span>[Groceries].async(<span>"mixers-dispatcher"</span>, <span>1</span>).map(<span>mix</span>).recover {<br/>    <span>case </span>MotorOverheatException =&gt; <span>Dough</span>(<span>0</span>)<br/>  }</pre>
<p>Here we decide to return an empty bowl of dough in the case of motor failure. The stream is then completed but this is fine in our case because our mixers are one-off sub-flows anyway.</p>
<p>The <kbd>recover</kbd> method is a special case of the <kbd>recoverWithRetries</kbd>. The latter accepts not only a partial function for decision-making but also a number of retries in the case multiple failures happen in the same processing stage.</p>
<p>Now we are only missing a decision as to how to handle the <kbd>StrongVibrationException</kbd>. If we decide not to handle it, the default behavior will be able to stop the whole stream. If that happens, the downstream stages will get informed about the failure and upstream stages will be cancelled. </p>
<p>We definitely don't want to close our bakery in case one of our mixers vibrates too much. Quite the opposite; we'd like to ignore this completely. Some stages support a defining supervision strategy the same way actors do. We can use this possibility to define a common error-handling behavior. First, we need to define a decision strategy:</p>
<pre><span>val </span><span>strategy</span>: Supervision.<span>Decider </span>= {<br/>  <span>case </span>StrongVibrationException   ⇒ Supervision.<span>resume<br/></span><span>  </span><span>case </span>_ =&gt; Supervision.Stop<br/>}</pre>
<p>There are three strategies available—stop, restart, and resume:</p>
<ul>
<li>The stopping strategy is the default one and it will stop the processing stage and propagate the failure of up and downstream stages.</li>
<li>The resuming strategy just drops the current element and the stream continues.</li>
<li>Restart is similar to resume—it drops current element and the stream continues but before that the stage is restarted and so any internal state is cleared.</li>
</ul>
<p>In our decider, we just want the stream to continue in the case of strong vibrations, but stop in the case of any other failure. We handle both other types of exceptions in addition to a supervision strategy and therefore we're safe with this decision.</p>
<p>This is how we apply our supervision strategy to the definition of the processing stage:</p>
<pre><span>private def </span>subMixFlow: Flow[Groceries, Dough, NotUsed] =<br/>  <span>Flow</span>[Groceries].async(<span>"mixers-dispatcher"</span>, <span>1</span>).map(<span>mix</span>).recover {<br/>    <span>case </span>MotorOverheatException =&gt; <span>Dough</span>(<span>0</span>)<br/>  }.withAttributes(ActorAttributes.<span>supervisionStrategy</span>(<span>strategy</span>))</pre>
<p>Now, if we start our example, it will run and deal with hardware failures as expected.</p>
<p>It looks good but we're not done because we haven't tested our bakery yet.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Testing</h1>
                </header>
            
            <article>
                
<p>Testing stream-based code might look complex because of the interconnectedness of all of the parts of the system. But more often than not testing streams boils down to unit-testing processing stages in isolation and relying on the Akka Streams that data flow between this stages will happen as expected.</p>
<p>Frequently, no special testing library is needed. Let's demonstrate this by testing our source:</p>
<pre><span>"manager source" </span>should {<br/>  <span>"emit shopping lists as needed" </span>in {<br/>    <span>val </span>future: Future[<span>Seq</span>[ShoppingList]] = Manager.<span>manager</span>.take(<span>100</span>).runWith(Sink.<span>seq</span>)<br/>    <span>val </span>result: <span>Seq</span>[ShoppingList] = Await.<span>result</span>(future, <span>1</span>.seconds)<br/>    assert(result.size == <span>100</span>)<br/>  }<br/>}</pre>
<p>In order to run this test snippet we need an implicit materializer to be in scope:</p>
<pre><span>implicit val </span><span>as</span>: ActorSystem = <span>ActorSystem</span>(<span>"test"</span>)<br/><span>implicit val </span><span>mat</span>: Materializer = <span>ActorMaterializer</span>()</pre>
<p>The general approach is that in order to test a <kbd>Sink</kbd> it can be attached to the special <kbd>Source</kbd>, and for a <kbd>Source</kbd> under test, we'll need a special <kbd>Sink</kbd>.</p>
<p>In both cases, sequence-based <kbd>Source</kbd>s and Sinks are probably the most useful ones. In our example, we're testing that our source emits at least one hundred shopping lists and does this in a timely manner. The results are available as a <kbd>Seq[ShoppingList]</kbd> and can be inspected if needed.</p>
<p>In order to test a flow, we need to provide both a test <kbd>Source</kbd> and <kbd>Sink</kbd>:</p>
<pre><span>"cook flow" </span>should {<br/>  <span>"convert flow elements one-to-one" </span>in {<br/>    <span>val </span>source = Source.<span>repeat</span>(<span>Dough</span>(<span>100</span>)).take(<span>1000</span>)<br/>    <span>val </span>sink = Sink.<span>seq</span>[RawCookies]<br/>    <span>val </span>future: Future[<span>Seq</span>[RawCookies]] = source.via(Cook.<span>formFlow</span>).runWith(sink)<br/>    <span>val </span>result: <span>Seq</span>[RawCookies] = Await.<span>result</span>(future, <span>1</span>.seconds)<br/>    assert(result.size == <span>1000</span>)<br/>    assert(result.forall(_.count == 2))<br/>  }<br/>}</pre>
<p>Here, we see the same approach. After defining the test input and output we drive the flow under test and verify that the output has expected properties.</p>
<p>There is an undesirable call to <kbd>Await.result</kbd> in both cases which relates to the fact that running the Akka Streams flow produces a <kbd>Future</kbd>. We can improve on that by using testing techniques as described in <a href="dba6e932-4169-4b60-9bde-26ac2073a1ab.xhtml"/><a href="dba6e932-4169-4b60-9bde-26ac2073a1ab.xhtml">Chapter 5</a>, <em>Property-Based Testing in Scala</em>.</p>
<p>Alternatively, it is also possible to use test toolkits provided by other Akka libraries.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Akka TestKit</h1>
                </header>
            
            <article>
                
<p>Akka Streams offers integration with Akka actors via the <kbd>actorRef</kbd> method. It is available as a Sink constructor so we can use an actor to receive elements of the flow which are then represented as messages received by the actor. It is convenient to use <kbd>TestProbe</kbd> from the Akka <kbd>TestKit</kbd> to verify assumptions about the flow. First, we need to add a dependency to the Akka <kbd>TestKit</kbd> in <kbd>build.sbt</kbd>:</p>
<pre><span>libraryDependencies </span>+= <span>com.typesafe.akka" </span>%% <span>"akka-testkit" </span>% akkaVersion % <span>Test</span></pre>
<p>Here is an example of how the <kbd>TestProbe</kbd> can be employed:</p>
<pre><span>"the boy flow" </span>should {<br/>  <span>"lookup a remote seller and communicate with it" </span>in {<br/>    <span>val </span>probe = <span>TestProbe</span>()<br/>    <span>val </span>source = Manager.<span>manager</span>.take(<span>1</span>)<br/>    <span>val </span>sink = Sink.<span>actorRef</span>[Groceries](probe.ref, NotUsed)<br/>    source.via(Boy.<span>shopFlow</span>).runWith(sink)<br/>    probe.expectMsgType[Groceries]<br/>  }<br/>}</pre>
<p>We test that there will be one message coming from the flow if one message goes into it. This time we're not waiting for the future to complete but formulate our assumptions with the syntax the <kbd>TestProbe</kbd> supports.</p>
<p>By now, you should have recognized the pattern we're using. First, set up the source and/or the sink, then wait for the flow to complete, and finally verify assumptions about the output of the flow. Surely enough, the Akka team abstracted this in a special test kit provided for Akka Streams.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Streams TestKit</h1>
                </header>
            
            <article>
                
<p>In order to use the Akka Streams <kbd>TestKit</kbd>, we need to add another dependency to our project configuration to <kbd>build.sbt</kbd>:</p>
<pre><span>libraryDependencies </span>++= <span>"com.typesafe.akka" </span>%% <span>"akka-stream-testkit" </span>% akkaVersion % <span>Test</span></pre>
<p>Let's see how the <kbd>TestSink</kbd> and <kbd>TestSource</kbd> provided by this module can simplify the way we formulate our testing logic. Now we'll test the whole flow from the <kbd>Boy</kbd> to the <kbd>Baker</kbd>:</p>
<pre><span>"the whole flow" </span>should {<br/>  <span>"produce cookies" </span>in {<br/>    <span>val </span>testSink = TestSink.<span>probe</span>[ReadyCookies]<br/>    <span>val </span>source = TestSource.<span>probe</span>[ShoppingList]<br/>    <span>val </span>(publisher: TestPublisher.Probe[ShoppingList],<br/>         subscriber: TestSubscriber.Probe[ReadyCookies]) =<br/>      source.via(Bakery.<span>flow</span>).toMat(testSink)(Keep.<span>both</span>).run()<br/>    subscriber.request(<span>10</span>)<br/>    publisher.sendNext(<span>ShoppingList</span>(<span>30</span>, <span>1000</span>, <span>100</span>, <span>100</span>))<br/>    subscriber.expectNext(<span>40</span>.seconds, <span>ReadyCookies</span>(<span>12</span>))<br/> subscriber.expectNext(<span>40</span>.seconds, <span>ReadyCookies</span>(<span>12</span>))<br/>  }<br/>}</pre>
<p>In this scenario, we first create <kbd>TestSink</kbd> and <kbd>TestSource</kbd> probes using constructors provided by the testing toolkit. Then we materialize them to <kbd>publisher</kbd> and <kbd>subscriber</kbd> in order to be able to drive the flow. Here, we're using the <kbd>toMat</kbd> syntax again. Until now, we implicitly used the default value (<kbd>Keep.left</kbd>) but now we want to keep both materialized results of the flow and of the sink. Running the flow returns its materialized instance which is a pair: <kbd>TestPublisher</kbd> and <kbd>TestSubscriber</kbd>. </p>
<p>We then use <kbd>subscriber</kbd> to request 10 messages from the flow. In Reactive Streams, the producer is not supposed to send anything downstream until there is demand, and we express the demand with this call. We expect the flow to output elements representing <kbd>RawCookies(12)</kbd>. Thus, our <kbd>subscriber.request</kbd> translates to 120 cookies to be produced.</p>
<p>Having this demand, we then initiate the flow by sending the next shopping list from the source. </p>
<p>Finally, we expect at least two batches of cookies to arrive at the sink. We provide sufficient time for the stream to push messages through all of the stages, accounting for delays in the mixing and baking stage.</p>
<p>We also cannot reliably predict how many cookies will be made because of the way we drop messages at the mixing stage in the case of <kbd>MotorOverheatException</kbd> and <kbd>SlowRotationSpeedException</kbd>.</p>
<p>In this example, we barely scratched the surface of all of the possibilities provided by the Akka Streams <kbd>TestKit</kbd>. As you develop Akka Streams-based systems it is worth revisiting both the documentation and the source code of the library and keeping in mind the different testing approaches they offer.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Running the application</h1>
                </header>
            
            <article>
                
<p>Please refer to <a href="bc164888-625c-460a-9b0b-e6c45c9eb074.xhtml">Appendix A</a>, <em>Preparing the Environment and Running Code Samples</em>, if you still have to install Java and/or SBT.</p>
<p>We will run our application in the terminal the same way we did in <a href="87c2e446-3730-49ae-b86b-fc8269678399.xhtml">Chapter 11</a><span>, </span><em>An Introduction to the Akka and Actor Models</em> and <a href="caabef7a-c854-4b39-b8fb-ac17b8ba6eee.xhtml">Chapter 12</a><span>, </span><em>Building Reactive Applications with Akka Typed</em>, using two separate terminal sessions for <kbd>Store</kbd> and <kbd>BakeryApp</kbd> using the following commands:</p>
<ul>
<li><kbd>sbt "runMain ch13.BakeryApp"</kbd></li>
<li><kbd>sbt "runMain ch13.Store"</kbd></li>
</ul>
<p>We prefer this method because of its conciseness. If you're about to run the app in interactive mode, please consult <a href="87c2e446-3730-49ae-b86b-fc8269678399.xhtml">Chapter 11</a>, <em>An Introduction to the Akka and Actor Models</em>, for a detailed explanation of this approach.</p>
<p>In our examples, we expect the remote <kbd>Store</kbd> app to be available at the moment we start the main <kbd>Bakery</kbd> stream. Because of this, we have to start the <kbd>Store</kbd> first or the <kbd>BakeryApp</kbd> will exit with an exception at the moment it fails to connect to the store. The next screenshot shows two terminal windows with commands to run the <kbd>Store</kbd> entered in the left window and the <kbd>BakeryApp</kbd> started in the right window. In the following screenshot, we can see that the <kbd>Store</kbd> has already been running for some time and the BakeryApp has just started to execute:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/471c2012-abc6-46db-87a0-284f5147748a.png" width="2420" height="1296"/></p>
<p class="mce-root"/>
<p>The <kbd>Bakery</kbd> in the right terminal will now run until stopped with the <em>Ctrl</em> + <em>C</em> shortcut or the terminal window is closed.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="p1">Traditional streaming solutions suffer from one of two issues. In the case of pulling, there is a need for locking or extensive use of resources on the side of the quick consumer. In the case of pushing, there is a possibility that a number of messages to process will grow bigger than the available memory, requiring a slow consumer to drop messages or terminate because of the memory overflow. Reactive Streams solves this problem by defining dynamic asynchronous pull-push with back pressure. Akka Streams implements the Reactive Streams standard using Akka which allows for seamless integration with both technologies.</p>
<p class="p1">Streams in Akka are built from blocks called stages or flows. These blocks can be nested and connected to each other, forming graphs. Graphs with single input and single output can be made runnable by connecting them to the source and sink. Graph definitions can be freely shared and reused.</p>
<p class="p1">Running a graph requires a materializer and produces a materialized value depending on the graph and sink definition.</p>
<p class="p1">Error handling in Akka Streams can be done in different ways including catching errors directly in the flow definition, defining a recovery method with optional retries and/or overriding a supervision strategy for processing stages which support it.</p>
<p class="p1">The modular nature of the flow definition allows for straightforward testing of single stages and their combinations. In order to reduce boilerplate for recurring test setup and expectation definitions, Akka Streams offers special test toolkit.</p>
<p>The reader is encouraged to take a look at the official Akka documentation at<span> </span><a href="https://doc.akka.io/docs/akka/current/stream/index.html">https://doc.akka.io/docs/akka/current/stream/index.html </a>to explore the possibilities offered by Akka Streams in more detail.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<p style="margin-left: 2em"/>
<ol>
<li>Name two different modes associated with "classic" streams. What is problematic with them?</li>
<li>Why are Reactive Streams considered as workable in dynamic pull-push mode?</li>
<li>What are the typical building blocks of Akka Stream's graph?</li>
<li>How do we convert a graph into a runnable graph?</li>
<li>What is the main goal of having materialization as a separate explicit step?</li>
<li>Describe the effects of applying different supervision strategies.</li>
<li>Which main abstractions provide an Akka Streams <kbd>TestKit</kbd>? Why are they useful?</li>
</ol>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<ul>
<li><span>Christian Baxter, </span><span><em>Mastering Akka: </em></span><em><span>Master the art of creating scalable, concurrent, and reactive applications using Akka</span></em></li>
<li><span>Héctor Veiga Ortiz, Piyush Mishra,<em> </em></span><em>Akka Cookbook: Learn how to use the Akka framework to build effective applications in Scala</em></li>
<li><span>Rambabu Posa, <em>Scala Reactive Programming: Build fault-tolerant, robust, and distributed applications in Scala</em></span></li>
</ul>


            </article>

            
        </section>
    </div>



  </body></html>