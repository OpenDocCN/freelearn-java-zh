<html><head></head><body>
        <section>

                            <header class="header-title chapter-title">
                    Best Practices and Broker Monitoring
                </header>
            
            <article>
                
<p>The previous chapters of this book focused on the setup of a successful microservice architecture using RabbitMQ at the example company <strong>Complete Car</strong> (<strong>CC</strong>). Many RabbitMQ features were included, however, no system is complete without an understanding of the best practices to use in its implementation. As with all production systems, proper monitoring and alerts are also needed to stay on top of things.</p>
<p>CC's cluster is stable and there are no performance issues. This chapter summarizes the key takeaways learned from CC's system, including best practices and recommendations for queues, routing, exchanges, message handling, and more.</p>
<p>This chapter explores the following topics:</p>
<ul>
<li>How to avoid losing messages</li>
<li>Keeping queues and brokers clean</li>
<li>Routing best practices</li>
<li>Networking over connections and channels</li>
<li>Exploring key takeaways</li>
<li>Monitoring – querying the REST API</li>
</ul>
<p>This chapter is an ideal reference guide when setting up infrastructure using RabbitMQ. Refer back to the key takeaways, best practices, and monitoring tips in this chapter for valuable insights when putting RabbitMQ into production.</p>
<h1 id="uuid-e9f65d07-dffa-46da-803c-e322eea666da">How to avoid losing messages</h1>
<p>Losing messages can be avoided by following the best practices in this section. For the most part, CC has followed the best practice of <strong>keeping queues short</strong> and efficient. Queues that contain too many messages have a negative impact on the broker's performance. An identified <strong>high RAM usage</strong> could indicate that the number of queued messages rapidly went up.</p>
<p>Here are some best practice recommendations for how to not lose messages in RabbitMQ:</p>
<ul>
<li>Use at least three nodes in the RabbitMQ cluster, and the <strong>quorum queue</strong> type to spread messages to different nodes.</li>
<li>If it is absolutely imperative that all messages are processed, declare a queue as <strong>durable</strong> and set the message delivery mode to <strong>persistent</strong>, as described in <a href="377ec533-342d-4a08-9011-7176de197886.xhtml">Chapter 2</a>, <em>Creating a Taxi Application</em>. Queues, exchanges, and messages need to be able to handle any restarts, crashes, or hardware failures that may occur.</li>
</ul>
<p>Here are some clarifications regarding message handling in RabbitMQ:</p>
<ul>
<li>Understanding the trade-offs that come with persistence is essential when designing a durable system architecture. <strong>Lazy queues</strong>, though using transient messages, have a similar effect on performance.</li>
<li>Using transient messages with durable queues creates speed without losing configuration but may result in message loss.</li>
</ul>
<p>What if all these best practices are followed and messages are still in jeopardy of being lost? The next section covers the dead letter exchange, so messages that would potentially be gone forever have a place to wait until they can be processed.</p>
<h2 id="uuid-c9bba823-1825-46f5-91a3-2e3fc31b7f57">Using a dead letter exchange</h2>
<p><span>Even when using durable queues and persistent messages, issues can occur that result in unhandled messages. A TTL might be set, a queue length might have been exceeded or the message might have been negatively acknowledged by the consumer. As a best practice, the routing key of the message should specify</span> <kbd>x-dead-letter-routing-key</kbd> <span>so that the message is never dropped. Attach queues to the exchange and manage messages programmatically. Try to avoid sending messages to the same exchange as this may result in a form of infinite recursion. Some messages might be unmanageable to handle and continually end up in the exchange. Make sure to handle these errors in the programming logic.</span></p>
<p>Set the <kbd>x-dead-letter-routing-key</kbd> property in the declaration of a queue. This helps with performance and separate error handling by components in the architecture, as described in <em><a href="bece97d2-6653-459f-bbdc-6e47f343c1d3.xhtml">Chapter 4</a>, Tweaking Message Delivery</em>.</p>
<p>It is recommended for applications that often get hit by spikes of messages to set a queue max-length. The queue max-length helps keeping the queue short by discarding messages from the head of the queue. The max-length can be set to a number of messages, or a set number of bytes. </p>
<h2 id="uuid-36f4d320-df60-4f9f-90af-421a204e7bc3">Handling acknowledgments and confirms</h2>
<p>In the event of a connection failure, a message in transit may get lost. Acknowledgments provide an alert to the server and the clients if messages need to be retransmitted. The client can either ack the message when it is received or when it has processed the message. However, it is important to remember that the application that consumes important messages should not ack until handled. That way, unprocessed messages from crashes or exceptions don't end up being missed. A publisher confirmation requires the server to confirm a message has been received from a publisher.</p>
<p>Confirms can also have an impact on system performance, but they are required if the publisher must process messages at least once.</p>
<h2 id="uuid-2e9156da-d1f8-4b51-b106-dd5efbbbe405">Best practices of message handling</h2>
<p>Queues and clients handle the burden of their payloads – messages. To further improve performance, fine-tune messages and message handling.</p>
<h3 id="uuid-2e21c8d5-4cee-4909-97fd-45820fe2f0a1">Limiting message size</h3>
<p>The number of messages sent per second is a much larger concern than the size of the messages themselves. However, sending large messages is not a best practice, and neither is sending too small messages since AMQP adds a small <span class="st">packet</span> overhead to all messages sent. </p>
<p>Examine messages to see whether they can be split and sent to different queues, as follows:</p>
<ul>
<li>Split iterable data into chunks and send a small chunk per message.</li>
<li>Store large files in a distributed store, such as Hadoop or networked attached storage.</li>
</ul>
<ul>
<li>Split the architecture into more modular components with a queue per component.</li>
<li>Offload appropriate metadata to a key-value store.</li>
</ul>
<p>While sending large messages can be avoided, bandwidth, architecture, and fail-over limits are a consideration. The size of the message will depend on the application but should be as small as possible.</p>
<h3 id="uuid-ce89db8f-3e3f-4063-aef2-a487a00d4ea9">Using consumers and prefetching</h3>
<p class="mce-root">Setting a prefetch value distributes workloads evenly across the system. Prefetching is allowed in RabbitMQ, but it is important to remember that prefetching is only effective when all consumers are busy.</p>
<p>RabbitMQ must manage consumption across queues and consumers. A prefetch value that is too low keeps the consumers idle as they wait for messages to arrive, which in turn will slow down the broker's ability to handle requests. Setting the prefetch value too high keeps one consumer busy while the rest remain idle, as described in <em><a href="4e1d39f3-47d1-4423-916c-2c2c01c75887.xhtml"/><a href="4e1d39f3-47d1-4423-916c-2c2c01c75887.xhtml">Chapter 3</a>, Sending Messages to Multiple Taxi Drivers</em>.</p>
<p>If processing time is low and the network is stable, then the prefetch value can be increased. In this case, the prefetch value can be determined easily by dividing the total round trip time by the processing time.</p>
<p>If there are many consumers and a longer processing time, the prefetch value trends lower. If processing times are long enough, set the prefetch limit to 1.</p>
<p>As queues get busier with demand, more system resources are consumed. Keeping the queues and brokers clean is imperative for good performance, which is covered in the next section.</p>
<h1 id="uuid-502a02dc-ce29-4e94-a07f-1582f509b360">Keeping queues and brokers clean</h1>
<p>A clean broker is an efficient broker. To keep power and space at an optimum level, making sure queues and brokers are clean is easy. RabbitMQ provides mechanisms for auto-deleting messages and queues to keep space free. These include setting the <strong>time to live</strong> (<strong>TTL</strong>) and auto-deletion of unused queues, which are detailed in the following sections.</p>
<h2 id="uuid-b9896432-048f-4d56-abe1-44819683e71e">Setting the TTL for messages or the max-length on queues</h2>
<p>Queues providing messaging support for long-running processes may grow extremely large. A too large queue might affect the performance of the broker. Setting the <strong>TTL </strong>allows messages to be removed from the queue after a certain time. If specified, these messages enter the dead letter exchange. This saves more messages and even handles potential issues without losing data.</p>
<p>Set a reasonable <strong>TTL</strong> with the <kbd>x-message-ttl</kbd> property when declaring a queue. Make sure to provide <kbd>x-dead-letter-exchange</kbd> and <kbd>x-dead-letter-routing-key</kbd> to avoid losing messages entirely.</p>
<p class="mce-root">It is recommended for applications that often get hit by spikes of messages to set a queue max-length. The queue max-length helps keeping the queue short by discarding messages from the head of the queue. The max-length can be set to a number of messages, or a set number of bytes. </p>
<h2 id="uuid-81938646-44a1-41ab-b6d1-b6b99cfc8910">Auto-deleting unused queues</h2>
<p>In addition to keeping queues from becoming overly large, queues can be dropped based on use.</p>
<p>There are three ways to delete an unused queue automatically, as follows:</p>
<ol>
<li>Set an expiration policy for the queue using the <kbd>x-expires</kbd> property on the declaration, keeping queues alive only for a number of non-zero milliseconds when unused.</li>
<li>Set the <kbd>auto-delete</kbd> queue property to <kbd>true</kbd> on the declaration. This means the queue will be dropped after the following scenarios:</li>
</ol>
<ul>
<li style="padding-left: 60px"> The initial connection is made.</li>
<li style="padding-left: 60px"> The last consumer shuts down.</li>
<li style="padding-left: 60px"> The channel/connection is closed or the queue has lost the <span><strong>Transmission Control Protocol</strong> (</span><strong>TCP</strong>) connection with the server.</li>
</ul>
<ol start="3">
<li>Set the exclusive property to <kbd>true</kbd> on queue declaration so that the structure belongs to the declaring connection and is deleted when the connection closes.</li>
</ol>
<p>Sometimes, the journey itself is what creates inefficiency in a message queue. To make sure messages are taking the best path possible, follow the best practices for routing found in the next section.</p>
<h1 id="uuid-471e1d1a-0999-4174-a262-e5daf02f0037">Routing best practices</h1>
<p>As a best practice, direct exchanges are the fastest to use. Even when using direct exchanges, those with multiple bindings require more time to calculate where messages must be sent. There are some additional best practices to consider for routing.</p>
<h2 id="uuid-e48e78cf-470c-4b73-8f9c-076eff1f9ac4">Designing a system with routing in mind</h2>
<p>Every endpoint is a service or application. Unlike CC, which operates between a car and, for the most part, a single application layer, many microservice architectures pass messages through dozens of services.</p>
<p>CC designed their system architecture around small services. They combined operations where it did make sense. After designing a smaller system, they consider where additional exchanges or queues could be beneficial. This kept the overall design small enough without limiting processing power.</p>
<h1 id="uuid-babf8390-51d1-4972-a3f4-13362a3c9bd7">Networking over connections and channels</h1>
<p>Thousands of connections add up to a heavy burden on a RabbitMQ server, causing it to run out of memory and crash. A large number of connections and channels can also negatively impact the RabbitMQ management interface due to the large number of performance metrics being processed. To avoid this, configure each application to create an extremely small number of connections – 1, if possible. Instead of using multiple connections, establish a channel for each thread. Each connection should be long-lived and the following best practices should be considered depending on the application structure.</p>
<p>Remember that even if new hardware offers hundreds of threads, only the number of channels set can be established and this number should be kept from growing too large. As some clients don't make channels thread-safe, it is best not to share channels between threads. Doing so may create a race condition, which could completely crash the application.</p>
<p>Repeatedly opening and closing connections and channels is also detrimental to system performance. Doing so increases latency as more TCP packets are sent over the network.</p>
<h2 id="uuid-9000b0cf-61d2-4c1b-9d37-a37e7160ae11">Using TLS and AMQPS for security</h2>
<p>RabbitMQ can be connected over AMQPS, which is the AMQP protocol wrapped in TLS. Data passed over the network is encrypted, but there is a performance impact to consider. To maximize performance, use VPC or VPN peering instead since they provide a private, isolated environment for traffic and do not involve the AMQP client and server directly.</p>
<p>Do not expose the backend over the frontend. The CC example is simplified. In reality, there would likely be an application layer added between unknown users and the broker.</p>
<h2 id="uuid-bdd99a5a-ab9d-4d02-8638-ed66aa5c901a">Separate connections</h2>
<p>By default, RabbitMQ will reduce the speed of connections that publish too quickly for queues to keep up. RabbitMQ simply applies back-pressure on the TCP connection, which places it in flow control. A flow-controlled connection shows a state of flow in the management UI and through HTTP API responses. This means the connection is experiencing blocking and unblocking several times a second to keep the message flow rate at a level that the rest of the server and the queues can handle.</p>
<p>When the publisher is using the same TCP connection as the consumer, messages can be blocked while replying to the broker. The server may not receive the acks from the client, which will have a negative impact on the speed and cause it to be overwhelmed. Achieving higher throughput is, therefore, best accomplished through separate connections for publishers and consumers.</p>
<h2 id="uuid-9a916bef-da72-4bd9-9088-481f8f7dde76">Splitting queues over different cores</h2>
<p>The CC infrastructure runs on multiple cores. To achieve better performance, queues are split among different cores and nodes. Queues in RabbitMQ are bound to the node where they are first declared. This holds true even for clustered brokers, as all messages routed to a specific queue go to the node where the queue lives. One queue in RabbitMQ can handle up to 50,000 messages a second. Better performance is therefore achieved when queues are split over different cores and nodes, and when they are spread between multiple queues.</p>
<p>It is possible to manually split queues evenly between nodes, but this can be difficult to remember. Alternatively, there are two plugins to assist with organizing multiple nodes or a single node cluster with multiple cores. These are the <strong>Consistent Hash Exchange</strong> and the <strong>RabbitMQ sharding</strong> plugins.</p>
<h3 id="uuid-b0ef0106-f527-4b4c-a812-ed455e8fb988">RabbitMQ sharding</h3>
<p>Sharding makes it easy to distribute messages among queues on different nodes. A queue can be spread among multiple actual queues. Once an exchange is defined as sharded, the supporting queues automatically start on every cluster node with messages spreading accordingly, as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-849 image-border" src="assets/284071c3-7926-4dae-8b99-dca7de34ec89.png" style="width:29.67em;height:25.25em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Fig 7.1: Sharding among queues</div>
<p>The routing keys ensure an even distribution of messages among queues. The plugin expects you to run a consumer per shard with new nodes being automatically incorporated. Note that it's important to consume from all queues. The plugin provides a centralized place to send messages, and load-balances messages across nodes by adding queues across the cluster. Read more about the RabbitMQ sharding plugin at: <a href="https://github.com/rabbitmq/rabbitmq-sharding">https://github.com/rabbitmq/rabbitmq-sharding</a>.</p>
<h3 id="uuid-fa613b61-43ef-46de-9095-b549ea3e3e88">Consistent Hash Exchange</h3>
<p>RabbitMQ offers another plugin that helps load-balance messages through the Consistent Hash Exchange. Based on the routing key, <strong>bound</strong> queues in this exchange are sent messages equally. This optimizes the use of a cluster with multiple cores, as the plugin creates a hash of the routing key and is consistent about spreading messages between queues bound to the exchange, ensuring optimal use over many cores in a cluster.</p>
<p>Read more about the Consistent Hash Exchange plugin at: <a href="https://github.com/rabbitmq/rabbitmq-consistent-hash-exchange">https://github.com/rabbitmq/rabbitmq-consistent-hash-exchange</a>.</p>
<h1 id="uuid-4b3b7b4c-3c6b-47a9-a6e2-2db9d13f0db2">Exploring key takeaways</h1>
<p>For the sake of simplification, optimization can be broken into two forms, and since cars have been a popular topic in this book, let's stick with that theme.</p>
<p><strong>Ferrari</strong> <strong>–</strong> <strong>fast and smooth</strong>: If the system must have fast performance and high throughput, use a single node. Keep queues as short as possible, and set the max length or TTL if possible. Do not set the lazy queue policies to keep retrieval time short. Use transient messages, rather than persistent ones, for the same reason. Take advantage of using multiple queues and consumers, providing maximum throughput. For the fastest possible throughput, manual acks should be disabled. Always strive to use the latest stable RabbitMQ version.</p>
<p><strong>Volvo</strong> <strong>–</strong> <strong>stable and reliable</strong>:<strong> </strong>A system that must be highly available and cannot afford to lose messages should have durable queues and send persistent messages. Queues should still be kept short.</p>
<p>It is recommended that clustering is set up through quorum queues. If mirrored queues are already in use, add the lazy queue policy to get a more stable setup. Make sure that three or five nodes are used in the system to achieve high availability. When setting up a RabbitMQ cluster, split queues among different cores and into different nodes, using the Consistent Hash Exchange or sharding plugins to keep everything running smoothly and efficiently. Always strive to use the latest stable RabbitMQ version.</p>
<p>Now that the best practice tips have been covered, it's time to consider what should occur if and when something goes wrong. Monitoring the cluster and setting alarm policies are two very important finishing touches to any production environment.</p>
<h1 id="uuid-59165335-cf23-448d-816d-a09223db7e1c">Monitoring – querying the REST API</h1>
<p>There are two main ways to retrieve live information when monitoring a RabbitMQ broker: one through the <kbd>rabbitmqctl</kbd> command-line tool and another through the <strong>REST API</strong> exposed over HTTP by the management console.</p>
<p>Any monitoring system can use these tools to collect metrics and report them to the log, analytics, reporting, and alert frameworks. Information could be pushed to external logging services for further analysis, as an example.</p>
<p>Since CC installed the management console, as described in <a href="4f4722d3-131f-4c38-9ea0-4c03e8545175.xhtml">Chapter 1</a><em>, A Rabbit Springs to Life</em>, the team opts to use the rich, well-documented API over the command line. RabbitMQ provides documentation at the <kbd>http://localhost:15672/</kbd> API on any node that has the management plugin installed. It is possible to retrieve the same raw metrics over the command line, albeit without graphics.</p>
<div class="packt_infobox">Keep in mind that the management console is backed by the API, so anything that is seen and done within a browser can be done through the API.</div>
<p>RabbitMQ exposes a variety of different metric types for collection, as discussed in the preceding sections. These include, but are not limited to, the following:</p>
<ul>
<li><strong>Node status</strong>: Testing the performance of RabbitMQ involves executing a set of commands to declare an aliveness-test queue and then publishing as well as consuming it. Set an alarm to fire if the command returns <kbd>0</kbd> (no messages consumed) through the appropriate request:</li>
</ul>
<pre style="padding-left: 60px">curl -s http://cc-admin:******@localhost:15672/api/aliveness-test/cc-prod-vhost | grep -c "ok"</pre>
<ul>
<li><strong>Cluster size</strong>: Testing the cluster size is useful for discovering network partitions. Set an alarm to fire if the cluster size is lower than expected:</li>
</ul>
<pre style="padding-left: 60px">curl -s http://cc-admin:******@localhost:15672/api/nodes | grep -o "contexts" | wc -l</pre>
<p style="padding-left: 60px">CC uses a <kbd>bash</kbd> script and Python to send an error when the number of nodes is less than expected.</p>
<ul>
<li><strong>Federation status</strong>: Federated queues may become unlinked due to a restart or another issue. Check the active upstream links on the central log aggregation broker and raise an alarm if it's less than the optimal size (<kbd>3</kbd>, in CC's case), as follows:</li>
</ul>
<pre style="padding-left: 60px">curl -s http://cc-admin:******@localhost:15672/api/federation-links/cc-prod-vhost | grep -o "running" | wc -l</pre>
<ul>
<li><strong>Queues' high watermarks</strong>: Cloud-based brokers sometimes offer scale at low cost but with message limits. In other cases, message latency is an issue. Ensure that the number of available messages in a queue is below a certain threshold:</li>
</ul>
<pre style="padding-left: 60px">curl -s -f http://cc-admin:******@localhost:15672/api/queues/cc-prod-vhost/taxi-dlq | jq '.messages_ready'</pre>
<p style="padding-left: 60px">In CC's case, they want to verify that the <kbd>taxi-dlq</kbd> queue has less than 25 messages. Otherwise, they raise an alarm indicating a bottleneck. Scripts need to handle a graceful failure if the queue does not exist.</p>
<ul>
<li><strong>Overall message throughput</strong>: Monitoring the intensity of messaging traffic on a particular broker makes it possible to increase or decrease resources as required. Collect message rates with the following command:</li>
</ul>
<pre style="padding-left: 60px">curl -s http://cc-admin:******@localhost:15672/api/vhosts/cc-prod-vhost | jq '.messages_details.rate'</pre>
<p style="padding-left: 60px">CC adds an alarm if the throughput threshold exceeds the upper limit of what one its brokers can withstand.</p>
<p style="padding-left: 60px">Some metrics come with rigid upper limits whose values are also available through the API. A recommendation is to raise an alarm whenever a threshold of 80 percent of the upper limit is reached. The following scripts return false when the alarm must be raised. These metrics include the following:</p>
<ul>
<li><strong>File descriptors</strong>: Many OSes have file descriptor limits. The performance of the message persistence on the disk can be affected if not enough descriptors are available. The number of file descriptors used can be compared with the amount of available file descriptors:</li>
</ul>
<pre style="padding-left: 60px">curl -s http://cc-admin:******@localhost:15672/api/nodes/rabbit@${host} | jq '.fd_used&lt;.fd_total*.8'</pre>
<p style="padding-left: 60px">It is possible to increase the number of available file descriptors on macOS X and Linux. File descriptors are used to access other files. It's a good idea to check throughputs if this limit is exceeded as well.</p>
<ul>
<li><strong>Socket descriptors</strong>: Socket descriptors maintain a handle to an individual socket for a connection. RabbitMQ stops accepting new connections if these descriptors are exhausted, which is a common issue with large clusters:</li>
</ul>
<pre style="padding-left: 60px">curl -s http://cc-admin:******@localhost:15672/api/nodes/rabbit@${host} | jq '.sockets_used&lt;.sockets_total*.8'</pre>
<p style="padding-left: 60px">Linux uses file descriptors for sockets, adjusting the count with the <kbd>ulimit</kbd> command. Using more channels and fewer connections, in line with best practices, helps to handle this issue as well.</p>
<ul>
<li><strong>Erlang processes</strong>: There is an upper limit to the number of processes an Erlang virtual machine creates. Although typically near 1 million processes, each requires resources to run. The number of Erlang processes used can be compared with the Erlang process limit:</li>
</ul>
<pre style="padding-left: 60px">curl -s http://cc-admin:******@localhost:15672/api/nodes/rabbit@${host} | jq '.proc_used&lt;.proc_total*.8</pre>
<p style="padding-left: 60px">An OS thread is not created for each process. Still, each uses a lightweight stack and requires time to schedule and maintain.</p>
<ul>
<li><strong>Memory and disk space</strong>: If memory or disk space is exhausted, RabbitMQ will not work properly – for example, flow control can be triggered. Check that there are sufficient resources and tune the hardware appropriately.<br/>
The total amount of memory used should be less then 80 percent of the memory usage high watermark:</li>
</ul>
<pre style="padding-left: 60px">curl -s http://cc-admin:******@localhost:15672/api/nodes/rabbit@${host} | jq '.mem_used&lt;.mem_limit*.8'curl -s</pre>
<p style="padding-left: 60px">The disk free space limit should be compared to the current free disk space:</p>
<pre style="padding-left: 60px">http://cc-admin:******@localhost:15672/api/nodes/rabbit@${host} | jq '.disk_free_limit&lt;.disk_free*.8'</pre>
<p>In addition to metrics, a working instance runs the following programs:</p>
<ul>
<li><kbd>rabbitmq-server</kbd>: This is obvious but should not be forgotten!</li>
<li><kbd>epmd</kbd>: The Erlang port mapper daemon, <kbd>epmd</kbd>, plays a critical role in clustering and networking. It is advisable to set up scripts to check that these services are running. List programs using <kbd>ps</kbd> on Linux or macOS X and <kbd>Get-Process</kbd> in Windows.</li>
</ul>
<p><kbd>ERROR REPORT</kbd> entries in the main log file reveal issues within the system. In Linux, RabbitMQ stores log files at <kbd>/var/log/rabbitmq/rabbit@&lt;hostname&gt;.log</kbd>. F<span>or more information, </span>check the configuration file at <a href="https://www.rabbitmq.com/logging.html#log-file-location">https://www.rabbitmq.com/logging.html#log-file-location</a>.</p>
<h1 id="uuid-2f666cb5-3955-4d57-abb4-d36e1bfdd05a">Summary</h1>
<p><span>This chapter concludes the study of microservices built on RabbitMQ with an examination of best practices as well as monitoring. The book went through the application funnel for CC, beginning with the basic service and scaling. New features and processes were added with ease and without interruption to the CC application. Over time, CC’s development team created a holistic, useful, reliable, long-life application. To avoid failures that could lead to bad user experience or even data loss, the CC team implemented a monitoring strategy. Collecting, logging, analyzing, and reporting metrics were outlined as CC formed an alert plan. Finally, the alert parameters were set up through the RabbitMQ management console.</span></p>
<p><span>Congratulations on completing your journey through this book! Armed with sufficient RabbitMQ wrangling skills, the next step is to create an instance for yourself. An easy way to get started with RabbitMQ is through the manager of the largest fleet of RabbitMQ clusters in the world – hosted RabbitMQ provider CloudAMQP.</span></p>


            </article>

            
        </section>
    </body></html>