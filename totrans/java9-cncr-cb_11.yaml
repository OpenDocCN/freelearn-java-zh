- en: Concurrent Programming Design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Using immutable objects when possible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoiding deadlocks by ordering locks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using atomic variables instead of synchronization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Holding locks for as short time as possible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delegating the management of threads to executors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using concurrent data structures instead of programming yourselves
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Taking precautions using lazy initialization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the fork/join framework instead of executors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoiding the use of blocking operations inside a lock
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoiding the use of deprecated methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using executors instead of thread groups
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using streams to process big data sets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other tips and tricks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Implementing a concurrent application is a difficult task. You have more than
    one thread in an execution at a time and all of them share resources, such as
    files, memory, objects, and so on. You have to be very careful with the design
    decisions you take. A bad decision can affect your program in a way that it would
    lead to poor performance or simply provoke data inconsistency situations.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I've included some suggestions to help you take correct design
    decisions, which would make your concurrent application better.
  prefs: []
  type: TYPE_NORMAL
- en: Using immutable objects when possible
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you develop an application in Java using object-oriented programming, you
    create some classes formed by attributes and methods. The methods of a class determine
    the operations that you can do with the class. Attributes store the data that
    defines the object. Normally, in each class, you implement some methods to establish
    the value of the attributes. Also, objects change as the application runs, and
    you use those methods to change the value of their attributes.
  prefs: []
  type: TYPE_NORMAL
- en: When you develop a concurrent application, you have to pay special attention
    to the objects shared by more than one thread. You must use a synchronization
    mechanism to protect access to such objects. If you don't use it, you may have
    data inconsistency problems in your application.
  prefs: []
  type: TYPE_NORMAL
- en: There are special kinds of objects that you can implement when you work with
    concurrent applications. They are called **immutable objects**; their main characteristic
    is that they can't be modified after they are created. If you need to change an
    immutable object, you must create a new one instead of changing the values of
    the attributes of the object.
  prefs: []
  type: TYPE_NORMAL
- en: 'This mechanism presents the following advantages when you use them in concurrent
    applications:'
  prefs: []
  type: TYPE_NORMAL
- en: These objects cannot be modified by any thread once they are created, so you
    won't need to use any synchronization mechanism to protect access to their attributes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You won't have any data inconsistency problems. As the attributes of these objects
    cannot be modified, you will always have access to a coherent copy of the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The only drawback of this approach is the overhead: creating new objects instead
    of modifying existing ones.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Java provides some immutable classes, such as the `String` class. When you
    have a `String` object and you try to assign a new value to it, you are creating
    a new `String` object instead of modifying the old value of the object. For example,
    check out the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In the second line, JVM creates a new `String` object.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The example of this recipe has been implemented using the Eclipse IDE. If you
    use Eclipse or a different IDE, such as NetBeans, open it and create a new Java
    project.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow these steps to implement an immutable class:'
  prefs: []
  type: TYPE_NORMAL
- en: Mark the class as `final`. It should not be extended by another class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All the attributes must be `final` and `private`. You can assign a value to
    an attribute only once.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Don't provide methods that can assign a value to an attribute. Attributes must
    be initialized in the constructor of the class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If any field value object is mutable (for example, `java.util.Date`), always
    return a defensive copy in the getter field.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Don''t leak the `this` reference from the immutable class constructor (for
    example, the following code that leaks the `this` reference before the constructor
    is complete):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you want to implement a class that stores the first and last name of a person,
    you would normally implement something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'You can convert this class into an immutable class by following the rules explained
    earlier. The following is the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Essentially, you followed the basic principles of an immutable class, which
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The class is marked as `final`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The attributes are marked as `final` and `private`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The value of the attributes can only be established in the constructor of the
    class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Its methods return the value of an attribute, but they don't modify them.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For mutable attributes (the `birthDate` attribute in our case), we return a
    defensive copy of the `get()` method by creating a new object.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Immutable objects can't always be used. Analyze each class of your application
    to decide whether you can implement them as immutable objects or not. If you can't
    implement a class as an immutable class and its objects are shared by more than
    one thread, you must use a synchronization mechanism to protect access to the
    attributes of the class.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *Using atomic variables instead of synchronization* recipe in this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoiding deadlocks by ordering locks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you need to acquire more than one lock in the methods of your application,
    you must be very careful with the order in which you get control of your locks.
    A bad choice can lead to a deadlock situation.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, you will implement an example of a deadlock situation, then
    learn how to solve it.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow these steps to implement the example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a class named `BadLocks` with two methods, named `operation1()` and
    `operation2()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Let's analyze the preceding code. If a thread calls the `operation1()` method
    and another thread calls the `operation2()` method, you can have a deadlock. If
    both `operation1()` and `operation2()` execute their respective first sentences
    at the same time, you will have the `operation1()` method waiting to get control
    of `lock2` and the `operation2()` method waiting to get control of `lock1`. Now
    you have a deadlock situation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To solve this situation, you can follow this rule:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you have to get control of more than one lock in different operations, try
    to lock them in the same order in all methods.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, release them in inverse order and encapsulate the locks and their unlocks
    in a single class. This is so that you don't have synchronization-related code
    distributed throughout the code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using this rule, you will avoid deadlock situations. For example, in the case
    presented earlier, you can change `operation2()` to first get `lock1` and then
    `lock2`. Now if both `operation1()` and `operation2()` execute their respective
    first sentences, one of them will be blocked waiting for `lock1` and the other
    will get `lock1` and `lock2` and they will do their operations. After this, the
    blocked thread will get the `lock1` and `lock2` locks and it will do its operation.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find a situation where a requirement prevents you from getting the locks
    in the same order in all the operations. In this situation, you can use the `tryLock()`
    method of the `Lock` class. This method returns a `Boolean` value to indicate
    whether you have control of the lock. You can try to get all the locks that you
    need to do the operation using the `tryLock()` method. If you can't get control
    of one of the locks, you must release all the locks that you may have had and
    start the operation again.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *Holding locks for as short a time period as possible* recipe in this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using atomic variables instead of synchronization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you have to share data between multiple threads, you have to protect access
    to that piece of data using a synchronization mechanism. You can use the `synchronized`
    keyword in the declaration of the method that modifies the data so that only one
    thread can modify data at a time. Another possibility is the utilization of a
    `Lock` class to create a critical section with instructions that modify data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since version 5, Java includes atomic variables. When a thread is doing an
    operation with an atomic variable, the implementation of the class includes a
    mechanism to check that the operation is done in one step. Basically, the operation
    gets the value of the variable, changes the value in a local variable, and then
    tries to change the old value with the new one. If the old value is still the
    same, it does the change. If not, the method begins the operation again. Java
    provides the following types of atomic variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '`AtomicBoolean`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AtomicInteger`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AtomicLong`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AtomicReference`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In some cases, Java's atomic variables offer a better performance than solutions
    based on synchronization mechanisms (specially when we care about atomicity within
    each separate variable). Some classes of the `java.util.concurrent` package use
    atomic variables instead of synchronization. In this recipe, you will develop
    an example that shows how an atomic attribute provides better performance than
    synchronization.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The example of this recipe has been implemented using the Eclipse IDE. If you
    use Eclipse or a different IDE, such as NetBeans, open it and create a new Java
    project.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow these steps to implement the example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a class named `TaskAtomic` and specify that it implements the `Runnable`
    interface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Declare a private `AtomicInteger` attribute named `number`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the constructor of the class to initialize its attributes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the `run()` method. In a loop with 1,000,000 steps, assign the number
    of steps to the atomic attribute as a value, using the `set()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a class named `TaskLock` and specify that it implements the `Runnable`
    interface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Declare a private `int` attribute named `number` and a private `Lock` attribute
    named `lock`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the constructor of the class to initialize its attributes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the `run()` method. In a loop with 1,000,000 steps, assign the number
    of the steps to the integer attribute. You have to get the lock before the assignment
    and release it after:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the main class of the example by creating a class named `Main` and
    adding the `main()` method to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `TaskAtomic` object named `atomicTask`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `TaskLock` object named `lockTask`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Declare the number of threads and create an array of `Thread` objects to store
    the threads:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Launch the specified number of threads to execute the `TaskLock` object. Calculate
    and write its execution time in the console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Launch the specified number of threads to execute the `TaskAtomic` object.
    Calculate and write its execution time in the console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you execute the example, you will see how the execution time of the `TaskAtomic`
    tasks that use atomic variables are always better than the `TaskLock` tasks that
    use locks. You will obtain a similar result if you use the `synchronized` keyword
    instead of locks.
  prefs: []
  type: TYPE_NORMAL
- en: The conclusion of this recipe is that utilization of atomic variables will give
    you better performance than other synchronization methods. If you don't have an
    atomic type that fits your needs, maybe you can try to implement your own atomic
    type.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *Implementing your own atomic object* recipe in [Chapter 8](part0365.html#AS2TA0-69b77957c9a14e36a0bec5f5a1363736), *Customizing
    Concurrency Classes*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Holding locks for as short time as possible
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Locks, just like other synchronization mechanisms, allow the definition of a
    critical section that only one thread can execute at a time. You must be very
    careful to define the critical section. It must only include those instructions
    that really need mutual exclusion. This is especially true if the critical section
    includes long operations. If the critical section includes lengthy operations
    that do not use shared resources, application performance will be worse than it
    could be.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, you will implement an example to see the difference in the performance
    of a task with a long operation inside the critical section and a task with a
    long operation outside the critical section.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The example of this recipe has been implemented using the Eclipse IDE. If you
    use Eclipse or a different IDE, such as NetBeans, open it and create a new Java
    project.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow these steps to implement the example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a class named `Operations`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement a `public static` method named `readData()`. It puts the current
    thread to sleep for 500 milliseconds:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement a `public static` method named `writeData()`. It puts the current
    thread to sleep for 500 milliseconds:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement a `public static` method named `processData()`. It puts the current
    thread to sleep for 2,000 milliseconds:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement a class named `Task1` and specify that it implements the `Runnable`
    interface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Declare a private `Lock` attribute named `lock`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the constructor of the class to initialize its attributes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the `run()` method. Acquire the lock, call the three operations of
    the `Operations` class, and release the lock:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement a class named `Task2` and specify that it implements the `Runnable`
    interface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Declare a private `Lock` attribute named `lock`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the constructor of the class to initialize its attributes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the `run()` method. Acquire the lock, call the `readData()` operation,
    and release the lock. Then, call the `processData()` method, acquire the lock,
    call the `writeData()` operation, and release the lock:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the main class of the example by creating a class named `Main` and
    adding the `main()` method to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `Lock` object named `lock`, a `Task1` object named `task1`, a `Task2`
    object named `task2`, and an array of 10 threads:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Launch 10 threads to execute the first task by controlling its execution time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Launch 10 threads to execute the second task by controlling its execution time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you execute the example, you will see a big difference between the execution
    time of the two approaches. The task that has all the operations inside the critical
    section takes longer than the other task.
  prefs: []
  type: TYPE_NORMAL
- en: When you need to implement a block of code protected by a lock, analyze it carefully
    to only include necessary instructions. Split the method into various critical
    sections, and use more than one lock if necessary to get the best performance
    of your application.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *Avoiding deadlocks by ordering locks* recipe in this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delegating the management of threads to executors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before Java 5, the Java Concurrency API, when we wanted to implement a concurrent
    application, we had to manage the threads by ourselves. First we used to implement
    the `Runnable` interface or an extension of the `Thread` class. Then, we used
    to create a `thread` object and start its execution using its `start()` method.
    We also had to control its status to know whether the thread had finished its
    execution or was still running.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java version 5, the concept of executor as a provider of a pool of execution
    threads appeared. This mechanism, implemented by the `Executor` and `ExecutorService`
    interfaces and the `ThreadPoolExecutor` and `ScheduledThreadPoolExecutor` classes,
    allows you to concentrate only on the implementation of the logic of the task.
    You implement the task and send it to the executor. It has a pool of threads,
    and it is this pool that is responsible for the creation, management, and finalization
    of the threads. In Java version 7, another implementation of the executor mechanism
    in the fork/join framework, specialized in problems that can be broken down into
    smaller subproblems, appeared. This approach has numerous advantages, which are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: We don't have to create threads for all the tasks. When we send a task to the
    executor and it's executed by a thread of the pool, we save the time used in creating
    a new thread. If our application has to execute a lot of tasks, the total saved
    time will be significant and the performance of the application will be better.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we create fewer threads, our application will use less memory as well. This
    can also extract better performance from our application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can build concurrent tasks executed in the executor by implementing either
    the `Runnable` or `Callable` interface. The `Callable` interface allows us to
    implement tasks that return a result, which provide a big advantage over traditional
    tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we send a task to an executor, it returns a `Future` object that allows
    us to know the status of the task and the returned result, whether it has finished
    its execution easily.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can schedule our tasks and execute them repeatedly with the special executor
    implemented by the `ScheduledThreadPoolExecutor` class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can easily control the resources used by an executor. We can establish the
    maximum number of threads in the pool, so our executor will never have more than
    that number of tasks running at a time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The use of executors has a lot of advantages over direct utilization of threads.
    In this recipe, you are going to implement an example that shows how you can obtain
    better performance using an executor than creating the threads yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The example of this recipe has been implemented using the Eclipse IDE. If you
    use Eclipse or a different IDE, such as NetBeans, open it and create a new Java
    project.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow these steps to implement the example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a class named `Task` and specify that it implements the `Runnable` interface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the `run()` method. Create a loop with 1,000,000 steps, and in each
    step, do some mathematical operations with an integer variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the main class of the example by creating a class named `Main` and
    adding the `main()` method to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Create 1,000 threads to execute 1,000 task objects and wait for their finalization,
    controlling the total execution time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Create an `Executor` object, send 1,000 `Task` objects to it, and wait for
    their finalization. Measure the total execution time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the entire execution of this example, we always obtained a smaller execution
    time for the executor than creating the thread directly. If your application has
    to execute a lot of tasks, better employ an executor.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *Using executors instead of thread groups* and *Using the fork/join framework
    instead of executors* recipes in this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using concurrent data structures instead of programming yourself
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data structures are an essential part of every program. You always have to manage
    the data that you store in a data structure. Arrays, lists, or trees are examples
    of common data structures. The Java API provides a lot of ready-to-use data structures,
    but when you work with concurrent applications, you have to be careful because
    not all structures provided by the Java API are **thread-safe**. If you choose
    a data structure that is not thread-safe, you can have inconsistent data in your
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you want to use a data structure in your concurrent application, you have
    to review the documentation of the class that implements that data structure to
    check that it supports concurrent operations. Java provides the following two
    kinds of concurrent data structures:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Non-blocking data structures**: All the operations provided by these data
    structures to either insert in or take off elements from the data structure return
    a null value if they can''t be done currently because the data structure is full
    or empty respectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Blocking data structures**: These data structures provide the same operations
    that are provided by non-blocking data structures. However, they also provide
    operations to insert and take off data that, if not done immediately, would block
    the thread until you''re able to do the operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These are some data structures provided by the Java API that you can use in
    your concurrent applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ConcurrentLinkedDeque`: This is a non-blocking data structure based on linked
    nodes that allow you to insert data at the beginning or end of the structure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LinkedBlockingDeque`: This is a blocking data structure based on linked nodes.
    It can have fixed capacity. You can insert elements at the beginning or end of
    the structure. It provides operations that, if not done immediately, block the
    thread until you''re able to do the operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ConcurrentLinkedQueue`: This is a non-blocking queue that allows you to insert
    elements at the end of the queue and take elements from its beginning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ArrayBlockingQueue`: This is a blocking queue with fixed size. You insert
    elements at the end of the queue and take elements from its beginning. It provides
    operations that, if not done because the queue is either full or empty, puts the
    thread to sleep until you''re able to do the operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LinkedBlockingQueue`: This is a blocking queue that allows you to insert elements
    at the end of the queue and take off elements from its beginning. It provides
    operations that, if not done because the queue is either full or empty, puts the
    thread to sleep until you''re able to do the operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DelayQueue`: This is a `LinkedBlockingQueue` queue with delayed elements.
    Every element inserted in this queue must implement the `Delayed` interface. An
    element can''t be taken off the list until its delay is 0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LinkedTransferQueue`: This is a blocking queue that provides operations to
    work in situations that can be implemented as a producer/consumer problem. It
    provides operations that, if not done because the queue is either full or empty,
    puts the thread to sleep until you''re able to do the operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PriorityBlockingQueue`: This is a blocking queue that orders its elements
    based on priority. All the elements inserted in this queue must implement the
    `Comparable` interface. The value returned by the `compareTo()` method will determine
    the position of the element in the queue. Just like all the blocking data structures,
    it provides operations that, if done immediately, puts the thread to sleep until
    you''re able to do the operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SynchronousQueue`: This is a blocking queue where every `insert` operation
    must wait for a `remove` operation for the other thread. The two operations must
    be done at the same time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ConcurrentHashMap`: This is a `HashMap` that allows concurrent operations.
    It''s a non-blocking data structure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ConcurrentSkipListMap`: This data structure associates keys with values. Every
    key can have only one value. It stores the keys in an ordered way and provides
    a method to find elements and get some elements from the map. It''s a non-blocking
    data structure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you need to use a data structure in your concurrent application, look in
    the Java API documentation to find the data structure that best fits your needs.
    Implement your own concurrent data structure that has some problems, which are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: They have a complex internal structure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have to take into account a lot of different situations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have to design a lot of tests to guarantee that it works correctly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you don't find a data structure that fits your needs completely, try to extend
    one of the existing concurrent data structures to implement one adequately to
    your problem.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The recipes in [Chapter 7](part0304.html#91TB00-69b77957c9a14e36a0bec5f5a1363736),
    *Concurrent Collections*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Taking precautions using lazy initialization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Lazy initialization** is a common programming technique that delays object
    creation until it is needed for the first time. This normally causes the initialization
    of the objects to be made in the implementation of the operations, instead of
    the constructor of the classes. The main advantage of this technique is that you
    can save memory. This is because you only create the indispensable objects needed
    for the execution of your applications. You could have declared a lot of objects
    in one class, but you don''t use every object in every execution of your program;
    therefore, your application doesn''t use the memory needed for the objects that
    you don''t use in an execution of the program. This advantage can be very useful
    for applications that run in environments with limited resources.'
  prefs: []
  type: TYPE_NORMAL
- en: By contrast, this technique has the disadvantage of having performance issues
    in your application, as you create objects the first time they are used inside
    an operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'This technique can also provoke problems if you use it in concurrent applications.
    As more than one thread can be executing an operation at a time, they can be creating
    an object at the same time, and this situation can be problematic. This has a
    special importance with **singleton** classes. An application has only one object
    of these classes and, as mentioned earlier, a concurrent application can create
    more than one object. Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: This is the typical method in a singleton class to obtain the reference of the
    unique object of that class existing in the application, using lazy initialization.
    If the object hasn't been created yet, it creates the object. Finally, it always
    returns it.
  prefs: []
  type: TYPE_NORMAL
- en: If two or more threads executes at the same time the comparison of the first
    sentence (`connection == null`), all of them will create a `Connection` object.
    This isn't a desirable situation.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, you will implement an elegant solution to the lazy initialization
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The example of this recipe has been implemented using the Eclipse IDE. If you
    use Eclipse or a different IDE, such as NetBeans, open it and create a new Java
    project.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow these steps to implement the example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a class named `DBConnectionOK`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Declare a `private` constructor. Write the name of the thread that executes
    it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Declare a `private static` class named `LazyDBConnectionOK`. It has a `private
    static final DBConnectionOK` instance named `INSTANCE`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the `getConnection()` method. It doesn''t receive any parameter and
    returns a `DBConnectionOK` object. It returns the `INSTANCE` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a class named `Task` and specify that it implements the `Runnable` interface.
    Implement the `run()` method. Call the `getConnection()` method of the `DBConnectionOK()`
    method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the main class of the example by creating a class named `Main` and
    adding the `main()` method to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Create 20 `Task` objects and 20 threads to execute them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The key of the example is the `getConnection()` method and the `private static
    class LazyDBConnection` instance. When the first thread calls the `getConnection()`
    method, the `LazyDBConnection` class initializes the `INSTANCE` object by calling
    the constructor of the `DBConnection` class. This object is returned by the `getConnection()`
    method. When the rest of the threads call the `getConnection()` method, the object
    is already created, so all the threads use the same object that is created only
    once.
  prefs: []
  type: TYPE_NORMAL
- en: When you run the example, you will see the start and end messages of 20 tasks,
    but only one creation message.
  prefs: []
  type: TYPE_NORMAL
- en: Using the fork/join framework instead of executors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Executors allow you to avoid the creation and management of threads. You implement
    tasks by implementing `Runnable` or `Callable` interfaces and sending them to
    the executor. It has a pool of threads and uses one of them to execute the tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Java 7 provides a new kind of executor with the fork/join framework. This executor,
    implemented in the `ForkJoinPool` class, is designed for problems that can be
    split into smaller parts using the divide and conquer technique. When you implement
    a task for the fork/join framework, you have to check the size of the problem
    you have to resolve. If it's bigger than a predefined size, you divide the problem
    into two or more subcategories and create as many subtasks as the number of divisions
    you have made. The task sends these subtasks to the `ForkJoinPool` class using
    the `fork()` operation and waits for its finalization using the `join()` operation.
  prefs: []
  type: TYPE_NORMAL
- en: For these kinds of problems, fork/join pools get better performance than classical
    executors. In this recipe, you are going to implement an example where you can
    check this point.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The example of this recipe has been implemented using the Eclipse IDE. If you
    use Eclipse or a different IDE, such as NetBeans, open it and create a new Java
    project.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow these steps to implement the example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a class named `TaskFJ` and specify that it extends the `RecursiveAction`
    class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Declare a private array of `int` numbers named `array`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Declare two private `int` attributes, named `start` and `end`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the constructor of the class to initialize its attributes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the `compute()` method. If this task has to process a block of more
    than 1,000 elements (determined by the `start` and `end` attributes), create two
    `TaskFJ` objects, send them to the `ForkJoinPool` class using the `fork()` method,
    and wait for their finalization using the `join()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Otherwise, increment the elements that this task has to process. After every
    increment operation, put the thread to sleep for 1 millisecond:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a class named `Task` and specify that it implements the `Runnable` interface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Declare a private array of `int` number named `array`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the constructor of the class to initialize its attribute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the `run()` method. Increment all the elements of the array. After
    every increment operation, put the thread to sleep for 1 millisecond:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the main class of the example by creating a class named `Main` and
    adding the `main()` method to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Create an `int` array with 100,000 elements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `Task` object and a `ThreadPoolExecutor` object and execute them.
    Execute the task by controlling the time during which the task is running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `TaskFJ` object and a `ForkJoinPool` object and execute them. Execute
    the task by controlling the time during which the task is running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you execute the example, you will see how the `ForkJoinPool` and `TaskFJ`
    classes get better performance than the `ThreadPoolExecutor` and `Task` classes.
  prefs: []
  type: TYPE_NORMAL
- en: If you have to solve a problem that can be split using the divide and conquer
    technique, use a `ForkJoinPool` class instead of a `ThreadPoolExecutor` class.
    You will get better performance.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *Delegating the management of threads to executors* recipe of this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoiding the use of blocking operations inside a lock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Blocking operations** are operations that block the execution of the current
    thread until an event occurs. Typical blocking operations are those that involve
    input or output operations with the console, a file, or network.'
  prefs: []
  type: TYPE_NORMAL
- en: If you use a blocking operation inside the critical section of a lock, you're
    deteriorating the performance of the application. While a thread is waiting for
    the event that would finish the blocking operation, the rest of the application
    might be waiting for the same event as well; however, none of the other threads
    will have access to the critical section and execute its code (the code of the
    critical section).
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, you will implement an example of this situation. The threads
    read a line from the console inside the critical section. This instruction makes
    the rest of the threads of the application will be blocked until the user introduces
    the line.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The example of this recipe has been implemented using the Eclipse IDE. If you
    use Eclipse or a different IDE, such as NetBeans, open it and create a new Java
    project.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow these steps to implement the example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a class named `Task` and specify that it implements the `Runnable` interface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Declare a private `Lock` attribute named `lock`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the constructor of the class to initialize its attribute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the `run()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Acquire the lock using the `lock()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Call the `criticalSection()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Read a line from the console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Free the lock using the `unlock()` method in the finally section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the `criticalSection()` method. Wait for a random period of time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the main class of the application by creating a class named `Main`
    and adding the `main()` method to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a new `ReentrantLock` object named `lock`. Create 10 `Task` objects
    and 10 threads to execute them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you execute this example, 10 threads start their execution, but only one
    enters in the critical section, which gets implemented in the `run()` method.
    As every task reads a line from the console before releasing the lock, all the
    applications will be blocked until you introduce text in the console.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *Holding locks for as short a time period as possible* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoiding the use of deprecated methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Java concurrency API also has deprecated operations. These are operations
    that were included in the first versions of the API, but now you shouldn't use
    them. They have been replaced by other operations that implement better practices
    than the original ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'The more critical deprecated operations are those that are provided by the
    `Thread` class. These operations are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`destroy()`: In the past, this method destroyed the thread. Actually, it throws
    a `NoSuchMethodError` exception.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`suspend()`: This method suspends the execution of the thread until it''s resumed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stop()`: This method forces the thread to finish its execution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`resume()`: This method resumes the execution of the thread.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `ThreadGroup` class also has some deprecated methods, which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`suspend()`: This method suspends the execution of all the threads that belong
    to this thread group until they resume'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stop()`: This method forces the execution of all the threads of this thread
    group to finish'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`resume()`: This method resumes the execution of all the threads of this thread
    group'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `stop()` operation has been deprecated because it can provoke inconsistent
    errors. As it forces the thread to finish its execution, you can have a thread
    that finishes its execution before the completion of an operation and can leave
    the data in an inconsistent status. For example, if you have a thread that is
    modifying a bank account and it's stopped before it is finished, the bank account
    will probably have erroneous data.
  prefs: []
  type: TYPE_NORMAL
- en: The `stop()` operation can also cause a deadlock situation. If this operation
    is called when the thread is executing a critical section protected by a synchronization
    mechanism (for example, a lock), this synchronization mechanism will continue
    to block and no thread will be able to enter the critical section. This is the
    reason why the `suspend()` and `resume()` operations have been deprecated.
  prefs: []
  type: TYPE_NORMAL
- en: If you need an alternative to these operations, you can use an internal attribute
    to store the status of the thread. This attribute must be protected with synchronized
    access, or use an atomic variable. You must check the value of this attribute
    and take actions according to it. Take into account that you have to avoid data
    inconsistency and deadlock situations to guarantee the correct operation of your
    application.
  prefs: []
  type: TYPE_NORMAL
- en: Using executors instead of thread groups
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `ThreadGroup` class provides a mechanism to group threads in a hierarchical
    structure so you can do operations with all the threads that belong to a thread
    group with only one call. By default, all the threads belong to the same group,
    but you can specify a different one when you create the thread.
  prefs: []
  type: TYPE_NORMAL
- en: 'Anyway, thread groups don''t provide any features that make their use interesting:'
  prefs: []
  type: TYPE_NORMAL
- en: You have to create the threads and manage their status
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The methods that control the status of all the threads of the thread group have
    been deprecated and their use is discouraged
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you need to group threads under a common structure, it is better to use
    an `Executor` implementation, such as `ThreadPoolExecutor`. It provides more functionalities,
    which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: You don't have to worry about the management of the threads. The executor creates
    and reuses them to save execution resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can implement your concurrent tasks by implementing either the `Runnable`
    or `Callable` interface. The `Callable` interface allows you to implement tasks
    that return a result, which provides a big advantage over traditional tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you send a task to an executor, it returns a `Future` object that allows
    you to know the status of the task and the returned result if it has finished
    its execution easily.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can schedule your tasks and execute them repeatedly with the special executor
    implemented by the `ScheduledThreadPoolExecutor` class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can easily control the resources used by an executor. You can establish
    the maximum number of threads in the pool so your executor will never have more
    than that number of tasks running at a time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For these reasons, it is better that you don't use thread groups and use executors
    instead.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *Delegating the management of threads to executors* recipe in this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using streams to process big data sets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A `Stream` interface is a sequence of elements that can be filtered and transformed
    to get a final result sequentially or in parallel. This final result can be a
    primitive data type (an integer, a long ...), an object or a data structure. These
    are the characteristics that better define `Stream`:'
  prefs: []
  type: TYPE_NORMAL
- en: A stream is a sequence of data, not a data structure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can create streams from different sources as collections (lists, arrays...),
    files, strings, or a class that provides the elements of the stream.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can't access an individual element of the streams.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can't modify the source of the stream.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Streams define two kinds of operations: intermediate operations that produce
    a new `Stream` interface that allows you to transform, filter, map, or sort the
    elements of the stream and terminal operations that generate the final result
    of the operation. A stream pipeline is formed by zero or more intermediate operations
    and a final operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Intermediate operations are lazy. They're not executed until the terminal operation
    begins its execution. Java can avoid the execution of an intermediate operation
    over an element or a set of elements of the stream if it detects that it doesn't
    affect the final result of the operation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you need to implement an operation that processes a big set of data in
    a concurrent way, you can use different elements of the **Java Concurrency API**
    to implement it. Java threads to either the **fork/join framework** or the **Executor
    framework**, but I think parallel streams are the best option. In this recipe,
    we will implement an example to explain the advantages that are provided by the
    use of parallel streams.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The example of this recipe has been implemented using the Eclipse IDE. If you
    use Eclipse or a different IDE, such as NetBeans, open it and create a new Java
    project.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow these steps to implement the example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a class named `Person`. This class will have six attributes to define
    some basic characteristics of a person. We will implement the methods to `get()`
    and `set()` the values of the attributes, but they won''t be included here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, implement a class named `PersonGenerator`. This class will only have a
    method named `generatedPersonList()` to generate a list of `Person` objects with
    random values with the size specified in parameters. This is the source code of
    this class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, implement a task named `PersonMapTask`. The main purpose of this task
    will be to convert a list of persons on a map, where the keys will be the name
    of the persons and the values will be a list with `Person` objects whose name
    is equal to the key. We will use the fork/join framework to implement this transformation,
    so the `PersonMapTask`  will extend the `RecursiveAction` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'The `PersonMapTask` class will have two private attributes: `List` of `Person`
    objects to process and `ConcurrentHashMap` to store results. We will use the constructor
    of the class to initialize both the attributes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Now it''s time to implement the `compute()` method. If the list has less than
    1,000 elements, we will process the elements and insert them in `ConcurrentHashMap`.
    We will use the `computeIfAbsent()` method to get `List` associated with a key
    or generate a new `ConcurrentMapedDeque` object if the key doesn''t exist in the
    map:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'If `List` has more than 1,000 elements, we will create two child tasks and
    delegate the process of a part of the list to them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, implement the `Main` class with the `main()` method. First, generate
    a list with 100,000 random `Person` objects:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, compare two methods to generate `Map` with the names as keys, which are
    part of `List`, and `Person` as value. List will use a parallel `Stream` function
    and the `collect()` method using the `groupingByConcurrent()` collector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'The second option is using the fork/join framework and the `PersonMapTask`
    class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we implemented two different versions of the same algorithm
    to obtain `Map` from `List`. If you execute it, you will obtain the same results
    and a similar execution time (at least the latter is true in my case when I executed
    the example in a four core computer). The biggest advantage we obtained using
    streams is the simplicity of the solution and its development time. With only
    one line of code, we implemented the solution. While in the other case, we implemented
    a new class (the `PersonMapTask`) using concurrent data structures and then executed
    it in the fork/join framework.
  prefs: []
  type: TYPE_NORMAL
- en: With Streams, you can divide your algorithm into simple steps that can be expressed
    in an elegant way, be easy to program and understand.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *Creating streams from different sources*, *Reducing the elements of a stream*
    and *Sorting the elements of a stream* recipes in [Chapter 6](part0249.html#7DES20-69b77957c9a14e36a0bec5f5a1363736),
    *Parallel and reactive streams*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other tips and tricks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this final recipe, we have included other tips and tricks that haven''t
    been included in other recipes of the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Whenever possible, use concurrent design patterns: In software engineering,
    a design pattern is a solution to a common problem. They are commonly used in
    software development and concurrency applications and are not an exception. Patterns
    such as signaling, rendezvous, and mutex define how to implement concurrent applications
    in concrete situations, and they have been used to implement concurrent utilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Implement concurrency at the highest possible level: Rich threading APIs, such
    as the Java concurrency API, offer you different classes to implement concurrency
    in your applications. Try to use the ones that provide you a higher level of abstraction.
    It will make it easier for you to implement your algorithm, and they are optimized
    to give better performance than using threads directly. Therefore, performance
    won''t be a problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Take scalability into account: One of the main objectives when you implement
    a concurrent algorithm is to take advantage of all the resources of your computer,
    especially the number of processors or cores. But this number may change over
    time. When you design a concurrent algorithm, don''t presuppose the number of
    cores or processors that your application will execute on. Get information about
    the system dynamically. For example, in Java, you can get it with the `Runtime.getRuntime().availableProcessors()` method
    and make your algorithm use this information to calculate the number of tasks
    it''s going to execute.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Prefer local thread variables over static and shared when possible: Thread
    local variables are a special kind of variable. Every task will have an independent
    value for this variable, so you don''t need any synchronization mechanism to protect
    access to it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the recipes in this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
