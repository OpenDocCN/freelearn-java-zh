- en: Stock Price Predictions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of this chapter is to predict the values of near-or long-term equity
    prices by using **machine learning** (**ML**). From an investor's perspective,
    investments (in equity) across several companies are stocks, while such investments
    in an individual company are shares. Most investors lean on a long-term investment
    strategy for the best returns. Investment analysts employ mathematical stock analysis
    models to help predict future stock prices or price movements in the long term.
    Such models factor in past equity prices and other indicators to perform a company's
    financial health evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: The overarching learning objective of this chapter is to implement a Scala solution
    that will predict stock market prices. Starting from the stock price prediction
    dataset, we will use the Spark ML library's ML APIs to build a stock price prediction
    pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the dataset we will refer to:'
  prefs: []
  type: TYPE_NORMAL
- en: Daily News for Stock Market Prediction | Kaggle.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In-text: ([Kaggle.com](http://Kaggle.com), 2018) Daily News for Stock Market
    Prediction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kaggle. [online] Available at: [https://www.kaggle.com/aaron7sun/stocknews](https://www.kaggle.com/aaron7sun/stocknews)
    [Accessed 27 Jul. 2018].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following list is a section-wise breakdown of the individual learning outcomes
    in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Stock price binary classification problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting started
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation objective
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stock price binary classification problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Stock prices have a tendency to go up and down. We want to Spark ML and a Spark
    time-series library to explore historical stock price data going back a couple
    years and come up numbers like the average closing price. We also want our stock
    price prediction model to forecast what the stock price will be over the timeframe
    of a few days.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter presents an ML methodology to reduce the complexity associated
    with stock price prediction. We will obtain a smaller set of optimal financial
    indicators by feature selection and employ a Random Forest algorithm to build
    a price prediction pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: We must first download the dataset from the `ModernScalaProjects_Code` folder.
  prefs: []
  type: TYPE_NORMAL
- en: Stock price prediction dataset at a glance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will use data from two sources:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reddit worldnews**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dow Jones Industrial Average** (**DJIA**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The *Getting started* section that follows has two clear goals:'
  prefs: []
  type: TYPE_NORMAL
- en: Moving our development environment into a virtual appliance from a previous
    local Spark shell-centered development environment. This naturally implies setting
    up prerequisite resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attaining the preceding goal also implies being able to spin up a brand new
    Spark cluster, running inside the virtual appliance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to address the goals of this section, we will compile a resource list—a
    list of prerequisite software to be set up—before taking a shot at the first stated
    goal of setting up the **Hortonworks Development Platform** (**HDP**) Sandbox,
    a so-called virtual appliance from the Hortonworks organization. The virtual appliance
    overview section is helpful regarding this.
  prefs: []
  type: TYPE_NORMAL
- en: At its core, the HDP Sandbox is a robust data pipeline development environment.
    This appliance and its supporting ecosystem, like the underlying OS and the virtual
    machine configuration settings, make up the core of the development infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the resource list—the prerequisite software—that must be set or
    verified before proceeding further:'
  prefs: []
  type: TYPE_NORMAL
- en: A 64-bit host machine with support for hardware virtualization. To check for
    processor and motherboard support for virtualization, download and run a small
    utility called SecurAble. BIOS should be enabled or set to support virtualization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Host OS Windows 7, 8, or 10, macOS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compatible browsers such as Internet Explorer 9, stable versions of Mozilla
    Firefox, Google Chrome, or Opera.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At least 16 GB of RAM on the host machine.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supported virtualization applications need to be installed, such as Oracle VirtualBox
    Version 5.1 or above (this is our preferred virtualization application) or VMWare
    Fusion.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The HDP Sandbox download file. This file is delivered as a virtual appliance
    with the **Open Virtualization Format Archive** (**OVA**) file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we will review the prerequisites on our resources list.
  prefs: []
  type: TYPE_NORMAL
- en: Support for hardware virtualization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Grab a copy of SecurAble from the `ModernScalaProjects_Code` folder. SecurAble
    is a small program that is able to tell you the following about your machine''s
    processor:'
  prefs: []
  type: TYPE_NORMAL
- en: Confirm the presence or absence of 64-bit instructions on your host machine
    processor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether there is hardware support for virtualization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To determine the preceding prerequisites, SecurAble will not make any changes
    to your machine. On running the SecurAble application file, it will present a
    screen that should like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c6352373-6f3a-44a7-b6f9-be17bb709f73.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of screen on running the SecurAble application file
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking on 64 Maximum Bit Length makes SecurAble return the presence or absence
    of 64-bit processing, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/98ad62c6-8210-48e6-b6f0-6c27a12e2241.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of window displaying the presence or absence of 64-bit processing
  prefs: []
  type: TYPE_NORMAL
- en: 'The chipset on my Windows 64-bit machine is confirmed as offering a 64-bit
    mode of operation. Next, clicking on Yes Hardware Virtualization makes SecurAble
    report back that my processor does offer hardware support for virtualization,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e4646632-5d0b-4225-ba81-fd91ffe0464a.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of window displaying the hardware support for virtualization on SecurAble
  prefs: []
  type: TYPE_NORMAL
- en: If SecurAble reports back with the exact same results on your machine, it is
    likely that you have a host machine that can support Oracle VirtualBox. Note that
    at the BIOS level, support for virtualization is likely already set. If that is
    not the case, enable it. Note that SecurAble won't be able to report on BIOS support
    for the virtualization feature.
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that the preceding prerequisites are satisfied before moving further.
    Next, take up prerequisite which is regarding installing a supported virtualization
    application that is able to host a virtual appliance.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the supported virtualization application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the steps to install the virtualization application:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the latest VirtualBox binaries from the Oracle VirtualBox website:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/38462476-3e66-4f26-a1db-fbb92e065eef.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of latest VirtualBox binaries
  prefs: []
  type: TYPE_NORMAL
- en: 'Double-click on the Oracle VirtualBox binary. The setup welcome screen presents
    itself as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/78887793-15ca-4780-9259-a579404a7e84.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of the setup window
  prefs: []
  type: TYPE_NORMAL
- en: 'Click Next on the welcome screen. In the new screen that presents itself, select
    where you want VirtualBox to be installed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/44c5ddb2-99d9-4963-8866-43869afebbc8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of setup steps to place the folder
  prefs: []
  type: TYPE_NORMAL
- en: 'Click OK to move on to the Ready to Install screen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/14ca56f5-5bd2-4ea7-b6de-0b37c81ea584.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of Ready for installation screen
  prefs: []
  type: TYPE_NORMAL
- en: 'Click Install and complete any self-explanatory steps needed to complete the
    installation. Once this process is complete, place a shortcut on your taskbar
    or on the desktop. Now, launch the VirtualBox application, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/6b765c50-c700-491f-82c0-b17aa422ac08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of Ready for launch of VirtualBox application
  prefs: []
  type: TYPE_NORMAL
- en: 'You may optionally remove the inaccessible machines `vm`, `vm_1`, and `CentOS` as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1a4b82b1-ceac-4aff-a859-8e3de5932f1f.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot displaying how to remove the inaccessible machines
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, deselect the Auto Capture Keyboard option under File | Preferences...
    | Input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4015e2d1-672c-4b18-b531-f9a6bdf3f5bd.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of final steps to set the virtual machine
  prefs: []
  type: TYPE_NORMAL
- en: The virtual machine is now all set. In the next step, we will download and import
    the Sandbox into it.
  prefs: []
  type: TYPE_NORMAL
- en: Downloading the HDP Sandbox and importing it
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the steps to download the HDP Sandbox:'
  prefs: []
  type: TYPE_NORMAL
- en: Head over to [https://hortonworks.com/downloads/#sandbox](https://hortonworks.com/downloads/#sandbox)
    and download the Hortonworks Sandbox virtual appliance file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Move the Sandbox virtual appliance file into a convenient location on your
    host machine. Perform the following click actions in sequence: File | Import Appliance....
    Then, choose a virtual appliance file to import, which thereby imports the respective
    disk image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/36c85b5d-81cc-40e5-85cc-c524d8bec275.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Steps to be performed to import the disk image
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s tweak Appliance settings in the Appliance settings screen. Make
    sure you increase the available RAM to at least `10000 MB`. Leave the other default
    settings intact and click Import:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3f0a0b95-dcee-483d-8ad0-b610adadb9a2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot to import the virtual appliance into Oracle VirtualBox
  prefs: []
  type: TYPE_NORMAL
- en: The virtual appliance has now been imported into Oracle VirtualBox. The following
    section offers a brief overview of the Hortonworks Sandbox virtual appliance.
  prefs: []
  type: TYPE_NORMAL
- en: Hortonworks Sandbox virtual appliance overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Hortonworks Sandbox is a virtual machine, or virtual appliance, which is
    delivered as a file with an `.ova` or `.ovf` extension. It appears as a bare machine
    to the host OS, and has the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: A guest operating system that is treated as an application by the underlying
    host operating system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The virtual appliance file we want is an `.ova` file, which is available in
    the `ModernScalaProjects_Code` folder under the virtual machines folder
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applications that run in the guest OS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All that being said, we are done setting up prerequisites. Let's run the virtual
    machine for the first time.
  prefs: []
  type: TYPE_NORMAL
- en: Turning on the virtual machine and powering up the Sandbox
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the Oracle VirtualBox startup icon. The startup screen with a powered-off
    Sandbox appears as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3841319e-0437-4b64-bc01-4c0944734c92.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of the startup screen with a powered-off Sandbox
  prefs: []
  type: TYPE_NORMAL
- en: The startup screen displays the updated Hortonworks Sandbox virtual appliance
    with its updated configuration. For example, our Base Memory is now 10000 MB.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, right-click on the Sandbox and click Start | Normal Start:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/6bc43418-3871-4240-828a-3a3bada41dd9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of steps to be performed to get started
  prefs: []
  type: TYPE_NORMAL
- en: 'If everything went well, you should see the following Hortonworks Docker Sandbox
    HDP [Running] screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dffcce19-8e3c-449c-a4b9-16806bec2a68.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of Hortonworks Docker Sandbox HDP [Running]
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to log in to the Sandbox. *Alt* + *F5* takes you to the `sandbox-host
    login` screen as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a81c4253-3350-4e5e-9900-922a7065e3b1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot displaying how to log in to the Sandbox
  prefs: []
  type: TYPE_NORMAL
- en: Sign in as `root` with a `Password` of `hadoop`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the `hosts` file, and map `127.0.0.1` to `sandbox-hdp.hortonworks.com`.
    On a Windows (host) machine, this is located under `C:\Windows\System32\drivers\etc`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4fb175e9-84a1-487d-a01d-ee543d6c2878.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot displaying editing of host files
  prefs: []
  type: TYPE_NORMAL
- en: Save the updated `hosts` file and verify that these changes took effect before
    loading the URL as `sandbox-hdp.hortonworks.com:8888` in the browser.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, load the URL as `sandbox-hdp.hortonworks.com:4200` in your browser to
    launch the Sandbox web client. Change the default password from `hadoop` to something
    else. Note that the virtual appliance runs a CentOS Linux guest OS:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d9b477bd-83dd-414d-8a1b-2ff2d272b8f2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot to launch the Sandbox web client
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will set up an SSH client for transferring files between
    the Sandbox and your local (host) machine.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up SSH access for data transfer between Sandbox and the host machine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**SSH** stands for **Secure Shell**. We want to set up the SSH network protocol
    to establish a remote login and secure file transfers between our host machine
    and a virtual machine that''s running the virtual appliance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Two steps need to be followed:'
  prefs: []
  type: TYPE_NORMAL
- en: Set up PuTTY, a third-party SSH and Telnet client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set up WinSCP, a **Secure File Transfer Protocol** (**SFTP**) client for Windows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up PuTTY, a third-party SSH and Telnet client
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following installation steps of PuTTY:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The PuTTY installer, `putty-64bit-0.70-installer.exe`, is available in the
    `ModernScalaProjects_Code` folder. You can run it by double-clicking on the installer
    icon as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b9cd6719-e2a4-409c-b1a5-89b814ba7a69.jpg)'
  prefs: []
  type: TYPE_IMG
- en: PuTTY installer icon
  prefs: []
  type: TYPE_NORMAL
- en: 'Choose a destination folder to install PuTTY into and click Next:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/cb23ddf9-66f4-47e4-b8a3-c419bccffd8c.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot to Install PuTTY
  prefs: []
  type: TYPE_NORMAL
- en: 'Select or deselect any product features you want to be installed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/aaa00e57-da33-40c6-9f9a-20466d7be783.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of list of product features
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, click Install. PuTTY and other supporting utilities will be installed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/124219fe-a14f-4978-9fd3-a68692da595c.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of PuTTY and supporting utilities being installed
  prefs: []
  type: TYPE_NORMAL
- en: 'Run PuTTYgen. On the PuTTY Key Generator screen, press the Generate button
    and follow the onscreen instructions. Click on the Save public key button and
    save the generated public key into a file called `authorized_keys` in a convenient
    location, but not before typing in a passphrase:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1610be45-722e-4f37-965b-8e362cf93585.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of steps to be performed after running PuTTY Key Generator
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on Save private key, which is marked by 3 in the preceding screenshot.
    This will let you save your private key in a convenient location. This could be
    the same as the public key location, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/302e7c1f-0e73-423f-9a23-4b86e78e68ea.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of private key being saved in a convenient location
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we want to upload the public key to our Sandbox. Start up the
    Sandbox, and then load the Sandbox web client like we did earlier. Carry out steps
    1, 2, 3, and 4, as shown in the following screenshot. The public key is saved
    as `authorized_key`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e984d752-f20c-4754-bc3b-c428dd7b3e8b.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot displaying the upload of public key to our Sandbox
  prefs: []
  type: TYPE_NORMAL
- en: Dismiss PuTTYgen with File | Exit.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open PuTTY and click on Session. We want to create and save a session. Follow
    the numbers in the following screenshot to set it up:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Session and select Logging
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter Host Name as our Sandbox
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter Port as `2222`
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Then click on button Save
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/fd63a21b-3f05-47a8-809d-31d13c5b1be1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot displaying the steps to be performed for creating and saving the
    session
  prefs: []
  type: TYPE_NORMAL
- en: 'Save the session as `sandbox-hdp.hortonworks.com` (saved sessions) by clicking
    Save. Next, click on Data under Connection and enter the login name of the Sandbox.
    Do not click Open yet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/601f33bc-0c9d-4d5f-ad13-ff6013d7fc9a.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot showing the steps to be performed after saving the session
  prefs: []
  type: TYPE_NORMAL
- en: 'After entering the Auto-login username, click on Connection | SSH | Auth |Load
    the private key after clicking on Browse.... Load the private key and click Open.
    This should establish an SSH connection with the Sandbox:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f0ec68f9-32e4-40d2-9688-d48bd05adeea.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of steps to be performed after entering the Auto-login username
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s recap and summarize the steps we took so far to set up PuTTY, a third-party
    SSH and Telnet client, and hence SSH access for data transfer between the Sandbox
    and the host machine:'
  prefs: []
  type: TYPE_NORMAL
- en: Click on Session. Enter the hostname under the Host Name (or IP address) field
    of the Sandbox virtual appliance and then select the appropriate SSH protocol. Moving
    on, navigate to Connection | Data and enter your login name for the Sandbox in
    the auto-login box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, navigate to Connection | SSH | Auth | Load the private key.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, click on Session. Load the saved session and click Save; this updates
    the session.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: WinSCP is a popular graphical SSH client for Windows that makes it easy to transfer
    files between the local (host) machine and the Sandbox. Let's set up WinSCP now.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up WinSCP, an SFTP client for Windows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following steps explain how to set up WinSCP:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The WinSCP binary file is available under the `ModernScalaProjects_Code` folder.
    Download it and run it. Once installed, launch WinSCP for the very first time.
    The Login screen presents itself as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9006aee6-6271-4f80-8ae2-f8b154a3cc9a.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of the login screen
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on New Site, making sure that the File protocol is SFTP, and under Host
    name, you may enter the Sandbox hostname. Change the port from `22` to `2222`.
    You might want to enter `root` under User name and the Password for the Sandbox
    WebClient. Next, click 6, which takes us to the Advanced Site Settings screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6943e276-a0a3-42b6-a922-45d1930b350a.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of Advanced Site Settings screen
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding Advanced Site Settings screen, drill down to Authentication
    under SSH and load the private key file. Click OK.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, launch WinSCP again. Clicking on Login should establish a connection with
    the Sandbox and you should be able to transfer files back and forth as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4e3f6445-5320-454a-9c0b-fd6dce9770c2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot showing Sandbox being able to transfer files back and forth
  prefs: []
  type: TYPE_NORMAL
- en: 'After the connection is established, the resulting screen should look as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ec691a8b-bdd3-48c8-9246-3e51969c1016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of screen after the connection is establiashed
  prefs: []
  type: TYPE_NORMAL
- en: In the next step, we will move on to Sandbox configuration updates.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the default Python required by Zeppelin
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Sandbox boasts a fully-fledged Spark development environment with one notable
    difference from our previous local Spark development environment: Zeppelin Notebook.'
  prefs: []
  type: TYPE_NORMAL
- en: What is Zeppelin?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Zeppelin is a web-based notebook that has the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: Data exploration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interactive data analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data visualization and interactive dashboards
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collaborative document sharing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zeppelin depends on Python 2.7 or above, but the Sandbox itself only supports
    Version 2.6\. Therefore, we are going to have to replace 2.6 with 2.7\. Before
    we go any further, let''s check our Python version:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5db67030-9dda-4741-9af2-57ba019d1831.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot displaying the python version
  prefs: []
  type: TYPE_NORMAL
- en: That's right! We need to get rid of Python 2.6 with Python 2.7 and bring the
    Notebook up to date.
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps to accomplish this are summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Set up the Anaconda data science environment. You can simply set up a lighter
    version of Anaconda, which would be Miniconda with Python 2.7\. Miniconda brings
    with it many popular data science packages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set up any packages that do not come packaged with Miniconda. Make sure that
    you have SciPy, NumPy, Matplotlib, and Pandas. Sometimes, we can simply pass a
    Spark/Scala `DataFrame` into Python on Pyspark to produce visualizations quickly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Work through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to download the installer for Miniconda and run it as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/75c0d8e1-6dcc-48a5-9d37-70b63f5c5601.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot displaying the installer for Miniconda
  prefs: []
  type: TYPE_NORMAL
- en: Go through the installation process. It is straightforward. Once the installation
    is complete, restart the web client to allow changes to take effect. Now, log
    back in to the Sandbox with `root` and your secret password.
  prefs: []
  type: TYPE_NORMAL
- en: 'To check whether we do have a new, upgraded Python, issue the `python` command
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ade5b58a-f703-45a8-91cc-d4555dd7ee05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot displaying how to issue the Python command
  prefs: []
  type: TYPE_NORMAL
- en: 'Voila! We have a new Python version: 2.7.14.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will update the Zeppelin instance using curl.
  prefs: []
  type: TYPE_NORMAL
- en: Updating our Zeppelin instance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Following steps need to be performed to update the Zeppelin instance:'
  prefs: []
  type: TYPE_NORMAL
- en: Install curl, if not installed already
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Update your Zeppelin instance with the latest and greatest notebooks from Hortonworks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Please follow the steps to install curl:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the `curl --help` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/39a6a4f1-ddd3-4c87-81f6-b271905e999d.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot displaying how to run the curl --help command
  prefs: []
  type: TYPE_NORMAL
- en: 'The `curl --help` command confirms that we have curl already installed. Let''s
    try updating Zeppelin now:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/edd0d588-9d88-4e27-9ff2-0eb9e9b52f1c.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot displaying updating of Zeppelin
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the `curl` command to update the Zeppelin instance with the latest notebooks.
    The following screenshot shows the updated Zeppelin instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/43cee218-3c22-4bbb-a681-84cdac45c925.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot displaying updated Zeppelin instance
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's go back to `hdp.hortonworks.com:8888`.
  prefs: []
  type: TYPE_NORMAL
- en: Launching the Ambari Dashboard and Zeppelin UI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the steps required to launch Ambari and Zeppelin:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the Launch Dashboard button and log in as `maria_dev` to navigate
    to the Ambari dashboard:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/30ad3895-24be-4834-a82a-ece2df5e729f.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot displaying navigation through the Ambari dashboard
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking on Zeppelin UI under Quick Links takes us to the Zeppelin UI, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/da934061-8dce-4d70-8ccd-95f115900051.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screendhot of Zeppelin UI page
  prefs: []
  type: TYPE_NORMAL
- en: The Zeppelin UI runs on port `9995`. For our Zeppelin Notebook to work with
    Spark 2 and Python 2.7, the Spark and Python interpreters need updating.
  prefs: []
  type: TYPE_NORMAL
- en: Updating Zeppelin Notebook configuration by adding or updating interpreters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following steps need to be performed to update the Zeppelin notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: We need to update the interpreters, including a Spark 2 interpreter and adding
    a Python interpreter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the Zeppelin UI page, click on anonymous | Interpreter as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7b9e55d1-2aae-4352-91f5-ce4e9360639a.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot to perform steps on the Zeppelin UI page
  prefs: []
  type: TYPE_NORMAL
- en: Clicking on the Interpreter link takes us to the interpreter's page. First,
    we will update the Spark 2 interpreter.
  prefs: []
  type: TYPE_NORMAL
- en: Updating a Spark 2 interpreter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the steps involved in updating the Spark 2 interpreter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will update the `SPARK_HOME` property as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/afb6b94a-5835-40ab-bb4d-9097afd44429.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot displaying how to update the SPARK_HOME property
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will update the `zeppelin.pyspark.python` property to point to the
    new Python interpreter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3ed9b87c-c188-43e2-874b-2b711f73adfb.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot displaying how to update the zeppelin.pyspark.python property
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s create a new Python interpreter as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e0e488db-8aeb-4375-aba7-742efc2f70f2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot to create a new Python interpreter
  prefs: []
  type: TYPE_NORMAL
- en: Update `zeppelin.pyspark.python` to `/usr/local/bin/bin/python`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For all of these interpreter changes to take effect, we will need to restart
    the services. Head over to the Ambari dashboard page. Locate Service Actions at
    the top-right corner and in the dropdown, select Restart All:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7eb274e3-b546-46dd-97ed-b9bff1e82f58.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot displaying final step for Zeppelin Notebook to be ready for development
  prefs: []
  type: TYPE_NORMAL
- en: At this point, the Zeppelin Notebook is ready for development.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation objectives
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of this section will be to get started with developing a data pipeline
    using the Random Forests algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: List of implementation goals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following implementation objectives are the same and cover both the Random
    Forests pipeline and linear regression. We will perform preliminary steps such
    as **Exploratory Data Analysis** (**EDA**) once and develop specific implementation
    code that pertains to a particular pipeline. Therefore, the implementation objectives
    are listed here as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Get the stock price dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Carry out preliminary EDA in the Sandbox Zeppelin Notebook environment (or Spark
    shell), and run a statistical analysis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Develop the pipeline incrementally in Zeppelin, and port the code into IntelliJ.
    This means doing the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a new Scala project in IntelliJ, or import an existing empty project
    into IntelliJ, and create Scala artifacts from code that was incrementally developed
    in the Notebook.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Do not forget to wire up all the necessary dependencies in the `build.sbt` file.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Interpret the results of the pipeline, such as how well the classifier performed.
    How close are the predicted values to those in the original dataset?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: In the next subsection, we will download the stock price dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – creating a Scala representation of the path to the dataset file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The stock price dataset is available in the `ModernScalaProjects_Code` folder.
    Grab a copy and upload it to the Sandbox, then place it in a convenient location
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In the next step, let's create a **resilient distributed dataset** (**RDD**).
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – creating an RDD[String]
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Invoke the `textFile` method of `sparkContext`, which is supplied by Spark
    in the Sandbox:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The resultant RDD, `result1`, is a partitioned structure. In the next step,
    we will iterate over these partitions.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – splitting the RDD around the newline character in the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Invoke a `flatMap` operation over the `result1` RDD, and split each partition
    around its `"\n"` (end of the line) character as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Each `partition` is after a string. In the next step, we will transform the
    `result2` RDD.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – transforming the RDD[String]
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Invoke a `map` operation over the `result2` RDD. Each line in this RDD (a row
    of data) consists of stock price headline data separated by a comma, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The resultant RDD, `result2A`, is an `RDD[Array[String]]`. The RDD consists
    of an array of strings, where each string represents a row.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 – carrying out preliminary data analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This step is broken down into a set of smaller steps. The process starts with
    the creation of `DataFrame`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating DataFrame from the original dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Load the stock price dataset file again by specifying an appropriate `option`
    for Spark to automatically infer the schema of the dataset before it can create
    the `DataFrame`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The resultant structure, `spDataFrame`, is `DataFrame`.
  prefs: []
  type: TYPE_NORMAL
- en: Dropping the Date and Label columns from the DataFrame
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`Date` and `Label` are columns we may exclude for now as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The resultant structure is a new `DataFrame` that consists of all 25 top headlines.
  prefs: []
  type: TYPE_NORMAL
- en: Having Spark describe the DataFrame
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Invoke the `describe` and `show` methods in that order to give us a visual
    of the first 20 rows as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In the next step, let's add a new column to the `DataFrame`, an `expAnalysisTestFrame`,
    called `AllMergedNews`.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a new column to the DataFrame and deriving Vector out of it
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s perform the following steps to add a new column and derive `Vector`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new `DataFrame` by creating a new `AllMergedNews` column in place
    of the `Top1` column, which is done by invoking the `withColumn` method as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, transform the `mergedNewsColumns` `DataFrame` into `Vector` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next step, we simply derive the `mergedFinalFrame` `DataFrame` from `mergedFrameList`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: At this point, we have `DataFrame` that needs some preprocessing. Let's start
    by getting rid of stop words.
  prefs: []
  type: TYPE_NORMAL
- en: Removing stop words – a preprocessing step
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The stop words we want to be eliminated are words such as *a*, *an*, *the*,
    and *in*. **Natural Language Toolkit** (**NLTK**) comes to the rescue as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The next step is going to be using the `transform` operation.
  prefs: []
  type: TYPE_NORMAL
- en: Transforming the merged DataFrame
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `mergedFinalFrame` `DataFrame` is passed into the `transform` method. This
    NLTK step gets rid of all stop words that were not necessary for our analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In the next step, we will use a feature transformer called `NGram`.
  prefs: []
  type: TYPE_NORMAL
- en: Transforming a DataFrame into an array of NGrams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'What is an n-gram? It is simply a sequence of items such as letters, words,
    and so on (as in our dataset). Our dataset resembles a corpus of text. It is an
    ideal candidate for processing into an array of n-grams, which is an array consisting
    of words from the latest version of our dataset, devoid of stop words:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In the next step, we will create a new dataset by adding a column called `ndashgrams`.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a new column to the DataFrame, devoid of stop words
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Derive a new `DataFrame` by adding a new column called `ndashgrams` to `DataFrame` `cleanedDataFrame2`
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The next step gets more interesting. We will apply what is known as a count
    vectorizer.
  prefs: []
  type: TYPE_NORMAL
- en: Constructing a vocabulary from our dataset corpus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Why `CountVectorizer`? We need one to construct a vocabulary of certain terms
    regarding our stock price corpus:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '`CountVectorizer` generates a `CountVectorizerModel`, which can convert our
    corpus into a sparse vector of n-gram token counts.'
  prefs: []
  type: TYPE_NORMAL
- en: Training CountVectorizer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We want to train our `CountVectorizer` by passing into it our latest version
    of the dataset as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Using StringIndexer to transform our input label column
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s index our `label` input in the dataset using `StringIndexer` as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Next, let's drop the input label column `label`.
  prefs: []
  type: TYPE_NORMAL
- en: Dropping the input label column
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Invoke the `drop` method on `DataFrame` `cleanedDataFrame4` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Next, let's add a new column called `label2` in place of the dropped `label`
    column.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a new column to our DataFrame
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This time, invoke the `withColumn` method to add in the `label2` column as
    a replacement for `label1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Now, it is time to divide our dataset into a training set and a test set.
  prefs: []
  type: TYPE_NORMAL
- en: Dividing the DataSet into training and test sets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s split the dataset into two datasets. 85% of the dataset will be the
    training dataset and the remaining 15% will be the testing dataset, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Let's create a `StringIndexer` to index the `label2` column.
  prefs: []
  type: TYPE_NORMAL
- en: Creating labelIndexer to index the indexedLabel column
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s create `labelIndexer` now. This will create a new indexed input and
    output the columns `label` and `indexedLabel`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Next, let's `transform` our indexed labels back to the original labels that
    were not indexed.
  prefs: []
  type: TYPE_NORMAL
- en: Creating StringIndexer to index a column label
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following will help us create a `StringIndexer` to index the `label` column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: In the next step, we will create `RandomForestClassifier`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating RandomForestClassifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s create `randomForestClassifier` now and pass in the appropriate hyperparameters
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We have a classifier now. Now, we will create a new pipeline and create stages,
    with each stage holding the indexers that we have just created.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new data pipeline with three stages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s create the appropriate imports first, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Let's start building a pipeline now. This is a pipeline that has three stages,
    which are `StringIndexer`, `LabelIndexer`, and `randomForestClassifier`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new data pipeline with hyperparameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following steps need to be performed to create a new data pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new pipeline with the following three stages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a hyperparameter called `NumTrees` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a hyperparameter tree called `MaxDepth` and set it to `2` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: It is time to train the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Training our new data pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have a pipeline that is ready to be trained on the training dataset. Fitting
    (training) also runs the indexers, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Next, run a `transformation` operation on our `stockPriceModel` and generate
    stock price predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Generating stock price predictions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following steps need to be performed to generate stock price predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the `stockPriceModel` transformation operation on our test dataset as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s display the relevant columns of our `predictions` `DataFrame` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we want to evaluate the accuracy of our model, its ability to generate
    predictions, or in other words, find out how close the generated output was to
    the predictor labels, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Before we wind up this chapter, there are other metrics that we can evaluate.
    We leave this as an exercise for the reader.
  prefs: []
  type: TYPE_NORMAL
- en: Using the `MulticlassMetrics` class in the Spark ML API, it is possible to generate
    metrics that can tell us how close the predicted label value in the predicted
    column is to the actual label value in the `label` column.
  prefs: []
  type: TYPE_NORMAL
- en: 'Readers are invited to come up with two more metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weighted precision
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many other ways to build ML models to predict stock prices and help
    investors build their long-term investment strategy. For example, linear regression
    is another commonly used but fairly popular method for predicting stock prices.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to leverage the Random Forests algorithm to
    predict stock prices based on historical trends.
  prefs: []
  type: TYPE_NORMAL
- en: In next chapter, we will create a spam classifier. We will start with two datasets,
    one representing ham and the other, spam dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are a list of few questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What do you understand by linear regression? Why is it important?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does linear regression differ from logistic regression?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name one powerful feature of the binary classifier.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the feature variables in relation to the stock price dataset?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
