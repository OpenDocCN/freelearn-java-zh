- en: Chapter 5. Load Balancing with mod_cluster
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章：使用mod_cluster进行负载均衡
- en: In this chapter, we will have a look at another load balancer solution. It is
    called **mod_cluster** ([http://www.jboss.org/mod_cluster](http://www.jboss.org/mod_cluster)).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨另一种负载均衡解决方案。它被称为**mod_cluster**([http://www.jboss.org/mod_cluster](http://www.jboss.org/mod_cluster))。
- en: In comparison with JK, mod_cluster is more powerful and complex in design. Nevertheless,
    the added complexity in design doesn't mean it's harder to use; mod_cluster is
    designed to be scalable and can dynamically find the worker nodes so as to form
    a cluster.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 与JK相比，mod_cluster在设计上更强大和复杂。然而，设计中的额外复杂性并不意味着它更难使用；mod_cluster被设计成可扩展的，并且可以动态地找到工作节点，从而形成一个集群。
- en: Such kinds of flexibilities usually create confusion among newcomers and give
    them the impression that mod_cluster is harder to use. Thus, to appreciate the
    power of mod_cluster and its simplicity of usage, we must understand its design
    first.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这种灵活性通常会给新手带来困惑，并给他们留下mod_cluster难以使用的印象。因此，为了欣赏mod_cluster的强大功能和使用的简便性，我们首先必须了解其设计。
- en: The design of mod_cluster
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: mod_cluster的设计
- en: 'From the previous chapter, we know that JK uses a TCP port to communicate with
    the JBoss EAP6 server via AJP13 protocols. When compared with JK, mod_cluster
    uses the following three channels to serve its functions:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 从上一章，我们知道JK使用TCP端口通过AJP13协议与JBoss EAP6服务器通信。与JK相比，mod_cluster使用以下三个通道来执行其功能：
- en: A **connector channel** supports the multiple protocols for the load balancer
    to proxy user requests to worker nodes. This part is almost synonymous with JK.
    The difference here is that besides the AJP13 protocol, mod_cluster also supports
    the HTTP/HTTPS protocols.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**连接器通道**支持负载均衡器代理用户请求到工作节点的多种协议。这部分几乎等同于JK。这里的区别在于，除了AJP13协议外，mod_cluster还支持HTTP/HTTPS协议。'
- en: An **advertising channel** discovers worker nodes. This channel uses IP multicasting
    to transfer UDP datagrams. The load balancer will advertise itself in a multicast
    group, and the worker nodes will find it automatically by subscribing to this
    group.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广告通道**用于发现工作节点。该通道使用IP多播来传输UDP数据报。负载均衡器将在多播组中广播自己，而工作节点将通过订阅此组自动找到它。'
- en: A **management channel** is used to transfer status and management messages
    between the load balancer and the worker nodes. The protocol used by the management
    channel is an extension of the HTTP/1.1 protocol. The name of the protocol is
    **MCMP**.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管理通道**用于在负载均衡器和工作节点之间传输状态和管理消息。管理通道使用的协议是HTTP/1.1协议的扩展。该协议的名称是**MCMP**。'
- en: When compared with JK, mod_cluster can collect many runtime factors of a worker
    node to judge its "busy-ness", and it calculates a number that indicates the "busy-ness"
    of each worker node. This number is called a **load factor**, and the factors
    are called **metrics**.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 与JK相比，mod_cluster可以收集工作节点的许多运行时因素来判断其“繁忙程度”，并计算出一个表示每个工作节点“繁忙程度”的数字。这个数字被称为**负载因子**，而因素被称为**度量指标**。
- en: Tip
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'mod_cluster provides us with multiple metrics to use, such as `SystemMemoryUsageLoadMetric`
    and `AverageSystemLoadMetric`. A complete list of metrics can be found here: [http://docs.jboss.org/mod_cluster/1.2.0/html/java.load.html](http://docs.jboss.org/mod_cluster/1.2.0/html/java.load.html).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: mod_cluster为我们提供了多个度量指标来使用，例如`SystemMemoryUsageLoadMetric`和`AverageSystemLoadMetric`。完整的度量指标列表可以在此处找到：[http://docs.jboss.org/mod_cluster/1.2.0/html/java.load.html](http://docs.jboss.org/mod_cluster/1.2.0/html/java.load.html)。
- en: 'The deployment of mod_cluster is divided into two parts: the first part is
    the load balancer, and the other part is the worker node. In our scenario, the
    load balancer is **httpd**, and mod_cluster provides a native component for it.
    On the worker node side, we are using JBoss EAP6, and mod_cluster provides a subsystem
    for it. To sum up, let''s have an overview of its structure:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: mod_cluster的部署分为两部分：第一部分是负载均衡器，另一部分是工作节点。在我们的场景中，负载均衡器是**httpd**，mod_cluster为其提供了一个原生组件。在工作节点端，我们使用JBoss
    EAP6，mod_cluster为其提供了一个子系统。总的来说，让我们概述其结构：
- en: '![The design of mod_cluster](img/2432OS_05_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![mod_cluster的设计](img/2432OS_05_01.jpg)'
- en: 'As per the preceding diagram, mod_cluster is divided into two parts: the load
    balancer side and the worker node side. In addition, it has the following three
    channels that form its functions:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的图示，mod_cluster分为两部分：负载均衡器端和工作节点端。此外，它还具有以下三个通道，形成了其功能：
- en: The **advertise** channel allows the load balancer to advertise itself, and
    the worker nodes can dynamically join or exit a cluster at runtime.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**advertise**通道允许负载均衡器进行自我宣传，并且工作节点可以在运行时动态加入或退出集群。'
- en: With the **mod_manager** channel, the load balancer can get the load factor
    information from the worker node. The MCPM protocol is used in this channel, and
    the load factor, along with the rest of the information of the worker nodes, is
    sent at regular intervals.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**mod_manager**通道，负载均衡器可以从工作节点获取负载因子信息。在此通道中，使用MCPM协议，负载因子以及工作节点的其余信息以固定时间间隔发送。
- en: The **mod_proxy_cluster** channel will forward user requests to the worker nodes
    from behind. It supports the AJP13 protocol similar to JK, and it supports HTTP/HTTPS
    additionally.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**mod_proxy_cluster**通道将从后面将用户请求转发到工作节点。它支持类似于JK的AJP13协议，并且额外支持HTTP/HTTPS。'
- en: After this overview of the design of mod_cluster, we will learn how to install
    mod_cluster in the following section.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在对mod_cluster的设计概述之后，我们将在下一节学习如何安装mod_cluster。
- en: Installing mod_cluster
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装mod_cluster
- en: In this section, we will learn how to compile mod_cluster from the source code
    and install it on our load balancer machine. The machine I'm using to install
    mod_cluster and httpd is called *lb*, which is the same machine used in the previous
    chapter.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何从源代码编译mod_cluster并将其安装在我们的负载均衡器机器上。我用来安装mod_cluster和httpd的机器被称为*lb*，与上一章中使用的机器相同。
- en: 'We have learned how to compile and install httpd in the previous chapter, and
    we have put a lot of JK-related configurations in our httpd installation. To make
    the instructions in this chapter clearer, let''s archive the following httpd installation
    from the previous chapter:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何编译和安装httpd，并且在我们的httpd安装中放置了许多与JK相关的配置。为了使本章的说明更清晰，让我们将上一章的以下httpd安装存档：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We'll need to use it in the next chapter, so please back it up properly. Our
    next step is to repeat the httpd compiling and installing processes as we have
    done in the previous chapter. We actually just need to rerun `make install` in
    the httpd source directory because we have already configured and compiled it
    properly, and we will get a fresh httpd installation by running this command.
    Now let's move on with the mod_cluster installation.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章中使用它，所以请妥善备份。我们的下一步是重复上一章中进行的httpd编译和安装过程。实际上，我们只需要在httpd源目录中重新运行`make
    install`，因为我们已经正确配置和编译了它，通过运行此命令我们将获得一个新的httpd安装。现在让我们继续mod_cluster的安装。
- en: Downloading mod_cluster
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载mod_cluster
- en: 'Now we need to download mod_cluster. The source code of mod_cluster is hosted
    at GitHub. We will use Version 1.2.6.Final in this book: [https://github.com/modcluster/mod_cluster/archive/1.2.6.Final.zip](https://github.com/modcluster/mod_cluster/archive/1.2.6.Final.zip).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要下载mod_cluster。mod_cluster的源代码托管在GitHub上。本书中将使用1.2.6.Final版本：[https://github.com/modcluster/mod_cluster/archive/1.2.6.Final.zip](https://github.com/modcluster/mod_cluster/archive/1.2.6.Final.zip)。
- en: 'Download it and extract the zip file, and you will get the source directory
    `mod_cluster-1.2.6.Final`. The following are its contents:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 下载它并解压zip文件，您将得到源目录`mod_cluster-1.2.6.Final`。以下是其内容：
- en: '![Downloading mod_cluster](img/2432OS_05_02.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![下载mod_cluster](img/2432OS_05_02.jpg)'
- en: 'In the source directory, we can see that mod_cluster contains several components,
    but we only need to care about the components in the `native` directory. The other
    Java modules are for the worker node. Since EAP6 already contains the mod_cluster
    subsystem out of the box, we don''t need to compile them. Now let''s have a look
    at the `native` directory:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在源目录中，我们可以看到mod_cluster包含几个组件，但我们只需要关注`native`目录中的组件。其他Java模块是为工作节点准备的。由于EAP6已经内置了mod_cluster子系统，我们不需要编译它们。现在让我们看看`native`目录：
- en: '![Downloading mod_cluster](img/2432OS_05_03.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![下载mod_cluster](img/2432OS_05_03.jpg)'
- en: 'You may have guessed the purposes of some components by their names; let''s
    still check them one by one:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经通过组件的名称猜到了它们的一些用途；我们仍然要逐个检查它们：
- en: '| advertise | The advertising module for the supporting autodiscovery worker
    node |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| advertise | 支持自动发现工作节点的广告模块 |'
- en: '| mod_proxy_cluster | The proxy module that supports the AJP/HTTP/HTTPS proxy
    requests. |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| mod_proxy_cluster | 支持AJP/HTTP/HTTPS代理请求的代理模块。|'
- en: '| mod_manager | The mod_cluster manager module that controls the worker node
    and gets load factors from the worker node. |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| mod_manager | 控制工作节点并从工作节点获取负载因子的mod_cluster管理模块。|'
- en: '| mod_slotmem | The shared memory module used by mod_cluster internally. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| mod_slotmem | mod_cluster内部使用的共享内存模块。 |'
- en: '| selinux | The SElinux policy files. We won''t cover this topic in the book.
    |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| selinux | SELinux策略文件。本书不会涉及这个主题。 |'
- en: '| include | Common header files. |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| include | 公共头文件。 |'
- en: '| scripts | Some installation scripts we won''t use. |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| scripts | 一些我们不会使用的安装脚本。 |'
- en: As we have understood the meaning of these components, it's now time to build
    them.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经理解了这些组件的含义，现在是时候构建它们了。
- en: Compiling and installing mod_cluster
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编译和安装mod_cluster
- en: 'The modules that we need to build are advertise, mod_proxy_cluster, mod_manager,
    and mod_slotmem. It doesn''t matter which module you build first; let''s start
    with `advertise`. We need to find a script called `buildconf` in the directory
    as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要构建的模块是advertise、mod_proxy_cluster、mod_manager和mod_slotmem。你构建哪个模块都无关紧要；让我们从`advertise`开始。我们需要在以下目录中找到一个名为`buildconf`的脚本：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now let''s run this script:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们运行这个脚本：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'It will create a script called `configure`. Then we need to run the this script
    using the following command:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 它将创建一个名为`configure`的脚本。然后我们需要使用以下命令运行此脚本：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We''ve used the `--with-apxs` option to tell mod_cluster the position of httpd.
    After the configuring process is complete, please run the `make` command, and
    we will get the following shared library named `mod_advertise.so`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了`--with-apxs`选项来告诉mod_cluster httpd的位置。配置过程完成后，请运行`make`命令，我们将得到以下名为`mod_advertise.so`的共享库：
- en: '![Compiling and installing mod_cluster](img/2432OS_05_19.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![编译和安装mod_cluster](img/2432OS_05_19.jpg)'
- en: 'After the preceding library is built, let''s move it to the httpd `modules`
    folder:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的库构建完成后，让我们将其移动到httpd的`modules`文件夹：
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This is all that we need to do for compiling and installing `advertise`. Go
    to the directories of the other three modules, and use the same procedure to build
    them one by one. We'll get `mod_proxy_cluster.so`, `mod_manager.so`, and `mod_slotmem.so`.
    Please move all of them to the httpd `modules` directory.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们编译和安装`advertise`需要做的所有事情。转到其他三个模块的目录，并使用相同的程序逐个构建它们。我们将得到`mod_proxy_cluster.so`、`mod_manager.so`和`mod_slotmem.so`。请将它们全部移动到httpd的`modules`目录。
- en: These are all the mod_cluster components we need to install. In the following
    section, we will configure httpd to use these modules.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们需要安装的所有mod_cluster组件。在下一节中，我们将配置httpd以使用这些模块。
- en: Configuring mod_cluster
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置mod_cluster
- en: After installing the necessary mod_cluster components in httpd, we will configure
    them properly in this section.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在httpd中安装必要的mod_cluster组件后，我们将在本节中正确配置它们。
- en: Configuring httpd.conf
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置httpd.conf
- en: 'Before we start to configure mod_cluster, we need to do some preparations in
    `httpd.conf`. The first thing to do is to change the `Listen` directive from `Listen
    80` to the following:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始配置mod_cluster之前，我们需要在`httpd.conf`中做一些准备工作。首先要做的是将`Listen`指令从`Listen 80`更改为以下内容：
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As we know, *lb* has two IP addresses: one is the public address 172.16.123.1,
    and the other is 10.0.1.33, which is the internal IP address of the load balancer
    used to communicate with the two EAP6 servers. Now let''s learn the purpose of
    the configuration:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，*lb*有两个IP地址：一个是公开地址172.16.123.1，另一个是10.0.1.33，这是负载均衡器用于与两个EAP6服务器通信的内部IP地址。现在让我们了解配置的目的：
- en: '`10.0.1.33:80` will be used for a mod_cluster management console. We don''t
    want public access of this management console, so we just bind it to the local
    IP address.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`10.0.1.33:80`将用于mod_cluster管理控制台。我们不希望这个管理控制台公开访问，所以我们只将其绑定到本地IP地址。'
- en: '`10.0.1.33:6666` will be used by mod_manager to communicate with the EAP6 servers,
    and the message encapsulated in the MCPM protocol will be transferred through
    this channel.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`10.0.1.33:6666`将由mod_manager用于与EAP6服务器通信，封装在MCPM协议中的消息将通过此通道传输。'
- en: '`172.16.123.1:80` is the public address that serves user requests. If you don''t
    have a separate public IP address, you can just use your local IP address to serve
    all the requests.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`172.16.123.1:80`是服务用户请求的公开地址。如果你没有单独的公开IP地址，你可以直接使用你的本地IP地址来服务所有请求。'
- en: 'After configuring the listening addresses, the next step is to configure the
    `LogLevel`. We need to change the log level to `debug`; the following is the configuration
    for doing so:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置了监听地址后，下一步是配置`LogLevel`。我们需要将日志级别更改为`debug`；以下是如何进行配置的：
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We need the debug log output later. We will now go to the `ServerName` section
    and add the hostname of our load balancer. We are using `lb` as the hostname,
    so the configuration is as shown:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要稍后查看调试日志输出。我们现在将转到 `ServerName` 部分，并添加我们的负载均衡器的主机名。我们使用 `lb` 作为主机名，所以配置如下：
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'And please don''t forget to bind this server name to the public IP address
    in `/etc/hosts`. Next, we need to add an `Include` directive at the bottom of
    `httpd.conf`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 并且请记住将此服务器名绑定到 `/etc/hosts` 中的公共 IP 地址。接下来，我们需要在 `httpd.conf` 的底部添加一个 `Include`
    指令：
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This is all we need to do in `httpd.conf`. In the next section, we'll create
    a separate configuration file for mod_cluster in the `conf.d` directory
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是在 `httpd.conf` 中我们需要做的所有事情。在下一节中，我们将在 `conf.d` 目录中为 mod_cluster 创建一个单独的配置文件。
- en: Configuring mod_cluster
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置 mod_cluster
- en: 'Now let''s create a directory named `conf.d` in httpd:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在 httpd 中创建一个名为 `conf.d` 的目录：
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then we need to create a file called `mod-cluster.conf` in the same directory:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要在同一个目录下创建一个名为 `mod-cluster.conf` 的文件：
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Due to the `Include conf.d/*.conf` directive in `httpd.conf`, the created configuration
    file will be loaded during httpd startup.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `httpd.conf` 中的 `Include conf.d/*.conf` 指令，创建的配置文件将在 httpd 启动时被加载。
- en: 'Now let''s add the contents to this file. First, we need to load the following
    modules of mod_cluster:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将内容添加到这个文件中。首先，我们需要加载以下 mod_cluster 模块：
- en: '[PRE11]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Note that mod_cluster relies on some of the already configured modules in `httpd.conf`:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到 mod_cluster 依赖于 `httpd.conf` 中已经配置的一些模块：
- en: '[PRE12]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The preceding modules have already been loaded in `httpd.conf`. Please note
    that the `proxy-balancer` module is disabled in httpd because it conflicts with
    mod_cluster.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的模块已经在 `httpd.conf` 中被加载。请注意，由于与 mod_cluster 冲突，httpd 中的 `proxy-balancer`
    模块已被禁用。
- en: 'Now we need to define two virtual hosts: one is for the web management console,
    and the other is for the management module to send/receive MCPM messages. Let''s
    go through them one at a time. Here''s the configuration for the first one:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要定义两个虚拟主机：一个用于网页管理控制台，另一个用于管理模块发送/接收 MCPM 消息。让我们逐个来看。以下是第一个的配置：
- en: '[PRE13]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In the previous virtual host definition, we have defined a location called
    `/mc` and bound it to `mod_cluster-manager`. This handler will provide us with
    a web-based management console, which we''ll use in the later sections. Now let''s
    check the second virtual host definition:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的虚拟主机定义中，我们已经定义了一个名为 `/mc` 的位置，并将其绑定到 `mod_cluster-manager`。这个处理器将为我们提供一个基于网页的管理控制台，我们将在后面的章节中使用。现在让我们检查第二个虚拟主机定义：
- en: '[PRE14]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'There are two important directives in the preceding settings. One is the `ServerAdvertise`
    directive. The address set in this directive will be advertised by mod_cluster
    in the multicast group. For example, our setting is as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的设置中，有两个重要的指令。一个是 `ServerAdvertise` 指令。在此指令中设置的地址将由 mod_cluster 在多播组中广播。例如，我们的设置如下：
- en: '[PRE15]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'So, mod_cluster will broadcast it in a multicast group by saying something
    to this effect: "My MCPM management channel is located at http://10.0.1.32:6666,
    come and join me!". The worker nodes that are subscribed to the multicast group
    will receive this information and can then join the cluster.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，mod_cluster 将通过说类似这样的话来在多播组中广播：“我的 MCPM 管理通道位于 http://10.0.1.32:6666，来加入我吧！”订阅了多播组的
    worker 节点将接收到这个信息，然后可以加入集群。
- en: 'Please note that we don''t need to configure the multicast address for advertising.
    This is because the default address for advertising is 224.0.1.105:23364, which
    matches the default settings in EAP6\. We''ll see this in the next section. If
    you want to change this setting, you can use the `AdvertiseGroup` directive by
    placing it under the `ServerAdvertise` directive:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们不需要配置广告的组播地址。这是因为广告的默认地址是 224.0.1.105:23364，这与 EAP6 的默认设置相匹配。我们将在下一节中看到这一点。如果您想更改此设置，您可以使用
    `AdvertiseGroup` 指令，将其放置在 `ServerAdvertise` 指令下：
- en: '[PRE16]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Tip
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'You can always check the online document for mod_cluster to learn about these
    detail configurations: ([http://docs.jboss.org/mod_cluster/1.2.0/html/native.config.html](http://docs.jboss.org/mod_cluster/1.2.0/html/native.config.html)).'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以随时查看 mod_cluster 的在线文档，了解这些详细配置：([http://docs.jboss.org/mod_cluster/1.2.0/html/native.config.html](http://docs.jboss.org/mod_cluster/1.2.0/html/native.config.html))。
- en: 'Now let''s see the following directive:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看下面的指令：
- en: '[PRE17]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: With the preceding directive, the virtual host 10.0.1.32:6666 is used as a management
    channel, and MCPM is used as the communication protocol for this channel. This
    is all we need to do in `mod-cluster.conf`.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面的指令，虚拟主机 10.0.1.32:6666 被用作管理通道，MCPM 被用作此通道的通信协议。这就是我们在 `mod-cluster.conf`
    中需要做的所有事情。
- en: Configuring EAP6
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置 EAP6
- en: Until now, we haven't looked at the `modcluster` subsystem configuration in
    EAP6\. Since the default configuration provided by the EAP6 domain mode is good
    to use, we don't need to change anything. Let's have a look at the configuration
    anyway.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们还没有查看 EAP6 中的 `modcluster` 子系统配置。由于 EAP6 域模式提供的默认配置已经很好用，我们不需要做任何更改。但让我们看一下配置。
- en: 'From the configuration in `domain.xml`, we can see the following default settings
    of the `modcluster` subsystem:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 从 `domain.xml` 中的配置，我们可以看到 `modcluster` 子系统的以下默认设置：
- en: '[PRE18]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can see that the `modcluster` subsystem is bound to the advertising socket
    named `modcluster` by the `advertising-socket` directive. Then we see that the
    `modcluster` subsystem is using the `busyness` metric by default. It is a metric
    that judges the server "busy-ness" from the working threads. Now let''s see the
    settings of the socket-binding `modcluster`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，`modcluster` 子系统通过 `advertising-socket` 指令绑定到名为 `modcluster` 的广告套接字。然后我们看到，`modcluster`
    子系统默认使用 `busyness` 指标。这是一个从工作线程判断服务器“忙碌程度”的指标。现在让我们看看 `modcluster` 套接字绑定的设置：
- en: '[PRE19]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: From the preceding configuration, we can see that `224.0.1.1.105:23364` is the
    default multicast group address for advertising. This matches the settings on
    the httpd side.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的配置中，我们可以看到 `224.0.1.1.105:23364` 是广告的默认多播组地址。这与 httpd 端的设置相匹配。
- en: These settings are of the `modcluster` subsystem in EAP6\. As we have gone through
    the settings of mod_cluster from both sides, in the following section we will
    test the cluster.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这些设置是 EAP6 中的 `modcluster` 子系统的设置。因为我们已经从两端了解了 mod_cluster 的设置，所以在下一节中，我们将测试集群。
- en: Testing the cluster
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试集群
- en: In this section we'll test our cluster, so we need to start our load balancer
    and EAP6 servers. Before we start httpd on `lb`, we need to start the two EAP6
    servers. After the two EAP6 servers have been started, start httpd. In the following
    section, we'll examine the process of starting up httpd.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将测试我们的集群，因此我们需要启动我们的负载均衡器和 EAP6 服务器。在我们开始在 `lb` 上启动 httpd 之前，我们需要启动两个
    EAP6 服务器。在两个 EAP6 服务器启动后，再启动 httpd。在以下章节中，我们将检查启动 httpd 的过程。
- en: Starting up httpd
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动 httpd
- en: 'Now we need to start the httpd server. If everything goes fine, mod_cluster
    in httpd will begin to advertise itself in a multicast group, and the `modcluster`
    subsystem in the two EAP6 servers will be able to find mod_cluster in httpd by
    fetching its address in the advertising channel. We will investigate this process
    in the following sections; let''s first start httpd. The command to start httpd
    on `lb` is as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要启动 httpd 服务器。如果一切顺利，httpd 中的 mod_cluster 将开始在一个多播组中广播自己，两个 EAP6 服务器中的
    `modcluster` 子系统将通过在广播通道中获取其地址来找到 httpd。我们将在以下章节中调查这个过程；让我们首先启动 httpd。在 `lb` 上启动
    httpd 的命令如下：
- en: '[PRE20]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'After httpd has been started, mod_cluster will advertise itself to the multicast
    group 224.0.1.105:23364, and the `modcluster` subsystem on the two EAP6 servers
    will fetch the address of the management channel from the group, which is 10.0.1.32:6666\.
    Then the load balancers and the two EAP6 worker nodes will form a cluster by communicating
    in the management channel with the MCPM protocol. This process is shown in the
    following diagram:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在 httpd 启动后，mod_cluster 将向多播组 224.0.1.105:23364 广播自己，两个 EAP6 服务器上的 `modcluster`
    子系统将从该组中获取管理通道的地址，即 10.0.1.32:6666。然后负载均衡器和两个 EAP6 工作节点将通过使用 MCPM 协议在管理通道中进行通信来形成一个集群。这个过程在以下图中展示：
- en: '![Starting up httpd](img/2432OS_05_09.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![启动 httpd](img/2432OS_05_09.jpg)'
- en: To understand these steps, we need to analyze the packets sent across the network.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这些步骤，我们需要分析通过网络发送的数据包。
- en: The protocol analysis
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 协议分析
- en: We can use Wireshark to capture the IP datagrams from one of the worker nodes.
    In my example I'll run Wireshark on `master`. We can verify the advertising message
    sent by the load balancer on this machine.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 Wireshark 捕获来自一个工作节点的一个 IP 数据包。在我的例子中，我将在 `master` 上运行 Wireshark。我们可以验证这台机器上负载均衡器发送的广告消息。
- en: Tip
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: There is also a small Java program that allows us to join the multicast group
    and receive the httpd advertisement. See this program at [https://github.com/mod_cluster/mod_cluster/blob/master/test/java/Advertize.java](https://github.com/mod_cluster/mod_cluster/blob/master/test/java/Advertize.java).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 也有一个小型的Java程序，允许我们加入多播组并接收httpd广告。请参阅此程序[https://github.com/mod_cluster/mod_cluster/blob/master/test/java/Advertize.java](https://github.com/mod_cluster/mod_cluster/blob/master/test/java/Advertize.java)。
- en: The advertising channel
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 广告通道
- en: 'I have started Wireshark on `master` to capture the IP datagrams. I set it
    to catch all the datagrams on 224.0.1.105:23364, and the following are my findings:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经在`master`上启动了Wireshark来捕获IP数据包。我将它设置为捕获224.0.1.105:23364上的所有数据包，以下是我的发现：
- en: '![The advertising channel](img/2432OS_05_10.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![广告通道](img/2432OS_05_10.jpg)'
- en: From the preceding screenshot, we can see that `master` is receiving the advertising
    messages periodically. From the **Time** column, we can see that the advertising
    message is sent at 10-second intervals.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的截图可以看出，`master`定期接收广告消息。从**时间**列中，我们可以看到广告消息以10秒的间隔发送。
- en: Tip
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: You can change this by placing the `AdvertiseFrequency` directive into `conf.d/mod-cluster.conf`.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过将`AdvertiseFrequency`指令放入`conf.d/mod-cluster.conf`来更改此设置。
- en: 'We can see that the advertising message is in HTTP format. The following are
    the details of the message:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到广告信息是以HTTP格式。以下是该消息的详细信息：
- en: '[PRE21]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: As shown in the previous code, the advertising message places the load balancer
    information in the HTTP headers. Among these headers, we should note the value
    of `X-Manager-Address`. It tells the worker nodes where to find the load balancer.
    The other headers provide additional information to the worker nodes; this information
    describes the load balancer.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述代码所示，广告信息将负载均衡器信息放置在HTTP头部中。在这些头部中，我们应该注意`X-Manager-Address`的值。它告诉工作节点在哪里找到负载均衡器。其他头部为工作节点提供额外的信息；这些信息描述了负载均衡器。
- en: The management channel
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管理通道
- en: 'After the worker node comes to know the management address of the load balancer,
    it will communicate with the load balancer and register itself on it. To see this
    process, we need to look into the httpd log. As we have set the `LogLevel` to
    `debug` in `httpd.conf`, we can get many useful details. mod_cluster has outputted
    a lot of useful log information in the debug level, so we can check `logs/error_log`
    to see the sequence clearly. Here is the log:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在工作节点得知负载均衡器的管理地址后，它将与负载均衡器通信并在其上注册自己。要查看此过程，我们需要查看httpd日志。由于我们在`httpd.conf`中设置了`LogLevel`为`debug`，我们可以获取许多有用的详细信息。mod_cluster在调试级别输出了很多有用的日志信息，因此我们可以检查`logs/error_log`以清楚地查看序列。以下是日志：
- en: '[PRE22]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '`INFO` is the first MCMP command we''ve seen till now. This is the command
    that the worker node uses to request more details of the load balancer. As mod_cluster
    forms the cluster dynamically, it doesn''t know the details of the cluster in
    advance. The load balancer and worker node just discover each other in the multicast
    channel, so the worker node needs to know more detailed information about the
    load balancer. That''s why the worker node will send the `INFO` request to the
    load balancer, and the load balancer will reply with an `INFO-RSP` response.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '`INFO`是我们迄今为止看到的第一个MCMP命令。这是工作节点用来请求更多负载均衡器详细信息的命令。由于mod_cluster动态形成集群，它事先不知道集群的详细信息。负载均衡器和工作节点只在多播通道中相互发现，因此工作节点需要更多关于负载均衡器的详细信息。这就是为什么工作节点会向负载均衡器发送`INFO`请求，负载均衡器会以`INFO-RSP`响应。'
- en: 'Now let''s see the next step:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看下一步：
- en: '[PRE23]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: After the worker node gets the details of the load balancer, it will send to
    the load balancer a `CONFIG` message that tells the load balancer the previous
    worker node details. The `JVMRoute` is the worker node's name; this is automatically
    generated by the mod_cluster subsystem in EAP6\. Now we know the server `14a0af8b-59dd-33f9-8233-1f2584fefa67`
    corresponds to the server `10.0.1.19`, which is our slave EAP6 server.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点获取到负载均衡器的详细信息后，会向负载均衡器发送一个`CONFIG`消息，告知负载均衡器之前的工作节点详细信息。`JVMRoute`是工作节点的名称；这是由EAP6中的mod_cluster子系统自动生成的。现在我们知道服务器`14a0af8b-59dd-33f9-8233-1f2584fefa67`对应于服务器`10.0.1.19`，这是我们从属的EAP6服务器。
- en: 'Let''s check the next step:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查下一步：
- en: '[PRE24]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The worker node sends `ENABLE-APP` to the load balancer. This is used by the
    worker node to ask the load balancer to route the request corresponding to the
    context and the `Alias` value to the node defined by `JVMRoute`. In addition,
    we see the enabled application is `cluster-demo1`. So if we access the load balancer
    URL with the route `/cluster-demo1`, the request will be forwarded to the EAP6
    servers. Now let''s see the next step:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点向负载均衡器发送`ENABLE-APP`。这是工作节点用来请求负载均衡器将对应于上下文和`Alias`值的请求路由到由`JVMRoute`定义的节点。此外，我们看到已启用的应用程序是`cluster-demo1`。因此，如果我们通过路由`/cluster-demo1`访问负载均衡器URL，请求将被转发到EAP6服务器。现在让我们看看下一步：
- en: '[PRE25]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The worker node sends the `STATUS` message, which contains its current load
    factor. From line two of the previous log, we can see that the load factor of
    the slave EAP6 server is `100` (the smaller the factor number, the busier the
    server is). This message is sent periodically, and the load factor is refreshed
    to reflect the real-time status of the worker node. So the load balancer could
    know which server is busier and send this request to the worker nodes that have
    a lighter load.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点发送包含其当前负载因子的`STATUS`消息。从前一个日志的第二行，我们可以看到从属EAP6服务器的负载因子为`100`（因子数字越小，服务器越忙）。此消息定期发送，负载因子刷新以反映工作节点的实时状态。因此，负载均衡器可以知道哪个服务器更忙，并将此请求发送到负载较轻的工作节点。
- en: With the previous process, the worker node and load balancer have gathered enough
    information about each other and established communication. Then the `mod_proxy_cluster.so`
    cluster will start to do the real proxy job. In the following section, we will
    check this part.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 通过前面的过程，工作节点和负载均衡器已经收集了足够的信息，并建立了通信。然后，`mod_proxy_cluster.so`集群将开始执行实际的代理工作。在下一节中，我们将检查这部分。
- en: The connector channel analysis
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接器通道分析
- en: 'In the previous section, we saw how the load balancer advertises itself and
    how the worker node discovers it and registers itself into the cluster. Now let''s
    go on to check the `error_log` and see what''s going on:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们看到了负载均衡器如何自我宣传，以及工作节点如何发现它并将自己注册到集群中。现在让我们继续检查`error_log`，看看发生了什么：
- en: '[PRE26]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: As per the preceding log, mod_cluster has established a connection with `ajp://10.0.1.19:8259`.
    This is the AJP connector of the EAP6 server on the slave host. We can see that
    mod_cluster has set a name for our cluster, which is `mycluster`. We can check
    the status of this cluster from the management console. Let's access the management
    console through its URL, `http://10.0.1.32/mc`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的日志，mod_cluster已与`ajp://10.0.1.19:8259`建立连接。这是从属主机上EAP6服务器的AJP连接器。我们可以看到，mod_cluster已为我们集群设置了一个名称，即`mycluster`。我们可以从管理控制台检查此集群的状态。让我们通过其URL
    `http://10.0.1.32/mc` 访问管理控制台。
- en: 'This is shown in the following screenshot:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这在下面的屏幕截图中有显示：
- en: '![The connector channel analysis](img/2432OS_05_13.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![连接器通道分析](img/2432OS_05_13.jpg)'
- en: 'From the preceding screenshot, we can see that the two EAP6 servers form a
    cluster, and they all belong to `mycluster`. If you want to change the name of
    the balancer name, you can use the `ManagerBalancerName` directive in `mod-cluster.conf`
    like this:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的屏幕截图，我们可以看到两个EAP6服务器形成一个集群，它们都属于`mycluster`。如果您想更改均衡器名称，您可以使用`mod-cluster.conf`中的`ManagerBalancerName`指令，如下所示：
- en: '[PRE27]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'As per the previous configuration, the balancer name is set to `packtlb`. Now
    if we save the changes and restart httpd, we can see the balancer name change
    accordingly:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的配置，均衡器名称设置为`packtlb`。现在，如果我们保存更改并重新启动httpd，我们可以看到均衡器名称相应地更改：
- en: '[PRE28]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: This is useful when there are multiple load balancers running at the same time.
    With the balancer name, we can easily see which worker node belongs to which load
    balancer.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 当同时运行多个负载均衡器时，这很有用。通过均衡器名称，我们可以轻松地看到哪个工作节点属于哪个负载均衡器。
- en: 'Now let''s come back to the debug log; here is the last part we need to look
    at:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回到调试日志；这是我们最后需要查看的部分：
- en: '[PRE29]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: After the AJP channels are established, mod_cluster from the httpd side will
    send `ajp_cping_cpong` messages to the EAP6 worker nodes periodically to check
    whether the nodes are still alive.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在AJP通道建立后，来自httpd侧的mod_cluster将定期发送`ajp_cping_cpong`消息到EAP6工作节点，以检查节点是否仍然存活。
- en: As we have done the protocol analysis, in the following section we'll access
    the cluster to see if it works properly.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经完成了协议分析，在下一节中，我们将访问集群以查看其是否正常工作。
- en: Accessing the cluster
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 访问集群
- en: 'We can access the load balancer using its URL: `http://lb/cluster-demo1/index.jsp`.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过其URL访问负载均衡器：`http://lb/cluster-demo1/index.jsp`。
- en: 'By checking the two EAP6 servers output, we can see that the request is dispatched
    to `master`:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查两个EAP6服务器的输出，我们可以看到请求被分配到`master`：
- en: '[PRE30]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now when we check the mod_cluster management console, we can see that the master
    server has been elected once:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们检查mod_cluster管理控制台，我们可以看到主服务器已被选举一次：
- en: '![Accessing the cluster](img/2432OS_05_15.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![访问集群](img/2432OS_05_15.jpg)'
- en: As we can see from the preceding screenshot, the **Elected** count becomes **1**
    for the master server.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一张截图所示，主服务器的**选举**次数变为**1**。
- en: Failover
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 故障转移
- en: 'Now let''s kill the master server by pressing the *Ctrl* + *C* keys:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过按*Ctrl* + *C*键来终止主服务器：
- en: '[PRE31]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'From the slave server, we can see that it starts to throw the following exception
    because it cannot connect to the master server:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 从从服务器，我们可以看到它开始抛出以下异常，因为它无法连接到主服务器：
- en: '[PRE32]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This is expected because we have killed the master server. But it can still
    function as a server. Now let''s access the load balancer again; we can see that
    the following request is dispatched to the slave server:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预期的，因为我们已经终止了主服务器。但它仍然可以作为服务器运行。现在让我们再次访问负载均衡器；我们可以看到以下请求被分配到从服务器：
- en: '[PRE33]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now let''s access the mod_cluster management console, and we can see that the
    master server is removed automatically. In addition, the **Elected** count of
    the slave server becomes **1**:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们访问mod_cluster管理控制台，我们可以看到主服务器已被自动移除。此外，从服务器的**选举**次数变为**1**：
- en: '![Failover](img/2432OS_05_16.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![故障转移](img/2432OS_05_16.jpg)'
- en: 'Now let''s restart the EAP6 server on the master server, and it will rejoin
    the cluster. From the httpd debug log output, we can confirm this as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们在主服务器上重启EAP6服务器，它将重新加入集群。从httpd调试日志输出中，我们可以确认如下：
- en: '[PRE34]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'From the slave server output, we can see that it also restores the connection
    to the domain controller:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 从从服务器输出中，我们可以看到它也恢复了与域控制器的连接：
- en: '[PRE35]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Stress testing
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 压力测试
- en: 'Now let''s try to use the Apache HTTP server benchmarking tool (called **ab**)
    to load test our cluster. Here is the command:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们尝试使用Apache HTTP服务器基准测试工具（称为**ab**）来对我们的集群进行负载测试。以下是命令：
- en: '[PRE36]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We''ve used `15` threads to request our cluster `1500` times. Here are the
    results:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了`15`个线程向我们的集群发送`1500`次请求。以下是结果：
- en: '[PRE37]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'You can see that ab created some load on mod_cluster. Here are the statuses
    of the two worker nodes during testing:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到ab在mod_cluster上创建了一些负载。以下是测试期间两个工作节点状态的详细信息：
- en: '![Stress testing](img/2432OS_05_17.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![压力测试](img/2432OS_05_17.jpg)'
- en: 'The preceding screenshot depicts the status of the master server, and the status
    of the slave server is shown in the following screenshot:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 上一张截图显示了主服务器状态，下一张截图显示了从服务器状态：
- en: '![Stress testing](img/2432OS_05_18.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![压力测试](img/2432OS_05_18.jpg)'
- en: We can see that both the worker nodes are elected (the elected counts are more
    than 1,500 because I've run the preceding tests many times). We can also see that
    the **Load** factor on slave became **99**. This means the slave server is busier
    than the master server, so the load balancer will dispatch more requests to the
    master server later.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到两个工作节点都被选举了（选举次数超过1,500次，因为我已经多次运行了前面的测试）。我们还可以看到从服务器的**负载**因子变为**99**。这意味着从服务器比主服务器更忙，因此负载均衡器将在稍后分配更多请求到主服务器。
- en: Summary
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we have looked at the design of mod_cluster and its usages.
    This chapter is just an introductory text to mod_cluster. If you want to check
    the more advanced usage, please refer to its constantly improving online document:
    [http://docs.jboss.org/mod_cluster/1.2.0/html_single/](http://docs.jboss.org/mod_cluster/1.2.0/html_single/).'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了mod_cluster的设计及其用法。本章只是对mod_cluster的入门介绍。如果您想查看更高级的用法，请参阅其不断改进的在线文档：[http://docs.jboss.org/mod_cluster/1.2.0/html_single/](http://docs.jboss.org/mod_cluster/1.2.0/html_single/)。
- en: 'If you have any questions about using mod_cluster, you can always ask questions
    on the JBoss forum: [https://community.jboss.org/en/mod_cluster/content](https://community.jboss.org/en/mod_cluster/content).'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对使用mod_cluster有任何疑问，您可以在JBoss论坛上提问：[https://community.jboss.org/en/mod_cluster/content](https://community.jboss.org/en/mod_cluster/content)。
- en: In the next chapter, we'll see how to apply **Secure Sockets Layer** (**SSL**)
    in a clustering environment.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到如何在集群环境中应用**安全套接字层**（**SSL**）。
