- en: Creating a Container Image of Your Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we had a glimpse of the power of Quarkus applications
    by running a traditional JVM application and then turning it into a native build.
    There is much more to Quarkus than lean executables and low resource usage, though,
    so, in this chapter, we will keep learning how to create container images of our
    application that can then be deployed into a Kubernetes-native environment. For
    this purpose, our to-do list includes installing the Docker tool and the Community
    version of OpenShift, which is called **Origin Community Distribution of Kubernetes**,
    or simply **OKD**. Then, we will learn how to scale our application so that we
    can improve its response time even further.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Docker in your environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Starting a Quarkus application in a container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running a native executable in a container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying your container image on OpenShift
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling our application to improve its throughput
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find the source code for the project in this chapter on GitHub at [https://github.com/PacktPublishing/Hands-On-Cloud-Native-Applications-with-Java-and-Quarkus/tree/master/Chapter03](https://github.com/PacktPublishing/Hands-On-Cloud-Native-Applications-with-Java-and-Quarkus/tree/master/Chapter03).
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Docker is a tool that lets us simplify the creation and execution of containers
    in our environment. Each container, in turn, wraps up an application and its dependencies
    into a single standardized unit that includes everything it needs to run, that
    is, the system tools, code, and other required libraries. This guarantees that
    your application will always execute in the same way by sharing a simple container
    image. Docker is available in two versions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Community Edition** (**CE**): The Docker CE, which we will be using in this
    book, is ideal for developers and small teams looking for a quick start with Docker
    and container-based applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enterprise Edition** (**EE**): The EE features additional capabilities such
    as a certified infrastructure, image management, and image security scanning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although we will be using the Community version of Docker, this isn't going
    to reduce your application's full potential as we will be able to leverage advanced
    container capabilities through a native Kubernetes platform, which is an ideal
    solution for running business-critical applications in production at scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'The installation of Docker is fully documented at [https://docs.docker.com/install/](https://docs.docker.com/install/).
    In a nutshell, you can follow several installation tactics, depending on your
    needs:'
  prefs: []
  type: TYPE_NORMAL
- en: From a midterm perspective, you may want to ease the upgrade of Docker. Most
    users choose to set up Docker's repositories and install and upgrade from there
    ([https://docs.docker.com/install/linux/docker-ce/fedora/#install-using-the-repository](https://docs.docker.com/install/linux/docker-ce/fedora/#install-using-the-repository)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another option, which turns out to be pretty useful if you are installing Docker
    on a machine that is offline, requires manually installing the RPM package and
    manually handling upgrades as well ([https://docs.docker.com/install/linux/docker-ce/fedora/#install-from-a-package](https://docs.docker.com/install/linux/docker-ce/fedora/#install-from-a-package)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, for quick and easy installation, you can use the automated script,
    which will detect your operating system and install Docker accordingly. For the
    sake of simplicity, we will choose this option.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s proceed with installing Docker by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The automated script can be downloaded from [https://get.docker.com/](https://get.docker.com/),
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, execute it with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Important! Just like any other shell script, verify its content before executing
    it! Its content needs to match with the `install.sh` script located at [https://github.com/docker/docker-install](https://github.com/docker/docker-install).
    If the content doesn't match, verify whether the automated script is still being
    maintained by going to the Docker install page.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you would like to run Docker as a non-privileged user, you should consider
    adding your user to the `docker` group by executing the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'For this to take effect, you will need to log out and log in again. We can
    check that our user is now in the Docker group by checking the output of the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should include `docker` in the list of groups. Now, you can verify
    that you can run Docker commands without a root user (or `sudo`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command will pull the `hello-world` test image from the Docker
    repository, and run it in a container. When the test image starts, it prints an
    informative message and exits:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This message shows that your installation appears to be working correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Running Quarkus applications in a container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you have installed Docker, you are just ready to build a Docker image out
    of your Java or native executable application. For this purpose, we will quickly
    build another simple application that inspects some environment variables to determine
    the container ID where the application is running.
  prefs: []
  type: TYPE_NORMAL
- en: The source code for this chapter is located in the `Chapter03/hello-okd` folder
    of this book's GitHub repository. We recommend importing the project into your
    IDE before you continue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s dive into the code by starting with the REST endpoint class (`HelloOKD`),
    which returns some information from a **Contexts and Dependency Injection** (**CDI**)
    service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code is for the `ContainerService` class, which is injected into
    the REST endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This example shows the use of the CDI `@ApplicationScoped` annotation for injected
    objects. An object that is defined as `@ApplicationScoped` is created once for
    the duration of the lifetime of an application. In our case, it returns the `HOSTNAME`
    environment variable, which defaults to the Docker container ID.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to test our simple REST service, the following `HelloOKDTest` has
    been included in the project under the `src/test/java` path. Through its `testHelloEndpoint`
    method, we verify that the status code of the REST call was a success:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we set off on our journey into Docker, let''s check that the preceding
    test passes. The test phase will automatically kick in as we run the `install`
    goal of our project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'A successful test should produce the following log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s move on to looking at Docker. If you take a look at the `src/main/docker`
    folder, you will notice that some of the files have been automatically added to
    your project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The first file in the list, `Dockerfile.jvm`, is a Dockerfile that''s been
    specifically written for a JVM environment. Its content is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: A Dockerfile is a plain text file that contains a set of commands that we can
    use to assemble an image so that it can be executed by Docker. A Dockerfile needs
    to match with a specific format and set of instructions that have been documented
    in the Dockerfile reference ([https://docs.docker.com/engine/reference/builder/](https://docs.docker.com/engine/reference/builder/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, the Dockerfile contains instructions for building a Java environment
    using Fabric8 Java Base Image and enables the JMX exporter ([https://github.com/prometheus/jmx_exporter](https://github.com/prometheus/jmx_exporter))
    to expose process metrics. Now, we will build the image for our container, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In your console, you can verify that the Docker pull process will be triggered
    and that all the commands in the Dockerfile contribute to building the intermediate
    layers of your `quarkus/hello-okd` container image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s check that the image is available in your local Docker repository
    by executing the `docker images` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the locally cached image is now available in your local Docker
    repository. You can run it using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In the `run` command, we have included some additional flags, such as `--rm`,
    which removes the container automatically after it exits. The `-i` flag will connect
    the container to the Terminal. Finally, the `-p` flag exposes port `8080` externally,
    thus mapping to port `8080` on the host machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we will be exporting the service on the host port, that is, `8080`, check
    that no other service is engaging that port! You should be able to collect this
    output on the console, which is a log of the agent startup and, at the bottom,
    a log of our `hello-okd` service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The Docker process is now running, which can be confirmed by the following
    command. This command will display the `Image` name for running containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output of running the preceding command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'You can test that the application is running in the container with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'You should be able to see the same container ID that was printed by the `docker
    ps` command in the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Now, let's rebuild our container image so that we can use the native executable.
  prefs: []
  type: TYPE_NORMAL
- en: Running the native executable process in a container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we have seen, the Quarkus Maven plugin has also produced `src/main/docker/Dockerfile.native`,
    which can be used as a template so that we can run our native executable in a
    container. Here''s the content of this file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Since there's no need to use a JDK layer to start our application, the base
    layer for our container will be a stripped-down RHEL image known as `ubi-minimal`.
  prefs: []
  type: TYPE_NORMAL
- en: Red Hat **Universal Base Images** (**UBI**) are OCI-compliant container OS images
    that include complimentary runtime languages and other packages that are freely
    redistributable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before building the Docker image, package your application by including the
    `-Dnative-image.docker-build` option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Check that the build was successful and then build the image with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'From the console, you will see that the container will be created in much the
    same way that the Java application was, but using a different initial image (`ubi-minimal`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check that the image is available in the Docker repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The `quarkus/hello-okd-native` image is now available. Now, run the container
    image using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'No additional JVM layers will be displayed on the console. Here, we can see
    that our service was started up in just a few milliseconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Verify that the application returns the container ID when requesting the `getContainerId`
    URI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'In our case, the output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Great! We just managed to run a native application as a Docker image. Our next
    task will be deploying our image into a Kubernetes-native environment.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Quarkus applications on a Kubernetes-native platform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have verified how simple it is to run Quarkus applications in a
    container, we will deploy our application into a Kubernetes-native environment.
    Even if Kubernetes itself is sufficient to orchestrate your services, you can
    greatly extend its capabilities by installing OpenShift. Besides leveraging Kubernetes
    features, OpenShift also provides the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Better management of container images through the use of **image streams**,
    which decouple the actual image from your application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced CI/CD capabilities to make the whole CI/CD workflow a lot easier, also
    including a Jenkins certified image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A simpler build process as it's easier to build a docker image inside OpenShift
    through the `BuildConfig` component, which can perform automated image builds
    and push them to its internal registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A wealth of certified plugins, such as storage/networking/monitoring plugins
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for multitenancy through the **Resource Scheduler** component, which
    will determine where to run Pods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A large set of certified databases and middleware products
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A simpler UI web application from where you can easily manage your cluster of
    services and create new applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'OpenShift is available in several flavors:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Red Hat OpenShift Container Platform** (requires a subscription): The supported
    Kubernetes platform that lets you build, deploy, and manage your container-based
    applications consistently across cloud and on-premises infrastructures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Red Hat OpenShift Dedicated** (requires a subscription): This provides a
    supported, private, high-availability Red Hat OpenShift cluster hosted on Amazon
    Web Services or Google Cloud Platform.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Red Hat OpenShift Online** (several plans are available): It provides on-demand
    access to Red Hat OpenShift so that you can manage containerized applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Origin Community Distribution of Kubernetes** (**OKD**): This is the Community
    version of the Red Hat OpenShift Container Platform that you can freely use in
    any environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the purpose of this book, we will be installing **Minishift**, a simplified
    version of **OKD**, to launch a single-node cluster inside a virtual machine.
    This is the simplest approach to get started and try OpenShift on your local machine.
  prefs: []
  type: TYPE_NORMAL
- en: The current version of Minishift is based on the release 3.x of Openshift. It
    is highly recommended to move to an Openshift 4.x platform for most advanced examples,
    such as developing Cloud based reactive applications, which is discussed in the
    last chapter of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'The installation of Minishift is quite simple: all you''ll need to do is download
    and unzip the latest distribution of it. Some prerequisites, however, do exist
    as you need to prepare your system by installing a hypervisor, which is required
    to start the virtual environment that OKD is provisioned on.'
  prefs: []
  type: TYPE_NORMAL
- en: Installing Minishift
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will learn how to install Minishift on a machine running
    Fedora. If you don't run Fedora on your machine, you can check out the prerequisites
    for your OS at [https://docs.okd.io/latest/minishift/getting-started/preparing-to-install.html](https://docs.okd.io/latest/minishift/getting-started/preparing-to-install.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you will need to install two kernel modules (`libvirt` and `qemu**-**kvm`),
    which are needed to manage the various virtualization platforms. These are compliant
    with the **Kernel-based Virtual Machine** (**KVM**) technology. Follow these steps
    to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From the shell, execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, to run the virtualization platform with your user, add it to the `libvirt`
    group:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, configure the group membership with the user you are currently logged
    in as:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, you will need to download and make the KVM driver for your Docker
    machine executable. As the root user, execute the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Once your user has been set up, download and unpack the latest Minishift release
    package from the official GitHub repository: [https://github.com/minishift/minishift/releases](https://github.com/minishift/minishift/releases).
    At the time of writing, this is the latest version of Minishift that can be downloaded:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the download has completed, unpack the `.tar` file into a destination
    folder. For example, to unpack it into your home (`~`) directory, execute the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Within this package, you will find the `minishift` executable, which can be
    used to start your Minishift environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will run the `minishift` command to start the installation process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Once complete, you should see a message similar to the following in your Terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: And that's it! Minishift has been installed in your environment!
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s recommended that you include the following folders in the `$PATH` environment
    variable:'
  prefs: []
  type: TYPE_NORMAL
- en: The folder where you have unpacked the `minishift` tool.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The folder where the `oc` client tool is located. This tool is a command-line
    utility that you can use to manage your Minishift cluster. Once you start up the
    cluster, this tool is copied to `~/.minishift/cache/oc/<oc-version>/linux`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, for example, if you unpacked Minishift in your home directory, replace
    `oc-version` with your tool version and execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'You can verify this by opening the OpenShift web console in your default browser
    (in our case, `https://192.168.42.190:8443`) or by passing the `console` argument
    to the `minishift` tool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the console runs on a secured connection, you will be warned that no
    signed certificates have been found in your browser. Add a security exception
    to your browser so that you land on the login page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bd93639c-7c77-45e3-9837-1486b67607e1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Log in with `developer/developer` to enter the dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3cdc899c-2da8-45da-9f2b-1268cc2d91e2.png)'
  prefs: []
  type: TYPE_IMG
- en: Congratulations! You have installed Minishift and verified it. The next step
    will be deploying our sample application on it.
  prefs: []
  type: TYPE_NORMAL
- en: Building and deploying a Quarkus application on OKD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Minishift's dashboard contains a set of templates that can be used to build
    our applications quickly. At the time of writing, there's no Quarkus template;
    however, we can easily build and deploy our image as a **binary build** that conveys
    the Dockerfile that we have already tested.
  prefs: []
  type: TYPE_NORMAL
- en: A **binary build** is a feature that allows developers to upload artifacts from
    a binary source instead of pulling the source from a Git repository URL.
  prefs: []
  type: TYPE_NORMAL
- en: For this purpose, we will be using the `oc` client tool, which is the Swiss
    Army knife that's used to configure OpenShift and its objects.
  prefs: []
  type: TYPE_NORMAL
- en: The following set of commands is contained in the `deploy-openshift.sh` file,
    which is located in the `Chapter03` directory of this book's GitHub repository.
    If you are impatient to see your application in the cloud, simply execute the
    script and check that the output matches what we've written in this paragraph.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we will need to do is create a namespace for our project, which
    will be created in our current OpenShift namespace. You can create the `quarkus-hello-okd`
    namespace with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The first thing we will need to do is define a binary build object using the
    `oc new-build` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The previous command will produce an image binary build that will be pushed
    into Minishift''s internal registry. The following output describes the resources
    that were created for this purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that the build configuration has been created, we can check its availability
    by querying the `bc` alias (which stands for build config):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'As it is, the binary build doesn''t contain any reference to our Dockerfile.
    We can add this information using the `oc patch` command, which is a useful shortcut
    that we can use to edit resources. In our case, we need to set the `dockerfilePath`
    attribute that refers to the `dockerStrategy` element to the location where our
    Dockerfile is. From the root of your Quarkus project, execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'If you check the binary build description, you will see that the Dockerfile
    path has been included:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is a bit verbose; however, it should contain the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are ready to start the build process, which will take the project''s
    root folder (`.`) as input and will result in uploading `ImageStream` onto your
    Minishift environment. Execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will notify you that the image has been built and pushed to the
    Minishift registry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'As a proof of concept, let''s check the list of image streams that are available
    in the default project using its alias, `is`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Your `ImageStream` is now available. All we have to do is create an application
    that uses `ImageStream quarkus-hello-okd` as input. This can be done using the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the resources will be created. This will be confirmed by the resulting
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, our application is ready to be consumed. To allow external clients to
    access it, we need to expose it through a route object, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The route will be exposed and the following log will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'We can verify the route address with the following command, which uses a JSON
    template to display the virtual host address of our `quarkus-hello-okd` route:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'In our case, the route is accessible at the following address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Please note that the actual IP address of the route is determined by the hypervisor
    according to your network configuration, so don't be surprised if it differs from
    the address that was exposed in this example.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should be able to acknowledge this information from the web console, which
    shows that the application is up and running and that a single Pod has been started:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/62302b35-e85a-458c-8f32-efe6d45a5781.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you go to the route host/port you have been assigned (in our case, `http://quarkus-hello-okd-myproject.192.168.42.5.nip.io`),
    you will see the following welcome screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fe8baf16-18e9-4e8a-b0f4-7eafd361f0a5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is a simple static page that has been included in `src/main/resources/META-INF/resources/index.html`
    to show you that your application is available and contains some useful information
    about where you can place static assets and configuration. Your REST service,
    on the other hand, is still available through the REST URI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the application is running on the `quarkus-hello-okd-1-84xwq` Pod, the
    expected output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: Now, let's learn how to scale our Quarkus service by adding some replicas of
    our application.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling our Quarkus service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, you've learned how to deploy a Quarkus application on Minishift. The
    application is running in a Pod, which is allocated in its own internal IP address
    and is the equivalent of a machine running a container. In our case, the application
    is running on one Pod in an OpenShift node. This is sufficient to guarantee the
    availability of our applications since some liveness and readiness probes are
    periodically executed. If your Pods stop responding, the OpenShift platform will
    automatically restart them.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, your application probably needs to satisfy a minimum throughput.
    This requirement usually can't be met with just one Pod unless the number of requests
    is pretty low. In this case, the simplest strategy is horizontal Pod scaling,
    which will improve the number of available resources that will be automatically
    balanced when a request for your application arrives on the router.
  prefs: []
  type: TYPE_NORMAL
- en: Before scaling up our application, we will need to define an upper memory limit
    for it, in order to reduce the impact it will have on the cluster in terms of
    system resources. Since our Quarkus application doesn't require a large amount
    of memory, we will set a limit of 50 MB as the upper limit, which is quite reasonable,
    and definitely thinner than an average Java application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute the following command to set the memory limit to 50 MB. This will update
    the **deployment configuration** of your application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: A deployment configuration (whose alias in the command line is simply `dc`)
    describes the state of a particular component of the application as a Pod template.
    When you update the deployment configuration, a deployment process occurs to scale
    down the application and scale it up with a new deployment configuration and a
    new replication controller for the application.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following output should be returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'As a proof of concept, you can verify the deployment configuration through
    the `describe` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the `describe` command is a bit verbose; however, you should
    be able to see the following setting in the `Limits` section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s scale our application to 10 instances. This will be pretty fast
    since we have set a memory limit on the resources that are consumed by each Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the expected output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Moving to the web console, in the Overview panel, we will see that our application
    has scaled to 10 Pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/37d3f292-5448-4e98-b08c-793a23f269f9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that we have a large number of available Pods, let''s try to run a load
    test against our application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you should be able to see the response that was produced by the REST application
    in your console. This displays the ID of the Pod that executed the request (the
    output has been truncated for brevity):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: Although measuring the performance of our applications is beyond the scope of
    this book, you can go ahead and measure the time that's needed to run the equivalent
    Java application in the same cluster. You will notice a different response in
    terms of time and memory consumption!
  prefs: []
  type: TYPE_NORMAL
- en: 'That was our last task for this chapter. When you are done with this example,
    and you want to clean up the resources we created in our project, simply execute
    the following command, which will perform a bulk cleanup of resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'The output may vary, depending on the number of Pods available. However, it
    should look similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: The preceding log confirms that all the deleted resources have been successfully
    evicted.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we ran a simple REST application in a Docker container and
    then ran it in a Kubernetes-native environment, that is, Minishift. We saw how
    simple it is to make our applications highly available with a sound throughput
    by leveraging the features of a bundled distribution of OKD.
  prefs: []
  type: TYPE_NORMAL
- en: Now, it's time to add some more features to our application. In the next chapter,
    we will learn how to configure the Undertow extension, which can be added to provide
    web server capabilities to our application. It also includes some UI assets, which
    we will look at in brief.
  prefs: []
  type: TYPE_NORMAL
