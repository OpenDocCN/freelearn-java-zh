<html><head></head><body><div class="chapter" title="Chapter&#xA0;7.&#xA0;Performance Optimization"><div class="titlepage"><div><div><h1 class="title"><a id="ch07"/>Chapter 7. Performance Optimization</h1></div></div></div><p>Performance optimization<a class="indexterm" id="id496"/> is additive by nature, as in it works by adding performance tuning to the knowledge of how the underlying system works, and to the result of performance measurement. This chapter builds on the previous ones that covered "how the underlying system works" and "performance measurement". Though you will notice some recipe-like sections in this chapter, you already know the pre-requisite in order to exploit those well. Performance tuning is an iterative process of measuring performance, determining bottlenecks, applying knowledge in order to experiment with tuning the code, and repeating it all until performance improves. In this chapter, we will cover:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Setting up projects for better performance</li><li class="listitem" style="list-style-type: disc">Identifying performance bottlenecks in the code</li><li class="listitem" style="list-style-type: disc">Profiling code with VisualVM</li><li class="listitem" style="list-style-type: disc">Performance tuning of Clojure code</li><li class="listitem" style="list-style-type: disc">JVM performance tuning</li></ul></div><div class="section" title="Project setup"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec48"/>Project setup</h1></div></div></div><p>While finding<a class="indexterm" id="id497"/> bottlenecks is essential to fixing performance problems in the code, there are several things one can do right from the start to ensure better performance.</p><div class="section" title="Software versions"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec95"/>Software versions</h2></div></div></div><p>Usually, new software versions include bug fixes, new features, and performance improvements. Unless <a class="indexterm" id="id498"/>advised to the contrary, it is better to use newer versions. For development with Clojure, consider the following software versions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>JVM version</strong></span>: As of this writing, Java 8 (Oracle JDK, OpenJDK, Zulu) has been released as the latest stable production-ready version. It is not only stable, it also has better performance in several areas (especially concurrency) than the earlier<a class="indexterm" id="id499"/> versions. If you have a choice, choose Java 8 over the older versions of Java.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Clojure version</strong></span>: As of this writing, Clojure 1.7.0 is the latest stable version that has several performance improvements over the older versions. There are also new<a class="indexterm" id="id500"/> features (transducers, volatile) that can make your code perform better. Choose Clojure 1.7 over the older versions unless you have no choice.</li></ul></div></div><div class="section" title="Leiningen project.clj configuration"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec96"/>Leiningen project.clj configuration</h2></div></div></div><p>As of version 2.5.1, the default Leiningen template (<code class="literal">lein new foo</code>, <code class="literal">lein new app foo</code>) needs few tweaks<a class="indexterm" id="id501"/> to make the project amenable to performance. Ensure your Leiningen <code class="literal">project.clj</code> file has<a class="indexterm" id="id502"/> the following entries, as appropriate.</p><div class="section" title="Enable reflection warning"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec31"/>Enable reflection warning</h3></div></div></div><p>One of the most<a class="indexterm" id="id503"/> common pitfalls in Clojure programming is to inadvertently let the code resort to reflection. Recall that we discussed this in <a class="link" href="ch03.html" title="Chapter 3. Leaning on Java">Chapter 3</a>, <span class="emphasis"><em>Leaning on Java. Enabling</em></span>, reflection warning is quite easy, let's fix it by adding the following entry to <code class="literal">project.clj</code>:</p><div class="informalexample"><pre class="programlisting">:global-vars {*unchecked-math* :warn-on-boxed ; in Clojure 1.7+
              *warn-on-reflection* true}</pre></div><p>In the previous configuration, the first setting <code class="literal">*unchecked-math* :warn-on-boxed</code> works only in Clojure 1.7—it emits numeric boxing warnings. The second setting <code class="literal">*warn-on-reflection* true</code> works on earlier Clojure versions as well as Clojure 1.7, and emits reflection warning messages in the code.</p><p>However, including these settings in <code class="literal">project.clj</code> may not be enough. Reflection warnings are emitted only when a namespace is loaded. You need to ensure that all namespaces are loaded in order to search for reflection warnings throughout the project. This can be done by writing tests that refer to all namespaces, or via scripts that do so.</p></div><div class="section" title="Enable optimized JVM options when benchmarking"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec32"/>Enable optimized JVM options when benchmarking</h3></div></div></div><p>In <a class="link" href="ch04.html" title="Chapter 4. Host Performance">Chapter 4</a>, <span class="emphasis"><em>Host Performance</em></span> we<a class="indexterm" id="id504"/> discussed that Leiningen enables tiered compilation by default, which provides low startup time at the cost of poor JIT compiler optimization. The default setting is quite misleading for performance benchmarking, so you should enable JVM options that are representative of what you would use in production:</p><div class="informalexample"><pre class="programlisting">:profiles {:perf {:test-paths ^:replace ["perf-test"]
                  :jvm-opts ^:replace ["-server"
                                       "-Xms2048m" "-Xmx2048m"]}}</pre></div><p>For example, the previous setting defines a Leiningen profile that overrides the default JVM options to configure a <code class="literal">server</code> Java runtime with 2 GB of fixed-size heap space. It also sets test paths to a directory <code class="literal">perf-test</code>. Now you can run performance tests as follows:</p><div class="informalexample"><pre class="programlisting">lein with-profile perf test</pre></div><p>If your project has<a class="indexterm" id="id505"/> performance test suites that require different JVM options, you should define multiple profiles for running tests, as appropriate.</p></div></div><div class="section" title="Distinguish between initialization and runtime"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec97"/>Distinguish between initialization and runtime</h2></div></div></div><p>Most non-trivial projects<a class="indexterm" id="id506"/> need a lot of context to be set up before they can function. Examples of such contexts could be app configuration, in-memory state, I/O resources, thread pools, caches, and so on. While many projects start with ad hoc configuration and initialization, eventually projects need to isolate the initialization phase from runtime. The purpose of this distinction is not only to sanitize the organization of code, but also to pre-compute as much as possible once before the runtime can take over to repeatedly respond to demands. This distinction also allows the initialization phase to easily (and conditionally, based on configuration) instrument the initialized code for performance logging and monitoring.</p><p>Non-trivial programs are usually divided into layers, such as business logic, caching, messaging, database access, and so on. Each layer has a dependency relationship with one or more of the other layers. It is feasible to carry out the isolation of the initialization phase by writing code using first principles, and many projects actually do that. However, there are a few libraries that simplify this process by letting you declare the dependency relationship between<a class="indexterm" id="id507"/> layers. <span class="strong"><strong>Component</strong></span> (<a class="ulink" href="https://github.com/stuartsierra/component">https://github.com/stuartsierra/component</a>) and <span class="strong"><strong>Prismatic Graph</strong></span> (<a class="ulink" href="https://github.com/Prismatic/plumbing">https://github.com/Prismatic/plumbing</a>) are notable <a class="indexterm" id="id508"/>examples of such libraries.</p><p>The Component library is well documented. It may not be easily apparent how to use Prismatic Graph for dependency resolution; following is a contrived example for illustration:</p><div class="informalexample"><pre class="programlisting">(require '[plumbing.core :refer [fnk]])
(require '[plumbing.graph :as g])

(def layers
  {:db      (fnk [config]    (let [pool (db-pool config)]
                               (reify IDatabase ...)))
   :cache   (fnk [config db] (let [cache-obj (mk-cache config)]
                               (reify ICache    ...)))
   :service (fnk [config db cache] (reify IService  ...))
   :web     (fnk [config service]  (reify IWeb      ...))})

(defn resolve-layers
  "Return a map of reified layers"
  [app-config]
  (let [compiled (g/compile layers)]
    (compiled {:config app-config})))</pre></div><p>This example merely shows the construction of a layer dependency graph, but often you may need different construction scope and order for testing. In that case you may define different graphs and resolve them, as and when appropriate. If you need teardown logic for testing, you can<a class="indexterm" id="id509"/> add extra <code class="literal">fnk</code> entries for each teardown step and use those for teardown.</p></div></div></div>
<div class="section" title="Identifying performance bottlenecks"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec49"/>Identifying performance bottlenecks</h1></div></div></div><p>We discussed in previous chapters that random performance tuning of code rarely works, because we may not be<a class="indexterm" id="id510"/> tuning in the right place. It is crucial to find the performance bottlenecks before we can tune those areas in the code. Upon finding the bottleneck, we can experiment with alternate solutions around it. In this section we will look into finding the bottlenecks.</p><div class="section" title="Latency bottlenecks in Clojure code"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec98"/>Latency bottlenecks in Clojure code</h2></div></div></div><p>Latency is the starting, and the most obvious, metric to drill-down in order to find bottlenecks. For Clojure code, we observed in <a class="link" href="ch06.html" title="Chapter 6. Measuring Performance">Chapter 6</a>, <span class="emphasis"><em>Measuring Performance</em></span> that code profiling tools can help<a class="indexterm" id="id511"/> us find the areas of bottleneck. Profilers are, of course, very useful. Once you discover hotspots <a class="indexterm" id="id512"/>via profilers, you may find ways to tune those for latency to a certain extent.</p><p>Most profilers work on aggregates, a batch of runs, ranking the hotspots in code by resources consumed. However, often the opportunity to tune latency lies in the long tail that may not be highlighted by the profilers. In such circumstances, we may employ a direct drill-down technique. Let's see how to carry out such drill-down using <span class="strong"><strong>Espejito</strong></span> (<a class="ulink" href="https://github.com/kumarshantanu/espejito">https://github.com/kumarshantanu/espejito</a>), a Clojure<a class="indexterm" id="id513"/> library for measuring latency (as of version 0.1.0) across measurement points in single-threaded execution paths. There are two parts of <a class="indexterm" id="id514"/>using <span class="strong"><strong>Espejito</strong></span>, both requiring change to your code—one to wrap the code being measured, and the other to report the collected measurement data. The following code illustrates a contrived E-commerce use case of adding an item to a cart:</p><div class="informalexample"><pre class="programlisting">(require '[espejito.core :as e])

;; in the top level handler (entry point to the use case)
(e/report e/print-table
  ...)

;; in web.clj
(e/measure "web/add-cart-item"
  (biz/add-item-to-cart (resolve-cart request) item-code qty)
  ...)

;; in service.clj (biz)
(defn add-item-to-cart
  [cart item qty]
  (e/measure "biz/add-cart-item"
    (db/save-cart-item (:id cart) (:id item) qty)
    ...))

;; in db.clj (db)
(defn save-cart-item
  [cart-id item-id qty]
  (e/measure "db/save-cart-item"
    ...))</pre></div><p>Reporting a call is required to be made only once at the outermost (top-level) layer of the code. Measurement calls can be made at any number of places in the call path. Be careful not to put measurement calls inside tight loops, which may shoot memory consumption up. When this execution path is triggered, the functionality works as usual, while the latencies are<a class="indexterm" id="id515"/> measured and recorded alongside transparently in memory. The <code class="literal">e/report</code> call prints a table of recorded metrics. An example output (edited to fit) would be:</p><div class="informalexample"><pre class="programlisting">|                 :name|:cumulat|:cumul%|:indiv |:indiv%|:thrown?|
|----------------------+--------+-------+-------+-------+--------|
|    web/add-cart-item |11.175ms|100.00%|2.476ms|22.16% |        |
| biz/add-item-to-cart | 8.699ms| 77.84%|1.705ms|15.26% |        |
|    db/save-cart-item | 6.994ms| 62.59%|6.994ms|62.59% |        |</pre></div><p>Here we can observe that the database call is the most expensive (individual latency), followed by the web layer. Our tuning preference may be guided by the order of expensiveness of the measurement points.</p><div class="section" title="Measure only when it is hot"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec33"/>Measure only when it is hot</h3></div></div></div><p>One important <a class="indexterm" id="id516"/>aspect we did not cover in the drill-down measurement is whether the environment is ready for measurement. The <code class="literal">e/report</code> call is invoked unconditionally every time, which would not only have its own overhead (table printing), but the JVM may not be warmed up and the JIT compiler may not have kicked in to correctly report the latencies. To ensure that we report only meaningful latencies, let's trigger the <code class="literal">e/report</code> call on an example condition:</p><div class="informalexample"><pre class="programlisting">(defmacro report-when
  [test &amp; body]
  `(if ~test
    (e/report e/print-table
      ~@body)
    ~@body))</pre></div><p>Now, let's assume it is a <span class="strong"><strong>Ring</strong></span>-based (<a class="ulink" href="https://github.com/ring-clojure/ring">https://github.com/ring-clojure/ring</a>) web app and you <a class="indexterm" id="id517"/>want to trigger the reporting only when the web request contains a parameter <code class="literal">report</code> with a value <code class="literal">true</code>. In that case, your call might look like the following:</p><div class="informalexample"><pre class="programlisting">(report-when (= "true" (get-in request [:params "report"]))
  ...)</pre></div><p>Condition-based invocation expects the JVM to be up across several calls, so it may not work with command-line apps.</p><p>This technique can also be used in performance tests, where non-reporting calls may be made during a certain warm-up period, followed by a reporting call that provides its own reporter function instead of <code class="literal">e/print-table</code>. You may even write a sampling reporter function that <a class="indexterm" id="id518"/>aggregates the samples over a duration and finally reports the latency metrics. Not only for performance testing, you can use this for latency monitoring where the reporter function logs the metrics instead of printing a table, or sends the latency breakup to a metrics aggregation system.</p></div></div><div class="section" title="Garbage collection bottlenecks"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec99"/>Garbage collection bottlenecks</h2></div></div></div><p>Since Clojure runs <a class="indexterm" id="id519"/>on the JVM, one has to be aware of the GC behavior in the application. You can print out the GC details at runtime by specifying the respective JVM options in <code class="literal">project.clj</code> or on the Java <a class="indexterm" id="id520"/>command-line:</p><div class="informalexample"><pre class="programlisting">:jvm-options ^:replace [..other options..
<span class="strong"><strong>                        "-verbose:gc" "-XX:+PrintGCDetails"</strong></span>
<span class="strong"><strong>                        "-XX:+PrintGC" "-XX:+PrintGCTimeStamps"</strong></span>
                        ..other options..]</pre></div><p>This causes a detailed summary of GC events to be printed as the application runs. To capture the output in a file, you can specify the following parameter:</p><div class="informalexample"><pre class="programlisting">:jvm-options ^:replace [..other options..
                        "-verbose:gc" "-XX:+PrintGCDetails"
                        "-XX:+PrintGC" "-XX:+PrintGCTimeStamps"
<span class="strong"><strong>                        "-Xloggc:./memory.log"</strong></span>
                        ..other options..]</pre></div><p>It is also useful to see the time between and during full GC events:</p><div class="informalexample"><pre class="programlisting">:jvm-options ^:replace [..other options..
                        "-verbose:gc" "-XX:+PrintGCDetails"
                        "-XX:+PrintGC" "-XX:+PrintGCTimeStamps"
<span class="strong"><strong>                        "-XX:+PrintGCApplicationStoppedTime"</strong></span>
<span class="strong"><strong>                        "-XX:+PrintGCApplicationConcurrentTime"</strong></span>
                        ..other options..]</pre></div><p>The other useful options to troubleshoot GC are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">-XX:+HeapDumpOnOutOfMemoryError</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">-XX:+PrintTenuringDistribution</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">-XX:+PrintHeapAtGC</code></li></ul></div><p>The output of the <a class="indexterm" id="id521"/>previous options may help you identify GC bottlenecks that you can try to fix by choosing the<a class="indexterm" id="id522"/> right garbage collector, other generational heap options, and code changes. For easy viewing of GC logs, you may like to use GUI tools such as<a class="indexterm" id="id523"/> <span class="strong"><strong>GCViewer</strong></span> (<a class="ulink" href="https://github.com/chewiebug/GCViewer">https://github.com/chewiebug/GCViewer</a>) for this purpose.</p><div class="section" title="Threads waiting at GC safepoint"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec34"/>Threads waiting at GC safepoint</h3></div></div></div><p>When there is a long<a class="indexterm" id="id524"/> tight loop (without any I/O operation) in the code, the thread executing it cannot be brought to safepoint if GC happens when the loop ends or goes out of memory (for example, fails to allocate). This may have a disastrous effect of stalling other critical threads during GC. You can identify this category of bottleneck by enabling safepoint logs using the following JVM option:</p><div class="informalexample"><pre class="programlisting">:jvm-options ^:replace [..other options..
                        "-verbose:gc" "-XX:+PrintGCDetails"
                        "-XX:+PrintGC" "-XX:+PrintGCTimeStamps"
<span class="strong"><strong>                        "-XX:+PrintSafepointStatistics"</strong></span>
                        ..other options..]</pre></div><p>The safepoint logs emitted by the previous option may help you identify the impact of a tight-loop thread on other threads during GC.</p></div><div class="section" title="Using jstat to probe GC details"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec35"/>Using jstat to probe GC details</h3></div></div></div><p>The Oracle<a class="indexterm" id="id525"/> JDK (also OpenJDK, Azul's Zulu) comes with a utility called <code class="literal">jstat</code> that can be handy to inspect GC details. You can find details on<a class="indexterm" id="id526"/> this utility at <a class="ulink" href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstat.html">https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstat.html</a> —the following examples show how to use it:</p><div class="informalexample"><pre class="programlisting">jstat -gc -t &lt;process-id&gt; 10000
jstat -gccause -t &lt;process-id&gt; 10000</pre></div><p>The first <a class="indexterm" id="id527"/>command mentioned previously monitors object allocations and freeing in various heap generations, together with other GC statistics, one in every 10 seconds. The second command also prints the reason for GC, along with other details.</p></div></div><div class="section" title="Inspecting generated bytecode for Clojure source"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec100"/>Inspecting generated bytecode for Clojure source</h2></div></div></div><p>We discussed in <a class="link" href="ch03.html" title="Chapter 3. Leaning on Java">Chapter 3</a>, <span class="emphasis"><em>Leaning on Java</em></span> how to see the generated equivalent Java code for any Clojure <a class="indexterm" id="id528"/>code. Sometimes, there may not be a direct correlation between the generated bytecode and Java, which is when inspecting the generated bytecode is very useful. Of course, it requires the reader to know<a class="indexterm" id="id529"/> at least a bit about the JVM instruction set (<a class="ulink" href="http://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html">http://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html</a>). This tool can allow you to very effectively analyze the cost of the generated bytecode instructions.</p><p>The project <span class="strong"><strong>no.disassemble</strong></span> (<a class="ulink" href="https://github.com/gtrak/no.disassemble">https://github.com/gtrak/no.disassemble</a>) is a very useful tool to<a class="indexterm" id="id530"/> discover the generated bytecode. Include it in your <code class="literal">project.clj</code> file as a Leiningen plugin:</p><div class="informalexample"><pre class="programlisting">:plugins [[lein-nodisassemble "0.1.3"]]</pre></div><p>Then, at the REPL, you can inspect the generated bytecodes one by one:</p><div class="informalexample"><pre class="programlisting">(require '[no.disassemble :as n])
(println (n/disassemble (map inc (range 10))))</pre></div><p>The previous snippet prints out the bytecode of the Clojure expression entered there.</p></div><div class="section" title="Throughput bottlenecks"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec101"/>Throughput bottlenecks</h2></div></div></div><p>The throughput <a class="indexterm" id="id531"/>bottlenecks usually arise from shared resources, which could be CPU, cache, memory, mutexes and locks, GC, disk, and other I/O devices. Each of these resources has a different way to find utilization, saturation, and load level. This also heavily depends on the operating system in use, as it manages the resources. Delving into the OS-specific ways of determining those factors is beyond the scope of this text. However, we will look at profiling some of these for bottlenecks in the next section.</p><p>The net effect of throughput shows up as an inverse relationship with latency. This is natural as per Little's law—as we will see in the next chapter. We covered throughput testing and latency testing under concurrency in <a class="link" href="ch06.html" title="Chapter 6. Measuring Performance">Chapter 6</a>, <span class="emphasis"><em>Measuring Performance</em></span>. This should be roughly a good indicator of the throughput trend.</p></div></div>
<div class="section" title="Profiling code with VisualVM"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec50"/>Profiling code with VisualVM</h1></div></div></div><p>The Oracle JDK (also OpenJDK) comes with a powerful profiler called <span class="strong"><strong>VisualVM</strong></span>; the distribution that comes<a class="indexterm" id="id532"/> with the JDK is known as Java VisualVM and can be invoked using the binary executable:</p><div class="informalexample"><pre class="programlisting">jvisualvm</pre></div><p>This launches the GUI profiler app where you can connect to running instances of the JVM. The profiler has powerful<a class="indexterm" id="id533"/> features (<a class="ulink" href="https://visualvm.java.net/features.html">https://visualvm.java.net/features.html</a>) that can be useful for finding various bottlenecks in code. Besides analyzing heap dump and thread dump, VisualVM can interactively graph CPU and heap consumption, and thread status in near real time. It also has sampling and tracing profilers for both CPU and memory.</p></div>
<div class="section" title="The Monitor tab"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec51"/>The Monitor tab</h1></div></div></div><p>The <span class="strong"><strong>Monitor</strong></span> tab has a<a class="indexterm" id="id534"/> graphical overview of the runtime, including CPU, heap, threads and loaded classes:</p><div class="mediaobject"><img alt="The Monitor tab" src="graphics/3642_07_01.jpg"/></div><p>This tab is useful for "at a glance" information, leaving further drill-down for other tabs.</p><div class="section" title="The Threads tab"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec102"/>The Threads tab</h2></div></div></div><p>In the following screenshot, the <span class="strong"><strong>Threads</strong></span> tab shows the status of all threads:</p><div class="mediaobject"><img alt="The Threads tab" src="graphics/3642_07_02.jpg"/></div><p>It is very useful to find out if any threads are undergoing contention, entering deadlock, are underutilized, or they are taking up more<a class="indexterm" id="id535"/> CPU. Especially in concurrent apps with in-memory state, and in apps that use limited I/O resources (such as connection pools, or network calls to other hosts) shared by threads, this feature provides a great insight if you set the thread names:</p><p>Notice the threads named <span class="strong"><strong>citius-RollingStore-store-1</strong></span> through <span class="strong"><strong>citius-RollingStore-store - 4</strong></span>. In an ideal no-contention scenario, those threads would have a green <span class="strong"><strong>Running</strong></span> status. See the legend at the bottom right of the image, which explains thread state:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Running</strong></span>: A thread is running, which<a class="indexterm" id="id536"/> is the ideal condition.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Sleeping</strong></span>: A thread has <a class="indexterm" id="id537"/>yielded control temporarily.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Wait</strong></span>: A thread is waiting for notification in a critical section. <code class="literal">Object.wait()</code> was called, and is now<a class="indexterm" id="id538"/> waiting for <code class="literal">Object.notify()</code> or <code class="literal">Object.notifyAll()</code> to wake it up.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Park</strong></span>: A thread is parked <a class="indexterm" id="id539"/>on a permit (binary semaphore) waiting for some condition. Usually seen with concurrent blocking calls in the <code class="literal">java.util.concurrent</code> API.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Monitor</strong></span>: A thread has<a class="indexterm" id="id540"/> reached object monitor waiting for some lock, perhaps waiting to enter or exit a critical section.</li></ul></div><p>You can install the<a class="indexterm" id="id541"/> <span class="emphasis"><em>Threads Inspector</em></span> plugin for details on threads of interest. To inspect thread dumps from the command line you can use the <code class="literal">jstack</code> or <code class="literal">kill -3</code> commands.</p></div><div class="section" title="The Sampler tab"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec103"/>The Sampler tab</h2></div></div></div><p>The <span class="strong"><strong>Sampler</strong></span> tab is the lightweight sampling profiler tab that can sample both CPU and memory consumption. You<a class="indexterm" id="id542"/> can easily find hotspots in code that may benefit from tuning. However, sampler profiling is limited by sampling period and frequency, inability to detect inlined code, and so on. It is a good general indicator of the bottlenecks <a class="indexterm" id="id543"/>and looks similar to the screenshots we saw in <a class="link" href="ch06.html" title="Chapter 6. Measuring Performance">Chapter 6</a>, <span class="emphasis"><em>Measuring Performance</em></span>. You can profile either CPU or memory at a time.</p><p>The <span class="strong"><strong>CPU</strong></span> tab<a class="indexterm" id="id544"/> displays both the overall CPU time distribution and per-thread CPU consumption. You can take a thread dump while sampling is in progress and analyze the dump. There are several VisualVM plugins available for more analysis.</p><p>The <span class="strong"><strong>Memory</strong></span> tab displays heap histogram metrics with distribution and instance count of objects. It also shows a PermGen histogram and per thread allocation data. It is a very good idea and highly recommended to set thread names in your project so that it is easy to locate those names in such tools. In this tab, you can force a GC, take a heap dump for analysis, and view memory metrics data in several ways.</p><div class="section" title="Setting the thread name"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec36"/>Setting the thread name</h3></div></div></div><p>Setting a thread name in <a class="indexterm" id="id545"/>Clojure is quite straightforward using Java interop:</p><div class="informalexample"><pre class="programlisting">(.setName ^Thread (Thread/currentThread) "service-thread-12")</pre></div><p>However, since threads often transcend several contexts, in most cases you should do so in a limited scope as follows:</p><div class="informalexample"><pre class="programlisting">(defmacro with-thread-name
  "Set current thread name; execute body of code in that context."
  [new-name &amp; body]
  `(let [^Thread thread# (Thread/currentThread)
         ^String t-name# thread#]
     (.setName thread# ~new-name)
     (try
       ~@body
       (finally
         (.setName thread# t-name#)))</pre></div><p>Now you can use this macro to execute any body of code with a specified thread name:</p><div class="informalexample"><pre class="programlisting">(with-thread-name (str "process-order-" order-id)
  ;; business code
  )</pre></div><p>This style of<a class="indexterm" id="id546"/> setting a thread name makes sure that the original name is restored before leaving the thread-local scope. If your code has various sections and you are setting a different thread name for each section, you can detect which code sections are causing contention by looking at the name when any contention appears on profiling and monitoring tools.</p></div></div><div class="section" title="The Profiler tab"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec104"/>The Profiler tab</h2></div></div></div><p>The <span class="strong"><strong>Profiler</strong></span> tab lets you instrument the running code in the JVM, and profile both CPU and memory consumption. This option adds a larger overhead than the <span class="strong"><strong>Sampler</strong></span> tab, and poses a different trade<a class="indexterm" id="id547"/> off in terms of JIT compilation, inlining, and accuracy. This tab does not have as much diversity in visualization as the <span class="strong"><strong>Sampler</strong></span> tab. The main difference this tab has with the <span class="strong"><strong>Sampler</strong></span> tab is it changes the bytecode of the running code for accurate measurement. When you choose CPU profiling, it starts instrumenting the code for CPU profiling. If <a class="indexterm" id="id548"/>you switch from CPU to memory profiling, it re-instruments the running code for memory profiling, and re-instruments every time you want a different profiling. One downside of such instrumentation is that it may massively slow down everything if your code is deployed in application containers, such as Tomcat.</p><p>While you can get most of the common CPU bottleneck information from <span class="strong"><strong>Sampler</strong></span>, you may need the <span class="strong"><strong>Profiler</strong></span> to investigate hotspots already discovered by <span class="strong"><strong>Sampler</strong></span> and other profiling techniques. You can selectively profile and drill-down only the known bottlenecks using the instrumenting profiler, thereby restricting its ill-effects to only small parts of the code.</p></div><div class="section" title="The Visual GC tab"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec105"/>The Visual GC tab</h2></div></div></div><p>The<a class="indexterm" id="id549"/> <span class="strong"><strong>Visual GC</strong></span> is a <a class="indexterm" id="id550"/>VisualVM plugin that visually depicts the GC status in near real time.</p><div class="mediaobject"><img alt="The Visual GC tab" src="graphics/3642_07_03.jpg"/></div><p>If your application uses<a class="indexterm" id="id551"/> a lot of memory and potentially has GC bottlenecks, this plugin may be very useful for various troubleshooting purposes.</p></div><div class="section" title="The Alternate profilers"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec106"/>The Alternate profilers</h2></div></div></div><p>Besides VisualVM, there are<a class="indexterm" id="id552"/> several third-party profilers and performance-monitoring tools for the Java platform. Among open source tools, Prometheus (<a class="ulink" href="http://prometheus.io/">http://prometheus.io/</a>) and<a class="indexterm" id="id553"/> Moskito (<a class="ulink" href="http://www.moskito.org/">http://www.moskito.org/</a>) are<a class="indexterm" id="id554"/> relatively popular. A non-exhaustive list of <a class="indexterm" id="id555"/>Open Source performance tools is here: <a class="ulink" href="http://java-source.net/open-source/profilers">http://java-source.net/open-source/profilers</a>
</p><p>There are several commercial proprietary profilers that you may want to know about. The YourKit (<a class="ulink" href="https://www.yourkit.com/">https://www.yourkit.com/</a>) Java<a class="indexterm" id="id556"/> profiler is probably the most notable profiler that many people have found much success with for profiling Clojure code. There are also other<a class="indexterm" id="id557"/> profiling tools for the JVM, such as JProfiler (<a class="ulink" href="https://www.ej-technologies.com/products/jprofiler/overview.html">https://www.ej-technologies.com/products/jprofiler/overview.html</a>), which is a desktop-based profiler and web-based hosted <a class="indexterm" id="id558"/>solutions such as New Relic<a class="indexterm" id="id559"/> (<a class="ulink" href="http://newrelic.com/">http://newrelic.com/</a>) and<a class="indexterm" id="id560"/> AppDynamics (<a class="ulink" href="https://www.appdynamics.com/">https://www.appdynamics.com/</a>).</p></div></div>
<div class="section" title="Performance tuning"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec52"/>Performance tuning</h1></div></div></div><p>Once we get insight into the code via testing and profiling results, we need to analyze the bottlenecks worth considering for optimization. A better approach is to find the most under-performing portion and optimize it, thereby eliminating the weakest link. We discussed performance aspects of hardware and JVM/Clojure in previous chapters. Optimization and tuning requires rethinking the design and code in light of those aspects, and then refactoring for performance objectives.</p><p>Once we establish the<a class="indexterm" id="id561"/> performance bottlenecks, we have to pinpoint the root cause and experiment with improvisations, one step at a time, to see what works. Tuning for performance is an iterative process that is backed by measurement, monitoring and experimentation.</p><div class="section" title="Tuning Clojure code"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec107"/>Tuning Clojure code</h2></div></div></div><p>Identifying the nature of the performance bottleneck helps a lot in order to experiment with the right aspects <a class="indexterm" id="id562"/>of the code. The key is to determine the origin of cost and <a class="indexterm" id="id563"/>whether the cost is reasonable.</p><div class="section" title="CPU/cache bound"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec37"/>CPU/cache bound</h3></div></div></div><p>As we noted in the <a class="indexterm" id="id564"/>beginning of this chapter, setting up a project with the right JVM options and project settings informs us of reflection and boxing, the common sources of CPU-bound performance issues after poor design and algorithm choice. As a general rule, we have to see <a class="indexterm" id="id565"/>whether we are doing unnecessary or suboptimal operations, especially inside loops. For example, transducers are amenable to better performance than lazy sequences in CPU-bound operations.</p><p>While public functions are recommended to work with immutable data structures, the implementation details can afford to use transients and arrays when performance is necessary. Records are a great alternative to maps, where appropriate, due to type hints and tight field layout in the former. Operations on primitive data types is faster (hence recommended) than their boxed equivalents.</p><p>In tight loops, besides transients and arrays you may prefer loop-recur with unchecked math for performance. You may also like to avoid using multi-methods and dynamic vars in tight loops, rather than pass arguments around. Using Java and macros may be the last resort, but still an option if there is such a need for performance.</p></div><div class="section" title="Memory bound"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec38"/>Memory bound</h3></div></div></div><p>Allocating less memory<a class="indexterm" id="id566"/> in code is always going to reduce memory-related performance issues. Optimization of memory-bound code is not only about reducing memory consumption, but it is also about memory layout and utilizing the CPU and cache well. We have to see whether we are using the data types that fit well in CPU registers and cache lines. For cache and memory-bound code, we have to know whether there are cache misses and the reason—often the data might be too large to fit in a cache line. For memory-bound code we have to care about data locality, whether the <a class="indexterm" id="id567"/>code is hitting the interconnect too often, and whether memory representation of data can be slimmed down.</p></div><div class="section" title="Multi-threaded"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec39"/>Multi-threaded</h3></div></div></div><p>Shared resources with side effects are the main source of contention and performance bottlenecks in multi-threaded code. As we saw in the <span class="emphasis"><em>Profiling VisualVM code </em></span>section in this chapter, profiling the threads better informs us about the bottlenecks. The best way to improve performance of multi-threaded <a class="indexterm" id="id568"/>code is to reduce contention. The easy way to reduce contention is to increase the resources and reduce concurrency, though only optimal levels of resources and concurrency would be good for performance. While designing for concurrency, append only, single writer, and shared nothing approaches work well.</p><p>Another way to reduce contention may be to exploit thread-local queueing of data until resources are available. This technique is similar to what Clojure agents use, though it is an involved technique. <a class="link" href="ch05.html" title="Chapter 5. Concurrency">Chapter 5</a>, <span class="emphasis"><em>Concurrency</em></span> covers agents in some detail. I would encourage you to study the agents source code for better understanding. When using CPU-bound resources (for example <code class="literal">java.util.concurrent.atomic.AtomicLong</code>) you may use the contention-striping technique used by some Java 8 classes (such as <code class="literal">java.util.concurrent.atomic.LongAdder</code>, which also balances between memory consumption and contention striping across processors.) This technique is also quite involved and generic contention-striping solutions may have to trade off read consistency to allow fast updates.</p></div></div><div class="section" title="I/O bound"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec108"/>I/O bound</h2></div></div></div><p>I/O-bound tasks could be limited by bandwidth or IOPS/latency. Any I/O bottleneck usually manifests in chatty I/O calls or unconstrained data serialization. Restricting I/O to only minimum required<a class="indexterm" id="id569"/> data is a common opportunity to minimize serialization and reduce latency. I/O operations can often be batched for higher throughput, for example <span class="emphasis"><em>SpyMemcached</em></span> library employs an asynchronous batched operation for high throughput.</p><p>I/O-bound bottlenecks are often coupled with multi-threaded scenarios. When the I/O calls are synchronous (for example, the JDBC API), one naturally has to depend upon multiple threads working on a bounded resource pool. Asynchronous I/O can relieve our threads from blocking, letting the threads do other useful work until the I/O response arrives. In synchronous I/O, we pay the cost of having threads (each allocated with memory) block on I/O calls while the kernel schedules them.</p></div><div class="section" title="JVM tuning"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec109"/>JVM tuning</h2></div></div></div><p>Often Clojure applications might inherit bloat from Clojure/Java libraries or frameworks, which cause poor performance. Hunting down unnecessary abstractions and unnecessary layers of code may bring decent performance gains. Reasoning about the performance of dependency libraries/frameworks before inclusion in a project is a good approach.</p><p>The JIT compiler, garbage collector and safepoint (in Oracle HotSpot JVM) have a significant impact on<a class="indexterm" id="id570"/> the performance of applications. We discussed the JIT compiler and garbage collector in <a class="link" href="ch04.html" title="Chapter 4. Host Performance">Chapter 4</a>, <span class="emphasis"><em>Host Performance</em></span>. When the HotSpot JVM reaches a point when it cannot carry out concurrent, incremental GC anymore, it needs to suspend the JVM safely in order to carry out a full GC. It is also called the stop-the-world GC pause that may run up to several minutes while the JVM appears frozen.</p><p>The Oracle and OpenJDK JVMs accept many command-line options when invoked, to tune and monitor the way components in the JVM behave. Tuning GC is common among people who want to extract optimum performance from the JVM. </p><p>You may like to experiment with the following JVM options (Oracle JVM or OpenJDK) for performance:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>JVM option</p>
</th><th style="text-align: left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">-XX:+AggressiveOpts</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Aggressive options that enable <a class="indexterm" id="id571"/>compressed heap pointers</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">-server</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Server class<a class="indexterm" id="id572"/> JIT thresholds (use -client for GUI apps)</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">-XX:+UseParNewGC</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Use <a class="indexterm" id="id573"/>Parallel GC</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">-Xms3g</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Specify min<a class="indexterm" id="id574"/> heap size (keep it less on desktop apps)</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">-Xmx3g</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Specify <a class="indexterm" id="id575"/>max heap size (keep min/max same on servers)</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">-XX:+UseLargePages</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Reduce<a class="indexterm" id="id576"/> Translation-Lookaside Buffer misses (if OS supports), see <a class="ulink" href="http://www.oracle.com/technetwork/java/javase/tech/largememory-jsp-137182.html">http://www.oracle.com/technetwork/java/javase/tech/largememory-jsp-137182.html</a> for details</p>
</td></tr></tbody></table></div><p>On the Java 6 HotSpot JVM, the<a class="indexterm" id="id577"/> <span class="strong"><strong>Concurrent Mark and Sweep</strong></span> (<span class="strong"><strong>CMS</strong></span>) garbage collector is well regarded for its GC performance. On the Java 7 and Java 8 HotSpot JVM, the default GC is a parallel collector (for better throughput), whereas at the time of writing this, there is a proposal to use the G1 collector (for lower pauses) by default in the upcoming Java 9. Note that the JVM GC can be tuned for different objectives, hence the same exact configuration for one application may not work well for another. Refer to the documents Oracle published for tuning the JVM at the<a class="indexterm" id="id578"/> following links:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><a class="ulink" href="http://www.oracle.com/technetwork/java/tuning-139912.html">http://www.oracle.com/technetwork/java/tuning-139912.html</a></li><li class="listitem" style="list-style-type: disc"><a class="ulink" href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/">https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/</a></li></ul></div></div><div class="section" title="Back pressure"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec110"/>Back pressure</h2></div></div></div><p>It is not uncommon to see applications behaving poorly under load. Typically, the application server simply appears unresponsive, which is often a combined result of high resource utilization, GC pressure, more threads that lead to busier thread scheduling, and cache misses. If the capacity of a system is known, the solution is to apply <span class="strong"><strong>back pressure</strong></span> by denying <a class="indexterm" id="id579"/>services after the capacity is reached. Note that back pressure cannot be applied optimally until the system is load-tested for optimum capacity. The capacity threshold that triggers back pressure may or may not be directly associated with individual services, but rather can be defined as load criteria.</p></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec53"/>Summary</h1></div></div></div><p>It is worth reiterating that performance optimization begins with learning about how the underlying system works, and measuring the performance of systems we build under representative hardware and load. The chief component of performance optimization is identifying the bottlenecks using various kinds of measurements and profiling. Thereafter, we can apply experiments to tune the performance of code and measure/profile once again to verify. The tuning mechanism varies depending on the type of bottleneck.</p><p>In the next chapter, we will see how to address performance concerns when building applications. Our focus will be on the several common patterns that impact performance.</p></div></body></html>