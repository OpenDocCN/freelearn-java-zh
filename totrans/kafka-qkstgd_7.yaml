- en: KSQL
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: KSQL
- en: In previous chapters, we wrote Java code to manipulate data streams with Kafka,
    and we also we built several Java processors for Kafka and Kafka Streams. In this
    chapter, we will use KSQL to achieve the same results.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们编写了 Java 代码来使用 Kafka 操作数据流，我们还为 Kafka 和 Kafka Streams 构建了几个 Java 处理器。在本章中，我们将使用
    KSQL 来实现相同的结果。
- en: 'This chapter covers the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了以下主题：
- en: KSQL in a nutshell
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简要介绍 KSQL
- en: Running KSQL
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行 KSQL
- en: Using the KSQL CLI
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 KSQL CLI
- en: Processing data with KSQL
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 KSQL 处理数据
- en: Writing to a topic
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向主题写入
- en: KSQL in a nutshell
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简要介绍 KSQL
- en: 'With Kafka Connect, we can build clients in several programming languages:
    JVM (Java, Clojure, Scala), C/C++, C#, Python, Go, Erlang, Ruby, Node.js, Perl,
    PHP, Rust, and Swift. In addition to this, if your programming language is not
    listed, you can use the Kafka REST proxy. But the Kafka authors realized that
    all programmers, especially data engineers, can all talk the same language: **Structured
    Query Language** (**SQL**). So, they decided to create an abstraction layer on
    Kafka Streams in which they could manipulate and query streams using SQL.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Kafka Connect，我们可以在多种编程语言中构建客户端：JVM（Java、Clojure、Scala）、C/C++、C#、Python、Go、Erlang、Ruby、Node.js、Perl、PHP、Rust
    和 Swift。除此之外，如果你的编程语言不在列表中，你可以使用 Kafka REST 代理。但 Kafka 开发者意识到，所有程序员，尤其是数据工程师，都可以使用同一种语言：**结构化查询语言**（**SQL**）。因此，他们决定在
    Kafka Streams 上创建一个抽象层，在这个抽象层中，他们可以使用 SQL 来操作和查询流。
- en: KSQL is a SQL engine for Apache Kafka. It allows writing SQL sentences to analyze
    data streams in real time. Remember that a stream is an unbounded data structure,
    so we don't know where it begins, and we are constantly receiving new data. Therefore,
    KSQL queries usually keep generating results until you stop them.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: KSQL 是 Apache Kafka 的 SQL 引擎。它允许编写 SQL 语句以实时分析数据流。请记住，流是一个无界的数据结构，所以我们不知道它从哪里开始，我们一直在接收新的数据。因此，KSQL
    查询通常会持续生成结果，直到你停止它们。
- en: KSQL runs over Kafka Streams. To run queries over a data stream, the queries
    are parsed, analyzed, and then a Kafka Streams topology is built and executed,
    just as we did at the end of each `process()` method when running Kafka Streams
    applications. KSQL has mapped the Kafka Streams concepts one to one, for example,
    tables, joins, streams, windowing functions, and so on.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: KSQL 在 Kafka Streams 上运行。要在一个数据流上运行查询，查询会被解析、分析，然后构建并执行一个 Kafka Streams 拓扑，就像我们在运行
    Kafka Streams 应用程序时在每个 `process()` 方法结束时所做的那样。KSQL 已经将 Kafka Streams 的概念一一映射，例如，表、连接、流、窗口函数等。
- en: KSQL runs on KSQL servers. So if we need more capacity, we can run one or more
    instances of KSQL servers. Internally, all the KSQL instances work together, sending
    and receiving information through a dedicated and private topic called `_confluent-ksql-default__command_topic`.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: KSQL 在 KSQL 服务器上运行。因此，如果我们需要更多容量，我们可以运行一个或多个 KSQL 服务器实例。内部，所有 KSQL 实例协同工作，通过一个称为
    `_confluent-ksql-default__command_topic` 的专用和私有主题发送和接收信息。
- en: 'As with all Kafka technologies, we can also interact with KSQL through a REST
    API. Also, KSQL, has its own fancy **command-line interface** (**CLI**). If you
    want to read more about KSQL read the online documentation at the following URL:
    [https://docs.confluent.io/current/ksql/docs/index.html](https://docs.confluent.io/current/ksql/docs/index.html).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有 Kafka 技术一样，我们也可以通过 REST API 与 KSQL 交互。此外，KSQL 还拥有自己的精美 **命令行界面**（**CLI**）。如果您想了解更多关于
    KSQL 的信息，请阅读以下 URL 上的在线文档：[https://docs.confluent.io/current/ksql/docs/index.html](https://docs.confluent.io/current/ksql/docs/index.html)。
- en: Running KSQL
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行 KSQL
- en: 'As mentioned previously, KSQL is shipped with the Confluent Platform. When
    we start the Confluent Platform, automatically at the end it starts a KSQL server,
    as shown in the *Figure 7 .1*:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，KSQL 随 Confluent 平台一起提供。当我们启动 Confluent 平台时，它会在结束时自动启动一个 KSQL 服务器，如图 *7.1*
    所示：
- en: '![](img/90352a54-1b1d-4e12-994e-9b7fae1ccfdd.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/90352a54-1b1d-4e12-994e-9b7fae1ccfdd.png)'
- en: 'Figure 7.1: Confluent Platform startup'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1：Confluent 平台启动
- en: 'To start the KSQL server alone (not recommendable), we can use the `ksql-server-start`
    command. Just type `./ksql` from the bin directory, as shown in *Figure 7.2*:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要单独启动 KSQL 服务器（不推荐），我们可以使用 `ksql-server-start` 命令。只需从 bin 目录中输入 `./ksql`，如图
    *7.2* 所示：
- en: '![](img/3dede300-c03e-4ea1-bb21-427859df15e8.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3dede300-c03e-4ea1-bb21-427859df15e8.png)'
- en: 'Figure 7.2: KSQL CLI start screen'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2：KSQL CLI 启动屏幕
- en: Using the KSQL CLI
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 KSQL CLI
- en: The KSQL CLI is a command prompt to interact with KSQL; it is very similar to
    the one that comes with relational databases such as MariaDB or MySQL. To see
    all the possible commands, type help and a list with the options will be displayed.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: KSQL CLI 是一个用于与 KSQL 交互的命令提示符；它与 MariaDB 或 MySQL 等关系型数据库附带的命令提示符非常相似。要查看所有可能的命令，请输入
    help，将显示一个带有选项的列表。
- en: At the moment, we have not informed KSQL of anything. We must declare that something
    is a table or a stream. We will use the information produced from previous chapters
    with the producers that write JSON information to the `healthchecks` topic.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们还没有向 KSQL 通知任何内容。我们必须声明某个东西是一个表或一个流。我们将使用前面章节中生产者写入 JSON 信息到 `healthchecks`
    主题产生的信息。
- en: 'If you remember, the data looks like this:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得，数据看起来是这样的：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'KSQL can read JSON data, and can also read data in Avro format. To declare
    a stream from the `healthchecks` topic, we use the following command:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: KSQL 可以读取 JSON 数据，也可以读取 Avro 格式的数据。要从 `healthchecks` 主题声明一个流，我们使用以下命令：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output is similar to this:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下内容：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To review the structure of an existing `STREAM`, we can use the `DESCRIBE`
    command, which is shown here and that tells us the data types and their structure:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看现有 `STREAM` 的结构，我们可以使用 `DESCRIBE` 命令，如下所示，它告诉我们数据类型及其结构：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output is similar to the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下内容：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Note that at the beginning, two extra fields are shown: `ROWTIME` (the message
    timestamp) and `ROWKEY` (the message key).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，一开始会显示两个额外的字段：`ROWTIME`（消息时间戳）和`ROWKEY`（消息键）。
- en: 'When we created the stream, we declared that the Kafka topic is `healthchecks`.
    So, if we execute the `SELECT` command, we obtain a list of the events that are
    in the topic to which our stream points in real time (remember to run a producer
    to obtain fresh data). The command is as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们创建流时，我们声明 Kafka 主题是 `healthchecks`。因此，如果我们执行 `SELECT` 命令，我们将获得一个列表，其中包含实时指向我们的流所在主题的事件（记得运行一个生产者以获取新鲜数据）。命令如下：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output is similar to this:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下内容：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `SELECT` command shows the data from the Kafka topic declared in the stream.
    The query never stops, so it will run till you stop it. New records are printed
    as new lines, as new events are produced in the topic. To stop a query, type *Ctrl*
    + *C*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`SELECT` 命令显示了流中声明的 Kafka 主题的数据。查询永远不会停止，所以它会一直运行，直到你停止它。新记录以新行打印，因为主题中新的事件被产生。要停止查询，请输入
    *Ctrl* + *C*。'
- en: Processing data with KSQL
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 KSQL 处理数据
- en: In previous chapters, we took the data from the `healthchecks` topic, calculated
    the `uptimes` of the machines, and pushed this data into a topic called `uptimes`.
    Now, we are going to do this with KSQL.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们从 `healthchecks` 主题获取数据，计算机器的 `uptimes`，并将这些数据推送到一个名为 `uptimes` 的主题。现在，我们将使用
    KSQL 来做这件事。
- en: 'At the time of writing, KSQL does not yet have a function to compare two dates,
    so we have the following two options:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写本文时，KSQL 还没有比较两个日期的函数，所以我们有以下两种选择：
- en: Code a **u****ser-defined function** (**UDF**) for KSQL in Java
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为 KSQL 编写一个**用户自定义函数**（**UDF**）的 Java 代码
- en: Use the existing functions to make our calculation
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用现有的函数来进行我们的计算
- en: 'As creating a new UDF is out of scope for now, let''s go for the second option:
    use the existing functions to make our calculation.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 由于现在创建新的 UDF 不在范围之内，让我们选择第二个选项：使用现有的函数来进行我们的计算。
- en: 'The first step is to parse the startup time using the `STRINGTOTIMESTAMP` function,
    shown as follows (remember that we declared the date in string format, because
    KSQL doesn''t yet have a `DATE` type):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是使用 `STRINGTOTIMESTAMP` 函数解析启动时间，如下所示（记住我们以字符串格式声明了日期，因为 KSQL 还没有 `DATE`
    类型）：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output is similar to this:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下内容：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The next step is to compare these dates to the current date. In KSQL, at the
    moment, there is no function to get today''s date either, so let''s use the `STRINGTOTIMESTAMP`
    function to parse today''s date, shown as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将这些日期与当前日期进行比较。在 KSQL 中，目前还没有获取今天日期的函数，所以让我们使用 `STRINGTOTIMESTAMP` 函数来解析今天的日期，如下所示：
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output is similar to this:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下内容：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, let''s compare these two dates and calculate the number of days between
    them, shown as follows (1 day = 86,400 seconds = 24 hours x 60 minutes x 60 seconds,
    1 second = 1,000 milliseconds):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们比较这两个日期，并计算它们之间的天数，如下所示（1 天 = 86,400 秒 = 24 小时 x 60 分钟 x 60 秒，1 秒 = 1,000
    毫秒）：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is similar to this:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下内容：
- en: '[PRE12]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Perfect, now we have calculated the uptime for every machine.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 完美，现在我们已经为每台机器计算了运行时间。
- en: Writing to a topic
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向主题写入
- en: So far, we have processed the data and printed the results in real time. To
    send these results to another topic, we use a `CREATE` command modality, where
    it is specified from a `SELECT`.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经处理了数据并在实时中打印了结果。要将这些结果发送到另一个主题，我们使用`CREATE`命令模式，其中指定来自`SELECT`。
- en: 'Let''s start by writing the uptime as a string and writing the data in a comma-delimited
    format, shown as follows (remember that KSQL supports comma-delimited, JSON, and
    Avro formats). At the moment, it''s enough because we''re only writing one value:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先以字符串形式编写uptime，并以逗号分隔的格式写入数据，如下所示（记住KSQL支持逗号分隔、JSON和Avro格式）。目前，这已经足够，因为我们只写入一个值：
- en: '[PRE13]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output is similar to this:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下内容：
- en: '[PRE14]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Our query is running in the background. To see it is running, we could use
    a console consumer of the `uptimes` topic, shown as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的查询正在后台运行。要查看它是否在运行，我们可以使用`uptimes`主题的控制台消费者，如下所示：
- en: '[PRE15]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output is similar to this:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下内容：
- en: '[PRE16]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The results are correct; however, we forgot to use the machine serial number
    as the message key. To do this, we have to rebuild our query and our stream.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是正确的；然而，我们忘记使用机器序列号作为消息键。为此，我们必须重建我们的查询和流。
- en: 'The first step is to use the `show queries` command, shown here:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是使用`show queries`命令，如下所示：
- en: '[PRE17]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output is similar to this:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下内容：
- en: '[PRE18]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'With the `Query ID`, use the `terminate <ID>` command, shown as follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`查询ID`，使用`terminate <ID>`命令，如下所示：
- en: '[PRE19]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output is similar to this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下内容：
- en: '[PRE20]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To delete the stream, use the `DROP STREAM` command, shown as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除流，使用`DROP STREAM`命令，如下所示：
- en: '[PRE21]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output is similar to this:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下内容：
- en: '[PRE22]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To write the events key correctly, we must use the `PARTITION BY` clause. First,
    we regenerate our stream with a partial calculation, shown as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 要正确写入事件键，我们必须使用`PARTITION BY`子句。首先，我们使用部分计算重新生成我们的流，如下所示：
- en: '[PRE23]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output is similar to this:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下内容：
- en: '[PRE24]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This stream has two fields (`serialNumber` and `uptime`). To write these calculated
    values to a topic, we use `CREATE STREAM`, `AS SELECT` as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 此流有两个字段（`serialNumber`和`uptime`）。要将这些计算值写入主题，我们使用`CREATE STREAM`，`AS SELECT`如下所示：
- en: '[PRE25]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The output is similar to this:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下内容：
- en: '[PRE26]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Finally, run a console consumer to show the results, demonstrated as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，运行控制台消费者以显示结果，如下所示：
- en: '[PRE27]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output is similar to this:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下内容：
- en: '[PRE28]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Now, close the KSQL CLI (*Ctrl* + *C* and close the command window). As the
    queries are still running in KSQL, you still see the outputs in the console consumer
    window.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，关闭KSQL CLI（*Ctrl* + *C* 并关闭命令窗口）。由于查询仍在KSQL中运行，你仍然可以在控制台消费者窗口中看到输出。
- en: Congratulations, you have built a Kafka Streams application with a few KSQL
    commands.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你，你已经使用几个KSQL命令构建了一个Kafka Streams应用程序。
- en: 'To unveil all the power of KSQL, it is important to review the official documentation
    at the following address:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 要揭示KSQL的全部功能，重要的是要查看以下地址的官方文档：
- en: '[https://docs.confluent.io/current/ksql/docs/tutorials/index.html](https://docs.confluent.io/current/ksql/docs/tutorials/index.html)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://docs.confluent.io/current/ksql/docs/tutorials/index.html](https://docs.confluent.io/current/ksql/docs/tutorials/index.html)'
- en: Summary
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: KSQL is still very new, but the product has gained adoption among developers.
    We all hope it continues to be extended to support more data formats (Protobuffers,
    Thrift, and so on) and more functions (more UDFs, such as geolocation and IoT,
    that are quite useful).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: KSQL仍然非常新，但该产品已经在开发者中获得了采用。我们都希望它继续扩展以支持更多数据格式（如Protobuffers、Thrift等）和更多功能（如地理定位和物联网等非常有用的更多UDFs）。
- en: So again, congratulations! In this chapter, we did the same as in the previous
    ones, but without writing a single line of Java code. This makes KSQL the preferred
    tool for people who are not programmers, but are dedicated to data analysis.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，再次恭喜！在本章中，我们与之前一样，但没有写一行Java代码。这使得KSQL成为非程序员但致力于数据分析的人们的首选工具。
