["```java\n<dependencies>\n  <!-- your other dependencies -->\n\n  <dependency>\n    <groupId>org.openjdk.jmh</groupId>\n    <artifactId>jmh-core</artifactId>\n    <version>${jmh.version}</version>\n    <scope>test</scope>\n  </dependency>\n  <dependency>\n    <groupId>org.openjdk.jmh</groupId>\n    <artifactId>jmh-generator-annprocess</artifactId>\n    <version>${jmh.version}</version>\n    <scope>test</scope> <!-- should be provided but for tests only this\n    is more accurate -->\n  </dependency>\n</dependencies>\n```", "```java\npublic class QuoteMicrobenchmark {\n    @Benchmark\n    public void compute() {\n        //\n    }\n}\n```", "```java\npublic class QuoteMicrobenchmark {\n    @Benchmark\n    public void compute(final QuoteState quoteState) {\n        quoteState.service.findByName(\"test\");\n    }\n\n    @State(Scope.Benchmark)\n    public static class QuoteState {\n        private QuoteService service;\n\n        @Setup\n        public void setup() {\n            service = new QuoteService();\n        }\n    }\n}\n```", "```java\n@State(Scope.Benchmark)\npublic class QuoteState {\n    private QuoteService service;\n    private SeContainer container;\n\n    @Setup\n    public void setup() {\n        container = SeContainerInitializer.newInstance().initialize();\n        service = container.select(QuoteService.class).get();\n    }\n\n    @TearDown\n    public void tearDown() {\n        container.close();\n    }\n}\n```", "```java\n@State(Scope.Benchmark)\npublic class QuoteState {\n    private QuoteService service;\n    private EJBContainer container;\n\n    @Setup\n    public void setup() {\n        container = EJBContainer.createEJBContainer(new HashMap<>());\n        service = CDI.current().select(QuoteService.class).get();\n    }\n\n    @TearDown\n    public void tearDown() {\n        container.close();\n    }\n}\n```", "```java\npublic void compute(final QuoteState quoteState, final Blackhole blackhole) {\n    blackhole.consume(quoteState.service.findByName(\"test\"));\n}\n```", "```java\nfinal Collection<RunResult> results = new Runner(\n    new OptionsBuilder()\n      .include(\"com.packt.MyBenchmark\")\n      .build())\n .run();\n```", "```java\n@RunWith(JMHRunner.class)\npublic class QuoteMicrobenchmarkTest {\n    @ExpectedPerformances(score = 2668993660.)\n    public static class QuoteMicrobenchmark {\n        @Benchmark\n        @Fork(1) @Threads(2)\n        @Warmup(iterations = 5) @Measurement(iterations = 50)\n        @ExpectedPerformances(score = 350000.)\n        public void findById(final QuoteState quoteState, final\n        Blackhole blackhole) {\n            blackhole.consume(quoteState.service.findById(\"test\"));\n        }\n\n        // other benchmark methods\n    }\n\n    public static class CustomerMicrobenchmark {\n        // benchmark methods\n    }\n}\n```", "```java\npublic static/*it is a nested class*/ class QuoteMicrobenchmark {\n    @Benchmark\n    @Fork(1) @Threads(2)\n    @Warmup(iterations = 5) @Measurement(iterations = 50)\n    @ExpectedPerformances(score = 350000.)\n    public void findById(final QuoteState quoteState, final Blackhole\n    blackhole) {\n        blackhole.consume(quoteState.service.findById(\"test\"));\n    }\n\n    @Benchmark\n    @Fork(1) @Threads(2) @Warmup(iterations = 10)\n    @Measurement(iterations = 100)\n    @ExpectedPerformances(score = 2660000.)\n    public void findByName(final QuoteState quoteState, final Blackhole\n    blackhole) {\n        blackhole.consume(quoteState.service.findByName(\"test\"));\n    }\n\n    @State(Scope.Benchmark)\n    public static class QuoteState {\n        private QuoteService service;\n\n        @Setup public void setup() { service = new QuoteService(); }\n    }\n}\n```", "```java\n@Target(METHOD)\n@Retention(RUNTIME)\npublic @interface ExpectedPerformances {\n    double score();\n    double scoreTolerance() default 0.1;\n}\n```", "```java\nchildren = Stream.of(getTestClass().getJavaClass().getClasses())\n        .filter(benchmarkClass ->\n        Stream.of(benchmarkClass.getMethods())\n        .anyMatch(m -> m.isAnnotationPresent(Benchmark.class)))\n        .collect(toList());\n```", "```java\nerrors.addAll(children.stream()\n        .flatMap(c -> Stream.of(c.getMethods()).filter(m ->\n        m.isAnnotationPresent(Benchmark.class)))\n        .filter(m ->\n        !m.isAnnotationPresent(ExpectedPerformances.class))\n        .map(m -> new IllegalArgumentException(\"No\n        @ExpectedPerformances on \" + m))\n        .collect(toList()));\n```", "```java\nfinal Collection<RunResult> results;\ntry {\n    results = new Runner(buildOptions(benchmarkClass)).run();\n} catch (final RunnerException e) {\n    throw new IllegalStateException(e);\n}\n\n// for all benchmarks assert the performances from the results\nfinal List<AssertionError> errors = Stream.of(benchmarkClass.getMethods())\n        .filter(m -> m.isAnnotationPresent(Benchmark.class))\n        .map(m -> {\n            final Optional<RunResult> methodResult = results.stream()\n                  .filter(r ->\n                  m.getName().equals(r.getPrimaryResult().getLabel()))\n                  .findFirst();\n                  assertTrue(m + \" didn't get any result\",\n                  methodResult.isPresent());\n\n            final ExpectedPerformances expectations =\n            m.getAnnotation(ExpectedPerformances.class);\n            final RunResult result = results.iterator().next();\n            final BenchmarkResult aggregatedResult =\n            result.getAggregatedResult();\n\n            final double actualScore =\n            aggregatedResult.getPrimaryResult().getScore();\n            final double expectedScore = expectations.score();\n            final double acceptedError = expectedScore *\n            expectations.scoreTolerance();\n            try { // use assert to get a common formatting for errors\n                assertEquals(m.getDeclaringClass().getSimpleName() +\n                \"#\" + m.getName(), expectedScore, actualScore,\n                acceptedError);\n                return null;\n            } catch (final AssertionError ae) {\n                return ae;\n            }\n        }).filter(Objects::nonNull).collect(toList());\nif (!errors.isEmpty()) {\n    throw new AssertionError(errors.stream()\n            .map(Throwable::getMessage)\n            .collect(Collectors.joining(\"\\n\")));\n}\n```", "```java\npublic class JMHRunner extends ParentRunner<Class<?>> {\n  private List<Class<?>> children;\n\n  public JMHRunner(final Class<?> klass) throws InitializationError {\n    super(klass);\n  }\n\n  @Override\n  protected List<Class<?>> getChildren() {\n    return children;\n  }\n\n  @Override\n  protected Description describeChild(final Class<?> child) {\n    return Description.createTestDescription(getTestClass().getJavaClass(), child.getSimpleName());\n  }\n```", "```java\n  @Override\n  protected void collectInitializationErrors(final List<Throwable>\n  errors) {\n    super.collectInitializationErrors(errors);\n\n    children = Stream.of(getTestClass().getJavaClass().getClasses())\n      .filter(benchmarkClass -> Stream.of(benchmarkClass.getMethods())\n        .anyMatch(m -> m.isAnnotationPresent(Benchmark.class)))\n      .collect(toList());\n\n    errors.addAll(children.stream()\n        .flatMap(c -> Stream.of(c.getMethods())\n        .filter(m -> m.isAnnotationPresent(Benchmark.class)))\n        .filter(m ->\n        !m.isAnnotationPresent(ExpectedPerformances.class))\n        .map(m -> new IllegalArgumentException(\"No\n        @ExpectedPerformances on \" + m))\n        .collect(toList()));\n  }\n```", "```java\n  @Override\n  protected boolean isIgnored(final Class<?> child) {\n    return child.isAnnotationPresent(Ignore.class);\n  }\n\n  @Override\n  protected void runChild(final Class<?> child, final RunNotifier \n  notifier) {\n    final Description description = describeChild(child);\n    if (isIgnored(child)) {\n      notifier.fireTestIgnored(description);\n    } else {\n      runLeaf(benchmarkStatement(child), description, notifier);\n    }\n  }\n```", "```java\n  private Statement benchmarkStatement(final Class<?> benchmarkClass) {\n    return new Statement() {\n      @Override\n      public void evaluate() throws Throwable {\n        final Collection<RunResult> results;\n        try {\n          results = new Runner(buildOptions(benchmarkClass)).run();\n        } catch (final RunnerException e) {\n          throw new IllegalStateException(e);\n        }\n\n        assertResults(benchmarkClass, results);\n      }\n    };\n  }\n\n  // all options will use JMH annotations so just\n  include the class to run\n  private Options buildOptions(final Class<?> test) {\n    return new OptionsBuilder()\n        .include(test.getName().replace('$', '.'))\n        .build();\n  }\n\n```", "```java\n  public void assertResults(final Class<?> benchmarkClass, final\n  Collection<RunResult> results) {\n    // for all benchmarks assert the performances from the results\n    final List<AssertionError> errors =\n    Stream.of(benchmarkClass.getMethods())\n        .filter(m -> m.isAnnotationPresent(Benchmark.class))\n        .map(m -> {\n          final Optional<RunResult> methodResult = results.stream()\n              .filter(r ->\n              m.getName().equals(r.getPrimaryResult().getLabel()))\n              .findFirst();\n              assertTrue(m + \" didn't get any result\",\n              methodResult.isPresent());\n\n          final ExpectedPerformances expectations =\n          m.getAnnotation(ExpectedPerformances.class);\n          final RunResult result = results.iterator().next();\n          final BenchmarkResult aggregatedResult =\n          result.getAggregatedResult();\n\n          final double actualScore =\n          aggregatedResult.getPrimaryResult().getScore();\n          final double expectedScore = expectations.score();\n          final double acceptedError = expectedScore *\n          expectations.scoreTolerance();\n          try { // use assert to get a common formatting for errors\n            assertEquals(m.getDeclaringClass().getSimpleName() + \"#\" +\n            m.getName(), expectedScore, actualScore, acceptedError);\n            return null;\n          } catch (final AssertionError ae) {\n            return ae;\n          }\n        }).filter(Objects::nonNull).collect(toList());\n    if (!errors.isEmpty()) {\n      throw new AssertionError(errors.stream()\n          .map(Throwable::getMessage)\n          .collect(Collectors.joining(\"\\n\")));\n    }\n  }\n}\n```", "```java\n<dependency>\n    <groupId>org.databene</groupId>\n    <artifactId>contiperf</artifactId>\n    <version>2.3.4</version>\n    <scope>test</scope>\n</dependency>\n```", "```java\npublic class QuoteMicrobenchmarkTest {\n    private static QuoteService service;\n\n    @Rule\n    public final ContiPerfRule rule = new ContiPerfRule();\n\n    @BeforeClass\n    public static void init() {\n        service = new QuoteService();\n    }\n\n    @Test\n    @Required(throughput = 7000000)\n    @PerfTest(rampUp = 100, duration = 10000, threads = 10, warmUp =\n    10000)\n    public void test() {\n        service.findByName(\"test\").orElse(null);\n    }\n}\n```", "```java\n@RunWith(Arquillian.class)\npublic class QuoteServicePerformanceTest {\n    @Deployment\n    public static Archive<?> quoteServiceApp() {\n        return ShrinkWrap.create(WebArchive.class, \"quote-manager.war\")\n                .addClasses(QuoteService.class,\n                InMemoryTestDatabaseConfiguration.class)\n                .addAsWebResource(new ClassLoaderAsset(\"META\n                -INF/beans.xml\"), \"WEB-INF/classes/META-INF/beans.xml\")\n                .addAsWebResource(new ClassLoaderAsset(\"META-\n                INF/persistence.xml\"), \"WEB-INF/classes/META-\n                INF/persistence.xml\");\n    }\n\n    @Inject\n    private QuoteService service;\n\n    @Before\n    public void before() {\n        final Quote quote = new Quote();\n        quote.setName(\"TEST\");\n        quote.setValue(10.);\n        service.create(quote);\n    }\n\n    @After\n    public void after() {\n        service.deleteByName(\"TEST\");\n    }\n\n    @Test\n    public void findByName() {\n        assertTrues(service.findByName(\"TEST\").orElse(false));\n    }\n}\n```", "```java\n@RunWith(Arquillian.class)\npublic class QuoteServicePerformanceTest {\n    @Deployment\n    public static Archive<?> quoteServiceApp() {\n        final WebArchive baseArchive =\n        ShrinkWrap.create(WebArchive.class, \"quote-manager.war\")\n              .addClasses(QuoteService.class)\n              .addAsWebResource(new ClassLoaderAsset(\"META\n              -INF/beans.xml\"), \"WEB-INF/classes/META-INF/beans.xml\")\n              .addAsWebResource(new ClassLoaderAsset(\"META\n              -INF/persistence.xml\"), \"WEB-INF/classes/META\n              -INF/persistence.xml\");\n        if (Boolean.getBoolean(\"test.performance.\" +\n        QuoteService.class.getSimpleName() + \".database.mysql\")) {\n            baseArchive.addClasses(DataSourceConfiguration.class);\n        } else {\n            baseArchive.addClasses(InMemoryDatabase.class);\n        }\n        return baseArchive;\n    }\n\n    @Rule\n    public final ContiPerfRule rule = new ContiPerfRule();\n\n    @Inject\n    private QuoteService service;\n\n    private final Collection<Long> id = new ArrayList<Long>();\n\n    @Before\n    public void before() {\n        IntStream.range(0, 1000000).forEach(i -> insertQuote(\"Q\" + i));\n        insertQuote(\"TEST\");\n    }\n\n    @After\n    public void after() {\n        id.forEach(service::delete);\n    }\n\n    @Test\n    @Required(max = 40)\n    @PerfTest(duration = 500000, warmUp = 200000)\n    public void findByName() {\n        service.findByName(\"TEST\");\n    }\n\n    private void insertQuote(final String name) {\n        final Quote entity = new Quote();\n        entity.setName(name);\n        entity.setValue(Math.random() * 100);\n        id.add(service.create(entity).getId());\n    }\n}\n```", "```java\n<dependency>\n  <groupId>junit</groupId>\n  <artifactId>junit</artifactId>\n  <version>4.12</version>\n  <scope>test</scope>\n</dependency>\n<dependency>\n  <groupId>org.jboss.arquillian.junit</groupId>\n  <artifactId>arquillian-junit-container</artifactId>\n  <version>1.1.13.Final</version>\n  <scope>test</scope>\n</dependency>\n<dependency>\n  <groupId>org.jboss.arquillian.container</groupId>\n  <artifactId>arquillian-glassfish-embedded-3.1</artifactId>\n  <version>1.0.1</version>\n  <scope>test</scope>\n</dependency>\n<dependency>\n  <groupId>org.glassfish.main.extras</groupId>\n  <artifactId>glassfish-embedded-all</artifactId>\n  <version>5.0</version>\n  <scope>test</scope>\n</dependency>\n```", "```java\n<plugin>\n  <groupId>com.lazerycode.jmeter</groupId>\n  <artifactId>jmeter-maven-plugin</artifactId>\n  <version>2.2.0</version>\n  <executions>\n    <execution>\n      <id>jmeter-tests</id>\n      <goals>\n        <goal>jmeter</goal>\n      </goals>\n    </execution>\n  </executions>\n  <configuration>\n    <remoteConfig>\n      <startServersBeforeTests>true</startServersBeforeTests>\n      <serverList>jmeter1.company.com,jmeter2.company.com</serverList>\n      <stopServersAfterTests>true</stopServersAfterTests>\n    </remoteConfig>\n  </configuration>\n</plugin>\n```", "```java\n<plugin>\n  <groupId>io.gatling</groupId>\n  <artifactId>gatling-maven-plugin</artifactId>\n  <version>${gatling-plugin.version}</version>\n  <executions>\n    <execution>\n      <phase>test</phase>\n      <goals>\n        <goal>execute</goal>\n      </goals>\n    </execution>\n  </executions>\n</plugin>\n```", "```java\n<plugin> \n  <groupId>com.ea.gatling</groupId>\n  <artifactId>gatling-aws-maven-plugin</artifactId>\n  <version>1.0.11</version>\n  <executions>\n    <execution>\n      <phase>test</phase>\n      <goals>\n        <goal>execute</goal>\n      </goals>\n    </execution>\n  </executions>\n</plugin>\n```", "```java\n<properties>\n  <ssh.private.key>${gatling.ssh.private.key}</ssh.private.key>\n  <ec2.key.pair.name>loadtest-keypair</ec2.key.pair.name>\n  <ec2.security.group>default</ec2.security.group>\n  <ec2.instance.count>3</ec2.instance.count>\n\n  <gatling.local.home>${project.build.directory}/gatling-charts\n  -highcharts-bundle-2.2.4/bin/gatling.sh</gatling.local.home>\n   <gatling.install.script>${project.basedir}/src/test/resources/install-\n  gatling.sh</gatling.install.script>\n  <gatling.root>gatling-charts-highcharts-bundle-2.2.4</gatling.root>\n  <gatling.java.opts>-Xms1g -Xmx16g -Xss4M \n  -XX:+CMSClassUnloadingEnabled -\n  XX:MaxPermSize=512M</gatling.java.opts>\n\n  <!-- Fully qualified name of the Gatling simulation and a name\n  describing the test -->\n  <gatling.simulation>com.FooTest</gatling.simulation>\n  <gatling.test.name>LoadTest</gatling.test.name>\n\n  <!-- (3) -->\n  <s3.upload.enabled>true</s3.upload.enabled>\n  <s3.bucket>loadtest-results</s3.bucket>\n  <s3.subfolder>my-loadtest</s3.subfolder>\n</properties>\n```", "```java\n<plugin>\n  <groupId>org.apache.maven.plugins</groupId>\n  <artifactId>maven-dependency-plugin</artifactId>\n  <version>3.0.2</version>\n  <executions>\n    <execution>\n      <id>download-gatling-distribution</id>\n      <phase>generate-test-resources</phase>\n      <goals>\n        <goal>unpack</goal>\n      </goals>\n      <configuration>\n        <artifactItems>\n          <artifactItem>\n            <groupId>io.gatling.highcharts</groupId>\n            <artifactId>gatling-charts-highcharts-bundle</artifactId>\n            <version>2.2.4</version>\n            <classifier>bundle</classifier>\n            <type>zip</type>\n            <overWrite>false</overWrite>\n            <outputDirectory>${project.build.directory}/gatling</outputDirectory>\n            <destFileName>gatling-charts-highcharts-bundle\n            -2.2.4.jar</destFileName>\n          </artifactItem>\n        </artifactItems>\n        <outputDirectory>${project.build.directory}/wars</outputDirectory>\n        <overWriteReleases>false</overWriteReleases>\n        <overWriteSnapshots>true</overWriteSnapshots>\n      </configuration>\n    </execution>\n  </executions>\n</plugin>\n```", "```java\n#!/bin/sh\n# Increase the maximum number of open files\nsudo ulimit -n 65536\necho \"* soft nofile 65535\" | sudo tee --append /etc/security/limits.conf\necho \"* hard nofile 65535\" | sudo tee --append /etc/security/limits.conf\n\nsudo yum install --quiet --assumeyes java-1.8.0-openjdk-devel.x86_64 htop screen\n\n# Install Gatling\nGATLING_VERSION=2.2.4\nURL=https://repo.maven.apache.org/maven2/io/gatling/highcharts/gatling-charts-highcharts-bundle/${GATLING_VERSION}/gatling-charts-highcharts-bundle-${GATLING_VERSION}-bundle.zip\nGATLING_ARCHIVE=gatling-charts-highcharts-bundle-${GATLING_VERSION}-bundle.zip\n\nwget --quiet ${URL} -O ${GATLING_ARCHIVE}\nunzip -q -o ${GATLING_ARCHIVE}\n\n# Remove example code to reduce Scala compilation time at the beginning of load test\nrm -rf gatling-charts-highcharts-bundle-${GATLING_VERSION}/user-files/simulations/computerdatabase/\n```", "```java\nmvn clean install # (1)\nmvn exec:java@deploy-application # (2)\nmvn test -Pperf-tests # (3)\nmvn exec:java@undeploy-application #(4)\n```"]