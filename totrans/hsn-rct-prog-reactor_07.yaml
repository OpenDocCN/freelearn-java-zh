- en: Flow Control and Backpressure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous chapters, we have discussed how Reactor offers effective controls
    to check the production rate. This mechanism is often called backpressure. However,
    there are instances where backpressure is not an efficient strategy. In such cases,
    Reactor offers a number of flow control optimizations that can be used without
    backpressure.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics regarding flow control
    and backpressure:'
  prefs: []
  type: TYPE_NORMAL
- en: GroupBy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Buffer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Window
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sample
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backpressure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Java Standard Edition, JDK 8 or above
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IntelliJ IDEA IDE 2018.1 or above
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The GitHub link for this chapter is [https://github.com/PacktPublishing/Hands-On-Reactive-Programming-with-Reactor/tree/master/Chapter07](https://github.com/PacktPublishing/Hands-On-Reactive-Programming-with-Reactor/tree/master/Chapter07).
  prefs: []
  type: TYPE_NORMAL
- en: Flow control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Flow control is all about managing the rate of events so that a producer does
    not overwhelm its subscribers when raising a large number of events. A fast producer
    will push many events to its subscribers. Each of the subscribers will process
    these events as it receives them, one at a time. This sequential process can be
    quite inefficient, as each event is delivered over a wire.
  prefs: []
  type: TYPE_NORMAL
- en: In order to improve the efficiency, there are operators in Reactor that allow
    the producer to raise events in chunks. Each chunk of events is delivered to the
    subscriber, allowing them to work on many events simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: The groupBy operator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `groupBy()` operator converts the `Flux<T>` into batches. The operator
    associates a key with each element of the `Flux<T>`. It then groups elements that
    have the same key. These groups are then emitted by the operator. This is depicted
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/77b226df-de1b-4a9f-9634-4fcfb7001657.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It is important to note that elements may lose their original sequence order
    once they are grouped. The order is enforced by the logic of the key generation.
    Since each element is only associated with one key, the generated groups are not
    empty. All the generated groups are disjointed by nature. Let''s try to generate
    some groups for our Fibonacci series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we have carried out the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: We partitioned the original dataset into groups of `Divisible by 2`, `Divisible
    by 3`, `Divisible by 5`, `Divisible by 7`, and so on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`groupBy` is emitted these partitioned datasets as a key-value pair. The key
    is a string and the value is `List<Long>`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The datasets were combined using the `concatMap` operator. We also printed the
    key using the operator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we printed the `List` in the `Subscribe` function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s run our test case to confirm the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/81d4fbc3-974f-430a-bc7a-f09efef88a45.png)'
  prefs: []
  type: TYPE_IMG
- en: The buffer operator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `buffer()` operator gathers all `Flux<T>` elements and emits them as a
    `List<T>`. Unlike groups generated by the `groupBy()` operator, all the elements
    in the `List<T>` buffer are in their original order. Alternatively, we could provide
    a `batchSize` to the operator. The operator will then generate *N* lists, each
    of which will have a specified number of elements. Let''s try to use the buffer
    operator on our Fibonacci series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we have done the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We partitioned the original dataset into buffer lists of 10 elements each
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We then printed the list using the `subscribe` function
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s run our test case to confirm the output. We can see that the Fibonacci
    elements are emitted in a single `List<Long>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a10c997e-0377-45cf-8c58-7c139903bc8d.png)'
  prefs: []
  type: TYPE_IMG
- en: There are many variants of the `buffer()` operator. Let's look at a few of them.
    Each of these generates multiple list buffers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `buffer(maxSize, skipSize)` operator takes two arguments. The first argument
    is the max size of each buffer. The second argument is the number of elements
    that must be skipped before starting a new buffer. The buffer lists generated
    by the operator have the following characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: If the `maxSize` is larger than the `skipSize`, the buffers are overlapping
    in nature. The next buffer starts from the element at the position specified by
    the `skipSize` of the previous buffer. This means that elements are duplicated
    across all buffers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the `maxSize` is smaller than the `skipSize`, the buffers are disjointed
    in nature. The generated lists miss elements from the original `Flux<T>`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If the `skipSize` is `0`, then all lists are disjointed in nature. They do
    not miss any elements from the original `Flux<T>`. Consider the following code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we have done the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We partitioned the original dataset into buffers of two elements each
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each of the buffer lists started at the fifth element, therefore dropping three
    elements
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We printed the list in the `subscribe` function
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s run the code to confirm the output. We can see that the Fibonacci elements
    are emitted in a single `List<Long>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0129c0fb-4fde-4600-91ea-b886d147ff03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `bufferUntil` and `bufferWhile` variants take a predicate condition and
    aggregate elements until the condition is true. The `bufferWhile` operator generates
    a single buffer that contains all elements that match the condition. On the other
    hand, the `bufferUntil` operator buffers non-matching elements to a list. When
    it finds a matching element, it adds it to the current buffer. It then starts
    a new buffer to add the next incoming element. This process is shown in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0fa957a0-164d-4277-984e-d1536c2fcbf4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Another overloaded `buffer()` method enables us to generate buffer lists based
    on the time period. The operator accepts a duration and aggregates all elements
    during that period. It can therefore collect all events that happened during the
    first `Duration`, the second `Duration`, and so on, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we have done the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We partitioned the original data based on a 10-nanosecond time slice
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each of the buffer lists contained elements emitted during the time period
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we printed the lists using the `subscribe` function
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s run this code to confirm the output. We can see that Fibonacci elements
    are emitted as multiple `List<Long>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f58603a7-ea36-435b-a1b3-4fb4b9c3eb7c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `buffer` operator offers a number of variants of the methods discussed
    here. All `buffer` methods provide a list, but only one of the overloaded methods
    allow us to convert a buffer into a collection dataset. We need to provide a supplier
    function to the overloaded `buffer` operator. This function is responsible for
    creating a collection instance. Let''s look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we have done the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We partitioned the original dataset into buffers of a maximum of five elements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of the buffers was emitted as a `HashSet`, which means that it contains
    only distinct elements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we printed the lists using the `subscribe` function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Since we used a `HashSet`, we can see that it does not contain duplicate elements
    of the Fibonacci series:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b95bb99a-69b9-4ac9-9fb7-01220a758f3d.png)'
  prefs: []
  type: TYPE_IMG
- en: The window operator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `window()` operator is similar to the `buffer()` operator. It also slices
    the original dataset, but emits each dataset as a processor, rather than as a
    new collection. Each processor serves as a publisher and emits items after subscribing
    to them. The `window` operator allows us to have a fixed window size, a time-based
    window, or a predicate-based window. Unlike the `buffer` operator, which allows
    us to build a single buffer for all published elements, the `window` operator
    does not allow you to publish elements in a single window.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `window()` operator offers better memory utilization, as the items are
    emitted immediately rather than first being cached to a collection and then emitted
    once the correct collection size is achieved. The `window` operator also offers
    better memory usage than the buffer operator. This is depicted with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we have done the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We partitioned the original data into windows with a maximum of 10 elements
    each
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each window is a type of `UnicastProcesser`, so it needed to be combined with
    the other generated windows using either `ConcatMap` or `flatMap`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we printed the lists using the subscribe function
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s run this code to confirm the output. We can see that the Fibonacci elements
    are emitted as multiple batches and then combined as one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a893f73a-7e23-4e4d-b0f2-3f68924f49e3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `WindowUntil` and the `WindowWhile` variants take a predicate condition
    and build a window batch until the condition is true. The `WindowWhile` operator
    generates a single window containing all the elements that match the condition.
    The `WindowUntil` operator, on the other hand, aggregates non-matching elements
    to a window. When it finds a matching element, it adds it to the current window.
    It then starts a new window to add the next incoming element. Consider the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we have done the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We partitioned the original data based on the condition that `x < 500`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All elements that matched the criteria were published in a single window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The window elements were emitted as `WindowFlux`. They were combined using `concatMap`
    or `flatMap`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we printed the elements with the subscribe function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s run our code to confirm the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d1932e7e-bbd3-4cd0-9094-ffe58371f4d6.png)'
  prefs: []
  type: TYPE_IMG
- en: The sample operator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `groupBy()`, `buffer()`, and `window()` operators aggregate inputs and consolidate
    them into chunks, based on their size, time period, or condition. They are not
    aimed at skipping events. At times, you may be required to skip events and listen
    to a particular event during a given time interval. This is often required for
    fast, non-changing events, such as user clicks. In such a situation, we need to
    throttle the flow and pick data selectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `sample()` operator allows us to accomplish this throttling. It takes a
    time period and listens to events published during that time period. It then publishes
    the last event that happened during the time period. This is depicted in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b170198e-5194-4446-84f1-d1bb2c4a3437.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s try to add a delay to our Fibonacci series and then throttle it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we have done the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We added the `delayElements()` operator. This operator is responsible for delaying
    each event by the supplied time period. In this case, we have delayed each element
    by 100 milliseconds.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we added the `sample()` operator with a time interval of one second.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We then printed the elements using the `Subscribe` function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We also added a `CountDownLatch` to wait for the test execution for completion/error
    events.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s run the code to confirm the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a043362b-520e-48ef-ab4b-c6b8a1843a5f.png)'
  prefs: []
  type: TYPE_IMG
- en: The `samplefirst()` operator is similar to the `sample()`operator. This operator
    publishes the first element that was received during the specified time period,
    rather than selecting the last element.
  prefs: []
  type: TYPE_NORMAL
- en: Backpressure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Backpressure is an integral part of Reactor. We have discussed it multiple
    times in previous chapters, but we will have a detailed look at the topic here.
    Let''s recap the out-of-the-box support for backpressure that is available with
    Reactor. Each of the subscribers requests the number of events that it can process
    using the subscription object. The publisher must respect this limit and publish
    events that are less than or equal to the requested limit. This is depicted in
    the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/252589c2-c331-4308-8982-084df0f7bb90.png)'
  prefs: []
  type: TYPE_IMG
- en: Invoking a request with `Long.MAX_VALUE` means requesting an unbounded number
    of events. The publisher can push as many events as it can. It is no longer bound
    by the subscriber limit.
  prefs: []
  type: TYPE_NORMAL
- en: 'As each subscriber is processing the received events, it can request additional
    events using the subscription handle. If the publisher is raising events rapidly,
    it must come up with a strategy to handle the non-requested events. Take a look
    at the following test code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, the following occurred:'
  prefs: []
  type: TYPE_NORMAL
- en: We created a publisher using the `Flux.create` API
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The publisher printed the requested number to the console and emitted 100 events
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The subscriber requested a single event in the subscribe hook
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The subscriber printed the received event to the console
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There is a `CountDownLatch` to pause the code for 1 second
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To sum up, the subscriber requested one event, but the publisher emitted 100\.
    Let''s run the test to see the result on the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ae5b1ad5-8591-4955-a36d-7143921a313e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding test failed to complete successfully. Our subscriber asked for
    one event and it received only one. The publisher, however, pushed 100 data events
    followed by the complete event. Reactor did some work behind the scenes to hold
    the events in a queue. It offers a few overflow strategies to handle events produced
    by a fast publisher:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Strategy** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `IGNORE` | This strategy ignores the limits of the subscriber for backpressure
    and keeps delivering the next event to the subscriber. |'
  prefs: []
  type: TYPE_TB
- en: '| `BUFFER` | This strategy combines the undelivered events in a buffer. Events
    from the buffer are delivered when the subscriber requests the next events. |'
  prefs: []
  type: TYPE_TB
- en: '| `DROP` | This strategy silently drops undelivered events that are produced.
    The subscriber will only get a newly produced event when the next request is raised.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `LATEST` | This strategy keeps the latest event raised in the buffer. The
    subscriber will only get the latest produced event when the next request is raised.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `ERROR` | This strategy raises an `OverFlowException` if the producer raises
    more than the events requested by the subscriber. |'
  prefs: []
  type: TYPE_TB
- en: 'The API created by default uses the `Overflow.Buffer` strategy. We could override
    this by passing the one we want in the overloaded `create` method. Let''s test
    the preceding code with the `Overflow.Error` strategy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The test case now fails with the following error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: OnBackpressure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reactor also provides operators to alter the overflow strategy configured with
    the publisher. There are various `OnBackpressureXXX()` operators that cater to
    each of the strategies available with Reactor. These are quite useful in scenarios
    in which none of the preceding strategies can be applied to the publisher.
  prefs: []
  type: TYPE_NORMAL
- en: A publisher is sometimes configured with an `IGNORE` strategy. In such cases,
    backpressure is configured using operators while subscribing to the publisher.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s work with our test case and apply backpressure operators to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we have done the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We configured `Flux<Integer>` with `OverflowStrategy.BUFFER`, the default configuration
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While subscribing to `Flux<Integer>`, we altered the strategy to use `OverflowStrategy.DROP`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Additionally, we passed a lambda to the operator to print the dropped value
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s run the code and validate the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8d1e9929-30cb-47a9-a4ea-2912ce8ddf29.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Additionally, there are the `onBackpressureLatest()`, `onBackpressureError()`,
    and `onBackpressureBuffer()` operators, which are similar to the `onBackpressureDrop()`
    operator. The `onBackpressureBuffer()` operator has a couple of overloaded variants.
    As a basic configuration, it allows us to specify the buffer size. We could also
    specify one of the following strategies to handle the overflow beyond the specified
    buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Buffer overflow** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `DROP_LATEST` | All generated events are buffered first and then the new
    events are dropped. This would keep the oldest events in the buffer. |'
  prefs: []
  type: TYPE_TB
- en: '| `DROP_OLDEST` | All generated events are buffered. Events that are currently
    in the buffer are then replaced with new events. This would keep the latest events
    in the buffer. |'
  prefs: []
  type: TYPE_TB
- en: '| `ERROR` | This raises an `OverFlowException` for events that are beyond the
    buffer. |'
  prefs: []
  type: TYPE_TB
- en: 'Let''s look at how this works with an example. We can also pass a consumer
    lambda to be invoked for the overflow events:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we have done the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We configured `Flux<Integer>` with `OverflowStrategy.BUFFER`, the default configuration
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While subscribing to `Flux<Integer>`, we altered the buffer size to two elements
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We configured the `DROP_LATEST` strategy for events beyond the buffer
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We also passed a lambda to the operator to print the dropped value
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s run the code and validate the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e35094bb-b847-4a8e-8c50-4372e6e3d4e8.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the flow control operators that are available
    in Reactor in detail. We looked at the different overload options that are available
    in the `groupBy`, `buffer`, and `window` operators. We then considered how we
    can throttle events using the sample operator, which allows only a single event
    to be delivered in the specified time interval. After that, we recapped the support
    for backpressure that is available in Reactor and studied the different overflow
    strategies that it provides. We also learned that Reactor uses the `Overflow.Buffer`
    strategy by default, which can be provided as part of the `Flux.create` API. Finally,
    we discussed the backpressure operators that can be used to alter the strategy
    of the producer. To sum up, we discussed the complete list of operators available
    for flow control and backpressure. In the next chapter we will look at handling
    and recovering errors.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why do we need the `groupBy` operator?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between the `groupBy` and `buffer` operators?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we throttle an event in Reactor?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between the `Overflow.Ignore` and `OverFlow.Latest` strategies?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which operators are available to change the backpressure strategy of a producer?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
