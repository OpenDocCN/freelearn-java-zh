- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing Architecture Elements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In many projects I’ve witnessed, especially projects that have been around for
    a while and have rotated in and out many developers over time, automated testing
    is a mystery. Everyone writes tests as they see fit because it’s required by some
    dusty rule documented in a wiki, but no one can answer targeted questions about
    a team’s testing strategy.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter provides a testing strategy for a Hexagonal Architecture. For each
    element of our architecture, we’ll discuss the type of test to cover it.
  prefs: []
  type: TYPE_NORMAL
- en: The test pyramid
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s start the discussion about testing along the lines of the **test pyramid**[1](#footnote-031)
    in *Figure 8**.1*, which is a metaphor that helps us to decide on how many tests
    of which type we should aim for.
  prefs: []
  type: TYPE_NORMAL
- en: '[1](#footnote-031-backlink) The test pyramid can be traced back to Mike Cohn’s
    book *Succeeding with Agile* from 2009.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – According to the test pyramid, we should create many cheap tests
    and fewer expensive ones](img/Figure_08.1._B19916.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – According to the test pyramid, we should create many cheap tests
    and fewer expensive ones
  prefs: []
  type: TYPE_NORMAL
- en: The basic statement of the pyramid is that we should have high coverage of fine-grained
    tests that are cheap to build, easy to maintain, fast-running, and stable. These
    are unit tests that verify that a single unit (usually a class) works as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Once tests combine multiple units and go across unit boundaries, architectural
    boundaries, or even system boundaries, they tend to become more expensive to build,
    slower to run, and more brittle (failing due to some configuration error instead
    of a functional error). The pyramid tells us that the more expensive those tests
    become, the less we should aim for high coverage of these tests because, otherwise,
    we’ll spend too much time building tests instead of new functionality.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the context, the test pyramid is often shown with different layers.
    Let’s take a look at the layers I chose to discuss testing our Hexagonal Architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The definitions of *unit test*, *integration test*, and *system test* vary with
    context. In one project, they may mean a different thing than in another.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are interpretations of different test types as we’ll use them
    in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Unit tests** are the base of the pyramid. A unit test usually instantiates
    a single class and tests its functionality through its interface. If the class
    under test has non-trivial dependencies on other classes, we can replace those
    dependencies with mock objects that simulate the behavior of the real objects,
    as required by the test.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration tests** form the next layer of the pyramid. These tests instantiate
    a network of multiple units and verify whether this network works as expected,
    by sending some data into it through the interface of an entry class. In our interpretation,
    integration tests will cross the boundary between two layers, so the network of
    objects is not complete or must work against mocks at some point.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**System tests**, finally, spin up the whole network of objects that make up
    our application and verify whether a certain use case works as expected through
    all the layers of the application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Above the system tests, there might be a layer of end-to-end tests that include
    the UI of the application. We’ll not consider end-to-end tests here since we’re
    only discussing a backend architecture in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The test pyramid, like any other guidance, is not a silver bullet for your test
    strategy. It’s a good default, but if, in your context, you can create and maintain
    integration or system tests cheaply, you can and should create more of those tests,
    as they are less vulnerable to changes in implementation details than unit tests.
    This would make the sides of the pyramid steeper, or maybe even invert them.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have defined some test types, let’s see which type of test fits
    best with each of the layers of our Hexagonal Architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Testing a domain entity with unit tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will start by looking at a domain entity at the center of our architecture.
    Let’s recall the `Account` entity from [*Chapter 5*](B19916_05.xhtml#_idTextAnchor044),
    *Implementing a Use Case*. The state of `Account` consists of a balance an account
    had at a certain point in the past (the baseline balance) and a list of deposits
    and withdrawals (activities) made since then.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now want to verify that the `withdraw()` method works as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/code-8.1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding test is a plain unit test that instantiates an `Account` in a
    specific state, calls its `withdraw()` method, and verifies that the withdrawal
    was successful and had the expected side effects on the state of the `Account`
    object under test.
  prefs: []
  type: TYPE_NORMAL
- en: The test is rather easy to set up, is easy to understand, and runs very fast.
    Tests don’t come much simpler than this. Unit tests such as these are our best
    bet to verify the business rules encoded within our domain entities. We don’t
    need any other type of test since domain entity behavior has little to no dependencies
    on other classes.
  prefs: []
  type: TYPE_NORMAL
- en: Testing a use case with unit tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Going a layer outward, the next architecture element to test is the use cases
    implemented as domain services. Let’s look at a test for `SendMoneyService`, discussed
    in [*Chapter 5*](B19916_05.xhtml#_idTextAnchor044), *Implementing a Use Case*.
    The *Send money* use case withdraws money from the source account and deposits
    it into the target account. We want to verify that everything works as expected
    when the transaction succeeds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/code-8.2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: To make the test a little more readable, it’s structured into `given`/`when`/`then`
    sections, which are commonly used in **Behavior-Driven Development**.
  prefs: []
  type: TYPE_NORMAL
- en: In the `given` section, we create the source and target `Account` objects and
    put them into the correct state with some methods whose names start with `given...()`.
    We also create a `SendMoneyCommand` object to act as input to the use case. In
    the `when` section, we simply call the `sendMoney()` method to invoke the use
    case. The `then` section asserts that the transaction was successful and verifies
    that certain methods have been called on the source and target `Account` objects.
  prefs: []
  type: TYPE_NORMAL
- en: Under the hood, the test makes use of the Mockito library to create `given...()`
    methods.[2](#footnote-030) Mockito also provides the `then()` method to verify
    whether a certain method has been called on a mock object.
  prefs: []
  type: TYPE_NORMAL
- en: '[2](#footnote-030-backlink) Mockito: [https://site.mockito.org/](https://site.mockito.org/).'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If used too much, mocking can give a false sense of security. Mocks may behave
    differently from the real thing, causing issues in production even though our
    tests are green. If you can use real objects instead of mocks without too much
    extra effort, you should probably do it. In the preceding example, we might choose
    to work with real `Account` objects instead of mocks, for example. This shouldn’t
    prove much more effort because the `Account` class is a domain model class that
    doesn’t have any complicated dependencies on other classes.
  prefs: []
  type: TYPE_NORMAL
- en: Since the use case service under test is stateless, we cannot verify a certain
    state in the `then` section. Instead, the test verifies that the service has interacted
    with certain methods on its (mocked) dependencies. This means that the test is
    vulnerable to changes in the structure of the code under test and not only its
    behavior. This, in turn, means that there is a higher chance that the test has
    to be modified if the code under test is refactored.
  prefs: []
  type: TYPE_NORMAL
- en: With this in mind, we should think hard about which interactions we actually
    want to verify in the test. It might be a good idea not to verify all interactions
    as we did in the preceding test and instead focus on the most important ones.
    Otherwise, we have to change the test with every single change to the class under
    test, undermining the value of the test.
  prefs: []
  type: TYPE_NORMAL
- en: While this test is still a unit test, it borders on being an integration test
    because we test the interaction on dependencies. However, it’s easier to create
    and maintain than a full-blown integration test because we’re working with mocks
    and don’t have to manage the real dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Testing a web adapter with integration tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Moving outward another layer, we arrive at our adapters. Let’s discuss testing
    a web adapter.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that a web adapter takes input, for example, in the form of JSON strings,
    via HTTP, might do some validation on it, maps the input to the format a use case
    expects, and then passes it to that use case. It then maps the result of the use
    case back to JSON and returns it to the client via an HTTP response.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the test for a web adapter, we want to make certain that all those steps
    work as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/code-8.3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding test is a standard integration test for a web controller named
    `SendMoneyController`, built with the Spring Boot framework. In the `testSendMoney()`
    method, we send a mock HTTP request to the web controller to trigger a transaction
    from one account to another.
  prefs: []
  type: TYPE_NORMAL
- en: With the `isOk()` method, we then verify that the status of the HTTP response
    is `200`, and we verify that the mocked use case class has been called.
  prefs: []
  type: TYPE_NORMAL
- en: Most responsibilities of a web adapter are covered by this test.
  prefs: []
  type: TYPE_NORMAL
- en: We’re not actually testing via the HTTP protocol since we’re mocking that away
    with the `MockMvc` object. We trust that the framework translates everything to
    and from HTTP properly. There’s no need to test the framework.
  prefs: []
  type: TYPE_NORMAL
- en: However, the whole path from mapping the input from JSON into a `SendMoneyCommand`
    object is covered. If we build the `SendMoneyCommand` object as a self-validating
    command, as explained in [*Chapter 5*](B19916_05.xhtml#_idTextAnchor044), *Implementing
    a Use Case*, we even make sure that this mapping produces syntactically valid
    input to the use case. Also, we have verified that the use case is actually called
    and that the HTTP response has the expected status.
  prefs: []
  type: TYPE_NORMAL
- en: So, why is this an integration test and not a unit test? Even though it seems
    that we only test a single web controller class in this test, there’s a lot more
    going on under the hood. With the `@WebMvcTest` annotation, we tell Spring to
    instantiate a whole network of objects that is responsible for responding to certain
    request paths, mapping between Java and JSON, validating HTTP input, and so on.
    And in this test, we verify that our web controller works as a part of this network.
  prefs: []
  type: TYPE_NORMAL
- en: Since the web controller is heavily coupled to the Spring framework, it makes
    sense to test it when integrated into this framework instead of testing it in
    isolation. If we tested the web controller with a plain unit test, we’d lose coverage
    of all the mapping, validation, and HTTP stuff, and we could never be sure whether
    it actually worked in production, where it’s just a cog in the mechanics of the
    framework.
  prefs: []
  type: TYPE_NORMAL
- en: Testing a persistence adapter with integration tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For a similar reason, it makes sense to cover persistence adapters with integration
    tests instead of unit tests since we not only want to verify the logic within
    the adapter but also the mapping into the database.
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to test the persistence adapter we built in [*Chapter 7*](B19916_07.xhtml#_idTextAnchor062),
    *Implementing a Persistence Adapter*. The adapter has two methods, one to load
    an `Account` entity from the database and another to save new account activities
    to the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/code-8.4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: With `@DataJpaTest`, we tell Spring to instantiate the network of objects that
    are needed for database access, including our Spring Data repositories that connect
    to the database. We use the `@Import` annotation to import some additional configurations
    to make sure that certain objects are added to that network. These objects are
    needed by the adapter under test to map incoming domain objects into database
    objects, for instance.
  prefs: []
  type: TYPE_NORMAL
- en: In the test for the `loadAccount()` method, we put the database into a certain
    state using an SQL script with the name `AccountPersistenceAdapterTest.sql`. Then,
    we simply load the account through the adapter API and verify that it has the
    state that we would expect it to have, given the database state in the SQL script.
  prefs: []
  type: TYPE_NORMAL
- en: The test for `updateActivities()` goes the other way around. We create an `Account`
    object with a new account activity and pass it to the adapter to persist. Then,
    we check whether the activity has been saved to the database through the API of
    `ActivityRepository`.
  prefs: []
  type: TYPE_NORMAL
- en: An important aspect of these tests is that we’re not mocking away the database.
    The tests actually hit the database. Had we mocked the database away, the tests
    would still cover the same lines of code, producing the same high coverage of
    lines of code. However, despite this high coverage, the tests would still have
    a rather high chance of failing in a setup with a real database, due to errors
    in SQL statements or unexpected mapping errors between database tables and Java
    objects.
  prefs: []
  type: TYPE_NORMAL
- en: Note that, by default, Spring will spin up an in-memory database to use during
    tests. This is very practical, as we don’t have to configure anything, and the
    tests will work out of the box. However, since this in-memory database is most
    probably not the database we use in production, there is still a significant chance
    of something going wrong with the real database even when the tests work perfectly
    against the in-memory database. Database vendors love to implement their own flavor
    of SQL, for instance.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, persistence adapter tests should run against the real database.
    Libraries such as **Testcontainers** are a great help in this regard, spinning
    up a Docker container with a database on demand.[3](#footnote-029)
  prefs: []
  type: TYPE_NORMAL
- en: '[3](#footnote-029-backlink) Testcontainers: [https://www.testcontainers.org/](https://www.testcontainers.org/).'
  prefs: []
  type: TYPE_NORMAL
- en: Running against the real database has the added benefit that we don’t have to
    take care of two different database systems. If we use the in-memory database
    during tests, we might have to configure it in a certain way, or we might have
    to create separate versions of database migration scripts for each database, which
    is a big hit on the maintainability of our tests.
  prefs: []
  type: TYPE_NORMAL
- en: Testing main paths with system tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the top of the pyramid are what I call **system tests**. A system test starts
    up the whole application and runs requests against its API, verifying that all
    our layers work in concert.
  prefs: []
  type: TYPE_NORMAL
- en: Hexagonal Architecture is all about creating a well-defined boundary between
    our application and the outside world. Doing so makes our application boundaries
    very testable by design. To test our application locally, we just need to swap
    out the adapters with mock adapters, as outlined in *Figure 8**.2*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – By replacing the adapters with mocks, we can run and test our
    application without dependencies on the outside world](img/Figure_08.2._B19916.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 – By replacing the adapters with mocks, we can run and test our application
    without dependencies on the outside world
  prefs: []
  type: TYPE_NORMAL
- en: On the left, we can replace the input adapters with a test driver that calls
    the application’s input ports to interact with it. The test driver can implement
    certain test scenarios that simulate user behavior during an automated test.
  prefs: []
  type: TYPE_NORMAL
- en: On the right, we can replace the output adapters with mock adapters that simulate
    the behavior of a real adapter and return previously specified values.[4](#footnote-028)
  prefs: []
  type: TYPE_NORMAL
- en: '[4](#footnote-028-backlink) Mocks: depending on who you ask and what you’re
    doing in your test, instead of calling it a “mock”, you should call it a “fake”
    or “stub”. Each term seems to have a slightly different semantic, but in the end,
    they all replace a “real” thing with a “mock” thing to be used in tests. I’m usually
    a fan of naming things just right, but in this case, I don’t see value in discussing
    the nuances between where a mock ends and a stub starts. Or is it the other way
    around?'
  prefs: []
  type: TYPE_NORMAL
- en: This way, we can create “application tests” that cover the “hexagon” of our
    application from the input ports, through our domain services and entities, to
    the output ports.
  prefs: []
  type: TYPE_NORMAL
- en: I would argue, however, that, instead of writing “application tests” that mock
    away the input and output adapters, we should aim to write “system tests” that
    cover the whole path from a real input adapter to a real output adapter. These
    tests uncover many subtle bugs that we wouldn’t catch if we mocked away the input
    and output adapters. These bugs include mapping errors between the layers, or
    simply wrong expectations between the application and the outside systems it’s
    talking to.
  prefs: []
  type: TYPE_NORMAL
- en: A “system test” such as this requires that we can spin up the real external
    systems our application talks to in a test setup.
  prefs: []
  type: TYPE_NORMAL
- en: On the input side, we need to make sure that we can make real HTTP calls to
    our application, for example, so that the requests go through our real web adapter.
    That should be rather easy, however, since we just need to start our application
    locally and let it listen to HTTP calls like it would in a production environment.
  prefs: []
  type: TYPE_NORMAL
- en: On the output side, we need to spin up a real database, for example, so that
    our tests go through the real persistence adapter. Most databases make that easy
    today by providing a Docker image that we can spin up locally. If our application
    talks to a third-party system that is not a database, we should still try to find
    (or create) a Docker image that contains that system so we can test our application
    against it by spinning up a local Docker container.
  prefs: []
  type: TYPE_NORMAL
- en: If no Docker image is available for a given external system, we can write a
    custom mock output adapter that simulates the real thing. Hexagonal Architecture
    makes it easy for us to replace the real output adapter with this mock for the
    purpose of our tests. And if a Docker image becomes available, we can switch to
    the real output adapter without too much effort.
  prefs: []
  type: TYPE_NORMAL
- en: There are valid reasons to test against mock adapters instead of real adapters,
    of course. If our application runs in multiple profiles, for example, and each
    profile uses a different (real) input or output adapter implemented against the
    same input and output ports, we might want to have tests that isolate errors in
    the application from errors in the adapters. Application tests that cover only
    our hexagon are exactly the tool we want, then. However, for a standard web application
    with a database, where the input and output adapters are rather static, we probably
    want to focus on system tests instead.
  prefs: []
  type: TYPE_NORMAL
- en: What would a system test look like? In a system test for the *Send money* use
    case, we send an HTTP request to the application and validate the response as
    well as the new balance of the account.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the Java and Spring world, this is what it might look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/code-8.5a.jpg)![](img/code-8.5b.jpg)'
  prefs: []
  type: TYPE_IMG
- en: With `@SpringBootTest`, we tell Spring to start up the whole network of objects
    that makes up the application. We also configure the application to expose itself
    on a random port.
  prefs: []
  type: TYPE_NORMAL
- en: In the test method, we simply create a request, send it to the application,
    and then check the response status and the new balance of the accounts.
  prefs: []
  type: TYPE_NORMAL
- en: We use a `TestRestTemplate` to send the request, and not `MockMvc`, as we did
    earlier in the web adapter test. This means that the test makes real HTTP calls,
    bringing the test a little closer to a production environment.
  prefs: []
  type: TYPE_NORMAL
- en: Just as we go over real HTTP, we go through the real output adapters. In our
    case, this is only a persistence adapter that connects the application to a database.
    In an application that talks to other systems, we would have additional output
    adapters in place. It’s not always feasible to have all these third-party systems
    up and running, even for a system test, so we might mock them away, after all.
    Our Hexagonal Architecture makes this as easy as it can be for us since we only
    have to stub out a couple of output port interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: Note that I went out of my way to make the test as readable as possible. I hid
    every bit of ugly logic within helper methods. These methods now form a domain-specific
    language that we can use to verify the state of things.
  prefs: []
  type: TYPE_NORMAL
- en: While a domain-specific language such as this is a good idea in any type of
    test, it’s even more important in system tests. System tests simulate the real
    users of the application much better than unit or integration tests can, so we
    can use them to verify the application from the viewpoint of the user. This is
    much easier with a suitable vocabulary at hand. This vocabulary also enables domain
    experts, who are best suited to embody a user of the application and probably
    aren’t programmers, to reason about the tests and give feedback. There are whole
    libraries for behavior-driven development, such as JGiven[5](#footnote-027), that
    provide a framework to create a vocabulary for your tests.
  prefs: []
  type: TYPE_NORMAL
- en: '[5](#footnote-027-backlink) JGiven: [https://jgiven.org/](https://jgiven.org/).'
  prefs: []
  type: TYPE_NORMAL
- en: If we create unit and integration tests as described in the previous sections,
    the system tests will cover a lot of the same code. Do they even provide any additional
    benefits? Yes, they do. Usually, they flush out other types of bugs than the unit
    and integration tests do. Some mapping between the layers could be off, for instance,
    which we would not notice with the unit and integration tests alone.
  prefs: []
  type: TYPE_NORMAL
- en: System tests play out their strength best if they combine multiple use cases
    to create scenarios. Each scenario represents a certain path a user might typically
    take through the application. If the most important scenarios are covered by passing
    system tests, we can assume that we haven’t broken them with our latest modifications
    and are ready to ship.
  prefs: []
  type: TYPE_NORMAL
- en: How much testing is enough?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A question many project teams I’ve been part of couldn’t answer is how much
    testing we should do. Is it enough if our tests cover 80% of our lines of code?
    Should it be higher than that?
  prefs: []
  type: TYPE_NORMAL
- en: Line coverage is a bad metric to measure test success. Any goal other than 100%
    is completely meaningless because important parts of the code base might not be
    covered at all.[6](#footnote-026) And even at 100%, we still can’t be sure that
    every bug has been squashed.
  prefs: []
  type: TYPE_NORMAL
- en: '[6](#footnote-026-backlink) Test coverage: if you want to read more about 100%
    test coverage, have a look at my article with the tongue-in-cheek title Why you
    should enforce 100% code coverage at [https://reflectoring.io/100-percent-test-coverage/](https://reflectoring.io/100-percent-test-coverage/).'
  prefs: []
  type: TYPE_NORMAL
- en: I suggest measuring test success by how comfortable we feel shipping the software.
    If we trust the tests enough to ship after having executed them, we’re good. The
    more often we ship, the more trust we have in our tests. If we only ship twice
    a year, no one will trust the tests because they only prove themselves twice a
    year.
  prefs: []
  type: TYPE_NORMAL
- en: This requires a leap of faith the first couple of times we ship, but if we make
    it a priority to fix and learn from bugs in production, we’re on the right track.
    For each production bug, we should ask the question, *“Why didn’t our tests catch
    this bug?”*, document the answer, and then add a test that covers it. Over time,
    this will make us comfortable with shipping, and the documentation will even provide
    a metric for gauging our improvement over time.
  prefs: []
  type: TYPE_NORMAL
- en: 'It helps, however, to start with a strategy that defines the tests we should
    create. One such strategy for our Hexagonal Architecture is this:'
  prefs: []
  type: TYPE_NORMAL
- en: While implementing a domain entity, cover it with a unit test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While implementing a use case service, cover it with a unit test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While implementing an adapter, cover it with an integration test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cover the most important paths a user can take through the application with
    a system test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note the phrase *while implementing* – when tests are done during the development
    of a feature and not after, they become a development tool and no longer feel
    like a chore.
  prefs: []
  type: TYPE_NORMAL
- en: However, if we have to spend an hour fixing tests every time we add a new field,
    we’re doing something wrong. Probably, our tests are too vulnerable to structural
    changes in the code, and we should look at how to improve that. Tests lose their
    value if we have to modify them for each refactoring.
  prefs: []
  type: TYPE_NORMAL
- en: How does this help me build maintainable software?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Hexagonal Architecture style cleanly separates domain logic and outward-facing
    adapters. This helps us to define a clear testing strategy that covers the central
    domain logic with unit tests and the adapters with integration tests.
  prefs: []
  type: TYPE_NORMAL
- en: The input and output ports provide very visible mocking points in tests. For
    each port, we can decide to mock it or use the real implementation. If the ports
    are each very small and focused, mocking them is a breeze instead of a chore.
    The fewer methods a port interface provides, the less confusion there is about
    which of the methods we have to mock in a test.
  prefs: []
  type: TYPE_NORMAL
- en: If it becomes too much of a burden to mock things away, or if we don’t know
    which kind of test we should use to cover a certain part of the code base, that's
    a warning sign. In this regard, our tests have the additional responsibility of
    being a canary – to warn us about flaws in the architecture and steer us back
    on the path to creating a maintainable code base.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have talked about our use cases and our adapters mostly in isolation.
    How do they communicate with each other? In the next chapter, we’ll take a look
    at some strategies for how to design data models that make up the common language
    between them.
  prefs: []
  type: TYPE_NORMAL
