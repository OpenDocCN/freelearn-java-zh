- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Monitoring and Observability
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控和可观察性
- en: '**Monitoring** and **observability** are fundamental to ensuring that RESTful
    services operate reliably, efficiently, and securely. In distributed systems,
    where requests often pass through multiple services and components, having proper
    observability practices in place is critical. Without them, diagnosing performance
    bottlenecks, identifying the root causes of errors, and optimizing service behavior
    becomes incredibly challenging.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**监控**和**可观察性**对于确保RESTful服务可靠、高效和安全地运行至关重要。在分布式系统中，请求通常需要通过多个服务和组件，因此实施适当的可观察性实践是至关重要的。没有这些实践，诊断性能瓶颈、识别错误的根本原因以及优化服务行为将变得极其困难。'
- en: In this chapter, we will guide you through the essential practices and tools
    needed to achieve effective observability for RESTful services. We will begin
    by discussing **logging** best practices, explaining how structured logging and
    correlation IDs can simplify troubleshooting. We will then delve into distributed
    tracing, demonstrating how trace information such as `traceId` , `spanId` , and
    `parentSpanId` helps map the lifecycle of a request as it flows across multiple
    services.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将指导你了解实现RESTful服务有效可观察性的基本实践和工具。我们将从讨论**日志记录**最佳实践开始，解释结构化日志和关联ID如何简化故障排除。然后我们将深入探讨分布式追踪，展示`traceId`、`spanId`和`parentSpanId`等追踪信息如何帮助映射请求在多个服务间流动的生命周期。
- en: We will introduce **Micrometer Tracing** , a powerful observability framework
    integrated into Spring Boot 3.x, which automatically instruments applications
    to capture trace data. Additionally, we will explore OpenTelemetry, a vendor-neutral
    framework that extends observability by collecting and correlating logs, metrics,
    and traces for a holistic view of distributed systems. By the end of this chapter,
    you will understand how to implement logging and tracing effectively, configure
    Spring Boot applications for observability, and visualize your data in tools like
    Zipkin and Jaeger.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将介绍**Micrometer追踪**，这是一个强大的可观察性框架，集成在Spring Boot 3.x中，它能够自动对应用程序进行仪器化以捕获追踪数据。此外，我们还将探索OpenTelemetry，这是一个供应商中立的框架，通过收集和关联日志、指标和追踪来扩展可观察性，以获得分布式系统的整体视图。到本章结束时，你将了解如何有效地实现日志记录和追踪，配置Spring
    Boot应用程序以实现可观察性，并在Zipkin和Jaeger等工具中可视化你的数据。
- en: This chapter provides practical examples, step-by-step guidance, and best practices
    to ensure you can successfully monitor and debug your RESTful services.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提供了实际示例、逐步指导和最佳实践，以确保你可以成功监控和调试你的RESTful服务。
- en: 'In this chapter, we will be covering the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Importance of logging in REST APIs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在REST API中日志记录的重要性
- en: Logging best practices for API troubleshooting
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API故障排除的日志记录最佳实践
- en: Logging basics with SLF4J
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SLF4J的日志记录基础
- en: Implementing a central logging filter
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现中央日志过滤器
- en: Implementing service tracing in distributed systems
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在分布式系统中实现服务追踪
- en: Implementing tracing using Micrometer
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Micrometer实现追踪
- en: Metrics from tracing data
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 追踪数据的指标
- en: OpenTelemetry for monitoring and observability
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenTelemetry用于监控和可观察性
- en: Best practices for end-to-end observability
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端到端可观察性的最佳实践
- en: Technical requirements
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we will enhance our existing APIs—the Product API and the
    Order Management API—to be able to trace requests between them. To be able to
    follow along and use the code examples as they are printed in the book, you should
    have the following:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将增强现有的API——产品API和订单管理API，以便能够追踪它们之间的请求。为了能够跟随书中的示例代码进行操作，你应该具备以下条件：
- en: Intermediate knowledge of the Java language and platform
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对Java语言和平台有中级了解
- en: At least a basic knowledge of Spring Boot or a similar framework
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少对Spring Boot或类似框架有基本了解
- en: Java 21 and Maven 3.9.0 installed
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装了Java 21和Maven 3.9.0
- en: Docker 27.3.1 or higher installed
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装了Docker 27.3.1或更高版本
- en: You can access the code for this chapter on GitHub at [https://github.com/PacktPublishing/Mastering-RESTful-Web-Services-with-Java/tree/main/chapter9](https://github.com/PacktPublishing/Mastering-RESTful-Web-Services-with-Java/tree/main/chapter9)
    .
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在GitHub上访问本章的代码：[https://github.com/PacktPublishing/Mastering-RESTful-Web-Services-with-Java/tree/main/chapter9](https://github.com/PacktPublishing/Mastering-RESTful-Web-Services-with-Java/tree/main/chapter9)。
- en: Importance of logging in REST AP Is
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在REST API中日志记录的重要性
- en: Logging is the foundational element of observability in any system. Logs are
    essentially records of events that happen while your application runs. They are
    the first source of information when trying to troubleshoot an issue in any environment,
    especially in production.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 日志是任何系统中可观察性的基础元素。日志基本上是记录应用程序运行期间发生的事件的记录。它们是在任何环境中尝试解决任何问题时信息的第一来源，尤其是在生产环境中。
- en: Logs act as the system’s memory, providing insights into what went wrong or
    how certain processes behaved. For a REST API, logs can show the path of each
    request, which is crucial for understanding failures or slow performance.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 日志充当系统的记忆，提供有关发生错误或某些过程如何行为的见解。对于REST API，日志可以显示每个请求的路径，这对于理解失败或缓慢的性能至关重要。
- en: For instance, suppose your API returns a `500` `Internal Server Error` to a
    user. Without logs, you would have no way of knowing what caused the error. However,
    with logs, you could see that a database query failed because the server ran out
    of connections, helping you fix the problem.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设您的API向用户返回了一个`500` `Internal Server Error`。没有日志，您将无法知道错误的原因。然而，有了日志，您可以看到数据库查询失败是因为服务器连接耗尽，这有助于您解决问题。
- en: In the next sections, we are going to cover an effective logging design that
    will empower our applications significantly when troubleshooting is needed.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将介绍一种有效的日志设计，当需要故障排除时，这将显著增强我们的应用程序。
- en: Common logging pitfalls
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见日志陷阱
- en: 'Despite the importance of logging, many developers struggle with using logs
    effectively. Common mistakes include:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管日志的重要性不言而喻，但许多开发者在使用日志方面都感到困难。常见的错误包括：
- en: '**Over-logging** : Logging too much information can make it hard to find key
    details.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过度记录日志**：记录过多的信息可能会使得找到关键细节变得困难。'
- en: '**Under-logging** : Insufficient logging might leave out key data needed for
    troubleshooting.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**记录日志不足**：日志记录不足可能会遗漏故障排除所需的关键数据。'
- en: '**Logging sensitive information** : Mistakenly logging things like user passwords
    or credit card numbers, which should never happen due to security and compliance
    concerns (e.g., GDPR or PCI DSS).'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**记录敏感信息**：错误地记录诸如用户密码或信用卡号码等信息，这些信息由于安全和合规性考虑（例如，GDPR或PCI DSS）绝不应该发生。'
- en: A balance needs to be struck between logging enough to troubleshoot issues and
    not overwhelming the system with unnecessary data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在记录足够的信息以进行故障排除和不过度占用系统的不必要数据之间需要找到平衡。
- en: Effective log design
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有效的日志设计
- en: 'Designing logs properly is crucial for them to be useful. Each log entry should
    include relevant metadata:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 正确设计日志对于它们的有用性至关重要。每个日志条目都应该包含相关的元数据：
- en: '**Timestamp** : When the log entry was created.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间戳**：日志条目创建的时间。'
- en: '**Log level** : Severity of the log ( `INFO` , `DEBUG` , `ERROR` ).'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志级别**：日志的严重性（`INFO`，`DEBUG`，`ERROR`）。'
- en: '**Service name** : The name of the service generating the log.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务名称**：生成日志的服务名称。'
- en: '**Correlation ID** : A unique ID that allows you to track a request through
    multiple services (more on this below).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关联ID**：一个唯一的ID，允许您跟踪通过多个服务（下面将详细介绍）的请求。'
- en: 'For example, a well-structured log entry in JSON might look like this:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个结构良好的JSON日志条目可能看起来像这样：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![img](img/Information_Box_Icon.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/Information_Box_Icon.png)'
- en: Correlation IDs
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 关联ID
- en: In microservices, a request might pass through multiple services. To track the
    entire request path, it is essential to attach a correlation ID to each request.
    The correlation ID is a unique identifier that stays with the request as it moves
    through the system. This allows you to correlate logs from different services
    to see how a single request was handled end to end. For example, a user request
    to retrieve profile information might go through an API gateway, then hit the
    authentication service, and finally query the user database. With a correlation
    ID, you can trace each step of the process across all services involved. Spring
    makes it easy to generate and propagate correlation IDs. You can generate a correlation
    ID at the start of a request and pass it along with HTTP headers between services.
    This will help you diagnose where issues occur in a chain of services.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在微服务中，一个请求可能会通过多个服务。为了跟踪整个请求路径，将关联ID附加到每个请求是必不可少的。关联ID是一个唯一标识符，它在请求通过系统时保持不变。这允许您关联来自不同服务的日志，以查看单个请求是如何从头到尾处理的。例如，用户请求检索个人资料信息可能通过API网关，然后击中身份验证服务，最后查询用户数据库。使用关联ID，您可以跟踪所有涉及服务中的每个步骤。Spring使生成和传播关联ID变得简单。您可以在请求开始时生成关联ID，并通过HTTP头在服务之间传递它。这将帮助您诊断服务链中出现问题的位置。
- en: Next, we will learn about the best logging practices, understand the different
    log levels and their structure, and what should and should not be logged to avoid
    security issues.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将学习最佳日志记录实践，了解不同的日志级别及其结构，以及应该和不应该记录的内容，以避免安全问题。
- en: Logging best practices for API troubleshooting
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: API故障排除的日志最佳实践
- en: Effective logging is essential for troubleshooting, especially when working
    with distributed systems or cloud-native architectures. Here are some best practices
    to ensure your logging strategy is robust.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的日志记录对于故障排除至关重要，尤其是在与分布式系统或云原生架构一起工作时。以下是一些最佳实践，以确保您的日志策略稳健。
- en: Choosing the right log level
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择合适的日志级别
- en: 'Logs should be written at the appropriate log level, which indicates the severity
    of the event:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 应在适当的日志级别写入日志，这表示事件的严重性：
- en: '`TRACE` : Used for very fine-grained details, primarily for debugging low-level
    operations like recording the internal state of loops, method entry/exit points,
    or interactions between components in detail. Should be turned off in production
    due to the huge amount of logs that are generated at this level.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TRACE`：用于非常细粒度的细节，主要用于调试低级操作，如记录循环的内部状态、方法入口/出口点或组件之间的详细交互。由于在此级别生成的日志量巨大，因此在生产环境中应关闭。'
- en: '`DEBUG` : Used for low-level information that helps in debugging issues, such
    as details of an HTTP request. Logs provide detailed information that helps during
    development or debugging, focusing on application-specific logic or operations.
    Also, this level should be turned off in production due to the huge amount of
    logs that are generated at this level.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DEBUG`：用于帮助调试问题的低级信息，例如HTTP请求的详细信息。日志提供详细的信息，有助于开发或调试期间，专注于特定于应用程序的逻辑或操作。此外，由于在此级别生成的日志量巨大，因此应在生产环境中关闭此级别。'
- en: '`INFO` : Used for general application flow information, such as when a service
    starts up or shuts down. These logs are less verbose than `DEBUG` or `TRACE` and
    are typically enabled in production.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`INFO`：用于通用应用程序流程信息，例如当服务启动或关闭时。这些日志比`DEBUG`或`TRACE`更简洁，通常在生产环境中启用。'
- en: '`WARN` : Indicates something unusual but not necessarily an error. For example,
    a service might temporarily run out of resources but recover. These logs are a
    warning for potential future issues. For example:'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WARN`：表示某些不一定是错误的不寻常情况。例如，服务可能会暂时耗尽资源但恢复。这些日志是对潜在未来问题的警告。例如：'
- en: '`ERROR` : Used when something has gone wrong, like an exception being thrown
    or a critical failure in a database connection. These logs often indicate that
    the system requires attention or intervention.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ERROR`：用于出现问题时，如抛出异常或数据库连接中的关键故障。这些日志通常表明系统需要关注或干预。'
- en: '`FATAL` : Indicates a critical error that causes the application or service
    to crash or become unusable. These logs are extremely rare and signify the most
    severe issues that require immediate attention. Note that this level is not present
    universally in libraries like SLF4J or Logback and is often represented by the
    `ERROR` level; however, it is present in Log4J and Log4J2 logging libraries, which
    will not be covered by this chapter.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FATAL`：表示导致应用程序或服务崩溃或变得不可用的关键错误。这些日志非常罕见，表明需要立即关注的严重问题。请注意，此级别并非在所有库（如SLF4J或Logback）中都存在，通常由`ERROR`级别表示；然而，它在Log4J和Log4J2日志库中存在，本章节不会涉及。'
- en: 'In a REST API, a failed user login attempt due to incorrect credentials might
    be logged at the `WARN` level:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在REST API中，由于凭据错误而失败的登录尝试可能会记录在`WARN`级别：
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Meanwhile, a database outage that causes the entire service to fail should
    be logged at the `ERROR` level or as `FATAL` if available:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，由于数据库故障导致整个服务失败的情况应该记录在`ERROR`级别，如果可用则记录为`FATAL`：
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Choosing the right level ensures that you can quickly filter out non-critical
    logs when troubleshooting.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适的级别可以确保你在故障排除时能够快速过滤掉非关键日志。
- en: Structured logging
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结构化日志
- en: Structured logging refers to logging in a consistent, machine-readable format,
    such as JSON. This allows logs to be easily parsed and queried by logging tools
    (like ELK Stack or Splunk), making it easier to filter, aggregate, and analyze
    logs.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化日志是指以一致、机器可读的格式进行日志记录，例如JSON。这使得日志可以轻松地被日志工具（如ELK Stack或Splunk）解析和查询，使得过滤、聚合和分析日志变得更加容易。
- en: 'Rather than logging a simple message like this:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是记录这样的简单消息：
- en: '[PRE3]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You should log the event in a structured format:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该以结构化格式记录事件：
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now, you can easily search for all login failures or group them by the `user`
    field.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以轻松地搜索所有登录失败或按`user`字段分组。
- en: Avoiding sensitive data in logs
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免在日志中包含敏感数据
- en: Sensitive information such as passwords, credit card numbers, or personal identifiers
    should never be logged. If this data is accidentally exposed in logs, it can lead
    to serious security breaches.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 像密码、信用卡号码或个人标识符这样的敏感信息绝不应该被记录。如果这些数据意外地在日志中暴露，可能会导致严重的安全漏洞。
- en: 'For example, if a login attempt fails, it is okay to log the username, but
    never log the password. A log message like this:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果登录尝试失败，记录用户名是可以的，但绝不能记录密码。这样的日志消息：
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'is dangerous. Instead, log something like this:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 是危险的。相反，记录类似以下内容：
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You can use Jackson’s `@JsonIgnore` or `@JsonProperty(access = Access.WRITE_ONLY)`
    annotations to prevent sensitive data from being serialized into logs.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用Jackson的`@JsonIgnore`或`@JsonProperty(access = Access.WRITE_ONLY)`注解来防止敏感数据被序列化到日志中。
- en: Jackson is a widely used Java library for processing JSON data. It provides
    powerful capabilities for serializing Java objects into JSON and deserializing
    JSON into Java objects, making it a crucial tool in RESTful web services where
    data is often exchanged in JSON format.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Jackson是一个广泛使用的Java库，用于处理JSON数据。它提供了将Java对象序列化为JSON和将JSON反序列化为Java对象的功能，使其在数据通常以JSON格式交换的RESTful
    Web服务中成为一项关键工具。
- en: In a Spring Boot application, Jackson is the default JSON processor and is commonly
    used to automatically transform request and response payloads, making API interactions
    seamless.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spring Boot应用程序中，Jackson是默认的JSON处理器，通常用于自动转换请求和响应负载，使API交互无缝。
- en: It allows developers to customize JSON output using annotations like `@JsonIgnore`
    , `@JsonProperty` , and `@JsonInclude` , ensuring that only the necessary fields
    are exposed while sensitive or unnecessary data is excluded.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 它允许开发者使用`@JsonIgnore`、`@JsonProperty`和`@JsonInclude`等注解自定义JSON输出，确保只暴露必要的字段，同时排除敏感或不必要的数据。
- en: This is particularly useful when logging requests or response objects, as it
    ensures that sensitive information (like passwords or credit card details) does
    not get exposed in log entries.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这在记录请求或响应对象时尤其有用，因为它确保敏感信息（如密码或信用卡详情）不会在日志条目中暴露。
- en: When to use each annotation?
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 何时使用每个注解？
- en: '`@JsonIgnore` : Use when you want to prevent a field from ever being included
    in serialized output, such as responses and logs, and deserialized input from
    requests.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@JsonIgnore`：当你想防止字段永远包含在序列化输出中，例如响应和日志，以及从请求中反序列化的输入时使用。'
- en: '`@JsonProperty(access = Access.WRITE_ONLY)` : Use when you need to accept the
    field as input but want to exclude it from all serialized output, making it suitable
    for fields that should remain private (e.g., passwords) during logging or API
    responses.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let us go through an example to demonstrate how to use these annotations in
    a RESTful service.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Suppose you have a `User` class with fields like `username` , `email` , and
    `password` . When logging this `User` object, we want to ensure that the password
    field is not included in the serialized output.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Completely exclude the field from serialization/deserialization
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `@JsonIgnore` annotation completely omits a field from deserialization and
    serialization, meaning it will not be included in the input or the output JSON
    at all.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: When you use `@JsonIgnore` on a field, it is completely ignored by Jackson both
    during serialization (when converting an object to JSON) and deserialization (when
    converting JSON to an object). This means that if you mark a field with `@JsonIgnore`
    , Jackson will neither include it in the output JSON nor allow it as an input
    in the JSON request body.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: This is useful when you want to ensure that sensitive information (e.g., passwords
    or tokens) is never exposed in any serialized output, including logs.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'With this setup, if you log the User object using Jackson for serialization,
    the password field will be omitted:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**Output log (password is excluded)** :'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In this example, the `password` field is completely omitted from the log output
    because of the `@JsonIgnore` annotation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Now that you know how to exclude fields from serialization and deserialization,
    let us see how to allow a field to be deserialized from JSON input but excluded
    from serialization, such as in logs or API responses.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Allowing data input deserialization but excluding it from output serialization
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `@JsonProperty(access = Access.WRITE_ONLY)` annotation is useful when you
    want a field to be deserialized (e.g., when receiving input from a user) but not
    serialized (e.g., when logging or sending data as a response). This is common
    for fields like passwords in user registration forms:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: With `@JsonProperty(access = Access.WRITE_ONLY)` , you can still accept the
    `password` field in incoming JSON requests, but it will be excluded from any serialized
    output, including logs.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '**Example usage:**'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: When a new user registration request comes in, the `password` field will be
    available for processing, but it will not be logged.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '**Incoming request** :'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**Output log (password is excluded from the log)** :'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: With `@JsonProperty(access = Access.WRITE_ONLY)` , the password is received
    by the application but is excluded from logs or other serialized JSON output,
    ensuring that sensitive data is protected.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: By using these annotations strategically, you can control sensitive data exposure
    in logs, which is an essential part of security best practices for RESTful APIs.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s get back to the last best practice for logging
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Capturing contextual information
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 捕获上下文信息
- en: 'To make logs more useful, include contextual information about each request,
    such as:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要使日志更有用，请包括每个请求的上下文信息，例如：
- en: HTTP method ( `GET` , `POST` , etc.)
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP方法（`GET`，`POST`等）
- en: Endpoint (e.g., `/api/v1/users/123` )
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端点（例如，`/api/v1/users/123`）
- en: Response status ( `200` , `404` , `500` , etc.)
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应状态（`200`，`404`，`500`等）
- en: Request headers and payloads (but be careful to exclude sensitive data)
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求头和有效负载（但请注意排除敏感数据）
- en: This information will allow you to better understand what happened during an
    API request.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这些信息将帮助您更好地了解API请求期间发生的情况。
- en: 'For example, a request log might look like this:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个请求日志可能看起来像这样：
- en: '[PRE14]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: By capturing such details, you can correlate issues with specific requests and
    quickly pinpoint where things went wrong.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 通过捕获此类详细信息，您可以关联特定请求的问题，并快速确定问题出在哪里。
- en: Next, we will dive into one of the most famous logging libraries in the market,
    SLF4J, and how to create logs from our application.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将深入了解市场上最著名的日志库之一，SLF4J，以及如何从我们的应用程序中创建日志。
- en: Logging basics with SLF4J
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SLF4J进行日志记录基础
- en: This section introduces how to add logging points into your own Java code using
    SLF4J. This is crucial since you need to add loggers throughout your entire application
    to be able to generate logs from its flow that will help you troubleshoot it when
    it is deployed, especially in production.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了如何使用SLF4J将日志记录点添加到自己的Java代码中。这对于您在整个应用程序中添加记录器以生成日志至关重要，这些日志可以帮助您在部署时调试它，尤其是在生产环境中。
- en: In Spring Boot, SLF4J (Simple Logging Facade for Java) is commonly used as a
    logging API that can work with different logging frameworks (such as Logback,
    Log4j2, etc.). Spring Boot uses SLF4J by default and integrates it seamlessly,
    so all we need to do is inject the logger and start logging messages.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spring Boot中，SLF4J（Java简单日志门面）通常用作可以与不同日志框架（如Logback、Log4j2等）一起工作的日志API。Spring
    Boot默认使用SLF4J并将其无缝集成，因此我们所需做的就是注入记录器并开始记录消息。
- en: Also, if you are not using Spring Boot, you can just add the SLF4J dependency
    to your Maven POM dependencies file or Gradle dependencies file to use it if the
    framework that you are using does not already include it.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果您不使用Spring Boot，您只需将SLF4J依赖项添加到您的Maven POM依赖项文件或Gradle依赖项文件中，以便在使用框架时如果尚未包含它，就可以使用它。
- en: 'Let us start with a simple example of how to log a Spring Boot application
    using SLF4J. Here is a User Creation service that uses SLF4J to log messages at
    different log levels ( `INFO` , `WARN` , `ERROR` ):'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从如何使用SLF4J记录Spring Boot应用程序的简单示例开始。以下是一个使用SLF4J在不同日志级别（`INFO`，`WARN`，`ERROR`）记录消息的用户创建服务：
- en: '[PRE15]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'In this example:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中：
- en: We log informational messages with `logger.info()` .
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`logger.info()`记录信息消息。
- en: We log an error with `logger.error()` , including the exception stack trace.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`logger.error()`记录错误，包括异常堆栈跟踪。
- en: The `LoggerFactory.getLogger(UserService.class)` creates a logger specifically
    for the `UserService` class.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LoggerFactory.getLogger(UserService.class)`为`UserService`类创建一个特定的记录器。'
- en: 'For successful user creation, we would have a log output like this:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 对于成功的用户创建，日志输出将如下所示：
- en: '[PRE16]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Or, for a failed user creation, for example, trying to create a null user,
    the output would be:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，对于失败的用户创建，例如尝试创建一个null用户，输出将是：
- en: '[PRE17]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Using SLF4J with different log levels helps organize and filter log messages,
    making it easier to troubleshoot and debug.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 使用不同日志级别的SLF4J有助于组织和过滤日志消息，使其更容易调试和调试。
- en: In the next section, let us look at how we can automate some of the logging
    in our application to reduce the burden of having tons of logging everywhere in
    your code, by implementing a central logging filter.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，让我们看看如何通过实现中央日志过滤器来自动化应用程序中的一些日志记录，以减少在代码中到处都有大量日志的负担。
- en: Implementing a central logging filter
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现中央日志过滤器
- en: To improve observability in a RESTful application, we can implement a central
    logging component that logs all incoming HTTP requests and responses. A filter
    is an effective choice for this as it allows you to intercept requests before
    they reach the controller layer, enabling you to log key requests and response
    details in one place.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高RESTful应用程序的可观察性，我们可以实现一个中央日志组件，记录所有传入的HTTP请求和响应。过滤器是一个有效的选择，因为它允许您在请求到达控制器层之前拦截请求，使您能够在一个地方记录关键请求和响应细节。
- en: 'In this example, we will implement a `RequestLoggingFilter` that logs incoming
    requests, following best practices such as structured logging, adding correlation
    IDs, and avoiding sensitive information. This filter will log essential request
    metadata, such as HTTP method, URL, status code, and processing time, in a structured
    JSON format:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们将实现一个`RequestLoggingFilter`，该过滤器记录传入的请求，遵循最佳实践，如结构化日志记录、添加关联ID和避免敏感信息。此过滤器将以结构化的JSON格式记录必要请求元数据，例如HTTP方法、URL、状态码和处理时间：
- en: '[PRE18]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: So, what is this filter doing?
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，这个过滤器到底在做什么呢？
- en: '**Choosing the right log level** : The filter logs complete requests at the
    `INFO` level, which is appropriate for general application flow information. If
    a request encounters an error, it could be logged at `ERROR` in other components,
    such as exception handlers.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选择合适的日志级别**：过滤器以`INFO`级别记录完整的请求，这对于一般应用程序流程信息是合适的。如果请求遇到错误，它可以在其他组件（如异常处理器）中以`ERROR`级别记录。'
- en: '**Structured logging** : The filter uses structured logging to log information
    in JSON format, including fields like `correlationId` , `method` , `url` , `status`
    , and `duration` . Structured logging allows for easier parsing, searching, and
    aggregating in centralized logging tools.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结构化日志记录**：过滤器使用结构化日志记录以JSON格式记录信息，包括`correlationId`、`method`、`url`、`status`和`duration`等字段。结构化日志记录使得在集中式日志工具中进行解析、搜索和聚合变得更加容易。'
- en: '**Avoiding sensitive data** : The filter avoids logging the request body directly,
    which could contain sensitive information like passwords. If needed, further filtering
    can exclude or mask sensitive data in headers or query parameters.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**避免敏感数据**：过滤器避免直接记录请求体，因为请求体可能包含敏感信息，如密码。如果需要，进一步的过滤可以排除或屏蔽头或查询参数中的敏感数据。'
- en: '**Capturing contextual information** : The filter captures relevant metadata
    for each request, including the HTTP method, URL, status code, and duration. This
    provides valuable context for debugging and performance analysis.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**捕获上下文信息**：过滤器捕获每个请求的相关元数据，包括HTTP方法、URL、状态码和持续时间。这为调试和性能分析提供了有价值的上下文。'
- en: '**Using correlation IDs** : The filter generates a correlation ID (if one is
    not already present) and stores it in the **Mapped Diagnostic Context (MDC)**
    . This ensures that the correlation ID is added to all subsequent logs within
    the request’s lifecycle, enabling end-to-end tracking across services.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用关联ID**：过滤器生成一个关联ID（如果尚未存在）并将其存储在**映射诊断上下文（MDC）**中。这确保了关联ID被添加到请求生命周期内的所有后续日志中，从而实现了跨服务的端到端跟踪。'
- en: '![img](img/lightbulb1.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/lightbulb1.png)'
- en: Mapped Diagnostic Context (MDC)
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 映射诊断上下文（MDC）
- en: '**Mapped Diagnostic Context (MDC)** is a feature in logging frameworks like
    SLF4J (with Logback) and Log4j that allows developers to store and retrieve contextual
    information per thread. This context information is automatically included in
    log messages, making it easier to track related logs across different parts of
    an application.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**映射诊断上下文（MDC）**是SLF4J（与Logback）和Log4j等日志框架中的功能，允许开发者按线程存储和检索上下文信息。此上下文信息自动包含在日志消息中，使得跟踪应用程序不同部分的关联日志变得更加容易。'
- en: 'With this logging filter in place, here is an example of what a log entry might
    look like:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在此日志过滤器设置到位后，以下是一个日志条目可能的样子：
- en: '[PRE19]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'But to have the `correlationId` spread to other services and enable the power
    of tracking the request across multiple services, we need to update the header
    with the proper newly generated value from `correlationId` , adding it before
    the request is sent. We will do it using `BeanPostProcessor` :'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 但为了将`correlationId`传播到其他服务并启用跨多个服务的请求跟踪功能，我们需要在发送请求之前更新头信息，添加从`correlationId`生成的新值。我们将使用`BeanPostProcessor`来完成这项工作：
- en: '[PRE20]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: As an example, in the Order Management API, before calling the `productsApi`
    into the `ProductsQueryUseCaseImpl` implementation, we will make a call to the
    `beanPostProcessor` to have the `ApiClient` bean updated with the `correlationId`
    set in the header from the request.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在订单管理API中，在调用`productsApi`到`ProductsQueryUseCaseImpl`实现之前，我们将调用`beanPostProcessor`以将请求头中设置的`correlationId`更新到`ApiClient`
    bean中。
- en: 'The `ApiClient` is the REST client that was generated by the OpenAPI plugin
    using the Product API specification and will be used for every call to the Product
    API from the Order Management API. Here is the updated version of the class:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '`ApiClient`是由OpenAPI插件使用产品API规范生成的REST客户端，并将用于从订单管理API对产品API的每次调用。以下是该类的更新版本：'
- en: '[PRE21]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This ensures that the `correlationId` is propagated with every service request.
    The filter in the called service will read the `correlationId` and include it
    in the logs, enabling you to uniquely track requests across the services.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这确保了`correlationId`与每个服务请求一起传播。被调用服务的过滤器将读取`correlationId`并将其包含在日志中，使您能够跨服务唯一跟踪请求。
- en: 'Additional functionality can be added to the filter to capture even more detailed
    logging information:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 可以向过滤器添加更多功能，以捕获更详细的日志信息：
- en: '**Log-specific headers** : Capture headers like `User-Agent` or `Authorization`
    , but exclude or mask sensitive details.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**记录特定头信息**：捕获像`User-Agent`或`Authorization`这样的头信息，但排除或屏蔽敏感细节。'
- en: '**Conditional logging for error responses** : Modify the filter to log `4xx`
    and `5xx` responses at `WARN` or `ERROR` levels for easier error tracking.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**条件日志记录错误响应**：修改过滤器以在`WARN`或`ERROR`级别记录`4xx`和`5xx`响应，以便更容易地进行错误跟踪。'
- en: '**Error handling** : Combine this filter with a global exception handler to
    capture and log unhandled exceptions, leveraging the correlation ID to tie error
    logs to their originating requests.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误处理**：将此过滤器与全局异常处理器结合使用，以捕获和记录未处理的异常，利用关联ID将错误日志与其原始请求关联起来。'
- en: This logging filter implements best practices and creates consistent, structured
    logs across the application, making it easier to monitor, troubleshoot, and analyze
    incoming API requests.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 此日志过滤器实现了最佳实践，并在整个应用程序中创建了一致的、结构化的日志，这使得监控、故障排除和分析传入的API请求变得更加容易。
- en: And to effectively track requests across multiple services, implementing tracing
    is essential. It helps maintain a clear trace and simplifies troubleshooting in
    distributed systems. In the next section, we will explore how to achieve this.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 而要有效地跨多个服务跟踪请求，实现追踪是必不可少的。它有助于保持清晰的追踪并简化分布式系统中的故障排除。在下一节中，我们将探讨如何实现这一点。
- en: Implementing service tracing in distributed systems
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在分布式系统中实现服务追踪
- en: In distributed systems, where a request might span multiple services, **distributed
    tracing** provides visibility into how a request moves through various components.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式系统中，一个请求可能跨越多个服务，**分布式追踪**提供了对请求如何通过各种组件的可见性。
- en: Let’s begin by understanding what we mean by distributed tracing.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先了解我们所说的分布式追踪是什么意思。
- en: What is distributed tracing?
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是分布式追踪？
- en: Distributed tracing allows you to follow the lifecycle of a request as it flows
    from one service to another. This helps you see where delays or errors occur.
    In tracing terminology, each step in the request’s journey is called a span, and
    a trace is the entire set of spans associated with a request.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式追踪允许您跟踪请求的生命周期，从一项服务流向另一项服务。这有助于您看到延迟或错误发生的位置。在追踪术语中，请求旅程中的每一步称为一个跨度，而追踪是与请求相关联的所有跨度的集合。
- en: 'For example, imagine a request comes into your system to create a new user.
    This request might touch on the following services:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，想象一个请求进入您的系统以创建新用户。这个请求可能会影响到以下服务：
- en: API gateway
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: API网关
- en: Authentication service
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 认证服务
- en: User service (to create the user in the database)
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户服务（用于在数据库中创建用户）
- en: Notification service (to send a welcome email)
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通知服务（用于发送欢迎邮件）
- en: Each of these steps is a span, and all the spans together form a trace.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 每个步骤都是一个跨度，所有跨度共同构成一个追踪。
- en: Distributed tracing tools, such as Zipkin or Jaeger, can visualize the trace
    and highlight which services or steps are causing delays.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式追踪工具，如Zipkin或Jaeger，可以可视化追踪并突出显示导致延迟的服务或步骤。
- en: Next, we will understand how each trace is identified uniquely by adding a trace
    ID to each request.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过为每个请求添加一个追踪ID来了解每个追踪是如何唯一标识的。
- en: Using trace IDs for end-to-end request tracking
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用追踪ID进行端到端请求跟踪
- en: Just like correlation IDs help in logs, trace IDs are unique identifiers attached
    to each request, allowing for end-to-end request tracking” you to track that request
    across multiple services. The difference is that trace IDs are automatically managed
    by tracing systems and include timing information.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 就像关联ID有助于日志一样，追踪ID是附加到每个请求的唯一标识符，允许进行端到端请求跟踪，您可以在多个服务中跟踪该请求。不同之处在于，追踪ID由追踪系统自动管理，并包括时间信息。
- en: In Spring, the Micrometer Tracing library automatically generates trace IDs
    for each request and propagates them across service boundaries. These IDs are
    included in the logs and tracing systems, allowing you to correlate logs and traces
    for detailed troubleshooting.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: 'In a Spring Boot application, Micrometer Tracing generates the following log
    message:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '`traceId` helps you connect this event to other related events across different
    services.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Now, let us learn how to implement the tracing feature with Micrometer.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Implementing tracing using Micrometer
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the release of Spring Boot 3.x, Spring Cloud Sleuth has been replaced by
    Micrometer Tracing for tracing support. Micrometer Tracing is fully compatible
    with Spring Boot 3.x and offers a more modern, flexible way to implement distributed
    tracing in your applications.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will walk through how to implement distributed tracing in
    a Spring Boot application using Micrometer Tracing, enabling you to track requests
    across services and get detailed insights into their performance.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Micrometer Tracing in Spring Boot
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To implement tracing in a Spring Boot application using Micrometer Tracing,
    follow these steps:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '**Add Micrometer Tracing dependencies** :'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Micrometer Tracing is part of the Micrometer ecosystem, and it integrates easily
    with Spring Boot 3.x. To enable Micrometer Tracing in your project, add the necessary
    dependencies to your `pom.xml` (if using Maven):'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Here is what these dependencies are used for:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '`micrometer-observation` : Provides the core Observation API that serves as
    a facade for metrics, logging, and tracing. It allows you to instrument code once
    and get multiple observability benefits, focusing on what you want to observe
    rather than how to implement it.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`micrometer-tracing-bridge-brave` : Bridges the Micrometer Observation API
    to Brave, enabling distributed tracing capabilities. This dependency is responsible
    for creating and propagating trace and span IDs across service boundaries, which
    is what adds the trace context to your logs.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spring-boot-starter-actuator` : Provides production-ready features to help
    monitor and manage your application. It includes endpoints for health checks,
    metrics, and other operational data. This starter automatically configures the
    observability infrastructure when combined with the Micrometer dependencies.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Together, these dependencies enable comprehensive observability with metrics,
    tracing, and health monitoring in a Spring Boot microservices architecture.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '**Configure Micrometer Tracing** :'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you’ve added the dependencies, Micrometer Tracing is automatically configured
    in Spring Boot. By default, Micrometer will instrument your HTTP requests, generating
    trace IDs and span IDs for each incoming request. These IDs are propagated across
    service boundaries.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'To enable tracing fully, you may need to configure how traces are exported.
    For example, to export traces to Zipkin, add the following configuration to your
    `application.yml` :'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In this configuration, we have the following parameters:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '`management.tracing.enabled=true` : Enables tracing for the application.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`management.tracing.sampling.probability=1.0` : Ensures that all requests are
    traced (for production, you might want to adjust this for performance reasons).'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`management.tracing.zipkin.enabled=true` : Enables exporting traces to Zipkin.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`management.tracing.zipkin.endpoint` : Specifies the URL of your Zipkin server
    for trace collection.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logging.pattern.level` : Specifies a pattern on which each log will be presented.
    Here, we are setting it to log as follows: application name, traceId, spanId.
    Note that the format for getting the values in the logs for the trace ID and the
    span Id can differ from library to library.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Configuring RestClient for tracing**'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To guarantee that the generated trace is propagated through the called services,
    you need to configure your HTTP client to propagate the trace context. This is
    done by configuring `RestClient` to use the one that is created by Spring, using
    the dependencies and configurations done in steps 1 and 2.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Since we are using `OpenAPI` in this book to generate the client that queries
    the Products API from the Order Management API, you need to override the generated
    `RestClient` from OpenAPI with the one from instantiated in Spring.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: 'To do that, you need to properly set the beans in the configuration. In the
    Order Management API, these configurations are done on the `ProductsApiConfiguration`
    class, under the `adapter.outbound.rest` package:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This code configures the `RestClient` bean with a custom `ClientHttpRequestFactory`
    and an `ObservationRegistry` from the imported `micrometer-observation` dependency.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Then, it adds the configured `RestClient` bean into the `ApiClient` bean, followed
    by the configured `ApiClient` bean into the `ProductsApi` bean. We use the `ProductsApi`
    bean to call the external Products API from the Order Management API.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: This is how we ensure that the `traceId` and `spanId` values are generated and
    that `traceId` is properly propagated over all the services that we call from
    the Order Management API.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: But also, after that, we are configuring a custom `SpanHandler` with a `LogSpanHandler`
    . That is used to log useful information from the trace context into the application
    logs. Information like the duration, the request origin, its timestamp, and the
    `traceId` give us various data to monitor and troubleshoot the application in
    production. In the next section, you will see a real example logged by this `SpanHandler`
    .
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '![img](img/Information_Box_Icon.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
- en: What are beans?
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: In Spring, beans are simply Java objects that are created, managed, and configured
    by the Spring **IoC (Inversion of Control)** container. Think of them as the building
    blocks of your application. When you define a class as a bean, you’re telling
    Spring to take responsibility for instantiating it, handling its dependencies,
    and managing its lifecycle. You can define beans using annotations like `@Component`
    , `@Service` , or `@Bean` , or through XML configuration. Once registered, these
    beans can be automatically “wired” together, meaning Spring will inject dependencies
    between them without you having to manually create and connect objects. This approach
    makes your code more modular, easier to test, and less coupled.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Viewing trace data
  id: totrans-218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once your application is instrumented with Micrometer Tracing, you can view
    the trace data in a distributed tracing tool like Zipkin or Jaeger. These tools
    allow you to visualize traces and spans, helping you diagnose performance bottlenecks
    or failures across services.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: 'Just to understand the difference between traces and spans:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: The trace would include multiple spans representing the various services and
    operations involved in a request.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each span includes timing data, enabling you to identify slow services or problematic
    operations.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When Micrometer Tracing is implemented in a Spring Boot application, the logs
    will include additional fields such as `traceId` and `spanId` . These fields help
    you correlate logs across services in a distributed system. The `traceId` remains
    the same for the entire lifecycle of a request across different services, while
    each service or operation within a service gets its own `spanId` .
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of how the logs will look with Micrometer Tracing enabled
    and properly configured, calling the Products API from the Order Management API.
    It follows the logging pattern that we defined in the `applications.yml` file:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'These are the elements contained in this log:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '`2025-03-19T16:45:39.207-03:00` : **Timestamp** – When this log entry was created'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`INFO` : **Log level** – Indicates an informational message (not an error)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`[order-management-api,67db1edfd85f42d21368a69936519fd1,1368a69936519fd1]`
    : Defined pattern logging, containing:'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service name** – Identifies which microservice generated the log'
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Trace Id** – Unique identifier tracking the request across all services'
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Span Id** – Identifies this specific operation within the trace'
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`24477` : **Process ID** – The operating system’s identifier for this application
    instance'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`---` : **Separator** – Visual divider in the log format'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`[order-management-api]` : **Application name** – Repeats the service name
    for readability'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`[nio-8090-exec-1]` : **Thread name** – The specific execution thread handling
    this request'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`[67db1edfd85f42d21368a69936519fd1-1368a69936519fd1]` : **Correlation ID**
    – Combined `traceId-spanId` for easy request tracking'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`c.p.o.a.o.rest.ProductsQueryUseCaseImpl` : **Logger name** – The class that
    generated this log (shortened)'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Getting product with id AA00001` : **Log message** – Simple text description
    of the operation being performed, showing the product ID being requested'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is how Micrometer Tracing enables the logs in the application to make it
    possible to track requests between applications.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: But if you want to have even more details in your logs, you will get them from
    the `LogSpanHandler` that we configured along with the beans in the configuration
    section.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us look at a specific log generated by the `LogSpanHandler` :'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This specific log is the one generated by the `LogSpanHandler` configuration
    that adds all the information from the trace context.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: The beginning of this log follows the same structure defined in the logging
    pattern shown previously, but what differs here is the information contained in
    its body, which is in JSON format.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us understand each of the elements inside of this JSON body generated by
    the `LogSpanHandler` and how they can help us in the observability of our applications:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '`traceId` : **Distributed trace identifier** – Links all spans across services
    for this request'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`parentId` : **Parent span ID** – This field identifies the parent span from
    which the current span originated. If the current service or operation was triggered
    by another service, the parent span ID helps trace the hierarchy of calls between
    services.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`id` : **Span ID** – Unique identifier for this specific operation'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kind` : **Span type** – `"CLIENT"` means the outbound request to another service'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`name` : **Operation name** – Describes what action was performed'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timestamp` : **Start time** – When this operation began (in microseconds)'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`duration` : **Execution time** – How long the operation took (6.246ms)'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`localEndpoint` : **Service information** – Details about the originating service'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tags` : Contextual metadata containing'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application name** – Service identifier'
  id: totrans-256
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Client name** – Target server hostname'
  id: totrans-257
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Exception** – Error status (none means successful)'
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HTTP URL** – Full URL that was called'
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Method** – HTTP verb used ( `GET` )'
  id: totrans-260
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Outcome** – Result category ( `SUCCESS` )'
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Status** – HTTP response code ( `200 = OK` )'
  id: totrans-262
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**URI** – Request path pattern with path variables'
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If you noticed, we talked about `parentSpanId` in this example. Let us understand
    better how this relates to `spanId` and how this can be useful in monitoring the
    performance of distributed systems.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Understanding parentSpanId and spanId
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In distributed tracing, every request generates a trace, which consists of multiple
    spans. A span represents a single unit of work, such as a service call, database
    query, or a specific business process within a service. Each span includes a unique
    identifier, called the `spanId` , and a `parentSpanId` that links it to the span
    from which it originated. This parent-child relationship helps to visualize how
    requests pro pagate through different services in a distributed system.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: In sum, a `spanId` is a unique identifier for the current operation or service,
    and `parentSpanId` is the `spanId` of the calling operation or service. This field
    links spans together, showing which service called another.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: Using these IDs, tracing tools like Zipkin or Jaeger can display a complete
    timeline of the trace, revealing the structure and timing of each request across
    services.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: To visualize the relationship between `spanId` and `parentSpanId` , let’s walk
    through an example trace for a user registration request in an e-commerce application,
    where each service involved in the trace has its own `spanId` and, if applicable,
    a `parentSpanId` .
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: An API gateway receives the initial request and generates a `traceId` and `spanId`
    .
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `User` service handles the user registration, with a span linked to the
    API gateway’s `spanId` as its `parentSpanId` .
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A `Notification` service sends a welcome email to the user. This service’s span
    has the `spanId` of the `User` service as its `parentSpanId` .
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Below is a simplified visualization of what this trace might look like in a
    tool like Jaeger:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '| **Span Name** | **Service** | **spanId** | **parentSpanId** | **Start Time**
    | **Duration** |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
- en: '| `register_user` | API Gateway | `span1` | - | 0ms | 15ms |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
- en: '| `create_user_record` | User | `span2` | `span1` | 5ms | 40ms |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
- en: '| `send_email` | Notification | `span3` | `span2` | 25ms | 30ms |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
- en: 'In this visualization:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: The `register_user` span from the API gateway is the root of the trace. It has
    no `parentSpanId` because it starts the trace.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `User Service` span ( `create_user_record` ) is a child of the `API Gateway`
    span, so it references `span1` as its `parentSpanId` .
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Notification` service span ( `send_email` ) is a child of the `User Service`
    span and has `span2` as its `parentSpanId` , indicating it was triggered by the
    user creation process.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The tracing tool displays the parent-child hierarchy as a timeline to visualize
    request propagation. Below is a diagram that matches this hierarchy, showing how
    each service relates in time:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'In a trace visualization tool:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: The `API Gateway` span ( `span1` ) initiates the request.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`User Service` ( `span2` ) begins shortly after `API Gateway` , and it takes
    more time as it performs operations like database insertion, for example.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Notification Service` ( `span3` ) starts after `User Service` completes the
    user creation. The duration of each span indicates how long each operation took.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parent-child hierarchy insights
  id: totrans-288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This trace hierarchy is useful for:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '**Identifying bottlenecks** : If `User Service` took unusually long, it would
    appear as a longer bar in the timeline, prompting an investiga tion.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tracing errors** : If an error occurred in `Notification Service` , you could
    see it in the trace and quickly trace it back to the originating request from
    `User Service` .'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Understanding dependencies** : By looking at the parent-child structure,
    you can see how each service depends on others and the sequence of operations.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This visualization and the `spanId` and `parentSpanId` relationship allow software
    engineers, architects, and system analysts to understand the flow and timeline
    of each request across multiple services, helping optimize performance, troubleshoot
    issues, and gain insights into the system’s behavior.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: Logs across multiple services
  id: totrans-294
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When a request flows through multiple services in a distributed system, each
    service logs its part of the request independently. By correlating these logs
    through unique identifiers like `traceId` and `spanId` , we can connect individual
    logs across services to form a complete picture of the request’s journey. This
    end-to-end visibility is crucial for understanding how services interact, identifying
    bottlenecks, and troubleshooting errors.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, a User Registration request passes through three services:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '**API Gateway** : Receives the initial request and routes it to the appropriate
    backend service.'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**User Service** : Processes the registration by creating a user record in
    the database.'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Notification Service** : Sends a welcome email to the user upon successful
    registration.'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each service logs its part of the request using the same `traceId` to correlate
    logs. The `spanId` is unique within each service, while the `parentSpanId` links
    it back to the calling service.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: 'The diagram below shows how the request moves through each service, with corresponding
    logs identified by numbers that correlate to the example logs below:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Each log entry shown below is marked with a number corresponding to the steps
    in the diagram above. By following `traceId` , `spanId` , and `parentSpanId` ,
    we can see how each service is connected within the trace, enabling us to reconstruct
    the request’s journey.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: Next, let us see examples of logs on each service this trace is going through.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: API Gateway log
  id: totrans-305
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When the API gateway receives the request, it generates a new `traceId` (A)
    and its own `spanId` (1).
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: User Service log
  id: totrans-308
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The User Service processes the registration, using the `traceId (A)` to connect
    it to the original request. The `User Service` log entry has a unique `spanId
    (2)` and references the API Gateway’s `spanId (1)` as its `parentSpanId` .
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Notification Service log
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After the User Service completes the user creation, it triggers the Notification
    Service to send a welcome email. The `Notification Service` log entry includes
    the `traceId` (A) to maintain continuity, generates its own `spanId` (3), and
    uses the User Service’s `spanId` (2) as its `parentSpanId` .
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'In this example, the `traceId` (A) remains the same across all services, linking
    the logs together to represent the entire request flow. Each log’s `spanId` and
    `parentSpanId` establish a parent-child relationship, showing how each service
    is connected in the sequence. Here’s how these logs work together:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '**Log 1 (API Gateway)** : Initiates the request with `traceId` (A) and `spanId`
    (1).'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Log 2 (User Service)** : Continues the request, referencing the API Gateway’s
    `spanId` (1) with its `parentSpanId` and creating a new `spanId` (2) for itself.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Log 3 (Notification Service)** : Completes the flow by linking back to the
    User Service’s `spanId` (2) and creating its own `spanId` (3).'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the combination of `traceId` , `spanId` , and `parentSpanId` , we can
    follow the lifecycle of the user registration request as it moves from service
    to service, providing a clear and structured view of the request’s journey.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: 'The logs are useful in the following ways:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: '**End-to-end traceability** : By searching for logs with the same `traceId`
    , you can trace a request across different services (API Gateway, User Service,
    and Notification Service) and see how the request was handled at each step.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service dependencies** : The `parentSpanId` helps you understand how services
    are connected. In the example above, the Notification service was called by the
    User service, which was triggered by the API Gateway. The logs show the hierarchy
    of calls.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance insights** : Comparing the timestamps across spans can give you
    insights into performance bottlenecks. For instance, you can measure how much
    time each service took to handle the request by comparing the timestamps.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Micrometer Tracing enriches your logs with essential trace and span data that
    allows you to track requests across distributed systems. This traceability simplifies
    troubleshooting and helps you visualize the flow of requests, making it easier
    to detect performance issues or service failures. By integrating this data with
    tools like Zipkin or Jaeger, you can also visualize traces in real time, further
    enhancing your observability strategy.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing traces with Zipkin
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To be able to run a local Zipkin instance on your machine, create the following
    `docker-compose.yml` file, which will automatically download and configure your
    local Zipkin instance with the following content:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: This file defines from where we are getting the Docker image and the version,
    that is the latest available. Also, we will run this at memory, using the default
    port `9411` .
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: 'To run this container, you need Docker installed on your system. Once it is
    installed, open a console in the same directory where this file is saved and run
    the following command:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Once the application is running, go to your local running Zipkin’s UI ( `http://localhost:9411`
    ) to view the traces. You should see a graphical representation of the trace,
    showing the `traceId` , `spanId` , and the parent-child relationships across services.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – Complete trace journey in Zipkin dashboard with Micrometer](img/B21843_09_1.png)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – Complete trace journey in Zipkin dashboard with Micrometer
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: Adding custom spans
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the automatic tracing of HTTP requests, you may want to create
    custom spans to trace specific operations within your services. For example, you
    can trace important business logic or database queries.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: 'To create custom spans, inject the `Tracer` into your service and use it to
    manually create and manage spans:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: In this example, we use `Tracer` to create a custom span called `createUser`
    , which tracks the execution of the user creation process. The span is manually
    started with `start()` and completed with `end()` . We also ensure that any exceptions
    are captured in the span by calling `newUserSpan.error(e)` .
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: Next, let us understand how we can extract metrics from the tracing data and
    how this can help us monitor the whole application environment behavior.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: Metrics from tracing data
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Metrics for RESTful web services are essential for evaluating and optimizing
    the performance of these services. These metrics provide insights into how efficiently
    APIs handle requests, process data, and deliver responses.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: This helps in ensuring that RESTful web services operate smoothly, providing
    a better user experience and meeting business objectives.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: With Micrometer Tracing in place, you can extract meaningful metrics from your
    trace data. Metrics give you quantitative insights into your API’s performance
    and health.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: Metrics like latency, throughput, and error rates are key to understanding how
    your REST API performs under load. These metrics help detect slow services, overloaded
    endpoints, or frequent errors that need to be addressed.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: Types of metrics to monitor
  id: totrans-344
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some common metrics to track in REST APIs include:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: '**Request duration** : How long does it take for the API to respond?'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Request count** : The number of requests served over a period.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Success/failure rate** : Percentage of successful vs. failed requests.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HTTP error codes** : Count of `4xx` and `5xx` responses.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can configure Micrometer to track these metrics automatically. For example,
    to track request duration, add the following configuration:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '**Metrics examples** :'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: '**Latency** : Average time it takes for a request to complete (e.g., 200ms).'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Throughput** : The system processes an average of 150 requests per second
    during peak hours.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Error Rate** : Percentage of requests that fail (e.g., 5% of requests return
    a 500 error).'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metrics can help identify performance bottlenecks. For instance, if one of your
    API endpoints consistently has a higher latency than others, it might indicate
    a need to optimize database queries, improve caching, or refactor code.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: For example, if the `/api/v1/users` endpoint shows an average response time
    of 500ms, but other endpoints respond in under 100ms, you can use tracing data
    to find out where the delay occurs (e.g., in a database query or a third-party
    API call).
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: Viewing metrics with Micrometer
  id: totrans-358
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Micrometer integrates with Prometheus and Grafana to visualize your metrics
    in real-time dashboards. This allows you to create custom views and alerts based
    on the performance of your API.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: For example, in Grafana, you can create a dashboard that visualizes the latency
    of your API endpoints over time using time series graphs. These graphs help you
    spot trends and optimize performance by highlighting periods of increased latency,
    which might indicate bottlenecks or resource constraints. For instance, you can
    use a line chart to display how the average response time of a specific endpoint
    changes over time, making it easier to identify patterns or anomalies.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, Grafana supports a variety of other visualizations that can be
    used to display metrics such as request counts, success/failure rates, and HTTP
    error codes. For example, you can use bar charts to compare the number of successful
    versus failed requests over a given period, or pie charts to show the distribution
    of different HTTP status codes returned by your API.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2 – Metrics displayed in a Grafana dashboard](img/B21843_09_2.png)'
  id: totrans-362
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – Metrics displayed in a Grafana dashboard
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have mastered Micrometer, let us look at another option for monitoring
    and observability, which is also open source and widely used in the market, OpenTelemetry.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: OpenTelemetry for monitoring and observability
  id: totrans-365
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenTelemetry is an open-source, vendor-neutral observability framework that
    provides tools to collect telemetry data (logs, metrics, and traces) from your
    applications. It is a comprehensive standard designed to provide deep insights
    into distributed systems and is widely supported across languages and platforms.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: OpenTelemetry unifies logs, metrics, and traces into one framework, providing
    a standardized way to instrument your services. It works with a variety of backends
    (like Prometheus, Jaeger, Zipkin, and Grafana) and supports distributed tracing
    across microservices.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: OpenTelemetry helps you track the complete lifecycle of a request as it moves
    through multiple services, providing valuable insights into service performance,
    latency, and bottlenecks.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenTelemetry consists of the following components:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: '**Traces** : Monitor the journey of requests across multiple services.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics** : Collect quantitative data on service performance, such as response
    times and error rates.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logs** : Record discrete events within the system, such as errors or warnings.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using OpenTelemetry in Spring Boot
  id: totrans-373
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: OpenTelemetry provides a standardized way to collect, process, and export telemetry
    data (logs, metrics, and traces) from your application. In a Spring Boot application,
    OpenTelemetry can be integrated to automatically capture tracing data across your
    services. Once integrated, this data can be exported to observability tools like
    Jaeger, Zipkin, or Grafana to visualize and monitor the flow of requests in real
    time.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll go through the steps to set up OpenTelemetry in a Spring
    Boot application, validate that tracing is working, and review sample logs showing
    the output after implementing OpenTelemetry.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: '**Add OpenTelemetry dependencies** : To integrate OpenTelemetry with Spring
    Boot, you’ll need the OpenTelemetry SDK along with specific instrumentation dependencies
    for Spring and HTTP clients. Add the following dependencies to your `pom.xml`
    :'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Under the dependency management tag:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'After that, proceed to add the following dependencies under the dependencies
    tag:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Let us understand what each of these dependencies are used for:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: '`opentelemetry-instrumentation-bom` :'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Bill of Materials (BOM) that ensures version alignment across all OpenTelemetry
    dependencies.
  id: totrans-383
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Helps manage compatible versions between OpenTelemetry components and their
    transitive dependencies.
  id: totrans-384
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Must be imported before other BOMs (like spring-boot-dependencies) when using
    Maven like we are doing here.
  id: totrans-385
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`micrometer-tracing-bridge-otel` :'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bridges Micrometer’s Observation API to OpenTelemetry’s tracing system.
  id: totrans-387
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Facilitates the propagation of trace context and spans between Micrometer and
    OpenTelemetry.
  id: totrans-388
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Essential component for enabling distributed tracing with OpenTelemetry in Spring
    Boot applications.
  id: totrans-389
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`opentelemetry-spring-boot-starter` :'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provides auto-configuration for OpenTelemetry in Spring Boot applications
  id: totrans-391
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Includes built-in instrumentation for many Spring Boot features
  id: totrans-392
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Simplifies the process of instrumenting a Spring Boot application with minimal
    configuration
  id: totrans-393
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Particularly useful for Spring Boot Native image applications or when seeking
    reduced startup overhead compared to the Java agent approach
  id: totrans-394
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`opentelemetry-exporter-otlp` :'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implements the OpenTelemetry Protocol (OTLP) exporter for sending telemetry
    data
  id: totrans-396
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Allows applications to export collected tracing data to OpenTelemetry Collectors
    or other backends
  id: totrans-397
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Supports standardized telemetry data delivery between observability tools
  id: totrans-398
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Can be configured to use either HTTP or gRPC transport protocols
  id: totrans-399
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spring-boot-starter-actuator` :'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adds production-grade monitoring and management features to Spring Boot applications.
  id: totrans-401
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Provides dependency management and auto-configuration for Micrometer (metrics
    and tracing)
  id: totrans-402
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Required foundation for both metrics and tracing capabilities in Spring Boot.
    This is mandatory for any tracing, either only with Micrometer or along with OpenTelemetry
  id: totrans-403
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Exposes endpoints for application health, metrics, and other operational data
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Configuring OpenTelemetry into the application** : Let us have the following
    properties in the `application.yml` .'
  id: totrans-405
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: First, we are going to define the URL where OpenTelemetry will send the traces,
    and in this case, this is the path and exposed port from Jaeger that we are going
    to run from the `docker-compose` file that you will define next.
  id: totrans-406
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-407
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Under the `otel` tag, we are setting OpenTelemetry to not export logs or metrics,
    only traces. It will also work without these configurations but will throw multiple
    exceptions in the application log because Jaeger only reads traces, not logs or
    metrics.
  id: totrans-408
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are going to use another backend tool like Grafana that consumes the
    logs and the metrics, instead of setting it to none, you should add the proper
    configuration for the backend that you are going to use.
  id: totrans-409
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Since OpenTelemetry is compatible with a wide variety of backends, you should
    refer to the documentation to see how to configure it for the logs and metrics
    backend that you will be using.
  id: totrans-410
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-411
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Next, under the management tag, you have the same configuration as shown in
    the Micrometer section. The configuration needs to contain tracing enabled and
    the sampling probability at 1.0 in order to generate as many traces as possible
    for our testing purposes. In production environments, you should configure that
    with a smaller value to avoid unneeded tracing.
  id: totrans-412
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-413
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Finally, be aware that the logging pattern with OpenTelemetry changes. Using
    pure Micrometer with Brave, as shown in the section Implementing tracing using
    Micrometer, registers the trace and the span as `traceId` and `spanId` in the
    MDC (Mapped Diagnostic Context), that is, from where the pattern gets its values.
    But OpenTelemetry registers them as `trace_id` and `span_id` . This is a slight
    change but if you do not take this into consideration, you will not see the tracing
    in your application logs.
  id: totrans-414
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-415
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '**Configuring OpenTelemetry exporter** : Create an OpenTelemetry configuration
    class in your Spring Boot application to export the traces to the defined tracing
    URL. This setup is generally handled automatically when using `opentelemetry-spring-boot-starter`
    , but you can add further customization to initialize it as a bean in Spring,
    like we are doing here.'
  id: totrans-416
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This will export the traces directly to be collected by the backend, which
    in our example will be Jaeger this time. To achieve that, we are going to use
    the OtlpHttpSpanExporter class from the OpenTelemetry library imported earlier:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: With this configuration, the `OtlpHttpSpanExporter` will export the traces directly
    into the defined tracing URL from the `applications.yml` , so Jaeger can read
    our traces directly. By default, OpenTelemetry will automatically instrument HTTP
    and Spring MVC requests.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: '**Validate tracing in the application** : To validate that OpenTelemetry tracing
    is working, we can:'
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Check traces in the exported tool: Start your Spring Boot application and use
    Jaeger (or the chosen backend) to view the traces. Each incoming request should
    appear in the tracing tool as a new trace with a unique `traceId` .'
  id: totrans-421
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Observe logs with trace and span IDs: After setting up OpenTelemetry, logs
    should contain `traceId` and `spanId` , allowing you to correlate log entries
    across services.'
  id: totrans-422
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Verify logs and trace visualization** : After implementing OpenTelemetry,
    you should see enhanced logs with traceId and spanId for each request. Additionally,
    the tracing backend (Zipkin, in this case) will provide a visual representation
    of the trace.'
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Logs with OpenTelemetry Tracing
  id: totrans-424
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Below is an example log output from the `order-management-api` calling the
    `product-api` after implementing OpenTelemetry. Notice the `traceId` and `spanId`
    added to each log entry, following the defined logging pattern into the `application.yml`
    file:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: It follows the same structure described in the section Viewing trace data, but
    here these traces and spans are being generated by OpenTelemetry.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also see the logs on the `product-api` side, which receives the `traceId`
    from the `order-management-api` and generates its own `spanId` :'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-429
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: With these IDs, each log entry can be correlated to a specific request and its
    journey across multiple services.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will learn how to run a local Jaeger instance to see the whole tracing
    in action.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
- en: Visualization example with Jaeger
  id: totrans-432
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To be able to run a local Jaeger instance on your machine, create the following
    `docker-compose.yml` file, which will automatically download and configure your
    local Jaeger instance with the following content:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: This file defines to get the latest Docker image for Jaeger. Also, here we are
    allocating port `4318` for tracing and `16686` for the Jaeger UI interface.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: The property `COLLECTOR_OTLP_ENABLED=true` is optional on Jaeger v2 since its
    default is always true and mandatory on Jaeger v1. At the time of this writing,
    you should get above v2 while running this `docker-compose.yml` file.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: 'To run this container, you need Docker installed on your system. Once it is
    installed, open a console in the same directory as where this file is saved and
    run the following command:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Once the application is running, go to your local running Jaeger’s UI ( `http://localhost:16686`
    ) to view the traces. You should see a graphical representation of the trace,
    showing the `traceId` , `spanId` , and the parent-child relationships across services,
    and even showing deeper details like database `INSERT` and durations, giving a
    broad view of the trace.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Complete trace journey in Jaeger dashboard with OpenTelemetry](img/B21843_09_3.png)'
  id: totrans-440
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – Complete trace journey in Jaeger dashboard with OpenTelemetry
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of any error, it will highlight what happened and where it happened:'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – Successful and error traces in Jaeger dashboard](img/B21843_09_4.png)'
  id: totrans-443
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – Successful and error traces in Jaeger dashboard
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to refer to this chapter repository to get the working code version
    and replicate the same behavior on your local machine.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: By examining both the logs in the application and the trace visualization in
    Jaeger, you can validate that OpenTelemetry is successfully capturing traces,
    correlating logs with tracing data, and providing a full view of the request’s
    journey through your distributed system. This setup not only helps troubleshoot
    issues but also provides insights into optimizing performance across services
    with the goal of monitoring distributed services.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: Let us take a look at how to create custom spans with OpenTelemetry.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: Creating custom spans
  id: totrans-448
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While OpenTelemetry automatically instruments HTTP requests, you can also create
    custom spans to monitor specific operations. Here’s an example in which a span
    is manually created for a user registration process:'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-450
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: In this example, a custom span named “ `UserService.registerUser` " is created,
    and a username attribute is added. The span is started with `.startSpan()` and
    ended with `.end()` .
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have mastered the usage of OpenTelemetry as well, let us focus
    on some of the best practices for observability that you should be aware of.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: Best practices for end-to-end observability
  id: totrans-453
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Observability is an ongoing process that involves logs, metrics, and traces
    working together to provide full visibility into your REST API’s performance and
    behavior.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: 'Preparing your environment to be completely covered by observability and monitoring
    is not an easy task, and you must consider the following topics:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: Combining logs, metrics, and traces
  id: totrans-456
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Logs, metrics, and traces complement each other to give you a holistic view
    of your application:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: '**Logs** : Provide detailed information about specific events.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics** : Offer a quantitative summary of performance over time.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Traces** : Show the lifecycle of individual requests across services.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By using these tools together, you can quickly diagnose issues and optimize
    performance. For example, you might use tracing to find a slow request, logs to
    determine why it’s slow, and metrics to track how often the issue occurs.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: Alarms and notifications
  id: totrans-462
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With observability tools in place, you can set up alarms to notify your team
    when something goes wrong. For example, you can configure Prometheus to send alerts
    when the error rate exceeds a certain threshold or when response times spike.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
- en: In the context of RESTful microservices, AWS CloudWatch offers comprehensive
    monitoring capabilities that transform raw operational data into readable, near-real-time
    metrics stored for up to 15 months.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: For example, when implementing API Gateway as the front door to your microservices
    architecture, CloudWatch can monitor key performance indicators such as IntegrationLatency
    to measure backend responsiveness, overall latency to assess API call efficiency,
    and cache performance metrics to optimize resource utilization. API Gateway logging,
    which feeds into CloudWatch Logs, provides valuable visibility into consumer access
    behaviors, allowing teams to understand common customer locations, analyze request
    patterns that might impact database partitioning, identify abnormal behavior that
    could indicate security concerns, and optimize configurations by tracking errors,
    latency, and cache performance. This monitoring framework creates a secure, easily
    maintainable environment that scales with growing business needs while providing
    actionable intelligence to continuously improve service delivery.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
- en: Continuous improvement
  id: totrans-466
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Observability is an ongoing process. As your system evolves, regularly review
    and refine your logging, tracing, and metrics collection to ensure you are capturing
    the most useful data. Use tools like Prometheus, Grafana, Zipkin, and OpenTelemetry
    to continually monitor and improve your system’s performance.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-468
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the core components and best practices for achieving
    effective monitoring and observability in RESTful services. Beginning with logging,
    we discussed the importance of structured logging for API troubleshooting, log
    levels to indicate severity, and correlation IDs to link requests across services.
    By implementing these logging practices centrally, such as with a filter in Spring
    Boot, we ensured consistent and secure logging across the application.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
- en: We then introduced distributed tracing, explaining how `traceId` , `spanId`
    , and `parentSpanId` create a parent-child relationship among services, allowing
    developers to track the journey of requests through a system.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: Micrometer Tracing was covered as a key tool in Spring Boot 3.x for enabling
    and managing distributed tracing. It automatically instruments Spring Boot applications,
    capturing trace and span information for each request.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
- en: Micrometer Tracing integrates with multiple exporters, including Prometheus,
    Zipkin, and Jaeger, to send trace data to external observability platforms. With
    its configurable sampling and tagging, Micrometer Tracing provides granular visibility
    into each service, enabling efficient troubleshooting and performance optimization.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: Building on tracing, we explored OpenTelemetry as a vendor-neutral observability
    framework that collects and correlates traces, metrics, and logs in distributed
    systems.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: OpenTelemetry integrates smoothly with Spring Boot to provide out-of-the-box
    tracing for HTTP and Spring MVC requests, with added flexibility to create custom
    spans. We covered how to configure OpenTelemetry, validate its functionality through
    logging and visualization in tools like Zipkin, and observe end-to-end traces
    across services.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
- en: By combining logging, tracing, and OpenTelemetry with tools like Zipkin or Jaeger
    for visualization, we can gain a comprehensive view of each request across services.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: This chapter provided foundational strategies for implementing robust observability,
    allowing for effective monitoring, faster troubleshooting, and insights to optimize
    the performance of RESTful APIs in complex, distributed environments.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn about scaling and performance optimization
    techniques, to be able to make the best out of your applications.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
