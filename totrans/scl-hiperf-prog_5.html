<html><head></head><body><div class="chapter" title="Chapter&#xA0;5.&#xA0;Lazy Collections and Event Sourcing"><div class="titlepage"><div><div><h1 class="title"><a id="ch05"/>Chapter 5. Lazy Collections and Event Sourcing</h1></div></div></div><p>In the last chapter, we explored a number of Scala collections that readily perform evaluations eagerly. The Scala standard library provides two collections that operate lazily: views and streams. To motivate an exploration of these collections, we will tackle another performance dilemma at MVT revolving around performance reports that are generated for clients. In this chapter, we will cover the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Views</li><li class="listitem" style="list-style-type: disc">Stream processing with two real-world applications</li><li class="listitem" style="list-style-type: disc">Event sourcing</li><li class="listitem" style="list-style-type: disc">Markov chain generation</li></ul></div><div class="section" title="Improving the client report generation speed"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec29"/>Improving the client report generation speed</h1></div></div></div><p>Wanting to learn more about the customers of MVT, you decide to attend the weekly client status meeting. As you look around, you see that you are the only engineer here and everyone else is from the sales team. Johnny, the head of the MVT client management team, runs through a list of newly-signed on clients. Each time he reads off a name, a loud bell is rung. It seems like a strange custom to you, but the sales team is excitedly cheering each time the bell rings.</p><p>After the new client listing ends and the ringing in your ears stops, one of the sales team members asks Johnny, "When will the performance reports be generated faster? Clients are calling me everyday complaining about the inability to see their positions and profits and losses during the trading day. It's embarrassing that we do not have this kind of transparency, and we will lose business because of this." You realize that the report in question is a PDF that can be downloaded via the private web portal that is exposed by MVT to clients. Unless a client is sophisticated enough to set up his or her own reporting using MVT's performance API, then the client is dependent upon the portal to inspect recent trading performance.</p><p>Realizing that this is an opportunity to better understand the issue, you ask, "Hi, I'm from the engineering team. I thought I would sit in today to learn more about our clients. Can you share more about the reporting performance problem? I'd like to help address the concern." Through conversation with the sales team, you learn that the PDF report is a first step towards a real-time streaming web app. The PDF report allows MVT to quickly give trading performance insight to clients. Each time the client clicks <span class="strong"><strong>View Performance</strong></span>, a report is generated that summarizes the performance trend by displaying whether or not the client has realized a profit or a loss in the last hour, day, and seven days. Particularly when the market is volatile, you learn that clients are more likely to generate reports. The sales team thinks this exacerbates the issue because reports generate even slower when everyone is trying to see recent trading performance. In some of the worst cases, the performance report takes about a dozen minutes to generate, which is totally unacceptable to clients that expect near real-time results.</p><div class="section" title="Diving into the reporting code"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec38"/>Diving into the reporting code</h2></div></div></div><p>Eager to dig into the problem, you find the repository that is responsible for working with reporting data. You explore the domain model to understand the concerns represented in this scope:</p><pre class="programlisting">case class Ticker(value: String) extends AnyVal &#13;
case class Price(value: BigDecimal) extends AnyVal &#13;
case class OrderId(value: Long) extends AnyVal &#13;
case class CreatedTimestamp(value: Instant) extends AnyVal &#13;
case class ClientId(value: Long) extends AnyVal &#13;
 &#13;
sealed trait Order { &#13;
  def created: CreatedTimestamp &#13;
  def id: OrderId &#13;
  def ticker: Ticker &#13;
  def price: Price &#13;
  def clientId: ClientId &#13;
} &#13;
case class BuyOrder(created: CreatedTimestamp, id: OrderId, ticker: Ticker, price:   Price, clientId: ClientId) extends Order &#13;
 &#13;
case class SellOrder(created: CreatedTimestamp, id: OrderId, ticker: Ticker, price: Price,clientId: ClientId) extends Order &#13;
 &#13;
case class Execution(created: CreatedTimestamp, id: OrderId, price: Price) &#13;
</pre><p>In the reporting context, linking orders to executions is important to build the performance trend report because this association allows MVT to identify the profit or loss realized from the trade. <code class="literal">ClientId</code> is a concept that you have not worked with before when working on the order book or performing data analysis. The client ID is used to identify an MVT client's account. As trades are executed on behalf of clients, the client ID allows us to link an executed order to a client account.</p><p>Scanning the code base, you spot the representation of a performance trend report before it is converted into PDF format:</p><pre class="programlisting">sealed trait LastHourPnL &#13;
case object LastHourPositive extends LastHourPnL &#13;
case object LastHourNegative extends LastHourPnL &#13;
 &#13;
sealed trait LastDayPnL &#13;
case object LastDayPositive extends LastDayPnL &#13;
case object LastDayNegative extends LastDayPnL &#13;
 &#13;
sealed trait LastSevenDayPnL &#13;
case object LastSevenDayPositive extends LastSevenDayPnL &#13;
case object LastSevenDayNegative extends LastSevenDayPnL &#13;
 &#13;
case class TradingPerformanceTrend( &#13;
  ticker: Ticker, &#13;
  lastHour: LastHourPnL, &#13;
  lastDay: LastDayPnL, &#13;
  lastSevenDay: LastSevenDayPnL) &#13;
</pre><p>The <span class="strong"><strong>profit and loss</strong></span> (<span class="strong"><strong>PnL</strong></span>) trend is represented by distinct ADTs for each supported time period: the last hour, last day, and last seven days. For each stock ticker, these three time periods are included in<code class="literal">TradingPerformanceTrend</code>. Across multiple tickers, you infer a client can identify whether or not MVT is generating a profit or a loss over time. Inspecting the signature of the <code class="literal">trend</code> method which is responsible for computing <code class="literal">TradingPerformanceTrend</code>, you confirm your thinking:</p><pre class="programlisting">def trend( &#13;
  now: () =&gt; Instant, &#13;
  findOrders: (Interval, Ticker) =&gt; List[Order], &#13;
  findExecutions: (Interval, Ticker) =&gt; List[Execution], &#13;
  request: GenerateTradingPerformanceTrend): &#13;
List[TradingPerformanceTrend] &#13;
 &#13;
case class GenerateTradingPerformanceTrend( &#13;
  tickers: List[Ticker], clientId: ClientId) &#13;
</pre><p>Computing the performance trend requires a way to determine the current time in order to determine how far to look back to compute each time period's trend. The <code class="literal">findOrders</code> and <code class="literal">findExecutions</code> arguments are functions that query the reporting data store for orders and executions that were created within a time interval for a particular ticker. The final argument contains the client's ID and the tickers to report on. Each period's trend is computed by a generalized inner-method named <code class="literal">periodPnL</code>, which looks like the following:</p><pre class="programlisting">  def periodPnL( &#13;
    duration: Duration): Map[Ticker, PeriodPnL] = { &#13;
    val currentTime = now() &#13;
    val interval = new Interval(currentTime.minus(duration), currentTime) &#13;
    (for { &#13;
      ticker &lt;- request.tickers &#13;
      orders = findOrders(interval, ticker) &#13;
      executions = findExecutions(interval, ticker) &#13;
      idToExecPrice = executions.groupBy(_.id).mapValues(es =&gt; &#13;
        Price.average(es.map(_.price))) &#13;
      signedExecutionPrices = for { &#13;
        o &lt;- orders &#13;
        if o.clientId == request.clientId &#13;
        price &lt;- idToExecPrice.get(o.id).map(p =&gt; o match { &#13;
          case _: BuyOrder =&gt; Price(p.value * -1) &#13;
          case _: SellOrder =&gt; p &#13;
        }).toList &#13;
      } yield price &#13;
      trend = signedExecutionPrices.foldLeft(PnL.zero) { &#13;
        case (pnl, p) =&gt; PnL(pnl.value + p.value) &#13;
      } match { &#13;
        case p if p.value &gt;= PnL.zero.value =&gt; PeriodPositive &#13;
        case _ =&gt; PeriodNegative &#13;
      } &#13;
    } yield ticker -&gt; trend).toMap &#13;
  } &#13;
</pre><p>The <code class="literal">periodPnL</code> method is an involved method that contains several logical steps. For each client-provided ticker, the associated orders and executions for the provided time period are retrieved. In order to correlate orders with executions, a map of <code class="literal">OrderId</code> to <code class="literal">Execution</code> is built by using <code class="literal">groupBy</code>. To simplify later calculations, the average execution price of each executed order is computed to reduce multiple executions for a single order to a single value.</p><p>With the <code class="literal">idToExecPrice</code> lookup table built, the next logical step is to filter out orders for other clients. Once only the client's orders remain, <code class="literal">idToExecution</code> is used to identify the orders that executed. The final two steps compute the performance trend by tabulating the client's absolute return (that is, profit and loss). The steps involve two additions to the domain model, as follows:</p><pre class="programlisting">case class PnL(value: BigDecimal) extends AnyVal &#13;
object PnL { &#13;
  val zero: PnL = PnL(BigDecimal(0)) &#13;
} &#13;
 &#13;
sealed trait PeriodPnL &#13;
case object PeriodPositive extends PeriodPnL &#13;
case object PeriodNegative extends PeriodPnL &#13;
</pre><p>The <code class="literal">PnL</code> value is a value class that is used to represent the client's dollar return. <code class="literal">PeriodPnL</code> is analogous to the previously introduced ADT that can be applied to any time period of data. This allows <code class="literal">PeriodPnL</code> to be reused for the last hour, last day, and last seven days trend computations.</p><p>When the trade represents a buy, the execution price is negated because the transaction represents cash being exchanged for stock. When the trade represents a sell, the execution price remains positive because the transaction represents exchanging stock for cash. After computing the performance trend for each ticker, the <code class="literal">List</code> of the <code class="literal">Ticker</code> and <code class="literal">PeriodPnL</code> tuples is converted to a <code class="literal">Map</code>.</p><p>Digesting this implementation, you can start to imagine why generating this PDF is time-consuming. There is no sign of caching results, which means that the trend report is recomputed each time a client makes a request. As the number of clients requesting reports increases, there is an increased wait time while reports are computed. Re-architecting the reporting infrastructure to cache reports is too large a near-term change. Instead, you try to identify incremental changes that can improve report generation performance.</p></div><div class="section" title="Using views to speed up report generation time"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec39"/>Using views to speed up report generation time</h2></div></div></div><p>When working on the order book, we learned that <code class="literal">List</code> eagerly evaluates results. This property means that, in <code class="literal">periodPnL</code>, the de-sugared for-comprehension <code class="literal">filter</code> and <code class="literal">map</code> operations performed on <code class="literal">orders</code> produce new lists. That is, each transformation produces a new collection. For customers with large order counts, it can be costly in terms of CPU time to iterate over an order set three times, in addition to incurring garbage collection costs due to repeated <code class="literal">List</code> creation. To ameliorate this concern, Scala provides a way to defer transforming elements until an element is needed by a downstream computation.</p><p>Conceptually, this is done by adding a view on top of the eagerly evaluated collection that allows transformations to be defined with deferred evaluation semantics. A lazily evaluated view of a collection can be constructed from any Scala collection by invoking <code class="literal">view</code>. For example, this snippet creates a view from a <code class="literal">List</code> of integers:</p><pre class="programlisting">val listView: SeqView[Int, List[Int]] = List(1, 2, 3).view &#13;
</pre><p>From this snippet, we learn that Scala represents a view into a collection with a different <code class="literal">SeqView</code> type that is parameterized by two types: the collection element, and the collection type. Seeing a view in use makes it easier to understand its runtime differences with an eagerly evaluated collection. Consider the following snippet performing the same operations on a <code class="literal">List</code> and a view over a <code class="literal">List</code>:</p><pre class="programlisting">println("List evaluation:") &#13;
val evens = List(0, 1, 2, 3, 4, 5).map(i =&gt; { &#13;
  println(s"Adding one to $i") &#13;
  i + 1 &#13;
}).filter(i =&gt; { &#13;
  println(s"Filtering $i") &#13;
  i % 2 == 0 &#13;
}) &#13;
 &#13;
println("--- Printing first two even elements ---") &#13;
println(evens.take(2)) &#13;
 &#13;
println("View evaluation:") &#13;
val evensView = List(0, 1, 2, 3, 4, 5).view.map(i =&gt; { &#13;
  println(s"Adding one to $i") &#13;
  i + 1 &#13;
}).filter(i =&gt; { &#13;
  println(s"Filtering $i") &#13;
  i % 2 == 0 &#13;
}) &#13;
 &#13;
println("--- Printing first two even elements ---") &#13;
println(evensView.take(2).toList) &#13;
</pre><p>This snippet performs simple arithmetic and then filters to find the even elements. For the sake of deepening our understanding, the snippet breaks the functional paradigm by adding the <code class="literal">println</code> side effect. The output of the list evaluation is as expected:</p><pre class="programlisting">List evaluation: &#13;
Adding one to 0 &#13;
Adding one to 1 &#13;
Adding one to 2 &#13;
Adding one to 3 &#13;
Adding one to 4 &#13;
Adding one to 5 &#13;
Filtering 1 &#13;
Filtering 2 &#13;
Filtering 3 &#13;
Filtering 4 &#13;
Filtering 5 &#13;
Filtering 6 &#13;
--- Printing first two even elements --- &#13;
List(2, 4) &#13;
</pre><p>With eager evaluation, each transformation is applied to each element before moving to the next transformation. Now, consider the following output from view evaluation:</p><pre class="programlisting">View evaluation: &#13;
--- Printing first two even elements --- &#13;
Adding one to 0 &#13;
Filtering 1 &#13;
Adding one to 1 &#13;
Filtering 2 &#13;
Adding one to 2 &#13;
Filtering 3 &#13;
Adding one to 3 &#13;
Filtering 4 &#13;
List(2, 4) &#13;
</pre><p>As we discussed earlier, with lazy evaluation no transformations are applied until an element is needed. In this example, this means that the addition and filtering do not occur until the invocation of <code class="literal">toList</code>. The absence of output after "view evaluation" is evidence that zero transformations occurred. Curiously, we also see that only the first four of six elements are evaluated. When a view applies transformations, it applies all transformations to each element rather than applying each transformation to all elements. By applying all transformations in one step, the view is able to return the first two elements without evaluating the entire collection. Here, we see the potential performance gains from view usage due to lazy evaluation. Before applying the concept of views to the performance trend report, let's take a deeper look at view implementation.</p><div class="section" title="Constructing a custom view"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec25"/>Constructing a custom view</h3></div></div></div><p>Views are able to defer evaluation by returning a data structure that composes the previous transformation state with the next transformation. The Scala implementation of views is admittedly complicated to digest because it provides a large number of capabilities while retaining support for all Scala collections. To build an intuition for how views are implemented, let's construct our own lazily evaluated view that works only for <code class="literal">List</code> and only supports <code class="literal">map</code> operations. To begin, we define the operations that are supported by our implementation of a <code class="literal">PseudoView</code> view:</p><pre class="programlisting">sealed trait PseudoView[A] { &#13;
  def map[B](f: A =&gt; B): PseudoView[B] &#13;
  def toList: List[A] &#13;
} &#13;
</pre><p>The <code class="literal">PseudoView</code> is defined as a trait that supports lazy application of a transformation from <code class="literal">A</code> to <code class="literal">B</code> and also supports evaluating all transformations to return a <code class="literal">List</code>. Next, we define two view types of view to support the initial case when zero transformations have been applied and to support applying a transformation to a previously transformed view. The signatures are shown in the following snippet:</p><pre class="programlisting">final class InitialView[A](xs: List[A]) extends PseudoView[A] &#13;
final class ComposedView[A, B](xs: List[A], fa: A =&gt; B) extends PseudoView[B] &#13;
</pre><p>In both scenarios, the original <code class="literal">List</code> must be carried through to support eventually applying the transformations. In the <code class="literal">InitialView</code> base case, there are zero transformations, which is why there is no additional state. <code class="literal">ComposedView</code> supports chaining computations by carrying the state of the previous <code class="literal">fa</code> transformation.</p><p>Implementing <code class="literal">InitialView</code> is a straightforward delegation to <code class="literal">ComposedView</code>:</p><pre class="programlisting">final class InitialView[A](xs: List[A]) extends PseudoView[A] { &#13;
  def map[B](f: A =&gt; B): PseudoView[B] = new ComposedView[A, B](xs, f) &#13;
  def toList: List[A] = xs &#13;
} &#13;
</pre><p>The <code class="literal">List</code> implementation shows how transformations are chained together using function composition:</p><pre class="programlisting">final class ComposedView[A, B](xs: List[A], fa: A =&gt; B) extends PseudoView[B] { &#13;
  def map[C](f: B =&gt; C): PseudoView[C] = new ComposedView(xs, f.compose(fa)) &#13;
  def toList: List[B] = xs.map(fa) &#13;
} &#13;
</pre><p>Let's construct a <code class="literal">PseudoView</code> companion object that provides view construction, as follows:</p><pre class="programlisting">object PseudoView {  &#13;
  def view[A, B](xs: List[A]): PseudoView[A] = new InitialView(xs) &#13;
} &#13;
</pre><p>We can now exercise <code class="literal">PseudoView</code> with a simple program to demonstrate that it defers evaluation:</p><pre class="programlisting">println("PseudoView evaluation:") &#13;
val listPseudoView = PseudoView.view(List(0, 1, 2)).map(i =&gt; { &#13;
  println(s"Adding one to $i") &#13;
  i + 1 &#13;
}).map(i =&gt; { &#13;
  println(s"Multiplying $i") &#13;
  i * 2 &#13;
}) &#13;
 &#13;
println("--- Converting PseudoView to List ---") &#13;
println(listPseudoView.toList) &#13;
</pre><p>Running this program, we see output equivalent to usage of Scala's view implementation:</p><pre class="programlisting">PseudoView evaluation: &#13;
--- Converting PseudoView to List --- &#13;
Adding one to 0 &#13;
Multiplying 1 &#13;
Adding one to 1 &#13;
Multiplying 2 &#13;
Adding one to 2 &#13;
Multiplying 3 &#13;
List(2, 4, 6) &#13;
</pre><p>
<code class="literal">PseudoView</code> helps build an intuition about how Scala implements views. From here, you can begin considering how to support other operations. For example, how can <code class="literal">filter</code> be implemented? The <code class="literal">filter</code> is interesting to consider because it constrains the original collection. As defined, <code class="literal">PseudoView</code> is ill-equipped to support the <code class="literal">filter</code> operations, which is one illustration of the complexity that is handled by Scala views. Scala views tackles this challenge by defining a trait named <code class="literal">Transformed</code>. The <code class="literal">Transformed</code> trait is the base trait for all view operations. A partial definition is shown, as follows:</p><pre class="programlisting">trait Transformed[+B] extends GenTraversableView[B, Coll] { &#13;
  def foreach[U](f: B =&gt; U): Unit &#13;
  lazy val underlying = self.underlying &#13;
} &#13;
</pre><p>The <code class="literal">underlying</code> lazy value is how the originally wrapped collection is accessed. This is analogous to how <code class="literal">PseudoView</code> passed the <code class="literal">List</code> state into <code class="literal">ComposedView</code>. <code class="literal">Transformed</code> defines a side-effecting <code class="literal">foreach</code> operation to support collection operations in a lazy manner. Using <code class="literal">foreach</code> allows implementations of this trait to modify the underlying collection. This is how <code class="literal">filter</code> is implemented:</p><pre class="programlisting">trait Filtered extends Transformed[A] { &#13;
  protected[this] val pred: A =&gt; Boolean &#13;
  def foreach[U](f: A =&gt; U) { &#13;
    for (x &lt;- self) &#13;
      if (pred(x)) f(x) &#13;
  } &#13;
} &#13;
</pre><p>
<code class="literal">Transformed</code> is used within the view API to maintain the state of necessary operations, while the external API supports interacting with <code class="literal">SeqView</code>. Following another pattern that is commonly found in Scala collections, <code class="literal">SeqView</code> inherits a number of operations by mixing in other traits. <code class="literal">SeqView</code> indirectly mixes in <code class="literal">TraversableViewLike</code>, which provides access to the <code class="literal">Transformed</code> operations.</p></div><div class="section" title="Applying views to improve report generation performance"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec26"/>Applying views to improve report generation performance</h3></div></div></div><p>With our newly-developed intuition for views, we may view (no pun intended!) the construction of performance trend reports differently. Scala's implementation of views makes it trivial to switch from eagerly evaluated collections to a lazily evaluated version. If you recall, once the order ID to the average execution price lookup table is constructed, a series of transformations are applied to the orders that are retrieved for the duration and ticker. By converting <code class="literal">orders</code> to a view, there is an opportunity to avoid unnecessary transformations and improve the speed of the performance trend report.</p><p>While it is trivial to convert to a view, it is less trivial to identify under which conditions lazy evaluation out-performs eager evaluation. As a good performance engineer, you want to benchmark your proposed change, but you do not have access to historical order and execution data to build a benchmark. Instead, you write a microbenchmark that simulates the problem that you are modeling. The question that you are trying to answer is, "For what size collection and what number of operations does it make sense to use a view over a <code class="literal">List</code>?" There is a cost to constructing a view because it involves retaining information about the deferred transformation, which implies it will not always be the most performant solution. You come up with the following scenarios to help answer your question:</p><pre class="programlisting">  @Benchmark &#13;
  def singleTransformList(state: ViewState): List[Int] = &#13;
    state.numbers.map(_ * 2) &#13;
 &#13;
  @Benchmark &#13;
  def singleTransformView(state: ViewState): Vector[Int] = &#13;
    state.numbers.view.map(_ * 2).toVector &#13;
 &#13;
  @Benchmark &#13;
  def twoTransformsList(state: ViewState): List[Int] = &#13;
    state.numbers.map(_ * 2).filter(_ % 3 == 0) &#13;
 &#13;
  @Benchmark &#13;
  def twoTransformsView(state: ViewState): Vector[Int] = &#13;
    state.numbers.view.map(_ * 2).filter(_ % 3 == 0).toVector &#13;
 &#13;
  @Benchmark &#13;
  def threeTransformsList(state: ViewState): List[Int] = &#13;
    state.numbers.map(_ * 2).map(_ + 7).filter(_ % 3 == 0) &#13;
 &#13;
  @Benchmark &#13;
  def threeTransformsView(state: ViewState): Vector[Int] = &#13;
    state.numbers.view.map(_ * 2).map(_ + 7).filter(_ % 3 == 0).toVector &#13;
</pre><p>For each collection type, a <code class="literal">List</code>, and a view over a <code class="literal">Vector</code>, you define three tests that exercise an increasing number of transformations. <code class="literal">Vector</code> is used instead of <code class="literal">List</code> because <code class="literal">toList</code> on a view is not specialized for <code class="literal">List</code>. As we have previously seen, <code class="literal">List</code> operations are written to take advantage of constant time and prepend performance. The <code class="literal">toList</code> performs linear time append operations, which gives the false impression that views deliver lower performance. Switching to <code class="literal">Vector</code> provides effectively constant time append operations. The state for this benchmark looks like the following:</p><pre class="programlisting">@State(Scope.Benchmark) &#13;
class ViewState { &#13;
 &#13;
  @Param(Array("10", "1000", "1000000")) &#13;
  var collectionSize: Int = 0 &#13;
 &#13;
  var numbers: List[Int] = Nil &#13;
 &#13;
  @Setup &#13;
  def setup(): Unit = { &#13;
    numbers = (for (i &lt;- 1 to collectionSize) yield i).toList &#13;
  } &#13;
} &#13;
</pre><p>
<code class="literal">ViewState</code> sweeps different collection sizes to help identify how sensitive view performance is to collection size. The benchmark is invoked via the following:</p><pre class="programlisting">
<span class="strong"><strong>sbt 'project chapter5' 'jmh:run ViewBenchmarks -foe true'</strong></span>
</pre><p>This invocation produces the following results:</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/><col/></colgroup><tbody><tr><td>
<p>
<span class="strong"><strong>Benchmark</strong></span>
</p>
</td><td>
<p>
<span class="strong"><strong>Collection size</strong></span>
</p>
</td><td>
<p>
<span class="strong"><strong>Throughput (ops per second)</strong></span>
</p>
</td><td>
<p>
<span class="strong"><strong>Error as percentage of throughput</strong></span>
</p>
</td></tr><tr><td>
<p>
<code class="literal">singleTransformList</code>
</p>
</td><td>
<p>10</p>
</td><td>
<p>15,171,067.61</p>
</td><td>
<p>± 2.46</p>
</td></tr><tr><td>
<p>
<code class="literal">singleTransformView</code>
</p>
</td><td>
<p>10</p>
</td><td>
<p>3,175,242.06</p>
</td><td>
<p>± 1.37</p>
</td></tr><tr><td>
<p>
<code class="literal">singleTransformList</code>
</p>
</td><td>
<p>1,000</p>
</td><td>
<p>133,818.44</p>
</td><td>
<p>± 1.58</p>
</td></tr><tr><td>
<p>
<code class="literal">singleTransformView</code>
</p>
</td><td>
<p>1,000</p>
</td><td>
<p>52,688.80</p>
</td><td>
<p>± 1.11</p>
</td></tr><tr><td>
<p>
<code class="literal">singleTransformList</code>
</p>
</td><td>
<p>1,000,000</p>
</td><td>
<p>30.40</p>
</td><td>
<p>± 2.72</p>
</td></tr><tr><td>
<p>
<code class="literal">singleTransformView</code>
</p>
</td><td>
<p>1,000,000</p>
</td><td>
<p>86.54</p>
</td><td>
<p>± 1.17</p>
</td></tr><tr><td>
<p>
<code class="literal">twoTransformsList</code>
</p>
</td><td>
<p>10</p>
</td><td>
<p>5,008,830.88</p>
</td><td>
<p>± 1.12</p>
</td></tr><tr><td>
<p>
<code class="literal">twoTransformsView</code>
</p>
</td><td>
<p>10</p>
</td><td>
<p>4,564,726.04</p>
</td><td>
<p>± 1.05</p>
</td></tr><tr><td>
<p>
<code class="literal">twoTransformsList</code>
</p>
</td><td>
<p>1,000</p>
</td><td>
<p>44,252.83</p>
</td><td>
<p>± 1.08</p>
</td></tr><tr><td>
<p>
<code class="literal">twoTransformsView</code>
</p>
</td><td>
<p>1,000</p>
</td><td>
<p>80,674.76</p>
</td><td>
<p>± 1.12</p>
</td></tr><tr><td>
<p>
<code class="literal">twoTransformsList</code>
</p>
</td><td>
<p>1,000,000</p>
</td><td>
<p>22.85</p>
</td><td>
<p>± 3.78</p>
</td></tr><tr><td>
<p>
<code class="literal">twoTransformsView</code>
</p>
</td><td>
<p>1,000,000</p>
</td><td>
<p>77.59</p>
</td><td>
<p>± 1.46</p>
</td></tr><tr><td>
<p>
<code class="literal">threeTransformsList</code>
</p>
</td><td>
<p>10</p>
</td><td>
<p>3,360,399.58</p>
</td><td>
<p>± 1.11</p>
</td></tr><tr><td>
<p>
<code class="literal">threeTransformsView</code>
</p>
</td><td>
<p>10</p>
</td><td>
<p>3,438,977.91</p>
</td><td>
<p>± 1.27</p>
</td></tr><tr><td>
<p>
<code class="literal">threeTransformsList</code>
</p>
</td><td>
<p>1,000</p>
</td><td>
<p>36,226.87</p>
</td><td>
<p>± 1.65</p>
</td></tr><tr><td>
<p>
<code class="literal">threeTransformsView</code>
</p>
</td><td>
<p>1,000</p>
</td><td>
<p>58,981.24</p>
</td><td>
<p>± 1.80</p>
</td></tr><tr><td>
<p>
<code class="literal">threeTransformsList</code>
</p>
</td><td>
<p>1,000,000</p>
</td><td>
<p>10.33</p>
</td><td>
<p>± 3.58</p>
</td></tr><tr><td>
<p>
<code class="literal">threeTransformsView</code>
</p>
</td><td>
<p>1,000,000</p>
</td><td>
<p>49.01</p>
</td><td>
<p>± 1.36</p>
</td></tr></tbody></table></div><p>The results give us an interesting insight into the cases where using a view yields better performance. For a small collection, such as 10 elements in our benchmark, a <code class="literal">List</code> performs better, regardless of the amount of operations, although this gap closes at 1,000,000 elements. When transforming a large collection, 1,000,000 elements in our benchmark, a view is more efficient with an increasing differential as the number of transformations increases. For example, with 1,000,000 elements and two transformations, views deliver approximately triple the throughput of <code class="literal">List</code>. In the case of a medium size collection, such as 1,000 elements in this example, this is not as clear-cut. When performing a single transformation, an eager <code class="literal">List</code> performs better, while a view delivers better throughput when applying more than one transformation.</p><p>As the volume of your data and the transformation count increase, it becomes more likely that a view offers better performance. Here, you see the tangible benefit of avoiding intermediate collections. A second axis of performance to consider is the nature of the transformation. Transformations that benefit from early termination (for example, <code class="literal">find</code>), benefit strongly from lazy evaluation. This benchmark illustrates that it is important to understand the size of your data and the transformations that you intend to perform.</p></div></div><div class="section" title="View caveats"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec40"/>View caveats</h2></div></div></div><p>Views offer a simple way to improve performance with minimally invasive changes to your system. The ease of use is part of the allure of views, which may tempt you to use them more frequently than you otherwise would. As our benchmarking in the previous section shows, there is a nontrivial overhead to using views, which means defaulting to views is a suboptimal choice. Looking past the pure performance perspective, there are other reasons to tread carefully when using views.</p><div class="section" title="SeqView extends Seq"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec27"/>SeqView extends Seq</h3></div></div></div><p>As views mirror the collection API, it can be a challenge to identify when transformations are being applied lazily. For this reason, we recommend setting well-defined boundaries for view usage. When working on client reporting, we limited view usage to a single inner-function and used a <code class="literal">List</code> eager collection type as the return type. Minimizing the area of a system performing a lazy evaluation can reduce cognitive load when building a runtime execution mental model.</p><p>On a related note, we feel that it is important to be cautious about how a view is transformed into an eagerly evaluated collection type. We showed conversion by invoking <code class="literal">toList</code>, which makes the intent explicit. <code class="literal">SeqView</code> also provides a <code class="literal">force</code> method to force evaluation. As a general rule, we avoid using <code class="literal">force</code> because it typically returns <code class="literal">scala.collection.immutable.Seq</code>. <code class="literal">SeqView</code> retains the collection type as its second generic parameter, which allows <code class="literal">force</code> to return the original collection type when there is enough evidence. However, certain operations, such as <code class="literal">map</code>, cause the view to lose evidence of the original collection type. When this happens, <code class="literal">force</code> returns the more general <code class="literal">Seq</code> collection type. <code class="literal">Seq</code> is a trait that is a super-type to all sequences in the collection library, including views and another lazy data structure that we will discuss later, named <code class="literal">scala.collection.immutable.Stream</code>. This inheritance scheme allows the following three statements to compile:</p><pre class="programlisting">val list: Seq[Int] = List(1, 2, 3) &#13;
val view: Seq[Int] = list.view &#13;
val stream: Seq[Int] = list.toStream &#13;
</pre><p>We believe this is undesirable because the <code class="literal">Seq</code> data type hides critical information about the underlying implementation. It represents both lazy and eagerly evaluated collections with the same type. Consider the following snippet example to understand why this is undesirable:</p><pre class="programlisting">def shouldGenerateOrder(xs: Seq[Execution]): Boolean =  &#13;
  xs.size &gt;= 3 &#13;
</pre><p>In this manufactured example, imagine that <code class="literal">shouldGenerateOrder</code> is invoked with a <code class="literal">Vector</code>, but then later the <code class="literal">Vector</code> is swapped out for <code class="literal">SeqView</code>. With <code class="literal">Vector</code>, identifying collection length is a constant time operation. With <code class="literal">SeqView</code>, you cannot reason with certainty about the runtime of the operation, except to say that it is definitely more expensive than <code class="literal">Vector.size</code>. <code class="literal">Seq</code> usage, and, therefore, the usage of <code class="literal">force</code>, should be avoided because it is difficult to reason about runtime behavior, and this can lead to unexpected side-effects.</p><p>In a typical software system, areas of responsibility are separated into discrete modules. Using the performance trend reporting example, you can imagine a separate module containing the translation from <code class="literal">List[TradingPerformanceTrend]</code> to a PDF report. You may be tempted to expose the view to other modules to extend the benefit of lazy transformations. If benchmarks justify making this type of change, then we encourage you to choose one of these options. Our preferred choice in this scenario is to use <code class="literal">Stream</code>, which is a lazily evaluated version of <code class="literal">List</code>. We explore <code class="literal">Stream</code> later in this chapter. Alternatively, if <code class="literal">Stream</code> cannot be used, be strict in your use of the <code class="literal">SeqView</code> datatype to clearly demarcate that the collection is lazily evaluated.</p></div><div class="section" title="Views are not memoizers"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec28"/>Views are not memoizers</h3></div></div></div><p>One additional consideration when using views is to be cognizant of when transformations are repeatedly applied. For example consider this manufactured example that focuses on a use case where a view is used as a base for multiple computations:</p><pre class="programlisting">&gt; val xs = List(1,2,3,4,5).view.map(x =&gt; {  println(s"multiply $x"); x * 2 }) &#13;
xs: scala.collection.SeqView[Int,Seq[_]] = SeqViewM(...) &#13;
&gt; val evens = xs.filter(_ % 2 == 0).toList &#13;
multiply 1 &#13;
multiply 2 &#13;
multiply 3 &#13;
multiply 4 &#13;
multiply 5 &#13;
evens: List[Int] = List(2, 4, 6, 8, 10) &#13;
 &#13;
&gt; val odds = xs.filter(_ % 2 != 0).toList &#13;
multiply 1 &#13;
multiply 2 &#13;
multiply 3 &#13;
multiply 4 &#13;
multiply 5 &#13;
odds: List[Int] = List() &#13;
</pre><p>In this example, <code class="literal">xs</code> is a view on a list of integers. A <code class="literal">map</code> transformation is lazily applied to multiply these integers by 2. The view is then used to create two <code class="literal">List</code> instances, one containing even elements, the other containing odd elements. We observe that the transformation is applied to the view twice, each time we turn the view into a list. This shows that the transformation is lazily applied, but the results of the computation are not cached. This is a characteristic of views to keep in mind, as expensive transformations applied several times can cause significant slowdowns. This is also the reason why side-effects should be avoided in transformations applied to views. If, for some reason, referential transparency is not upheld, the combination of side-effects and multiple evaluations due to view usage can lead to exceptionally difficult to maintain software.</p><p>This example is straightforward, and the misuse of views is easy to spot. However, even methods that are provided by the standard library can lead to undesirable results when used with views. Consider this snippet:</p><pre class="programlisting">&gt; val (evens, odds) = List(1,2,3,4,5).view.map(x =&gt; {  println(s"multiply $x"); x * 2 }).partition(_ % 2 == 0) &#13;
evens: scala.collection.SeqView[Int,Seq[_]] = SeqViewMF(...) &#13;
odds: scala.collection.SeqView[Int,Seq[_]] = SeqViewMF(...) &#13;
 &#13;
&gt; println(evens.toList, odds.toList) &#13;
multiply 1 &#13;
multiply 2 &#13;
multiply 3 &#13;
multiply 4 &#13;
multiply 5 &#13;
multiply 1 &#13;
multiply 2 &#13;
multiply 3 &#13;
multiply 4 &#13;
multiply 5 &#13;
(List(2, 4, 6, 8, 10),List()) &#13;
</pre><p>This example achieves the same results as the previous sample, but we rely on the built-in <code class="literal">partition</code> method to split the original list into two distinct collections each operating on the original view. Again, we see the <code class="literal">map</code> transformation applied twice to the original view. This is due to the underlying implementation of <code class="literal">partition</code> in <code class="literal">TraversableViewLike</code>. The main takeaway is that views and lazy evaluation can help yield better performance, but they should be used carefully. It is a good idea to experiment and try your algorithm in the REPL to confirm that you are using views correctly.</p><p>In our running example on reporting on trading performance trends, we saw an easy-to-miss example of lazy evaluation when operating on a <code class="literal">Map</code>. Recall that there was a lookup table built using the following code:</p><pre class="programlisting">executions.groupBy(_.id).mapValues(es =&gt;&#13;
Price.average(es.map(_.price)))</pre><p>The return type of <code class="literal">mapValues</code> is <code class="literal">Map[A, B]</code>, which does not suggest any difference in evaluation strategy. Let's run a simple example in the REPL:</p><pre class="programlisting">&gt; val m = Map("a" -&gt; 1, "b" -&gt; 2)&#13;
m: scala.collection.immutable.Map[String,Int] = Map(a -&gt; 1, b -&gt; 2)&#13;
&gt; val m_prime = m.mapValues{ v =&gt; println(s"Mapping $v"); v * 2}&#13;
Mapping 1&#13;
Mapping 2&#13;
m_prime: scala.collection.immutable.Map[String,Int] = Map(a -&gt; 2, b -&gt; 4)&#13;
&gt; m_prime.get("a")&#13;
Mapping 1&#13;
res0: Option[Int] = Some(2)&#13;
&gt; m_prime.get("a")&#13;
Mapping 1&#13;
res1: Option[Int] = Some(2)</pre><p>Notice how, each time we call <code class="literal">get</code> on <code class="literal">m_prime</code> to retrieve a value, we can observe the transformation being applied, even when using the same key. The <code class="literal">mapValues</code> is a lazily-evaluated transformation of each value in the map akin to a view operating on the keys of a map. The types that are involved do not provide any insight, and unless you inspect the implementation of <code class="literal">Map</code> or carefully read the documentation that is associated with <code class="literal">mapValues</code>, you will likely miss this important detail. Consider the caveats of views when working with <code class="literal">mapValues</code>.</p></div></div><div class="section" title="Zipping up report generation"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec41"/>Zipping up report generation</h2></div></div></div><p>While investigating the implementation of <code class="literal">TradingPerformanceTrend</code>, we took a deep dive into views and found how they can improve performance. We now return to the implementation of <code class="literal">trend</code> to complete the generation of the <code class="literal">List[radingPerformanceTrend]</code>. The following snippet shows <code class="literal">trend</code> with the implementation of <code class="literal">periodPnL</code> hidden because we thoroughly reviewed it:</p><pre class="programlisting">def trend( &#13;
  now: () =&gt; Instant, &#13;
  findOrders: (Duration, Ticker) =&gt; List[Order], &#13;
  findExecutions: (Duration, Ticker) =&gt; List[Execution], &#13;
    request: GenerateTradingPerformanceTrend): List[TradingPerformanceTrend] = { &#13;
    def periodPnL( &#13;
      start: Instant =&gt; Instant): Map[Ticker, PeriodPnL] = { ... } &#13;
    &#13;
    val tickerToLastHour = periodPnL(now =&gt; &#13;
      now.minus(Period.hours(1).getMillis)).mapValues { &#13;
      case PeriodPositive =&gt; LastHourPositive &#13;
      case PeriodNegative =&gt; LastHourNegative &#13;
    } &#13;
    val tickerToLastDay = periodPnL(now =&gt; &#13;
      now.minus(Period.days(1).getMillis)).mapValues { &#13;
      case PeriodPositive =&gt; LastDayPositive &#13;
      case PeriodNegative =&gt; LastDayNegative &#13;
    } &#13;
    val tickerToLastSevenDays = periodPnL(now =&gt; &#13;
      now.minus(Period.days(7).getMillis)).mapValues { &#13;
      case PeriodPositive =&gt; LastSevenDayPositive &#13;
      case PeriodNegative =&gt; LastSevenDayNegative &#13;
    } &#13;
    tickerToLastHour.zip(tickerToLastDay).zip(tickerToLastSevenDays).map({ &#13;
      case (((t, lastHour), (_, lastDay)), (_, lastSevenDays)) =&gt; &#13;
        TradingPerformanceTrend(t, lastHour, lastDay, lastSevenDays) &#13;
    }).toList &#13;
  } &#13;
</pre><p>This method focuses on marshaling the translation of PnL for a time period to the appropriate time period's performance trend. The final expression involving two invocations of <code class="literal">zip</code> makes the transformation from three maps with keys of <code class="literal">Ticker</code> and corresponding period PnL trend values to <code class="literal">List[TradingPerformanceTrend]</code> elegant. <code class="literal">zip</code> iterates over two collections to yield a tuple for each index of both collections. Here is a simple snippet to illustrate <code class="literal">zip</code> usage:</p><pre class="programlisting">println(List(1, 3, 5, 7).zip(List(2, 4, 6))) &#13;
</pre><p>This yields the following:</p><pre class="programlisting">List((1,2), (3,4), (5,6)) &#13;
</pre><p>The result is that corresponding indexes are "zipped" together. For example, at index one, the first list's value is three and the second list's value is four, yielding the tuple, <code class="literal">(3, 4)</code>. The first list has four elements while the second list only has three elements; this is silently omitted from the resulting collection. This behavior is well-documented, but it might be unexpected at first glance. In our reporting use case, we are certain that each key (that is, each <code class="literal">Ticker</code>), appears in all three maps. In this use case, we are certain that all three maps are of equal length.</p><p>However, there is a subtle bug in our usage of <code class="literal">zip</code>. The <code class="literal">zip</code> uses a collection's iterator to iterate over elements, which implies that usage of <code class="literal">zip</code> is sensitive to ordering. Each of the three maps is constructed by invoking <code class="literal">toMap</code>, which indirectly delegates to a <code class="literal">scala.collection.immutable.HashMap</code> implementation of <code class="literal">Map</code>. Similar to <code class="literal">Set</code>, Scala provides several handwritten implementations of <code class="literal">Map</code> (for example, <code class="literal">Map2</code>) for small collection sizes before constructing a <code class="literal">HashMap</code>. By now, you may realize the flaw, <code class="literal">HashMap</code> does not guarantee ordering.</p><p>To fix this bug and retain usage of <code class="literal">zip</code>, we can leverage our earlier discovery of <code class="literal">SortedMap</code>, the trait backed by <code class="literal">TreeMap</code> with sorted keys. Swapping out <code class="literal">Map</code> for <code class="literal">SortedMap</code> and making appropriate changes to define an <code class="literal">Ordering</code> for <code class="literal">Ticker</code>, we now have a bug-free, elegant solution to generating trading performance trend reports. With a judicious usage of views, we found a way to deliver iterative performance improvements with minimally invasive changes. This will give the sales team something to ring the bell about! This gives us additional time to consider other approaches to generating reports.</p></div></div></div>
<div class="section" title="Rethinking reporting architecture"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec30"/>Rethinking reporting architecture</h1></div></div></div><p>After deploying a new version of the web portal that generates the performance report containing your view changes, you begin wondering what else can be done to improve report generation performance. It strikes you that, for a particular time interval, the report is immutable. The computed PnL trend for a particular hour never changes once computed. Although the report is immutable, it is needlessly being recomputed each time a client requests the report. Given this line of thinking, you wonder how difficult it is to generate a new report each hour as new execution data becomes available. On-the-fly, order and execution events can be transformed as they are created into the inputs that are required for the client performance trend report. With a pregenerated report, the web portal performance issues should completely disappear because the responsibility of report generation no longer belongs to the web portal.</p><p>This new report generation strategy leads us to explore a new design paradigm, called event sourcing. Event sourcing describes an architectural approach to designing systems that relies on processing events over time instead of relying on a model of the current state to answer different questions. The reporting system that we worked on performs significant work to identify the subset of orders that executed because current state rather than events is stored. Imagine that, instead of working with data, such as <code class="literal">Order</code> and <code class="literal">Execution</code>, we instead worked with events that represent things that happened in the system over time. One relevant event to report could be the <code class="literal">OrderExecuted</code> event that can be modeled, as follows:</p><pre class="programlisting">case class OrderExecuted(created: CreatedTimestamp, orderId: OrderId, price: Price) &#13;
</pre><p>This event describes something that happened instead of representing a snapshot of current state. To extend this example, imagine if <code class="literal">Order</code> also included an optional <code class="literal">Price</code> to denote execution price:</p><pre class="programlisting">sealed trait Order { &#13;
  def created: CreatedTimestamp &#13;
  def id: OrderId &#13;
  def ticker: Ticker &#13;
  def price: Price &#13;
  def clientId: ClientId &#13;
  def executionPrice: Option[Price] &#13;
} &#13;
</pre><p>If this data model is mapped to a relational database, <code class="literal">executionPrice</code> would be a nullable database value that is overwritten when an execution occurs. When the domain model only reflects the current state, then immutability is lost. As a functional programmer, this statement should concern you because you understand the reasoning capabilities that immutability provides. Storing only the current state of data may also lead to excessively large objects that are difficult to program with. For example, how would you represent that an <code class="literal">Order</code> was canceled? With the current approach, the most expedient method is to add a Boolean flag named <code class="literal">isCanceled</code>. Over time, as your system's requirements become more complicated, the <code class="literal">Order</code> object will grow and you will track more characteristics about the current state. This means that loading a set of <code class="literal">Order</code> objects into memory from a database will grow more unwieldy due to growing memory requirements. This is a dilemma that you likely have experienced if you have extensive <span class="strong"><strong>Object Relational Mapping</strong></span> (<span class="strong"><strong>ORM</strong></span>) experience.</p><p>To avoid bloating <code class="literal">Order</code>, you may try to deconstruct the concept of an order to support multiple use cases. For example, if you are only interested in executed orders, the model may change the <code class="literal">executionPrice</code> datatype from <code class="literal">Option[Price]</code> to <code class="literal">Price</code>, and you may no longer require the canceled Boolean flag because, by definition, an executed order could not have been canceled.</p><p>Identifying multiple definitions or representations for what you once thought was a single concept is an important step toward addressing the shortcomings that we walked through. Extending this approach, we come back to the topic of event sourcing. We can replay a set of events to build <code class="literal">OrderExecuted</code>. Let's slightly modify the events emitted from the order book to look like the following:</p><pre class="programlisting">sealed trait OrderBookEvent &#13;
case class BuyOrderSubmitted(created: CreatedTimestamp,  &#13;
  id: OrderId, ticker: Ticker, price: Price, clientId: ClientId) &#13;
  extends OrderBookEvent &#13;
case class SellOrderSubmitted(created: CreatedTimestamp,  &#13;
  id: OrderId, ticker: Ticker, price: Price clientId: ClientId) &#13;
  extends OrderBookEvent &#13;
case class OrderCanceled(created: CreatedTimestamp, id: OrderId) &#13;
  extends OrderBookEvent &#13;
case class OrderExecuted(created: CreatedTimestamp,  &#13;
  id: OrderId, price: Price) extends OrderBookEvent &#13;
</pre><p>If all <code class="literal">OrderBookEvents</code> were persisted (for example, to disk), it is then possible to write a program that reads all the events and constructs a set of <code class="literal">ExecutedOrders</code> by correlating <code class="literal">BuyOrderSubmitted</code> and <code class="literal">SellOrderSubmitted</code> events with <code class="literal">OrderExecuted</code> events. An advantage that we see with this approach is that, over time, we are able to ask new questions about what happened in our system and then easily answer them by reading the events. In contrast, if a model built on the current state did not include executions when it was first designed, it is impossible to retroactively answer the question, "Which orders executed last week?"</p><p>Our new idea is exciting, and it has the potential to yield great improvements. However, it comes with a set of challenges. The main difference with the previous section is that our new use case does not load the <code class="literal">Order</code> and <code class="literal">Execution</code> collections in memory from a data store. Instead, we are planning to process the incoming <code class="literal">OrderBookEvent</code> as it is generated by the order book. Conceptually, this approach still involves processing a sequence of data. However, with the previous approach, the entire data set existed prior to beginning any transformations. Processing events on-the-fly requires designing software that handles data that has not yet been generated. Clearly, neither eager collections nor views are a good tool for our new system. Luckily, the standard Scala library provides us with the right abstraction: <code class="literal">Stream</code>. Let's take a closer look at this new collection type to better understand how <code class="literal">Stream</code> can help us implement an event sourcing approach to the client performance reporting architecture.</p><div class="section" title="An overview of Stream"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec42"/>An overview of Stream</h2></div></div></div><p>A stream can be seen as a mix between a list and a view. Like a view, it is lazily evaluated and transformations are applied only when its elements are accessed or collected. Like a <code class="literal">List</code>, the elements of a <code class="literal">Stream</code> are only evaluated once. A <code class="literal">Stream</code> is sometimes described as an unrealized <code class="literal">List</code>, meaning that it is essentially a <code class="literal">List</code> that has not yet been fully evaluated, or realized.</p><p>Where a <code class="literal">List</code> can be constructed with the cons (<code class="literal">::</code>) operator, a <code class="literal">Stream </code>can be similarly constructed with its own operator:</p><pre class="programlisting">&gt; val days = "Monday" :: "Tuesday" :: "Wednesday" :: Nil &#13;
days: List[String] = List(Monday, Tuesday, Wednesday) &#13;
 &#13;
&gt; val months = "January" #:: "February" #:: "March" #:: Stream.empty &#13;
months: scala.collection.immutable.Stream[String] = Stream(January, ?) &#13;
</pre><p>The syntax to create a <code class="literal">Stream</code> is close to the one to create a <code class="literal">List</code>. One difference is the returned value. Where a <code class="literal">List</code> is immediately evaluated, a <code class="literal">Stream</code> is not. Only the first element (<code class="literal">"January"</code>) is computed; the remaining values are still unknown (and denoted by a<code class="literal">?</code> character).</p><p>Let's observe what happens when we access part of the stream:</p><pre class="programlisting">scala&gt; println(months.take(2).toList) &#13;
List(January, February) &#13;
scala&gt; months &#13;
res0: scala.collection.immutable.Stream[String] = Stream(January, February, ?) &#13;
</pre><p>We forced the evaluation of the first two elements of the <code class="literal">Stream</code> by turning it into a <code class="literal">List</code> (see the following sidebar). The first two months are printed. We then display the value of <code class="literal">months</code> to discover that the second element (<code class="literal">"February"</code>) is now computed.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note37"/>Note</h3><p>In the preceding example, <code class="literal">toList</code> is the call that forces the evaluation of the <code class="literal">Stream</code>. <code class="literal">take(2)</code> is a lazily applied transformer that also returns an unevaluated <code class="literal">Stream</code>:</p></div></div><pre class="programlisting">scala&gt; months.take(2) &#13;
res0: scala.collection.immutable.Stream[String] = Stream(January, ?) &#13;
</pre><p>To highlight the evaluation characteristics of a <code class="literal">Stream</code>, we look at another example of creating a <code class="literal">Stream</code>:</p><pre class="programlisting">def powerOf2: Stream[Int] = { &#13;
  def next(n: Int): Stream[Int] = { &#13;
    println(s"Adding $n") &#13;
    n #:: next(2 * n) &#13;
  } &#13;
  1 #:: next(1) &#13;
} &#13;
</pre><p>This short snippet defines a function that creates a <code class="literal">Stream</code> of powers of 2. It is an infinite <code class="literal">Stream</code> initialized with the first value 1 and the tail is defined as another <code class="literal">Stream</code>. We added a <code class="literal">println</code> statement to allow us to study the evaluation of the elements:</p><pre class="programlisting">scala&gt; val s = powerOf2 &#13;
s: Stream[Int] = Stream(1, ?) &#13;
 &#13;
scala&gt; s.take(8).toList &#13;
Adding 1 &#13;
Adding 2 &#13;
Adding 4 &#13;
Adding 8 &#13;
Adding 16 &#13;
Adding 32 &#13;
Adding 64 &#13;
res0: List[Int] = List(1, 1, 2, 4, 8, 16, 32, 64) &#13;
 &#13;
scala&gt; s.take(10).toList &#13;
Adding 128 &#13;
Adding 256 &#13;
res1: List[Int] = List(1, 1, 2, 4, 8, 16, 32, 64, 128, 256) &#13;
</pre><p>Note how the first eight elements are only evaluated when we perform the first conversion to a <code class="literal">List</code>. In the second call, only elements 9 and 10 are computed; the first eight are already realized and are part of the <code class="literal">Stream</code>.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note38"/>Note</h3><p>Based on the previous example, you may wonder if a <code class="literal">Stream</code> is an immutable data structure. Its fully qualified name is <code class="literal">scala.collection.immutable.Stream</code>, so this should give you a good hint. It is true that accessing the <code class="literal">Stream</code> and realizing some of its elements causes a modification of the <code class="literal">Stream</code>. However, the data structure is still considered immutable. The values it contains never change once assigned; even before being evaluated, the values exist and have a definition in the <code class="literal">Stream</code>.</p></div></div><p>The previous example shows an interesting property of <code class="literal">Stream</code>: it is possible to create a virtually infinite <code class="literal">Stream</code>. The <code class="literal">Stream</code> that is created by <code class="literal">powerOf2</code> is unbounded and it is always possible to create one more element thanks to our <code class="literal">next</code> method. Another useful technique is the creation of recursive streams. A recursive <code class="literal">Stream</code> refers to itself in its definition. Let's adapt our previous example. Instead of returning the complete sequence of powers of 2, we will allow the caller to set a starting value:</p><pre class="programlisting">def powerOf2(n: Int): Stream[Int] = math.pow(2, n).toInt #:: powerOf2(n+1) &#13;
</pre><p>The <code class="literal">math.pow</code> is used to compute <span class="emphasis"><em>2^n</em></span>. Note that we calculate the first value and define the rest of the <code class="literal">Stream</code> as <code class="literal">powerOf2(n+1)</code>, that is, the next power of 2:</p><pre class="programlisting">scala&gt; powerOf2(3).take(10).toList &#13;
res0: List[Int] = List(8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096) &#13;
</pre><p>The companion object of <code class="literal">Stream</code> provides several factory methods to instantiate a <code class="literal">Stream</code>. Let's look at a few of them:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">Stream.apply</code>: This allows us to create a <code class="literal">Stream</code> for a finite sequence of values:</li></ul></div><pre class="programlisting">       scala&gt; Stream(1,2,3,4) &#13;
       res0: scala.collection.immutable.Stream[Int] = Stream(1, ?) &#13;
       scala&gt; Stream(List(1,2,3,4):_*) &#13;
       res1: scala.collection.immutable.Stream[Int] = Stream(1, ?) &#13;
</pre><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">Stream.fill[A](n: Int)(a: =&gt; A)</code>: This produces a <code class="literal">Stream</code> containing the element <code class="literal">a</code>, <code class="literal">n</code> times:</li></ul></div><pre class="programlisting">       scala&gt; Stream.fill(4)(10) &#13;
       res0: scala.collection.immutable.Stream[Int] = Stream(10, ?) &#13;
       scala&gt; res0.toList &#13;
       res1: List[Int] = List(10, 10, 10, 10) &#13;
</pre><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">Stream.from(start: Int)</code>: This creates an increasing sequence of integers beginning with <code class="literal">start</code>:</li></ul></div><pre class="programlisting">       scala&gt; Stream.from(4) &#13;
       res0: scala.collection.immutable.Stream[Int] = Stream(4, ?) &#13;
       scala&gt; res0.take(3).toList &#13;
       res1: List[Int] = List(4, 5, 6) &#13;
</pre><p>We invite you to look at the other methods that are available on the companion object. Note that a <code class="literal">Stream</code> can also be constructed from a <code class="literal">List</code> directly, as follows:</p><pre class="programlisting">scala&gt; List(1,2,3,4,5).toStream &#13;
res0: scala.collection.immutable.Stream[Int] = Stream(1, ?) &#13;
</pre><p>The previous code may be misleading. Turning a <code class="literal">List</code> into a <code class="literal">Stream</code> does not spare the price of evaluating the whole <code class="literal">List</code> in memory. Similarly, if we were to apply transformations (such as <code class="literal">map</code> or <code class="literal">filter</code>) to the <code class="literal">List</code> before the call to <code class="literal">toStream</code>, we would be performing these computations on the entire <code class="literal">List</code>.</p><p>Just like a <code class="literal">List</code>, you can pattern match on a <code class="literal">Stream</code>, as follows:</p><pre class="programlisting">scala&gt; val s = Stream(1,2,3,4) &#13;
s: scala.collection.immutable.Stream[Int] = Stream(1, ?) &#13;
scala&gt; s match { &#13;
     | case _ #:: _ #:: i #:: _ =&gt; i &#13;
     | } &#13;
res0: Int = 3 &#13;
</pre><p>This pattern matching extracts the third element from the <code class="literal">s</code> stream. Pattern matching on a stream forces the realization of the elements required to evaluate the match expression. In the preceding case, the first three items are calculated.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note39"/>Note</h3><p>To pattern match on an empty stream, you can use the <code class="literal">Stream.Empty</code> object. It is a singleton instance to represent an empty <code class="literal">Stream</code>. It works similarly to <code class="literal">Nil</code> for <code class="literal">List</code>. Note that the object <code class="literal">Stream</code> contains an <code class="literal">empty</code> method returning this singleton; however, pattern matching requires a stable identifier, and it cannot use calls to a method as a valid <code class="literal">case</code>.</p></div></div></div><div class="section" title="Transforming events"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec43"/>Transforming events</h2></div></div></div><p>Returning to the reporting system, how can we apply the principles of event sourcing and leverage <code class="literal">Stream</code> to change how reports are generated? To compute <code class="literal">TradingPerformanceTrend</code> for a client, we need to compute PnL trend values for three time periods: each hour, each day, and each seven days. We can write a method with the following signature that gets us closer to identifying the PnL for each trend:</p><pre class="programlisting">def processPnl(e: OrderBookEvent, s: TradeState): (TradeState, Option[PnlEvent]) &#13;
</pre><p>The signature of <code class="literal">processPnl</code> accepts an <code class="literal">OrderBookEvent</code> and state in the form of <code class="literal">TradeState</code> to produce a new <code class="literal">TradeState</code> and, optionally, a <code class="literal">PnlEvent</code>. Let's first inspect <code class="literal">PnlEvent</code> to understand the end result of this method before inspecting <code class="literal">TradeState</code>:</p><pre class="programlisting">sealed trait PnlEvent &#13;
case class PnlIncreased(created: EventInstant, clientId: ClientId, &#13;
  ticker: Ticker, profit: Pnl) extends PnlEvent &#13;
case class PnlDecreased(created: EventInstant, clientId: ClientId, &#13;
  ticker: Ticker, loss: Pnl)extends PnlEvent &#13;
 &#13;
case class Pnl(value: BigDecimal) extends AnyVal { &#13;
  def isProfit: Boolean = value.signum &gt;= 0 &#13;
} &#13;
object Pnl { &#13;
  def fromExecution(buy: Price, sell: Price): Pnl = &#13;
    Pnl(sell.value - buy.value) &#13;
 &#13;
  val zero: Pnl = Pnl(BigDecimal(0)) &#13;
} &#13;
</pre><p>We see that <code class="literal">PnlEvent</code> models an ADT that expresses when a client's PnL increased or decreased. Using the past tense to name the event (for example, increased) makes it clear that this is a fact or a record of something that has completed. We have not yet looked at how <code class="literal">TradeState</code> is defined or the implementation of <code class="literal">processPnl</code>, but we can already infer the behavior by studying the emitted events. We display the definition of <code class="literal">TradeState</code>, which is needed to correlate submitted orders with executions, as follows:</p><pre class="programlisting">case class PendingOrder(ticker: Ticker, price: Price,  &#13;
  clientId: ClientId)  &#13;
 &#13;
  case class TradeState( &#13;
    pendingBuys: Map[OrderId, PendingOrder], &#13;
    pendingSells: Map[OrderId, PendingOrder]) { &#13;
    def cancelOrder(id: OrderId): TradeState = copy( &#13;
      pendingBuys = pendingBuys - id, pendingSells = pendingSells - id) &#13;
    def addPendingBuy(o: PendingOrder, id: OrderId): TradeState = &#13;
      copy(pendingBuys = pendingBuys + (id -&gt; o)) &#13;
    def addPendingSell(o: PendingOrder, id: OrderId): TradeState = &#13;
      copy(pendingSells = pendingSells + (id -&gt; o)) &#13;
  } &#13;
object TradeState { &#13;
 val empty: TradeState = TradeState(Map.empty, Map.empty) &#13;
} &#13;
</pre><p>Next, we inspect the implementation of <code class="literal">processPnl</code> to view how <code class="literal">PnlEvents</code> are created, as follows:</p><pre class="programlisting">  def processPnl( &#13;
    s: TradeState, &#13;
    e: OrderBookEvent): (TradeState, Option[PnlEvent]) = e match { &#13;
    case BuyOrderSubmitted(_, id, t, p, cId) =&gt; &#13;
      s.addPendingBuy(PendingOrder(t, p, cId), id) -&gt; None &#13;
    case SellOrderSubmitted(_, id, t, p, cId) =&gt; &#13;
      s.addPendingSell(PendingOrder(t, p, cId), id) -&gt; None &#13;
    case OrderCanceled(_, id) =&gt; s.cancelOrder(id) -&gt; None &#13;
    case OrderExecuted(ts, id, price) =&gt; &#13;
      val (p, o) = (s.pendingBuys.get(id), s.pendingSells.get(id)) match { &#13;
        case (Some(order), None) =&gt; &#13;
          Pnl.fromBidExecution(order.price, price) -&gt; order &#13;
        case (None, Some(order)) =&gt; &#13;
          Pnl.fromOfferExecution(price, order.price) -&gt; order &#13;
        case error =&gt; sys.error( &#13;
          s"Unsupported retrieval of ID = $id returned: $error") &#13;
      } &#13;
      s.cancelOrder(id) -&gt; Some( &#13;
        if (p.isProfit) PnlIncreased(ts, o.clientId, o.ticker, p) &#13;
        else PnlDecreased(ts, o.clientId, o.ticker, p)) &#13;
  } &#13;
</pre><p>This implementation shows that the <code class="literal">PnlEvent</code> is pattern matched to determine the event type, and this is handled accordingly. When an order is submitted, <code class="literal">TradeState</code> is updated to reflect that there is a new pending order that will be either canceled or executed. When an order is canceled, the pending order is removed from <code class="literal">TradeState</code>. When an execution occurs, the pending order is removed and, additionally, a <code class="literal">PnlEvent</code> is emitted after computing the trade PnL. The trade PnL compares the execution price to the pending order's original price.</p><p>
<code class="literal">PnlEvent</code> provides enough information to compute PnL trend performance for all three time periods (hour, day, and seven days) required by <code class="literal">TradingPerformanceTrend</code>. The transformation from <code class="literal">OrderBookEvent</code> to <code class="literal">PnlEvent</code> is side-effect-free, and the creation of a new event, instead of replacing current state, leads to an immutable model. In the light of these characteristics, <code class="literal">processPnl</code> is easily unit-testable and makes the intent explicit. By making the intent explicit, it is possible to communicate with less technical stakeholders about how the system works.</p><p>Using <code class="literal">PnlEvent</code> as an input to a method that follows the analogous <code class="literal">(State, InputEvent) =&gt; (State, Option[OutputEvent])</code> signature, we can now compute hourly PnL trend, as follows:</p><pre class="programlisting">def processHourlyPnl(e: PnlEvent, s: HourlyState): (HourlyState, Option[HourlyPnlTrendCalculated]) &#13;
</pre><p>This signature shows that, by maintaining state in <code class="literal">HourlyState</code>, it is possible to emit the <code class="literal">HourlyPnlTrendCalculated</code> event. The emitted event is defined, as follows:</p><pre class="programlisting">case class HourlyPnlTrendCalculated( &#13;
      start: HourInstant, &#13;
      clientId: ClientId, &#13;
      ticker: Ticker, &#13;
      pnl: LastHourPnL) &#13;
</pre><p>For a particular hour, client ID, and ticker, <code class="literal">HourlyPnlTrendCalculated</code> is a record of whether the last hour PnL is positive or negative. The <code class="literal">HourInstant</code> class is a value class with a companion object method that transforms an instant to the start of the hour:</p><pre class="programlisting">case class HourInstant(value: Instant) extends AnyVal { &#13;
  def isSameHour(h: HourInstant): Boolean = &#13;
    h.value.toDateTime.getHourOfDay == value.toDateTime.getHourOfDay &#13;
} &#13;
object HourInstant { &#13;
  def create(i: EventInstant): HourInstant = &#13;
    HourInstant(i.value.toDateTime.withMillisOfSecond(0) &#13;
     .withSecondOfMinute(0).withMinuteOfHour(0).toInstant) &#13;
} &#13;
</pre><p>Let's have a look at how <code class="literal">HourlyState</code> is defined to better understand the state that is needed to yield <code class="literal">HourlyPnlTrendCalculated</code>:</p><pre class="programlisting">case class HourlyState( &#13;
      keyToHourlyPnl: Map[(ClientId, Ticker), (HourInstant, Pnl)]) &#13;
object HourlyState { &#13;
 val empty: HourlyState = HourlyState(Map.empty) &#13;
} &#13;
</pre><p>For a <code class="literal">ClientId</code> and a <code class="literal">Ticker</code>, the PnL for the current hour is stored in <code class="literal">HourlyState</code>. Accumulating the PnL allows <code class="literal">processHourlyPnl</code> to determine the PnL trend at the end of an hour. We now inspect the implementation of <code class="literal">processHourlyPnl</code> to see how <code class="literal">PnlEvent</code> is transformed into <code class="literal">HourlyPnlTrendCalculated</code>:</p><pre class="programlisting">def processHourlyPnl( &#13;
 s: HourlyState, &#13;
 e: PnlEvent): (HourlyState, Option[HourlyPnlTrendCalculated]) = { &#13;
 def processChange( &#13;
   ts: EventInstant, &#13;
   clientId: ClientId, &#13;
   ticker: Ticker, &#13;
   pnl: Pnl): (HourlyState, Option[HourlyPnlTrendCalculated]) = { &#13;
   val (start, p) = s.keyToHourlyPnl.get((clientId, ticker)).fold( &#13;
     (HourInstant.create(ts), Pnl.zero))(identity) &#13;
   start.isSameHour(HourInstant.create(ts)) match { &#13;
     case true =&gt; (s.copy(keyToHourlyPnl = s.keyToHourlyPnl + &#13;
       ((clientId, ticker) -&gt;(start, p + pnl))), None) &#13;
     case false =&gt; (s.copy(keyToHourlyPnl = &#13;
       s.keyToHourlyPnl + ((clientId, ticker) -&gt; &#13;
         (HourInstant.create(ts), Pnl.zero + pnl))), &#13;
       Some(HourlyPnlTrendCalculated(start, clientId, ticker, &#13;
         p.isProfit match { &#13;
           case true =&gt; LastHourPositive &#13;
           case false =&gt; LastHourNegative &#13;
         }))) &#13;
   } &#13;
 } &#13;
 &#13;
 e match { &#13;
   case PnlIncreased(ts, clientId, ticker, pnl) =&gt; processChange( &#13;
     ts, clientId, ticker, pnl) &#13;
   case PnlDecreased(ts, clientId, ticker, pnl) =&gt; processChange( &#13;
     ts, clientId, ticker, pnl) &#13;
 } &#13;
} &#13;
</pre><p>Handling an increased and decreased PnL follows the same flow. The inner-method named <code class="literal">processChange</code> handles the identical processing steps. The <code class="literal">processChange</code> determines whether or not to emit <code class="literal">HourlyPnlTrendCalculated</code> by comparing the <code class="literal">HourInstant</code> value that is added when an entry is first added to the state with the hour of the timestamp provided by the event. When the comparison shows the hour has changed, then the hourly PnL trend has been computed because the hour is completed. When the hour is unchanged, the provided PnL is added to the state's PnL to continue accumulating the hour's PnL.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note40"/>Note</h3><p>An obvious shortcoming of this approach is that, when a client or a ticker does not have any executed orders, it will not be possible to determine that the hour is completed. For simplicity, we are not treating time as a first-class event. However, you can imagine how it is possible to model the passing of time as an event that is a second input to <code class="literal">processHourlyPnl</code>. For example, the event might be the following:
</p><p><code class="literal">case class HourElapsed(hour: HourInstant)</code></p><p>
To use this event, we could change the signature of <code class="literal">processHourlyPnl</code> to receive an event argument that is of the <code class="literal">Either[HourElapsed, PnlEvent]</code> type. Scheduling <code class="literal">HourElapsed</code> on a timer enables us to modify the implementation of <code class="literal">processHourlyPnl</code> to emit <code class="literal">HourlyPnlTrendCalculated</code> as soon as the hour elapses instead of when a trade occurs in the next hour. This simple example shows how you can model time as an explicit part of the domain when you consider your system from an event sourcing point of view.</p></div></div><p>It is straightforward to imagine writing analogous methods that emit events for the daily and seven day PnL trend events, and then a method that awaits all three PnL trend events to produce the <code class="literal">TradingPerformanceTrendGenerated</code> event. The final step is to write a side-effecting method that persists <code class="literal">TradingPerformanceTrend</code> so that it can be read by the web portal. At this point, we have a collection of methods that performs transformations on events, but they are not yet wired together cohesively. Next, we take a look at how to create a pipeline to transform events.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note41"/>Note</h3><p>Note that, in this case study, we do not actually calculate a PnL. Performing a real PnL calculation would involve more complicated algorithms and would force us to introduce more domain concepts. We opted for a simpler approach with a report that is closer to an exposure report. This allows us to focus on the code and the programming practices that we want to illustrate.</p></div></div></div><div class="section" title="Building the event sourcing pipeline"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec44"/>Building the event sourcing pipeline</h2></div></div></div><p>We use the term pipeline to refer to an arranged set of transformations that may require multiple steps to yield a desired end result. This term brings to mind an image of a set of pipes spanning multiple directions with twists and turns along the way. Our goal is to write a program that receives <code class="literal">PnlEvents</code> traits and prints the <code class="literal">HourlyPnlTrendCalculated</code> events to a standard output. In a true production environment, you can imagine replacing printing to standard output with writing to a persistent data store. In either case, we are building a pipeline that performs a set of referentially transparent transformations and concludes with a side-effect.</p><p>The pipeline must accumulate the intermediate state of each transformation as new events are processed. In the functional programming paradigm, accumulation is often associated with a <code class="literal">foldLeft</code> operation. Let's look at a toy example that sums a list of integers to better understand accumulation:</p><pre class="programlisting">val sum = Stream(1, 2, 3, 4, 5).foldLeft(0) { case (acc, i) =&gt; acc + i } &#13;
println(sum) // prints 15  &#13;
</pre><p>Here, we see <code class="literal">foldLeft</code> applied to compute the sum of a list of integers by providing an initial sum value of zero and currying a function to add the current element to the accumulated sum. The <code class="literal">acc</code> value is an often used shorthand for 'accumulator'. In this example, the accumulator and the list elements share the same data type, integer. This is merely a coincidence and is not a requirement for <code class="literal">foldLeft</code> operations. This implies that the accumulator can be a different type than the collection element.</p><p>We can use <code class="literal">foldLeft</code> as the basis of our event sourcing pipeline to support processing a list of <code class="literal">OrderBookEvents</code> while accumulating intermediate state. From the implementation of the two processing methods, we saw the need to maintain <code class="literal">TradeState</code> and <code class="literal">HourlyState</code>. We define <code class="literal">PipelineState</code> to encapsulate the required state, as follows:</p><pre class="programlisting">case class PipelineState(tradeState: TradeState, hourlyState: HourlyState) &#13;
object PipelineState { &#13;
  val empty: PipelineState = PipelineState(TradeState.empty, HourlyState.empty) &#13;
} &#13;
</pre><p>
<code class="literal">PipelineState</code> serves as the accumulator when folding over the <code class="literal">OrderBookEvent</code>, allowing us to store the intermediate state for both of the transformation methods. Now, we are ready to define the signature of our pipeline:</p><pre class="programlisting">def pipeline(initial: PipelineState, f: HourlyPnlTrendCalculated =&gt; Unit, xs: List[OrderBookEvent]): PipelineState &#13;
</pre><p>The <code class="literal">pipeline</code> accepts the initial state, a side-effecting function to be invoked when an <code class="literal">HourlyPnlTrendCalculated</code> event is generated, and a set of <code class="literal">OrderBookEvents</code> to source. The return value of the pipeline is the state of the pipeline once the events are processed. Let's look at how we can leverage <code class="literal">foldLeft</code> to implement <code class="literal">pipeline</code>:</p><pre class="programlisting">def pipeline( &#13;
    initial: PipelineState, &#13;
    f: HourlyPnlTrendCalculated =&gt; Unit, &#13;
    xs: Stream[OrderBookEvent]): PipelineState = xs.foldLeft(initial) { &#13;
    case (PipelineState(ts, hs), e) =&gt; &#13;
      val (tss, pnlEvent) = processPnl(ts, e) &#13;
      PipelineState(tss, &#13;
        pnlEvent.map(processHourlyPnl(hs, _)).fold(hs) { &#13;
          case (hss, Some(hourlyEvent)) =&gt; &#13;
            f(hourlyEvent) &#13;
            hss &#13;
          case (hss, None) =&gt; hss &#13;
        }) &#13;
  } &#13;
</pre><p>The implementation of <code class="literal">pipeline</code> is based on folding over the provided events using the provided <code class="literal">PipelineState</code> as a starting point for accumulation. The curried function provided to <code class="literal">foldLeft</code> is where the wiring of transformations takes place. Stitching together the two transformation methods and the side-effecting event handler requires handling several different scenarios. Let's walk through each of the possible cases to better understand how the pipeline works. The <code class="literal">processPnl</code> is invoked to produce a new <code class="literal">TradeState</code> and optionally yield a <code class="literal">PnlEvent</code>. If no <code class="literal">PnlEvent</code> is generated, then <code class="literal">processHourlyPnl</code> is not invoked and the previous <code class="literal">HourlyState</code> is returned.</p><p>If a <code class="literal">PnlEvent</code> is generated, then <code class="literal">processHourlyPnl</code> is evaluated to determine whether an <code class="literal">HourlyPnlTrendCalculated</code> is created. When <code class="literal">HourlyPnlTrendCalculated</code> is generated, then the side-effecting <code class="literal">HourlyPnlTrendCalculated</code> event handler is invoked and the new <code class="literal">HourlyState</code> is returned. If no <code class="literal">HourlyPnlTrendCalculated</code> is generated, then the existing <code class="literal">HourlyState</code> is returned.</p><p>We construct a simple example to prove that the pipeline works as intended, as follows:</p><pre class="programlisting">val now = EventInstant(HourInstant.create(EventInstant( &#13;
      new Instant())).value) &#13;
    val Foo = Ticker("FOO") &#13;
 &#13;
    pipeline(PipelineState.empty, println, Stream( &#13;
      BuyOrderSubmitted(now, OrderId(1), Foo, Price(21.07), ClientId(1)), &#13;
      OrderExecuted(EventInstant(now.value.plus(Duration.standardMinutes(30))), &#13;
        OrderId(1), Price(21.00)), &#13;
      BuyOrderSubmitted(EventInstant(now.value.plus( &#13;
        Duration.standardMinutes(35))), &#13;
        OrderId(2), Foo, Price(24.02), ClientId(1)), &#13;
      OrderExecuted(EventInstant(now.value.plus(Duration.standardHours(1))), &#13;
        OrderId(2), Price(24.02)))) &#13;
</pre><p>At the start of the hour, a buy order is submitted for the stock, FOO. Within the hour, the buy order is executed at a price lower than the buying price, indicating the trade was profitable. As we know, the current implementation relies on executions in the subsequent hour in order to produce <code class="literal">HourlyPnlTrendCalculated</code>.  To create this event, a second buy order is submitted at the start of the second hour. Running this snippet produces a single <code class="literal">HourlyPnlTrendCalculated</code> event that is written to standard output:</p><pre class="programlisting">HourlyPnlTrendCalculated(HourInstant(2016-02-15T20:00:00.000Z),ClientId(1),Ticker(FOO),LastHourPositive) &#13;
</pre><p>Although the wiring together of transformations is somewhat involved, we managed to build a simple event sourcing pipeline using only the Scala standard library and our existing knowledge of Scala collections. This example demonstrated the power of <code class="literal">foldLeft</code> to help build an event sourcing pipeline. Using this implementation, we can write a fully-featured program that is able to write a pregenerated version of the performance report to a persistent data store that can be read by the web portal. This new design allows us to shift the burden of report generation outside the web portal's responsibilities, allowing the web portal to provide a responsive user experience. Another benefit of this new approach is how it puts a domain-oriented language at the center of the design. All our events use business terms and focus on modeling domain concepts, making it easier for developers and stakeholders to communicate with each other.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note42"/>Note</h3><p>You might be wondering about a data structure that shares some characteristics of <code class="literal">Stream</code> that we did not yet mention: <code class="literal">Iterator</code>. As the name implies, <code class="literal">Iterator</code> provides facilities to iterate over a sequence of data. Its simplified definition boils down to the following:</p><div class="informalexample"><pre class="programlisting">trait Iterator[A] { 
  def next: A 
  def hasNext: Boolean 
}</pre></div><p>Like <code class="literal">Stream</code>, an <code class="literal">Iterator</code> is able to avoid loading an entire dataset into memory, which enables programs to be written with constant memory usage. Unlike <code class="literal">Stream</code>, an <code class="literal">Iterator</code> is mutable and intended for only a single iteration over a collection (it extends the <code class="literal">TraversableOnce</code> trait). It should be noted that, according to the standard library documentation, one should never use an iterator after calling a method on it. For example, calling <code class="literal">size</code> on an <code class="literal">Iterator</code> returns the size of the sequence, but it also consumes the entire sequence and renders the instance of <code class="literal">Iterator</code> useless. The only exceptions to this rule are <code class="literal">next</code> and <code class="literal">hasNext</code>. These properties lead to software that is difficult to reason with, which is the antithesis of what we strive for as functional programmers. For this reason, we omit an in-depth discussion about <code class="literal">Iterator</code>.</p></div></div><p>We encourage you to further explore event sourcing by reading the documentation of the Event Store database at <a class="ulink" href="http://docs.geteventstore.com/introduction/event-sourcing-basics/">http://docs.geteventstore.com/introduction/event-sourcing-basics/</a>. Event Store is a database that is developed around the concept of event sourcing. Event Store was created by Greg Young, a notable writer on the topic of event sourcing. While enriching your understanding about event sourcing, reflect on when you believe it is appropriate to apply the event sourcing technique. For CRUD applications that have simple behavior, event sourcing may not be a worthwhile time investment. When you model more complex behaviors or consider scenarios involving strict performance and scaling requirements, the time investment for event sourcing may become justified. For example, like we saw with performance trend reporting, considering the performance challenges from the event sourcing paradigm exposed an entirely different way of approaching the design.</p><p>As you continue exploring the world of stream processing, you will discover that you wish to construct more complex transformations than our event sourcing pipeline example. To continue digging deeper into the the topic of stream processing, we suggest researching two relevant libraries: <code class="literal">akka streams</code> and <code class="literal">functional streams</code> (formerly, <code class="literal">scalaz-stream</code>). These libraries provide tools to build more sophisticated transformation pipelines using different abstractions than <code class="literal">Stream</code>. In combination with learning about Event Store, you will deepen your understanding of how event sourcing ties in with stream processing.</p></div><div class="section" title="Streaming Markov chains"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec45"/>Streaming Markov chains</h2></div></div></div><p>With the simple program at the end of the previous section, we demonstrated that we can wire together a pipeline of transformations operating on events. As a well-intentioned engineer, you wish to develop automated tests that prove the pipeline works as intended. One approach is to add a sample of historical production data into the repository to build tests. This is often a good choice, but you are concerned that the sample is not large enough to represent a broad number of scenarios. Another option is to write a generator of events that can create production-like data. This approach requires more up-front effort, but it yields a more dynamic way to exercise the pipeline.</p><p>A recent lunchtime conversation with Dave about Markov chains sparked the thought about testing the event sourcing pipeline with generated data. Dave described how a Markov chain is a statistical model of state transitions that only relies on the current state to determine the next state. Dave is representing the states of the stock market as a Markov chain, allowing him to build trading strategies based on whether or not he perceives the stock market to be in an upswing, downswing, or steady state. After reading through the Markov chain Wikipedia page, you envision writing an event generator based on a Markov chain.</p><p>Our end goal is to be able to generate an infinite number of <code class="literal">OrderBookEvent</code>s that follows production-like patterns. For example, we know from previous experience that proportionally there are often more cancelations than executions, particularly during volatile markets. The event generator should be able to represent different probabilities of events occurring. As a Markov chain only depends on its current state to identify its next state, a <code class="literal">Stream</code> is a natural fit because we only need to inspect the current element to determine the next element. For our representation of a Markov chain, we need to identify the chance of transitioning from the current state to any of the other possible states. The following table illustrates one possible set of probabilities:</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/><col/><col/></colgroup><tbody><tr><td>
<p>
<span class="strong"><strong>Current state</strong></span>
</p>
</td><td>
<p>
<span class="strong"><strong>Chance of buy</strong></span>
</p>
</td><td>
<p>
<span class="strong"><strong>Chance of sell</strong></span>
</p>
</td><td>
<p>
<span class="strong"><strong>Chance of execution</strong></span>
</p>
</td><td>
<p>
<span class="strong"><strong>Chance of cancel</strong></span>
</p>
</td></tr><tr><td>
<p>
<code class="literal">BuyOrderSubmitted</code>
</p>
</td><td>
<p>10%</p>
</td><td>
<p>15%</p>
</td><td>
<p>40%</p>
</td><td>
<p>40%</p>
</td></tr><tr><td>
<p>
<code class="literal">SellOrderSubmitted</code>
</p>
</td><td>
<p>25%</p>
</td><td>
<p>10%</p>
</td><td>
<p>35%</p>
</td><td>
<p>25%</p>
</td></tr><tr><td>
<p>
<code class="literal">OrderCanceled</code>
</p>
</td><td>
<p>60%</p>
</td><td>
<p>50%</p>
</td><td>
<p>40%</p>
</td><td>
<p>10%</p>
</td></tr><tr><td>
<p>
<code class="literal">OrderExecuted</code>
</p>
</td><td>
<p>30%</p>
</td><td>
<p>30%</p>
</td><td>
<p>55%</p>
</td><td>
<p>30%</p>
</td></tr></tbody></table></div><p>This table defines the likelihood of receiving an <code class="literal">OrderBookEvent</code> given the current <code class="literal">OrderBookEvent</code>. For example, given that a sell order was submitted, there is a 10% chance of seeing a second sell order next and a 35% chance that an execution occurs next. We can develop state transition probabilities according to the market conditions that we wish to simulate in the pipeline.</p><p>We can model the transitions using the following domain:</p><pre class="programlisting">  sealed trait Step &#13;
  case object GenerateBuy extends Step &#13;
  case object GenerateSell extends Step &#13;
  case object GenerateCancel extends Step &#13;
  case object GenerateExecution extends Step &#13;
 &#13;
  case class Weight(value: Int) extends AnyVal &#13;
  case class GeneratedWeight(value: Int) extends AnyVal &#13;
  case class StepTransitionWeights( &#13;
    buy: Weight, &#13;
    sell: Weight, &#13;
    cancel: Weight, &#13;
    execution: Weight) &#13;
</pre><p>In this domain, <code class="literal">Step</code> is an ADT that models the possible states. For a given <code class="literal">Step</code>, we will associate <code class="literal">StepTransitionWeights</code> to define the probability of transitioning to different states based on provided weightings. <code class="literal">GeneratedWeight</code> is a value class that defines the weight generated for the current <code class="literal">Step</code>. We will use <code class="literal">GeneratedWeight</code> to drive the transition from one <code class="literal">Step</code> to the next <code class="literal">Step</code>.</p><p>Our next step, so-to-speak, is to make use of our domain to generate events according to probabilities that we define. To make use of <code class="literal">Step</code>, we define a representation of the Markov chain state that is required, as follows:</p><pre class="programlisting">  case class State( &#13;
    pendingOrders: Set[OrderId], &#13;
    step: Step) &#13;
</pre><p>The Markov chain requires knowledge of the current state, which is represented by <code class="literal">step</code>. Additionally, we put a twist on the Markov chain by maintaining the set of orders that are submitted that are neither canceled nor executed in <code class="literal">pendingOrders</code>. This additional state is needed for two reasons. First, generating cancel and execution events requires linking to a known order ID. Second, we constrain our representation of a Markov chain by requiring at least one pending order to exist before creating a cancel or an execution. If there are no pending orders, it is invalid to transition to a state that generates either <code class="literal">OrderCanceled</code> or <code class="literal">OrderExecuted</code>.</p><p>Using <code class="literal">State</code>, we can write a method with the following signature to manage transitions:</p><pre class="programlisting">def nextState( &#13;
      weight: StepTransitionWeights =&gt; GeneratedWeight, &#13;
      stepToWeights: Map[Step, StepTransitionWeights], &#13;
      s: State): (State, OrderBookEvent) &#13;
</pre><p>Given a way to generate a weight from the current <code class="literal">StepTransitionWeights</code>, a mapping of <code class="literal">Step</code> to <code class="literal">StepTransitionWeights</code>, and the current <code class="literal">State</code>, we are able to produce a new <code class="literal">State</code> and an <code class="literal">OrderBookEvent</code>. For brevity, we omit the implementation of <code class="literal">nextState</code> because we want to focus most intently on stream processing. From the signature, we have enough insight to apply the method, but we encourage you to inspect the repository to fill in any blanks in your understanding.</p><p>The <code class="literal">nextState</code> method is the driver of state transitions in our Markov chain representation. We can now generate an infinite <code class="literal">Stream</code> of <code class="literal">OrderBookEvent</code>s based on transition probabilities using the convenience <code class="literal">Stream</code> method, <code class="literal">iterate</code>. From the Scala documentation, <code class="literal">iterate</code> produces an infinite stream by repeatedly applying a function to the start value. Let's see how we can use <code class="literal">iterate</code>:</p><pre class="programlisting">val stepToWeights = Map[Step, StepTransitionWeights]( &#13;
      GenerateBuy -&gt; StepTransitionWeights( &#13;
        Weight(10), Weight(25), Weight(40), Weight(40)), &#13;
      GenerateSell -&gt; StepTransitionWeights( &#13;
        Weight(25), Weight(10), Weight(40), Weight(25)), &#13;
      GenerateCancel -&gt; StepTransitionWeights( &#13;
        Weight(60), Weight(50), Weight(40), Weight(10)), &#13;
      GenerateExecution -&gt; StepTransitionWeights( &#13;
        Weight(30), Weight(30), Weight(60), Weight(25))) &#13;
 &#13;
    val next = State.nextState( &#13;
      t =&gt; GeneratedWeight(Random.nextInt(t.weightSum.value) + 1), &#13;
      stepToWeights, _: State) &#13;
 &#13;
    println("State\tEvent") &#13;
    Stream.iterate(State.initialBuy) { case (s, e) =&gt; next(s) } &#13;
      .take(5) &#13;
      .foreach { case (s, e) =&gt; println(s"$s\t$e")  } &#13;
</pre><p>This snippet creates a Markov chain to generate various <code class="literal">OrderBookEvent</code>s by providing a mapping of <code class="literal">Step</code> to <code class="literal">StepTransitionWeights</code> as the basis to invoke <code class="literal">State.nextState</code>. <code class="literal">State.nextState</code> is partially applied, leaving the current state unapplied. The <code class="literal">next</code> function has the <code class="literal">State =&gt; (State, OrderBookEvent)</code> signature. With the necessary scaffolding in place, <code class="literal">Stream.iterate</code> is used to generate an infinite sequence of multiple <code class="literal">OrderBookEvent</code>s by invoking <code class="literal">next</code>. Similar to <code class="literal">foldLeft</code>, we provide an initial value to begin the <code class="literal">initialBuy</code> iteration, which is defined as follows:</p><pre class="programlisting">val initialBuy: (State, OrderBookEvent) = { &#13;
      val e = randomBuySubmitted() &#13;
      State(Set(e.id), GenerateBuy) -&gt; e &#13;
    } &#13;
</pre><p>Running this snippet produces output that is similar to the following:</p><pre class="programlisting"><span class="strong"><strong>    State = State(Set(OrderId(1612147067584751204)),GenerateBuy)&#13;
    Event = BuyOrderSubmitted(EventInstant(2016-02-22T23:52:40.662Z),OrderId(1612147067584751204),Ticker(FOO),Price(32),ClientId(28))&#13;
    State = State(Set(OrderId(1612147067584751204), OrderId(7606120383704417020)),GenerateBuy)&#13;
    Event = BuyOrderSubmitted(EventInstant(2016-02-22T23:52:40.722Z),OrderId(7606120383704417020),Ticker(XYZ),Price(18),ClientId(54))&#13;
    State = State(Set(OrderId(1612147067584751204), OrderId(7606120383704417020), OrderId(5522110701609898973)),GenerateBuy)&#13;
    Event = BuyOrderSubmitted(EventInstant(2016-02-22T23:52:40.723Z),OrderId(5522110701609898973),Ticker(XYZ),Price(62),ClientId(28))&#13;
    State = State(Set(OrderId(7606120383704417020), OrderId(5522110701609898973)),GenerateExecution)&#13;
    Event = OrderExecuted(EventInstant(2016-02-22T23:52:40.725Z),OrderId(1612147067584751204),Price(21))&#13;
    State = State(Set(OrderId(7606120383704417020), OrderId(5522110701609898973), OrderId(5898687547952369568)),GenerateSell)&#13;
    Event = SellOrderSubmitted(EventInstant(2016-02-22T23:52:40.725Z),OrderId(5898687547952369568),Ticker(BAR),Price(76),ClientId(45))&#13;
</strong></span></pre><p>Of course, each invocation differs depending upon the random values that are created for <code class="literal">GeneratedWeight</code>, which is used to probabilistically select the next transition. This snippet provides a base to compose larger-scale tests for the reporting infrastructure. Through this example, we see an interesting application of Markov chains to support generating representative events from various market conditions without requiring access to volumes of production data. We are now able to write tests to confirm whether or not the reporting infrastructure correctly computes PnL trends in different market conditions.</p></div><div class="section" title="Stream caveats"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec46"/>Stream caveats</h2></div></div></div><p>For all their goodness, <code class="literal">Stream</code> should be used with caution. In this section, we mention a few of the main caveats of <code class="literal">Stream</code>, and how to avoid them.</p><div class="section" title="Streams are memoizers"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec29"/>Streams are memoizers</h3></div></div></div><p>While views do not cache the result of a computation and, therefore, recalculate and realize each element each time it is accessed, <code class="literal">Stream</code> does save the final form of its elements. An element is only ever realized once, the first time it is accessed. While this is a great characteristic to avoid computing the same result several times, it can also lead to a large consumption of memory, to the point where your program may eventually run out of memory.</p><p>To avoid <code class="literal">Stream</code> memoization, it is good practice to avoid storing a <code class="literal">Stream</code> in a <code class="literal">val</code>. Using a <code class="literal">val</code> creates a permanent reference to the head of the <code class="literal">Stream</code>, ensuring that every element that is realized will be cached. If a <code class="literal">Stream</code> is defined as a <code class="literal">def</code>, it can be garbage collected as soon as it is no longer needed.</p><p>Memoization can happen when calling certain methods that are defined on <code class="literal">Stream</code>. For example, <code class="literal">drop</code> or <code class="literal">dropWhile</code> will evaluate and memoize all the intermediate elements to be dropped. The elements are memoized as the methods are defined on an instance of <code class="literal">Stream</code> (and <code class="literal">Stream</code> has a reference on its own head). We can implement our own <code class="literal">drop</code> function to avoid caching the intermediate elements in memory:</p><pre class="programlisting">@tailrec &#13;
def drop[A](s: Stream[A], count: Int): Stream[A] = count match { &#13;
  case 0 =&gt; s &#13;
  case n if n &gt; 0 =&gt; drop(s.tail, count - 1) &#13;
  case n if n &lt; 0 =&gt; throw new Exception("cannot drop negative count") &#13;
} &#13;
</pre><p>We pattern match on the value of <code class="literal">count</code> to know whether we can return the given <code class="literal">Stream</code> or need to perform a recursive call on the tail. Our method is tail-recursive. This makes sure that we do not keep a reference to the head of the <code class="literal">Stream</code>, since a tail-recursive function recycles its reference each time that it loops. Our <code class="literal">s</code> reference will only point to the remaining part of the <code class="literal">Stream</code>, not the head.</p><p>Another example of a problematic method is <code class="literal">max</code>. Calling <code class="literal">max</code> will memoize all the elements of the <code class="literal">Stream</code> to determine which one is the greatest. Let's implement a safe version of <code class="literal">max</code>, as follows:</p><pre class="programlisting">def max(s: =&gt; Stream[Int]): Option[Int] = { &#13;
 @tailrec &#13;
 def loop(ss: Stream[Int], current: Option[Int]): Option[Int] = ss match { &#13;
   case Stream.Empty =&gt; current &#13;
   case h #:: rest if current.exists(_ &gt;= h) =&gt; loop(rest, current) &#13;
   case h #:: rest =&gt; loop(rest, Some(h)) &#13;
 } &#13;
 loop(s, None) &#13;
} &#13;
</pre><p>This time, we used an internal tail recursive function to be able to expose a friendly API. We represent the current max value as an <code class="literal">Option[Int]</code> to handle the case where the method is called with an empty <code class="literal">Stream</code>. Note that <code class="literal">max</code> accepts <code class="literal">s</code> as a by-name parameter. This is important because, otherwise, we would be keeping a reference to the head of the <code class="literal">Stream</code> before calling the internal tail-recursive <code class="literal">loop</code> method. Another possible implementation is as follows:</p><pre class="programlisting">def max(s: =&gt; Stream[Int]): Option[Int] = { &#13;
 @tailrec &#13;
 def loop(ss: Stream[Int], current: Int): Int = ss match { &#13;
   case Stream.Empty =&gt; current &#13;
   case h #:: hs if h &gt; current =&gt; loop(hs, h) &#13;
   case h #:: hs if h &lt;= current =&gt; loop(hs, current) &#13;
 } &#13;
 &#13;
 s match { &#13;
   case Stream.Empty =&gt; None &#13;
   case h #:: rest =&gt; Some(loop(rest, h)) &#13;
 } &#13;
} &#13;
</pre><p>This implementation is arguably simpler. We check in the <code class="literal">max</code> function whether the <code class="literal">Stream</code> is empty or not; this allows us to either return right away (with <code class="literal">None</code>), or call <code class="literal">loop</code> with a valid default value (the first element in the <code class="literal">Stream</code>). The <code class="literal">loop</code> does not have to deal with <code class="literal">Option[Int]</code> anymore. However, this example does not achieve the goal of avoiding memoization. The pattern matching will cause <code class="literal">rest</code> to keep a reference on the entire tail of the original <code class="literal">Stream</code>, which will prevent garbage collection of the intermediate elements. A good practice is to only pattern match on a <code class="literal">Stream</code> inside a consuming, tail-recursive method.</p></div><div class="section" title="Stream can be infinite"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec30"/>Stream can be infinite</h3></div></div></div><p>We saw during our overview that it is possible to define an infinite <code class="literal">Stream</code>. However, you need to be careful when working with an infinite <code class="literal">Stream</code>. Some methods may cause the evaluation of the entire <code class="literal">Stream</code>, leading to <code class="literal">OutOfMemoryError</code>. Some are obvious, such as <code class="literal">toList</code>, which will try to store the entire <code class="literal">Stream</code> into a <code class="literal">List</code>, causing the realization of all the elements. Others are more subtle. For example, <code class="literal">Stream</code> has a <code class="literal">size</code> method that is similar to the one defined on <code class="literal">List</code>. Calling <code class="literal">size</code> on an infinite <code class="literal">Stream </code>will cause the program to run out of memory. Similarly, <code class="literal">max</code> and <code class="literal">sum</code> will attempt to realize the entire sequence and crash your system. This behavior is particularly dangerous as <code class="literal">Stream</code> extends <code class="literal">Seq</code>, the base trait for sequences. Consider the following code:</p><pre class="programlisting">def range(s: Seq[Int]): Int = s.max - s.min &#13;
</pre><p>This short method takes a <code class="literal">Seq[Int]</code> as single parameter, and returns its range, that is, the difference between the greatest and lowest elements. As <code class="literal">Stream</code> extends <code class="literal">Seq</code> the following call is valid:</p><pre class="programlisting">val s: Stream[Int] = ??? &#13;
range(s) &#13;
</pre><p>The compiler will happily and promptly generate the bytecode for this snippet. However, <code class="literal">s</code> could be defined as an infinite <code class="literal">Stream</code>:</p><pre class="programlisting">val s: Stream[Int] = powerOf2(0) &#13;
range(s) &#13;
java.lang.OutOfMemoryError: GC overhead limit exceeded &#13;
  at .powerOf2(&lt;console&gt;:10) &#13;
  at $anonfun$powerOf2$1.apply(&lt;console&gt;:10) &#13;
  at $anonfun$powerOf2$1.apply(&lt;console&gt;:10) &#13;
  at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1233) &#13;
  at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1223) &#13;
  at scala.collection.immutable.Stream.reduceLeft(Stream.scala:627) &#13;
  at scala.collection.TraversableOnce$class.max(TraversableOnce.scala:229) &#13;
  at scala.collection.AbstractTraversable.max(Traversable.scala:104) &#13;
  at .range(&lt;console&gt;:10) &#13;
  ... 23 elided &#13;
</pre><p>The call to <code class="literal">range</code> never returns due to the implementation of <code class="literal">max</code> and <code class="literal">min</code>. This example illustrates a good practice that we mentioned earlier in this chapter.</p></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec31"/>Summary</h1></div></div></div><p>Throughout this chapter, we explored two lazily evaluated collections that are provided by the standard Scala library: views and streams. We explored their characteristics and implementation details, as well as the limitations to bear in mind when using these abstractions. Leveraging your newly-acquired knowledge, you addressed a critical performance problem affecting MVT clients trying to view their performance trend.</p><p>In the <span class="emphasis"><em>Stream</em></span> sections, we took the opportunity to tie the concept of stream processing to event sourcing. We briefly explored the event sourcing paradigm and introduced a simple event-driven transformation pipeline to improve the architecture of the reporting system and to define a stronger domain model. Lastly, we built a Markov chain event generator to exercise our new approach to generating reports.</p><p>By exploring both eager and lazy collections, you now possess a strong working knowledge of the collections that are provided by the Scala standard library. In the next chapter, we will continue our exploration of Scala concepts viewed through the functional paradigm by diving into concurrency.</p></div></body></html>