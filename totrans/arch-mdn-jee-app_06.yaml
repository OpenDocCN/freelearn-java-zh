- en: Application Development Workflows
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用程序开发工作流程
- en: kIn the previous chapter, we saw the necessity for software companies to move
    fast. This has an impact on the infrastructure and runtime environments and on
    the way teams of engineers are working together. The motivations behind modern
    environments are scalability, flexibility and minimizing time and effort.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们看到了软件公司快速行动的必要性。这对基础设施和运行时环境以及工程师团队的合作方式都有影响。现代环境的动机在于可扩展性、灵活性和最小化时间和精力。
- en: Development workflows are even more important than the infrastructure alone.
    The whole process of writing source code until the running application is in production
    should be specified in a reasonable and productive way. Again, moving fast in
    a fast-moving world implies that these processes run automated and reliably with
    as little human intervention as possible.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 开发工作流程甚至比基础设施本身更重要。从编写源代码到运行的应用程序在生产中运行的全过程都应该以合理和高效的方式进行指定。再次强调，在快速变化的世界中快速行动意味着这些流程应该尽可能自动化和可靠地运行，尽可能减少人为干预。
- en: 'This chapter will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: The motivations and necessity of Continuous Delivery
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续交付的动机和必要性
- en: The contents of a productive pipeline
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产力管道的内容
- en: How to automate all steps involved
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何自动化所有涉及步骤
- en: How to sustainably ensure and improve software quality
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何可持续地确保和提升软件质量
- en: The required team culture and habits
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所需的团队文化和习惯
- en: Motivation and goals of productive development workflows
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产力开发工作流程的动机和目标
- en: Moving fast in terms of development workflows aims to enable fast feedback by
    fast turnarounds. In order to increase productivity, developers who work on the
    application's behavior need to verify the implemented features and bug fixes in
    a timely manner. This includes the time spent on builds, software tests, and deployments.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发工作流程中快速行动旨在通过快速周转来提供快速反馈。为了提高生产力，负责应用程序行为的开发者需要及时验证实施的功能和错误修复。这包括在构建、软件测试和部署上花费的时间。
- en: The key to productive workflows is automation. Software engineers should spend
    as much time as possible on designing, implementing, and discussing business logic
    and as little as possible on cross-cutting concerns and repetitive tasks. Computers
    are designed for quickly and reliably performing deterministic, straightforward
    tasks. Humans, however, are better at designing, thinking, and brainstorming creative
    and complex tasks. Simple, straightforward processes that don't require a lot
    of decision-making should therefore be performed by software.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 生产力工作流程的关键是自动化。软件工程师应该尽可能多地花时间在设计、实施和讨论业务逻辑上，尽可能少地花在横切关注点和重复性任务上。计算机被设计用来快速且可靠地执行确定性和直接的任务。然而，人类在设计和思考创造性、复杂任务方面更擅长。因此，不需要太多决策的简单、直接的过程应该由软件执行。
- en: Build systems are a good start. They automate compiling, resolving dependencies,
    and packaging of software projects. Continuous Integration servers take this approach
    further. They orchestrate the whole development workflow from building artifacts
    to automated testing and deployments. Continuous Integration servers are the *golden
    source of truth* of software delivery. They continuously integrate the work of
    all developers in a central place, making sure the project is in a shippable state.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 构建系统是一个良好的起点。它们自动化编译、解决依赖关系和软件项目的打包。持续集成服务器将这种方法进一步推进。它们协调整个开发工作流程，从构建工件到自动化测试和部署。持续集成服务器是软件交付的*黄金真相来源*。它们在中央位置持续集成所有开发者的工作，确保项目处于可发货状态。
- en: Continuous Delivery continues the approach of Continuous Integration by automatically
    shipping the built software to certain environments on each build. Since software
    changes have to be verified properly before they go to production, applications
    are first deployed to test and staging environments. All deployment actions have
    to make sure the environment is prepared and configured and rolled out properly.
    Automated and manual end-to-end tests make sure the software works as expected.
    Deployment to production is then done in a *half-automated* way by triggering
    the automated deployment manually.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 持续交付通过在每次构建时自动将构建的软件发送到某些环境，继续了持续集成的做法。由于软件更改在进入生产之前必须得到适当的验证，因此应用程序首先部署到测试和预生产环境中。所有部署操作都必须确保环境已准备好并正确配置，并且已正确推出。自动和手动端到端测试确保软件按预期工作。然后通过手动触发自动化部署以*半自动化*的方式将软件部署到生产环境中。
- en: The difference between Continuous Delivery and Continuous Deployment is that
    the latter automatically deploys each committed software version to production,
    if the quality requirements are met, of course.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 持续交付与持续部署之间的区别在于，后者在满足质量要求的情况下，会自动将每个提交的软件版本部署到生产环境中。
- en: All these approaches minimize the developer intervention required, minimize
    turnaround times, and improve productivity.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些方法都最大限度地减少了开发者干预的需求，最大限度地减少了周转时间，并提高了生产力。
- en: Ideally, the Continuous Delivery approach supports not only rollouts but also
    reliable rollbacks. Software versions, although verified before, sometimes need
    to be rolled back for some reason. In such a situation, there is either the way
    of rolling forward, for example, by committing a new version that will undo the
    recent changes, or by rolling back to the working state.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，持续交付方法不仅支持推出，还支持可靠的回滚。尽管软件版本在验证之前，但有时出于某些原因需要回滚。在这种情况下，可以通过提交一个将撤销最近更改的新版本，或者回滚到工作状态的方式来向前推进。
- en: As mentioned earlier, software should be built in a reliable way. All versions
    of used technology, such as build dependencies or application servers, are specified
    explicitly. Rebuilt applications and containers produce the same result. In the
    same way, pipeline steps of development workflows should result in the same outcome.
    It is crucial that the same application artifact that has been verified in test
    environments is deployed to production later on. Later in this chapter, we cover
    how to achieve reproducible, repeatable, and independent builds.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，软件应以可靠的方式进行构建。所有使用的技术的版本，例如构建依赖项或应用程序服务器，都应明确指定。重新构建的应用程序和容器会产生相同的结果。同样，开发工作流程的管道步骤也应产生相同的输出。确保在测试环境中验证过的相同应用程序工件随后被部署到生产环境中至关重要。在本章的后面部分，我们将介绍如何实现可重复、可重复和独立的构建。
- en: In terms of reliability, automated processes are an important aspect as well.
    Especially, deployments that are executed by software rather than human intervention
    are far less prone to error. All necessary pipeline steps are well defined and
    implicitly verified each and every time they are executed. This builds confidence
    into the automated processes, ultimately more than executing processes manually.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在可靠性方面，自动化流程也是一个重要方面。特别是，由软件执行而不是人为干预的部署远不太可能出错。所有必要的管道步骤都得到了很好的定义，并且在每次执行时都隐式验证。这为自动化流程建立了信心，最终比手动执行流程更可靠。
- en: Verification and testing are important prerequisites of Continuous Delivery.
    Experience shows that the vast majority of software tests can be executed in an
    automated way. The next chapter will cover this topic in depth. Besides testing,
    quality assurance also covers the software quality of the project in regard to
    architecture and code quality.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 验证和测试是持续交付的重要前提。经验表明，绝大多数软件测试都可以以自动化的方式进行执行。下一章将深入探讨这一主题。除了测试之外，质量保证还涵盖了项目在架构和代码质量方面的软件质量。
- en: Continuous Delivery workflows include all steps necessary in order to build,
    test, ship, and deploy software in a productive and automated way. Let's see how
    to build effective workflows.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 持续交付工作流程包括构建、测试、运输和以生产化和自动化的方式部署软件所需的所有步骤。让我们看看如何构建有效的工作流程。
- en: Realizing development workflows
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现开发工作流程
- en: Continuous Delivery pipelines consist of several pipeline build steps that are
    executed in sequence or in parallel, respectively. All the steps are executed
    as part of a single build. Builds are usually triggered by committing or rather
    pushing code changes into version control.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 持续交付管道由多个按顺序或并行执行的管道构建步骤组成。所有步骤都是作为单个构建的一部分执行的。构建通常由提交或更确切地说，是将代码更改推送到版本控制中触发。
- en: The following examines the aspects of a Continuous Delivery pipeline. These
    general steps are indifferent to the used technology.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 以下将探讨持续交付管道的各个方面。这些通用步骤与所使用的技术无关。
- en: 'The following diagram shows a high-level overview of a simplified Continuous
    Delivery pipeline. The steps are executed in a Continuous Integration server and
    use external repositories such as version control, artifact, and container repositories:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了简化后的持续交付管道的高级概述。这些步骤在持续集成服务器上执行，并使用外部仓库，如版本控制、工件和容器仓库：
- en: '![](img/b958f901-28cc-4ee0-bbd3-aa877f33d055.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b958f901-28cc-4ee0-bbd3-aa877f33d055.png)'
- en: Version control everything
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 版本控制一切
- en: Developers agree that source code should be kept under version control. Distributed
    version controls such as Git have been widely accepted as state-of-the-art tools.
    However, as mentioned earlier, besides application source code, there are more
    assets to track.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者普遍认为源代码应该被纳入版本控制。分布式版本控制工具，如Git，已被广泛接受为最先进的工具。然而，正如之前提到的，除了应用程序源代码外，还有更多资产需要跟踪。
- en: The motivation behind infrastructure as code is to keep all artifacts needed
    to ship the application in one central place. All changes made to the application,
    configuration, or environment are represented as code and checked in to the repository.
    Infrastructure as code leverages reproduciblity and automation. Taking this approach
    further also includes the definition of Continuous Delivery pipelines as code.
    The *Pipeline as code* section will cover this approach with the widely used Jenkins
    server as an example.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 基础设施即代码背后的动机是将所有需要部署应用程序的工件保存在一个中央位置。对应用程序、配置或环境所做的所有更改都表示为代码并提交到仓库。基础设施即代码利用可重复性和自动化。进一步采取这种方法还包括将持续交付管道定义为代码。*管道即代码*部分将以广泛使用的Jenkins服务器为例介绍这种方法。
- en: As we have seen in the previous chapter, the first principle of 12-factor applications
    is in fact to keep all files and artifacts needed to build and run the application
    in one repository.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一章中看到的，12因素应用的第一原则实际上是将构建和运行应用程序所需的所有文件和工件保存在一个仓库中。
- en: The first step of the Continuous Delivery pipeline is to check out a specific
    commit from the version control repository. Teams that use distributed version
    control systems need to synchronize the desired state to a centralized repository.
    The Continuous Integration server takes the state of a specific commit in history
    to start the build process.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 持续交付管道的第一步是从版本控制仓库检出特定的提交。使用分布式版本控制系统的团队需要将所需状态同步到集中式仓库。持续集成服务器从历史中的特定提交状态开始启动构建过程。
- en: The reason behind taking a specific commit version rather than just the latest
    state is to enable reproducibility. Rebuilding the same build version can only
    reliably result in the same outcome if the build is based on a specific commit.
    This is only possible if the build originated from checking-in to version control
    with a particular commit. Check-in actions usually trigger builds from the corresponding
    commit version.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 选择特定提交版本而不是最新状态的原因是为了实现可重复性。只有基于特定提交的构建才能可靠地产生相同的结果。这只有在构建是从带有特定提交的版本控制检查中开始的条件下才可能实现。检查入操作通常从相应的提交版本触发构建。
- en: Checking out the state of the repository provides all sources and files necessary.
    The next step is to build the software artifacts.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 检出仓库状态提供了所有必要的源代码和文件。下一步是构建软件工件。
- en: Building binaries
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建二进制文件
- en: As we have seen in the first chapter, the term binaries includes all executable
    artifacts that run the enterprise application. The project repository only contains
    source code and files and artifacts required by the infrastructure. The binaries
    are built by the Continuous Integration server.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第一章中看到的，术语二进制文件包括所有运行企业应用程序的可执行工件。项目仓库仅包含源代码和基础设施所需文件和工件。二进制文件由持续集成服务器构建。
- en: A step in the pipeline is responsible for building these binaries and making
    them accessible in a reliable way.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 管道中的一个步骤负责构建这些二进制文件并以可靠的方式使其可用。
- en: Java artifacts
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java 艺术品
- en: In Java EE, binaries first of all include the packaged enterprise application
    in form of an archive. Following the approach of zero-dependency applications
    results in building and packaging the project into a thin WAR file, containing
    only the application's business logic. This build action includes to resolve required
    dependencies, compile Java sources, and package the binary classes and other files
    into the archive. The WAR files are the first produced artifact within the build
    pipeline.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Java EE 中，二进制文件首先包括以归档形式打包的企业应用程序。遵循零依赖应用程序的方法会导致将项目构建和打包到一个薄的 WAR 文件中，其中只包含应用程序的业务逻辑。此构建操作包括解决所需的依赖项、编译
    Java 源代码，并将二进制类和其他文件打包到归档中。WAR 文件是构建管道中产生的第一个艺术品。
- en: The application artifacts are built using build systems such as Maven or Gradle,
    which are installed and executed on the CI server. Usually, the project build
    already executes basic code level tests. Tests that are executed on code level
    without requiring a container runtime can verify the behavior of classes and components
    early in the pipeline. The Continuous Delivery approach of failing fast and breaking
    the build as early as possible minimizes turnaround times.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序艺术品使用 Maven 或 Gradle 等构建系统构建，这些系统安装在 CI 服务器上并执行。通常，项目构建已经执行了基本的代码级别测试。无需容器运行时即可在代码级别执行的测试可以在管道早期验证类和组件的行为。快速失败和尽可能早地中断构建的持续交付方法最小化了周转时间。
- en: If required, build systems can publish the artifacts onto an artifact repository.
    Artifact repositories, such as **Sonatype Nexus** or **JFrog Artifactory**, save
    the built artifact versions for later retrieval. However, if the application is
    shipped in Linux containers, the artifact doesn't necessarily have to be deployed
    onto a repository.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，构建系统可以将艺术品发布到艺术品仓库。例如，**Sonatype Nexus** 或 **JFrog Artifactory** 这样的艺术品仓库保存构建的艺术品版本以供以后检索。然而，如果应用程序以
    Linux 容器形式分发，艺术品不一定需要部署到仓库。
- en: As shown in Chapter 2, *Designing and Structuring Java Enterprise Applications*,
    a Java project is built using Maven via the command `mvn package`. The package
    phase compiles all Java production sources, compiles and executes the test sources,
    and packages the application in our case, to a WAR file. The CI server executes
    a build system command similar to this to build the artifact in its local workspace
    directory. The artifact can be deployed to an artifact repository, for example,
    using the `mvn deploy` command, to be used in subsequent steps; or it will be
    taken directly from the workspace directory.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如第 2 章所示，*设计和结构化 Java 企业应用程序*，Java 项目通过命令 `mvn package` 使用 Maven 构建。包阶段编译所有
    Java 生产源代码，编译和执行测试源代码，并将应用程序（在我们的例子中）打包到 WAR 文件中。CI 服务器执行类似此命令的构建系统命令，在本地工作区目录中构建艺术品。可以使用
    `mvn deploy` 命令将艺术品部署到艺术品仓库，用于后续步骤；或者它可以直接从工作区目录中获取。
- en: Artifact versions
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 艺术品版本
- en: As mentioned earlier, the build systems need to produce artifacts in a reliable
    way. This requires that Java artifacts are built and archived with a distinct
    version, which is identifiable later on. Software tests verify specific versions
    of enterprise applications. Later deployments need to refer the identical versions
    in later build steps as well. Being able to identify and refer to distinct artifact
    versions is necessary. This is true for all binaries.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，构建系统需要以可靠的方式生成艺术品。这要求 Java 艺术品以独特的版本构建和归档，以便以后可以识别。软件测试验证企业应用程序的特定版本。后续部署需要引用后续构建步骤中的相同版本。能够识别和引用不同的艺术品版本是必要的。这对于所有二进制文件都适用。
- en: One of the 12-factor principles is to explicitly declare dependencies, not only
    for dependencies being used but also in regard to their versions. As mentioned
    earlier, the same holds true for container builds. Specified Docker base images
    as well as installed software should be explicitly, uniquely identified by their
    versions.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 12 个因素原则之一是明确声明依赖项，不仅适用于正在使用的依赖项，还适用于它们的版本。如前所述，这对于容器构建同样适用。指定的 Docker 基础镜像以及安装的软件应通过它们的版本明确、唯一地标识。
- en: It is quite common, however, to specify Java builds as *snapshot* versions,
    for example, `0.1-SNAPSHOT`. A snapshot, as opposed to a release version, represents
    a software state which is currently being developed. Dependency resolution always
    attempts to include the latest snapshot when several snapshot versions are existent,
    comparable to the Docker `latest` tag. The workflow behind snapshots is to release
    the snapshot version to a uniquely numbered version, once the level of development
    is sufficient.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，指定Java构建为快照版本是很常见的，例如，`0.1-SNAPSHOT`。与发布版本不同，快照代表当前正在开发的软件状态。依赖关系解析始终尝试在存在多个快照版本时包含最新的快照，类似于Docker的`latest`标签。快照背后的工作流程是在开发水平足够时，将快照版本发布到唯一编号的版本。
- en: However, snapshot versioning contradicts the idea of Continuous Delivery. In
    CD pipelines every commit is a potential candidate for production deployment.
    Snapshot versions are naturally not meant to be deployed on production. This implies
    that the workflow would need to change the snapshot to a release version, once
    the software version has been sufficiently verified. However, once built, Java
    artifacts are not meant to be changed. The same artifact that has been verified
    should be used for deployment. Therefore, snapshot versions do not fit Continuous
    Delivery pipelines.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，快照版本与持续交付的理念相矛盾。在持续交付管道中，每个提交都是一个潜在的生产部署候选者。快照版本自然不适用于生产部署。这意味着工作流程需要将快照版本更改为发布版本，一旦软件版本得到充分验证。然而，一旦构建完成，Java工件就不应该被更改。经过验证的相同工件应该用于部署。因此，快照版本不适合持续交付管道。
- en: Following the widely adopted approach of **semantic versioning**, application
    developers need to take care of their versions in regard to backward-compatibility.
    A semantic versioning describes software versions such as `1.1.0`, `1.0.0-beta`,
    or `1.0.1+b102`. In order to represent versions that are both eligible for Continuous
    Delivery and provide semantic versioning metadata, properly numbered versions
    with unique build metadata are a good solution. An example is `1.0.1+b102`, for
    *major* version `1`, *minor* version `0`, *patch* version `1`, and build number
    `102`. The part after the plus sign represents the optional build metadata. Even
    if the semantic version was not changed in between a number of builds, the produced
    artifacts are still identifiable. The artifacts can be published to an artifact
    repository and retrieved via these version numbers later on.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循广泛采用的语义版本化方法，应用开发者需要关注其版本的向后兼容性。语义版本化描述了如`1.1.0`、`1.0.0-beta`或`1.0.1+b102`这样的软件版本。为了表示既适用于持续交付又提供语义版本化元数据的版本，带有唯一构建元数据的正确编号版本是一个很好的解决方案。例如，`1.0.1+b102`表示*主版本*为`1`、*次版本*为`0`、*修订版本*为`1`和构建编号`102`。加号后面的部分代表可选的构建元数据。即使在一连串构建中语义版本没有改变，产生的工件仍然可以识别。这些工件可以被发布到工件仓库，并通过这些版本号在以后检索。
- en: This versioning approach targets enterprise application projects rather than
    products. Products which have multiple shipped and supported versions at a time,
    require to have more complex versioning workflows.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这种版本化方法针对的是企业级应用项目，而不是产品。同时拥有多个已发布和受支持版本的产品，需要更复杂的版本化工作流程。
- en: At the time of writing, there isn't a de facto standard for versioning containers
    yet. Some companies follow a semantic versioning approach whereas others exclusively
    use CI server build numbers or commit hashes. All of these approaches are valid,
    as long as container images aren't rebuilt or distributed using the same tag twice.
    A single build must result in a distinct container image version.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，还没有关于容器版本化的既定标准。一些公司遵循语义版本化方法，而其他公司则仅使用CI服务器构建编号或提交哈希。所有这些方法都是有效的，只要容器镜像不使用相同的标签重建或分发两次。单个构建必须产生一个独特的容器镜像版本。
- en: Building containers
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建容器
- en: Container images also represent binaries, since they contain the running application,
    including runtime and operating system binaries. In order to build container images,
    base images and all artifacts that are added at build time need to be present.
    If they don't already exist on the build environment, base images are retrieved
    implicitly.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 容器镜像也代表二进制文件，因为它们包含了运行中的应用程序，包括运行时和操作系统二进制文件。为了构建容器镜像，需要存在基础镜像以及所有在构建时添加的工件。如果它们在构建环境中不存在，基础镜像会隐式地被检索。
- en: For each build step defined in the Dockerfile, an image layer is added on top
    of the previous layer. Last but not least, the application that was built just
    before is added to the container image build. As shown previously, Java EE application
    containers consist of an installed and configured application server that auto-deploys
    the web archive at runtime.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在Dockerfile中定义的每个构建步骤，都会在上一层之上添加一个镜像层。最后但同样重要的是，将刚刚构建的应用程序添加到容器镜像构建中。如前所述，Java
    EE应用程序容器由一个安装和配置的应用服务器组成，该服务器在运行时自动部署Web存档。
- en: This image build is orchestrated by the CI server as part of the pipeline. One
    solution is to have the Docker runtime installed, in the same way as the Maven
    build system. The pipeline step then simply invokes an image build similar to
    `docker build -t docker.example.com/hello-cloud:1 .` in the job workspace directory.
    The Docker image build, for example, takes the WAR file under Maven's `target`
    directory and adds it into the container.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这个镜像构建是由CI服务器作为流水线的一部分来执行的。一个解决方案是安装Docker运行时，就像Maven构建系统一样。然后，流水线步骤简单地调用在作业工作空间目录中的类似`docker
    build -t docker.example.com/hello-cloud:1 .`的镜像构建。例如，Docker镜像构建会将Maven的`target`目录下的WAR文件添加到容器中。
- en: The built image is tagged with an image name and unique tag, depending on the
    build number or some other unique information. Docker image names imply the registry
    they will be pushed to. An image identifier such as `docker.example.com/hello-cloud:1`
    will implicitly be transmitted from and to the host `docker.example.com`. The
    pipeline pushes the image to the Docker registry in most cases, a company-specific
    registry.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 构建的镜像会根据构建号或其他唯一信息标记为镜像名称和唯一标记。Docker镜像名称暗示了它们将被推送到哪个注册表。例如，`docker.example.com/hello-cloud:1`这样的镜像标识符将隐式地从主机`docker.example.com`传输。在大多数情况下，流水线会将镜像推送到Docker注册表，通常是公司特定的注册表。
- en: Depending on the company's workflow, Docker images can be re-tagged as part
    of the pipeline as well. For example, special tags such as the `latest` tag can
    refer to the actual *latest* built versions and so on. This is accomplished by
    explicitly re-tagging the image, so that two identifiers point to the same image.
    Unlike Java archives, Docker images can be re-tagged without changing their contents.
    The second tag needs to be pushed to the repository, as well. However, the rest
    of this chapter will show you that it's not required to refer to images using
    *latest* versions, such as the Docker `latest` tag. In fact, similar to snapshot
    versioning it's advisable to avoid *latest* versions. Being explicit in all artifact
    versions is less prone to error.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 根据公司的流程，Docker镜像也可以作为流水线的一部分进行重新标记。例如，特殊的标记，如`latest`标记，可以指向实际构建的最新版本等。这是通过显式重新标记镜像来实现的，使得两个标识符指向同一个镜像。与Java归档不同，Docker镜像可以在不更改其内容的情况下重新标记。第二个标记还需要推送到仓库。然而，本章的其余部分将向您展示，使用*latest*版本，如Docker的`latest`标记来引用镜像并不是必需的。实际上，与快照版本类似，建议避免使用*latest*版本。在所有工件版本中保持明确性可以减少错误的可能性。
- en: Some engineers argue that running Docker builds inside the CI server may not
    be the best idea if the CI server itself runs as a Docker container. Docker image
    builds start temporarily running containers. It is certainly possible to either
    run containers in a container or connect the runtime to another Docker host, without
    opening the whole platform to potential security concerns. However, some companies
    choose to build the images outside of the CI server instead. For example, OpenShift,
    a PaaS built on top of Kubernetes, provides build functionality that comprises
    a CI server as well as image builds. It is therefore possible to orchestrate image
    builds from the CI server which are then built in the OpenShift platform. This
    provides an alternative to building container images directly on the CI server.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一些工程师认为，如果CI服务器本身运行在Docker容器中，在CI服务器内部运行Docker构建可能不是最佳选择。Docker镜像构建会临时运行容器。当然，可以在容器中运行容器或将运行时连接到另一个Docker主机，而不必将整个平台暴露于潜在的安全风险。然而，一些公司选择在CI服务器之外构建镜像。例如，OpenShift，一个建立在Kubernetes之上的PaaS，提供了包含CI服务器和镜像构建功能的构建功能。因此，可以从CI服务器编排镜像构建，然后在OpenShift平台上构建。这为在CI服务器上直接构建容器镜像提供了另一种选择。
- en: Quality assurance
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 质量保证
- en: The Java artifact build already performs some basic quality assurance. It executes
    included code level tests, such as unit tests. A reasonable pipeline consists
    of several test scopes and scenarios, all with slightly different strengths and
    weaknesses. The included unit tests operate at code level and can be executed
    without any further running environment. They aim to verify the behavior of the
    individual classes and components and provide fast feedback in case of test failures.
    We will see in the next chapter that unit tests need to run self-sufficiently
    and fast.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Java工件构建已经执行了一些基本的质量保证。它执行包含的代码级别测试，例如单元测试。一个合理的管道由几个测试范围和场景组成，它们都有略微不同的优势和劣势。包含的单元测试在代码级别运行，可以在没有任何进一步运行环境的情况下执行。它们的目的是验证单个类和组件的行为，并在测试失败的情况下提供快速反馈。我们将在下一章中看到，单元测试需要独立且快速地运行。
- en: Test results are usually recorded from the CI server for visibility and monitoring
    reasons. Making the outcome of the pipeline steps visible is an important aspect
    of Continuous Delivery. The CI server can track the number of passed unit tests
    and show trends over time.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 测试结果通常从CI服务器记录下来，以便于可见性和监控。使管道步骤的结果可见是持续交付的重要方面。CI服务器可以跟踪通过的单位测试数量，并显示随时间的变化趋势。
- en: There are build system plugins available that track the code coverage of the
    executed tests. The coverage shows which parts of the code base have been executed
    during the test runs. Generally speaking, a greater code coverage is desirable.
    However, a high percentage of coverage alone tells nothing about the quality of
    tests and coverage of test assertions. The test results, together with their coverage,
    are just one of a few quality characteristics.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的构建系统插件可以跟踪执行测试的代码覆盖率。覆盖率显示了在测试运行期间代码库的哪些部分已被执行。一般来说，更高的代码覆盖率是可取的。然而，覆盖率的高百分比本身并不能说明测试的质量和测试断言的覆盖率。测试结果及其覆盖率只是几个质量特性之一。
- en: Source code can already provide a lot of information about the software's quality.
    So-called **static code analysis** performs certain quality checks on the static
    source code files of the project without executing them. This analysis gathers
    information about code statements, class and method sizes, dependencies between
    classes and packages, and complexity of methods. Static code analysis can already
    find potential errors in the source code, such as resources that are not properly
    closed.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 源代码已经可以提供关于软件质量的很多信息。所谓的**静态代码分析**在项目静态源代码文件上执行某些质量检查，而不执行它们。这种分析收集有关代码语句、类和方法的大小、类和包之间的依赖关系以及方法复杂性的信息。静态代码分析已经可以在源代码中找到潜在的错误，例如未正确关闭的资源。
- en: '**SonarQube** is one of the most well-known code quality tools. It provides
    information about the quality of software projects by correlating the results
    of different analysis methods, such as static code analysis or test coverage.
    The merged information is used to provide helpful quality metrics for software
    engineers and architects. For example, which methods are complex but at the same
    time sufficiently tested? Which components and classes are the biggest in size
    and complexity and therefore candidates to be refactored? Which packages have
    cyclic dependencies and likely contain components that should be merged together?
    How does the test coverage evolve over time? How many code analysis warnings and
    errors are there and how does this number evolve over time?'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**SonarQube** 是最知名的代码质量工具之一。它通过关联不同分析方法的结果，如静态代码分析或测试覆盖率，来提供关于软件项目质量的信息。合并的信息被用来为软件工程师和架构师提供有用的质量指标。例如，哪些方法是复杂的但同时又经过充分测试的？哪些组件和类在大小和复杂性方面最大，因此是重构的候选者？哪些包存在循环依赖，可能包含应该合并在一起的组件？测试覆盖率是如何随时间演变的？有多少代码分析警告和错误，以及这个数字是如何随时间演变的？'
- en: It's advisable to follow some basic guidelines regarding static code analysis.
    Some metrics just give insights in terms of rough ideas about the software quality.
    Test coverage is such an example. A project with high coverage does not necessarily
    imply well-tested software; the assertion statements could be impractical or insufficient.
    However, the trend of test coverage does give an idea about the quality, for example,
    whether software tests are added for new and existing functionality and bug fixes.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循一些关于静态代码分析的基本指南是明智的。一些指标只是从粗略的角度提供了关于软件质量的见解。测试覆盖率就是一个例子。覆盖率高的项目并不一定意味着软件经过良好的测试；断言语句可能是不切实际的或不足够的。然而，测试覆盖率的趋势确实可以提供关于质量的信息，例如，软件测试是否添加了新的和现有的功能以及错误修复。
- en: There are also metrics that should be strictly followed. Code analysis warnings
    and errors are one of these. Warnings and errors tell engineers about code style
    and quality violations. They are indicators about issues that need to be fixed.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 也有一些指标应该严格遵守。代码分析警告和错误就是其中之一。警告和错误会告诉工程师有关代码风格和质量违规的问题。它们是关于需要修复的问题的指标。
- en: First of all, there should be no such things as compilation or analysis warnings.
    Either the build passes the quality checks sufficiently, a *green traffic light*;
    or the quality is not sufficient for deployment, a *red traffic light*. There
    is nothing reasonable in between. Software teams need to clarify which issues
    are plausible and to be resolved and which aren't. Warnings that indicate minor
    issues in the project therefore are treated as errors; if there is a good reason
    to resolve them, then the engineers have to, otherwise the build should fail.
    If the detected error or warning represents a *false positive*, it won't be resolved;
    instead, it has to be ignored by the process. In that case, the build is successful.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，不应该有编译或分析警告。要么构建通过了足够的质量检查，一个**绿灯**；要么质量不足以部署，一个**红灯**。两者之间没有合理的中间状态。软件团队需要明确哪些问题是合理的并且需要解决，哪些不是。因此，项目中表明轻微问题的警告被视为错误；如果有充分的理由解决它们，工程师必须这样做，否则构建应该失败。如果检测到的错误或警告代表了一个**假阳性**，它不会被解决；相反，它必须由过程忽略。在这种情况下，构建是成功的。
- en: Following this approach enables a **zero-warning policy**. Project builds and
    analyses that contain a lot of errors and warnings all the time, even if they
    are not critical, introduce certain issues. The existing warnings and errors obfuscate
    the quality view of the project. Engineers won't be able to tell on the first
    look whether the hundreds of issues are actually issues or not. Besides that,
    having a lot of issues already demotivates engineers to fix newly introduced warnings
    at all. For example, imagine a house that is in a terrible condition, with damaged
    walls and broken windows. Nobody would care if another window gets broken or not.
    But a recently broken window of an otherwise pristine house that has been taken
    good care of urges the person in charge to take action. The same is true for software
    quality checks. If there are hundreds of warnings already, nobody cares about
    that last commit's newly introduced violation. Therefore, the number of project
    quality violation should be zero. Errors in builds or code analyses should break
    the pipeline build. Either the project code needs to be fixed or the quality rules
    need to be adjusted for the issue to be resolved.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 采用这种方法可以实现**零警告政策**。项目构建和分析中始终存在大量错误和警告，即使它们不是关键的，也会引入某些问题。现有的警告和错误会模糊项目的质量视图。工程师无法一眼看出数百个问题是否真的是问题。此外，已经存在大量问题会削弱工程师修复新引入的警告的积极性。例如，想象一个房屋状况极差，墙壁损坏，窗户破碎。如果再有一扇窗户破碎，没有人会在意。但是，一个最近破碎的窗户，而其他方面都保养得很好的房子，会促使负责人采取行动。对于软件质量检查也是如此。如果有数百个警告，没有人会关心最后一次提交中新引入的违规行为。因此，项目的质量违规数量应该是零。构建或代码分析中的错误应该中断管道构建。要么项目代码需要修复，要么需要调整质量规则以解决问题。
- en: Code quality tools such as SonarQube are integrated in a build pipeline step.
    Since the quality analysis operates on static input only, the step can easily
    be parallelized to the next pipeline steps. If the quality gate does not accept
    the result, the build will fail and the engineers need resolve the issue before
    continuing development. This is an important aspect to integrate quality into
    the pipeline. The analysis should not only give insights but also actively prevent
    the execution to force action.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 代码质量工具，如SonarQube，在构建管道步骤中集成。由于质量分析仅操作静态输入，该步骤可以轻松并行化到下一个管道步骤。如果质量门不接受结果，构建将失败，工程师需要在继续开发之前解决该问题。这是将质量集成到管道中的重要方面。分析不仅应该提供见解，还应该积极阻止执行以强制采取行动。
- en: Deployment
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署
- en: After the binaries have been built and after, or during, the software quality
    is being verified, the enterprise application will be deployed. There are usually
    several environments for testing purposes, depending on the project circumstances,
    such as test or staging and, of course, production. As mentioned earlier, these
    environments should be as similar as possible. This vastly simplifies the deployment
    process orchestrated by the CI server.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建二进制文件之后，或在软件质量正在验证期间，企业应用程序将被部署。根据项目情况，通常有几个用于测试目的的环境，例如测试或预发布，当然还有生产环境。如前所述，这些环境应尽可能相似。这大大简化了CI服务器编排的部署过程。
- en: The process of deploying the application generally takes the binaries in the
    version that has just been built and deploys them onto the environment. Depending
    on what the infrastructure looks like, this can take place using plain scripts
    or more sophisticated technology. The principle should be the same, the binaries
    as well as the configuration are made available to the environment in an automated
    and reliable way. Preparation steps that are potentially required by the application
    or the environment will be executed in this step as well.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 部署应用程序的过程通常涉及将刚刚构建的版本中的二进制文件部署到环境中。根据基础设施的外观，这可以通过简单的脚本或更复杂的技术来实现。原则应该是相同的，二进制文件以及配置应以自动和可靠的方式提供给环境。在这个步骤中，还将执行应用程序或环境可能需要的潜在准备步骤。
- en: Modern environments such as container orchestration frameworks support infrastructure
    as code. Infrastructure configuration is captured in files in the project's repository
    and applied to all environments at deployment time. Potential differences, such
    as Kubernetes config maps contents, are represented as different manifestations
    in the repository as well.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现代环境，例如容器编排框架，支持基础设施即代码。基础设施配置被捕获在项目仓库中的文件中，并在部署时应用于所有环境。潜在差异，例如Kubernetes配置映射的内容，也在仓库中以不同的表现形式表示。
- en: Using IaC as well as containers provides even more reliability than home-grown
    shell scripts. The application should always be rolled out in an idempotent way,
    independent of which state the environment was in. Since container images contain
    the whole stack, the outcome is the same as if the software was installed from
    scratch. Required environment configuration is applied from IaC files as well.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用IaC以及容器比自制的shell脚本提供更高的可靠性。应用程序应始终以幂等的方式部署，无论环境处于何种状态。由于容器镜像包含整个堆栈，结果与从头开始安装软件相同。所需的环境配置也通过IaC文件应用。
- en: New container image versions can be deployed by orchestration frameworks in
    many ways. There are certain commands that explicitly set Docker images used in
    Kubernetes deployments. However, in order to fulfill the requirement of reliability
    and reproducibility, it makes sense to only edit the infrastructure as code files
    and apply them on the cluster. This ensures that the configuration files stay
    the single source of truth. The CI server can edit the image definitions in the
    IaC files and commit the changes to the VCS repository.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 新的容器镜像版本可以通过编排框架以多种方式部署。有一些命令会明确设置Kubernetes部署中使用的Docker镜像。然而，为了满足可靠性和可重复性的要求，只编辑基础设施即代码文件并在集群上应用它们是有意义的。这确保了配置文件是唯一的真相来源。CI服务器可以编辑IaC文件中的镜像定义，并将更改提交到VCS仓库。
- en: 'As seen in the previous chapter, Docker images are specified in Kubernetes
    deployment definitions:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章所述，Docker镜像在Kubernetes部署定义中指定：
- en: '[PRE0]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: These image definitions are updated within the CI server process and applied
    to the Kubernetes cluster. The CI server executes Kubernetes commands via the
    `kubectl` CLI. This is the standard way to communicate with Kubernetes clusters.
    `kubectl apply -f <file>` applies the infrastructure as code contents of a file
    or directory containing YAML or JSON definitions. The pipeline step executes a
    command similar to this, providing the updated Kubernetes files which were updated
    in the project repository.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Following this approach enables that infrastructure as code files both contain
    the current state of the environments as well as changes made by engineers. All
    updates are rolled out by applying the Kubernetes files in the corresponding version
    to the cluster. The cluster aims to satisfy the new desired state, containing
    the new image version, and will therefore perform a rolling update. After triggering
    this the update, the CI server validates whether the deployment has been executed
    successfully. Kubernetes rollout actions can be followed by commands similar to
    `kubectl rollout status <deployment>`, which waits until the deployment is either
    rolled out successfully, or failed.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: This procedure is executed on all environments. If single deployment definitions
    are used for several environments, the image tag definition only has to be updated
    once, of course.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: 'To give a more concrete example, the following shows a potential configuration
    file structure of a Maven project:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aa21a40d-2b34-45f4-a5c2-4bfa4b5e9c86.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
- en: The `hello-cloud.yaml` file contains multiple Kubernetes resource definitions.
    This is possible by separating each YAML object definitions with a three-dashed
    line (`---`). It's equally doable to provide separate files for each resource
    type, such as `deployment.yaml`, `service.yaml`, and so on. Kubernetes can handle
    both approaches. The `kind` type definitions in the YAML objects indicate the
    type of the resource.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: The previous chapter showed how container orchestration frameworks enable zero-downtime
    deployments out of the box. Applying new image versions to the environments orchestrated
    by the CI server also accomplishes this goal. The environments will therefore
    be able to serve traffic with at least one active application at a time. This
    approach is especially important for production environments.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Configuration
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ideally, infrastructure as code covers all aspects required to define the whole
    environment, including runtimes, networking, and configuration. Using container
    technologies and container orchestration greatly supports and simplifies this
    approach. As mentioned earlier, confidential content such as credentials should
    not be put under version control. This should be configured manually on the environment
    by an administrator.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: 'Configuration that differs in several environments can be represented using
    multiple files in the project repository. For example, it makes sense to include
    subfolders for each environment. The following image shows an example:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在多个环境中不同的配置可以使用项目存储库中的多个文件来表示。例如，为每个环境包含子文件夹是有意义的。以下图像展示了示例：
- en: '![](img/90519667-dfc0-4342-9896-3edeb17e8f4f.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![示例图像](img/90519667-dfc0-4342-9896-3edeb17e8f4f.png)'
- en: 'The contents of the `configmap.yaml` file include the specific config map contents
    as well as potentially different namespace definitions. As mentioned in the previous
    chapter, Kubernetes namespaces are a way to differentiate environments. The following
    code shows an example of a specific production config map:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`configmap.yaml` 文件的内容包括特定的配置映射内容以及可能的不同命名空间定义。如前一章所述，Kubernetes 命名空间是一种区分环境的方式。以下代码展示了特定生产配置映射的示例：'
- en: '[PRE1]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Credentials
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 凭证
- en: Due to security reasons, secret content such as credentials is typically not
    included in the project repository. An administrator usually configures them manually
    on the specific environments. Similar to other Kubernetes resources, secrets are
    bound to a specific namespace.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 由于安全原因，通常不会在项目存储库中包含秘密内容，如凭证。管理员通常会在特定环境中手动配置它们。与其他 Kubernetes 资源类似，秘密绑定到特定的命名空间。
- en: If a project requires multiple secrets, for example, specific credentials for
    various external systems, manually configuring them can become cumbersome and
    difficult to keep track of. Configured secrets have to be documented and tracked
    in a secure form, external to the project repository.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个项目需要多个秘密，例如，针对各种外部系统的特定凭证，手动配置它们可能会变得繁琐且难以跟踪。配置的秘密必须以安全的形式进行文档化和跟踪，且在项目存储库之外。
- en: Another approach is to store encrypted credentials that can be decrypted using
    a single master key in the repository. The repository can therefore safely contain
    the configured credentials, in encrypted form, and still be safe from disclosing
    the secrets. The running application will use the dynamically provided master
    key to decrypt the configured credentials. This approach provides security as
    well as manageability.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是在存储库中存储加密凭证，这些凭证可以使用单个主密钥解密。因此，存储库可以安全地包含配置的凭证，以加密形式存在，同时仍然安全，不会泄露秘密。运行中的应用程序将使用动态提供的主密钥来解密配置的凭证。这种方法提供了安全性和可管理性。
- en: Let's look at a potential solution. Encrypted configuration values can safely
    be stored in Kubernetes config maps, since the decrypted values will only be visible
    to the container process. The project can define the encrypted credentials together
    with other configuration values in the config maps definitions as code. An administrator
    adds a secret to each environment, containing the master key which was used to
    symmetrically encrypt the credentials. This master key is provided to the running
    container, for example, using environment variables as seen earlier. The running
    application uses this single environment variable to decrypt all encrypted credential
    values.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个潜在的解决方案。加密的配置值可以安全地存储在 Kubernetes 配置映射中，因为解密后的值只会对容器进程可见。项目可以在配置映射定义中将加密凭证与其他配置值一起定义为代码。管理员为每个环境添加一个包含用于对称加密凭证的主密钥的秘密。这个主密钥被提供给运行中的容器，例如，使用前面看到的作为环境变量。运行中的应用程序使用这个单一的环境变量来解密所有加密的凭证值。
- en: Depending on the used technology and algorithm, one solution is to use the Java
    EE application to decrypt the credentials directly when loading properties files.
    To provide a secure solution using recent encryption algorithms, the **Java Cryptographic
    Extensions** (**JCE**) should be installed in the runtime. Another approach is
    to decrypt the values before the application is being deployed.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 根据所使用的技术和算法，一个解决方案是在加载属性文件时直接使用 Java EE 应用程序解密凭证。为了提供一个使用最新加密算法的安全解决方案，应在运行时安装**Java
    密码学扩展**（**JCE**）。另一种方法是部署应用程序之前先解密值。
- en: Data migration
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据迁移
- en: Applications that use a database to store their state are bound to a specific
    database schema. Changes in the schema usually require the application model to
    change and vice versa. With an application being actively developed and a domain
    model being continuously refined and refactored, the model will eventually require
    the database schema to change. New model classes or properties thereof which are
    added need to be persisted in the database as well. Classes and properties that
    are refactored or removed should be migrated in the database also, so that the
    schema doesn't diverge.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数据库存储其状态的程序绑定到特定的数据库模式。通常，模式的变化需要应用程序模型进行更改，反之亦然。随着应用程序的积极开发和领域模型的持续精炼和重构，模型最终将需要数据库模式进行更改。新添加的模型类或其属性需要也在数据库中持久化。重构或删除的类和属性也应该在数据库中进行迁移，以避免模式出现分歧。
- en: However, data migrations are more difficult than code changes. Stateless applications
    can simply be replaced by new versions thereof, containing the new functionality.
    A database that contains the application's state, however, needs to carefully
    migrate the state when the schema changes.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，数据迁移比代码更改更困难。无状态应用程序可以简单地用新版本替换，其中包含新的功能。然而，包含应用程序状态的数据库需要在模式更改时仔细迁移状态。
- en: This happens in migration scripts. Relational databases support altering their
    tables while keeping the data intact. These scripts are executed before the new
    version of the software is deployed, making sure the database schema matches the
    application.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况发生在迁移脚本中。关系型数据库支持在保持数据完整性的同时更改其表。这些脚本在部署软件的新版本之前执行，确保数据库模式与应用程序匹配。
- en: There is an important aspect to keep in mind when deploying applications using
    a zero-downtime approach. Rolling updates will leave at least one active instance
    running in the environment at a time. This results in having both the old and
    the new software version active for a short period of time. The orchestration
    should take care that the applications are gracefully started and shut down, respectively,
    letting in-flight requests finish their work. Applications that connect to a central
    database instance will result in several versions of the application simultaneously
    accessing the database. This requires the application to support so-called **N-1
    compatibility**. The current application version needs to function with the same
    database schema version plus and minus one version, respectively.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用零停机时间方法部署应用程序时，需要记住一个重要的方面。滚动更新将至少在环境中同时运行一个活动实例。这导致旧软件版本和新软件版本在短时间内同时激活。编排应该注意，应用程序应该优雅地启动和关闭，分别让正在进行的请求完成其工作。连接到中央数据库实例的应用程序将导致多个应用程序版本同时访问数据库。这要求应用程序支持所谓的**N-1兼容性**。当前的应用程序版本需要与加上和减去一个版本的相同数据库模式版本一起工作。
- en: To support N-1 compatibility, the rolling update approach needs to both deploy
    a new application version and to updates the database schema, making sure the
    versions do not differ more than one version. This implies that, the corresponding
    database migrations are executed just before the application deployment takes
    place. The database schema, as well as the application, therefore evolves in small
    migration steps, not in jumps.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了支持N-1兼容性，滚动更新方法需要同时部署新的应用程序版本和更新数据库模式，确保版本之间的差异不超过一个版本。这意味着，相应的数据库迁移将在应用程序部署之前执行。因此，数据库模式和应用程序都通过小迁移步骤而不是跳跃式地发展。
- en: This approach, however, is not trivial and involves certain planning and caution.
    Especially, application version rollbacks require particular attention.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法并不简单，涉及一定的规划和谨慎。特别是，应用程序版本回滚需要特别注意。
- en: Adding database structures
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加数据库结构
- en: Adding tables or table columns to a database schema is comparatively straightforward.
    The new table or column does not collide with older application versions, since
    they are unknown to them.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 向数据库模式添加表或表列相对简单。新的表或列不会与旧的应用程序版本冲突，因为它们对它们来说是未知的。
- en: New tables that resulted from new domain entities can simply be added to the
    schema, resulting in version *N+1*.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 由新的领域实体产生的新表可以直接添加到模式中，从而产生版本*N+1*。
- en: New table columns that define certain constraints, such as *not null* or *unique*,
    need to take care of the current state of the table. The old application version
    can still write to the table; it will ignore the new column. Therefore, constraints
    can not necessarily be satisfied. New columns first need to be *nullable* and
    without further constraints. The new application version has to deal with empty
    values in that column, presumably `null` values, which originate from the old
    application version.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 定义某些约束（如 *not null* 或 *unique*）的新表列需要考虑表当前的状态。旧的应用程序版本仍然可以向表中写入；它将忽略新列。因此，约束不一定能够满足。新列首先必须是
    *可空的* 并且没有其他约束。新的应用程序版本必须处理该列中的空值，可能是来自旧应用程序版本的 `null` 值。
- en: Only the next version (*N+2*) will then, after the current deployment has been
    completed, contain the correct constraints. This means that adding a column that
    defines constraints needs at least two separate deployments. The first deployment
    adds the column and enhances the application's model in a `null`-safe way. The
    second deployment makes sure all contained values fulfill the column constraints,
    adds the constraints, and removes the `null`-safe behavior. These steps are, of
    course, only required, if the column target state defines constraints.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在当前部署完成后，下一个版本（*N+2*）才会包含正确的约束。这意味着添加定义约束的列至少需要两个单独的部署。第一个部署添加了列，并以 `null`-安全的方式增强了应用程序的模型。第二个部署确保所有包含的值满足列约束，添加约束，并移除
    `null`-安全行为。当然，这些步骤仅在列的目标状态定义约束时才是必需的。
- en: Rollbacks to the old versions work in a similar way. Rolling back to the intermediate
    deployment (*N+2* to *N+1*) requires the constraints to be removed again.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 回滚到旧版本的方式类似。回滚到中间部署（从 *N+2* 到 *N+1*）需要再次移除约束。
- en: 'Rolling back to the original state (*N+0*) would remove the whole column. However,
    data migrations should not remove data that is not transferred somewhere else.
    Rolling back to the state without the column could also simply leave the column
    untouched so as not to lose data. The question the business experts have to answer
    is: What happens with the data that was added in the meantime? Intentionally not
    deleting this data could be a reasonable approach. However, when the column is
    added again, the rollout script needs to take already existing columns into consideration.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 回滚到原始状态（*N+0*）将删除整个列。然而，数据迁移不应删除未转移到其他地方的数据。回滚到没有列的状态也可以简单地不更改列，以避免丢失数据。业务专家必须回答的问题是：在此期间添加的数据会发生什么？故意不删除这些数据可能是一个合理的方法。然而，当再次添加列时，滚动脚本需要考虑已存在的列。
- en: Changing database structures
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更改数据库结构
- en: Changing existing database tables or columns is more complex. Whether columns
    are renamed or changed in type or constraint, the transitions have to be executed
    in several steps. Directly renaming or changing columns would lead to incompatibilities
    with the deployed application instances; changes require intermediate columns.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 更改现有的数据库表或列更为复杂。无论是重命名列还是更改类型或约束，过渡必须在几个步骤中执行。直接重命名或更改列会导致与已部署的应用程序实例不兼容；更改需要中间列。
- en: Let's examine this approach using an example. Assume the car entity has a property
    *color*, which must be set, represented in the database column `color`. Assuming
    it will be refactored to the name *chassis color* or `chassis_color` in the database
    column.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个例子来检查这种方法。假设汽车实体有一个属性 *color*，必须设置，在数据库列 `color` 中表示。假设它将被重构为数据库列中的 *chassis
    color* 或 `chassis_color`。
- en: Similar to the previous approach, the change is executed in several deployments.
    The first deployment adds a nullable column `chassis_color`. The application code
    is enhanced to use the new model property. Since the older application version
    doesn't know about the property yet, it is not reliably written from all places
    during the first deployment. Therefore, the first code version still reads the
    color from the old, `color` column, but writes values to both the old and new
    column.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的方法类似，更改是在几次部署中执行的。第一次部署添加了一个可空列 `chassis_color`。应用程序代码被增强以使用新的模型属性。由于较旧的应用程序版本尚不了解该属性，因此在第一次部署期间并非从所有位置可靠地写入，因此第一个代码版本仍然从旧的、`color`
    列中读取颜色，但将值写入旧列和新列。
- en: The migration script on the next deployment updates the missing column values
    by overwriting the `chassis_color` column with the `color` column contents. By
    doing this, it is ensured that the new column is populated consistently. The not
    null constraint is added to the new column as well. The application code version
    will then only read from the new, but still write to both, because of the short
    period when the older version is still active.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: The next deployment step removes the not null constraint from the `color` column.
    The application code of this version doesn't use the old column anymore, and both
    reads and writes to `chassis_color`.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: The next and final deployment then drops the `color` column. Now all data has
    been gradually transferred to the new `chassis_color` column. The application
    code doesn't include the old model property anymore.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Changing column types or foreign key constraints require similar steps. The
    only way to gradually migrate databases with zero-downtime is to migrate in small
    steps, using intermediate columns and properties. It is advisable to perform several
    commits that only contain these changes to both the migration scripts and application
    code.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the previous approach, rollback migrations have to be executed in
    reverse, for both the database scripts and code changes.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Removing database structures
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Removing tables or columns is more straightforward than changing them. Once
    certain properties of the domain model are not required anymore, their usages
    can be removed from the application.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: The first deployment changes the application code to stop reading from the database
    column but still to write to it. This is required to ensure that the old version
    can still read values other than `null`.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: The next deployment will remove a potential not null constraint from the database
    column. The application code stops writing to column. In this step, occurrences
    of the model property can already be removed from the code base.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: The final deployment step will drop the column. As mentioned before, it highly
    depends on the business use case whether column data should actually be dropped.
    Rollback scripts would need to recreate removed columns, which implies that the
    previous data is gone.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Implementing migration
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have seen, data migrations have to be executed in several steps. Rollout
    as well as rollback scripts are executed right before the deployment. This implies
    that the application supports N-1 compatibility as well as that only one deployment
    is being executed at a time.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: The migration process requires to perform several software releases, each of
    them consistent in application code and schema migration scripts. Engineers need
    to plan their commits accordingly. It's advisable to perform the full schema migration
    in a timely manner, to keep the database schema clean and to ensure that ongoing
    migrations aren't simply forgotten about.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: It's in the nature of the corresponding model refactoring, whether existing
    data needs to be kept or can be discarded. Generally speaking, it is advisable
    to not throw away data. This means not to drop structures containing data that
    doesn't exist somewhere else.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: As we have seen in the examples, the migrations will be applied in graceful
    steps; especially in regard to database constraints, such as *not null* or referential
    integrity constraints. Migration scripts should be resilient. For example, the
    migration should not fail when trying to create already existing columns. They
    could already exist from previous rollbacks. In general, it makes sense to think
    through and test different rollout and rollback scenarios upfront.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Engineers need to keep the update time in mind when updating table contents.
    Updating huge tables at once will take a non-negligible amount of time in which
    the data is potentially locked. This needs to be considered upfront; ideally,
    by testing the scripts in a separate database. For huge amount of data involved,
    the update steps can be executed in shards, for example, by partitioning the data
    by their IDs.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: All rollout and rollback migration scripts should reside in the project repository.
    The database schema comprises a schema version that corresponds to the numbered
    migration scripts. This version is stored in the database as metadata together
    with the current schema state. Before every deployment, the database schema is
    migrated to its desired version. Right after that, the application with a corresponding
    version is deployed, making sure that the versions don't differ by more than one.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: In a container orchestration framework this means that the database migration
    needs to be performed right before the new application version is deployed via
    rolling updates. Since there can be many replicas of pods, this process has to
    be idempotent. Executing the migration of a database schema to the same version
    twice, has to result in the same outcome. Kubernetes pods can define so-called
    **init containers** which execute *one-shot* processes before the actual containers
    start. Init containers run mutually exclusive. They have to exit successfully
    before the actual pod container process can be started.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet shows an example of `initContainer`:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The preceding example implies that the init container image contains the correct
    tooling to connect to the database instance as well as all recent migration scripts.
    In order to make this possible, this image is built as part of the pipeline, as
    well, including all migration scripts from the repository.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: There are, however, many solutions to migrate database schemas. The important
    aspect here is that the idempotent migration needs to be executed upfront, while
    no second deployment action is being rolled out. The migration scripts of the
    corresponding versions would be executed in ascending or descending order, depending
    on whether the database schema version is upgraded or rolled back, until the version
    matches. After the scripts have been executed, the metadata version is updated
    in the database, as well.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: The correlation between code and database versions can be tracked in the project
    repository. For example, the most recent rollout script contained in a commit
    version corresponds to the required database schema. The *Build metadata* section
    covers the topic of required metadata and where to store it in more depth.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the chosen migration solution highly depends on the project''s technology,
    there is no *silver bullet* approach that can be shown here. The following example
    gives one possible solution on migration file structure and execution in *pseudo
    code*. It shows migration files for the example of changing the `color` column
    to `chassis_color` discussed earlier:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/63d62980-027e-4ce4-a646-eec8916ec559.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
- en: The preceding example shows the rollout and rollback scripts that migrate the
    database schema version to the desired state. Rollout script `004_remove_color.sql`
    transposes the schema version to version `4` by removing the `color` column of
    the example shown earlier. The corresponding rollback script `003_add_color.sql`
    rolls back the schema to version `3`, where the `color` column still existed;
    in other words, version `3` contains the `color` column whereas version `4` doesn't,
    with these two migration files being able to roll back and forth.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'The following shows the pseudo code of the script that performs the migrations.
    The desired version to migrate to is provided as an argument when invoking the
    script:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This migration script is executed in the init container before the actual deployment.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Verifying the output of the pipeline steps is one of the most important aspects
    in Continuous Delivery. It increases the software quality by detecting potential
    errors before going live. Proper verification creates reliability in the processes.
    By writing software tests in general and regression tests in particular, developers
    become confident in changing and refactoring functionality. Ultimately, software
    tests enable us to automate development processes.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Building binaries already executes code level tests. Other tests contained in
    the project may be executed in separate pipeline steps, depending whether they
    operate at code level or a running container. End-to-end tests, especially, require
    a running environment.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: After the application has been deployed on test environments, end-to-end tests
    can be executed there. Usually, a project contains several layers of tests, with
    separate responsibilities, running in separate steps. There can be a great variety
    of tests, depending on the project and used technology. The approach is always
    to execute pipeline steps and sufficiently verify the outcome. By doing so, the
    risk of breaking new or existing functionality and introducing potential errors
    is minimized. Especially, container orchestration frameworks with their *production-ready*
    nature support companies in the goal to ship scalable, highly available enterprise
    applications with high quality. Chapter 7, *Testing*, covers all different manifestations
    of testing, including its execution in Continuous Delivery pipelines.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Failing tests will immediately cause the pipeline to stop and will prevent the
    corresponding binary from being used further. This is an important aspect to enable
    fast feedback and also to enforce software quality in the process. Engineers should
    absolutely avoid to bypass steps of the normal process and other *quick fixes*.
    They contradict the idea of continuous improvement and building quality into the
    Continuous Delivery process and ultimately lead to errors. If a test or quality
    gate fails, the build has to break and either the application's code or the verification
    has to change.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Failing tests should not only break the build but also provide insights into
    why the step failed and record the result. This is part of the build's metadata.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Build metadata
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Build metadata records all information that is gathered during the execution
    of the build. Especially, the specific versions of all assets should be tracked
    for further reference.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Builds that run from the beginning to the end don't necessarily need further
    information. The steps are executed in one run until either the build breaks or
    finishes successfully. If, however, specific steps or artifacts are required to
    be referenced or re-executed, further information is required.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Artifact versions are the prime example for this necessity. A WAR file and its
    contents corresponds to a specific version in the VCS commit history. In order
    to track the originating commit from a deployed application, this information
    needs to be tracked somewhere. The same is true for container image versions.
    In order to identify the origin and contents of a container, the versions need
    to be traceable. Database schema versions are another example. A database schema
    version matches a specific application version, including the previous and the
    next version, by following N-1 compatibility. A deployment that migrates the database
    schema needs to know the schema version to migrate to for the desired application
    version.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'Build metadata is especially required when the process enables rolling out
    specific application versions. In general, Continuous Delivery deployments roll
    forward to the current repository version. However, especially with database schemas
    and migrations involved, the possibility of rolling the environments to an arbitrary
    state is a huge benefit. The process in theory works like this: *take this specific
    application version and perform everything required in order to run it on this
    specific environment*, no matter whether the rollout is moving forward or backward.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: In order to improve traceability and reproducibility, it is advisable to track
    quality information about the build as well. This includes, for example, results
    of automated tests, manual tests, or code quality analyses. The deployment steps
    then are able to verify the existence of specific metadata before deploying.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: There are many solutions possible for representing metadata. Some artifact repositories
    such as JFrog Artifactory provide the possibility of linking built artifacts with
    custom metadata.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Another approach is to use the CI server to track this information. This sounds
    like a good fit to store metadata for a build; however, depending on how the CI
    server is operated and set up, it is not necessarily advisable to use it to store
    persistent data. Old builds can be discarded and lose information.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: In general, the number of *points of truth*, for example, to store artifacts
    and information, should be kept low and explicitly defined. Using artifact repositories
    for metadata therefore certainly makes sense.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Another, more custom solution, is to use company VCS repositories to track certain
    information. The big benefit of using, for example, Git to store metadata is that
    it provides full flexibility of the data and structure being persisted. CI servers
    already contain functionality to access VCS repositories, therefore no vendor-specific
    tooling is required. Repositories can store all kind of information that are persisted
    as files, such as recorded test result.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: The metadata repository, however implemented, is accessed at various points
    in the pipeline, for example, when performing deployments.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Going to production
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last step in the Continuous Delivery pipeline is deploying to production.
    This deployment is either triggered manually or, when sufficient verification
    and automated tests are implemented, automatically. The vast majority of companies
    use a manually triggered deployment. But even if the pipeline does not go *all
    the way* from the beginning, Continuous Delivery provides great benefits by automating
    all steps necessary.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: 'The pipeline then only has two kick-off spots: the initial commit to the repository
    that triggers the execution, and the final deployment to production after all
    steps have been verified, manually and automatically.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: In a container orchestration environment, deploying to production, that is,
    either deploying to a separate namespace or a separate cluster, happens in the
    same way as deploying to test environments. Since the infrastructure as code definitions
    are similar or ideally identical to the ones executed before, this technology
    lowers the risk of environment mismatches to production.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Branching models
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Software development processes can make use of different branching models. Software
    branches emerge from the same origin and differ in the state of development to
    make it possible to develop on multiple development stages in parallel.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Especially feature branches are a popular approach. Feature branching creates
    a separate branch which is used to develop a certain software feature. The branch
    is merged into the *master* branch or *trunk* after the feature is finished. The
    master branch and other branches remain untouched while the feature is being developed.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: Another branching model is to use release branches. Release branches contain
    single software releases of a specific version. The idea is to have a dedicated
    point for a released version where bug fixes and features can be added. All changes
    made to the master branch that apply for the specific release as well are also
    made in the release branch.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: However, branching models like these contradict the idea of Continuous Delivery.
    Feature branches, for example, postpone the integration of features into the master
    branch. The longer the integration of new functionality is delayed, the bigger
    the possibility for potential merge conflicts. Feature branches are therefore
    only advisable in Continuous Delivery pipelines if they are short-lived and integrated
    into master in a timely manner.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Release versions and working upon these releases in parallel contradicts the
    idea of continuously shipping versions as well. Features that are implemented
    are ideally shipped to production as soon as possible.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: This is at least the case for enterprise projects. The continuous life cycle
    implies that every commit is a potential candidate for production deployment.
    It makes sense to integrate and apply the work on the master branch, making it
    possible to integrate and deploy features as early as possible, verified by automated
    tests. The branching model of Continuous Delivery and Continuous Deployment, respectively,
    therefore is quite straightforward. Changes are directly applied to the master
    branch, built, verified, and deployed by the build pipeline.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: It's usually not required to manually tag releases. Every commit in the Continuous
    Delivery pipeline implicitly qualifies for being released and deployed to production,
    unless the automated verification identifies errors.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows the concept of a Continuous Deployment branching
    model:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fb2ffb01-a248-4930-8d3f-226ca071588e.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
- en: Individual features branches are kept short-lived and are merged back to *master*
    in a timely manner. The releases are implicitly created on successful builds.
    Broken builds won't result in a deployment to production.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Products, as well as libraries, however, may advisably have different branching
    models. With multiple supported *major* and *minor* versions, and their potential
    bug fixes, it makes sense to implement branches for separate release versions.
    The release version branches, such as `v1.0.2` can then be used to continue support
    for bug fixes, for example, into `v1.0.3`, while the major development continues
    on a newer version, such as `v2.2.0`.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Technology
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When designing Continuous Delivery pipelines, the question remains, which technology
    to use. This includes not only the CI server itself, but all the tools used within
    the development workflow such as version control, artifact repositories, build
    systems, and runtime technologies.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: What technology is being used depends on the actual requirements and not least
    of what the team is familiar with. The following examples will make use of Jenkins,
    Git, Maven, Docker, and Kubernetes. As of writing this book these are widely-used
    technologies. However, for engineers it's more important to comprehend the underlying
    principles and motivations. The technology is quite interchangeable.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: No matter what tools are selected, it's advisable to use the tools for what
    they are meant for. Experience shows that tools are quite often being misused
    for tasks that would better be executed using different technology. A prime example
    for this is the build system, for example Maven. Projects often define build processes
    that have more responsibilities than just building the artifacts.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: It makes sense not to mix responsibilities of building containers or deploying
    software into the artifact build. These concerns are preferably realized directly
    by the Continuous Integration server. Bringing these steps into the build process
    unnecessarily couples the build technology to the environment.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: It's therefore advisable to use the tools for what they were intended to do,
    in a straightforward way. For example, Docker containers are advisably built via
    the corresponding Docker binaries rather than build system plugins. Required abstraction
    layers are rather added in pipeline as code definitions, as demonstrated in the
    following examples.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Pipeline-as-code
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We previously saw the benefits of representing configuration as code, primarily
    infrastructure as code files. The same motivations led to pipeline as code definitions,
    configuration that specifies the CI server pipeline steps.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: In the past, many CI servers such as Jenkins required to be configured manually.
    CI server jobs had to be laboriously *clicked together* to build up pipelines.
    Especially, rebuilding pipelines for new applications or feature branches thereof
    required cumbersome manual work.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Pipeline as code definitions specify the Continuous Delivery pipeline as part
    of the software project. The CI server builds up and executes the pipeline appropriately,
    following the script. This vastly simplifies defining and reusing project build
    pipelines.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of CI servers that support pipeline definitions as code. The
    most important aspect is that engineers understand the motivations and benefits
    behind this technology. The following shows examples for Jenkins, a widely used
    CI server in the Java ecosystem.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: Users of Jenkins can craft pipelines in a `Jenkinsfile`, which is defined using
    a Groovy DSL. Groovy is an optionally typed, dynamic JVM language, that suits
    well for DSL and scripts. Gradle build scripts use a Groovy DSL, as well.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: The following examples show the steps of a very simple pipeline of a Java enterprise
    project. The examples are meant to give a rough understanding of the executed
    process. For full information on Jenkinsfiles, their syntax and semantics, refer
    to the documentation.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: The following shows an example `Jenkinsfile`, containing a basic pipeline definition.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `stage` definitions refer to steps in the Jenkins pipeline. Since the Groovy
    script offers a full-fledged programming language, it is possible and advisable
    to apply clean code practices that produce readable code. Therefore, the contents
    of the specific steps are refactored to separate methods, all in the same layer
    of abstraction.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: 'The `prepare()` step, for example, encapsulates several executions to fulfill
    build prerequisites, such as checking out the build repository. The following
    code shows its method definition:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The build stage also encapsulates several sub-steps, from executing the Maven
    build, recording metadata and test results, to building the Docker images. The
    following code shows its method definition:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: These examples provide insight into how to define and encapsulate specific behavior
    into steps. Providing detailed Jenkinsfile examples is beyond the scope of this
    book. I will show you the rough steps necessary to give an idea of what logical
    executions are required, and how to define them in these pipeline scripts in a
    readable, productive way. The actual implementations, however, heavily depend
    on the project.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Jenkins pipeline definitions provide the possibility to include so-called pipeline
    libraries. These are predefined libraries that contain often-used functionality
    to simplify usage and reduce duplication beyond several projects. It is advisable
    to outsource certain functionality, especially in regard to environment specifics,
    into company-specific library definitions.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows the deployment of the *car manufacture* application
    to a Kubernetes environment. The `deploy()` method would be called from within
    the build pipeline when deploying a specific image and database schema version
    to a Kubernetes namespace:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This example updates and commits the Kubernetes YAML definitions in the VCS
    repository. The execution applies the infrastructure as code to the Kubernetes
    namespace and waits for the deployment to finish.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: These examples aim to give the reader an idea of how to integrate Continuous
    Delivery pipelines as pipeline as code definitions with a container orchestration
    framework such as Kubernetes. As mentioned earlier, it is also possible to make
    use of pipeline libraries to encapsulate often-used `kubectl` shell commands.
    Dynamic languages such as Groovy allow engineers to develop pipeline scripts in
    a readable way, treating them with the same effort as other code.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Workflows with Java EE
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The demonstrated examples cover general Java build piplines which are, of course,
    applicable to Java EE as well. In fact, using Java Enterprise highly supports
    productive development pipelines. Fast builds and therefore fast developer feedback
    is crucial to effective Continuous Delivery workflows.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Zero-dependency applications, especially when packaged in containers, leverage
    these principles as we have seen in [Chapter 4](f0a49441-e411-49c4-a4b6-c6193ba36094.xhtml),
    *Lightweight Java EE*. The enterprise application in the packaged artifact or
    the container layer, respectively, only contains the business logic that was developed
    against the API. The application container provides the implementation.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: The Continuous Delivery pipeline benefits from zero-dependency applications,
    since the involved build and distribution steps only require short execution and
    transmission times, respectively. Artifact builds as well as container builds
    run as fast as they can get, with only copying what's absolutely necessary. In
    the same way, publishing and deploying artifacts, as well as container layers,
    only contain the required business concerns, to minimize transmission time. This
    leads to fast turnaround and fast feedback.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Having effective pipelines is crucial to implementing a Continuous Delivery
    culture in the development team. Engineers are motivated to check in early and
    often, since the pipeline runs fast, provides fast feedback, and increases the
    confidence that the software quality is met.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, build times should not take more than a few seconds. Build
    pipeline executions, including end-to-end tests, should not take more than a few
    minutes, ideally even faster.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Putting effort into making builds and pipelines run faster should be a goal
    of the engineering team. During a workday, developers often build and check in
    the project. Every check-in results in a Continuous Delivery build that is a potential
    candidate for production deployment. If this overall process takes just, for example,
    1 minute longer, all developers in the team wait 1 minute longer, every time they
    build the software. One can imagine that this delay adds up to a big number over
    time. Developers are tempted to check in less often if they have to wait for their
    result.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Improving the stability and performance of the pipeline, therefore, is a long-term
    investment in the team's productivity. Tests and steps that provide quick, helpful
    feedback by breaking the build faster in case of errors should run as early as
    possible. If some end-to-end tests run inevitably longer in time, due to the nature
    of the project and the tests, they can be defined in separate downstream pipelines
    steps, to not delay feedback of earlier verification. Steps that can run in parallel,
    such as static code analyses, should do so, to speed up the overall execution.
    Using the modern approaches of Java EE development greatly supports crafting productive
    build pipelines.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Still, technology is only one aspect of effective Continuous Delivery. Introducing
    Continuous Delivery has an even bigger impact on the development team's culture.
    Let's have a closer look into this.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Delivery culture and team habits
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Effective Continuous Delivery depends on a healthy team culture. If the team
    does not live by the principles and recommendations Continuous Delivery makes,
    the best technology doesn't help much. Pipelines that implement automated deployments
    have little value if there aren't sufficient software tests verifying the deployed
    software. The most eager CI server can't help much if developers seldom check
    in their changes, making integration hard and cumbersome. Full test coverage and
    code quality checks have no value if the team doesn't react to failing tests or,
    in the worst case, set the test execution to ignore.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Responsibility
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Continuous Delivery starts with being responsible for the software. As mentioned
    earlier, for the DevOps movement, it is not sufficient for developers to just
    build their software and let other teams deal with potential errors. The development
    team that creates and owns the application knows about its responsibilities, used
    technologies, and troubleshooting in case of potential errors.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a small startup that has only a single developer who responsible for
    the application. This person obviously has to deal with all technical issues,
    such as development, builds, deployment, and troubleshooting the application.
    He or she will have the best knowledge about the application's internals and will
    be able to fix potential issues effectively. Obviously, this single point of responsibility
    approach is the opposite of scalability and only works for tiny teams.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: 'In bigger companies, there are more applications, more developers, and more
    teams with different responsibilities. The challenge with splitting and shifting
    responsibilities is to transfer knowledge. The knowledge is ideally spread within
    a team of engineers who closely work on the same software. Like in small startups,
    the mantra for developing applications should be: *you build it, you run it*.
    For a single team, this is only possible with the support of central, well-defined
    and automated processes. Implementing Continuous Delivery pipelines implement
    these processes to reliably ship software.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: Managing and refining these processes becomes the responsibility of the whole
    team of engineers and is no longer an *ops problem*. All developers are equally
    responsible for building and shipping working software that provides value to
    the business. This certainly involves some duties, or team habits.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Check in early and often
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Continuous Delivery has to be lived by the whole team. Developers who work on
    features or bug fixes should check in into the master branch early and often.
    This is crucial to enable Continuous Integration. The more time passes before
    changes are merged into the master branch, the harder the merging and integration
    of features becomes. Adding complex functionality in a big bang contradicts the
    idea of *continuous* evolution of software. Functionality that should not be visible
    to users yet can be excluded by feature toggles.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Checking in often encourages developers to write sufficient, automated software
    tests from the beginning. This is certainly an effort to make during development
    but will always pay off in the long run. While developing a feature, engineers
    are aware of its functionality and boundaries. It's far less effort to include
    not only unit tests but sophisticated end-to-end tests from the beginning then
    it is after the feature has been written.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: Especially for less-experienced developers it's important to mention that committing
    early, premature versions of features is nothing to be embarrassed about, but
    part of the development process. Code which hasn't been refactored yet and doesn't
    look perfect, but fulfills the requirements and provides business value, can be
    cleaned up in a second run. It's far more helpful to commit code early in the
    process than refraining from committing until the very last minute.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Immediately fixing issues
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Immediately solving build errors is another important team habit to develop.
    Tests that fail should not be ignored or postponed but fixed as soon as possible.
    Builds that fail often and are not taken good care of decrease the productivity
    of all team members. A failing test that makes the project unable to be built,
    for example, prevents other developers from integrating and verifying their features.
    Still, failing builds due to test failures or quality violations is a sign that
    the validation works and is, obviously, much better than false negatives, that
    is, mistakenly green builds. It is, however, important to fix project builds as
    soon as they fail. Developers should execute basic and fast verifications, such
    as building the Java project and executing code level tests, on their local machines
    before pushing to the central repository. They should take care not to misuse
    the pipeline to find careless mistakes which unnecessarily disturb other team
    members.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, compiler or code analysis warnings should be treated as
    errors that break the build. This introduces a zero-warning policy that urges
    engineers to either fix the issue or adjust the validation. Build, compilation,
    or code style warnings are therefore also errors that break the build and need
    to be fixed as soon as possible.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: The team member whose commit caused the build to break should ideally be the
    first to look into the root cause. It is, however, a responsibility of the whole
    team to keep the pipeline in a healthy state. This goes back to the whole team
    being responsible for the whole project. There should not be exclusive *code ownership*,
    that is, parts of the projects which are exclusively known to a single team member.
    It will always be the case that developers who wrote specific functionality have
    better knowledge about it. Still, in all cases, the team should be able to work
    on all areas of the project and fix potential issues.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Visibility
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The visibility that Continuous Delivery enables is another important aspect.
    The whole development process, including commits, builds, verifications, and deployments,
    can be tracked and comprehended in a single place. What visibility aspects are
    important in a Continuous Delivery pipeline?
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: First of all, it needs to be represented whether the software is in a shippable
    state. This includes the build's health in terms of compilation, tests, and code
    analyses. A dashboard or so-called **extreme feedback** device, such as physical
    green and red LEDs, provide a quick overview about it.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: A reasonable build visibility ideally does not overload with information if
    the build is green but provides clear and direct insight in case of failing builds.
    This again follows the principle that there are no such things as warnings in
    the build; it either passes successfully and there is nothing else to do or it
    breaks and requires action. Dashboards or other devices that provide this *green
    or red* information already provide helpful insights. These visibility instruments
    should be accessible to all team members to embrace collaboration.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: However, in order not to disrupt the day-to-day development too much, it makes
    sense to notify persons in charge, whose commits caused the build to break, first.
    They likely have further knowledge how to fix the build again without disturbing
    the work of their teammates if not necessary. CI servers provide functionality
    to send emails, use chat communication, or other forms of notification. This both
    increases the quality of the software as well as the developer's productivity.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: The information that is gathered during builds can be used to measure the quality
    of the software project. This first of all includes build and test results and
    code quality metrics, such as test coverage. This information can be displayed
    over time to provide insights and trends about the software quality.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Other very interesting metadata concerns the build pipeline itself. How long
    does a build usually take? How many builds are there in a day? How often does
    the build fail? What is the most common failure cause? How long does it take a
    failing build to be fixed again (*time to recover*)? The answers to these questions
    provide helpful insights about the quality of the Continuous Delivery process.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: The gathered information serves as good starting points to improve the process
    further. Visibility of Continuous Delivery not only illuminates the current project
    status but can also draw the engineers' attention to certain hotspots. The overall
    goal is to continuously improve the software.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: Improve continuously
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The whole mindset of Continuous Delivery aims to delivery software with consistent
    quality. Automated processes encourage the usage of quality verifications.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Good software quality, of course, does not come for free. Sufficient test cases
    as well as code quality analyses require a certain time and effort. Automation
    and continuously improving the quality, however, will, after an initial threshold,
    pay off in the long run, and eventually lead to better software.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: New features as well as found bugs need to be verified sufficiently during development
    in order to ensure that functionality works as expected. By automating the tests
    and keeping them as regression, developers can be sure that no new bugs can disrupt
    the functionality in the future. The same is true for code quality analyses. Once
    the analysis is set up with appropriate rules and the found errors are eradicated,
    it ensures that no new violations can find their way into the software. If new
    false positive violations emerge, the rules are adjusted and will prevent new
    false positives in the future.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Introducing new test scenarios, such as end-to-end tests, also highly supports
    this approach. Regression tests decrease the risk of newly introduced bugs more
    and more. Again, automation is the key. As we will see in Chapter 7, *Testing*,
    human intervention is helpful for defining reasonable test scenarios. However,
    it is crucial to the software quality that these test are then automated made
    part of the pipeline. By doing so, the quality is improved more and more over
    time.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: This, of course, requires the engineers to put a certain priority into quality
    improvements. Improving software quality, as well as refactoring, doesn't provide
    any immediate benefits for the business. These efforts will, instead, pay off
    in the long run - by still being able to produce new features with a constant
    velocity or changing existing behavior with certainty that nothing else breaks.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Productive development workflows require fast turnaround times as well as fast
    feedback. Automating repetitive tasks minimizes the times spent on build, tests
    and deployments. Zero-dependency Java EE applications supports fast feedback by
    minimizing build, publish, and deployment times.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: It's important to define which category of errors will break the build. Developers
    should be aware that a build is either broken, due to legitimate errors, or passed,
    without anything to complain about. Warnings that have no effect on the build
    outcome have little value.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Data migration is another important topic to consider. Deploying stateless applications
    is comparably easy; what needs to be taken into account are the database schemas
    that need to match the application code. Rolling updates together with migration
    scripts, that rollout modifications in small changes, enable applications to be
    deployed with zero-downtime. Applications therefore need to support N-1 compatibility.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Delivery depends on a healthy team culture. It's not sufficient to
    implement just the technical necessities; all software engineers need to embrace
    the principles. Potential build issues, test results, software quality, and deployment
    statuses should be visible to the whole software team.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Delivery processes support to continuously improve the software.
    Verification steps that are added, such as automated software tests, run every
    time the application is built, enabling regression tests and avoiding specific
    bugs to happen twice. This of course requires developers to put effort into the
    quality improvement. The effort put into Continuous Delivery will pay off in the
    long run.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: The following chapter stays in the field of software quality and will cover
    testing enterprise applications.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
