<html><head></head><body>
		<div id="_idContainer165">
			<h1 id="_idParaDest-196"><a id="_idTextAnchor205"/>Assessments</h1>
			<p>This section contains answers to the questions from all chapters.</p>
			<h1 id="_idParaDest-197"><a id="_idTextAnchor206"/>Chapter 1 – Evolution of Java Virtual Machine</h1>
			<ol>
				<li>Java code is compiled to bytecode. JVM uses interpreters to convert the bytecode to machine language and uses JIT compilers to compile the most commonly used code snippets (hotspots). This approach helps Java to achieve "write-once run-anywhere," as a result of which programmers don't have to write machine-specific code.</li>
				<li>A class loader subsystem is responsible for loading the classes. It not only finds the classes, but also verifies and resolves the classes.</li>
				<li>JVM has five memory areas:<p>a. Method: A shared area, where all the class-level data is stored at the JVM level</p><p>b. Heap: All instance variables and objects stored at the JVM level (shared across threads)</p><p>c. Stack: A runtime stack per thread to store the local variables at the method scope, as well as operands and frame data</p><p>d. Registries: PC registers with the addresses of current executing instructions (for each thread)</p><p>e. Native method stack: Native method information for each thread that is used to invoke native methods</p></li>
			</ol>
			<h1 id="_idParaDest-198"><a id="_idTextAnchor207"/>Chapter 2 – JIT, Hotspot, and GraalJIT</h1>
			<ol>
				<li value="1">A code cache is a special memory area within JVM that is used by JVM to store the compiled code. The code is compiled by JIT compilers and stored in the code cache. If a method is compiled and is found in the code cache, JVM will use that code to run, instead of interpreting the method code. Refer to the <em class="italic">Code cache</em> section for more details</li>
				<li>The code cache size can be changed using the following flags for fine-tuning. Refer to the <em class="italic">Code cache</em> section for more details:<p>a. <strong class="source-inline">-XX:InitialCodeCacheSize</strong> – The initial size of the code cache. The default size is 160 KB (the size varies based on the JVM version)</p><p>b. <strong class="source-inline">-XX:ReservedCodeCacheSize</strong> – This is the maximum size the code cache can grow to. The default size is 32/48 MB. When the code cache reaches this limit, JVM will throw a warning, <strong class="source-inline">CodeCache is full. Compiler has been disabled.</strong> JVM offers the <strong class="source-inline">UseCodeCacheFlushing</strong> option to flush the code cache when the code cache is full. The code cache is also flushed when the compiled code is not hot enough (when the counter is less than the compiler threshold).</p><p>c. <strong class="source-inline">-XX:CodeCacheExpansionSize</strong> – This is the expansion size. When it scales up, its default value is 32/64 KB.</p></li>
				<li>The compiler threshold is the factor that is used to decide when the code is "hot." When the code reaches the compiler threshold, JVM will spin off the JIT compilation (C1 or C2) on a compilation thread. Refer to the <em class="italic">Compiler threshold</em> section for more details.</li>
				<li>Sometimes, the code can become hot while it is running a long-running loop. In such cases, JVM will compile that code and perform OSR. Refer to the <em class="italic">On-stack replacement</em> section for more details and a detailed flow chart regarding how JVM performs OSR.</li>
				<li>In JVM, there is an interpreter and two types of compiler – C1 and C2. Users can specify any specific compiler to be used to optimize the code. By default, JVM performs tiered compilation, which is a combination of C1 and C2, based on various compiler thresholds. There are five tiers:<p>a. Interpreted code (level 0)</p><p>b. Simple C1 compiled code (level 1)</p><p>c. Limited C1 compiled code (level 2)</p><p>d. Full C1 compiled code (level 3)</p><p>e. C2 compiled code (level 4)</p><p>There are three main patterns that JVM follows:</p><p>a. Normal Flow</p><p>b. C2 Busy </p><p>c. Trivial Code</p></li>
				<li>Refer to the <em class="italic">Tiered compilation</em> section for more details. </li>
				<li>Inlining is one of the key optimization techniques that JIT compilers use. Based on the profiling of the code, JIT identifies the methods that can be inlined in order to avoid method calls. Method calls are expensive, as it performs jumps and stack frames are created.</li>
				<li>Monomorphic dispatch is another optimization technique used to identify the specific implementations of a polymorphic implementation. JIT profiles the code, identifies the specific implementation, and optimizes the code around that. Please refer to the <em class="italic">Monomorphic, bimorphic, and megamorphic dispatch</em> section for more details.</li>
				<li>Loop unrolling is one of the most effective optimizations that JIT performs, by inlining code in the loop body, with additional code, and reducing the number of iterations a loop has to iterate through. Please refer to the <em class="italic">Loop optimization – loop unrolling</em> section for more details and examples.</li>
				<li>Escape analysis is an optimization technique that the JIT profiler performs to identify the allocation and scope of the variables, and takes decisions in avoiding heap allocation, and replaces that with stack allocation, based on the scope of the variable. This is one of the most advanced analyses performed by JIT profilers. Please refer to the <em class="italic">Escape analysis</em> section for more details.</li>
				<li>JIT performs deoptimization when any of the optimistic assumptions that were made to optimize and compile the code are invalid. JIT will make the compiled code non-entrant and fall back to the interpreter.</li>
				<li>JVMCI stands for <em class="italic">Java Virtual Machine Compiler Interface</em>. This interface was added to the JDK in Java 9. JVMCI provides an API to extend JVM and build custom compilers. Graal JIT is an implementation of JVMCI. Please refer to the <em class="italic">Graal JIT and the JVM Compiler Interface (JVMCI)</em> section for more details.</li>
			</ol>
			<h1 id="_idParaDest-199"><a id="_idTextAnchor208"/>Chapter 3 – Graal VM Architecture</h1>
			<ol>
				<li value="1">GraalVM comes in two versions – Community Edition and Enterprise Edition. Refer to <em class="italic">Reviewing the GraalVM editions</em> section for more details.</li>
				<li>JVMCI stands for <em class="italic">Java Virtual Machine Compiler Interface</em>. Java 9 and above provide a way to implement custom JIT compilers. JVMCI provides an API to implement these custom compilers and provides access to JVM objects and the code cache. Graal JIT is an implementation of JVMCI. Refer to the <em class="italic">Java Virtual Machine Compiler Interface (JVMCI)</em> section for more details.</li>
				<li>Graal JIT replaces the C2 JIT compiler. Graal JIT is completely written in Java from the ground up but uses the hardened logic and best practices of the C2 compiler. Graal JIT implements better optimization strategies than C2 JIT, making it the best JIT compiler for Java. Graal JIT can also be used to compile other languages that are converted into intermediate representations in order to use the advanced optimization strategies. Refer to the <em class="italic">Graal compiler and tooling</em> section for more details.</li>
				<li>Graal JIT requires a considerable amount of time to warm up, profile, and optimize the code. In certain use cases, this may not be suitable (such as serverless or containers). For such cases, Graal provides AOT compilation to compile the code directly to the native image. </li>
				<li>Graal AOT optimization is more related to static code analysis, but it does now have the runtime profile of the code to apply any advanced optimization<strong class="bold">. Profile Guided Optimization </strong>(<strong class="bold">PGO</strong>) provides a way to compile the code with instrumentation, generate a profile of the runtime, and use that profile to recompile the code to the most optimum native image. Refer to the <em class="italic">SubstrateVM (Graal AOT, Native Image)</em> section for more details.</li>
				<li>The Truffle framework is built on top of Graal to support non-JVM languages to run on Graal JVM. Truffle provides the Truffle Language Implementation API and various other polyglot APIs to provide a very sophisticated environment where code in multiple languages can be embedded and interact. Refer to the <em class="italic">Truffle</em> section for more details.</li>
				<li>SubstrateVM is an embeddable VM that can be packaged along with the native images that are compiled by the Graal AOT compiler. Refer to the <em class="italic">SubstrateVM (Graal AOT and Native Image)</em> section for more details.</li>
				<li>Guest Access Context is an object that is used by the host language (such as Java) to provide access to the guest language (such as JavaScript) to various OS resources, such as the filesystem, I/O, and thread. Refer to the <em class="italic">Security</em> section for more details.</li>
				<li>GraalVM provides the most advanced JIT compilation, ideal for long-running processes involving high throughput. The GraalVM AOT compiler, along with SubstrateVM, provides the smallest and fastest runtime for cloud-native microservices implementations. Combined with PGO, it generates the optimum code to run on the cloud. Refer to the <em class="italic">GraalVM microservices architecture overview</em> section for more details.</li>
			</ol>
			<h1 id="_idParaDest-200"><a id="_idTextAnchor209"/>Chapter 4 – Graal Just-In-Time Compiler</h1>
			<ol>
				<li value="1">Graal JIT compilation can be divided into two phases: frontend and backend. <p>The frontend phase is platform-independent compilation, where the code is converted to a platform-independent intermediate representation called <strong class="bold">High-Level Intermediate Representation </strong>(<strong class="bold">HIR</strong>), represented via Graal Graphs. This HIR is optimized in three tiers: High, Medium, and Low.</p><p>The backend phase is more platform-dependent compilation, where a <strong class="bold">Low-Level Intermediate Representation</strong> (<strong class="bold">LIR</strong>) is created and optimized at the machine code level. These optimizations are platform dependent.</p><p>Refer to the <em class="italic">Graal JIT compilation pipeline and Tiered Optimization</em> section for more details. </p></li>
				<li><strong class="bold">Intermediate Representations</strong> (<strong class="bold">IRs</strong>) are among the most important data structures for compiler design. IRs provide a graph that helps the compiler understand the structure of the code, identify opportunities, and perform optimizations. Refer to the <em class="italic">Graal Intermediate Representation</em> section for more details.</li>
				<li><strong class="bold">Static Single Assignment</strong> (<strong class="bold">SSA</strong>) is a form used in IRs where each variable is assigned once, and any time there is a change in the value, a new variable is used. Every variable is declared before it is used. This helps us to keep track of variables and values and helps optimize the code better using graphs. Refer to the <em class="italic">Graal intermediate representation</em> section for more details.</li>
				<li>Speculative optimization is a compiler optimization technique of performing various code optimizations with speculation. Speculations are assumptions that are made based on profiling the code. The optimizations are performed on the code based on these assumptions. When these assumptions are proven wrong, at runtime, a deoptimization is performed. This helps to optimize focused parts of the code, instead of the whole code, which might slow down the runtime. Refer to the <em class="italic">Graal compiler optimizations</em> section for more details.</li>
				<li>Escape analysis is an optimization technique that identifies the scope and usage of the objects and decides the allocation of the objects either on the heap or the stack or the register. This has a significant impact on memory usage and performance. Escape analysis is performed at the method level, while partial escape analysis performs a deeper analysis of the code to track the objects not just at the method-level scope, but also at the control block level. This helps further optimize the code. Refer to the <em class="italic">Partial escape analysis</em> section for more details.</li>
			</ol>
			<h1 id="_idParaDest-201"><a id="_idTextAnchor210"/>Chapter 5 – Graal Ahead-of-Time Compiler and Native Image</h1>
			<ol>
				<li value="1">GraalVM comes with a tool called the Native Image builder, <strong class="source-inline">native-image</strong>. This can be used to compile ahead of time and create a native image. Please refer to the <em class="italic">Building native images</em> section for more details.</li>
				<li>The Native Image builder, when it compiles the code ahead of time, performs points-to analysis to understand all the dependent classes and methods that are accessed by the application code. It uses this information to optimize the native image, by only building the required code into the image. This provides faster execution and smaller images. Please refer to the <em class="italic">Building native images</em> section for more details.</li>
				<li>The Native Image builder performs region analysis to initialize classes ahead of time into the heap so that the startup of the native image is faster. Please refer to the <em class="italic">Building native images</em> section for more details.</li>
				<li>The Native Image builder packages the <strong class="bold">Garbage Collector</strong> (<strong class="bold">GC</strong>) code along with the native image. There are two types of GC that can be enabled in the native image. The Serial GC is a default GC and is available both in the Community and Enterprise editions. G1 performs more advanced garbage collection and is only available in the Enterprise edition. Please refer to the <em class="italic">Native Image memory management configurations</em> section for more details. </li>
				<li>The Native Image builder can only perform static code analysis, unlike the JIT compiler, which can perform the runtime profiling of the code and optimize the code at runtime. PGO brings the runtime profiling information to a native image for further optimization. Please refer to the <em class="italic">Profile-guided optimization (PGO)</em> section for more details.</li>
				<li>Since native images are built ahead of time, the Native Image builder needs to have all the classes loaded at build time. Hence, native images have limitations in supporting dynamic features such as reflection and JNI. However, GraalVM's Native Image builder provides ways to pass dynamic resource information at build time. Please refer to the <em class="italic">Native image configuration</em> and <em class="italic">Limitations of Graal AOT (Native Image)</em> sections for more details.</li>
			</ol>
			<h1 id="_idParaDest-202"><a id="_idTextAnchor211"/>Chapter 6 – Truffle – An Overview</h1>
			<ol>
				<li value="1">Specialization is a key optimization that helps identify the specific type of a variable. In dynamically typed languages, the type of a variable is not declared in the code. The interpreter starts assuming generic types and, based on the runtime profiling, will speculate on the type of the variable. Please refer to the <em class="italic">Truffle interpreter/compiler pipeline</em> section for more details.</li>
				<li>When Truffle speculates on a specialized type of a node, the node is rewritten dynamically, and the Truffle AST provides a way to rewrite the nodes to optimize the AST before submitting it to Graal for further optimized execution. Please refer to the <em class="italic">Truffle interpreter/compiler pipeline</em> section for more details.</li>
				<li>When Truffle finds that the AST has not been rewritten, it assumes that the AST has stabilized. The code is then compiled to machine code for the guest language after aggressive constant folding, inlining, and escape analysis. This is called Partial Evaluation. Please refer to <em class="italic">Partial Evaluation</em> in the <em class="italic">Truffle interpreter/compiler pipeline</em> section for more details.</li>
				<li>Truffle provides a Domain-Specific Language implemented as annotation generators. This helps guest language developers write smaller code and focus on the logic, rather than the boilerplate code. Please refer to the <em class="italic">Truffle DSL</em> section for more details.</li>
				<li>A frame is a Truffle class that provides the interface to read and store data in the current namespace. Refer to <em class="italic">Frame management and local variables</em> in the <em class="italic">Truffle interoperability</em> section for more details.</li>
				<li>Truffle defines a Dynamic Object Model to provide a standard interface and framework for various guest language implementations to have a standard way of defining and exchanging data. Refer to <em class="italic">Dynamic Object Model</em> in the <em class="italic">Truffle interoperability</em> section for more details.</li>
			</ol>
			<h1 id="_idParaDest-203"><a id="_idTextAnchor212"/>Chapter 7 – GraalVM Polyglot – JavaScript and Node.js</h1>
			<ol>
				<li value="1"><strong class="source-inline">Polyglot</strong> is the object that is used in JavaScript to run other language code. We use the method <strong class="source-inline">eval()</strong> to run the code. Please refer to the <em class="italic">JavaScript interoperability</em> section for more details on how to use this object to run the code.</li>
				<li>The <strong class="source-inline">Context</strong> object provides the polyglot context to allow the guest language code to run in the host language. A polyglot context represents the global runtime state of all installed and permitted languages. Please refer to the <em class="italic">JavaScript embedded code in Java</em> section for more details on how to use this object to run the code.</li>
				<li>The <strong class="source-inline">Context</strong> object helps provide fine-grained access control. The access control can be controlled with <strong class="source-inline">ContextBuilder</strong>. Please refer to the <em class="italic">JavaScript embedded code in Java</em> section for more details on how to use this object to run the code.</li>
				<li>GraalVM provides a Native Image builder option to build native images of applications that have multiple languages embedded. A language flag is used to let the Native Image builder know which languages are used in the application. This flag can also be specified in <strong class="source-inline">native-image</strong> property files. Refer to the <em class="italic">Polyglot native images</em> section in this chapter to understand more. Refer to <em class="italic">Chapter 5</em> , <em class="italic">Graal Ahead-of-Time Compiler and Native Image</em> for more details about the native image.</li>
				<li>The <strong class="source-inline">binding</strong> object acts as an intermediate layer between Java and JavaScript to access methods, variables, and objects between the languages. Please refer to the <em class="italic">Bindings</em> section to find out more about the binding object and how it is used as an intermediate layer between languages.</li>
			</ol>
			<h1 id="_idParaDest-204"><a id="_idTextAnchor213"/>Chapter 8 – GraalVM Polyglot – Java on Truffle, Python, and R</h1>
			<ol>
				<li value="1">Java on Truffle is the new way to run Java programs on top of the Truffle framework. Java on Truffle provides an interpreter that is completely built on Java and runs in the same memory space as other Truffle languages. This was introduced in GraalVM version 21. For more details refer to the <em class="italic">Understanding Espresso (Java on Truffle)</em> section.</li>
				<li>Java on Truffle provides an isolationist layer, which helps to run untrusted code and code written in an older version of JDK, and provides hot-swap and other advanced features. To learn more about the advantages of using Java on Truffle, refer to the <em class="italic">Why do we need Java on Java?</em> section for more details.</li>
				<li>The <strong class="source-inline">Polyglot.cast()</strong> method is used in Java on Truffle to typecast the data that is exported or returned by dynamic languages. Refer to the <em class="italic">Exploring Espresso interoperability with other Truffle languages</em> section for more details and code examples.</li>
				<li><strong class="bold">SST</strong> stands for <strong class="bold">Simple Syntax Tree</strong> and <strong class="bold">ST</strong> stands for <strong class="bold">Scope Tree</strong>. Python generates these intermediate representations before converting them into an AST intermediate representation. Python does this using the ANTLR parser and the cache, and speeds up parsing. Refer to the <em class="italic">Understanding Graalpython compilation and interpreter pipeline</em> section for more details.</li>
				<li>A <strong class="source-inline">.pyc</strong> file is a cache Python creates after parsing Python code and generating SST and ST representations. This helps speed up parsing the next time the Python module is loaded. Python automatically keeps this cache validated. Refer to the <em class="italic">Understanding Graalpython compilation and interpreter pipeline</em> section for more details.</li>
				<li><strong class="source-inline">polyglot.import_value()</strong> is used to import definitions from other dynamic languages, and <strong class="source-inline">polyglot.export_value()</strong> is used to export Python definitions to other languages. <strong class="source-inline">polyglot.eval()</strong> is used to execute other language code. Refer to the <em class="italic">Exploring interoperability between Python and other dynamic languages</em> section for more detailed explanations and sample code.</li>
				<li>In R, we use the <strong class="source-inline">import()</strong> function to import the definitions from other languages. Refer to the <em class="italic">Exploring interoperability of R</em> section for more details.</li>
				<li>We use <strong class="source-inline">java.type('classname')</strong> to load a Java class and interoperate with it. This function provides the class, and we can use the <strong class="source-inline">new()</strong> function to create an instance of the object. Refer to the <em class="italic">Exploring the interoperability of R</em> section for more details and sample code.</li>
			</ol>
			<h1 id="_idParaDest-205"><a id="_idTextAnchor214"/>Chapter 9 – GraalVM Polyglot – LLVM, Ruby, and WASM</h1>
			<ol>
				<li value="1">Sulong is an LLVM interpreter that is written in Java and internally uses the Truffle language implementation framework. This enables all language compilers that can generate LLVM IR to directly run on GraalVM. Refer to the <em class="italic">Understanding LLVM – the (Sulong) Truffle interface</em> section for more details.</li>
				<li>GraalVM Enterprise Edition provides a managed environment of LLVM. The managed mode of execution provides a safe runtime, which, with additional safety, guarantees to catch illegal pointer accesses and access arrays outside of the bounds.<p>The TruffleRuby interpreter interoperates with the LLVM interpreter to implement the C extensions. This also extends the possibility to use other LLVM languages, such as Rust and Swift, to run as Ruby extensions. Refer to the <em class="italic">Understanding the TruffleRuby interpreter/compiler pipeline</em> section for more details. </p></li>
				<li>WASM is binary code that can run on modern web browsers. It has a very small footprint and performs much faster than JavaScript. Refer to the <em class="italic">Understanding WASM</em> section for more details.<p>Emscripten or <strong class="source-inline">emcc</strong> is the compiler that generates the WASM binary image (<strong class="source-inline">.wasm</strong>) files. Refer to the <em class="italic">Installing and running GraalWasm</em> section for more details.</p></li>
			</ol>
			<h1 id="_idParaDest-206"><a id="_idTextAnchor215"/>Chapter 10 – Microservices Architecture with GraalVM</h1>
			<ol>
				<li value="1">Microservices is an architectural pattern that decomposes a large application into smaller, manageable, and self-contained components that expose the functionality through a standard interface called services. Please refer to the <em class="italic">Microservices architecture overview</em> section for more details.</li>
				<li>The microservices architecture pattern helps us build an application that is scalable, manageable, and loosely coupled. This is very important for building cloud-native applications in order to get the most out of the cloud infrastructure and services. Please refer to the <em class="italic">Microservices architecture overview</em> section for more details.</li>
				<li>GraalVM provides a high-performance runtime for JVM and non-JVM languages with a small footprint, which is critical for building scalable cloud-native applications. Refer to the <em class="italic">Reviewing modern architectural requirements</em> section in <em class="italic">Chapter 3</em>, <em class="italic">Graal VM Architecture, </em>and the <em class="italic">Understanding how GraalVM helps build a microservice architecture</em> section in this chapter for more details. </li>
			</ol>
		</div>
	</body></html>