- en: Scaling and Connecting Your Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will look in greater detail at the process of deploying,
    scaling, and connecting your applications. In [Chapter 6](461aee71-984a-4158-addc-fc49341d3455.xhtml),
    *Deploying Applications on the Cloud with OpenShift*, you have already learned
    the basic information about deploying services to the OpenShift cloud. Now it's
    time to extend this knowledge and learn how to use it in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start with deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's examine what happens under the hood during deployment of our services.
    We are going to continue work on an example from the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples reference: `chapter8/catalog-service-openshift-load-balancing`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You have to open the web console, and navigate to Applications| Deployments
    | catalog-service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9cd46b6b-7ca7-4fca-bd03-009c0bcf94ce.png)'
  prefs: []
  type: TYPE_IMG
- en: Now we will be able to see the deployment configuration. This is the graphical
    representation of OpenShift's `DeploymentConfiguration` object.
  prefs: []
  type: TYPE_NORMAL
- en: As you learned in [Chapter 6](461aee71-984a-4158-addc-fc49341d3455.xhtml), *Deploying
    Applications on the Cloud with OpenShift*, OpenShift adds another layer on top
    of Kubernetes to provide a more convenient and productive programmer experience.
    It does that, among other things, by extending the object model of Kubernetes.
    `DeploymentConfiguration` and Deployments are OpenShift objects that extend the
    Kubernetes object model.
  prefs: []
  type: TYPE_NORMAL
- en: The `DeploymentConfiguration` object manages the creation of the Deployments
    objects. It contains all the necessary information to create Deployments, which,
    as its name suggests, represents an instance of deployment. When one of the Deployments
    triggers happens, the old deployment object is replaced by the new one. All of
    the deployment objects are based on `DeploymentConfiguration`. Deployments, among
    others, encapsulate Kubernetes's `ReplicationController` object. Let's understand
    it in greater detail.
  prefs: []
  type: TYPE_NORMAL
- en: Learning the basics of ReplicationController
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`ReplicationController` contains the following information: the pod template,
    selector, and the number of replicas. Let''s examine those further.'
  prefs: []
  type: TYPE_NORMAL
- en: The pod template is basically a pod definition. It contains information about
    the containers, volumes, ports, and labels. Every pod created by this replication
    controller will be started using this pod template. The selector is used to determine
    which pods are governed by this `ReplicationController`. Finally, the number of
    replicas is the number of pods that we want to be running.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes works in the following way: it monitors the current state of the
    cluster, and if that state is different from the desired state it takes actions
    so that the desired state is restored. The same thing happens with `ReplicationControllers`.
    `ReplicationController` continuously monitors the number of pods that are associated
    with it. If the number of the pods is different than the desired number, it starts
    or stops pods so that the desired state is restored. The pod is started using
    the pod template.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s examine the `ReplicationController` that Kubernetes created for our
    catalog-service. To do this, we will use the CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e9048a8c-5ec5-4be4-9a53-6c0c4fff0465.png)'
  prefs: []
  type: TYPE_IMG
- en: As you will notice in the preceding screenshot, there are three replication
    controllers created for catalog-service. This is the case because of each redeployment
    of the application results in the creation of a new deployment object with its
    own replication controller. Note that only catalog-service-3 has the desired number
    of instances greater than 0—the previous deployments have been made inactive when
    the new deployment was taking place.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the description of the active controller:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/991f5556-3a23-416b-9029-9fbfcf65d9e5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The selector has three labels: app, deployment, and deployment-config. It unambiguously
    identifies the pods associated with the given deployment.'
  prefs: []
  type: TYPE_NORMAL
- en: Exactly the same labels are used in the pod template. Other parts of the pod
    template contain the image from which the container is built, and the environment
    variables that we provided during the creation of the service. Finally, the number
    of current and desired replicas is set, by default, to one.
  prefs: []
  type: TYPE_NORMAL
- en: 'OK. So how do we scale our service so that it runs on more than one instance?
    Let''s move to the web console again. We need to navigate to Application | Deployments
    again and enter the catalog-service configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b723deee-6a03-417f-9635-512df87f04f7.png)'
  prefs: []
  type: TYPE_IMG
- en: To scale the catalog-service application, we have to adjust the Replicas field
    to the number of instances that we want to have. That's it.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we look at the `ReplicationControllers` in the `oc`, we will see the following
    information:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7ab5e556-694f-4204-a573-6256888f291a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The number of pods has been changed to 5\. As we saw in the `oc` output, additional
    pods have been started and we now have five instances. Let''s check in the console
    (navigate to Applications | Pods):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/870f86c6-83b8-4afa-b501-20d33e004397.png)'
  prefs: []
  type: TYPE_IMG
- en: OpenShift has indeed scaled our application according to our needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'After having worked with OpenShift for some time, you should be able to see
    what we meant in [Chapter 6](461aee71-984a-4158-addc-fc49341d3455.xhtml), *Deploying
    Applications on the Cloud with OpenShift*, when we wrote that OpenShift builds
    an effective and easy-to-use application development environment on top of Kubernetes.
    The preceding example showed how it works very well: Kubernetes is responsible
    for making sure that the state of the cluster equals the description provided.
    In the preceding example, this description is provided by a `ReplicationController`
    object (which is part of the Kubernetes object model). Note, however, that OpenShift
    has abstracted away all the nitty-gritty details from us. We have only provided
    the information such as the address of the code repository or number of replicas
    that we want to have. The OpenShift layer abstracts away the technical details
    of cluster configuration and provides us with convenient, easy-to-use tools, which
    allow the programmer to concentrate on the development.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's return to our main topic. The next thing that we will configure is **load
    balancing**.
  prefs: []
  type: TYPE_NORMAL
- en: Load balancing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have just learned how to scale our service. The next natural step is to configure
    the load balancer. The good news is that OpenShift will do most of the stuff automatically
    for us.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 6](461aee71-984a-4158-addc-fc49341d3455.xhtml), *Deploying Applications
    on the Cloud with OpenShift*, where we introduced services, we learned that a
    service is reached using a virtual cluster IP. To understand how load balancing
    works, let's understand how cluster IP is implemented.
  prefs: []
  type: TYPE_NORMAL
- en: As we have also learned here, each node in a Kubernetes cluster runs a bunch
    of services, which allow a cluster to provide its functionality. One of those
    services is **kube-proxy**. Kube-proxy runs on every node and is, among other
    things, responsible for service implementation. Kube-proxy continuously monitors
    the object model describing the cluster and gathers information about currently
    active services and pods on which those services run. When the new service appears,
    kube-proxy modifies the iptables rules so that the virtual cluster's IP is routed
    to one of the available pods. The iptables rules are created so that the choice
    of the pod is random. Also, note that those IP rules have to be constantly rewritten
    to match the current state of the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: A kube-proxy runs on every node of the cluster. Owing to that, on each node,
    there is a set of iptables rules, which forward the package to the appropriate
    pods. As a result, the service is accessible from each node of the cluster on
    its virtual cluster IP.
  prefs: []
  type: TYPE_NORMAL
- en: What's the implication of that from the client service perspective? The cluster
    infrastructure is hidden from the service client. The client doesn't need to have
    any knowledge about nodes, pods, and their dynamic movement inside the cluster.
    They just invoke the service using its IP as if it was a physical host.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s return to our example and look at the load balancing of our host. Let''s
    return to the example in which we are working within this chapter. We statically
    scaled our catalog service to five instances. Let''s enter the web console in
    order to look at all the pods on which the application currently runs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6969b4f4-2a1f-4af4-b46b-c496a13cd544.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s trace to which pods are the requests forwarded. In order to achieve
    that, we implemented a simple REST filter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The preceding filter adds a `"pod"` property to the response headers. The filter
    will be evaluated after the response is processed (1). On each pod, there is a
    `"HOSTNAME"` environment variable set. We can use this variable and add it to
    the response metadata (2).
  prefs: []
  type: TYPE_NORMAL
- en: 'As a result, we are ready to trace the load balancing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7eecbe42-793c-4170-890a-a21a339d2987.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding screenshot, note that the request is being automatically load
    balanced among the available pods.
  prefs: []
  type: TYPE_NORMAL
- en: Service discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have already shown you how to configure balancing for our application. We
    know now that you have access to the virtual cluster IP address behind which the
    request is being balanced by OpenShift. However, how do we actually know how to
    connect to our services? We are going to learn that in the next topic. Before
    we do that, we must introduce our new services that will be talking to each other.
  prefs: []
  type: TYPE_NORMAL
- en: New services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the first chapter, we briefly introduced the pet store application and described
    the services that constitute it. By now, we have used solely the catalog service
    in our examples. Now it's time to implement both the pricing service and customer
    gateway service. These services will serve as an example in this and the future
    chapters. Let's start with the pricing service.
  prefs: []
  type: TYPE_NORMAL
- en: The pricing service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The pricing service is very similar to catalog service. It can be used to obtain
    prices for a pet using their names. Let''s go straight to the implementation.
    Initially, we have to create the database. As before, we will use the PostgreSQL
    template:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5089d432-68ce-4dd0-9f27-59d4b4d38d0d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As with the catalog service''s database, we would also like to override the
    labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9fbf091d-5253-4678-b04e-5b33860b96a3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To populate the database, we have to create the following script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, enter the sample data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To populate the database, we will execute the following script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Our pricing database is ready. We can now start writing the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples reference: `chapter8/pricing-service`.'
  prefs: []
  type: TYPE_NORMAL
- en: We have to configure the database in the similar way that we did for catalog-service.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In order for the database to work, we have to provide the JDBC driver module:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f4d00ccd-6c6b-4a34-95be-730bda614b66.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, we also need `persistence.xml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We have to provide an `Entity`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'As in `catalog-service`, we will need a service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need REST resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We would also need an application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Our second service is ready. It''s time to deploy it on OpenShift. Push your
    application to your GitHub repository and invoke:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'After your application is deployed, you can create a route to it and verify
    that it indeed works:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0fb5813b-9d84-4ff6-a8f6-e5bceb63a29c.png)'
  prefs: []
  type: TYPE_IMG
- en: It indeed does. Let's move to the second service.
  prefs: []
  type: TYPE_NORMAL
- en: The customer gateway service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, the stuff becomes more interesting again. The customer-gateway
    service is a gateway to our application, which would provide the external interface
    for the web client. The first request that we will implement is obtaining the
    list of pets. Let''s take a look at the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d07150cb-66ec-4f06-b830-675259ac11e7.png)'
  prefs: []
  type: TYPE_IMG
- en: When the `/catalog/item` request is being executed, the service asks **CATALOG**
    for available items. Based on that information, the pet store service asks the
    **PRICE** service about the price of each pet, merges the results, and then returns
    them to the client. However, how will the gateway service know the addresses of
    the services? We will find that out soon.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples reference: `chapter8/customer-gateway-env`.'
  prefs: []
  type: TYPE_NORMAL
- en: The customer service is configured in a similar way to previous services. If
    you have doubts regarding some parts of configuration please refer to the description
    of those.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the implementation details of `catalog/item` request starting
    with the REST resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `getItems` method gathers the items from the `CatalogService` (1), obtains
    a price for all of them, and merges the obtained results into the list of pets
    available in the store. Please note that we have introduced `CatalogItemView`—a
    transport object which is a part of the API for the web client.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have also implemented the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The getItems method implementation (1) is pretty straightforward. We are combining
    data from catalog and pricing services and returning the list of resulting object.
    The most interesting part here is the proxies which enable us to communicate with
    those services (2). Let's learn how to implement them.
  prefs: []
  type: TYPE_NORMAL
- en: Environment variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When the new service is created, its coordinates are written into environment
    variables in every pod in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s log in to one of the pods inside the cluster and take a look at it.
    All the OpenShift environment variable names are written in uppercase, and we
    need the data about the pricing service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3bfc0bb5-3f2a-4b60-9285-181178c10b32.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding screenshot, note that there are a number of variables describing
    the coordinates of the service. The property that interests us is the host address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Note that this is the virtual cluster IP again. As a result, as long as the
    service is not removed, the proxy address will stay the same. Underlying infrastructure
    changes caused by deployments, node addition, or failures will not result in the
    change of the previous address.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s write proxies that will use this variable in order to connect to the
    services. We will start with the pricing-service proxy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: That's just it. We obtained the `clusterIP` of the pricing-service when the
    proxy was being created (1) and the user straightforward REST Client API to provide
    an adapter for the `getPrice` method invocation (2).
  prefs: []
  type: TYPE_NORMAL
- en: The implementation of `catalogProxy` is analogous.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we are ready to check whether our application is working. Let''s create
    a route for the `petstore` service and check the web browser:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/af7f0316-1188-46d8-be09-6b7b70d36885.png)'
  prefs: []
  type: TYPE_IMG
- en: It works indeed. This solution has a major disadvantage though—an ordering problem.
    If the pod is created before the service, then service coordinates won't be present
    in the pod environment. Is there a better way to discover the services, then?
    Yes, through **Domain Name Service** (**DNS**).
  prefs: []
  type: TYPE_NORMAL
- en: DNS discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Each OpenShift cluster contains a DNS service. This service allows you to discover
    services easily using the service name. Each service registers to the DNS service
    during the registration, and later periodically sends live messages to it. The
    DNS server creates a record using the following pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Let's take the pricing service as an example. We have created the `petstore`
    application. As a result, the name of the service created using the preceding
    pattern would be pricing-`service.petstore.svc`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can confirm that information inside web console. Let''s navigate to Applications
    | Services | pricing-service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8155956d-79f5-4a9d-a357-d143e73638e0.png)'
  prefs: []
  type: TYPE_IMG
- en: Take note of the `hostname` field—this is the address that we created previously.
    Another important thing to note is that those service names are visible only from
    inside the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to refactor our application to use elegant DNS discovery.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples reference: `chapter8/customer-gateway-dns`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have to rewrite both our proxies. Let''s start with `PricingProxy`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We defined a `targetPath` that we can use repeatedly to connect to services
    (1). We are going to provide it as a parameter using YAML configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Again, `CatalogProxy` implementation is analogous.
  prefs: []
  type: TYPE_NORMAL
- en: Now we are ready to redeploy the customer-gateway service again. You can once
    again check whether it works correctly.
  prefs: []
  type: TYPE_NORMAL
- en: As you may recall, we were using the name of the service when we were creating
    the environment file for our databases. Each service in the cluster can be reached
    using this method.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to scale and discover services inside the cluster.
    As you were able to see throughout this chapter, most of the work was done by
    OpenShift. Load balancing is implemented automatically by the services, and the
    integrated DNS service allows for straightforward service discovery.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn more about networking. You will also learn
    how to provide resiliency to a service invocation so that underlying network failures
    won't cause your application to stop working.
  prefs: []
  type: TYPE_NORMAL
