- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Measuring Performance and Benchmarking Your Applications
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测量性能和基准测试你的应用程序
- en: In the preceding chapters, we learned how to architect a solution for data ingestion
    and data publishing problems. We also discussed how we can choose the correct
    technology stack and platform to implement a cost-effective and scalable solution.
    Apart from these, we learned about various architectural patterns for data ingestion.
    We also discussed data governance and data security. However, as an architect,
    our job is not only to create a scalable solution but a high-performing one. This
    is where the role of performance engineering comes into a data architect’s toolkit.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们学习了如何为数据摄取和数据发布问题设计解决方案。我们还讨论了如何选择正确的技术栈和平台来实现成本效益高且可伸缩的解决方案。除此之外，我们还了解了各种数据摄取的架构模式。我们还讨论了数据治理和数据安全。然而，作为架构师，我们的工作不仅仅是创建可伸缩的解决方案，还要创建高性能的解决方案。这就是性能工程在数据架构师工具箱中发挥作用的地方。
- en: In this chapter, we will discuss the meaning of performance engineering and
    why is it so important. We will also learn how is it different from performance
    testing. Then, we will learn how to plan our performance tests and other performance
    engineering activities. Then, we will briefly discuss performance benchmarking
    techniques. Finally, we will learn about the common methodologies to fine-tune
    the performance of our solution to mitigate or avoid various kinds of performance
    bottlenecks during data ingestion or data publishing.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论性能工程的意义以及为什么它如此重要。我们还将了解它与性能测试有何不同。然后，我们将学习如何规划我们的性能测试和其他性能工程活动。然后，我们将简要讨论性能基准测试技术。最后，我们将了解在数据摄取或数据发布过程中缓解或避免各种性能瓶颈的常见方法来微调我们解决方案的性能。
- en: By the end of this chapter, you will know what performance engineering is and
    how to plan for it. You will know how to benchmark and publish performance results.
    You will know what the available performance tools are and when to use them. Finally,
    you will know how to fine-tune performance to create an optimized, highly performant
    solution for the data problem, as well as how to perform performance benchmarking.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将了解性能工程是什么以及如何为其制定计划。你将知道如何进行基准测试和发布性能结果。你将了解可用的性能工具以及何时使用它们。最后，你将了解如何微调性能以创建针对数据问题的优化、高性能解决方案，以及如何进行性能基准测试。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Performance engineering and planning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能工程与规划
- en: Tools for performance engineering
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能工程工具
- en: Publishing performance benchmarks
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布性能基准
- en: Optimizing performance
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化性能
- en: Performance engineering and planning
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能工程与规划
- en: '**Software performance engineering** (**SPE**) is a systematic and quantitative
    software-based approach to designing, architecting, and implementing solutions
    optimally to meet various **non-functional requirements** (**NFRs**) such as performance,
    capacity, scalability, availability, and reliability. Earlier in this book, we
    dealt with scalability, availability, and reliability. In this chapter, we will
    focus on performance and capacity. Alternatively, SPE is defined as a proactive
    and continuous process of performance testing and monitoring. It involves different
    stakeholders such as testers, developers, performance engineers, business analysts,
    and architects. As we will discuss later in this chapter, performance engineering
    is a seamless process that runs in parallel with development activities, providing
    a continuous feedback loop to the developers and architects so that performance
    requirements are imbibed while the software is developed.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**软件性能工程**（**SPE**）是一种系统性和量化的基于软件的方法，旨在设计、架构和实施解决方案，以最佳方式满足各种**非功能性需求**（**NFRs**），如性能、容量、可伸缩性、可用性和可靠性。在本书的早期，我们讨论了可伸缩性、可用性和可靠性。在本章中，我们将重点关注性能和容量。或者，SPE被定义为一种主动和持续的性能测试和监控过程。它涉及不同的利益相关者，如测试人员、开发者、性能工程师、业务分析师和架构师。正如我们将在本章后面讨论的，性能工程是一个无缝的过程，它与开发活动并行运行，为开发者和架构师提供持续的反馈循环，以便在软件开发过程中吸收性能需求。'
- en: 'Now that we’ve defined performance engineering, let’s discuss the phases of
    a performance engineering life cycle and how it progresses alongside the **software
    development life cycle** (**SDLC**) activities. The following diagram shows this:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经定义了性能工程，那么让我们讨论一下性能工程生命周期的各个阶段以及它是如何与**软件开发生命周期（SDLC**）活动并行的。以下图表展示了这一点：
- en: '![Figure 11.1 – Performance engineering life cycle ](img/B17084_11_001.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图11.1 – 性能工程生命周期](img/B17084_11_001.jpg)'
- en: Figure 11.1 – Performance engineering life cycle
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1 – 性能工程生命周期
- en: 'As we can see, the following are the various stages of the performance engineering
    life cycle:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，以下是性能工程生命周期的各个阶段：
- en: '**NFR gathering**: To develop a high-performant data pipeline, it is important
    to understand the NFRs of the solution. For example, while designing a DaaS, it
    makes more sense to know what the required **transactions per second** (**TPS**)
    are and what the average parallel load to the system would be. There may be another
    requirement while designing the pipeline, which is that it should be able to be
    integrated with Datadog for monitoring purposes. In such a scenario, a technology
    stack should be chosen so that Datadog integration is supported. To gather all
    this information, we need a close connection between product owners, system analysts,
    **subject matter experts** (**SMEs**), architects, the SPE team, and DevOps.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收集NFR**：为了开发高性能的数据管道，了解解决方案的非功能性需求非常重要。例如，在设计DaaS时，了解所需的每秒**事务数（TPS**）和系统平均并行负载更有意义。在设计管道时，可能还有另一个要求，即它应该能够与Datadog集成以进行监控。在这种情况下，应选择支持Datadog集成的技术堆栈。为了收集所有这些信息，我们需要产品负责人、系统分析师、**领域专家（SMEs**）、架构师、SPE团队和DevOps之间有紧密的联系。'
- en: '**Design for performance and performance modeling**: In the waterfall model,
    performance testing and optimization are done after the functional and integrational
    test cycles are over. The problem with this approach is that sometimes, architectures
    that work beautifully with small datasets may not work at all in terms of load
    testing. Due to this, we have to re-engineer the solution again. This causes a
    lot of waste in terms of effort, time, and money. As modern data engineering teams
    have increasingly adopted agile methodologies, the opportunity has increased for
    simultaneously adopting performance engineering. After the nonfunctional requirements
    have been gathered, designing for performance requires that the following criteria
    be fulfilled:'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**针对性能和性能建模进行设计**：在瀑布模型中，性能测试和优化是在功能性和集成测试周期结束后进行的。这种方法的缺点是，与小型数据集完美工作的架构在负载测试方面可能根本不起作用。因此，我们必须再次重新设计解决方案。这导致在努力、时间和金钱方面造成了大量的浪费。由于现代数据工程团队越来越多地采用敏捷方法，同时采用性能工程的机会也增加了。在收集了非功能性需求之后，针对性能的设计需要满足以下标准：'
- en: Satisfy the NFRs with optimal speed
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以最佳速度满足NFRs
- en: The solution must be scalable enough to have similar performance, even with
    increased load
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决方案必须足够可扩展，即使在负载增加的情况下也能保持相似的性能
- en: Our architecture should be designed to scale as business data increases exponentially.
    This brings to life ideas such as design to fail, scaling out rather than scaling
    up the application, and auto-scaling resources in the cloud. Another method that’s
    commonly applied during performance-oriented design is **performance modeling**.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的架构应该设计成随着业务数据的指数增长而扩展。这使设计失败、扩展应用而不是向上扩展应用以及云中自动扩展资源等想法变得生动起来。在以性能为导向的设计中，通常还应用了另一种常见方法，即**性能建模**。
- en: Performance modeling is the process of modeling application performance based
    on features involved in the growth rate of data to find out probable breaches
    of SLA. It also helps validate design decisions and infrastructure decisions.
    Let’s look at an example – suppose input messages are coming in an application
    at a rate of *x*, and the service rate of the application is *y*. What happens
    if the arrival rate of messages quadruples itself? How do we ensure the same response
    time? Do we need to quadruple the service rate or double the service rate? This
    kind of decision can be made by doing performance modeling. In modern data architectures
    where applications tend to run on containerized or virtualized platforms, this
    can determine how to allocate resources to scale in the future.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 性能建模是基于数据增长率中涉及的特征来建模应用性能的过程，目的是找出可能的SLA违规情况。它还有助于验证设计决策和基础设施决策。让我们来看一个例子——假设输入消息以速率*x*进入一个应用，该应用的响应速率是*y*。如果消息的到达速率是其自身的四倍会发生什么？我们如何确保相同的响应时间？我们需要将服务速率增加到四倍还是增加到两倍？这种决策可以通过性能建模来完成。在现代数据架构中，应用往往运行在容器化或虚拟化平台上，这可以确定未来如何分配资源以进行扩展。
- en: '**Modular performance tests and optimization**: In this phase, using NFRs,
    **non-functional tests** (**NFTs**) are classified as stress tests, load tests,
    or soak tests. Once the test cases have been classified, a test case document
    that maps NFTs with detailed steps to run the test scenario is prepared. Optionally,
    an NFT to NFR performance matrix is created. Then, using these documents, NFRs
    can be tested as a module gets developed and functionally tested. Running these
    test cases along with functional testing ensures early detection of any performance
    glitches. Optimization and performance tuning can be done as required by the development
    or DevOps teams.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模块化性能测试和优化**：在这个阶段，使用NFRs，**非功能性测试**（NFTs）被分类为压力测试、负载测试或浸泡测试。一旦测试用例被分类，就准备一个测试用例文档，该文档将NFTs与运行测试场景的详细步骤相对应。可选地，创建一个NFT到NFR性能矩阵。然后，使用这些文档，可以在模块开发并功能测试时测试NFRs。运行这些测试用例与功能测试相结合，可以确保早期发现任何性能问题。优化和性能调整可以根据开发或DevOps团队的需求进行。'
- en: '**Fully integrated performance test**: Once the modular performance test is
    done, end-to-end performance tests can be run. As the **quality assurance** (**QA**)
    of a scenario finishes, that scenario moves to be tested for integration performance.
    Usually, in this layer, not much tuning or optimization is required. However,
    optimization of the overall end-to-end flow may be required during this activity.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**完全集成的性能测试**：一旦完成模块化性能测试，就可以运行端到端性能测试。随着场景的**质量保证**（QA）完成，该场景将移动到测试集成性能。通常，在这一层，不需要太多调整或优化。然而，在此次活动期间，可能需要优化整体端到端流程。'
- en: '**Monitoring and capacity management**: Once the pipeline is in production,
    we need to continuously monitor and evaluate any unusual activities. Based on
    the future and current state of the workloads, capacity can be predicted and managed
    properly.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控和容量管理**：一旦管道投入生产，我们需要持续监控和评估任何异常活动。根据未来和当前的工作负载状态，可以预测并适当管理容量。'
- en: In this section, we learned the various stages of the performance engineering
    life cycle. Next, let’s understand the differences between performance engineering
    and performance testing.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了性能工程生命周期的各个阶段。接下来，让我们了解性能工程与性能测试之间的区别。
- en: Performance engineering versus performance testing
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能工程与性能测试
- en: 'The key differences between performance engineering and performance testing
    are as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 性能工程与性能测试之间的关键区别如下：
- en: Performance testing is a QA activity that runs test cases to check the quality
    of NFRs and find any issues. It is performed to check how the system will behave
    in terms of production load and anticipates any issues that could come up during
    heavy loads. On the other hand, performance engineering is a holistic process
    that runs hand-in-hand with SDLC. Unlike performance testing, performance engineering
    starts as early as the analysis phase. It also facilitates the discovery of performance
    issues early in the development life cycle.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能测试是一个QA活动，它运行测试用例来检查NFRs的质量并找出任何问题。它是为了检查系统在负载生产方面的行为，并预测在重负载期间可能出现的任何问题。另一方面，性能工程是一个与SDLC同步进行的整体过程。与性能测试不同，性能工程从分析阶段开始。它还促进了在开发生命周期早期发现性能问题。
- en: Performance testing follows the waterfall model of the software development
    process. It is only done when software development and functional testing have
    been completed. The problem with such an approach is that if the application fails
    to perform with production loads, we may need to redesign and re-implement, causing
    unnecessary time and financial loss. However, performance engineering is a continuous
    process that goes hand-in-hand with all phases of SDLC and is usually implemented
    by agile teams with a continuous feedback loop to the development and design team.
    By providing early analysis of performance needs and early discovery of issues,
    performance engineering helps us save time and money.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能测试遵循软件开发过程的水下模型。它仅在软件开发和功能测试完成后进行。这种方法的缺点是，如果应用程序在生产负载下无法正常工作，我们可能需要重新设计和重新实现，这会导致不必要的耗时和财务损失。然而，性能工程是一个持续的过程，与SDLC的所有阶段相辅相成，通常由敏捷团队实施，并具有持续反馈循环到开发和设计团队。通过提供性能需求的前期分析和问题的早期发现，性能工程帮助我们节省时间和金钱。
- en: Performance testing is conducted by the QA team, whereas performance engineering
    involves architects, developers, SMEs, performance engineers, and QA.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能测试由QA团队执行，而性能工程涉及架构师、开发者、SMEs、性能工程师和QA。
- en: In this section, we learned about performance engineering, why is it needed,
    and its life cycle. We also discussed the difference between performance testing
    and performance engineering. In the next section, we will briefly discuss the
    performance engineering tools available in the market.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了性能工程，为什么需要它，以及它的生命周期。我们还讨论了性能测试和性能工程之间的区别。在下一节中，我们将简要讨论市场上可用的性能工程工具。
- en: Tools for performance engineering
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能工程工具
- en: In this section, we will briefly discuss various performance engineering tools.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将简要讨论各种性能工程工具。
- en: 'The following are the different categories of performance engineering tools
    available:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是可以用的不同类别的性能工程工具：
- en: '**Observability tools**: These tools monitor and gather information about the
    application. These tools potentially help to identify bottlenecks, track throughput
    and latency, memory usage, and so on. In data engineering, each system is different,
    and the throughput and latency requirements are also different. Observability
    tools help identify if our application is lagging in terms of throughput or latency
    and by how much. They also help identify hidden issues that may only show up in
    the long run, in production. For example, a small memory leak in the application
    may not be noticeable within a few days of deployment. When such an application
    keeps on running, the tenured region of JVM heap space keeps slowly increasing
    until it overruns the heap space. The following are a few examples of observability
    tools:'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可观测性工具**：这些工具监控并收集关于应用程序的信息。这些工具可能有助于识别瓶颈、跟踪吞吐量和延迟、内存使用等情况。在数据工程中，每个系统都是不同的，吞吐量和延迟的要求也不同。可观测性工具有助于确定我们的应用程序在吞吐量或延迟方面是否落后，以及落后多少。它们还有助于识别可能仅在长期运行中、在生产中出现的隐藏问题。例如，应用程序中的微小内存泄漏在部署后的几天内可能不明显。当这样的应用程序持续运行时，JVM堆空间的旧区域会缓慢增加，直到超过堆空间。以下是一些可观测性工具的例子：'
- en: '**Datadog**: This is a very popular monitoring tool that can do application
    monitoring, network monitoring, database monitoring, container monitoring, serverless
    monitoring, and more. It has an inbuilt dashboard and capabilities to customize
    your dashboard according to your needs. It has alerting, log integration, and
    other cool features. It is a paid product, which provides enterprise support.
    For more information, please visit [https://www.datadoghq.com/](https://www.datadoghq.com/).'
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Datadog**：这是一个非常流行的监控工具，可以进行应用程序监控、网络监控、数据库监控、容器监控、无服务器监控等。它具有内置的仪表板和根据您的需求自定义仪表板的功能。它具有警报、日志集成和其他酷炫功能。这是一个付费产品，提供企业级支持。更多信息，请访问[https://www.datadoghq.com/](https://www.datadoghq.com/)。'
- en: '**Grafana with Graphite/Prometheus**: This is an open source monitoring and
    dashboarding tool. It is either used with Prometheus or Graphite. Both Prometheus
    and Graphite are open source monitoring toolkits that help generate and publish
    various metrics. Prometheus has a data collector module that can pull data to
    generate metrics. On the other hand, Graphite can only passively listen for data
    but can’t collect it. Some other tool, such as Collectd, needs to collect and
    push data to Graphite. To query Graphite metrics, functions are used, whereas
    PromQL is used to query Prometheus metrics. These generated metrics are integrated
    with Grafana to create different kinds of dashboards, such as stats dashboards,
    time series monitoring, status timeline and history, alerting dashboards, and
    so on. For more information, please visit [https://grafana.com/](https://grafana.com/).'
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Grafana与Graphite/Prometheus**: 这是一个开源的监控和仪表盘工具。它可以与Prometheus或Graphite一起使用。Prometheus和Graphite都是开源的监控工具包，有助于生成和发布各种指标。Prometheus有一个数据收集模块，可以拉取数据以生成指标。另一方面，Graphite只能被动监听数据，但不能收集它。一些其他工具，如Collectd，需要收集并将数据推送到Graphite。查询Graphite指标时使用函数，而PromQL用于查询Prometheus指标。这些生成的指标与Grafana集成，以创建不同类型的仪表盘，例如统计仪表盘、时间序列监控、状态时间线和历史记录、警报仪表盘等。更多信息，请访问[https://grafana.com/](https://grafana.com/)。'
- en: '**Dynatrace**: Dynatrace is another commercial monitoring and dashboarding
    tool that has very similar features to Datadog. It also provides an AI assistant
    to help answer your queries dynamically. It supports DevOps and CloudOps integrations
    such as CI/CD pipelines and so on. For more information, please visit [https://www.dynatrace.com/](https://www.dynatrace.com/).'
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Dynatrace**: Dynatrace是另一个具有与Datadog非常相似功能的商业监控和仪表盘工具。它还提供了一个AI助手，可以帮助动态回答您的查询。它支持DevOps和CloudOps集成，如CI/CD管道等。更多信息，请访问[https://www.dynatrace.com/](https://www.dynatrace.com/)。'
- en: '**Confluent Control Center**: This is an inbuilt confluent Kafka monitoring
    tool that is shipped with an Enterprise (Licensed) version of Confluent Kafka.
    It helps monitor various Kafka components such as topics, producers, consumers,
    Kafka Connect clusters, KSQL queries, as well as overall Kafka cluster health.
    For more information, please visit [https://docs.confluent.io/platform/current/control-center/index.xhtml](https://docs.confluent.io/platform/current/control-center/index.xhtml).'
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Confluent Control Center**: 这是一个内置的Confluent Kafka监控工具，随Confluent Kafka的企业（授权）版本一起提供。它有助于监控各种Kafka组件，如主题、生产者、消费者、Kafka
    Connect集群、KSQL查询以及整体Kafka集群健康。更多信息，请访问[https://docs.confluent.io/platform/current/control-center/index.xhtml](https://docs.confluent.io/platform/current/control-center/index.xhtml)。'
- en: '**Lenses**: This is a tool that provides observability of Kafka topics, clusters,
    and streams. Lenses not only supports observability but also DataOps for Kafka
    clusters. For more information, please visit [https://docs.lenses.io/](https://docs.lenses.io/).'
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Lenses**: 这是一个提供Kafka主题、集群和流可观测性的工具。Lenses不仅支持可观测性，还支持Kafka集群的DataOps。更多信息，请访问[https://docs.lenses.io/](https://docs.lenses.io/)。'
- en: '**Performance testing and benchmarking tools**: These tools are used to do
    all kinds of performance tests, such as smoke tests, load tests, and stress tests.
    Some of them also provide benchmarking features. The following are a few of the
    tools that can be used for performance testing and benchmarking:'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能测试和基准测试工具**: 这些工具用于进行各种性能测试，例如烟雾测试、负载测试和压力测试。其中一些还提供基准测试功能。以下是一些可用于性能测试和基准测试的工具：'
- en: '**JMeter**: This is a free open source tool written in Java that does performance
    tests. It is especially helpful for big data performance testing and any performance
    testing of APIs, such as REST and GraphQL. JMeter Hadoop plugins are available
    to do big data performance testing. We can run the load tests and export the result
    to a file in multiple formats. For more information, please visit [https://jmeter.apache.org/](https://jmeter.apache.org/).'
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**JMeter**: 这是一个用Java编写的免费开源工具，用于性能测试。它特别适用于大数据性能测试以及任何API的性能测试，如REST和GraphQL。JMeter
    Hadoop插件可用于进行大数据性能测试。我们可以运行负载测试并将结果导出为多种格式的文件。更多信息，请访问[https://jmeter.apache.org/](https://jmeter.apache.org/)。'
- en: '**SoapUI**: This is another open source performance test tool that is used
    for functional testing as well. It supports load testing with multiple users,
    threads, and parallelism for web services such as REST, SOAP, and GraphQL. It
    has a professional commercial edition as well called ReadyAPI. The commercial
    edition supports more advanced features and specific plugins for testing GraphQL
    and Kafka streaming applications. For more information, please visit [https://www.soapui.org/](https://www.soapui.org/).'
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SoapUI**：这是另一个用于功能测试的开源性能测试工具。它支持对REST、SOAP和GraphQL等Web服务的多用户、线程和并行负载测试。它还有一个名为ReadyAPI的专业商业版，该商业版支持更多高级功能和针对测试GraphQL和Kafka流应用的特定插件。更多信息，请访问[https://www.soapui.org/](https://www.soapui.org/)。'
- en: '**Blazemeter**: This is another open source performance test tool that’s used
    to run scalable tests for microservices such as REST or GraphQL APIs. It supports
    a few monitoring functionalities as well. For more information, please visit [https://www.blazemeter.com/](https://www.blazemeter.com/).'
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Blazemeter**：这是另一个开源性能测试工具，用于运行微服务（如REST或GraphQL API）的可扩展测试。它还支持一些监控功能。更多信息，请访问[https://www.blazemeter.com/](https://www.blazemeter.com/)。'
- en: '**LoadRunner**: LoadRunner is a commercial product from Microfocus that enables
    load testing for various workloads and various kinds of applications. It supports
    testing of over 50 types of applications such as microservices, HTML, MQTT, Oracle,
    and so on. For more information, please visit [https://www.microfocus.com/en-us/products/loadrunner-professional/overview](https://www.microfocus.com/en-us/products/loadrunner-professional/overview).'
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LoadRunner**：LoadRunner是Microfocus的一个商业产品，它能够为各种工作负载和各种类型的应用程序提供负载测试。它支持超过50种应用程序的测试，例如微服务、HTML、MQTT、Oracle等。更多信息，请访问[https://www.microfocus.com/en-us/products/loadrunner-professional/overview](https://www.microfocus.com/en-us/products/loadrunner-professional/overview)。'
- en: '**SandStorm**: This is a commercial benchmarking and enterprise-level performance
    testing tool. It has huge support for various applications and tools, from JDBC
    connections to big data testing. It supports NoSQL databases such as Cassandra,
    HBase, and MongoDB, as well as other big data components such as Hadoop, Elasticsearch,
    and Solar. It also provides support for messaging platforms such as Kafka and
    RabbitMQ. For more information, please visit [http://www.sandstormsolution.com/](http://www.sandstormsolution.com/).'
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SandStorm**：这是一个商业基准测试和企业级性能测试工具。它对各种应用程序和工具提供巨大支持，从JDBC连接到大数据测试。它支持Cassandra、HBase和MongoDB等NoSQL数据库，以及Hadoop、Elasticsearch和Solar等大数据组件。它还提供对Kafka和RabbitMQ等消息平台的支持。更多信息，请访问[http://www.sandstormsolution.com/](http://www.sandstormsolution.com/)。'
- en: '`kafka-producer-perf-test.sh` and `kafka-consumer-perf-test.sh`. While the
    former script is used to test producer performance, the latter is used to test
    consumer performance. To learn more about this feature, go to [https://docs.cloudera.com/runtime/7.2.10/kafka-managing/topics/kafka-manage-cli-perf-test.xhtml](https://docs.cloudera.com/runtime/7.2.10/kafka-managing/topics/kafka-manage-cli-perf-test.xhtml).'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kafka-producer-perf-test.sh` 和 `kafka-consumer-perf-test.sh`。前一个脚本用于测试生产者性能，后一个脚本用于测试消费者性能。要了解更多关于此功能的信息，请访问[https://docs.cloudera.com/runtime/7.2.10/kafka-managing/topics/kafka-manage-cli-perf-test.xhtml](https://docs.cloudera.com/runtime/7.2.10/kafka-managing/topics/kafka-manage-cli-perf-test.xhtml)。'
- en: '**OpenMessaging Benchmark Framework**: This is a set of tools that allows you
    to benchmark distributed messaging systems over the cloud easily. It supports
    multiple message platforms such as Apache Kafka, Apache Pulsar, Apache RocketMQ,
    and so on. For more information, please visit [https://openmessaging.cloud/docs/benchmarks/](https://openmessaging.cloud/docs/benchmarks/).'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**OpenMessaging Benchmark Framework**：这是一套工具，允许您轻松地在云上对分布式消息系统进行基准测试。它支持Apache
    Kafka、Apache Pulsar、Apache RocketMQ等多个消息平台。更多信息，请访问[https://openmessaging.cloud/docs/benchmarks/](https://openmessaging.cloud/docs/benchmarks/)。'
- en: In this section, we briefly discussed multiple tools that can be used for performance
    engineering. Now that we have a fair idea of what performance engineering is,
    how to do it, and the tools we can use for it, let’s look at how we can create
    performance benchmarks using the knowledge that we have gained.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们简要讨论了可以用于性能工程的多款工具。现在我们已经对性能工程有了相当的了解，包括如何进行以及我们可以使用的工具，让我们看看如何利用我们所获得的知识来创建性能基准。
- en: Publishing performance benchmarks
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发布性能基准
- en: In this section, we will learn about performance benchmarking and how to develop
    and publish them. We will start by defining what a performance benchmark is. A
    benchmark in software performance testing is defined as a point of reference against
    which the quality measures of a software solution can be assessed. It can be used
    to do a comparative study of different solutions to the same problem or compare
    software products.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习关于性能基准测试以及如何开发和发布它们。我们将从定义性能基准是什么开始。软件性能测试中的基准被定义为评估软件解决方案质量度量的参考点。它可以用来对同一问题的不同解决方案进行比较研究，或比较软件产品。
- en: Benchmarks are like stats or metrics to determine the quality of software. Just
    like in sports such as soccer, each player’s worth or quality is determined by
    various stats such as their overall number of goals scored, number of goals scored
    per match, number of goals scored tournament-wise, and so on. These stats help
    compare different players under different specifications. Similarly, benchmarks
    in the software world help determine the worth of a software product or solution
    under specific conditions.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试就像统计数据或度量标准，用于确定软件的质量。就像在足球等运动中，每位球员的价值或质量是通过各种统计数据来确定的，例如他们总共进球数、每场比赛进球数、锦标赛进球数等。这些统计数据有助于在不同规格下比较不同的球员。同样，软件世界中的基准测试有助于在特定条件下确定软件产品或解决方案的价值。
- en: Now, let’s practically run some performance tests and create a performance benchmark.
    We will use the REST API that we developed in [*Chapter 9*](B17084_09.xhtml#_idTextAnchor144),
    *Exposing MongoDB as a Service*, to do the performance testing. We will use JMeter
    to test and record the performance of the application. We chose JMeter since it
    is easy to use and is an open source product based on Java.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们实际运行一些性能测试并创建性能基准。我们将使用我们在[*第9章*](B17084_09.xhtml#_idTextAnchor144)，“将MongoDB作为服务公开”中开发的REST
    API来进行性能测试。我们将使用JMeter来测试和记录应用程序的性能。我们选择JMeter，因为它易于使用，并且是一个基于Java的开源产品。
- en: 'Follow these steps to do a performance test and benchmark:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤进行性能测试和基准测试：
- en: '**Add a thread group**:  First, we must add a thread group. To add a thread
    group, we need to do the following:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**添加线程组**：首先，我们必须添加一个线程组。要添加线程组，我们需要执行以下操作：'
- en: Start the JMeter tool.
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动JMeter工具。
- en: From the tree in the left pane, select **Test Plan**.
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧的树中选择**测试计划**。
- en: 'Right-click on **Test Plan**. Then, click **Add** | **Threads (Users)** | **Thread
    Group** to add a thread group, as shown in the following screenshot:'
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键单击**测试计划**。然后，点击**添加** | **线程（用户）** | **线程组**以添加线程组，如图下所示：
- en: '![Figure-11.2 – Adding a thread group ](img/B17084_11_002.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图-11.2 – 添加线程组](img/B17084_11_002.jpg)'
- en: Figure-11.2 – Adding a thread group
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图-11.2 – 添加线程组
- en: 'In the **Thread Group** creation wizard, fill in the thread group’s name and
    enter the thread’s properties, as shown in the following screenshot:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在**线程组**创建向导中，填写线程组的名称并输入线程属性，如图下所示：
- en: '![Figure 11.3 – The Thread Group creation wizard ](img/B17084_11_003.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图11.3 – 线程组创建向导](img/B17084_11_003.jpg)'
- en: Figure 11.3 – The Thread Group creation wizard
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3 – 线程组创建向导
- en: 'As you can see, **Number of Threads (users)**, **Loop Count**, and **Ramp-up
    period (seconds)** have been configured. Let’s try to understand these terms:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，**线程数（用户）**、**循环次数**和**预热时间（秒）**已经配置。让我们尝试理解这些术语：
- en: '**Number of Threads (users)** corresponds to the number of users making the
    request simultaneously, as shown in the following diagram:'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线程数（用户）**对应于同时发起请求的用户数量，如图下所示：'
- en: '![Figure 11.4 – Number of threads versus loop count ](img/B17084_11_004.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图11.4 – 线程数与循环次数的关系](img/B17084_11_004.jpg)'
- en: Figure 11.4 – Number of threads versus loop count
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.4 – 线程数与循环次数的关系
- en: '`5`. So, a user makes 5 requests to the server.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`5`。因此，一个用户向服务器发送5个请求。'
- en: '`50` and `50`. Hence, there is a delay of 1 second before it starts the next
    user.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`50`和`50`。因此，在启动下一个用户之前有一个1秒的延迟。'
- en: Now that we have configured our thread group, let’s try adding the JMeter elements.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经配置了线程组，让我们尝试添加JMeter元素。
- en: '**Configure the JMeter elements**: Now, we will add a JMeter config element
    known as an HTTP Request. This helps make REST or web service calls for load tests.
    Right-click **REST Thread group** and select **Add** | **Sampler** | **HTTP Request**,
    as shown in the following screenshot:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**配置 JMeter 元素**：现在，我们将添加一个名为 HTTP 请求的 JMeter 配置元素。这有助于在负载测试中进行 REST 或 Web
    服务调用。右键点击 **REST 线程组** 并选择 **添加** | **采样器** | **HTTP 请求**，如图下截图所示：'
- en: '![Figure 11.5 – Adding a sampler ](img/B17084_11_005.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.5 – 添加采样器](img/B17084_11_005.jpg)'
- en: Figure 11.5 – Adding a sampler
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.5 – 添加采样器
- en: 'Set up `http`, `8080` (if running on a local machine), `GET`, and our **Path**,
    as shown in the following screenshot:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 `http`、`8080`（如果运行在本地机器上）、`GET` 和我们的 **路径**，如图下截图所示：
- en: '![Figure 11.6 – Configuring the HTTP Request sampler ](img/B17084_11_006.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.6 – 配置 HTTP 请求采样器](img/B17084_11_006.jpg)'
- en: Figure 11.6 – Configuring the HTTP Request sampler
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.6 – 配置 HTTP 请求采样器
- en: Now that we have configured the HTTP Request sampler, we need to add a few JMeter
    elements that can monitor and publish performance reports. For this, we must configure
    one or more listeners.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经配置了 HTTP 请求采样器，我们需要添加一些 JMeter 元素来监控和发布性能报告。为此，我们必须配置一个或多个监听器。
- en: '**Add a listener**: To create performance benchmarks, we must add three listeners,
    as follows:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**添加监听器**：要创建性能基准，我们必须添加三个监听器，如下所示：'
- en: '**Summary Report**'
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**总结报告**'
- en: '**Aggregate Report**'
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聚合报告**'
- en: '**Response Time Graph**'
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**响应时间图**'
- en: 'The steps to add a listener are similar to configuring any new listener. Here,
    we will demonstrate how to add an aggregated performance benchmark, as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 添加监听器的步骤与配置任何新的监听器类似。在此，我们将演示如何添加聚合性能基准，如下所示：
- en: 'Right-click **REST Thread Group** and then select **Add** | **Listener** |
    **Aggregate Report**, as shown in the following screenshot:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键点击 **REST 线程组**，然后选择 **添加** | **监听器** | **聚合报告**，如图下截图所示：
- en: '![Figure 11.7 – Adding a listener ](img/B17084_11_007.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.7 – 添加监听器](img/B17084_11_007.jpg)'
- en: Figure 11.7 – Adding a listener
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.7 – 添加监听器
- en: 'Rename the report to `Aggregate Performance Benchmark` in the configuration
    wizard of **Aggregate Report**, as shown in the following screenshot:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **聚合报告** 的配置向导中将报告重命名为 `聚合性能基准`，如图下截图所示：
- en: '![Figure 11.8 – Configuring the Aggregate Report listener ](img/B17084_11_008.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.8 – 配置聚合报告监听器](img/B17084_11_008.jpg)'
- en: Figure 11.8 – Configuring the Aggregate Report listener
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.8 – 配置聚合报告监听器
- en: Follow similar steps to set up the **Summary Report** and **Response Time Graph**
    listeners. By doing so, we will be set to run the test and generate the report.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 按照类似的步骤设置 **总结报告** 和 **响应时间图** 监听器。通过这样做，我们将准备好运行测试并生成报告。
- en: '**Run load tests and create a benchmark**: Run the tests by clicking the start
    symbol that’s encircled in red in the following screenshot:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**运行负载测试并创建基准**：通过点击以下截图中用红色圈出的启动符号来运行测试：'
- en: '![Figure 11.9 – Running performance tests by clicking the Run button ](img/B17084_11_009.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.9 – 通过点击运行按钮运行性能测试](img/B17084_11_009.jpg)'
- en: Figure 11.9 – Running performance tests by clicking the Run button
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.9 – 通过点击运行按钮运行性能测试
- en: 'On successfully executing the performance tests, the following reports are
    generated:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功执行性能测试后，将生成以下报告：
- en: '**Summary Report**: This report provides a summary of the performance benchmark
    and shows the average, minimum, and maximum response time of the request. You
    can also see the average throughput of the application. The following screenshot
    shows a summary of the benchmark results:'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总结报告**：此报告提供了性能基准的总结，并显示了请求的平均、最小和最大响应时间。您还可以看到应用程序的平均吞吐量。以下截图显示了基准结果的总结：'
- en: '![Figure 11.10 – Generated summary benchmark report ](img/B17084_11_010.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.10 – 生成的总结基准报告](img/B17084_11_010.jpg)'
- en: Figure 11.10 – Generated summary benchmark report
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.10 – 生成的总结基准报告
- en: 'Notice the **# Samples** column in the preceding screenshot; its value is **250**.
    The value of the samples is derived using the following formula:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 注意前一个截图中的 **# 样本** 列；其值为 **250**。样本值的计算使用以下公式：
- en: '![](img/Formula_11.1.jpg)![](img/Formula_11.2.jpg)![](img/Formula_11.3.jpg)![](img/Formula_11.4.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_11.1.jpg)![](img/Formula_11.2.jpg)![](img/Formula_11.3.jpg)![](img/Formula_11.4.jpg)'
- en: '**Aggregate Report**: This denotes the aggregated benchmark report. Apart from
    showing the average, median, and maximum response time, it has columns such as
    **90% Line** and **95% Line**. A **90% Line** column denotes the average response
    time of 90% of the request. It assumes that 10% of the request contains outliers.
    Similarly, a **95% Line** assumes that 5% of requests are outliers. The following
    screenshot shows the aggregated performance benchmark:'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**综合报告**：这表示聚合基准测试报告。除了显示平均、中位数和最大响应时间外，它还有如**90%线**和**95%线**等列。**90%线**列表示90%请求的平均响应时间。它假设10%的请求包含异常值。同样，**95%线**假设5%的请求是异常值。以下截图显示了聚合的性能基准测试：'
- en: '![Figure 11.11 – Generated aggregated benchmark report ](img/B17084_11_011.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图11.11 – 生成的聚合基准测试报告](img/B17084_11_011.jpg)'
- en: Figure 11.11 – Generated aggregated benchmark report
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.11 – 生成的聚合基准测试报告
- en: '**Response Time Graph**: A performance benchmark can contain multiple charts
    or tables to benchmark the application performance. A Response Time Graph depicts
    the recorded response time at different timelines:'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**响应时间图**：性能基准测试可以包含多个图表或表格来测试应用性能。响应时间图描绘了在不同时间线记录的响应时间：'
- en: '![Figure 11.12 – Generated Response Time Graph ](img/B17084_11_012.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图11.12 – 生成的响应时间图](img/B17084_11_012.jpg)'
- en: Figure 11.12 – Generated Response Time Graph
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.12 – 生成的响应时间图
- en: In performance benchmarking activities, a lot of the time, we do comparative
    studies where these reports are used to create a combined report or graph visualization
    comparing the performance benchmarks of two different solutions.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在性能基准测试活动中，很多时候我们会进行对比研究，这些报告被用来创建一个综合报告或图形可视化，比较两个不同解决方案的性能基准。
- en: In this section, we learned why benchmarking is needed and what needs to be
    considered while benchmarking our solutions. Benchmarking provides us with a way
    to categorize or classify our application performance as good, bad, or just fine.
    In the next section, we will find out how can we improve our performance and optimize
    our data engineering solutions.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了为什么需要基准测试，以及在我们对解决方案进行基准测试时需要考虑什么。基准测试为我们提供了一种将我们的应用程序性能分类或分类为好、坏或一般的方法。在下一节中，我们将了解如何提高我们的性能并优化我们的数据工程解决方案。
- en: Optimizing performance
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化性能
- en: One of the main reasons that benchmarking, performance testing, and monitoring
    of applications and systems are done is because of a goal – to optimize the performance
    so that the system can work to its best potential. The difference between extraordinary
    software and ordinary software is determined by how well the system is tuned for
    better performance. In this section, we will learn about various techniques you
    can use to fine-tune your data engineering pipeline. Although performance tuning
    is a vast topic, when it comes to various data engineering solutions, we will
    try to cover the basics of optimizing Java-based data engineering solutions. In
    the following subsection, we will briefly look at various performance tuning techniques.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 做基准测试、性能测试和监控系统应用和系统的主要原因是出于一个目标——优化性能，以便系统能够发挥其最佳潜力。卓越软件与普通软件之间的区别在于系统调整得有多好以实现更好的性能。在本节中，我们将了解您可以使用各种技术来微调您的数据工程管道。尽管性能调整是一个广泛的话题，但当涉及到各种数据工程解决方案时，我们将尝试涵盖基于Java的数据工程解决方案优化的基础知识。在接下来的子节中，我们将简要介绍各种性能调整技术。
- en: Java Virtual Machine and garbage collection optimizations
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Java虚拟机（JVM）和垃圾回收优化
- en: '**Java Virtual Machine** (**JVM**) performance tuning is the process of adjusting
    the various JVM arguments or parameters to suit the need of our application so
    that it performs the best it can.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**Java虚拟机**（**JVM**）性能调整是调整各种JVM参数或参数以适应我们应用程序的需求，以便它能发挥最佳性能的过程。'
- en: 'JVM tuning involves two kinds of optimization, as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: JVM调整涉及两种优化，如下所示：
- en: Heap space optimization
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆空间优化
- en: '**Garbage collection** (**GC**) optimization'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**垃圾回收**（**GC**）优化'
- en: But before we talk about these optimizations, it is worth noting that JVM tuning
    needs to be the last resort to tune the performance of an application. We should
    start by tuning application code bases, databases, and resource availability.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 但在我们讨论这些优化之前，值得注意的是，JVM调整应该是调整应用程序性能的最后手段。我们应该从调整应用程序代码库、数据库和资源可用性开始。
- en: Overview of the JVM heap space
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: JVM堆空间概述
- en: Before we deep dive into JVM and GC tuning, let’s spend some time understanding
    the JVM heap space.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨JVM和GC调优之前，让我们花些时间了解JVM堆空间。
- en: 'The following diagram shows what a JVM heap space looks like:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了JVM堆空间的外观：
- en: '![Figure 11.13 – JVM heap space ](img/B17084_11_013.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图11.13 – JVM堆空间](img/B17084_11_013.jpg)'
- en: Figure 11.13 – JVM heap space
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.13 – JVM堆空间
- en: 'As we can see, the JVM heap space is divided into four compartments, as follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，JVM堆空间被划分为四个部分，如下所示：
- en: Meta or Perm Space
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 元空间或Perm空间
- en: Eden Space
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Eden Space
- en: Survivor Space
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Survivor空间
- en: Tenured Space
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Tenured空间
- en: Meta Space (known as Perm Space for older JDK versions) stores the metadata
    of the heap.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 元空间（在较老的JDK版本中称为Perm空间）存储堆的元数据。
- en: 'Java objects get promoted from Eden Space to Tenured Space, based on the tenure
    for which they are alive. The following steps show how the Java objects get promoted:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Java对象根据其存活时间从Eden Space提升到Tenured Space。以下步骤显示了Java对象如何被提升：
- en: The newly created objects from the Java application get stored in *Eden Space*.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Java应用程序新创建的对象被存储在*Eden Space*中。
- en: When *Eden Space* is full, a minor GC event occurs and the objects that are
    still referenced by the Java application are promoted to *Survivor Space 0*.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当*Eden Space*满时，会发生一个小的GC事件，并且仍然被Java应用程序引用的对象被提升到*Survivor Space 0*。
- en: Again, in the next cycle, when *Eden Space* is full, a second minor GC event
    gets triggered. At first, this moves all the objects that are still referenced
    by the application from *Survivor Space 0* to *Survivor Space 1*, and then it
    promotes referenced objects from *Eden Space* to *Survivor Space 0*.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次，在下一个周期中，当*Eden Space*满时，会触发第二个小的GC事件。首先，它会将所有仍然被应用程序引用的对象从*Survivor Space
    0*移动到*Survivor Space 1*，然后它将引用对象从*Eden Space*提升到*Survivor Space 0*。
- en: A major GC event occurs when referenced objects are promoted from *Survivor
    Space 1* to *Tenured Space*. Objects that get promoted to tenured space are called
    old-generation objects. *Eden Space*, *Survivor Space 0*, and *Survivor Space
    1* objects are young-generation objects.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当引用对象从*Survivor Space 1*提升到*Tenured Space*时，会发生一个主要的GC事件。被提升到tenured space的对象被称为老年代对象。*Eden
    Space*、*Survivor Space 0*和*Survivor Space 1*对象是年轻代对象。
- en: Earlier, we discussed how minor and major GC happens to free up the heap space.
    But is there a single way or multiple ways to do GC? If so, what should we choose
    and when? We’ll explore this in the next section.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们讨论了如何通过小GC和大GC来释放堆空间。但是，GC是否有单一的方式或多种方式？如果是的话，我们应该选择哪种，以及在何时选择？我们将在下一节中探讨这个问题。
- en: Important note
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 重要注意事项
- en: '**Garbage collection** is a process that automatically determines what memory
    in the JVM is no longer being used by a Java application and recycles that memory
    for other usages.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**垃圾收集**是一个自动确定JVM中哪些内存不再被Java应用程序使用，并将该内存回收以供其他用途的过程。'
- en: Types of garbage collector
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 垃圾收集器类型
- en: 'The following are the different types of GCs:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些不同的GC类型：
- en: '**Serial garbage collector**: A single GC is suitable for single-threaded applications.
    It freezes all application threads while doing garbage collection and does so
    using a single thread.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**串行垃圾收集器**：单个GC适用于单线程应用程序。在执行垃圾收集时，它会冻结所有应用程序线程，并使用单个线程进行操作。'
- en: '**Parallel garbage collector**: A parallel GC also freezes all threads from
    the application but uses multiple threads to do garbage collection. Hence, the
    pause interval of the application threads reduces considerably. It is designed
    to work for multi-processor environments or multi-threaded environments with medium
    and large data sizes.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并行垃圾收集器**：并行GC也会冻结应用程序的所有线程，但使用多个线程进行垃圾收集。因此，应用程序线程的暂停间隔大大减少。它旨在适用于多处理器环境或具有中等和大数据量的多线程环境。'
- en: '**Concurrent Mark Sweep (CMS) garbage collector**: As evident from the name,
    the garbage collection job is performed concurrent to the application. So, it
    doesn’t require application threads to pause. Instead, it shares threads with
    the application thread for concurrent sweep execution. However, it needs to pause
    application threads shortly for an **initial mark pause**, where it marks the
    live objects initially. Then, a second pause, called a **remark pause**, suspends
    application threads and is used to find any Java objects that need to be collected.
    These Java objects are created during the concurrent tracing phase. The following
    diagram explains the difference between serial, parallel, and CMS GCs:'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并发标记清除（CMS）垃圾收集器**：从其名称中可以看出，垃圾收集工作与应用程序并发执行。因此，它不需要应用程序线程暂停。相反，它与应用程序线程共享线程以进行并发清除执行。然而，它需要短暂暂停应用程序线程进行**初始标记暂停**，在那里它最初标记活动对象。然后，第二次暂停，称为**remark暂停**，暂停应用程序线程，并用于查找需要收集的任何Java对象。这些Java对象是在并发跟踪阶段创建的。以下图表解释了串行、并行和CMS
    GC之间的区别：'
- en: '![Figure 11.14 – Difference between the single, parallel, and CMS garbage collectors
    ](img/B17084_11_014.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图11.14 – 单一、并行和CMS垃圾收集器的区别](img/B17084_11_014.jpg)'
- en: Figure 11.14 – Difference between the single, parallel, and CMS garbage collectors
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.14 – 单一、并行和CMS垃圾收集器的区别
- en: As we can see, the serial collector uses a single thread for garbage collection,
    while pausing all application threads. The parallel collector pauses the application
    threads but since it uses multiple threads to do its job, the pause time is less.
    CMS, on the other hand, runs concurrently along with the application threads after
    the initial mark phase.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，串行收集器使用单个线程进行垃圾收集，同时暂停所有应用程序线程。并行收集器暂停应用程序线程，但由于它使用多个线程来完成工作，因此暂停时间更短。另一方面，CMS在初始标记阶段之后与应用程序线程并发运行。
- en: '**G1 garbage collector**: This is a relatively new GC introduced in Java 7
    and later. It depends on a new algorithm for concurrent garbage collection. It
    runs its longer job alongside the application threads and quicker jobs by pausing
    the threads. It works using the evacuation style of memory cleaning. For the evacuation
    style of memory cleaning, the G1 collector divides the heap into regions. Each
    region is a small, independent heap that can be dynamically assigned to Eden,
    Survivor, or Tenured Space. The following diagram shows how the G1 collector sees
    the data:'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**G1垃圾收集器**：这是一个相对较新的GC，在Java 7及以后的版本中引入。它依赖于一个用于并发垃圾收集的新算法。它与应用程序线程并行运行其较长时间的工作，并通过暂停线程来运行较快的任务。它使用内存清理的驱逐风格工作。对于内存清理的驱逐风格，G1收集器将堆划分为区域。每个区域都是一个小的、独立的堆，可以动态分配给Eden、Survivor或Tenured
    Space。以下图表显示了G1收集器如何看待数据：'
- en: '![Figure 11.15 – G1 garbage collector divides heap space into regions ](img/B17084_11_015.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![图11.15 – G1垃圾收集器将堆空间划分为区域](img/B17084_11_015.jpg)'
- en: Figure 11.15 – G1 garbage collector divides heap space into regions
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.15 – G1垃圾收集器将堆空间划分为区域
- en: The GC simply copies data from one region to another. This needs to be retained
    and marks the older region as blank.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: GC简单地从某一区域复制数据到另一区域。这需要保留并标记旧区域为空白。
- en: '**Z garbage collector**: This is an experimental GC for very scalable low latency
    implementations.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Z垃圾收集器**：这是一个用于非常可扩展的低延迟实现的实验性GC。'
- en: 'The following points should be kept in mind regarding GC:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在GC方面，以下几点应予以注意：
- en: Minor GC events should collect as many dead objects as possible to reduce the
    frequency of full GC.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小型GC事件应尽可能收集尽可能多的已死亡对象，以减少完全GC的频率。
- en: More efficient object cleanup is possible when more memory is available for
    a GC event. More efficient object cleanup ensures a lower frequency of full GC
    events.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当GC事件有更多可用内存时，可以实现更有效的对象清理。更有效的对象清理确保完全GC事件的频率更低。
- en: In the case of performance tuning using GC, you can only tune two parameters
    out of the three – that is, throughput, latency, and memory usage.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用GC进行性能调整的情况下，你只能调整三个参数中的两个 – 那就是吞吐量、延迟和内存使用。
- en: Next, let’s see how to tune the performance using a GC.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看如何使用GC调整性能。
- en: Tuning performance using a GC
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用GC调整性能
- en: 'Performance tuning using GC settings is also known as GC tuning. We must follow
    these steps to perform GC tuning:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GC设置进行性能调整也称为GC调整。我们必须遵循以下步骤来执行GC调整：
- en: '**Investigate the memory footprint**: One of the most commonly used methods
    to look for any performance issue caused due to GC can be found in the memory
    footprint and is present in the GC logs. GC logs can be enabled and generated
    from a Java application without affecting performance. So, it is a popular tool
    to investigate performance issues in production. You can enable GC logs using
    the following command:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**调查内存占用**：查找由于GC引起的任何性能问题的最常用方法之一是内存占用，它存在于GC日志中。GC日志可以在不影响性能的情况下从Java应用程序中启用和生成。因此，它是调查生产中性能问题的流行工具。您可以使用以下命令启用GC日志：'
- en: '[PRE0]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following screenshot shows what a typical GC log looks like:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的屏幕截图显示了典型的GC日志看起来像什么：
- en: '![Figure – 11.16 – Sample GC log ](img/B17084_11_016.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图 – 11.16 – 示例GC日志](img/B17084_11_016.jpg)'
- en: Figure – 11.16 – Sample GC log
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 – 11.16 – 示例GC日志
- en: 'In the preceding screenshot, each line shows various GC information. Let’s
    focus on the third line of the log, which shows a full GC event:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个屏幕截图中，每一行都显示了各种GC信息。让我们关注日志的第三行，它显示了一个完全GC事件：
- en: '![Figure – 11.17 – Anatomy of a GC log statement ](img/B17084_11_017.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图 – 11.17 – GC日志语句的解剖](img/B17084_11_017.jpg)'
- en: Figure – 11.17 – Anatomy of a GC log statement
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 – 11.17 – GC日志语句的解剖
- en: 'As shown in the preceding diagram, let’s pick apart the GC log statement and
    understand the various parts of it:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，让我们分析GC日志语句并了解其各个部分：
- en: '`2022-07-01T16:46:0.434`: The timestamp when the GC event occurred.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`2022-07-01T16:46:0.434`: GC事件发生的日期和时间戳。'
- en: '`Full GC`: This field describes the type of GC. It can either be a full GC
    or GC.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Full GC`: 此字段描述了GC的类型。它可以是完全GC或GC。'
- en: '`[PSYoungGen: 10752K->0K(141824K)]`: After the GC event occurred, all the space
    used in the young generation was recycled. Also, the value inside brackets (`141824K`)
    denotes the total allocated space in the young generation.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`[PSYoungGen: 10752K->0K(141824K)]`: GC事件发生后，年轻代中使用的所有空间都被回收了。括号内的值(`141824K`)表示年轻代分配的总空间。'
- en: '`[ParOldGen: 213644K->215361K(459264K)]`: After the GC ran, the old generation’s
    used space increased from `213644K` to `215361K`. Total allocated memory for the
    old generation is `459264K`.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`[ParOldGen: 213644K->215361K(459264K)]`: GC运行后，旧代的使用空间从`213644K`增加到`215361K`。旧代分配的总内存为`459264K`。'
- en: '`224396K->215361K(601088K)`: After the GC ran, the total memory of used space
    was reduced from `224396K` to `215361K`. The total allocated memory is `601088K`.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`224396K->215361K(601088K)`: GC运行后，使用的总内存从`224396K`减少到`215361K`。总分配内存为`601088K`。'
- en: '`[Metaspace: 2649K->2649K(1056768K)]`: No memory was reclaimed from the Meta
    space as a result of the GC. The total allocated Meta space is `1056768K`.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`[Metaspace: 2649K->2649K(1056768K)]`: 由于GC，元空间没有回收任何内存。总共分配的元空间为`1056768K`。'
- en: '`3.4609247 secs`: Total time taken by GC.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`3.4609247 secs`: GC所花费的总时间。'
- en: '`[Times: user=3.40 sys=0.02, real=3.46 secs]`: This part of the log statement
    tells us about the time taken to do the garbage collection. The `user` time tells
    the processor time that the GC took to execute. The `sys` time denotes the time
    taken by I/O and other system activities. Finally, the `real` time denotes the
    total time taken to finish the GC event.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`[Times: user=3.40 sys=0.02, real=3.46 secs]`: 这部分日志语句告诉我们垃圾收集所花费的时间。`user`时间告诉处理器GC执行所花费的时间。`sys`时间表示I/O和其他系统活动所花费的时间。最后，`real`时间表示完成GC事件所花费的总时间。'
- en: Based on these footprints, we can determine whether we need to increase the
    heap space or increase the meta space and specifies any memory leaks that are
    happening in the application.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些痕迹，我们可以确定是否需要增加堆空间或元空间，并指定应用程序中发生的任何内存泄漏。
- en: '**Memory tuning**: A memory leak may occur if the following observations are
    listed:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**内存调整**：如果列出以下观察结果，则可能会发生内存泄漏：'
- en: The JVM heap size is being filled frequently
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: JVM堆大小频繁被填满
- en: The young generation space is being completely recycled, but the old generation
    used space is increasing with every GC run
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年轻代空间正在被完全回收，但每次GC运行后，旧代的使用空间都在增加。
- en: 'Before deciding whether it is a genuine memory leak problem or not, you should
    increase the heap space using the following commands:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定是否是真正的内存泄漏问题之前，您应该使用以下命令增加堆空间：
- en: '[PRE1]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If this doesn’t help, then the root cause is most likely a memory leak.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这不起作用，那么最可能的原因是内存泄漏。
- en: 'If we see that the young generation space is getting filled frequently or that
    the Meta space is being heavily used, we can plan to change the total allocated
    space in all these regions using the following commands:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '`-XX:MaxMetaspaceSize`: This sets the maximum amount of memory that can be
    allocated for the class metadata. The default value is `infinite` (or the same
    as the heap space).'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-XX:MetaspaceSize`: Sets the threshold size of the allocated class metadata
    above which the GC will be triggered.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-XX:MinMetaspaceFreeRatio`: The minimum percentage of the Meta space memory
    region that needs to be available after garbage collection. If the amount of memory
    left is below the threshold, the Meta space region will be resized.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-XX:MaxMetaspaceFreeRatio`: The maximum percentage of the Meta space memory
    region that needs to be available after garbage collection. If the amount of memory
    left is above the threshold, the Meta space region will be resized.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-XX:NewSize`: This sets the initial size of the young generation space.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-XXMaxNewSize`: This specifies the maximum size of young generation space.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-Xmn`: This specifies the size of the entire young generation space, meaning
    Eden and the two survivor spaces.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-XX:+G1GC` command.'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set `-Xmx` and `-Xms` to the same value to reduce application pause intervals.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the `-XX:+AlwaysPreTouch` flag to `true` so that the memory pages are loaded
    when the application is started.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you are using G1, check whether the minor GC or full GC is taking more time.
    If the minor GC is taking more time, we can reduce the values of `-XX:G1NewSizePercent`
    and `-XX:G1MaxNewSizePercent` . If the major GC is taking more time, we can increase
    the value of the `-XX:G1MixedGCCountTarget` flag, which will help spread the tenured
    GC into multiple runs and reduce the frequency of full GC events.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`--XX:MaxGCPauseMillis` property to clean more garbage in a single GC run.
    However, this may affect your latency.*   Load memory pages into memory at the
    start of the application by setting the `-XX:+AlwaysPreTouch` and `-XX:+UseLargePages`
    flags.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '**Latency** is the total time elapsed to process and send an event, message,
    or data to its destination. On the other hand, **throughput** is the number of
    records, events, or messages processed within a specified period.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Although JVM and GC tuning is a vast topic, we briefly tried to cover a few
    important JVM and GC tuning techniques to improve throughput and latency. In the
    next section, we will discuss how can we optimize big data loads.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Big data performance tuning
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Performance tuning for big data is a huge topic. For brevity, we will limit
    ourselves to a few performance tuning tips and tricks that are usually applied
    to the most popular big data processing technologies, namely Spark and Hive.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Hive performance tuning
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Hive performance tuning** is the collective process and technique to improve
    and accelerate the performance of your Hive environment. The following are some
    commonly faced Hive performance issues:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**Hive 性能调优**是提高和加速您 Hive 环境性能的过程和技术的集合。以下是一些常见的 Hive 性能问题：'
- en: '**Slow-running queries**: Often, you will notice that your Hive query is taking
    a huge amount of time to finish. There can be several reasons for slow-running
    queries. The following are a few commonly encountered scenarios of slow-running
    queries and their solution:'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**运行缓慢的查询**：通常，您会注意到您的 Hive 查询需要花费大量时间才能完成。运行缓慢的查询可能有几个原因。以下是一些常见的运行缓慢查询场景及其解决方案：'
- en: Poorly written queries result in a cross-join or full outer join. An unintended
    cross-join can happen when the join columns in either of the tables have duplicates
    or a self-join is happening in the query. Fine-tune your Hive queries to avoid
    cross-joins as much as possible.
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写不良的查询会导致交叉连接或全外连接。当任一表的连接列有重复或查询中发生自连接时，可能会发生意外的交叉连接。尽可能优化您的 Hive 查询以避免交叉连接。
- en: The speed of a slow-running query can be improved by applying a map-side join
    if one of the join tables contains a small amount of data. In a map-side join,
    the smaller dataset is broadcast to all mapper nodes so that the join happens
    locally without much shuffling. The downside of a map-side join is that the data
    in the smaller table needs to be small enough to fit into memory.
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果其中一个连接表包含少量数据，可以通过应用 map-side join 来提高运行缓慢查询的速度。在 map-side join 中，较小的数据集被广播到所有
    mapper 节点，以便在本地进行连接而无需大量洗牌。map-side join 的缺点是，较小表中的数据需要足够小，以便适合内存。
- en: For a scenario suitable for a map-side join, we can further improve the speed
    of the tables needed for the join to be bucketed. **Bucketing** is the technique
    by which data in a Hive table is broken into a fixed number of ranges or clusters,
    based on the join column(s). A bucketed table can be used for a **bucket map-join**
    or **sort-merge-bucket (SMB) map-join**, both of which perform better than normal
    map-joins. However, bucketed tables can be joined with each other, only if the
    total buckets of one table are multiples of the number of buckets in the other
    table. For example, Table1 has 2 buckets and Table2 has 4 buckets. Since 4 is
    a multiple of 2, these tables can be joined.
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于适合 map-side join 的场景，我们可以进一步通过将需要连接的表进行分桶来提高速度。**分桶**是一种技术，根据连接列将 Hive 表中的数据分成固定数量的范围或簇。分桶表可用于
    **桶映射连接**或**排序合并分桶（SMB）映射连接**，这两种方式都比普通映射连接表现更好。然而，只有当一张表的总桶数是另一张表桶数的倍数时，分桶表才能相互连接。例如，Table1
    有 2 个桶，Table2 有 4 个桶。由于 4 是 2 的倍数，这些表可以连接。
- en: Sometimes, data grows rapidly, which makes Hive jobs slow. In such cases, map-side
    operations take a huge amount of time. To overcome such issues, use partitioning.
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有时，数据会迅速增长，这会导致 Hive 作业变慢。在这种情况下，map-side 操作会花费大量时间。为了克服这些问题，请使用分区。
- en: If you notice that data read is slow or data shuffle is quite slow, check for
    the *data format* and *compression* that were used. For example, columnar structures
    such as Parquet and ORC have 5% to 10% higher performance than JSON. The columnar
    format also is known to have around a 90% higher compression ratio than JSON.
    More compressed data can reduce a good amount of network latency and hence improve
    overall performance.
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您注意到数据读取速度慢或数据洗牌速度相当慢，请检查所使用的 *数据格式* 和 *压缩*。例如，Parquet 和 ORC 等列式结构比 JSON 性能高
    5% 到 10%。列式格式也已知比 JSON 具有大约 90% 的更高压缩率。更多压缩的数据可以减少大量的网络延迟，从而提高整体性能。
- en: 'The Hive execution speed can be considerably improved by changing the *execution
    engine* from map-reduce to Tez or Spark. You can do this by setting the following
    parameter in the Hive configuration file:'
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将 *执行引擎* 从 map-reduce 更改为 Tez 或 Spark，可以显著提高 Hive 的执行速度。您可以通过在 Hive 配置文件中设置以下参数来实现这一点：
- en: '[PRE2]'
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`TimeoutException`, chances are that you have encountered a *small file issue*.
    This occurs when millions of small files (whose size is less than the block size
    of 128 MB) are written into the Hive table’s external path. Each HDFS file has
    metadata stored in Hadoop’s name-node. Too many small files in a Hive table cause
    too much metadata to be read by the job. Hence, the job fails either due to memory
    overrun or timeout exceptions. In such cases, either run a compaction job (refer
    to the *Core batch processing patterns* section of [*Chapter 7*](B17084_07.xhtml#_idTextAnchor110),
    *Core Architectural Design Patterns*) or store the data in sequential files.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TimeoutException`，很可能是你遇到了*小文件问题*。这发生在数百万个小文件（其大小小于128MB的块大小）被写入Hive表的外部路径时。每个HDFS文件都有存储在Hadoop的NameNode中的元数据。Hive表中过多的文件会导致作业读取过多的元数据。因此，作业可能由于内存溢出或超时异常而失败。在这种情况下，可以运行压缩作业（参考[*第7章*](B17084_07.xhtml#_idTextAnchor110)的*核心批量处理模式*部分，*核心架构设计模式*）或将数据存储在顺序文件中。'
- en: With that, we’ve discussed various Hive optimization techniques that are used
    to fine-tune Hive query speeds and performance. Now, let’s look at Spark performance
    tuning.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们已经讨论了各种Hive优化技术，这些技术用于微调Hive查询速度和性能。现在，让我们看看Spark性能调优。
- en: Spark performance tuning
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Spark性能调优
- en: Spark is the most popular big data processing engine. When Spark applications
    are tuned properly, it lowers the resource cost while maintaining the SLA for
    critical processes. This is important for both cloud and on-premise environments.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: Spark是最受欢迎的大数据处理引擎。当Spark应用程序得到适当调整时，它可以在保持关键流程SLA的同时降低资源成本。这对云和本地环境都很重要。
- en: A Spark tuning job starts by debugging and observing the problems that occur
    during a Spark job’s execution. You can observe various metrics using the Spark
    UI or any profiling application such as Datadog.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 一个Spark调优作业从调试和观察Spark作业执行期间发生的问题开始。您可以使用Spark UI或任何分析应用程序（如Datadog）来观察各种指标。
- en: 'The following are a few best practices for Spark optimization that are commonly
    applied while handling Spark applications:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些在处理Spark应用程序时常用的Spark优化最佳实践：
- en: '**Serialization**:'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**序列化**：'
- en: '*Problem*: Slow data read from a Hive table or HDFS'
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*问题*：从Hive表或HDFS读取数据缓慢'
- en: '*Cause*: The default Java serializer slows down the read speed of the data
    from Hive or HDFS'
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*原因*：默认的Java序列化器降低了从Hive或HDFS读取数据的读取速度'
- en: '*Solution*: To overcome this problem, we should set the default serializer
    to Kyro Serializer, which performs a much faster Serde operation'
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*解决方案*：为了克服这个问题，我们应该将默认序列化器设置为Kryo序列化器，它执行更快的Serde操作'
- en: '**Partition sizes**:'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分区大小**：'
- en: '*Problem*: The Spark job runs slowly since one or two executors among many
    executors take much more time to finish the task. Sometimes, the job hangs due
    to a slow-performing executor.'
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*问题*：由于一个或两个执行器在众多执行器中花费了更多的时间来完成任务，Spark作业运行缓慢。有时，作业会因为性能较慢的执行器而挂起。'
- en: '*Cause*: A possible cause can be data skew. In such a scenario, you will find
    that the slow-performing executor is processing the bulk of the data. Hence, the
    data is not well-partitioned.'
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*原因*：可能的原因是数据倾斜。在这种情况下，你会发现性能较慢的执行器正在处理大部分数据。因此，数据没有很好地分区。'
- en: '*Solution*: Repartition the data loaded into Spark DataFrames before processing
    the data further.'
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*解决方案*：在进一步处理数据之前，重新分区加载到Spark DataFrame中的数据。'
- en: 'Let’s look at another common problem that’s encountered related to partitioning:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看另一个与分区相关的常见问题：
- en: '*Problem*: The Spark jobs are slowing down as all executors are heavily loaded
    and all executors are taking a long time to process the job.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*问题*：由于所有执行器都负载过重，所有执行器处理作业的时间都很长，Spark作业正在变慢。'
- en: '*Cause*: The likely cause is that the data has outgrown and you are running
    the Spark job with far fewer partitions.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*原因*：可能的原因是数据量过大，而你运行的Spark作业分区数量却很少。'
- en: '*Solution*: Repartition the data loaded in the Spark DataFrame and increase
    the number of partitions. Adjust the number of partitions until optimum performance
    is achieved.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*解决方案*：重新分区Spark DataFrame中加载的数据，并增加分区数量。调整分区数量，直到达到最佳性能。'
- en: 'Another common problem that’s encountered in Spark is as follows:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark中遇到的另一个常见问题是以下内容：
- en: '*Problem*: A Spark job needs to write a single file as an output but the job
    gets stuck in the last step.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*问题*：Spark作业需要写入单个文件作为输出，但作业在最后一步卡住了。'
- en: '*Cause*: Since you have used `repartition()` to create a single output file,
    a full data shuffle takes place, choking the performance.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*原因*：由于您使用了`repartition()`来创建单个输出文件，因此发生了完整的数据洗牌，这阻碍了性能。'
- en: '*Solution*: Use `coalesce()` instead of `repartition()`. `coalesce()` avoids
    doing a full shuffle as it collects data from all other partitions and copies
    data to a selected partition that contains the maximum amount of data.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*解决方案*：使用`coalesce()`代替`repartition()`。`coalesce()`避免进行完整的洗牌操作，因为它从所有其他分区收集数据并将数据复制到包含最多数据的选定分区。'
- en: '`OutofMemoryException`, GC overhead memory exceeded, or JVM heap space overrun.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OutofMemoryException`、GC开销内存超过或JVM堆空间溢出。'
- en: '*Cause*: Inefficient configuration of the driver and executor memory and CPU
    cores.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*原因*：驱动器和执行器内存以及CPU核心的配置效率低下。'
- en: '*Solution*: There is no one solution. Here, we will discuss various best practices
    that can be used to avoid inefficient driver and executor resource configuration.
    Before we begin, we will assume that you have basic familiarity with Apache Spark
    and know its basic concepts. If you are new to Apache Spark, you can read this
    concise blog about the basics of the Spark architecture: [https://www.edureka.co/blog/spark-architecture/](https://www.edureka.co/blog/spark-architecture/).'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*解决方案*：没有一种解决方案。在这里，我们将讨论可以用来避免低效的驱动器和执行器资源配置的各种最佳实践。在我们开始之前，我们将假设您对Apache
    Spark有基本的了解，并知道其基本概念。如果您是Apache Spark的新手，您可以阅读这篇关于Spark架构基础的简要博客：[https://www.edureka.co/blog/spark-architecture/](https://www.edureka.co/blog/spark-architecture/)。'
- en: 'For both executor and driver sizing, there is a total of five properties that
    we need to set for Spark job optimization. They are as follows:'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于执行器和驱动器的大小调整，我们需要为Spark作业优化设置总共五个属性。它们如下：
- en: '`5` by using the following property:'
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用以下属性计算`5`：
- en: '[PRE3]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](img/Formula_11.5.jpg)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_11.5.jpg)'
- en: Here, Nc denotes the number of cores per node, Ec denotes the executor cores
    per executor, and Tn denotes the total number of nodes.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，Nc表示每个节点的核心数，Ec表示每个执行器的执行器核心数，Tn表示节点的总数。
- en: In this use case, *Nc* is 16, *Ec* is 5, and *Tn* is 3\. Hence, we reach the
    same result of 8 (`FLOOR`(16*3/5) -1).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个用例中，*Nc*是16，*Ec*是5，*Tn*是3。因此，我们得到相同的结果8（`FLOOR`(16*3/5) -1）。
- en: With that, we have discussed how to optimally set the driver and executor properties.
    However, for Spark 3.0 and above running on a YARN cluster, it makes more sense
    to enable dynamic allocation. Although you can set a minimum and a maximum number
    of executor cores, you must let the environment itself determine the number of
    executors needed. Optionally, you may want to set a cap on the maximum number
    of executors (by using the `spark.dynamicAllocation.maxExecutors` property) after
    discussing this with your Hadoop admin.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，我们已经讨论了如何最优地设置驱动器和执行器属性。然而，对于在YARN集群上运行的Spark 3.0及以上版本，启用动态分配更有意义。虽然您可以设置执行器核心的最小值和最大值，但您必须让环境本身确定所需的执行器数量。在讨论过这个问题后，您可能还想设置最大执行器数量的上限（通过使用`spark.dynamicAllocation.maxExecutors`属性）。
- en: '**Executor memory or executor-memory**: To calculate the optimal executor memory,
    we need to understand the total amount of memory that’s used by an executor. The
    total memory that’s used by an executor is the total of the executor memory and
    the memory overhead:'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行器内存或executor-memory**：为了计算最优执行器内存，我们需要了解执行器使用的总内存量。执行器使用的总内存是执行器内存和内存开销的总和：'
- en: '![Figure 11.18 – Total memory used by executor = memory overhead + executor-memory
    ](img/B17084_11_018.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![图11.18 – 执行器使用的总内存 = 内存开销 + 执行器内存](img/B17084_11_018.png)'
- en: Figure 11.18 – Total memory used by executor = memory overhead + executor-memory
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.18 – 执行器使用的总内存 = 内存开销 + 执行器内存
- en: 'The memory overhead of the executor defaults to a greater amount between 10%
    of the executor’s memory size or 384 MB. Now, to find the correct executor memory
    size, we need to look at the YARN resource manager’s **Nodes** tab. Each record
    in the **Nodes** tab will have a **Total Memory Column**, as shown in the following
    screenshot:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 执行器的内存开销默认为执行器内存大小的10%或384 MB之间的较大值。现在，为了找到正确的执行器内存大小，我们需要查看YARN资源管理器的**节点**标签页。**节点**标签页中的每一条记录都将有一个**总内存列**，如下面的截图所示：
- en: '![Figure 11.19 – Total memory available for the executors in a node ](img/B17084_11_019.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![图11.19 – 节点中执行器的可用总内存](img/B17084_11_019.jpg)'
- en: Figure 11.19 – Total memory available for the executors in a node
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.19 – 节点中执行器的可用总内存
- en: 'In the preceding screenshot, a total of **112 GB** of memory is available from
    the node for executors and drivers, after memory has been set aside for the cluster
    manager. Now, we must calculate the memory overhead for this executor by using
    the following formula:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的屏幕截图上，节点为执行器和驱动器提供了总共**112 GB**的内存，在为集群管理器预留内存之后。现在，我们必须使用以下公式来计算这个执行器的内存开销：
- en: '![](img/Formula_11.6.jpg)![](img/Formula_11.7.jpg)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_11.6.jpg)![](img/Formula_11.7.jpg)'
- en: 'Let’s try to use the example described earlier for calculating the executor
    memory. We will divide this available node memory by the total number of executors
    per node. Then, we will divide this by 1.1\. The formula to calculate executor
    memory is as follows:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用之前描述的例子来计算执行器内存。我们将把可用的节点内存除以每个节点的总执行器数量。然后，我们将这个结果除以1.1。计算执行器内存的公式如下：
- en: '![](img/Formula_11.8.jpg)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_11.8.jpg)'
- en: Here, *Nm* is the total node memory and *Ne* is the number of executors per
    node.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*Nm* 是总节点内存，而 *Ne* 是每个节点的执行器数量。
- en: Using the preceding formula in our scenario, the executor memory should be 36.94
    GB (112/3 – .384). So, we can set the executor memory to 36 GB.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的场景中使用前面的公式，执行器内存应该是36.94 GB（112/3 – .384）。因此，我们可以将执行器内存设置为36 GB。
- en: '`1`.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1`.'
- en: '**Driver memory or driver-memory**: Driver memory is either less than or equal
    to the executor memory. Based on a specific scenario, this value can be set to
    less than or equal to the executor’s memory. One of the optimizations that is
    advisable in the case of driver memory issues is to make the driver memory the
    same as the executor memory. This can speed up performance.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**驱动器内存或driver-memory**：驱动器内存要么小于或等于执行器内存，要么等于执行器内存。根据特定场景，这个值可以设置为小于或等于执行器的内存。在驱动器内存问题的情况下，建议的一种优化是将驱动器内存设置为与执行器内存相同。这可以加快性能。'
- en: '**Directed acyclic graph (DAG) optimization**: Let’s look at some issues that
    you can resolve using DAG optimization:'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有向无环图（DAG）优化**：让我们看看一些你可以通过DAG优化解决的问题：'
- en: '*Problem*: In the DAG, we can see that more than one stage is identical in
    terms of all its tasks or operations.'
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*问题*：在DAG中，我们可以看到多个阶段在所有任务或操作方面都是相同的。'
- en: '*Cause*: The DataFrame, denoted as d1, is being used to derive more than one
    DataFrame (for example – d2, d3, and d4). Since Spark is lazily computed, when
    creating each DataFrame (d2, d3, and d4), d1 is recalculated every time.'
  id: totrans-254
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*原因*：DataFrame，表示为d1，正在被用来派生出多个DataFrame（例如 – d2、d3和d4）。由于Spark是惰性计算的，当创建每个DataFrame（d2、d3和d4）时，d1会每次都重新计算。'
- en: '*Solution*: In such a scenario, we must persist the dependent DataFrame (d1)
    using the `Dataset<T> persist(StorageLevel newLevel)` method.'
  id: totrans-255
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*解决方案*：在这种情况下，我们必须使用`Dataset<T> persist(StorageLevel newLevel)`方法持久化依赖的DataFrame（d1）。'
- en: Now that we’ve discussed performance tuning for big data, let’s learn how to
    tune real-time applications.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经讨论了大数据的性能调优，那么让我们学习如何调整实时应用。
- en: Optimizing streaming applications
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化流式应用
- en: Now, let’s learn how to optimize streaming applications. Here, our discussion
    will mainly focus on Kafka since we discussed this earlier in this book. When
    it comes to streaming applications, we can tune their latency and throughput.
    In this section, we will learn how to observe a performance bottleneck in Kafka.
    Then, we will learn how to optimize producers and consumers. Finally, we will
    discuss a few tips and tricks that help tune overall Kafka cluster performance.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们学习如何优化流式应用。在这里，我们的讨论将主要关注Kafka，因为我们在这本书的早期已经讨论过它。当涉及到流式应用时，我们可以调整它们的延迟和吞吐量。在本节中，我们将学习如何观察Kafka中的性能瓶颈。然后，我们将学习如何优化生产者和消费者。最后，我们将讨论一些有助于调整整体Kafka集群性能的小技巧和技巧。
- en: Observing performance bottlenecks in streaming applications
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 观察流式应用中的性能瓶颈
- en: The first thing about any tuning is monitoring and finding out what the problem
    is and where it’s occurring. For real-time stream processing applications, this
    is of utmost importance. There are quite a few Kafka observability tools available
    such as Lenses and **Confluent Control Center** (**C3**). Here, we will see how
    C3 helps us observe anomalies.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 任何调优的第一件事就是监控和找出问题所在及其发生的位置。对于实时流处理应用来说，这一点至关重要。市面上有许多Kafka可观察性工具，例如Lenses和**Confluent
    Control Center**（**C3**）。在这里，我们将看看C3如何帮助我们观察异常。
- en: 'When you navigate to any topic in C3, you will see three tabs – **Producer**,
    **Consumer**, and **Consumer lag**. The **Consumer lag** tab can tell if a consumer
    is slow or not. The following screenshot shows that the consumer (group) is lagging
    by **1,654** records while reading data from the topic:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 当您导航到C3中的任何主题时，您将看到三个标签页 – **生产者**、**消费者**和**消费者延迟**。**消费者延迟**标签页可以告诉您消费者是否缓慢。以下截图显示，在从主题读取数据时，消费者（组）落后**1,654**条记录：
- en: '![Figure 11.20 – Consumer lag ](img/B17084_11_020.jpg)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![图11.20 – 消费者延迟](img/B17084_11_020.jpg)'
- en: Figure 11.20 – Consumer lag
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.20 – 消费者延迟
- en: 'The preceding screenshot also shows the number of active consumers in this
    consumer group. This can indicate whether the consumer is set to utilize the full
    performance potential of the topic or not. To learn more, click on the **Consumer
    group ID** property (in the preceding screenshot, it is **analyticsTeam**). You
    will see the following screen:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的截图还显示了该消费者组的活跃消费者数量。这可以表明消费者是否被设置为利用主题的全部性能潜力。要了解更多信息，请点击**消费者组ID**属性（在前面截图中为**analyticsTeam**）。您将看到以下屏幕：
- en: '![Figure 11.21 – Partition-wise consumer lag  ](img/B17084_11_021.jpg)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![图11.21 – 分区消费者延迟](img/B17084_11_021.jpg)'
- en: Figure 11.21 – Partition-wise consumer lag
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.21 – 分区消费者延迟
- en: The preceding screenshot shows the lag of the consumer group partition-wise.
    From *Figure 11.19* and *Figure 11.20*, it is evident that only one consumer is
    running but that the topic has three partitions. As we can see, there is scope
    for tuning the consumer application by increasing the number of consumers in the
    consumer group. Similarly, we can look at the producer speed versus the consumer
    speed of a topic and find any slowness in the producer.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的截图显示了消费者组分区级别的延迟。从*图11.19*和*图11.20*可以看出，只有一个消费者正在运行，但该主题有三个分区。正如我们所看到的，通过增加消费者组中的消费者数量，我们可以调整消费者应用程序。同样，我们可以查看主题的生产者速度与消费者速度，并找出生产者中的任何缓慢之处。
- en: Producer tuning
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生产者调优
- en: 'The following are a few common tuning techniques for Kafka producers:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些针对Kafka生产者的常见调优技术：
- en: When the producer sends a message to the Kafka broker, it receives an acknowledgment.
    The `acks=all` property, along with the value of `min.insync.replicas`, determine
    the throughput of a producer. If `acks=all` is set and the acknowledgment takes
    more time to come (because it must write all its replicas before sending the acknowledgment),
    then the producer cannot produce any further messages. This reduces the throughput
    considerably. We must make a choice here between durability and throughput.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当生产者向Kafka代理发送消息时，它会收到一个确认。`acks=all`属性以及`min.insync.replicas`的值决定了生产者的吞吐量。如果`acks=all`被设置，并且确认需要更长的时间来到来（因为它必须在发送确认之前写入所有副本），那么生产者就不能再产生任何消息。这会大大降低吞吐量。在这里，我们必须在持久性和吞吐量之间做出选择。
- en: 'Idempotent producers guarantee exactly-once delivery of messages. However,
    this comes with a cost: it reduces the throughput of a producer. So, a system
    must choose between deduplication and throughput. While using idempotent producers,
    you can improve throughput slightly by increasing the value of `max.in.flight.requests.per.connection`.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有幂等性的生产者确保消息的精确一次投递。然而，这也有代价：它会降低生产者的吞吐量。因此，系统必须在去重和吞吐量之间做出选择。在使用幂等性生产者时，可以通过增加`max.in.flight.requests.per.connection`的值来略微提高吞吐量。
- en: One way to improve throughput is to increase the property value of `batch.size`.
    Although a producer is used to send the message, it does so asynchronously (for
    most applications). Producers usually have a buffer where producing records are
    batched before they’re sent to the Kafka broker. Sending the records to the broker
    in batches improves the throughput of the producer. However, latency increases
    as the value of `batch.size` increases. Set `batch.size` to a balanced value so
    that we get optimum throughput without affecting the latency considerably.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高吞吐量的方法之一是增加`batch.size`属性的值。尽管生产者用于发送消息，但它是以异步方式进行的（对于大多数应用）。生产者通常有一个缓冲区，在将记录发送到Kafka代理之前，生产记录会被批量处理。将记录批量发送到代理可以提高生产者的吞吐量。然而，随着`batch.size`值的增加，延迟也会增加。将`batch.size`设置为平衡的值，以便在不严重影响延迟的情况下获得最佳吞吐量。
- en: '`Linger.ms` is another property that is affected when the messages in the Kafka
    producer buffer are sent to the Kafka broker. The higher the value of `linger.ms`,
    the higher the throughput and latency will be. Again, it must be set in a balanced
    fashion to have optimum throughput as well as latency. For extremely huge loads
    of data, a higher value of `linger.ms` can give a considerable boost to performance.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Linger.ms`是另一个属性，当Kafka生产者缓冲区中的消息发送到Kafka代理时受到影响。`linger.ms`的值越高，吞吐量和延迟就越高。同样，它必须以平衡的方式设置，以获得最佳吞吐量和延迟。对于极大量的数据，较高的`linger.ms`值可以显著提高性能。'
- en: With that, we have briefly discussed the techniques for producer optimization.
    Now, let’s find out how we can optimize the performance of Kafka consumers.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们已经简要讨论了生产者优化的技术。现在，让我们找出如何优化Kafka消费者的性能。
- en: Consumer tuning
  id: totrans-275
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 消费者调优
- en: 'The following are a few tips and tricks you can utilize to optimize the consumer
    to make full use of the potential improvements the consumer can have:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些你可以利用的技巧和窍门来优化消费者，以充分利用消费者可能带来的潜在改进：
- en: For a consumer to consume in the most optimized fashion, the total number of
    consumers should be equal to the number of partitions. In a multithreaded Kafka
    consumer, the total number of threads across all the consumers in the consumer
    group should be equal to the number of topic partitions.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了使消费者以最优化方式消费，消费者的总数应等于分区的数量。在多线程Kafka消费者中，消费者组中所有消费者线程的总数应等于主题分区的数量。
- en: Another typical scenario that makes the consumer slow is too much rebalancing
    of the consumer. This can happen if the time that’s taken to poll and process
    `max.poll.records` is more than the value of `max.poll.interval.ms`. In such cases,
    you may want to either increase the value of `max.poll.interval.ms` or decrease
    the value of `max.poll.records`.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个导致消费者变慢的典型场景是消费者过多的重新平衡。如果轮询和处理`max.poll.records`所需的时间超过`max.poll.interval.ms`的值，就会发生这种情况。在这种情况下，你可能想增加`max.poll.interval.ms`的值或减少`max.poll.records`的值。
- en: Rebalancing can happen in scenarios where a consumer can’t send the heartbeat
    or the heartbeat packages reach slowly due to network latency. If we are okay
    with static consumers (the consumer statically maps to a partition), we can configure
    a unique `group.instance.id` value for each consumer instance in the consumer
    group. This will increase latency for the consumer that goes down but will ensure
    great latency and throughput for other partitions as it will avoid unnecessary
    consumer rebalancing.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在消费者无法发送心跳或由于网络延迟导致心跳包发送缓慢的场景中，可能会发生重新平衡。如果我们对静态消费者（消费者静态映射到分区）没有问题，我们可以为消费者组中的每个消费者实例配置一个唯一的`group.instance.id`值。这将增加下线消费者的延迟，但将确保其他分区的延迟和吞吐量极高，因为它将避免不必要的消费者重新平衡。
- en: Since `consumer.commitSync()` blocks your thread unless a commit is done successfully,
    it may be slower in most cases compared to `consumer.commitAsync()`. However,
    if there is a fatal error, it makes sense to use `commitSync()` to ensure the
    messages are committed before the consumer application goes down.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于`consumer.commitSync()`在成功提交之前会阻塞线程，所以在大多数情况下，它可能比`consumer.commitAsync()`慢。然而，如果发生致命错误，使用`commitSync()`来确保在消费者应用程序关闭之前消息被提交是有意义的。
- en: Although we mainly focused this discussion on Apache Kafka, other alternative
    products that enable stream processing such as Apache Pulsar and AWS Kinesis have
    similar performance tuning techniques.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们主要讨论了Apache Kafka，但其他支持流处理的替代产品，如Apache Pulsar和AWS Kinesis，也有类似的性能调优技术。
- en: Database tuning
  id: totrans-282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据库调优
- en: Database tuning is an important activity when it comes to performance tuning.
    It includes SQL tuning, data read and write tuning from database tables, database-level
    tuning, and making optimizations while creating data models. Since these all vary
    considerably from one database to another (including SQL and NoSQL databases),
    database tuning is outside the scope of this book.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库调优是性能调优中的重要活动。它包括SQL调优、从数据库表中的数据读写调优、数据库级调优以及在创建数据模型时进行优化。由于这些内容在各个数据库之间差异很大（包括SQL和NoSQL数据库），因此数据库调优不在此书的范围之内。
- en: Now, let’s summarize what we learned in this chapter.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们总结一下本章所学的内容。
- en: Summary
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: We started this chapter by understanding what performance engineering is and
    learning about the performance engineering life cycle. We also pointed out the
    differences between performance engineering and performance testing. Then, we
    briefly discussed the various tools that are available to help with performance
    engineering. We learned about the basics of performance benchmarking and what
    to consider while creating a benchmark. Then, we learned about various performance
    optimization techniques and how to apply them to Java applications, big data applications,
    streaming applications, and databases.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从理解性能工程是什么以及学习性能工程生命周期开始本章。我们还指出了性能工程与性能测试之间的区别。然后，我们简要讨论了各种可用的工具，这些工具可以帮助进行性能工程。我们了解了性能基准测试的基础以及创建基准时需要考虑的因素。接着，我们学习了各种性能优化技术以及如何将它们应用到Java应用程序、大数据应用程序、流式应用程序和数据库中。
- en: With that, we have learned how to do performance engineering for both batch-based
    and real-time data engineering problems. In the next chapter, we will learn how
    to evaluate multiple architectural solutions and how to present the recommendations.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们已经学会了如何为基于批处理和实时数据工程问题进行性能工程。在下一章中，我们将学习如何评估多个架构解决方案以及如何提出建议。
