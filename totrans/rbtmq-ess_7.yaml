- en: Best Practices and Broker Monitoring
  prefs: []
  type: TYPE_NORMAL
- en: The previous chapters of this book focused on the setup of a successful microservice
    architecture using RabbitMQ at the example company **Complete Car** (**CC**).
    Many RabbitMQ features were included, however, no system is complete without an
    understanding of the best practices to use in its implementation. As with all
    production systems, proper monitoring and alerts are also needed to stay on top
    of things.
  prefs: []
  type: TYPE_NORMAL
- en: CC's cluster is stable and there are no performance issues. This chapter summarizes
    the key takeaways learned from CC's system, including best practices and recommendations
    for queues, routing, exchanges, message handling, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter explores the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: How to avoid losing messages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping queues and brokers clean
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Routing best practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Networking over connections and channels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring key takeaways
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring – querying the REST API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter is an ideal reference guide when setting up infrastructure using
    RabbitMQ. Refer back to the key takeaways, best practices, and monitoring tips
    in this chapter for valuable insights when putting RabbitMQ into production.
  prefs: []
  type: TYPE_NORMAL
- en: How to avoid losing messages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Losing messages can be avoided by following the best practices in this section.
    For the most part, CC has followed the best practice of **keeping queues short**
    and efficient. Queues that contain too many messages have a negative impact on
    the broker's performance. An identified **high RAM usage** could indicate that
    the number of queued messages rapidly went up.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some best practice recommendations for how to not lose messages in
    RabbitMQ:'
  prefs: []
  type: TYPE_NORMAL
- en: Use at least three nodes in the RabbitMQ cluster, and the **quorum queue** type
    to spread messages to different nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If it is absolutely imperative that all messages are processed, declare a queue
    as **durable** and set the message delivery mode to **persistent**, as described
    in [Chapter 2](377ec533-342d-4a08-9011-7176de197886.xhtml), *Creating a Taxi Application*.
    Queues, exchanges, and messages need to be able to handle any restarts, crashes,
    or hardware failures that may occur.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are some clarifications regarding message handling in RabbitMQ:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the trade-offs that come with persistence is essential when designing
    a durable system architecture. **Lazy queues**, though using transient messages,
    have a similar effect on performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using transient messages with durable queues creates speed without losing configuration
    but may result in message loss.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What if all these best practices are followed and messages are still in jeopardy
    of being lost? The next section covers the dead letter exchange, so messages that
    would potentially be gone forever have a place to wait until they can be processed.
  prefs: []
  type: TYPE_NORMAL
- en: Using a dead letter exchange
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Even when using durable queues and persistent messages, issues can occur that
    result in unhandled messages. A TTL might be set, a queue length might have been
    exceeded or the message might have been negatively acknowledged by the consumer.
    As a best practice, the routing key of the message should specify `x-dead-letter-routing-key`
    so that the message is never dropped. Attach queues to the exchange and manage
    messages programmatically. Try to avoid sending messages to the same exchange
    as this may result in a form of infinite recursion. Some messages might be unmanageable
    to handle and continually end up in the exchange. Make sure to handle these errors
    in the programming logic.
  prefs: []
  type: TYPE_NORMAL
- en: Set the `x-dead-letter-routing-key` property in the declaration of a queue.
    This helps with performance and separate error handling by components in the architecture,
    as described in *[Chapter 4](bece97d2-6653-459f-bbdc-6e47f343c1d3.xhtml), Tweaking
    Message Delivery*.
  prefs: []
  type: TYPE_NORMAL
- en: It is recommended for applications that often get hit by spikes of messages
    to set a queue max-length. The queue max-length helps keeping the queue short
    by discarding messages from the head of the queue. The max-length can be set to
    a number of messages, or a set number of bytes.
  prefs: []
  type: TYPE_NORMAL
- en: Handling acknowledgments and confirms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the event of a connection failure, a message in transit may get lost. Acknowledgments
    provide an alert to the server and the clients if messages need to be retransmitted.
    The client can either ack the message when it is received or when it has processed
    the message. However, it is important to remember that the application that consumes
    important messages should not ack until handled. That way, unprocessed messages
    from crashes or exceptions don't end up being missed. A publisher confirmation
    requires the server to confirm a message has been received from a publisher.
  prefs: []
  type: TYPE_NORMAL
- en: Confirms can also have an impact on system performance, but they are required
    if the publisher must process messages at least once.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices of message handling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Queues and clients handle the burden of their payloads – messages. To further
    improve performance, fine-tune messages and message handling.
  prefs: []
  type: TYPE_NORMAL
- en: Limiting message size
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The number of messages sent per second is a much larger concern than the size
    of the messages themselves. However, sending large messages is not a best practice,
    and neither is sending too small messages since AMQP adds a small packet overhead
    to all messages sent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examine messages to see whether they can be split and sent to different queues,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Split iterable data into chunks and send a small chunk per message.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Store large files in a distributed store, such as Hadoop or networked attached
    storage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Split the architecture into more modular components with a queue per component.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Offload appropriate metadata to a key-value store.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While sending large messages can be avoided, bandwidth, architecture, and fail-over
    limits are a consideration. The size of the message will depend on the application
    but should be as small as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Using consumers and prefetching
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Setting a prefetch value distributes workloads evenly across the system. Prefetching
    is allowed in RabbitMQ, but it is important to remember that prefetching is only
    effective when all consumers are busy.
  prefs: []
  type: TYPE_NORMAL
- en: RabbitMQ must manage consumption across queues and consumers. A prefetch value
    that is too low keeps the consumers idle as they wait for messages to arrive,
    which in turn will slow down the broker's ability to handle requests. Setting
    the prefetch value too high keeps one consumer busy while the rest remain idle,
    as described in *[Chapter 3](4e1d39f3-47d1-4423-916c-2c2c01c75887.xhtml), Sending
    Messages to Multiple Taxi Drivers*.
  prefs: []
  type: TYPE_NORMAL
- en: If processing time is low and the network is stable, then the prefetch value
    can be increased. In this case, the prefetch value can be determined easily by
    dividing the total round trip time by the processing time.
  prefs: []
  type: TYPE_NORMAL
- en: If there are many consumers and a longer processing time, the prefetch value
    trends lower. If processing times are long enough, set the prefetch limit to 1.
  prefs: []
  type: TYPE_NORMAL
- en: As queues get busier with demand, more system resources are consumed. Keeping
    the queues and brokers clean is imperative for good performance, which is covered
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping queues and brokers clean
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A clean broker is an efficient broker. To keep power and space at an optimum
    level, making sure queues and brokers are clean is easy. RabbitMQ provides mechanisms
    for auto-deleting messages and queues to keep space free. These include setting
    the **time to live** (**TTL**) and auto-deletion of unused queues, which are detailed
    in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Setting the TTL for messages or the max-length on queues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Queues providing messaging support for long-running processes may grow extremely
    large. A too large queue might affect the performance of the broker. Setting the
    **TTL **allows messages to be removed from the queue after a certain time. If
    specified, these messages enter the dead letter exchange. This saves more messages
    and even handles potential issues without losing data.
  prefs: []
  type: TYPE_NORMAL
- en: Set a reasonable **TTL** with the `x-message-ttl` property when declaring a
    queue. Make sure to provide `x-dead-letter-exchange` and `x-dead-letter-routing-key`
    to avoid losing messages entirely.
  prefs: []
  type: TYPE_NORMAL
- en: It is recommended for applications that often get hit by spikes of messages
    to set a queue max-length. The queue max-length helps keeping the queue short
    by discarding messages from the head of the queue. The max-length can be set to
    a number of messages, or a set number of bytes.
  prefs: []
  type: TYPE_NORMAL
- en: Auto-deleting unused queues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to keeping queues from becoming overly large, queues can be dropped
    based on use.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three ways to delete an unused queue automatically, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Set an expiration policy for the queue using the `x-expires` property on the
    declaration, keeping queues alive only for a number of non-zero milliseconds when
    unused.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Set the `auto-delete` queue property to `true` on the declaration. This means
    the queue will be dropped after the following scenarios:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The initial connection is made.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last consumer shuts down.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The channel/connection is closed or the queue has lost the **Transmission Control
    Protocol** (**TCP**) connection with the server.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set the exclusive property to `true` on queue declaration so that the structure
    belongs to the declaring connection and is deleted when the connection closes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sometimes, the journey itself is what creates inefficiency in a message queue.
    To make sure messages are taking the best path possible, follow the best practices
    for routing found in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Routing best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a best practice, direct exchanges are the fastest to use. Even when using
    direct exchanges, those with multiple bindings require more time to calculate
    where messages must be sent. There are some additional best practices to consider
    for routing.
  prefs: []
  type: TYPE_NORMAL
- en: Designing a system with routing in mind
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every endpoint is a service or application. Unlike CC, which operates between
    a car and, for the most part, a single application layer, many microservice architectures
    pass messages through dozens of services.
  prefs: []
  type: TYPE_NORMAL
- en: CC designed their system architecture around small services. They combined operations
    where it did make sense. After designing a smaller system, they consider where
    additional exchanges or queues could be beneficial. This kept the overall design
    small enough without limiting processing power.
  prefs: []
  type: TYPE_NORMAL
- en: Networking over connections and channels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thousands of connections add up to a heavy burden on a RabbitMQ server, causing
    it to run out of memory and crash. A large number of connections and channels
    can also negatively impact the RabbitMQ management interface due to the large
    number of performance metrics being processed. To avoid this, configure each application
    to create an extremely small number of connections – 1, if possible. Instead of
    using multiple connections, establish a channel for each thread. Each connection
    should be long-lived and the following best practices should be considered depending
    on the application structure.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that even if new hardware offers hundreds of threads, only the number
    of channels set can be established and this number should be kept from growing
    too large. As some clients don't make channels thread-safe, it is best not to
    share channels between threads. Doing so may create a race condition, which could
    completely crash the application.
  prefs: []
  type: TYPE_NORMAL
- en: Repeatedly opening and closing connections and channels is also detrimental
    to system performance. Doing so increases latency as more TCP packets are sent
    over the network.
  prefs: []
  type: TYPE_NORMAL
- en: Using TLS and AMQPS for security
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RabbitMQ can be connected over AMQPS, which is the AMQP protocol wrapped in
    TLS. Data passed over the network is encrypted, but there is a performance impact
    to consider. To maximize performance, use VPC or VPN peering instead since they
    provide a private, isolated environment for traffic and do not involve the AMQP
    client and server directly.
  prefs: []
  type: TYPE_NORMAL
- en: Do not expose the backend over the frontend. The CC example is simplified. In
    reality, there would likely be an application layer added between unknown users
    and the broker.
  prefs: []
  type: TYPE_NORMAL
- en: Separate connections
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By default, RabbitMQ will reduce the speed of connections that publish too quickly
    for queues to keep up. RabbitMQ simply applies back-pressure on the TCP connection,
    which places it in flow control. A flow-controlled connection shows a state of
    flow in the management UI and through HTTP API responses. This means the connection
    is experiencing blocking and unblocking several times a second to keep the message
    flow rate at a level that the rest of the server and the queues can handle.
  prefs: []
  type: TYPE_NORMAL
- en: When the publisher is using the same TCP connection as the consumer, messages
    can be blocked while replying to the broker. The server may not receive the acks
    from the client, which will have a negative impact on the speed and cause it to
    be overwhelmed. Achieving higher throughput is, therefore, best accomplished through
    separate connections for publishers and consumers.
  prefs: []
  type: TYPE_NORMAL
- en: Splitting queues over different cores
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The CC infrastructure runs on multiple cores. To achieve better performance,
    queues are split among different cores and nodes. Queues in RabbitMQ are bound
    to the node where they are first declared. This holds true even for clustered
    brokers, as all messages routed to a specific queue go to the node where the queue
    lives. One queue in RabbitMQ can handle up to 50,000 messages a second. Better
    performance is therefore achieved when queues are split over different cores and
    nodes, and when they are spread between multiple queues.
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to manually split queues evenly between nodes, but this can be
    difficult to remember. Alternatively, there are two plugins to assist with organizing
    multiple nodes or a single node cluster with multiple cores. These are the **Consistent
    Hash Exchange** and the **RabbitMQ sharding** plugins.
  prefs: []
  type: TYPE_NORMAL
- en: RabbitMQ sharding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Sharding makes it easy to distribute messages among queues on different nodes. A
    queue can be spread among multiple actual queues. Once an exchange is defined
    as sharded, the supporting queues automatically start on every cluster node with
    messages spreading accordingly, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/284071c3-7926-4dae-8b99-dca7de34ec89.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig 7.1: Sharding among queues'
  prefs: []
  type: TYPE_NORMAL
- en: The routing keys ensure an even distribution of messages among queues. The plugin
    expects you to run a consumer per shard with new nodes being automatically incorporated.
    Note that it's important to consume from all queues. The plugin provides a centralized
    place to send messages, and load-balances messages across nodes by adding queues
    across the cluster. Read more about the RabbitMQ sharding plugin at: [https://github.com/rabbitmq/rabbitmq-sharding](https://github.com/rabbitmq/rabbitmq-sharding).
  prefs: []
  type: TYPE_NORMAL
- en: Consistent Hash Exchange
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: RabbitMQ offers another plugin that helps load-balance messages through the
    Consistent Hash Exchange. Based on the routing key, **bound** queues in this exchange
    are sent messages equally. This optimizes the use of a cluster with multiple cores,
    as the plugin creates a hash of the routing key and is consistent about spreading
    messages between queues bound to the exchange, ensuring optimal use over many
    cores in a cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Read more about the Consistent Hash Exchange plugin at: [https://github.com/rabbitmq/rabbitmq-consistent-hash-exchange](https://github.com/rabbitmq/rabbitmq-consistent-hash-exchange).
  prefs: []
  type: TYPE_NORMAL
- en: Exploring key takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the sake of simplification, optimization can be broken into two forms, and
    since cars have been a popular topic in this book, let's stick with that theme.
  prefs: []
  type: TYPE_NORMAL
- en: '**Ferrari** **–** **fast and smooth**: If the system must have fast performance
    and high throughput, use a single node. Keep queues as short as possible, and
    set the max length or TTL if possible. Do not set the lazy queue policies to keep
    retrieval time short. Use transient messages, rather than persistent ones, for
    the same reason. Take advantage of using multiple queues and consumers, providing
    maximum throughput. For the fastest possible throughput, manual acks should be
    disabled. Always strive to use the latest stable RabbitMQ version.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Volvo** **–** **stable and reliable**:A system that must be highly available
    and cannot afford to lose messages should have durable queues and send persistent
    messages. Queues should still be kept short.'
  prefs: []
  type: TYPE_NORMAL
- en: It is recommended that clustering is set up through quorum queues. If mirrored
    queues are already in use, add the lazy queue policy to get a more stable setup.
    Make sure that three or five nodes are used in the system to achieve high availability.
    When setting up a RabbitMQ cluster, split queues among different cores and into
    different nodes, using the Consistent Hash Exchange or sharding plugins to keep
    everything running smoothly and efficiently. Always strive to use the latest stable
    RabbitMQ version.
  prefs: []
  type: TYPE_NORMAL
- en: Now that the best practice tips have been covered, it's time to consider what
    should occur if and when something goes wrong. Monitoring the cluster and setting
    alarm policies are two very important finishing touches to any production environment.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring – querying the REST API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two main ways to retrieve live information when monitoring a RabbitMQ
    broker: one through the `rabbitmqctl` command-line tool and another through the
    **REST API** exposed over HTTP by the management console.'
  prefs: []
  type: TYPE_NORMAL
- en: Any monitoring system can use these tools to collect metrics and report them
    to the log, analytics, reporting, and alert frameworks. Information could be pushed
    to external logging services for further analysis, as an example.
  prefs: []
  type: TYPE_NORMAL
- en: Since CC installed the management console, as described in [Chapter 1](4f4722d3-131f-4c38-9ea0-4c03e8545175.xhtml)*,
    A Rabbit Springs to Life*, the team opts to use the rich, well-documented API
    over the command line. RabbitMQ provides documentation at the `http://localhost:15672/` API
    on any node that has the management plugin installed. It is possible to retrieve
    the same raw metrics over the command line, albeit without graphics.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that the management console is backed by the API, so anything that
    is seen and done within a browser can be done through the API.
  prefs: []
  type: TYPE_NORMAL
- en: 'RabbitMQ exposes a variety of different metric types for collection, as discussed
    in the preceding sections. These include, but are not limited to, the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Node status**: Testing the performance of RabbitMQ involves executing a set
    of commands to declare an aliveness-test queue and then publishing as well as
    consuming it. Set an alarm to fire if the command returns `0` (no messages consumed)
    through the appropriate request:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Cluster size**: Testing the cluster size is useful for discovering network
    partitions. Set an alarm to fire if the cluster size is lower than expected:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: CC uses a `bash` script and Python to send an error when the number of nodes
    is less than expected.
  prefs: []
  type: TYPE_NORMAL
- en: '**Federation status**: Federated queues may become unlinked due to a restart
    or another issue. Check the active upstream links on the central log aggregation
    broker and raise an alarm if it''s less than the optimal size (`3`, in CC''s case),
    as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Queues'' high watermarks**: Cloud-based brokers sometimes offer scale at
    low cost but with message limits. In other cases, message latency is an issue.
    Ensure that the number of available messages in a queue is below a certain threshold:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In CC's case, they want to verify that the `taxi-dlq` queue has less than 25
    messages. Otherwise, they raise an alarm indicating a bottleneck. Scripts need
    to handle a graceful failure if the queue does not exist.
  prefs: []
  type: TYPE_NORMAL
- en: '**Overall message throughput**: Monitoring the intensity of messaging traffic
    on a particular broker makes it possible to increase or decrease resources as
    required. Collect message rates with the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: CC adds an alarm if the throughput threshold exceeds the upper limit of what
    one its brokers can withstand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some metrics come with rigid upper limits whose values are also available through
    the API. A recommendation is to raise an alarm whenever a threshold of 80 percent
    of the upper limit is reached. The following scripts return false when the alarm
    must be raised. These metrics include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**File descriptors**: Many OSes have file descriptor limits. The performance
    of the message persistence on the disk can be affected if not enough descriptors
    are available. The number of file descriptors used can be compared with the amount
    of available file descriptors:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: It is possible to increase the number of available file descriptors on macOS
    X and Linux. File descriptors are used to access other files. It's a good idea
    to check throughputs if this limit is exceeded as well.
  prefs: []
  type: TYPE_NORMAL
- en: '**Socket descriptors**: Socket descriptors maintain a handle to an individual
    socket for a connection. RabbitMQ stops accepting new connections if these descriptors
    are exhausted, which is a common issue with large clusters:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Linux uses file descriptors for sockets, adjusting the count with the `ulimit`
    command. Using more channels and fewer connections, in line with best practices,
    helps to handle this issue as well.
  prefs: []
  type: TYPE_NORMAL
- en: '**Erlang processes**: There is an upper limit to the number of processes an
    Erlang virtual machine creates. Although typically near 1 million processes, each
    requires resources to run. The number of Erlang processes used can be compared
    with the Erlang process limit:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: An OS thread is not created for each process. Still, each uses a lightweight
    stack and requires time to schedule and maintain.
  prefs: []
  type: TYPE_NORMAL
- en: '**Memory and disk space**: If memory or disk space is exhausted, RabbitMQ will
    not work properly – for example, flow control can be triggered. Check that there
    are sufficient resources and tune the hardware appropriately.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The total amount of memory used should be less then 80 percent of the memory
    usage high watermark:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The disk free space limit should be compared to the current free disk space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to metrics, a working instance runs the following programs:'
  prefs: []
  type: TYPE_NORMAL
- en: '`rabbitmq-server`: This is obvious but should not be forgotten!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`epmd`: The Erlang port mapper daemon, `epmd`, plays a critical role in clustering
    and networking. It is advisable to set up scripts to check that these services
    are running. List programs using `ps` on Linux or macOS X and `Get-Process` in
    Windows.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ERROR REPORT` entries in the main log file reveal issues within the system.
    In Linux, RabbitMQ stores log files at `/var/log/rabbitmq/rabbit@<hostname>.log`.
    For more information, check the configuration file at [https://www.rabbitmq.com/logging.html#log-file-location](https://www.rabbitmq.com/logging.html#log-file-location).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter concludes the study of microservices built on RabbitMQ with an
    examination of best practices as well as monitoring. The book went through the
    application funnel for CC, beginning with the basic service and scaling. New features
    and processes were added with ease and without interruption to the CC application.
    Over time, CC’s development team created a holistic, useful, reliable, long-life
    application. To avoid failures that could lead to bad user experience or even
    data loss, the CC team implemented a monitoring strategy. Collecting, logging,
    analyzing, and reporting metrics were outlined as CC formed an alert plan. Finally,
    the alert parameters were set up through the RabbitMQ management console.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations on completing your journey through this book! Armed with sufficient
    RabbitMQ wrangling skills, the next step is to create an instance for yourself.
    An easy way to get started with RabbitMQ is through the manager of the largest
    fleet of RabbitMQ clusters in the world – hosted RabbitMQ provider CloudAMQP.
  prefs: []
  type: TYPE_NORMAL
