- en: Best Practices and Broker Monitoring
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
- en: The previous chapters of this book focused on the setup of a successful microservice
    architecture using RabbitMQ at the example company **Complete Car** (**CC**).
    Many RabbitMQ features were included, however, no system is complete without an
    understanding of the best practices to use in its implementation. As with all
    production systems, proper monitoring and alerts are also needed to stay on top
    of things.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: CC's cluster is stable and there are no performance issues. This chapter summarizes
    the key takeaways learned from CC's system, including best practices and recommendations
    for queues, routing, exchanges, message handling, and more.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter explores the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: How to avoid losing messages
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping queues and brokers clean
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Routing best practices
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Networking over connections and channels
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring key takeaways
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring – querying the REST API
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter is an ideal reference guide when setting up infrastructure using
    RabbitMQ. Refer back to the key takeaways, best practices, and monitoring tips
    in this chapter for valuable insights when putting RabbitMQ into production.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: How to avoid losing messages
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Losing messages can be avoided by following the best practices in this section.
    For the most part, CC has followed the best practice of **keeping queues short**
    and efficient. Queues that contain too many messages have a negative impact on
    the broker's performance. An identified **high RAM usage** could indicate that
    the number of queued messages rapidly went up.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some best practice recommendations for how to not lose messages in
    RabbitMQ:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Use at least three nodes in the RabbitMQ cluster, and the **quorum queue** type
    to spread messages to different nodes.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If it is absolutely imperative that all messages are processed, declare a queue
    as **durable** and set the message delivery mode to **persistent**, as described
    in [Chapter 2](377ec533-342d-4a08-9011-7176de197886.xhtml), *Creating a Taxi Application*.
    Queues, exchanges, and messages need to be able to handle any restarts, crashes,
    or hardware failures that may occur.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are some clarifications regarding message handling in RabbitMQ:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the trade-offs that come with persistence is essential when designing
    a durable system architecture. **Lazy queues**, though using transient messages,
    have a similar effect on performance.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using transient messages with durable queues creates speed without losing configuration
    but may result in message loss.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What if all these best practices are followed and messages are still in jeopardy
    of being lost? The next section covers the dead letter exchange, so messages that
    would potentially be gone forever have a place to wait until they can be processed.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Using a dead letter exchange
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Even when using durable queues and persistent messages, issues can occur that
    result in unhandled messages. A TTL might be set, a queue length might have been
    exceeded or the message might have been negatively acknowledged by the consumer.
    As a best practice, the routing key of the message should specify `x-dead-letter-routing-key`
    so that the message is never dropped. Attach queues to the exchange and manage
    messages programmatically. Try to avoid sending messages to the same exchange
    as this may result in a form of infinite recursion. Some messages might be unmanageable
    to handle and continually end up in the exchange. Make sure to handle these errors
    in the programming logic.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Set the `x-dead-letter-routing-key` property in the declaration of a queue.
    This helps with performance and separate error handling by components in the architecture,
    as described in *[Chapter 4](bece97d2-6653-459f-bbdc-6e47f343c1d3.xhtml), Tweaking
    Message Delivery*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: It is recommended for applications that often get hit by spikes of messages
    to set a queue max-length. The queue max-length helps keeping the queue short
    by discarding messages from the head of the queue. The max-length can be set to
    a number of messages, or a set number of bytes.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Handling acknowledgments and confirms
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the event of a connection failure, a message in transit may get lost. Acknowledgments
    provide an alert to the server and the clients if messages need to be retransmitted.
    The client can either ack the message when it is received or when it has processed
    the message. However, it is important to remember that the application that consumes
    important messages should not ack until handled. That way, unprocessed messages
    from crashes or exceptions don't end up being missed. A publisher confirmation
    requires the server to confirm a message has been received from a publisher.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Confirms can also have an impact on system performance, but they are required
    if the publisher must process messages at least once.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Best practices of message handling
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Queues and clients handle the burden of their payloads – messages. To further
    improve performance, fine-tune messages and message handling.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Limiting message size
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The number of messages sent per second is a much larger concern than the size
    of the messages themselves. However, sending large messages is not a best practice,
    and neither is sending too small messages since AMQP adds a small packet overhead
    to all messages sent.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: 'Examine messages to see whether they can be split and sent to different queues,
    as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Split iterable data into chunks and send a small chunk per message.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Store large files in a distributed store, such as Hadoop or networked attached
    storage.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Split the architecture into more modular components with a queue per component.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Offload appropriate metadata to a key-value store.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While sending large messages can be avoided, bandwidth, architecture, and fail-over
    limits are a consideration. The size of the message will depend on the application
    but should be as small as possible.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Using consumers and prefetching
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Setting a prefetch value distributes workloads evenly across the system. Prefetching
    is allowed in RabbitMQ, but it is important to remember that prefetching is only
    effective when all consumers are busy.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: RabbitMQ must manage consumption across queues and consumers. A prefetch value
    that is too low keeps the consumers idle as they wait for messages to arrive,
    which in turn will slow down the broker's ability to handle requests. Setting
    the prefetch value too high keeps one consumer busy while the rest remain idle,
    as described in *[Chapter 3](4e1d39f3-47d1-4423-916c-2c2c01c75887.xhtml), Sending
    Messages to Multiple Taxi Drivers*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: If processing time is low and the network is stable, then the prefetch value
    can be increased. In this case, the prefetch value can be determined easily by
    dividing the total round trip time by the processing time.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: If there are many consumers and a longer processing time, the prefetch value
    trends lower. If processing times are long enough, set the prefetch limit to 1.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: As queues get busier with demand, more system resources are consumed. Keeping
    the queues and brokers clean is imperative for good performance, which is covered
    in the next section.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Keeping queues and brokers clean
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A clean broker is an efficient broker. To keep power and space at an optimum
    level, making sure queues and brokers are clean is easy. RabbitMQ provides mechanisms
    for auto-deleting messages and queues to keep space free. These include setting
    the **time to live** (**TTL**) and auto-deletion of unused queues, which are detailed
    in the following sections.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Setting the TTL for messages or the max-length on queues
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Queues providing messaging support for long-running processes may grow extremely
    large. A too large queue might affect the performance of the broker. Setting the
    **TTL **allows messages to be removed from the queue after a certain time. If
    specified, these messages enter the dead letter exchange. This saves more messages
    and even handles potential issues without losing data.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Set a reasonable **TTL** with the `x-message-ttl` property when declaring a
    queue. Make sure to provide `x-dead-letter-exchange` and `x-dead-letter-routing-key`
    to avoid losing messages entirely.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: It is recommended for applications that often get hit by spikes of messages
    to set a queue max-length. The queue max-length helps keeping the queue short
    by discarding messages from the head of the queue. The max-length can be set to
    a number of messages, or a set number of bytes.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Auto-deleting unused queues
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to keeping queues from becoming overly large, queues can be dropped
    based on use.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three ways to delete an unused queue automatically, as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Set an expiration policy for the queue using the `x-expires` property on the
    declaration, keeping queues alive only for a number of non-zero milliseconds when
    unused.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Set the `auto-delete` queue property to `true` on the declaration. This means
    the queue will be dropped after the following scenarios:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The initial connection is made.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last consumer shuts down.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The channel/connection is closed or the queue has lost the **Transmission Control
    Protocol** (**TCP**) connection with the server.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set the exclusive property to `true` on queue declaration so that the structure
    belongs to the declaring connection and is deleted when the connection closes.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sometimes, the journey itself is what creates inefficiency in a message queue.
    To make sure messages are taking the best path possible, follow the best practices
    for routing found in the next section.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Routing best practices
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a best practice, direct exchanges are the fastest to use. Even when using
    direct exchanges, those with multiple bindings require more time to calculate
    where messages must be sent. There are some additional best practices to consider
    for routing.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Designing a system with routing in mind
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every endpoint is a service or application. Unlike CC, which operates between
    a car and, for the most part, a single application layer, many microservice architectures
    pass messages through dozens of services.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: CC designed their system architecture around small services. They combined operations
    where it did make sense. After designing a smaller system, they consider where
    additional exchanges or queues could be beneficial. This kept the overall design
    small enough without limiting processing power.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Networking over connections and channels
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thousands of connections add up to a heavy burden on a RabbitMQ server, causing
    it to run out of memory and crash. A large number of connections and channels
    can also negatively impact the RabbitMQ management interface due to the large
    number of performance metrics being processed. To avoid this, configure each application
    to create an extremely small number of connections – 1, if possible. Instead of
    using multiple connections, establish a channel for each thread. Each connection
    should be long-lived and the following best practices should be considered depending
    on the application structure.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Remember that even if new hardware offers hundreds of threads, only the number
    of channels set can be established and this number should be kept from growing
    too large. As some clients don't make channels thread-safe, it is best not to
    share channels between threads. Doing so may create a race condition, which could
    completely crash the application.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: Repeatedly opening and closing connections and channels is also detrimental
    to system performance. Doing so increases latency as more TCP packets are sent
    over the network.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Using TLS and AMQPS for security
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RabbitMQ can be connected over AMQPS, which is the AMQP protocol wrapped in
    TLS. Data passed over the network is encrypted, but there is a performance impact
    to consider. To maximize performance, use VPC or VPN peering instead since they
    provide a private, isolated environment for traffic and do not involve the AMQP
    client and server directly.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ 可以通过 AMQPS 连接，即 TLS 包装的 AMQP 协议。通过网络传输的数据被加密，但需要考虑性能影响。为了最大化性能，请使用
    VPC 或 VPN 对等连接，因为它们为流量提供了一个私有、隔离的环境，并且不直接涉及 AMQP 客户端和服务器。
- en: Do not expose the backend over the frontend. The CC example is simplified. In
    reality, there would likely be an application layer added between unknown users
    and the broker.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 不要在前端暴露后端。CC 示例被简化了。在现实中，很可能在未知用户和代理之间添加一个应用层。
- en: Separate connections
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分离的连接
- en: By default, RabbitMQ will reduce the speed of connections that publish too quickly
    for queues to keep up. RabbitMQ simply applies back-pressure on the TCP connection,
    which places it in flow control. A flow-controlled connection shows a state of
    flow in the management UI and through HTTP API responses. This means the connection
    is experiencing blocking and unblocking several times a second to keep the message
    flow rate at a level that the rest of the server and the queues can handle.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，RabbitMQ 会降低发布速度过快的连接速度，以便队列能够跟上。RabbitMQ 简单地对 TCP 连接应用反向压力，将其置于流量控制状态。流量控制的连接在管理
    UI 和 HTTP API 响应中显示流量状态。这意味着连接每秒经历多次阻塞和解阻塞，以保持消息流率在一个服务器和队列都能处理的水准。
- en: When the publisher is using the same TCP connection as the consumer, messages
    can be blocked while replying to the broker. The server may not receive the acks
    from the client, which will have a negative impact on the speed and cause it to
    be overwhelmed. Achieving higher throughput is, therefore, best accomplished through
    separate connections for publishers and consumers.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当发布者使用与消费者相同的 TCP 连接时，在回复代理时可能会阻塞消息。服务器可能无法从客户端收到确认，这将对其速度产生负面影响，并可能导致其过载。因此，通过为发布者和消费者使用单独的连接来实现更高的吞吐量是最佳选择。
- en: Splitting queues over different cores
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在不同的核心上分割队列
- en: The CC infrastructure runs on multiple cores. To achieve better performance,
    queues are split among different cores and nodes. Queues in RabbitMQ are bound
    to the node where they are first declared. This holds true even for clustered
    brokers, as all messages routed to a specific queue go to the node where the queue
    lives. One queue in RabbitMQ can handle up to 50,000 messages a second. Better
    performance is therefore achieved when queues are split over different cores and
    nodes, and when they are spread between multiple queues.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: CC 基础设施运行在多个核心上。为了获得更好的性能，队列被分散在不同的核心和节点之间。RabbitMQ 中的队列绑定到它们首次声明的节点。即使对于集群代理也是如此，因为所有路由到特定队列的消息都发送到队列所在的节点。RabbitMQ
    中的一个队列每秒可以处理高达 50,000 条消息。因此，当队列在不同核心和节点之间分割，并在多个队列之间分散时，可以获得更好的性能。
- en: It is possible to manually split queues evenly between nodes, but this can be
    difficult to remember. Alternatively, there are two plugins to assist with organizing
    multiple nodes or a single node cluster with multiple cores. These are the **Consistent
    Hash Exchange** and the **RabbitMQ sharding** plugins.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 可以手动在节点之间均匀分割队列，但这可能难以记住。或者，有两个插件可以帮助组织多个节点或单个节点集群的多核。这些是**一致性哈希交换**和**RabbitMQ
    分片**插件。
- en: RabbitMQ sharding
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RabbitMQ 分片
- en: 'Sharding makes it easy to distribute messages among queues on different nodes. A
    queue can be spread among multiple actual queues. Once an exchange is defined
    as sharded, the supporting queues automatically start on every cluster node with
    messages spreading accordingly, as shown in the following diagram:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 分片使得在不同节点上的队列之间分配消息变得容易。一个队列可以分散到多个实际队列中。一旦交换被定义为分片，支持队列将自动在每个集群节点上启动，消息相应地分散，如下所示：
- en: '![](img/284071c3-7926-4dae-8b99-dca7de34ec89.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/284071c3-7926-4dae-8b99-dca7de34ec89.png)'
- en: 'Fig 7.1: Sharding among queues'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1：队列间的分片
- en: The routing keys ensure an even distribution of messages among queues. The plugin
    expects you to run a consumer per shard with new nodes being automatically incorporated.
    Note that it's important to consume from all queues. The plugin provides a centralized
    place to send messages, and load-balances messages across nodes by adding queues
    across the cluster. Read more about the RabbitMQ sharding plugin at: [https://github.com/rabbitmq/rabbitmq-sharding](https://github.com/rabbitmq/rabbitmq-sharding).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Consistent Hash Exchange
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: RabbitMQ offers another plugin that helps load-balance messages through the
    Consistent Hash Exchange. Based on the routing key, **bound** queues in this exchange
    are sent messages equally. This optimizes the use of a cluster with multiple cores,
    as the plugin creates a hash of the routing key and is consistent about spreading
    messages between queues bound to the exchange, ensuring optimal use over many
    cores in a cluster.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Read more about the Consistent Hash Exchange plugin at: [https://github.com/rabbitmq/rabbitmq-consistent-hash-exchange](https://github.com/rabbitmq/rabbitmq-consistent-hash-exchange).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Exploring key takeaways
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the sake of simplification, optimization can be broken into two forms, and
    since cars have been a popular topic in this book, let's stick with that theme.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '**Ferrari** **–** **fast and smooth**: If the system must have fast performance
    and high throughput, use a single node. Keep queues as short as possible, and
    set the max length or TTL if possible. Do not set the lazy queue policies to keep
    retrieval time short. Use transient messages, rather than persistent ones, for
    the same reason. Take advantage of using multiple queues and consumers, providing
    maximum throughput. For the fastest possible throughput, manual acks should be
    disabled. Always strive to use the latest stable RabbitMQ version.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '**Volvo** **–** **stable and reliable**:A system that must be highly available
    and cannot afford to lose messages should have durable queues and send persistent
    messages. Queues should still be kept short.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: It is recommended that clustering is set up through quorum queues. If mirrored
    queues are already in use, add the lazy queue policy to get a more stable setup.
    Make sure that three or five nodes are used in the system to achieve high availability.
    When setting up a RabbitMQ cluster, split queues among different cores and into
    different nodes, using the Consistent Hash Exchange or sharding plugins to keep
    everything running smoothly and efficiently. Always strive to use the latest stable
    RabbitMQ version.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Now that the best practice tips have been covered, it's time to consider what
    should occur if and when something goes wrong. Monitoring the cluster and setting
    alarm policies are two very important finishing touches to any production environment.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring – querying the REST API
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two main ways to retrieve live information when monitoring a RabbitMQ
    broker: one through the `rabbitmqctl` command-line tool and another through the
    **REST API** exposed over HTTP by the management console.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Any monitoring system can use these tools to collect metrics and report them
    to the log, analytics, reporting, and alert frameworks. Information could be pushed
    to external logging services for further analysis, as an example.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Since CC installed the management console, as described in [Chapter 1](4f4722d3-131f-4c38-9ea0-4c03e8545175.xhtml)*,
    A Rabbit Springs to Life*, the team opts to use the rich, well-documented API
    over the command line. RabbitMQ provides documentation at the `http://localhost:15672/` API
    on any node that has the management plugin installed. It is possible to retrieve
    the same raw metrics over the command line, albeit without graphics.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that the management console is backed by the API, so anything that
    is seen and done within a browser can be done through the API.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 'RabbitMQ exposes a variety of different metric types for collection, as discussed
    in the preceding sections. These include, but are not limited to, the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '**Node status**: Testing the performance of RabbitMQ involves executing a set
    of commands to declare an aliveness-test queue and then publishing as well as
    consuming it. Set an alarm to fire if the command returns `0` (no messages consumed)
    through the appropriate request:'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Cluster size**: Testing the cluster size is useful for discovering network
    partitions. Set an alarm to fire if the cluster size is lower than expected:'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: CC uses a `bash` script and Python to send an error when the number of nodes
    is less than expected.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '**Federation status**: Federated queues may become unlinked due to a restart
    or another issue. Check the active upstream links on the central log aggregation
    broker and raise an alarm if it''s less than the optimal size (`3`, in CC''s case),
    as follows:'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Queues'' high watermarks**: Cloud-based brokers sometimes offer scale at
    low cost but with message limits. In other cases, message latency is an issue.
    Ensure that the number of available messages in a queue is below a certain threshold:'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In CC's case, they want to verify that the `taxi-dlq` queue has less than 25
    messages. Otherwise, they raise an alarm indicating a bottleneck. Scripts need
    to handle a graceful failure if the queue does not exist.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '**Overall message throughput**: Monitoring the intensity of messaging traffic
    on a particular broker makes it possible to increase or decrease resources as
    required. Collect message rates with the following command:'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: CC adds an alarm if the throughput threshold exceeds the upper limit of what
    one its brokers can withstand.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'Some metrics come with rigid upper limits whose values are also available through
    the API. A recommendation is to raise an alarm whenever a threshold of 80 percent
    of the upper limit is reached. The following scripts return false when the alarm
    must be raised. These metrics include the following:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '**File descriptors**: Many OSes have file descriptor limits. The performance
    of the message persistence on the disk can be affected if not enough descriptors
    are available. The number of file descriptors used can be compared with the amount
    of available file descriptors:'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: It is possible to increase the number of available file descriptors on macOS
    X and Linux. File descriptors are used to access other files. It's a good idea
    to check throughputs if this limit is exceeded as well.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '**Socket descriptors**: Socket descriptors maintain a handle to an individual
    socket for a connection. RabbitMQ stops accepting new connections if these descriptors
    are exhausted, which is a common issue with large clusters:'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Linux uses file descriptors for sockets, adjusting the count with the `ulimit`
    command. Using more channels and fewer connections, in line with best practices,
    helps to handle this issue as well.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '**Erlang processes**: There is an upper limit to the number of processes an
    Erlang virtual machine creates. Although typically near 1 million processes, each
    requires resources to run. The number of Erlang processes used can be compared
    with the Erlang process limit:'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: An OS thread is not created for each process. Still, each uses a lightweight
    stack and requires time to schedule and maintain.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '**Memory and disk space**: If memory or disk space is exhausted, RabbitMQ will
    not work properly – for example, flow control can be triggered. Check that there
    are sufficient resources and tune the hardware appropriately.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The total amount of memory used should be less then 80 percent of the memory
    usage high watermark:'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The disk free space limit should be compared to the current free disk space:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In addition to metrics, a working instance runs the following programs:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '`rabbitmq-server`: This is obvious but should not be forgotten!'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`epmd`: The Erlang port mapper daemon, `epmd`, plays a critical role in clustering
    and networking. It is advisable to set up scripts to check that these services
    are running. List programs using `ps` on Linux or macOS X and `Get-Process` in
    Windows.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ERROR REPORT` entries in the main log file reveal issues within the system.
    In Linux, RabbitMQ stores log files at `/var/log/rabbitmq/rabbit@<hostname>.log`.
    For more information, check the configuration file at [https://www.rabbitmq.com/logging.html#log-file-location](https://www.rabbitmq.com/logging.html#log-file-location).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter concludes the study of microservices built on RabbitMQ with an
    examination of best practices as well as monitoring. The book went through the
    application funnel for CC, beginning with the basic service and scaling. New features
    and processes were added with ease and without interruption to the CC application.
    Over time, CC’s development team created a holistic, useful, reliable, long-life
    application. To avoid failures that could lead to bad user experience or even
    data loss, the CC team implemented a monitoring strategy. Collecting, logging,
    analyzing, and reporting metrics were outlined as CC formed an alert plan. Finally,
    the alert parameters were set up through the RabbitMQ management console.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations on completing your journey through this book! Armed with sufficient
    RabbitMQ wrangling skills, the next step is to create an instance for yourself.
    An easy way to get started with RabbitMQ is through the manager of the largest
    fleet of RabbitMQ clusters in the world – hosted RabbitMQ provider CloudAMQP.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
