<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Flowables and Backpressure</h1>
                </header>
            
            <article>
                
<p>In the previous chapter, we learned about different operators that intercept rapidly firing emissions and either consolidate or omit them to decrease the emissions passed downstream. But for most cases where a source is producing emissions faster than the downstream can process them, it is better to proactively make the source slow down in the first place and emit at a pace that agrees with the downstream operations. This is known as backpressure or flow control, and it can be enabled by using a <kbd>Flowable</kbd> instead of an <kbd>Observable</kbd>. This will be the core type that we work with in this chapter, and we will learn about the right times to leverage it in our applications. We will cover the following topics in this chapter:</p>
<ul>
<li>Understanding backpressure</li>
<li><kbd>Flowable</kbd> and <kbd>Subscriber</kbd></li>
<li>Using <kbd>Flowable.create()</kbd></li>
<li>Interoperating Observables and Flowables</li>
<li>Backpressure operators</li>
<li>Using <kbd>Flowable.generate()</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding backpressure</h1>
                </header>
            
            <article>
                
<p>Throughout this book, I emphasized the "push-based" nature of Observables. Pushing items synchronously and one at a time from the source all the way to the <kbd>Observer</kbd> is indeed how <kbd>Observable</kbd> chains work by default without any concurrency.</p>
<p>For instance, the following is an <kbd>Observable</kbd> that will emit the numbers 1 through 999,999,999. It will map each integer to a <kbd>MyItem</kbd> instance, which simply holds it as a property. But let's slow down the processing of each emission by 50 milliseconds in the <kbd>Observer</kbd>. This shows that even if the downstream is slowly processing each emission, the upstream synchronously keeps pace with it. This is because one thread is doing all the work:</p>
<pre style="padding-left: 60px"> import io.reactivex.Observable;<br/><br/> public class Launcher {<br/><br/>     public static void main(String[] args) {<br/><br/>         Observable.range(1, 999_999_999)<br/>                 .map(MyItem::new)<br/>                 .subscribe(myItem -&gt; {<br/>                     sleep(50);<br/>                     System.out.println("Received MyItem " + myItem.id);<br/>                 });<br/>     }<br/><br/>     static void sleep(long milliseconds) {<br/>         try {<br/>             Thread.sleep(milliseconds);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/><br/>     static final class MyItem {<br/><br/>         final int id;<br/><br/>         MyItem(int id) {<br/>             this.id = id;<br/>             System.out.println("Constructing MyItem " + id);<br/>         }<br/>     }<br/> }</pre>
<p>The output is as follows:</p>
<pre style="padding-left: 60px"> Constructing MyItem 1<br/> Received MyItem 1<br/> Constructing MyItem 2<br/> Received MyItem 2<br/> Constructing MyItem 3<br/> Received MyItem 3<br/> Constructing MyItem 4<br/> Received MyItem 4<br/> Constructing MyItem 5<br/> Received MyItem 5<br/> Constructing MyItem 6<br/> Received MyItem 6<br/> Constructing MyItem 7<br/> Received MyItem 7<br/> ...</pre>
<p>The outputted alternation between <kbd>Constructing MyItem</kbd> and <kbd>Received MyItem</kbd> shows that each emission is bring processed one at a time from the source all the way to the terminal <kbd>Observer</kbd>. This is because one thread is doing all the work for this entire operation, making everything synchronous. The consumers and producers are passing emissions in a serialized, consistent flow.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">An example that needs backpressure</h1>
                </header>
            
            <article>
                
<p>When you add concurrency operations to an <kbd>Observable</kbd> chain (particularly <kbd>observeOn()</kbd>, parallelization, and operators such as <kbd>delay()</kbd>), the operation become <em>asynchronous</em>. This means hat multiple parts of the <kbd>Observable</kbd> chain can be processing emissions at a given time, and producers can outpace consumers as they are now operating on different threads. An emission is no longer strictly being handed downstream one at a time from the source all the way to the <kbd>Observer</kbd> before starting the next one. This is because once an emission hits a different <kbd>Scheduler</kbd> through <kbd>observeOn()</kbd> (or other concurrent operators), the source is no longer in charge of pushing that emission to the <kbd>Observer</kbd>. Therefore, the source will start pushing the next emission even though the previous emission may not have reached the Observer yet.</p>
<p>If we take our previous example and add <kbd>observeOn(Shedulers.io())</kbd> right before <kbd>subscribe()</kbd> (as shown in the following code), you will notice something very blatant:</p>
<pre style="padding-left: 60px"> import io.reactivex.Observable;<br/> import io.reactivex.schedulers.Schedulers;<br/><br/> public class Launcher {<br/><br/>     public static void main(String[] args) {<br/><br/>         Observable.range(1, 999_999_999)<br/>                 .map(MyItem::new)<br/>                 .observeOn(Schedulers.io())<br/>                 .subscribe(myItem -&gt; {<br/>                     sleep(50);<br/>                     System.out.println("Received MyItem " + myItem.id);<br/>                 });<br/><br/>         sleep(Long.MAX_VALUE);<br/>     }<br/><br/>     static void sleep(long milliseconds) {<br/>         try {<br/>             Thread.sleep(milliseconds);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/><br/>     static final class MyItem {<br/><br/>         final int id;<br/><br/>         MyItem(int id) {<br/>             this.id = id;<br/>             System.out.println("Constructing MyItem " + id);<br/>         }<br/>     }<br/> }</pre>
<p> The output is as follows:</p>
<pre style="padding-left: 60px"> ...<br/> Constructing MyItem 1001899<br/> Constructing MyItem 1001900<br/> Constructing MyItem 1001901<br/> Constructing MyItem 1001902<br/> Received MyItem 38<br/> Constructing MyItem 1001903<br/> Constructing MyItem 1001904<br/> Constructing MyItem 1001905<br/> Constructing MyItem 1001906<br/> Constructing MyItem 1001907<br/> ..</pre>
<p>This is just a section of my console output. Note that when <kbd>MyItem 1001902</kbd> is created, the <kbd>Observer</kbd> is still only processing <kbd>MyItem 38</kbd>. The emissions are being pushed much faster than the <kbd>Observer</kbd> can process them, and because backlogged emissions get queued by <kbd>observeOn()</kbd> in an unbounded manner, this could lead to many problems, including <kbd>OutOfMemoryError</kbd> exceptions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introducing the Flowable</h1>
                </header>
            
            <article>
                
<p>So how do we mitigate this? You could get hacky and try to use native Java concurrency tools such as semaphores. But thankfully, RxJava has a streamlined solution to this problem: the  <kbd>Flowable</kbd>. The <kbd>Flowable</kbd> is a backpressured variant of the <kbd>Observable</kbd> that tells the source to emit at a pace specified by the downstream operations.</p>
<p>In the following code, replace <kbd>Observable.range()</kbd> with <kbd>Flowable.range()</kbd>, and this will make this entire chain work with Flowables instead of Observables. Run the code and you will see a very different behavior with the output:</p>
<pre style="padding-left: 60px"> import io.reactivex.Observable;<br/> import io.reactivex.schedulers.Schedulers;<br/> import io.reactivex.Flowable;<br/><br/> public class Launcher {<br/><br/>     public static void main(String[] args) {<br/><br/>         Flowable.range(1, 999_999_999)<br/>                 .map(MyItem::new)<br/>                 .observeOn(Schedulers.io())<br/>                 .subscribe(myItem -&gt; {<br/>                     sleep(50);<br/>                     System.out.println("Received MyItem " + myItem.id);<br/>                 });<br/><br/>         sleep(Long.MAX_VALUE);<br/>     }<br/><br/>     static void sleep(long milliseconds) {<br/>         try {<br/>             Thread.sleep(milliseconds);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/><br/>     static final class MyItem {<br/><br/>         final int id;<br/><br/>         MyItem(int id) {<br/>             this.id = id;<br/>             System.out.println("Constructing MyItem " + id);<br/>         }<br/>     }<br/> }</pre>
<p><span> The output is as follows:</span></p>
<pre style="padding-left: 60px"> Constructing MyItem 1<br/> Constructing MyItem 2<br/> Constructing MyItem 3<br/> ...<br/> Constructing MyItem 127<br/> Constructing MyItem 128<br/> Received MyItem 1<br/> Received MyItem 2<br/> Received MyItem 3<br/> ...<br/> Received MyItem 95<br/> Received MyItem 96<br/> Constructing MyItem 129<br/> Constructing MyItem 130<br/> Constructing MyItem 131<br/> ...<br/> Constructing MyItem 223<br/> Constructing MyItem 224<br/> Received MyItem 97<br/> Received MyItem 98<br/> Received MyItem 99<br/> ...</pre>
<div class="packt_infobox">Note that Flowables do not subscribe with Observers but rather Subscribers, which we will dive into later.</div>
<p>You will notice something very different with the output when using <kbd>Flowable</kbd>. I omitted parts of the preceding output using <kbd>...</kbd> to highlight some key events. 128 emissions were immediately pushed from <kbd>Flowable.range()</kbd>, which constructed 128 <kbd>MyItem</kbd> instances. After that, <kbd>observeOn()</kbd> pushed 96 of them downstream to <kbd>Subscriber</kbd>. After these 96 emissions were processed by <kbd>Subscriber</kbd>, another 96 were pushed from the source. Then another 96 were passed to <kbd>Subscriber</kbd>.</p>
<p>Do you see a pattern yet? The source started by pushing 128 emissions, and after that, a steady flow of 96 emissions at a time was processed by the <kbd>Flowable</kbd> chain. It is almost like the entire <kbd>Flowable</kbd> chain strives to have no more than 96 emissions in its pipeline at any given time. Effectively, that is exactly what is happening! This is what we call <strong>backpressure</strong>, and it effectively introduces a pull dynamic to the push-based operation to limit how frequently the source emits.</p>
<p>But why did <kbd>Flowable.range()</kbd> start with 128 emissions, and why did <kbd>observeOn()</kbd> only send 96 downstream before requesting another 96, leaving 32 unprocessed emissions? The initial batch of emissions is a bit larger so some extra work is queued if there is any idle time. If (in theory) our <kbd>Flowable</kbd> operation started by requesting 96 emissions and continued to emit steadily at 96 emissions at a time, there would be moments where operations might wait idly for the next 96. Therefore, an extra rolling cache of 32 emissions is maintained to provide work during these idle moments, which can provide greater throughput. This is much like a warehouse holding a little extra inventory to supply orders while it waits for more from the factory.</p>
<p>What is great about Flowables and their operators is that they usually do all the work for you. You do not have to specify any backpressure policies or parameters unless you need to create your own Flowables from scratch or deal with sources (such as Observables) that do not implement backpressure. We will cover these cases in the rest of the chapter, and hopefully, you will not run into them often.</p>
<p>Otherwise, Flowable is just like an <kbd>Observable</kbd> with nearly all the operators we learned so far. You can convert from an <kbd>Observable</kbd> into a <kbd>Flowable</kbd> and vice-versa, which we will cover later. But first, let's cover when we should use Flowables instead of Observables.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">When to use Flowables and backpressure</h1>
                </header>
            
            <article>
                
<p>It is critical to know when to use <kbd>Flowable</kbd> versus <kbd>Observable</kbd>. Overall, the benefits offered from the <kbd>Flowable</kbd> are leaner usage of memory (preventing <kbd>OutOfMemoryError</kbd> exceptions) as well as prevention of <kbd>MissingBackpressureException</kbd>. The latter can occur if operations backpressure against a source but the source has no backpressure protocol in its implementation. However, the disadvantage of Flowable is that it adds overhead and may not perform as quickly as an <kbd>Observable</kbd>.</p>
<p>Here are a few guidelines to help you choose between an <kbd>Observable</kbd> versus a <kbd>Flowable</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Use an Observable If...</h1>
                </header>
            
            <article>
                
<ul>
<li>You expect few emissions over the life of the <kbd>Observable</kbd> subscription (less than 1000) or the emissions are intermittent and far apart. If you expect only a trickle of emissions coming from a source, an <kbd>Observable</kbd> will do the job just fine and have less overhead. But when you are dealing with large amounts of data and performing complex operations on them, you will likely want to use a <kbd>Flowable</kbd>.</li>
<li>Your operation is strictly synchronous and has limited usage of concurrency. This includes simple usage of <kbd>subscribeOn()</kbd> at the start of an <kbd>Observable</kbd> chain because the process is still operating on a single thread and emitting items synchronously downstream. However, when you start zipping and combining different streams on different threads, parallelize, or use operators such as <kbd>observeOn()</kbd>, <kbd>interval()</kbd>, and <kbd>delay()</kbd>, your application is no longer synchronous and you might be better-off using a <kbd>Flowable</kbd>.</li>
<li>You want to emit user interface events such as button clicks, <kbd>ListView</kbd> selections, or other user inputs on Android, JavaFX, or Swing. Since users cannot programmatically be told to slow down, there is rarely any opportunity using a <kbd>Flowable</kbd>. To cope with rapid user inputs, you are likely better-off using the operators discussed in <a href="964f5943-b955-49f7-b53e-801754d06c3c.xhtml">Chapter 7</a>, <em>Switching, Throttling, Windowing, and Buffering</em>.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Use a Flowable If...</h1>
                </header>
            
            <article>
                
<ul>
<li>You are dealing with over 10,000 elements and there is opportunity for the source to generate emissions in a regulated manner. This is especially true when the source is asynchronous and pushes large amounts of data.</li>
<li>You want to emit from IO operations that support blocking while returning results, which is how many IO sources work. Data sources that iterate records, such as lines from files or a <kbd>ResultSet</kbd> in JDBC, are especially easy to control because iteration can pause and resume as needed. Network and Streaming APIs that can request a certain amount of returned results can easily be backpressured as well.</li>
</ul>
<p>Note in RxJava 1.0, the <kbd>Observable</kbd> was backpressured and was essentially what the <kbd>Flowable</kbd> is in RxJava 2.0. The reason the <kbd>Flowable</kbd> and <kbd>Observable</kbd> became separate types is due to the merits of both for different situations, as described precedingly.</p>
<p>You will find that you can easily interoperate Observables and Flowables together. But you need to be careful and aware of the context they are being used in and where undesired bottlenecks can occur.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding the Flowable and Subscriber</h1>
                </header>
            
            <article>
                
<p>Pretty much all the <kbd>Observable</kbd> factories and operators you learned up to this point also apply to Flowable. On the factory side, there is <kbd>Flowable.range()</kbd>, <kbd>Flowable.just()</kbd>, <kbd>Flowable.fromIterable()</kbd>, and <kbd>Flowable.interval()</kbd>. Most of these implement backpressure for you, and usage is generally the same as the <kbd>Observable</kbd> equivalent.</p>
<p>However, consider <kbd>Flowable.interval()</kbd>, which pushes time-based emissions at fixed time intervals. Can this be backpressured logically? Contemplate the fact that each emission is sensitively tied to the time it emits. If we slowed down <kbd>Flowable.interval()</kbd>, our emissions would no longer reflect time intervals and become misleading. Therefore, <kbd>Flowable.interval()</kbd> is one of those few cases in the standard API that can throw <kbd>MissingBackpressureException</kbd> the moment downstream requests backpressure. Here, if we emit every millisecond against a slow <kbd>intenseCalculation()</kbd> that occurs after <kbd>observeOn()</kbd>, we will get this error:</p>
<pre style="padding-left: 60px"> import io.reactivex.Flowable;<br/> import io.reactivex.schedulers.Schedulers;<br/> import java.util.concurrent.ThreadLocalRandom;<br/> import java.util.concurrent.TimeUnit;<br/> public class Launcher {<br/>    public static void main(String[] args) {<br/>         Flowable.interval(1, TimeUnit.MILLISECONDS)<br/>                 .observeOn(Schedulers.io())<br/>                 .map(i -&gt; intenseCalculation(i))<br/>                 .subscribe(System.out::println, Throwable::printStackTrace);<br/>        sleep(Long.MAX_VALUE);<br/>     }<br/>    public static &lt;T&gt; T intenseCalculation(T value) {<br/>         sleep(ThreadLocalRandom.current().nextInt(3000));<br/>         return value;<br/>     }<br/>     public static void sleep(long millis) {<br/>         try {<br/>             Thread.sleep(millis);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/> }</pre>
<p>The output is as follows:</p>
<pre style="padding-left: 60px">0<br/>io.reactivex.exceptions.MissingBackpressureException: Cant deliver value 128 due to lack of requests<br/>    at io.reactivex.internal.operators.flowable.FlowableInterval<br/>  ...</pre>
<p>To overcome this issue, you can use operators such as <kbd>onBackpresureDrop()</kbd> or <kbd>onBackPressureBuffer()</kbd>, which we will learn about later in this chapter. <kbd>Flowable.interval()</kbd> is one of those factories that logically cannot be backpressured at the source, so you can use operators after it to handle backpressure for you. Otherwise, most of the other <kbd>Flowable</kbd> factories you work with support backpressure. Later, we need to call out how to create our own <kbd>Flowable</kbd> sources that conform to backpressure, and we will discuss this shortly. But first, we will explore the Subscriber a bit more.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Subscriber</h1>
                </header>
            
            <article>
                
<p>Instead of an <kbd>Observer</kbd>, the <kbd>Flowable</kbd> uses a <kbd>Subscriber</kbd> to consume emissions and events at the end of a <kbd>Flowable</kbd> chain. If you pass only lambda event arguments (and not an entire <kbd>Subscriber</kbd> object), <kbd>subscribe()</kbd> does not return a <kbd>Disposable</kbd> but rather a <kbd>Subscription</kbd>, which can be disposed of by calling <kbd>cancel()</kbd> instead of <kbd>dispose()</kbd>. The <kbd>Subscription</kbd> can also serve another purpose; it communicates upstream how many items are wanted using its <kbd>request()</kbd> method. <kbd>Subscription</kbd> can also be leveraged in the <kbd>onSubscribe()</kbd> method of <kbd>Subscriber</kbd> to <kbd>request()</kbd> elements the moment it is ready to receive emissions.</p>
<p>Just like an <kbd>Observer</kbd>, the quickest way to create a <kbd>Subscriber</kbd> is to pass lambda arguments to <kbd>subscribe()</kbd>, as we have been doing earlier (and shown again in the following code). This default implementation of <kbd>Subscriber</kbd> will request an unbounded number of emissions upstream, but any operators preceding it will still automatically handle backpressure:</p>
<pre style="padding-left: 60px"> import io.reactivex.Flowable;<br/> import io.reactivex.schedulers.Schedulers;<br/> import java.util.concurrent.ThreadLocalRandom;<br/>public class Launcher {<br/>    public static void main(String[] args) {<br/>       Flowable.range(1,1000)<br/>                .doOnNext(s -&gt; System.out.println("Source pushed " + s))<br/>                .observeOn(Schedulers.io())<br/>                .map(i -&gt; intenseCalculation(i))<br/>                .subscribe(s -&gt; System.out.println("Subscriber received " + s),<br/>                        Throwable::printStackTrace,<br/>                        () -&gt; System.out.println("Done!")<br/>                );<br/>        sleep(20000);<br/>     }<br/>     public static &lt;T&gt; T intenseCalculation(T value) {<br/>         <em>//sleep up to 200 milliseconds</em><br/>         sleep(ThreadLocalRandom.current().nextInt(200));<br/>         return value;<br/>     }<br/>    public static void sleep(long millis) {<br/>         try {<br/>             Thread.sleep(millis);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/> }</pre>
<p>Of course, you can implement your own <kbd>Subscriber</kbd> as well, which, of course, has the <kbd>onNext()</kbd>, <kbd>onError()</kbd>, and <kbd>onComplete()</kbd> methods as well as <kbd>onSubscribe()</kbd>. This is not as straightforward as implementing an <kbd>Observer</kbd> because you need to call <kbd>request()</kbd> on <kbd>Subscription</kbd> to request emissions at the right moments.</p>
<p>The quickest and easiest way to implement a <kbd>Subscriber</kbd> is to have the <kbd>onSubscribe()</kbd> method call <kbd>request(Long.MAX_VALUE)</kbd> on <kbd>Subscription</kbd>, which essentially tells the upstream "give me everything now". Even though the operators preceding <kbd>Subscriber</kbd> will request emissions at their own backpressured pace, no backpressure will exist between the last operator and the <kbd>Subscriber</kbd>. This is usually fine since the upstream operators will constrain the flow anyway.</p>
<p>Here, we reimplement our previous example but implement our own <kbd>Subscriber</kbd>:</p>
<pre style="padding-left: 60px"> import io.reactivex.Flowable;<br/> import io.reactivex.schedulers.Schedulers;<br/> import org.reactivestreams.Subscriber;<br/> import org.reactivestreams.Subscription;<br/> import java.util.concurrent.ThreadLocalRandom;<br/> public class Launcher {<br/>    public static void main(String[] args) {<br/>       Flowable.range(1,1000)<br/>                .doOnNext(s -&gt; System.out.println("Source pushed " + s))<br/>                .observeOn(Schedulers.io())<br/>                .map(i -&gt; intenseCalculation(i))<br/>                .subscribe(new Subscriber&lt;Integer&gt;() {<br/>                    @Override<br/>                    public void onSubscribe(Subscription subscription) {<br/>                        subscription.request(Long.MAX_VALUE);<br/>                    }<br/>                   @Override<br/>                    public void onNext(Integer s) {<br/>                        sleep(50);<br/>                        System.out.println("Subscriber received " + s);<br/>                    }<br/>                   @Override<br/>                    public void onError(Throwable e) {<br/>                        e.printStackTrace();<br/>                    }<br/>                   @Override<br/>                    public void onComplete() {<br/>                        System.out.println("Done!");<br/>                    }<br/>                });<br/>        sleep(20000);<br/>     }<br/>     public static &lt;T&gt; T intenseCalculation(T value) {<br/>         <em>//sleep up to 200 milliseconds</em><br/>         sleep(ThreadLocalRandom.current().nextInt(200));<br/>         return value;<br/>     }<br/>    public static void sleep(long millis) {<br/>         try {<br/>             Thread.sleep(millis);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/> }</pre>
<p>If you want your <kbd>Subscriber</kbd> to establish an explicit backpressured relationship with the operator preceding it, you will need to micromanage the <kbd>request()</kbd> calls. Say, for some extreme situation, you decide that you want <kbd>Subscriber</kbd> to request 40 emissions initially and then 20 emissions at a time after that. This is what you would need to do:</p>
<pre style="padding-left: 60px"> import io.reactivex.Flowable;<br/> import io.reactivex.schedulers.Schedulers;<br/> import org.reactivestreams.Subscriber;<br/> import org.reactivestreams.Subscription;<br/> import java.util.concurrent.ThreadLocalRandom;<br/> import java.util.concurrent.atomic.AtomicInteger;<br/>public class Launcher {<br/>    public static void main(String[] args) {<br/>       Flowable.range(1,1000)<br/>                .doOnNext(s -&gt; System.out.println("Source pushed " + s))<br/>                .observeOn(Schedulers.io())<br/>                .map(i -&gt; intenseCalculation(i))<br/>                .subscribe(new Subscriber&lt;Integer&gt;() {<br/>                   Subscription subscription;<br/>                    AtomicInteger count = new AtomicInteger(0);<br/>                   @Override<br/>                    public void onSubscribe(Subscription subscription) {<br/>                        this.subscription = subscription;<br/>                        System.out.println("Requesting 40 items!");<br/>                        subscription.request(40);<br/>                    }<br/>                   @Override<br/>                    public void onNext(Integer s) {<br/>                        sleep(50);<br/>                        System.out.println("Subscriber received " + s);<br/>                       if (count.incrementAndGet() % 20 == 0 &amp;&amp; count.get() &gt;= 40)<br/>                            System.out.println("Requesting 20 more!");<br/>                            subscription.request(20);<br/>                    }<br/>                   @Override<br/>                    public void onError(Throwable e) {<br/>                        e.printStackTrace();<br/>                    }<br/>                   @Override<br/>                    public void onComplete() {<br/>                        System.out.println("Done!");<br/>                    }<br/>                });<br/>        sleep(20000);<br/>     }<br/>     public static &lt;T&gt; T intenseCalculation(T value) {<br/>         //sleep up to 200 milliseconds<br/>         sleep(ThreadLocalRandom.current().nextInt(200));<br/>         return value;<br/>     }<br/>    public static void sleep(long millis) {<br/>         try {<br/>             Thread.sleep(millis);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/> }</pre>
<p><span>The output is as follows:</span></p>
<pre style="padding-left: 60px"> Requesting 40 items!<br/> Source pushed 1<br/> Source pushed 2<br/> ...<br/> Source pushed 127<br/> Source pushed 128<br/> Subscriber received 1<br/> Subscriber received 2<br/> ...<br/> Subscriber received 39<br/> Subscriber received 40<br/> Requesting 20 more!<br/> Subscriber received 41<br/> Subscriber received 42<br/> ...<br/> Subscriber received 59<br/> Subscriber received 60<br/> Requesting 20 more!<br/> Subscriber received 61<br/> Subscriber received 62<br/> ...<br/> Subscriber received 79<br/> Subscriber received 80<br/> Requesting 20 more!<br/> Subscriber received 81<br/> Subscriber received 82<br/> ...</pre>
<p>Note that the source is still emitting 128 emissions initially and then still pushes 96 emissions at a time. But our <kbd>Subscriber</kbd> received only 40 emissions, as specified, and then consistently calls for 20 more. The <kbd>request()</kbd> calls in our <kbd>Subscriber</kbd> only communicate to the immediate operator upstream to it, which is <kbd>map()</kbd>. The <kbd>map()</kbd> operator likely relays that request to <kbd>observeOn()</kbd>, which is caching items and only flushing out 40 and then 20, as requested by the <kbd>Subscriber</kbd>. When its cache gets low or clears out, it will request another 96 from the upstream.</p>
<div class="packt_tip">This is a warning: you should not rely on these exact numbers of requested emissions, such as 128 and 96. These are an internal implementation we happen to observe, and these numbers may be changed to aid further implementation optimizations in the future.</div>
<p>This custom implementation may actually be reducing our throughput, but it demonstrates how to manage custom backpressure with your own <kbd>Subscriber</kbd> implementation. Just keep in mind that the <kbd>request()</kbd> calls do not go all the way upstream. They only go to the preceding operator, which decides how to relay that request upstream.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a Flowable</h1>
                </header>
            
            <article>
                
<p>Earlier in this book, we used <kbd>Observable.create()</kbd> a handful of times to create our own <kbd>Observable</kbd> from scratch, which describes how to emit items when it is subscribed to, as shown in the following code snippet:</p>
<pre style="padding-left: 60px">import io.reactivex.Observable;<br/>import io.reactivex.schedulers.Schedulers;<br/>public class Launcher {<br/>    public static void main(String[] args) {<br/>        Observable&lt;Integer&gt; source = Observable.create(emitter -&gt; {<br/>             for (int i=0; i&lt;=1000; i++) {<br/>                 if (emitter.isDisposed())<br/>                     return;<br/>                emitter.onNext(i);<br/>             }<br/>            emitter.onComplete();<br/>         });<br/>        source.observeOn(Schedulers.io())<br/>                 .subscribe(System.out::println);<br/>        sleep(1000);<br/>     }<br/> }</pre>
<p><span>The output is as follows:</span></p>
<pre style="padding-left: 60px"> 0<br/> 1<br/> 2<br/> 3<br/> 4<br/> ...</pre>
<p>This <kbd>Observable.create()</kbd>will emit the integers 0 to 1000 and then call <kbd>onComplete()</kbd>. It can be stopped abruptly if <kbd>dispose()</kbd> is called on the <kbd>Disposable</kbd> returned from <kbd>subscribe()</kbd>, and the for-loop will check for this.</p>
<p>However, think for a moment how something like this can be backpressured if we execute <kbd>Flowable.create()</kbd>, the <kbd>Flowable</kbd> equivalent of <kbd>Observable.create()</kbd>. Using a simple for-loop like the preceding one, there is no notion of emissions <em>stopping</em> and <em>resuming</em> based on the requests of a downstream <kbd>Subscriber</kbd>. Doing backpressure properly is going to add some complexity. There are simpler ways to support backpressure, but they often involve compromised strategies such as buffering and dropping, which we will cover first. There are also a few utilities to implement backpressure at the source, which we will cover afterward.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using Flowable.create() and BackpressureStrategy</h1>
                </header>
            
            <article>
                
<p>Leveraging <kbd>Flowable.create()</kbd> to create a <kbd>Flowable</kbd> feels much like <kbd>Observable.create()</kbd>, but there is one critical difference; you must specify a <kbd>BackpressureStrategy</kbd> as a second argument. This enumerable type does not by any means provide magic implementations of backpressure support. As a matter of fact, this simply supports backpressure by caching or dropping emissions or not implementing backpressure at all.</p>
<p>Here, we use <kbd>Flowable.create()</kbd> to create a <kbd>Flowable</kbd>, but we provide a second <kbd>BackpressureStrategy.BUFFER</kbd> argument to buffer the emissions before they are backpressured:</p>
<pre style="padding-left: 60px"> import io.reactivex.BackpressureStrategy;<br/> import io.reactivex.Flowable;<br/> import io.reactivex.schedulers.Schedulers;<br/>public class Launcher {<br/>    public static void main(String[] args) {<br/>        Flowable&lt;Integer&gt; source = Flowable.create(emitter -&gt; {<br/>             for (int i=0; i&lt;=1000; i++) {<br/>                 if (emitter.isCancelled())<br/>                     return;<br/>                emitter.onNext(i);<br/>             }<br/>            emitter.onComplete();<br/>         }, BackpressureStrategy.BUFFER);<br/>        source.observeOn(Schedulers.io())<br/>                 .subscribe(System.out::println);<br/>        sleep(1000);<br/>     }<br/>    public static void sleep(long millis) {<br/>         try {<br/>             Thread.sleep(millis);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/> }</pre>
<p><span>The output is as follows:</span></p>
<pre style="padding-left: 60px"> 0<br/> 1<br/> 2<br/> 3<br/> 4<br/> ...</pre>
<p>This is not optimal because the emissions will be held in an unbounded queue, and it is possible that when <kbd>Flowable.create()</kbd> pushes too many emissions, you will get an <kbd>OutOfMemoryError</kbd>. But at least it prevents <kbd>MissingBackpressureException</kbd> and can make your custom <kbd>Flowable</kbd> workable to a small degree. We will learn about a more robust way to implement backpressure later in this chapter using <kbd>Flowable.generate()</kbd>.</p>
<p>There are currently five <kbd>BackpressureStrategy</kbd> options you can choose from.</p>
<table>
<tbody>
<tr>
<td><strong>BackpressureStrategy</strong></td>
<td><strong>Description</strong></td>
</tr>
<tr>
<td>MISSING</td>
<td>Essentially results in no backpressure implementation at all. The downstream must deal with backpressure overflow, which can be helpful when used with <kbd>onBackpressureXXX()</kbd> operators, which we will cover later in this chapter.</td>
</tr>
<tr>
<td>ERROR</td>
<td>Signals a <kbd>MissingBackpressureException</kbd> the moment the downstream cannot keep up with the source.</td>
</tr>
<tr>
<td>BUFFER</td>
<td>Queues up emissions in an unbounded queue until the downstream is able to consume them, but can cause an <kbd>OutOfMemoryError</kbd> if the queue gets too large.</td>
</tr>
<tr>
<td>DROP</td>
<td>If the downstream cannot keep up, this will ignore upstream emissions and not queue anything while the downstream is busy.</td>
</tr>
<tr>
<td>LATEST</td>
<td>This will keep only the latest emission until the downstream is ready to receive it.</td>
</tr>
</tbody>
</table>
<p>Next, we will see some of these strategies used as operators, particularly converting Observables into Flowables.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Turning an Observable into a Flowable (and vice-versa)</h1>
                </header>
            
            <article>
                
<p>There is another way that you can implement <kbd>BackpressureStrategy</kbd> against a source that has no notion of backpressure. You can turn an Observable into <kbd>Flowable</kbd> easily by calling its <kbd>toFlowable()</kbd> operator, which accepts a <kbd>BackpressureStrategy</kbd> as an argument. In the following code, we turn <kbd>Observable.range()</kbd> into <kbd>Flowable</kbd> using <kbd>BackpressureStrategy.BUFFER</kbd>. The Observable has no notion of backpressure, so it is going to push items as quickly as it can regardless if the downstream can keep up. But <kbd>toFlowable()</kbd>, with a buffering strategy, will act as a proxy to backlog the emissions when the downstream cannot keep up:</p>
<pre style="padding-left: 60px"> import io.reactivex.BackpressureStrategy;<br/> import io.reactivex.Observable;<br/> import io.reactivex.schedulers.Schedulers;<br/>public class Launcher {<br/>    public static void main(String[] args) {<br/>        Observable&lt;Integer&gt; source = Observable.range(1,1000);<br/>        source.toFlowable(BackpressureStrategy.BUFFER)<br/>                 .observeOn(Schedulers.io())<br/>                 .subscribe(System.out::println);<br/>        sleep(10000);<br/>     }<br/>    public static void sleep(long millis) {<br/>         try {<br/>             Thread.sleep(millis);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/> }</pre>
<div class="packt_infobox">Again, note that <kbd>toFlowable()</kbd>, with a buffering strategy, is going to have an unbounded queue, which can cause an <kbd>OutOfMemoryError</kbd>. In the real world, it would be better to use <kbd>Flowable.range()</kbd> in the first place, but sometimes, you may only be provided with an <kbd>Observable</kbd>.</div>
<p>The <kbd>Flowable</kbd> also has a <kbd>toObservable()</kbd> operator, which will turn a <kbd>Flowable&lt;T&gt;</kbd> into an <kbd>Observable&lt;T&gt;</kbd>. This can be helpful in making a <kbd>Flowable</kbd> usable in an <kbd>Observable</kbd> chain, especially with operators such as <kbd>flatMap()</kbd>, as shown in the following code:</p>
<pre style="padding-left: 60px"> import io.reactivex.Flowable;<br/> import io.reactivex.Observable;<br/> import io.reactivex.schedulers.Schedulers;<br/>public class Launcher {<br/>    public static void main(String[] args) {<br/>        Flowable&lt;Integer&gt; integers =<br/>                 Flowable.range(1, 1000)<br/>                         .subscribeOn(Schedulers.computation());<br/>        Observable.just("Alpha","Beta","Gamma","Delta","Epsilon")<br/>                 .flatMap(s -&gt; integers.map(i -&gt; i + "-" + s).toObservable())<br/>                 .subscribe(System.out::println);<br/>        sleep(5000);<br/>     }<br/>    public static void sleep(long millis) {<br/>         try {<br/>             Thread.sleep(millis);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/> }</pre>
<p>If <kbd>Observable&lt;String&gt;</kbd> had much more than five emissions (such as 1,000 or 10,000), then it would probably be better to turn that into a <kbd>Flowable</kbd> instead of turning the flat-mapped <kbd>Flowable</kbd> into an <kbd>Observable</kbd>.</p>
<p>Even if you call <kbd>toObservable()</kbd>, the <kbd>Flowable</kbd> will still leverage backpressure upstream. But at the point it becomes an <kbd>Observable</kbd>, the downstream will no longer be backpressured and will request a <kbd>Long.MAX_VALUE</kbd> number of emissions. This may be fine as long as no more intensive operations or concurrency changes happen downstream and the <kbd>Flowable</kbd> operations upstream constrains the number of emissions.</p>
<p>But typically, when you commit to using a <kbd>Flowable</kbd>, you should strive to make your operations remain <kbd>Flowable</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using onBackpressureXXX() operators</h1>
                </header>
            
            <article>
                
<p>If you are provided a <kbd>Flowable</kbd> that has no backpressure implementation (including ones derived from <kbd>Observable</kbd>), you can apply <kbd>BackpressureStrategy</kbd> using <kbd>onBackpressureXXX()</kbd> operators. These also provide a few additional configuration options. This can be helpful if, for example, you have a <kbd>Flowable.interval()</kbd> that emits faster than consumers can keep up. <kbd>Flowable.interval()</kbd> cannot be slowed down at the source because it is time-driven, but we can use an <kbd>onBackpressureXXX()</kbd> operator to proxy between it and the downstream. We will use <kbd>Flowable.interval()</kbd> for these examples, but this can apply to any <kbd>Flowable</kbd> that does not have backpressure implemented.</p>
<p> </p>
<p>Sometimes, <kbd>Flowable</kbd> may simply be configured with <kbd>BackpressureStrategy.MISSING</kbd> so these <kbd>onBackpressureXXX()</kbd> operators can specify the strategy later.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">onBackPressureBuffer()</h1>
                </header>
            
            <article>
                
<p> </p>
<p>The <kbd>onBackPressureBuffer()</kbd>will take an existing <kbd>Flowable</kbd> that is assumed to not have backpressure implemented and then essentially apply <kbd>BackpressureStrategy.BUFFER</kbd> at that point to the downstream. Since <kbd>Flowable.interval()</kbd> cannot be backpressured at the source, putting <kbd>onBackPressureBuffer()</kbd> after it will proxy a backpressured queue to the downstream:</p>
<pre style="padding-left: 60px">import io.reactivex.Flowable;<br/> import io.reactivex.schedulers.Schedulers;<br/> import java.util.concurrent.TimeUnit;<br/>public class Launcher {<br/>    public static void main(String[] args) {<br/>        Flowable.interval(1, TimeUnit.MILLISECONDS)<br/>                 .onBackpressureBuffer()<br/>                 .observeOn(Schedulers.io())<br/>                 .subscribe(i -&gt; {<br/>                     sleep(5);<br/>                     System.out.println(i);<br/>                 });<br/>        sleep(5000);<br/>     }<br/>    public static void sleep(long millis) {<br/>         try {<br/>             Thread.sleep(millis);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/> }</pre>
<p>The output is as follows:</p>
<pre style="padding-left: 60px"> 0<br/> 1<br/> 2<br/> 3<br/> 4<br/> 5<br/> 6<br/> 7<br/> ...</pre>
<p>There are a number of overload arguments that you can provide as well. We will not get into all of them, and you can refer to the JavaDocs for more information, but we will highlight the common ones. The capacity argument will create a maximum threshold for the buffer rather than allowing it to be unbounded. An <kbd>onOverflow</kbd> <kbd>Action</kbd> lambda can be specified to fire an action when an overflow exceeds the capacity. You can also specify a <kbd>BackpressureOverflowStrategy</kbd> enum to instruct how to handle an overflow that exceeds the capacity.</p>
<p>Here are the three <kbd>BackpressureOverflowStrategy</kbd> enum items that you can choose from:</p>
<table>
<tbody>
<tr>
<td><strong>BackpressureOverflowStrategy</strong></td>
<td><strong>Description</strong></td>
</tr>
<tr>
<td>ERROR</td>
<td>Simply throws an error the moment capacity is exceeded</td>
</tr>
<tr>
<td>DROP_OLDEST</td>
<td>Drops the oldest value from the buffer to make way for a new one</td>
</tr>
<tr>
<td>DROP_LATEST</td>
<td>Drops the latest value from the buffer to prioritize older, unconsumed values</td>
</tr>
</tbody>
</table>
<p>In the following code, we hold a maximum capacity of 10 and specify to use <kbd>BackpressureOverflowStrategy.DROP_LATEST</kbd> in the event of an overflow. We also will print a notification in the event of an overflow:</p>
<pre style="padding-left: 60px">import io.reactivex.BackpressureOverflowStrategy;<br/> import io.reactivex.Flowable;<br/> import io.reactivex.schedulers.Schedulers;<br/> import java.util.concurrent.TimeUnit;<br/>public class Launcher {<br/>    public static void main(String[] args) {<br/>        Flowable.interval(1, TimeUnit.MILLISECONDS)<br/>                 .onBackpressureBuffer(10,<br/>                         () -&gt; System.out.println("overflow!"),<br/>                         BackpressureOverflowStrategy.DROP_LATEST)<br/>                 .observeOn(Schedulers.io())<br/>                 .subscribe(i -&gt; {<br/>                     sleep(5);<br/>                     System.out.println(i);<br/>                 });<br/>        sleep(5000);<br/>     }<br/>    public static void sleep(long millis) {<br/>         try {<br/>             Thread.sleep(millis);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/> }</pre>
<p><span>The output is as follows:</span></p>
<pre style="padding-left: 60px"> ...<br/> overflow!<br/> overflow!<br/> 135<br/> overflow!<br/> overflow!<br/> overflow!<br/> overflow!<br/> overflow!<br/> 136<br/> overflow!<br/> overflow!<br/> overflow!<br/> overflow!<br/> overflow!<br/> 492<br/> overflow!<br/> overflow!<br/> overflow!<br/> ...</pre>
<p>Note that in this part of my noisy output, there was a large range of numbers skipped between <kbd>136</kbd> and <kbd>492</kbd>. This is because these emissions were dropped from the queue due to <kbd>BackpressureOverflowStrategy.DROP_LATEST</kbd>. The queue was already filled with emissions waiting to be consumed, so the new emissions were ignored.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">onBackPressureLatest()</h1>
                </header>
            
            <article>
                
<p>A slight variant of <kbd>onBackpressureBuffer()</kbd> is <kbd>onBackPressureLatest()</kbd>. This will retain the latest value from the source while the downstream is busy, and once the downstream is free to process more, it will provide the latest value. Any previous values emitted during this busy period will be lost:</p>
<pre style="padding-left: 60px">import io.reactivex.Flowable;<br/> import io.reactivex.schedulers.Schedulers;<br/>import java.util.concurrent.TimeUnit;<br/>public class Launcher {<br/>    public static void main(String[] args) {<br/>        Flowable.interval(1, TimeUnit.MILLISECONDS)<br/>                 .onBackpressureLatest()<br/>                 .observeOn(Schedulers.io())<br/>                 .subscribe(i -&gt; {<br/>                     sleep(5);<br/>                     System.out.println(i);<br/>                 });<br/>        sleep(5000);<br/>     }<br/>    public static void sleep(long millis) {<br/>         try {<br/>             Thread.sleep(millis);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/> }</pre>
<p><span>The output is as follows:</span></p>
<pre style="padding-left: 60px"> ...<br/> 122<br/> 123<br/> 124<br/> 125<br/> 126<br/> 127<br/> 494<br/> 495<br/> 496<br/> 497<br/> ...</pre>
<p>If you study my output, you will notice that there is a jump between <kbd>127</kbd> and <kbd>494</kbd>. This is because all numbers in between were ultimately beaten by <kbd>494</kbd> being the latest value, and at that time, the downstream was ready to process more emissions. It started by consuming the cached <kbd>494</kbd> and the others before it was dropped.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">onBackPressureDrop()</h1>
                </header>
            
            <article>
                
<p>The <kbd>onBackpressureDrop()</kbd>will simply discard emissions if the downstream is too busy to process them. This is helpful when emissions are considered redundant if the downstream is already occupied (such as a "<kbd>RUN</kbd>" request being sent repeatedly, although the resulting process is already running). You can optionally provide an <kbd>onDrop</kbd> lambda argument specifying what to do with each dropped item, which we will simply print, as shown in the following code:</p>
<pre style="padding-left: 60px">import io.reactivex.Flowable;<br/> import io.reactivex.schedulers.Schedulers;<br/> import java.util.concurrent.TimeUnit;<br/>public class Launcher {<br/>    public static void main(String[] args) {<br/>        Flowable.interval(1, TimeUnit.MILLISECONDS)<br/>                 .onBackpressureDrop(i -&gt; System.out.println("Dropping " + i))<br/>                 .observeOn(Schedulers.io())<br/>                 .subscribe(i -&gt; {<br/>                     sleep(5);<br/>                     System.out.println(i);<br/>                 });<br/>        sleep(5000);<br/>     }<br/>    public static void sleep(long millis) {<br/>         try {<br/>             Thread.sleep(millis);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/> }</pre>
<p><span>The output is as follows:</span></p>
<pre style="padding-left: 60px"> ...<br/> Dropping 653<br/> Dropping 654<br/> Dropping 655<br/> Dropping 656<br/> 127<br/> Dropping 657<br/> Dropping 658<br/> Dropping 659<br/> Dropping 660<br/> Dropping 661<br/> 493<br/> Dropping 662<br/> Dropping 663<br/> Dropping 664<br/> ...</pre>
<p>In my output, note that there is a large jump between <kbd>127</kbd> and <kbd>493</kbd>. The numbers between them were dropped because the downstream was already busy when they were ready to be processed, so they were discarded rather than queued.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using Flowable.generate()</h1>
                </header>
            
            <article>
                
<p>A lot of the content we covered so far in this chapter did not show the optimal approaches to backpressure a source. Yes, using a <kbd>Flowable</kbd> and most of the standard factories and operators will automatically handle backpressure for you. However, if you are creating your own custom sources, <kbd>Flowable.create()</kbd> or the <kbd>onBackPressureXXX()</kbd> operators are somewhat compromised in how they handle backpressure requests. While quick and effective for some cases, caching emissions or simply dropping them is not always desirable. It would be better to make the source backpressured in the first place.</p>
<p>Thankfully, <kbd>Flowable.generate()</kbd> exists to help create backpressure, respecting sources at a nicely abstracted level. It will accept a <kbd>Consumer&lt;Emitter&lt;T&gt;&gt;</kbd> much like <kbd>Flowable.create()</kbd>, but it will use a lambda to specify what <kbd>onNext()</kbd>, <kbd>onComplete()</kbd>, and <kbd>onError()</kbd> events to pass each time an item is requested from the upstream.</p>
<p>Before you use <kbd>Flowable.generate()</kbd>, consider making your source <kbd>Iterable&lt;T&gt;</kbd> instead and passing it to <kbd>Flowable.fromIterable()</kbd>. The <kbd>Flowable.fromIterable()</kbd>will respect backpressure and might be easier to use for many cases. Otherwise, <kbd>Flowable.generate()</kbd> is your next best option if you need something more specific.</p>
<p>The simplest overload for <kbd>Flowable.generate()</kbd> accepts just <kbd>Consumer&lt;Emitter&lt;T&gt;&gt;</kbd> and assumes that there is no state maintained between emissions. This can be helpful in creating a backpressure-aware random integer generator, as displayed here. Note that 128 emissions are immediately emitted, but after that, 96 are pushed downstream before another 96 are sent from the source:</p>
<pre style="padding-left: 60px">import io.reactivex.Flowable;<br/> import io.reactivex.schedulers.Schedulers;<br/> import java.util.concurrent.ThreadLocalRandom;<br/>public class Launcher {<br/>    public static void main(String[] args) {<br/>        randomGenerator(1,10000)<br/>                 .subscribeOn(Schedulers.computation())<br/>                 .doOnNext(i -&gt; System.out.println("Emitting " + i))<br/>                 .observeOn(Schedulers.io())<br/>                 .subscribe(i -&gt; {<br/>                     sleep(50);<br/>                     System.out.println("Received " + i);<br/>                 });<br/>        sleep(10000);<br/>     }<br/>    static Flowable&lt;Integer&gt; randomGenerator(int min, int max) {<br/>         return Flowable.generate(emitter -&gt;<br/>                 emitter.onNext(ThreadLocalRandom.current().nextInt(min, max))<br/>         );<br/>     }<br/>    public static void sleep(long millis) {<br/>         try {<br/>             Thread.sleep(millis);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/> }</pre>
<p><span>The output is as follows:</span></p>
<pre style="padding-left: 60px"> ...<br/> Emitting 8014<br/> Emitting 3112<br/> Emitting 5958<br/> Emitting 4834 //128th emission<br/> Received 9563<br/> Received 4359<br/> Received 9362<br/> ...<br/> Received 4880<br/> Received 3192<br/> Received 979 //96th emission<br/> Emitting 8268<br/> Emitting 3889<br/> Emitting 2595<br/>...</pre>
<p>With <kbd>Flowable.generate()</kbd>, invoking multiple <kbd>onNext()</kbd> operators within <kbd>Consumer&lt;Emitter&lt;T&gt;&gt;</kbd> will result in <kbd>IllegalStateException</kbd>. The downstream needs it only to invoke <kbd>onNext()</kbd> once, so it can make the repeated calls, as required, to maintain flow. It will also emit <kbd>onError()</kbd> for you in the event that an exception occurs.</p>
<p>You can also provide a state that can act somewhat like a "seed" similar to <kbd>reduce()</kbd> and maintain a state that is passed from one emission to the next. Suppose we want to create something similar to <kbd>Flowable.range()</kbd> but instead, we want to emit the integers in reverse between <kbd>upperBound</kbd> and <kbd>lowerBound</kbd>. Using <kbd>AtomicInteger</kbd> as our state, we can decrement it and pass its value to the emitter's <kbd>onNext()</kbd> operator until <kbd>lowerBound</kbd> is encountered. This is demonstrated as follows:</p>
<pre style="padding-left: 60px">import io.reactivex.Flowable;<br/> import io.reactivex.schedulers.Schedulers;<br/> import java.util.concurrent.atomic.AtomicInteger;<br/>public class Launcher {<br/>    public static void main(String[] args) {<br/>        rangeReverse(100,-100)<br/>                 .subscribeOn(Schedulers.computation())<br/>                 .doOnNext(i -&gt; System.out.println("Emitting " + i))<br/>                 .observeOn(Schedulers.io())<br/>                 .subscribe(i -&gt; {<br/>                     sleep(50);<br/>                     System.out.println("Received " + i);<br/>                 });<br/>        sleep(50000);<br/>     }<br/>    static Flowable&lt;Integer&gt; rangeReverse(int upperBound, int lowerBound) {<br/>         return Flowable.generate(() -&gt; new AtomicInteger(upperBound + 1),<br/>                 (state, emitter) -&gt; {<br/>                     int current = state.decrementAndGet();<br/>                     emitter.onNext(current);<br/>                     if (current == lowerBound)<br/>                         emitter.onComplete();<br/>                 }<br/>         );<br/>     }<br/>    public static void sleep(long millis) {<br/>         try {<br/>             Thread.sleep(millis);<br/>         } catch (InterruptedException e) {<br/>             e.printStackTrace();<br/>         }<br/>     }<br/> }</pre>
<p>The output is as follows:</p>
<pre style="padding-left: 60px"> Emitting 100<br/> Emitting 99<br/> ...<br/> Emitting -25<br/> Emitting -26<br/> Emitting -27 //128th emission<br/> Received 100<br/> Received 99<br/> Received 98<br/> ...<br/> Received 7<br/> Received 6<br/> Received 5 // 96th emission<br/> Emitting -28<br/> Emitting -29<br/> Emitting -30</pre>
<p><kbd>Flowable.generator()</kbd> provides a nicely abstracted mechanism to create a source that respects backpressure. For this reason, you might want to prefer this over <kbd>Flowable.create()</kbd> if you do not want to mess with caching or dropping emissions.</p>
<p>With <kbd>Flowable.generate()</kbd>, you can also provide a third <kbd>Consumer&lt;? super S&gt; disposeState</kbd> argument to do any disposal operations on termination, which can be helpful for IO sources.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, you learned about <kbd>Flowable</kbd> and backpressure and which situations it should be preferred over an <kbd>Observable</kbd>. Flowables are especially preferable when concurrency enters your application and a lot of data can flow through it, as it regulates how much data comes from the source at a given time. Some Flowables, such as <kbd>Flowable.interval()</kbd> or those derived from an <kbd>Observable</kbd>, do not have backpressure implemented. In these situations, you can use <kbd>onBackpressureXXX()</kbd> operators to queue or drop emissions for the downstream. If you are creating your own <kbd>Flowable</kbd> source from scratch, prefer to use the existing <kbd>Flowable</kbd> factories, and if that fails, prefer <kbd>Flowable.generate()</kbd> instead of <kbd>Flowable.create()</kbd>.</p>
<p>If you got to this point and understand most of the content in this book so far, congrats! You have all the core concepts of RxJava in your toolkit, and the rest of the book is all a walk in the park from here. The next chapter will cover how to create your own operators, which can be a somewhat advanced task. At a minimum, you should know how to compose existing operators to create new operators, which will be one of the next topics.</p>


            </article>

            
        </section>
    </body></html>