- en: Chapter 2. Clojure Abstractions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章 Clojure 抽象
- en: Clojure has four founding ideas. Firstly, it was set up to be a functional language.
    It is not pure (as in purely functional), but emphasizes immutability. Secondly,
    it is a dialect of Lisp; Clojure is malleable enough that users can extend the
    language without waiting for the language implementers to add new features and
    constructs. Thirdly, it was built to leverage concurrency for the new generation
    challenges. Lastly, it was designed to be a hosted language. As of today, Clojure
    implementations exist for the JVM, CLR, JavaScript, Python, Ruby, and Scheme.
    Clojure blends seamlessly with its host language.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 有四个基本理念。首先，它被建立为一个函数式语言。它不是纯函数式（如纯粹函数式），但强调不可变性。其次，它是一种 Lisp 方言；Clojure
    足够灵活，用户可以在不等待语言实现者添加新特性和结构的情况下扩展语言。第三，它是为了利用并发来应对新一代挑战而构建的。最后，它被设计为托管语言。截至目前，Clojure
    实现存在于 JVM、CLR、JavaScript、Python、Ruby 和 Scheme 上。Clojure 与其宿主语言无缝融合。
- en: 'Clojure is rich in abstractions. Though the syntax itself is very minimal,
    the abstractions are finely grained, mostly composable, and designed to tackle
    a wide variety of concerns in the least complicated way. In this chapter, we will
    discuss the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 丰富的抽象。尽管语法本身非常简洁，但抽象是细粒度的、大部分可组合的，并且旨在以最简单的方式解决广泛的问题。在本章中，我们将讨论以下主题：
- en: Performance characteristics of non-numeric scalars
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非数值标量的性能特征
- en: Immutability and epochal time model paving the way for performance by isolation
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不变性以及纪元时间模型通过隔离铺平了性能之路
- en: Persistent data structures and their performance characteristics
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持久数据结构和它们的性能特征
- en: Laziness and its impact on performance
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 惰性及其对性能的影响
- en: Transients as a high-performance, short-term escape hatch
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 临时对象作为高性能、短期逃逸通道
- en: Other abstractions, such as tail recursion, protocols/types, multimethods, and
    many more
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他抽象，如尾递归、协议/类型、多方法等
- en: Non-numeric scalars and interning
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非数值标量与池化
- en: 'Strings and characters in Clojure are the same as in Java. The string literals
    are implicitly interned. Interning is a way of storing only the unique values
    in the heap and sharing the reference everywhere it is required. Depending on
    the JVM vendor and the version of Java you use, the interned data may be stored
    in a string pool, Permgen, ordinary heap, or some special area in the heap marked
    for interned data. Interned data is subject to garbage collection when not in
    use, just like ordinary objects. Take a look at the following code:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 中的字符串和字符与 Java 中的相同。字符串字面量是隐式池化的。池化是一种只存储唯一值在堆中并在需要的地方共享引用的方法。根据 JVM
    供应商和您使用的 Java 版本，池化数据可能存储在字符串池、Permgen、普通堆或堆中标记为池化数据的一些特殊区域。当不使用时，池化数据会像普通对象一样受到垃圾回收。请看以下代码：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that `identical?` in Clojure is the same as `==` in Java. The benefit of
    interning a string is that there is no memory allocation overhead for duplicate
    strings. Commonly, applications on the JVM spend quite some time on string processing.
    So, it makes sense to have them interned whenever there is a chance of duplicate
    strings being simultaneously processed. Most of the JVM implementations today
    have an extremely fast intern operation; however, you should measure the overhead
    for your JVM if you have an older version.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，Clojure 中的 `identical?` 与 Java 中的 `==` 相同。字符串池化的好处是没有重复字符串的内存分配开销。通常，在 JVM
    上的应用程序在字符串处理上花费相当多的时间。因此，当有机会同时处理重复字符串时，将它们池化是有意义的。今天的大多数 JVM 实现都有一个非常快速的池化操作；然而，如果您有较旧的版本，您应该测量
    JVM 的开销。
- en: Another benefit of string interning is that when you know that two string tokens
    are interned, you can compare them faster for equality using `identical?` than
    non-interned string tokens. The equivalence function `=` first checks for identical
    references before conducting a content check.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串池化的另一个好处是，当你知道两个字符串标记被池化时，你可以使用 `identical?` 比非池化字符串标记更快地比较它们是否相等。等价函数 `=`
    首先检查引用是否相同，然后再进行内容检查。
- en: 'Symbols in Clojure always contain interned string references within them, so
    generating a symbol from a given string is nearly as fast as interning a string.
    However, two symbols created from the same string will not be identical:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 中的符号总是包含池化字符串引用，因此从给定字符串生成符号的速度几乎与池化字符串一样快。然而，从同一字符串创建的两个符号不会相同：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Keywords are, on the basis of their implementation, built on top of symbols
    and are designed to work with the `identical?` function for equivalence. So, comparing
    keywords for equality using `identical?` would be faster, just as with interned
    string tokens.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 关键字基于其实现建立在符号之上，并设计为与`identical?`函数一起用于等价性。因此，使用`identical?`比较关键字以进行相等性检查将更快，就像池化的字符串标记一样。
- en: Clojure is increasingly being used for large-volume data processing, which includes
    text and composite data structures. In many cases, the data is either stored as
    JSON or EDN ([http://edn-format.org](http://edn-format.org)). When processing
    such data, you can save memory by interning strings or using symbols/keywords.
    Remember that string tokens read from such data would not be automatically interned,
    whereas the symbols and keywords read from EDN data would invariably be interned.
    You may come across such situations when dealing with relational or NoSQL databases,
    web services, CSV or XML files, log parsing, and so on.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure越来越被用于大量数据处理，这包括文本和复合数据结构。在许多情况下，数据要么以JSON或EDN（[http://edn-format.org](http://edn-format.org)）的形式存储。在处理此类数据时，您可以通过字符串池化或使用符号/关键字来节省内存。请记住，从这种数据中读取的字符串标记不会被自动池化，而从中读取的符号和关键字则必然会被池化。在处理关系型或NoSQL数据库、Web服务、CSV或XML文件、日志解析等情况时，您可能会遇到这种情况。
- en: Interning is linked to the JVM **Garbage Collection** (**GC**), which, in turn,
    is closely linked to performance. When you do not intern the string data and let
    duplicates exist, they end up being allocated on the heap. More heap usage leads
    to GC overhead. Interning a string has a tiny but measurable and upfront performance
    overhead, whereas GC is often unpredictable and unclear. GC performance, in most
    JVM implementations, has not increased in a similar proportion to the performance
    advances in hardware. So, often, effective performance depends on preventing GC
    from becoming the bottleneck, which in most cases means minimizing it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 池化与JVM的垃圾回收（**GC**）相关联，而垃圾回收反过来又与性能密切相关。当您不池化字符串数据并允许重复存在时，它们最终会在堆上分配。更多的堆使用会导致GC开销增加。池化字符串会有微小但可测量且即时的性能开销，而GC通常是不可预测且不清晰的。在大多数JVM实现中，GC性能并没有像硬件性能提升那样以相似的比例增长。因此，通常，有效的性能取决于防止GC成为瓶颈，这在大多数情况下意味着最小化它。
- en: Identity, value, and epochal time model
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 身份、值和时态时间模型
- en: One of the principal virtues of Clojure is its simple design that results in
    malleable, beautiful composability. Using symbols in place of pointers is a programming
    practice that has existed for several decades now. It has found widespread adoption
    in several imperative languages. Clojure dissects that notion in order to uncover
    the core concerns that need to be addressed. The following subsections illustrate
    this aspect of Clojure.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure的一个主要优点是其简单的设计，这导致了可塑性强、美观的组合性。用符号代替指针是一种存在了几十年的编程实践。它已在几种命令式语言中得到广泛应用。Clojure剖析了这个概念，以揭示需要解决的核心问题。以下小节将说明Clojure的这一方面。
- en: We program using logical entities to represent values. For example, a value
    of `30` means nothing unless it is associated with a logical entity, let's say
    `age`. The logical entity `age` is the identity here. Now, even though `age` represents
    a value, the value may change with time; this brings us to the notion of `state`,
    which represents the value of the identity at a certain time. Hence, `state` is
    a function of time and is causally related to what we do in the program. Clojure's
    power lies in binding an identity with its value that holds true at the time and
    the identity remains isolated from any new value it may represent later. We will
    discuss state management in [Chapter 5](ch05.html "Chapter 5. Concurrency"), *Concurrency*.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用逻辑实体来表示值。例如，`30`这个值如果没有与逻辑实体关联，比如`age`，就没有意义。这里的逻辑实体`age`是身份。现在，尽管`age`代表一个值，但这个值可能会随时间变化；这引出了`状态`的概念，它代表在某个时间点的身份值。因此，`状态`是时间的函数，并且与我们在程序中执行的操作有因果关系。Clojure的力量在于将身份与其在特定时间保持为真的值绑定在一起，而身份保持与它可能后来代表的任何新值隔离。我们将在[第5章](ch05.html
    "第5章。并发") *并发* 中讨论状态管理。
- en: Variables and mutation
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变量和修改
- en: If you have previously worked with an imperative language (C/C++, Java, and
    so on), you may be familiar with the concept of a variable. A **variable** is
    a reference to a block of memory. When we update its value, we essentially update
    the place in memory where the value is stored. The variable continues to point
    to the place where the older version of the value was stored. So, essentially,
    a variable is an alias for the place of storage of values.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你之前使用过命令式语言（如C/C++、Java等），你可能对变量的概念很熟悉。**变量**是对内存块的一个引用。当我们更新其值时，我们实际上是在更新存储值的内存位置。变量继续指向存储旧版本值的那个位置。因此，本质上，变量是值存储位置的别名。
- en: A little analysis would reveal that variables are strongly linked to the processes
    that read or mutate their values. Every mutation is a state transition. The processes
    that read/update the variable should be aware of the possible states of the variable
    to make sense of the state. Can you see a problem here? It conflates identity
    and state! It is impossible to refer to a value or a state in time when dealing
    with a variable—the value could change at any time unless you have complete control
    over the process accessing it. The mutability model does not accommodate the concept
    of time that causes its state transition.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 有一点分析可以揭示，变量与读取或突变其值的进程紧密相关。每一次突变都是一个状态转换。读取/更新变量的进程应该了解变量的可能状态，以便理解状态。你能在这里看到问题吗？它混淆了身份和状态！在处理变量时，在时间上引用一个值或状态是不可能的——除非你完全控制访问它的进程，否则值可能会随时改变。可变模型不适应导致其状态转换的时间概念。
- en: The issues with mutability do not stop here. When you have a composite data
    structure containing mutable variables, the entire data structure becomes mutable.
    How can we mutate it without potentially undermining the other processes that
    might be observing it? How can we share this data structure with concurrent processes?
    How can we use this data structure as a key in a hash-map? This data structure
    does not convey anything. Its meaning could change with mutation! How do we send
    such a thing to another process without also compensating for the time, which
    can mutate it in different ways?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 可变性的问题并不止于此。当你有一个包含可变变量的复合数据结构时，整个数据结构就变得可变了。我们如何在不破坏可能正在观察它的其他进程的情况下突变它？我们如何与并发进程共享这个数据结构？我们如何将这个数据结构用作哈希表中的键？这个数据结构什么也没传达。它的意义可能会随着突变而改变！我们如何在不补偿可能以不同方式突变它的时间的情况下将这样的事物发送给另一个进程？
- en: Immutability is an important tenet of functional programming. It not only simplifies
    the programming model, but also paves the way for safety and concurrency. Clojure
    supports immutability throughout the language. Clojure also supports fast, mutation-oriented
    data structures as well as thread-safe state management via concurrency primitives.
    We will discuss these topics in the forthcoming sections and chapters.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 不变性是函数式编程的一个重要原则。它不仅简化了编程模型，还为安全性和并发性铺平了道路。Clojure在整个语言中支持不变性。Clojure还支持快速、以突变为导向的数据结构，以及通过并发原语实现线程安全的状态管理。我们将在接下来的章节中讨论这些主题。
- en: Collection types
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集合类型
- en: 'There are a few types of collections in Clojure, which are categorized based
    on their properties. The following Venn diagram depicts this categorization on
    the basis of whether the collections are counted (so that `counted?` returns `true`)
    or associative (so that `associative?` returns `true`) or sequential (so that
    `sequential?` returns `true`):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure中有几种集合类型，这些类型根据其属性进行分类。以下维恩图根据集合是否计数（`counted?`返回`true`）、是否关联（`associative?`返回`true`）或顺序（`sequential?`返回`true`）来描述这种分类：
- en: '![Collection types](img/B04596_02_01.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![集合类型](img/B04596_02_01.jpg)'
- en: The previous diagram illustrates the characteristics that different kinds of
    data structures share. The sequential structures let us iterate over the items
    in the collection, the item count of counted structures can be found constant
    with respect to time, and associative structures can be looked at with keys for
    corresponding values. The **CharSequence** box shows the character sequence Java
    types that can be converted to a Clojure sequence using (`seq charseq`).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的图展示了不同类型的数据结构所共有的特征。顺序结构允许我们对集合中的项目进行迭代，计数结构的项数可以随时间保持不变，关联结构可以通过键来查看相应的值。"**CharSequence**"框显示了Java类型字符序列，可以使用`seq
    charseq`将其转换为Clojure序列。
- en: Persistent data structures
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持久性数据结构
- en: As we've noticed in the previous section, Clojure's data structures are not
    only immutable, but can produce new values without impacting the old version.
    Operations produce these new values in such a way that old values remain accessible;
    the new version is produced in compliance with the complexity guarantees of that
    data structure, and both the old and new versions continue to meet the complexity
    guarantees. The operations can be recursively applied and can still meet the complexity
    guarantees. Such immutable data structures as the ones provided by Clojure are
    called **persistent data structures**. They are "persistent", as in, when a new
    version is created, both the old and new versions "persist" in terms of both the
    value and complexity guarantee. They have nothing to do with storage or durability
    of data. Making changes to the old version doesn't impede working with the new
    version and vice versa. Both versions persist in a similar way.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一节中注意到的，Clojure 的数据结构不仅不可变，而且可以在不影响旧版本的情况下产生新值。操作以这种方式产生新值，使得旧值仍然可访问；新版本的产生符合该数据结构的复杂度保证，并且旧版本和新版本继续满足复杂度保证。这些操作可以递归应用，并且仍然可以满足复杂度保证。Clojure
    提供的这种不可变数据结构被称为 **持久数据结构**。它们是“持久”的，即当创建新版本时，旧版本和新版本在值和复杂度保证方面都“持续”存在。这与数据的存储或持久性无关。修改旧版本不会妨碍使用新版本，反之亦然。两个版本都以类似的方式持续存在。
- en: Among the publications that have inspired the implementation of Clojure's persistent
    data structures, two of them are well known. Chris Okasaki's *Purely Functional
    Data Structures* has influenced the implementation of persistent data structures
    and lazy sequences/operations. Clojure's persistent queue implementation is adapted
    from Okasaki's *Batched Queues*. Phil Bagwell's *Ideal Hash Tries*, though meant
    for mutable and imperative data structures, was adapted to implement Clojure's
    persistent map/vector/set.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在启发 Clojure 持久数据结构实现的出版物中，其中两本尤为知名。Chris Okasaki 的 *纯函数式数据结构* 对持久数据结构和惰性序列/操作的实施产生了影响。Clojure
    的持久队列实现是从 Okasaki 的 *批处理队列* 中改编而来的。Phil Bagwell 的 *理想哈希树*，虽然旨在用于可变和命令式数据结构，但被改编以实现
    Clojure 的持久映射/向量/集合。
- en: Constructing lesser-used data structures
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建较少使用的数据结构
- en: 'Clojure supports a well-known literal syntax for lists, vectors, sets, and
    maps. Shown in the following list are some less-used methods for creating other
    data structures:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 支持一种著名的字面量语法，用于创建列表、向量、集合和映射。以下列表展示了创建其他数据结构的一些较少使用的方法：
- en: 'Map (`PersistentArrayMap` and `PersistentHashMap`):'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '映射 (`PersistentArrayMap` 和 `PersistentHashMap`):'
- en: '[PRE2]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Sorted map (`PersistentTreeMap`):'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '排序映射 (`PersistentTreeMap`):'
- en: '[PRE3]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Sorted set (`PersistentTreeSet`):'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '排序集合 (`PersistentTreeSet`):'
- en: '[PRE4]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Queue (`PersistentQueue`):'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '队列 (`PersistentQueue`):'
- en: '[PRE5]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As you can see, abstractions such as `TreeMap` (sorted by key), `TreeSet` (sorted
    by element), and `Queue` should be instantiated by calling their respective APIs.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，如 `TreeMap`（按键排序）、`TreeSet`（按元素排序）和 `Queue` 这样的抽象应该通过调用它们各自的 API 来实例化。
- en: Complexity guarantee
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 复杂度保证
- en: 'The following table gives a summary of the complexity guarantees (using the
    Big-O notation) of various kinds of persistent data structures in Clojure:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格总结了 Clojure 中各种持久数据结构的复杂度保证（使用大 O 表示法）：
- en: '| Operation | PersistentList | PersistentHashMap | PersistentArrayMap | PersistentVector
    | PersistentQueue | PersistentTreeMap |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | PersistentList | PersistentHashMap | PersistentArrayMap | PersistentVector
    | PersistentQueue | PersistentTreeMap |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| `count` | O(1) | O(1) | O(1) | O(1) | O(1) | O(1) |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| `count` | O(1) | O(1) | O(1) | O(1) | O(1) | O(1) |'
- en: '| `conj` | O(1) |   |   | O(1) | O(1) |   |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| `conj` | O(1) |   |   | O(1) | O(1) |   |'
- en: '| `first` | O(1) |   |   | O(<7) | O(<7) |   |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| `first` | O(1) |   |   | O(<7) | O(<7) |   |'
- en: '| `rest` | O(1) |   |   | O(<7) | O(<7) |   |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| `rest` | O(1) |   |   | O(<7) | O(<7) |   |'
- en: '| `doseq` | O(n) | O(n) | O(n) | O(n) | O(n) |   |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| `doseq` | O(n) | O(n) | O(n) | O(n) | O(n) |   |'
- en: '| `nth` | O(n) |   |   | O(<7) | O(<7) |   |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| `nth` | O(n) |   |   | O(<7) | O(<7) |   |'
- en: '| `last` | O(n) |   |   | O(n) | O(n) |   |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| `last` | O(n) |   |   | O(n) | O(n) |   |'
- en: '| `get` |   | O(<7) | O(1) | O(<7) | O(<7) | O(log n) |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| `get` |   | O(<7) | O(1) | O(<7) | O(<7) | O(log n) |'
- en: '| `assoc` |   | O(<7) | O(1) | O(<7) |   | O(log n) |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| `assoc` |   | O(<7) | O(1) | O(<7) |   | O(log n) |'
- en: '| `dissoc` |   | O(<7) | O(1) | O(<7) |   | O(log n) |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| `dissoc` |   | O(<7) | O(1) | O(<7) |   | O(log n) |'
- en: '| `peek` |   |   |   | O(1) | O(1) |   |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| `peek` |   |   |   | O(1) | O(1) |   |'
- en: '| `pop` |   |   |   | O(<7) | O(1) |   |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| `pop` |   |   |   | O(<7) | O(1) |   |'
- en: A **list** is a sequential data structure. It provides constant time access
    for count and for anything regarding the first element only. For example, `conj`
    adds the element to the head and guarantees *O(1)* complexity. Similarly, `first`
    and `rest` provide *O(1)* guarantees too. Everything else provides an *O(n)* complexity
    guarantee.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**列表**是一种顺序数据结构。它为计数和仅涉及第一个元素的操作提供常数时间访问。例如，`conj`将元素添加到头部并保证*O(1)*复杂度。同样，`first`和`rest`也提供*O(1)*保证。其他所有操作都提供*O(n)*复杂度保证。'
- en: Persistent hash-maps and vectors use the trie data structure with a branching
    factor of 32 under the hood. So, even though the complexity is *O(log* *[32]*
    *n)*, only 2^(32) hash codes can fit into the trie nodes. Hence, log[32] 2^(32),
    which turns out to be `6.4` and is less than `7`, is the worst-case complexity
    and can be considered near-constant time. As the trie grows larger, the portion
    to copy gets proportionately tiny due to structure sharing. Persistent hash-set
    implementation is also based on hash-map; hence, the hash-sets share the characteristics
    of the hash-maps. In a persistent vector, the last incomplete node is placed at
    the tail, which is always directly accessible from the root. This makes using
    `conj` to the end a constant time operation.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 持久哈希映射和向量在底层使用32个分支因子的trie数据结构。因此，尽管复杂度是*O(log* *[32]* *n)*，但只有2^(32)个哈希码可以放入trie节点中。因此，log[32]
    2^(32)，结果是`6.4`，小于`7`，是最坏情况下的复杂度，可以认为是接近常数时间。随着trie的增长，由于结构共享，需要复制的部分成比例地变得很小。持久哈希集实现也是基于哈希映射的；因此，哈希集共享哈希映射的特性。在持久向量中，最后一个不完整的节点放在尾部，这总是可以从根直接访问。这使得使用`conj`到末尾的操作是常数时间操作。
- en: Persistent tree-maps and tree-sets are basically sorted maps and sets respectively.
    Their implementation uses red-black trees and is generally more expensive than
    hash-maps and hash-sets. A persistent queue uses a persistent vector under the
    hood for adding new elements. Removing an element from a persistent queue takes
    the head off `seq`, which is created from the vector where new elements are added.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 持久树映射和树集基本上分别是排序映射和排序集。它们的实现使用红黑树，通常比哈希映射和哈希集更昂贵。持久队列在底层使用持久向量来添加新元素。从持久队列中移除元素会从向量中移除头部，该向量是从添加新元素的位置创建的。
- en: The complexity of an algorithm over a data structure is not an absolute measure
    of its performance. For example, working with hash-maps involves computing the
    hashCode, which is not included in the complexity guarantee. Our choice of data
    structures should be based on the actual use case. For example, when should we
    use a list instead of a vector? Probably when we need sequential or **last-in-first-out**
    (**LIFO**) access, or when constructing an **abstract-syntax-tree** (**AST**)
    for a function call.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 算法在数据结构上的复杂度并不是其性能的绝对度量。例如，使用哈希映射涉及计算hashCode，这不包括在复杂度保证中。我们应该根据实际用例选择数据结构。例如，何时应该使用列表而不是向量？可能是在需要顺序或**后进先出**（**LIFO**）访问时，或者当为函数调用构造**抽象语法树**（**AST**）时。
- en: O(<7) implies near constant time
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: O(<7)表示接近常数时间
- en: You may know that the **Big-O** notation is used to express the upper bound
    (worst case) of the efficiency of any algorithm. The variable *n* is used to express
    the number of elements in the algorithm. For example, a binary search on a sorted
    associative collection, such as a sorted vector, is a logarithmic time, that is
    an *O(log* *[2]* *n)* or simply an *O(log n)* algorithm. Since there can be a
    maximum of 2^(32) (technically 2^(31) due to a signed positive integer) elements
    in a Java collection and log[2] 2^(32) is 32, the binary search can be *O(≤32)*
    in the worst case. Similarly, though operations on persistent collections are
    O(log[32] n), in the worst case they actually turn out to be O(log[32] 2^(32))
    at maximum, which is *O(<7)*. Note that this is much lower than logarithmic time
    and approaches near constant time. This implies not so bad performance for persistent
    collections even in the worst possible scenario.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能知道，**大O**符号用于表示任何算法效率的上界（最坏情况）。变量*n*用于表示算法中的元素数量。例如，在排序关联集合上进行的二分搜索，如排序向量，是对数时间，即*O(log*
    *[2]* *n)*或简单地*O(log n)*算法。由于Java集合中最多可以有2^(32)（技术上由于有符号正整数是2^(31)）个元素，log[2]
    2^(32)是32，因此二分搜索在最坏情况下可以是*O(≤32)*。同样，尽管持久集合的操作是O(log[32] n)，但在最坏情况下实际上最多是O(log[32]
    2^(32))，这是*O(<7)*。请注意，这比对数时间低得多，接近常数时间。这意味着即使在最坏的情况下，持久集合的性能也不是很糟糕。
- en: The concatenation of persistent data structures
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 持久数据结构的连接
- en: 'While persistent data structures have excellent performance characteristics,
    the concatenation of two persistent data structures has been a linear time *O(N)*
    operation, except for some recent developments. The `concat` function, as of Clojure
    1.7, still provides linear time concatenation. Experimental work on **Relaxed
    Radix Balanced** (**RRB**) trees is going on in the **core.rrb-vector** contrib
    project ([https://github.com/clojure/core.rrb-vector](https://github.com/clojure/core.rrb-vector)),
    which may provide logarithmic time *O(log N)* concatenation. Readers interested
    in the details should refer to the following links:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管持久数据结构具有出色的性能特性，但两个持久数据结构的连接操作一直是一个线性时间 *O(N)* 操作，除了最近的一些发展。截至 Clojure 1.7，`concat`
    函数仍然提供线性时间连接。在 **core.rrb-vector** 贡献项目中进行的 **Relaxed Radix Balanced** (**RRB**)
    树的实验工作正在进行中（[https://github.com/clojure/core.rrb-vector](https://github.com/clojure/core.rrb-vector)），这可能提供对数时间
    *O(log N)* 连接。对细节感兴趣的读者应参考以下链接：
- en: The RRB-trees paper at [http://infoscience.epfl.ch/record/169879/files/RMTrees.pdf](http://infoscience.epfl.ch/record/169879/files/RMTrees.pdf)
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RRB-trees 论文在 [http://infoscience.epfl.ch/record/169879/files/RMTrees.pdf](http://infoscience.epfl.ch/record/169879/files/RMTrees.pdf)
- en: Phil Bagwell's talk at [http://www.youtube.com/watch?v=K2NYwP90bNs](http://www.youtube.com/watch?v=K2NYwP90bNs)
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Phil Bagwell 在 [http://www.youtube.com/watch?v=K2NYwP90bNs](http://www.youtube.com/watch?v=K2NYwP90bNs)
    的演讲
- en: Tiark Rompf's talk at [http://skillsmatter.com/podcast/scala/fast-concatenation-immutable-vectors](http://skillsmatter.com/podcast/scala/fast-concatenation-immutable-vectors)
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tiark Rompf 在 [http://skillsmatter.com/podcast/scala/fast-concatenation-immutable-vectors](http://skillsmatter.com/podcast/scala/fast-concatenation-immutable-vectors)
    的演讲
- en: Sequences and laziness
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序列和懒性
- en: '|   | *"A seq is like a logical cursor."* |   |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '|    | *"A seq is like a logical cursor."*    |'
- en: '|   | --*Rich Hickey* |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '|    | --*Rich Hickey* |'
- en: '**Sequences** (commonly known as **seqs**) are a way to sequentially consume
    a succession of data. As with iterators, they let a user begin consuming elements
    from the head and proceed realizing one element after another. However, unlike
    iterators, sequences are immutable. Also, since sequences are only a view of the
    underlying data, they do not modify the storage structure of the data.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**序列**（通常称为 **seqs**）是按顺序消费一系列数据的方式。与迭代器一样，它们允许用户从头部开始消费元素，并逐个实现一个元素。然而，与迭代器不同，序列是不可变的。此外，由于序列只是底层数据的视图，它们不会修改数据的存储结构。'
- en: What makes sequences stand apart is they are not data structures per se; rather,
    they are a data abstraction over a stream of data. The data may be produced by
    an algorithm or a data source connected to an I/O operation. For example, the
    `resultset-seq` function accepts a `java.sql.ResultSet` JDBC instance as an argument
    and produces lazily realized rows of data as `seq`.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 使序列与众不同的地方在于它们本身不是数据结构；相反，它们是对数据流的数据抽象。数据可能由算法或与 I/O 操作连接的数据源产生。例如，`resultset-seq`
    函数接受一个 `java.sql.ResultSet` JDBC 实例作为参数，并以 `seq` 的形式产生懒实现的行数据。
- en: Clojure data structures can be turned into sequences using the `seq` function.
    For example, (`seq [:a :b :c :d]`) returns a sequence. Calling `seq` over an empty
    collection returns nil.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 数据结构可以通过 `seq` 函数转换为序列。例如，（`seq [:a :b :c :d]`）返回一个序列。对空集合调用 `seq` 返回
    nil。
- en: 'Sequences can be consumed by the following functions:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 序列可以被以下函数消费：
- en: '`first`: This returns the head of the sequence'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`first`：此函数返回序列的头部'
- en: '`rest`: This returns the remaining sequence, even if it''s empty, after removing
    the head'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rest`：此函数返回移除头部后的剩余序列，即使它是空的'
- en: '`next`: This returns the remaining sequence or nil, if it''s empty, after removing
    the head'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`next`：此函数返回移除头部后的剩余序列或 nil，如果它是空的'
- en: Laziness
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 懒性
- en: Clojure is a strict (as in, the opposite of "lazy") language, which can choose
    to explicitly make use of laziness when required. Anybody can create a lazily
    evaluated sequence using the `lazy-seq` macro. Some Clojure operations over collections,
    such as `map`, `filter`, and more are intentionally lazy.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 是一种严格的（即“懒”的对立面）语言，可以在需要时显式地利用懒性。任何人都可以使用 `lazy-seq` 宏创建一个懒评估序列。一些 Clojure
    对集合的操作，如 `map`、`filter` 等，都是有意为之的懒操作。
- en: '**Laziness** simply means that the value is not computed until actually required.
    Once the value is computed, it is cached so that any future reference to the value
    need not re-compute it. The caching of the value is called **memoization**. Laziness
    and memoization often go hand in hand.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**惰性**简单来说就是值只有在实际需要时才会被计算。一旦值被计算，它就会被缓存起来，这样任何对值的未来引用都不需要重新计算它。值的缓存称为 **记忆化**。惰性和记忆化常常是相辅相成的。'
- en: Laziness in data structure operations
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据结构操作中的惰性
- en: 'Laziness and memoization together form an extremely useful combination to keep
    the single-threaded performance of functional algorithms comparable to its imperative
    counterparts. For an example, consider the following Java code:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 惰性和记忆化结合在一起形成了一种极其有用的组合，可以保持函数式算法的单线程性能与其命令式对应物相当。例如，考虑以下 Java 代码：
- en: '[PRE6]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As is clear from the preceding snippet, it has a linear time complexity, that
    is, *O(n)*, and the whole operation is performed in a single pass. The comparable
    Clojure code is as follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如前文片段所示，它具有线性时间复杂度，即 *O(n*)，整个操作都在单次遍历中完成。相应的 Clojure 代码如下：
- en: '[PRE7]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now, since we know `map` and `filter` are lazy, we can deduce that the Clojure
    version also has linear time complexity, that is, *O(n)*, and finishes the task
    in one pass with no significant memory overhead. Imagine, for a moment, that `map`
    and `filter` are not lazy—what would be the complexity then? How many passes would
    it make? It's not just that map and filter would both have taken one pass, that
    is, *O(n)*, each; they would each have taken as much memory as the original collection
    in the worst case, due to storing the intermediate results.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，既然我们知道 `map` 和 `filter` 是惰性的，我们可以推断出 Clojure 版本也具有线性时间复杂度，即 *O(n*)，并且可以在一次遍历中完成任务，没有显著的内存开销。想象一下，如果
    `map` 和 `filter` 不是惰性的，那么复杂度会是什么？它需要多少次遍历？不仅仅是 map 和 filter 都会各自进行一次遍历，即 *O(n*)，每个；在最坏的情况下，它们各自会占用与原始集合一样多的内存，因为需要存储中间结果。
- en: It is important to know the value of laziness and memoization in an immutability-emphasizing
    functional language such as Clojure. They form a basis for **amortization** in
    persistent data structures, which is about focusing on the overall performance
    of a composite operation instead of microanalyzing the performance of each operation
    in it; the operations are tuned to perform faster in those operations that matter
    the most.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在强调不可变性的函数式语言如 Clojure 中了解惰性和记忆化的价值非常重要。它们是持久数据结构中 **摊销** 的基础，这涉及到关注复合操作的整体性能，而不是微观分析其中每个操作的性能；操作被调整以在最重要的操作中更快地执行。
- en: Another important bit of detail is that when a lazy sequence is realized, the
    data is memoized and stored. On the JVM, all the heap references that are reachable
    in some way are not garbage collected. So, as a consequence, the entire data structure
    is kept in the memory unless you lose the head of the sequence. When working with
    lazy sequences using local bindings, make sure you don't keep referring to the
    lazy sequence from any of the locals. When writing functions that may accept lazy
    sequence(s), take care that any reference to the lazy `seq` does not outlive the
    execution of the function in the form of a closure or some such.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的细节是，当惰性序列被实现时，数据会被记忆化并存储。在 JVM 上，所有以某种方式可达的堆引用都不会被垃圾回收。因此，结果就是，整个数据结构除非你失去了序列的头部，否则会一直保留在内存中。当使用局部绑定处理惰性序列时，确保你不会从任何局部引用惰性序列。当编写可能接受惰性序列（s）的函数时，注意任何对惰性
    `seq` 的引用都不应该超出函数执行的生存期，形式为闭包或其他。
- en: Constructing lazy sequences
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建惰性序列
- en: 'Now that we know what lazy sequences are, let''s try to create a retry counter
    that should return true only as many times as the retry can be performed. This
    is shown in the following code:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了惰性序列是什么，让我们尝试创建一个重试计数器，它应该只在重试可以进行时返回 true。这如下面的代码所示：
- en: '[PRE8]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `lazy-seq` macro makes sure that the stack is not used for recursion. We
    can see that this function would return endless values. Hence, in order to inspect
    what it returns, we should limit the number of elements as shown in the following
    code:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`lazy-seq` 宏确保栈不会被用于递归。我们可以看到这个函数会返回无限多的值。因此，为了检查它返回的内容，我们应该限制元素的数量，如下面的代码所示：'
- en: '[PRE9]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, let''s try using it in a mock fashion:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试以模拟的方式使用它：
- en: '[PRE10]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'As expected, the output should print `Retrying` five times before printing
    `No more retries` and exiting as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期，输出应该打印 `Retrying` 五次，然后打印 `No more retries` 并退出，如下所示：
- en: '[PRE11]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s take another simpler example of constructing a lazy sequence, which
    gives us a countdown from a specified number to zero:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再举一个更简单的例子来构建一个惰性序列，它可以从指定的数字倒数到零：
- en: '[PRE12]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can inspect the values it returns as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以如下检查它返回的值：
- en: '[PRE13]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Lazy sequences can loop indefinitely without exhausting the stack and can come
    in handy when working with other lazy operations. To maintain a balance between
    space-saving and performance, consuming lazy sequences results in the chunking
    of elements by a factor of 32\. That means lazy seqs are realized in a chunk-size
    of 32, even though they are consumed sequentially.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 惰性序列可以无限循环而不会耗尽栈空间，当与其他惰性操作一起工作时非常有用。为了在节省空间和性能之间保持平衡，消耗惰性序列会导致元素以32的倍数进行分块。这意味着尽管惰性序列是按顺序消耗的，但它们是以32个元素为一个块来实现的。
- en: Custom chunking
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自定义分块
- en: 'The default chunk size 32 may not be optimum for all lazy sequences—you can
    override the chunking behavior when you need to. Consider the following snippet
    (adapted from Kevin Downey''s public gist at [https://gist.github.com/hiredman/324145](https://gist.github.com/hiredman/324145)):'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 默认块大小32可能不是所有惰性序列的最佳选择——当你需要时可以覆盖分块行为。考虑以下代码片段（改编自Kevin Downey在[https://gist.github.com/hiredman/324145](https://gist.github.com/hiredman/324145)的公开gist）：
- en: '[PRE14]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'As per the previous snippet, the user is allowed to pass a chunk size that
    is used to produce the lazy sequence. A larger chunk size may be useful when processing
    large text files, such as when processing CSV or log files. You would notice the
    following four less-known functions used in the snippet:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的代码片段，用户可以传递一个块大小，该大小用于生成惰性序列。在处理大型文本文件时，例如处理CSV或日志文件时，较大的块大小可能很有用。你会在代码片段中注意到以下四个不太为人所知的功能：
- en: '`clojure.core/chunk-cons`'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clojure.core/chunk-cons`'
- en: '`clojure.core/chunk-buffer`'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clojure.core/chunk-buffer`'
- en: '`clojure.core/chunk-append`'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clojure.core/chunk-append`'
- en: '`clojure.core/chunk`'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clojure.core/chunk`'
- en: While `chunk-cons` is the equivalent of `clojure.core/cons` for chunked sequences,
    `chunk-buffer` creates a mutable chunk buffer (controls the chunk size), `chunk-append`
    appends an item to the end of a mutable chunk buffer, and chunk turns a mutable
    chunk buffer into an immutable chunk.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`chunk-cons`是针对分块序列的`clojure.core/cons`的等价物，但`chunk-buffer`创建了一个可变的块缓冲区（控制块大小），`chunk-append`将一个项目追加到可变块缓冲区的末尾，而`chunk`将可变块缓冲区转换为不可变块。
- en: 'The `clojure.core` namespace has several functions related to chunked sequences
    listed as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`clojure.core`命名空间中列出了与分块序列相关的几个函数，如下所示：'
- en: '`chunk`'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk`'
- en: '`chunk-rest`'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk-rest`'
- en: '`chunk-cons`'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk-cons`'
- en: '`chunk-next`'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk-next`'
- en: '`chunk-first`'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk-first`'
- en: '`chunk-append`'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk-append`'
- en: '`chunked-seq?`'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunked-seq?`'
- en: '`chunk-buffer`'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk-buffer`'
- en: These functions are not documented, so although I would encourage you to study
    their source code to understand what they do, I would advise you not to make any
    assumptions about their support in future Clojure versions.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这些函数没有文档说明，所以我鼓励你研究它们的源代码以了解它们的功能，但我建议你不要对未来Clojure版本中它们的支持做出任何假设。
- en: Macros and closures
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 宏和闭包
- en: 'Often, we define a macro so as to turn the parameter body of code into a closure
    and delegate it to a function. See the following example:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们定义一个宏，以便将代码的参数体转换为闭包并将其委托给函数。请看以下示例：
- en: '[PRE15]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'When using such code, if the body binds a local to a lazy sequence it may be
    retained longer than necessary, likely with bad consequences on memory consumption
    and performance. Fortunately, this can be easily fixed:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用这样的代码时，如果主体将一个局部变量绑定到一个惰性序列，它可能比必要的保留时间更长，这可能会对内存消耗和性能产生不良影响。幸运的是，这可以很容易地修复：
- en: '[PRE16]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Notice the `^:once` hint and the `fn*` macro, which make the Clojure compiler
    clear the closed-over references, thus avoiding the problem. Let''s see this in
    action (Alan Malloy''s example from [https://groups.google.com/d/msg/clojure/Ys3kEz5c_eE/3St2AbIc3zMJ](https://groups.google.com/d/msg/clojure/Ys3kEz5c_eE/3St2AbIc3zMJ)):'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`^:once`提示和`fn*`宏，这使得Clojure编译器清除闭包引用，从而避免了这个问题。让我们看看它是如何工作的（来自Alan Malloy的[https://groups.google.com/d/msg/clojure/Ys3kEz5c_eE/3St2AbIc3zMJ](https://groups.google.com/d/msg/clojure/Ys3kEz5c_eE/3St2AbIc3zMJ)的示例）：
- en: '[PRE17]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The manifestation of the previous condition depends on the available heap space.
    This issue is tricky to detect as it only raises `OutOfMemoryError`, which is
    easy to misunderstand as a heap space issue instead of a memory leak. As a preventive
    measure, I would suggest using `^:once` with `fn*` in all cases where you close
    over any potentially lazy sequence.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个条件的体现取决于可用的堆空间。这个问题很难检测，因为它只会引发 `OutOfMemoryError`，这很容易被误解为堆空间问题而不是内存泄漏。作为预防措施，我建议在所有关闭任何可能懒加载序列的情况下使用
    `^:once` 与 `fn*`。
- en: Transducers
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转换器
- en: Clojure 1.7 introduced a new abstraction called transducers for "composable
    algorithmic transformations", commonly used to apply a series of transformations
    over collections. The idea of transducers follows from the **reducing function**,
    which accepts arguments of the form (`result, input`) and returns `result`. A
    reducing function is what we typically use with reduce. A **transducer** accepts
    a reducing function, wraps/composes over its functionality to provide something
    extra, and returns another reducing function.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure 1.7 引入了一个名为转换器的新抽象，用于“可组合算法转换”，通常用于在集合上应用一系列转换。转换器的想法源于**累加函数**，它接受形式为
    (`result, input`) 的参数并返回 `result`。累加函数是我们通常与 `reduce` 一起使用的函数。**转换器**接受一个累加函数，将其功能包装/组合以提供额外的功能，并返回另一个累加函数。
- en: The functions in `clojure.core` that deal with collections have acquired an
    `arity-1` variant, which returns a transducer, namely `map`, `cat`, `mapcat`,
    `filter`, `remove`, `take`, `take-while`, `take-nth`, `drop`, `drop-while`, `replace`,
    `partition-by`, `partition-all`, `keep`, `keep-indexed`, `dedupe` and `random-sample`.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 处理集合的 `clojure.core` 中的函数已经获得了一个 `arity-1` 变体，它返回一个转换器，即 `map`、`cat`、`mapcat`、`filter`、`remove`、`take`、`take-while`、`take-nth`、`drop`、`drop-while`、`replace`、`partition-by`、`partition-all`、`keep`、`keep-indexed`、`dedupe`
    和 `random-sample`。
- en: 'Consider the following few examples, all of which do the same thing:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下几个例子，它们都做了相同的事情：
- en: '[PRE18]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here, (`filter odd?`) returns a transducer—in the first example the transducer
    wraps over the reducer function `+` to return another combined reducing function.
    While we use the ordinary `reduce` function in the first example, in the second
    example we use the `transduce` function that accepts a transducer as an argument.
    In the third example, we write a transducer `filter-odd?`, which emulates what
    (`filter odd?`) does. Let''s see how the performance varies between traditional
    and transducer versions:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，(`filter odd?`) 返回一个转换器——在第一个例子中，转换器将累加函数 `+` 包装起来，以返回另一个组合的累加函数。虽然我们在第一个例子中使用了普通的
    `reduce` 函数，但在第二个例子中，我们使用了接受转换器作为参数的 `transduce` 函数。在第三个例子中，我们编写了一个转换器 `filter-odd?`，它模拟了
    (`filter odd?`) 的行为。让我们看看传统版本和转换器版本之间的性能差异：
- en: '[PRE19]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Performance characteristics
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能特性
- en: The key point behind transducers is how orthogonal each transformation is allowed
    to be, yet highly composable also. At the same time, transformations can happen
    in lockstep for the entire sequence instead of each operation producing lazy chunked
    sequences. This often causes significant performance benefits with transducers.
    Lazy sequences are still going to be useful when the final result is too large
    to realize at once—for other use cases transducers should fit the need aptly with
    improved performance. Since the core functions have been overhauled to work with
    transducers, it makes sense to model transformations more often than not in terms
    of transducers.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 转换器背后的关键点在于每个转换可以允许多么正交，同时又能高度可组合。同时，转换可以在整个序列上同步发生，而不是每个操作都产生懒加载的块序列。这通常会给转换器带来显著的性能优势。当最终结果太大而无法一次性实现时，懒加载序列仍然会很有用——对于其他用例，转换器应该能够适当地满足需求并提高性能。由于核心函数已经被彻底改造以与转换器一起工作，因此经常用转换器来建模转换是有意义的。
- en: Transients
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 瞬态
- en: Earlier in this chapter, we discussed the virtues of immutability and the pitfalls
    of mutability. However, even though mutability is fundamentally unsafe, it also
    has very good single-threaded performance. Now, what if there was a way to restrict
    the mutable operation in a local context in order to provide safety guarantees?
    That would be equivalent to combining the performance advantage and local safety
    guarantees. That is exactly the abstraction called **transients**, which is provided
    by Clojure.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '在本章前面，我们讨论了不可变性的优点和可变性的陷阱。然而，尽管可变性在本质上是不安全的，但它也具有非常好的单线程性能。现在，如果有一种方法可以限制局部上下文中的可变操作，以提供安全保证，那将等同于结合性能优势和局部安全保证。这正是
    Clojure 提供的称为 **transients** 的抽象。 '
- en: 'Firstly, let''s verify that it is safe (up to Clojure 1.6 only):'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们验证它是安全的（仅限于 Clojure 1.6）：
- en: '[PRE20]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'As we can see previously, up to Clojure 1.6, a transient created in one thread
    cannot be accessed by another. However, this operation is allowed in Clojure 1.7
    in order for transducers to play well with the `core.async` ([https://github.com/clojure/core.async](https://github.com/clojure/core.async))
    library —the developer should maintain operational consistency on transients across
    threads:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，直到 Clojure 1.6，一个线程中创建的 transient 不能被另一个线程访问。然而，在 Clojure 1.7 中允许这种操作，以便
    transducers 能够与 `core.async` ([https://github.com/clojure/core.async](https://github.com/clojure/core.async))
    库良好地协作——开发者应在跨线程上保持 transients 的操作一致性：
- en: '[PRE21]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'So, transients cannot be converted to seqs. Hence, they cannot participate
    in the birthing of new persistent data structures and leak out of the scope of
    execution. Consider the following code:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，transients 不能转换为 seqs。因此，它们不能参与新持久数据结构的生成，并且会从执行范围中泄漏出来。考虑以下代码：
- en: '[PRE22]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The `persistent!` function permanently converts `transient` into an equivalent
    persistent data structure. Effectively, transients are for one-time use only.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`persistent!` 函数永久地将 `transient` 转换为等效的持久数据结构。实际上，transients 只能用于一次性使用。'
- en: 'Conversion between `persistent` and `transient` data structures (the `transient`
    and `persistent!` functions) is constant time, that is, it is an *O(1)* operation.
    Transients can be created from unsorted maps, vectors, and sets only. The functions
    that mutate transients are: `conj!`, `disj!`, `pop!`, `assoc!`, and `dissoc!`.
    Read-only operations such as `get`, `nth`, `count`, and many more work as usual
    on transients, but functions such as `contains?` and those that imply seqs, such
    as `first`, `rest`, and `next`, do not.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `persistent` 和 `transient` 数据结构之间（`transient` 和 `persistent!` 函数）的转换是常数时间，即它是一个
    *O(1)* 操作。transients 只能从未排序的映射、向量和集合中创建。修改 transients 的函数有：`conj!`、`disj!`、`pop!`、`assoc!`
    和 `dissoc!`。只读操作，如 `get`、`nth`、`count` 等，在 transients 上按常规工作，但像 `contains?` 和那些暗示
    seqs 的函数，如 `first`、`rest` 和 `next`，则不工作。
- en: Fast repetition
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速重复
- en: 'The function `clojure.core/repeatedly` lets us execute a function many times
    and produces a lazy sequence of results. Peter Taoussanis, in his open source
    serialization library **Nippy** ([https://github.com/ptaoussanis/nippy](https://github.com/ptaoussanis/nippy)),
    wrote a transient-aware variant that performs significantly better. It is reproduced,
    as shown, with his permission (note that the arity of the function is not the
    same as `repeatedly`):'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 `clojure.core/repeatedly` 允许我们多次执行一个函数，并产生一个结果的惰性序列。Peter Taoussanis 在他的开源序列化库
    **Nippy** ([https://github.com/ptaoussanis/nippy](https://github.com/ptaoussanis/nippy))
    中编写了一个对 transient 有意识的变体，其性能显著提高。它在他的许可下被复制，如下所示（注意，该函数的参数数量与 `repeatedly` 不同）：
- en: '[PRE23]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Performance miscellanea
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能杂项
- en: Besides the major abstractions we saw earlier in the chapter, there are other
    smaller, but nevertheless very performance-critical, parts of Clojure that we
    will see in this section.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 除了本章前面看到的重大抽象之外，Clojure 还有其他一些较小但同样非常关键的性能部分，我们将在本节中看到。
- en: Disabling assertions in production
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在生产环境中禁用断言
- en: Assertions are very useful to catch logical errors in the code during development,
    but they impose a runtime overhead that you may like to avoid in the production
    environment. Since `assert` is a compile time variable, the assertions can be
    silenced either by binding `assert` to false or by using `alter-var-root` before
    the code is loaded. Unfortunately, both the techniques are cumbersome to use.
    Paul Stadig's library called **assertions** ([https://github.com/pjstadig/assertions](https://github.com/pjstadig/assertions))
    helps with this exact use-case by enabling or disabling assertions via the command-line
    argument `-ea` to the Java runtime.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 断言在开发过程中捕获代码中的逻辑错误非常有用，但它们在生产环境中可能会带来运行时开销，你可能想避免。由于 `assert` 是一个编译时变量，断言可以通过将
    `assert` 绑定到 `false` 或在代码加载之前使用 `alter-var-root` 来静默。不幸的是，这两种技术都很难使用。Paul Stadig
    的名为 **assertions** 的库（[https://github.com/pjstadig/assertions](https://github.com/pjstadig/assertions)）通过通过命令行参数
    `-ea` 到Java运行时启用或禁用断言来帮助解决这个特定用例。
- en: 'To use it, you must include it in your Leiningen `project.clj` file as a dependency:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用它，你必须将其包含在你的 Leiningen `project.clj` 文件中作为依赖项：
- en: '[PRE24]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'You must use this library''s `assert` macro instead of Clojure''s own, so each
    `ns` block in the application should look similar to this:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须使用这个库的 `assert` 宏而不是Clojure自己的，因此应用程序中的每个 `ns` 块都应该类似于以下内容：
- en: '[PRE25]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'When running the application, you should include the `-ea` argument to the
    JRE to enable assertions, whereas its exclusion implies no assertion at runtime:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行应用程序时，你应该将 `-ea` 参数包含到JRE中，以启用断言，而排除它则意味着在运行时没有断言：
- en: '[PRE26]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Note that this usage will not automatically avoid assertions in the dependency
    libraries.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这种用法不会自动避免依赖库中的断言。
- en: Destructuring
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解构
- en: '**Destructuring** is one of Clojure''s built-in mini languages and, arguably,
    a top productivity booster during development. This feature leads to the parsing
    of values to match the left-hand side of the binding forms. The more complicated
    the binding form, the more work there is that needs to be done. Not surprisingly,
    this has a little bit of performance overhead.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**解构** 是Clojure的内置迷你语言之一，并且可以说是开发期间的一个顶级生产力提升器。这个特性导致了将值解析以匹配绑定形式的左侧。绑定形式越复杂，需要完成的工作就越多。不出所料，这会有一点性能开销。'
- en: It is easy to avoid this overhead by using explicit functions to unravel data
    in the tight loops and other performance-critical code. After all, it all boils
    down to making the program work less and do more.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用显式函数在紧密循环和其他性能关键代码中解开数据，可以轻松避免这种开销。毕竟，这一切都归结于让程序工作得少，做得多。
- en: Recursion and tail-call optimization (TCO)
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 递归和尾调用优化（TCO）
- en: Functional languages have this concept of tail-call optimization related to
    recursion. So, the idea is that when a recursive call is at the tail position,
    it does not take up space on the stack for recursion. Clojure supports a form
    of user-assisted recursive call to make sure the recursive calls do not blow the
    stack. This is kind of an imperative looping, but is extremely fast.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 函数式语言有与递归相关的尾调用优化概念。所以，想法是当递归调用处于尾位置时，它不会占用递归的栈空间。Clojure 支持一种用户辅助递归调用形式，以确保递归调用不会耗尽栈空间。这有点像命令式循环，但速度非常快。
- en: 'When carrying out computations, it may make a lot of sense to use `loop-recur`
    in the tight loops instead of iterating over synthetic numbers. For example, we
    want to add all odd integers from zero through to 1,000,000\. Let''s compare the
    code:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行计算时，在紧密循环中使用 `loop-recur` 而不是迭代合成数字可能非常有意义。例如，我们想要将0到1,000,000之间的所有奇数相加。让我们比较一下代码：
- en: '[PRE27]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'When we run the code, we get interesting results:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行代码时，我们得到了有趣的结果：
- en: '[PRE28]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The `time` macro is far from perfect as the performance-benchmarking tool, but
    the relative numbers indicate a trend—in the subsequent chapters, we will look
    at the *Criterium* library for more scientific benchmarking. Here, we use `loop-recur`
    not only to iterate faster, but we are also able to change the algorithm itself
    by iterating only about half as many times as we did in the other example.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '`time` 宏作为性能基准工具远非完美，但相对数值表明了一种趋势——在随后的章节中，我们将探讨 *Criterium* 库进行更科学的基准测试。在这里，我们使用
    `loop-recur` 不仅是为了更快地迭代，而且我们还能通过只迭代大约其他示例一半的次数来改变算法本身。'
- en: Premature end of iteration
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 迭代提前结束
- en: 'When accumulating over a collection, in some cases, we may want to end it prematurely.
    Prior to Clojure 1.5, `loop-recur` was the only way to do it. When using `reduce`,
    we can do just that using the `reduced` function introduced in Clojure 1.5 as
    shown:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在对集合进行累积时，在某些情况下，我们可能希望提前结束。在Clojure 1.5之前，`loop-recur`是唯一的方法。当使用`reduce`时，我们可以使用Clojure
    1.5中引入的`reduced`函数来完成，如下所示：
- en: '[PRE29]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Here, we multiply all the numbers in a collection and, upon finding any of the
    numbers as zero, immediately return the result zero instead of continuing up to
    the last element.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们乘以集合中的所有数字，并在找到任何数字为零时，立即返回结果零，而不是继续到最后一个元素。
- en: The function `reduced?` helps detect when a reduced value is returned. Clojure
    1.7 introduces the `ensure-reduced` function to box up non-reduced values as reduced.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`reduced?`有助于检测何时返回了减少值。Clojure 1.7引入了`ensure-reduced`函数，用于将非减少值装箱为减少值。
- en: Multimethods versus protocols
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多态方法与协议
- en: '**Multimethods** are a fantastic expressive abstraction for a polymorphic dispatch
    on the dispatch function''s return value. The `dispatch` functions associated
    with a multimethod are maintained at runtime and are looked up whenever a multimethod
    call is invoked. While multimethods provide a lot of flexibility in determining
    the dispatch, the performance overhead is simply too high compared to that of
    protocol implementations.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '**多态方法**是一种出色的多态分派表达式抽象，其分派函数的返回值用于分派。与多态方法相关联的分派函数在运行时维护，并在每次调用多态方法时查找。虽然多态方法在确定分派方面提供了很多灵活性，但与协议实现相比，性能开销实在太高。'
- en: Protocols (`defprotocol`) are implemented using reify, records (`defrecord`),
    and types (`deftype`, `extend-type`) in Clojure. This is a big discussion topic—since
    we are discussing the performance characteristics, it should suffice to say that
    protocol implementations dispatch on polymorphic types and are significantly faster
    than multimethods. Protocols and types are generally the implementation detail
    of an API, so they are usually fronted by functions.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 协议（`defprotocol`）在Clojure中通过`reify`、记录（`defrecord`）和类型（`deftype`、`extend-type`）实现。这是一个大讨论话题——既然我们在讨论性能特征，那么只需说协议实现基于多态类型进行分派，并且比多态方法快得多就足够了。协议和类型通常是API的实现细节，因此它们通常由函数来呈现。
- en: Due to the multimethods' flexibility, they still have a place. However, in performance-critical
    code it is advisable to use protocols, records, and types instead.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 由于多态方法的灵活性，它们仍然有其位置。然而，在性能关键代码中，建议使用协议、记录和类型。
- en: Inlining
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内联
- en: 'It is well known that macros are expanded inline at the call site and avoid
    a function call. As a consequence, there is a small performance benefit. There
    is also a `definline` macro that lets you write a function just like a normal
    macro. It creates an actual function that gets inlined at the call site:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 宏在调用位置内联展开并且避免了函数调用。因此，存在一定的性能优势。还有一个`definline`宏，允许你像正常宏一样编写函数。它创建了一个实际函数，在调用位置内联：
- en: '[PRE30]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Note
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that the JVM also analyzes the code it runs and does its own inlining of
    code at runtime. While you may choose to inline the hot functions, this technique
    is known to give only a modest performance boost.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，JVM也会分析它运行的代码，并在运行时进行代码内联。虽然你可以选择内联热点函数，但这种技术仅能提供适度的性能提升。
- en: 'When we define a `var` object, its value is looked up each time it is used.
    When we define a `var` object using a `:const` meta pointing to a `long` or `double`
    value, it is inlined from wherever it is called:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们定义一个`var`对象时，其值在每次使用时都会被查找。当我们使用指向`long`或`double`值的`:const`元数据定义`var`对象时，它将从调用位置内联：
- en: '[PRE31]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This is known to give a decent performance boost when applicable. See the following
    example:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这在适用时众所周知可以提供不错的性能提升。请看以下示例：
- en: '[PRE32]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Summary
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Performance is one of the cornerstones of Clojure's design. Abstractions in
    Clojure are designed for simplicity, power, and safety, with performance firmly
    in mind. We saw the performance characteristics of various abstractions and also
    how to make decisions about abstractions depending on performance use cases.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 性能是Clojure设计的基础之一。Clojure中的抽象设计用于简单性、强大性和安全性，同时始终考虑性能。我们看到了各种抽象的性能特征，以及如何根据性能用例做出抽象决策。
- en: In the next chapter, we will see how Clojure interoperates with Java and how
    we can extract Java's power to derive optimum performance.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到Clojure如何与Java交互，以及我们如何提取Java的力量以获得最佳性能。
