- en: Chapter 10. Concepts of Graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A graph is a generalization of a tree. In a tree, every node has one parent.
    In a graph, a node can have multiple parents. The most common way to think about
    a graph is as a set of vertices and edges. Vertices are like points and edges
    are like lines that connect the points. In the generic notion of a graph, there
    is no restriction on which vertices can be connected by edges. This allows graphs
    to model a versatile category of real-life concepts. The Internet, for example,
    is a graph where the vertices are the web pages and the edges the hyperlinks between
    the pages. A social networking site, such as Facebook, has a graph of profiles
    in which the vertices are the profiles and the edges the friendships between the
    profiles. Each software has a graph of dependencies, called a dependency graph,
    in which the vertices are the different software libraries used and the edges
    the dependencies between the software libraries. There is no end to examples of
    graphs. In this chapter, we will discuss the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Different types of graphs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ADT graph
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Representation of graphs in memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traversal of a graph
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cycle detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spanning trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimum spanning trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is a graph?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A graph is a collection of vertices and edges that connect the vertices. *Figure
    1* gives a visual representation of an example of a graph. There are a few features
    to note here, which we will discuss next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What is a graph?](img/00070.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Example of an undirected graph'
  prefs: []
  type: TYPE_NORMAL
- en: '**Undirected graph**: An undirected graph is a graph in which the edges have
    no direction, as shown in *Figure 1*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Directed graph**: This is a graph in which the edges have a direction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Path**: A path is a sequence of edges that connects a set of vertices that
    are distinct from one another, except the first and the last vertices as they
    may be the same. For example, in *Figure 1*, the edges **AB**, **BD**, and **DE**
    represent a path. It can also be described as the **ABDE** path, which does not
    repeat its vertices. In the case of a directed graph, the edges must traverse
    only in the specified direction to form the sequence of edges required to make
    a path.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cycle**: A cycle is a path with at least two vertices involved; it starts
    and ends on the same vertex. For example, in *Figure 1*, the path **DCED** is
    a cycle.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Loop**: A loop is an edge that connects a node to itself. In *Figure 1*,
    vertex **A** has a loop.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Subgraph**: The subgraph of a graph is another type of graph where all the
    edges and vertices are the same as the edges and vertices of the original graph.
    For example, in *Figure 1*, the nodes **A**, **B**, and **C** along with the edges
    **AB** and **BC** represent a subgraph.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Connected graph**: A connected graph is a graph in which there exists a path
    that starts from any arbitrary vertex and ends in any arbitrary, but different
    vertex. The graph in *Figure 1* is not connected. But, the subgraph with vertices
    **H**, **I**, and **J** and the edges **HI**, **IJ**, and **JH** represent a connected
    subgraph:![What is a graph?](img/00071.jpeg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure 2\. Example directed graph
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Tree**: A tree is a connected but undirected graph with no cycles and loops.
    *Figure 3* shows an example of a tree. Note that this is slightly different from
    the tree we have studied earlier. This tree does not have any particular root.
    The nodes in this tree do not have any particular parent, and any node can act
    as a root:![What is a graph?](img/00072.jpeg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure 3\. Example tree
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Forest**: A forest is an unconnected, undirected graph with no cycles or
    loops. You can think of a forest as a collection of trees. A single tree is also
    a forest. In other words, a forest is a collection of zero or more trees.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Complete graph**: A complete graph is an undirected graph that has the maximum
    number of edges, given a certain number of vertices. It also has constraints as
    per which there can only be one edge between two given vertices, with no loops.
    *Figure 4* shows an example of a complete graph. For a complete graph with the
    set of vertices *V* and the set of edges *E*, *|E| = |V| ( |V| - 1) / 2*. It is
    easy to see why this is the case. Each vertex will have an edge between itself
    and other *|V| - 1* nodes. That makes a total of *|V| ( |V| - 1)* edges. However,
    in this approach, each edge is counted twice, once for each of its two vertices.
    So, the actual number of edges in a complete graph is *|V| ( |V| - 1) / 2*:![What
    is a graph?](img/00073.jpeg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure 4\. A complete graph
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The graph ADT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will now define what a data structure representing a graph should do. Later,
    we will discuss the different implementations of this ADT. A graph must support
    the following operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Add Vertex**: This adds a new vertex'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Remove Vertex**: This removes a vertex'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Add edge**: This adds a new edge; in our graph, we will allow a maximum of
    one edge between two vertices for simplicity'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Remove edge**: This removes an edge'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adjacent**: This checks whether the two given vertices are adjacent to each
    other, that is, whether there is an edge between the given nodes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neighbors**: This returns a list of vertices that are adjacent to the given
    vertex'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Get Vertex Value**: This gets the value stored in a vertex'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Set Vertex Value**: This stores a value in a vertex'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Get Edge Value**: This gets the value stored in an edge'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Set Edge Value**: This sets the value stored in an edge'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Is undirected**: This returns whether the graph is undirected'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Get all vertices**: This returns a self-balancing binary search tree containing
    all the vertices'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Max Vertex ID**: This returns the highest ID of the vertices'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our algorithms will depend on the above operations being available in a graph
    data structure. The following Java interface is a realization of this ADT:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We identify each vertex by an ID; edges are identified by a source vertex and
    a target vertex. In the case of an undirected graph, the source and target could
    be interchanged. But, in the case of a directed graph, they are noninterchangeable.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have an ADT, we would like to have an implantation. To implement
    a graph data structure, we need to choose a representation in memory.
  prefs: []
  type: TYPE_NORMAL
- en: Representation of a graph in memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A graph can be represented mainly in three different ways: adjacency matrix,
    adjacency list, and incidence matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: Adjacency matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An adjacency matrix is a matrix, a table of values, where each value represents
    an edge and both the rows are the columns that represent the vertices. The values
    in a matrix can be the members of the entry. The values of the edges can be stored
    in the matrix itself. There could also be a special value for representing the
    absence of an edge. The following image shows an adjacency matrix for the graph
    in *Figure 1*, where the value of the edge represents the number of edges between
    the corresponding vertices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Adjacency matrix](img/00074.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following things can be noted about an adjacency matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: Rows are used to represent the sources and columns to represent the targets
    of the edges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the case of an undirected graph, the source and target are indistinguishable,
    so the adjacency matrix is symmetric
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code provides an implementation of the graph ADT with the adjacency
    matrix. We use a two-dimensional array to store the matrix. The ID of any vertex
    is directly used as the index of the array. This is true for both the array to
    store the values stored within the vertices and the values stored in the edges,
    or even the existence of the edges. When we remove a vertex, we don''t free its
    space; we do this so that the IDs of the newer vertices don''t get shifted. This
    improves lookup performance but is wasteful in terms of resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We create two special objects to signify an edge and a vertex; these objects
    do not yet hold a value. A null reference refers to the edge or vertex that does
    not exist:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'A flag determines whether the graph is undirected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding a vertex involves creating a new matrix and an array of vertex values
    and copying all the older values into it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we don''t free any space, removing a vertex simply involves setting values
    to null. Note that removing a vertex has to be accompanied by the removal of all
    the associated edges, which is done in a loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding an edge involves setting a particular position in the adjacency matrix.
    If the graph is undirected, there will be two updates. This is because the source
    and target could be interchanged and the adjacency matrix is always symmetric:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following operation is the simplest of all as it involves setting only
    one edge to null. In the case of an undirected graph, there would be a corresponding
    update that would interchange the source and target:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is a trivial operation of checking the adjacency matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'For any given source, find all the edges in the same row of the matrix and
    add them to a linked list that we can return. Note that in a directed graph, it
    traverses the edges only in the forward direction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We store all the values of the vertices in a different array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The values stored in the edges can be stored in the adjacency matrix itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Complexity of operations in a sparse adjacency matrix graph
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now let''s analyze the complexity of the operations we have already discussed:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Add vertex**: Adding a vertex requires us to create a new two-dimensional
    array with length and w the complexities of the idth *|V|* and then copy the entire
    old content to the new array. Here, *|V|* represents the cardinality of the set
    *V* of the vertices. What is the size of the adjacency matrix then? It''s a square
    matrix whose length or width equals *|V|*, so its size is *|V|*². Hence, adding
    a new edge has this complexity: *θ(|V|*²*)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Remove Vertex**: Removing a vertex involves removing all the edges that correspond
    to the given vertex. The maximum number of edges that can be associated with a
    single vertex is *|V|*, which is the length of a row or column in the adjacency
    matrix. We must set all the values in the row and column containing the vertex
    being deleted, so the number of values that need to be changed is calculated as
    *2|V| - 1*. The "minus one" part comes from the fact that the row and column have
    one edge in common, the edge representing a loop on the node that is being deleted.
    The common edge is counted twice, both in the row and the column. So one of them
    must be stopped. Therefore, the complexity of this operation is *θ(2|V| - 1) =
    θ(|V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Add edge and Remove edge**: Adding an edge is as simple as setting a special
    value at a single entry in the adjacency matrix. It has this complexity: *θ(1)*.
    Removing an edge is just setting null at the same position.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adjacent**: This operation involves checking whether an edge exists between
    the given source and target. It checks one entry in the adjacency matrix, hence
    this complexity: *θ(1)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neighbors**: This operation requires reading all the values in the row of
    an adjacency matrix. So it requires reading *|V|* values and possibly adding them
    to a linked list. Therefore, the complexity of this operation is *θ( |V| )*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Setting and getting values at vertices and edges**: These operations require
    reading/setting a single value into/from the adjacency matrix. These operations
    are all *θ(1)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Get all vertices**: This involves scanning through all the vertices and inserting
    them in a binary search tree. So this operation is *θ( |V| lg |V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More space-efficient adjacency-matrix-based graph
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The trouble with the above graph implementation is that we are unable to recover
    any space when vertices are deleted. The problem with recovering space is that
    it changes the indexes of the vertices that are added later. To avoid this, we
    can choose to have an ID of a vertex that is separate from its index position
    in the arrays. If we do this, we need to be able to search the index of a vertex
    with the given ID. This mapping can be done with a self-balancing binary search
    tree, which is what we are going to do here.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we create a separate class that represents a graph vertex. The idea
    is to allow a comparison to exist on the ID of a vertex. Different graph implementations
    can then extend this class to accommodate additional data in the graph vertex:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'With this class available, we can implement our adjacency-matrix-based graph
    implementation with a dense vertex and edge representation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we extend the `GraphVertex` class to include an `addition` field that
    stores the index of a vertex in the adjacency matrix as well as in the array meant
    for storing the values of the vertices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The `nextId` variable is used to store the next ID that would be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Special values to represent empty vertices and edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the binary search tree that stores the vertices with their
    indexes in the arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The process of adding involves the same operations as before apart from the
    extra operation of generating a new ID and storing an entry in the search tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The removal of a vertex now actually involves creating a smaller adjacency
    matrix and copying all the edges, except the ones associated with the vertex that
    is being deleted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'First, copy all the rows before the one for the vertex being deleted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, copy all the rows after the one for the vertex being deleted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now adjust all the indexes of the vertices added after the one that is deleted.
    We do this by traversing the tree in preorder and updating only when appropriate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding an edge involves setting an entry in the adjacency matrix. However,
    before doing this, we need to look up the index of the vertex:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the same as adding an edge, other than the fact that we change the
    corresponding entry in the adjacency matrix to null:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Checking whether two vertices are adjacent involves looking up a value in the
    adjacency matrix like before. But again, we must first look up the indexes of
    the vertices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Getting the list of neighbors is a little trickier. We don''t have a search
    mechanism that lets us search by index to look up the ID. So instead of reading
    a row in the adjacency matrix, we simply preorder traverse the search tree and
    check whether there is an edge for the vertex in the adjacency matrix. We add
    a vertex only when there is an edge between the source vertex and the vertex in
    question:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The process of setting and getting values into/from the edges and vertices
    is the same as before, except that we need to look up the index from the ID of
    the vertex before using it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Complexity of operations in a dense adjacency-matrix-based graph
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following are the complexities of the operations we just discussed in a
    dense adjacency-matrix-based graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Add vertex**: Addition still has the same *θ(|V|*²*)* operation for creating
    a new adjacency matrix and copying all the old values. The additional operation
    of inserting a new vertex in the search tree is *θ(lg |V|)*. So the entire operation
    is still *θ(|V|**2**)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Remove vertex**: The removal of a vertex here follows the same operation
    of recreating an adjacency matrix and copying all the old values, which is *θ(|V|*²*)*.
    The operation of removing a vertex from the search tree is *θ(lg |V|)*. So the
    entire operation is *θ(|V|*²*)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Add edge and remove edge**: The operation of updating an entry in the adjacency
    matrix is still *θ(1)*. However, now we need to have two lookups in the search
    tree to figure out the indexes of the source and target. Both these searches are
    *θ(lg |V|)*. So the entire operation is *θ(lg |V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adjacent**: This is also *θ(lg |V|)* due to the same reason mentioned in
    the preceding bullet point.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neighbors**: Traversing the search tree is *θ(|V|)*, and for each of the
    vertices thus traversed, we create a constant number of operations. Looking up
    the index of the source vertex is *θ(lg |V|)*. Hence, the entire operation is
    still *θ(|V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Setting and getting values at vertices and edges**: These operations require
    a fixed number of lookups (one or two) and then a constant time operation for
    setting or getting the appropriate value. The lookups are *θ(lg |V|)*, so the
    entire operations are also *θ(lg |V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Get all** **vertices**: Just like the previous implementation, this operation
    is *θ( |V| lg |V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adjacency list
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An adjacency list is a more space-efficient graph representation of sparse graphs.
    A sparse graph is a graph that has a very few edges as compared to the number
    of edges in a complete graph with the same number of vertices. A complete graph
    has *|V| ( |V| - 1) / 2 = θ (|V|* *2* *)* edges, and the memory space required
    to store a graph as an adjacency matrix is also *θ (|V|* *2* *)*. So, in the case
    of a dense (almost complete) graph, it makes sense to store it as an adjacency
    matrix. However, this is not true for a sparse graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'In an adjacency list representation, vertices are stored in an array or some
    other data structure, and edges are stored along with the vertices in some list
    or some other structure. First, we will consider an adjacency-list-based representation
    where the vertices are stored in an array indexed by their IDs, as in the case
    of a sparse adjacency matrix representation. It has the same problem: we cannot
    reduce the size of the array of vertices when a vertex is deleted. However, in
    this case, the list of edges are deleted, and this makes it way more space-efficient
    than what we encountered in an adjacency matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Edge` class stores the details of the target and the value of an edge
    originating from a vertex. The vertex stores a collection of the associated edges.
    We make the edge comparable based of the ID of the target so that we can store
    them in a binary search tree to easily look it up based on the ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'To improve the performance of the `getNeighbors` operation, we store a list
    of neighbors in the node. We store a pointer in the node that corresponds to the
    target of this node in the `targetNode` state variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Vertex` class is used to store a vertex along with its associated edges.
    The edges are stored in a red black tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The vertices are then stored in an array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding a vertex does not require us to copy any edges; it just ensures that
    the vertices are copied to a newly created array of bigger size:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Removing a vertex requires that you first set the vertex to null at its position.
    However, you must also remove all the edges from all the other vertices for which
    the deleted vertex was the target:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We must remove all the edges associated with the vertex being deleted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding an edge requires making corresponding entries in the vertices associated
    with it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Removing an edge requires removing the corresponding entries in the associated
    vertices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Checking adjacency involves looking up the source vertex first and then looking
    up an edge for the target in the corresponding red black tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We have the list of neighbors precomputed, so we simply return this list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The process of setting and getting the values of a vertex or an edge are self-explanatory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Complexity of operations in an adjacency-list-based graph
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following lists the complexities of the operations we have discussed in
    an adjacency-list-based graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Add vertex**: Addition of a vertex requires that you create a new array first
    and then copy all the vertices to it. So it is *θ(|V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Remove Vertex**: The removal process does not change the array of the vertices.
    However, this operation involves checking each vertex to remove the edges which
    has the vertex being deleted as the target. So this operation is *θ(|V|)* as well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Add edge and remove edge: The first step of this operation is to look up the
    source vertex, which is constant time. The second step is to add or remove an
    edge in a red black tree, so it is *θ(lg |V|)*. So the entire operation of adding/deleting
    an edge is *θ(lg |V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adjacent**: The first step of this operation is to look up the source vertex,
    which is constant time. The second step is to look up the edge in a red black
    tree, so it is *θ(lg |V|)*. So the entire operation of adding/deleting an edge
    is *θ(lg |V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neighbors**: Since the list of neighbors is precomputed, the complexity is
    the same as that for looking up a vertex, which is constant time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Setting and Getting values at vertices**: These operations require looking
    up the vertex first, which is constant time. The second step is setting/getting
    the value. These operations are *θ(1)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Setting and Getting values at edges**: These operations require looking up
    the source vertex first and then looking up the particular edge. The first is
    *θ(1)* and the second is *θ(lg |V|)*. At the end, setting or getting the value
    of an edge is *θ(l)*. Hence, the total operation is *θ(lg |V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Get all vertices**: This operation is *θ( |V| lg |V| )*, just like the previous
    implementations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adjacency-list-based graph with dense storage for vertices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Just as in the case of an adjacency-matrix-based graph, dense storage of vertices
    can be done using a search tree instead of an array. This allows us to recover
    space when we delete a vertex without affecting the IDs of the other vertices.
    Everything else remains the same as the array-based storage of the vertices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The `nextId` variable stores the value that would be the ID of the next vertex
    that is inserted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'We have the `Edge` and `Vertex` class as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, instead of using an array to store the vertices, use a red black tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding a new vertex means inserting a new one in the red black tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The removal process, as before, involves not only removing the vertex but also
    going through all the other vertices and deleting every edge that has the vertex
    that is being deleted as the target:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The first step is to find the source and the target node to confirm that they
    exist. After this, add an edge to the collection of edges of the source node.
    If the graph is undirected, add an edge to the collection of edges in the target
    node as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The first step is the same as that of the previous one. After this, the edge
    is removed from the collection of the edges of the source node. If the graph is
    undirected, the edge is also removed from the collection of edges in the target
    node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The first step is the same as that of the previous one. After this, the edge
    with the correct target is looked up. If the edge is found, the vertices are adjacent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'We just look up the vertex and then return our precomputed list of neighbors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The process of setting and getting values is the same as before, except that
    we need to look up the vertex/vertices in the red black tree instead of the array
    before setting up the values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Complexity of the operations of an adjacency-list-based graph with dense storage
    for vertices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The complexity of the operations of an adjacency-list-based graph is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Add vertex**: Addition of a vertex requires insertion of one in the red black
    tree. So this operation is *θ(lg |V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Remove Vertex**: The removal process requires deletion of the vertex from
    the red black tree, which is *θ(lg |V|)*. However, this operation involves checking
    each vertex to remove the edges which has the vertex being deleted as the target.
    So this operation is *θ(|V|)* as well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Add edge and remove edge**: The first step of this operation is to look up
    the source vertex, which is *θ(lg |V|)*. The second step is to add or remove an
    edge to/from a red black tree, so this is also *θ(lg |V|)*. Therefore, the entire
    operation of adding/deleting an edge is *θ(lg |V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adjacent**: The first step of this operation is to look up the source vertex,
    which is *θ(lg |V|)*. The second step is to look up the edge in a red black tree,
    which is *θ(lg |V|)* too. Therefore, the entire operation of adding/deleting an
    edge is *θ(lg |V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neighbors**: The list of neighbors is precomputed, so the complexity of this
    operation is the same as that of searching a vertex, which is *θ(lg |V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Setting and getting values at vertices**: These operations require you to
    first look up the vertex, which is *θ(lg |V|)*. The second step is to set/get
    the value. These operations are *θ(lg |V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Setting and getting values at edges**: These operations require you to first
    look up the source vertex and then the particular edge. Both of these operations
    are *θ(lg |V|)*. At the end, setting or getting the value of an edge is *θ(l)*.
    Hence, the total operation is *θ(lg |V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Get all vertices**: Here too, this operation is *θ( |V| lg |V|)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traversal of a graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The traversal of a graph is the graph's equivalent of the traversal of a tree,
    as discussed in an earlier chapter. Just as in the case of a tree, we can traverse
    either breadth-first or depth-first. However, unlike a tree, a graph can reach
    all the vertices without going through the edges. This makes it necessary to consider
    the traversal of all the edges and vertices separately. Another thing is that
    a graph has no designated root, so we can start from any particular vertex. Finally,
    since a graph may not be connected, we may not be able to traverse all the vertices/edges,
    starting from one single vertex. This is achieved by performing the traversal
    repeatedly, starting each time from any vertex that has not been visited yet already.
    This is a simple extension of the basic breadth-first or depth-first traversal
    that we are going to discuss here.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s discuss visiting vertices using both the breadth-first and depth-first
    search. It involves maintaining two collections of vertices: one that stores all
    the vertices that are discovered but are yet to be visited/explored and another
    that stores a Boolean array that checks whether a vertex has already been explored/visited.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The collection of vertices that are discovered but yet to be explored can be
    of two types: if it is a stack, we have a depth-first traversal, and if it is
    a queue, we have a breadth-first traversal.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To implement both depth-first and breadth-first searches in a single method,
    we need to create a super interface of our `Stack and Queue` interfaces. We will
    need to define three methods in it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Now implement these methods in the `Stack` and `Queue` interfaces as default
    methods to delegate to their appropriate methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'This allows us to use the `OrderedStore` interface to hold both a stack and
    a queue. We also create a new functional interface that represents a lambda that
    takes two arguments and does not return anything:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: We implement this search as a default method in the Graph interface itself.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'In the beginning, we only insert the starting vertex to the collection of vertices
    that are not yet explored. Then, we loop until all the vertices that can be discovered
    in the search are processed and there are no more elements in the collection of
    vertices. We avoid processing each vertex from the collection of vertices if it
    has already been processed. Otherwise, we mark it as "being processed" and invoke
    the visitor on it. Finally, we expand this vertex by inserting all its neighbors
    to the collection of elements that have to be processed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The process of traversal of edges is also very similar; we can follow either
    the breadth-first or depth-first traversal. In this case, the visitor needs access
    to both the source and target of the edges, which makes it necessary to store
    both of them in the stack or queue we use. For this purpose, we create a class
    named `Edge`. The class is comparable so that edges can be stored in a binary
    search tree for easy search ability:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can implement the process of traversal of edges using the breadth-first
    and depth-first traversal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Complexity of traversals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For each traversal, either all vertices or edges, all edges must be traversed.
    This is true even if you just want to visit the vertices. The actual complexity
    depends on the particular map implementation, so we will use that the complexity
    of the operation `getNeighbors` method is *θ(g(|V|))*.
  prefs: []
  type: TYPE_NORMAL
- en: If you're visiting either the edges or vertices, ensure that each vertex is
    expanded only once. This operation is done *|V|* times, each of which is *θ(g(|V|))*.
    So the complexity, due to the expansion of the vertex, to find out the neighbors
    is *θ(|V|g(|V|))*. When expanded, they are visited once, and for each edge, we
    have one neighbor. Some of these neighbors have been visited before; however,
    we need to perform constant time to verify this. So each vertex is visited once
    and each neighbor is checked once. This changes the complexity to *θ(|V|g(|V|)
    + |E| )*. Since we have seen an implementation of a graph that has the constant
    time `getNeighbors` method, we can have a traversal in *θ(|V| + |E| )*.
  prefs: []
  type: TYPE_NORMAL
- en: Cycle detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the uses of a traversal is cycle detection. A connected undirected graph
    without any cycle is a tree. A directed graph without any cycle is called a directed
    acyclic graph (DAG). Cycle detection in graphs can be done in a very similar manner.
    In the case of an undirected graph, if we do a DFS and the same node is visited
    twice as the target of an edge, there is a cycle. Since the edge is undirected,
    we are satisfied if either the source or the target has not been seen before.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of a directed graph, visiting the same node twice is not enough
    if you want to know whether there is a cycle; we should also consider the direction
    of the edges. This means while traversing the edges, we need to know whether we
    can reach the same node we started with. This requires us to remember the entire
    path while doing a DFS. This is why we use a recursive helper method to detect
    a cycle in a directed graph. We create the helper method for the directed cycle
    first. The `checkDirectedCycleFromVertex` method takes the path and binary search
    tree of the vertices. The list of vertices is the one that stores all the vertices,
    and the ones already visited must be removed so that they are not used as the
    starting point of cycle detection later. The list of integers is the path from
    the starting point in a depth-first traversal. If a vertex is repeated in the
    same path, it means a cycle exists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The head of the list is the deepest vertex in the path; we need to expand this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Now if any neighbor is already present in the path, a cycle exists, which is
    what we check. If a cycle is found, we throw an instance of a custom exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we create the method for detection of cycles in either type of graph. Go
    through all the vertices as there might be unconnected parts of the graph. A directed
    graph may have connected vertices that cannot be reached from a particular starting
    vertex due to the directionality of the edges. However, once a vertex is visited
    in any traversal, it does not need to be visited again. This is taken care of
    by having all the vertices in a binary search tree and removing the ones that
    have been visited already:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we get a list of all the vertices. We get it directly by understanding
    how the vertices are stored inside the graphs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Complexity of the cycle detection algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let's check out the complexity of cycle detection in an undirected graph.
    The complexity of `getAllVertices` is *Ө* *(|V| lg |V|)*. Looking up a vertex
    in the search tree of vertices that have already been visited is *Ө* *( lg |V|
    )*. We do this twice for every edge. We also have to insert a new vertex in the
    `metAlready` search tree and delete a vertex from the `allVertices` search tree;
    the complexity of these operations for each edge is *Ө* *( lg |V| )*. So the total
    complexity is *Ө* *(|E| lg |V| )*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s consider the complexity of cycle detection in a directed graph.
    Here, we traverse each edge once. However, for each edge, we have to look through
    the entire path to know whether the current vertex is seen in the path. The path
    can potentially be of this length: *|V| - 1*. So when we check it for each edge,
    the complexity is *O(|E||V|)*; this is a lot higher than *O(|E|lg |V|)*.'
  prefs: []
  type: TYPE_NORMAL
- en: Spanning tree and minimum spanning tree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A spanning tree in a connected graph is a subgraph consisting of all the vertices
    and some edges. So, a subgraph is a tree; it is a connected graph with no loops
    or cycles. *Figure 5* shows an example of a spanning tree in a graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Spanning tree and minimum spanning tree](img/00075.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5\. A spanning tree of a graph (shown in red)
  prefs: []
  type: TYPE_NORMAL
- en: A tree has minimum number of edges required to keep the vertices connected.
    Removing any edge from a tree will disconnect the graph. This can be useful in
    a map of roads that connect different places and has a minimal number of roads.
    With this motivation, we would really be interested in a spanning tree that has
    a minimum total length of roads. This may be important because constructing roads
    is a costly affair. Alternatively, we could design a bus route map for a city
    and have all the important places connected without creating too many routes;
    also, shorter routes are better. Such a spanning tree is called a minimum spanning
    tree. Finding a minimum spanning tree is an important problem. But before we discuss
    the algorithm, let's see some of the properties of a minimum spanning tree.
  prefs: []
  type: TYPE_NORMAL
- en: For any tree with vertices V and edges E, |V| = |E| + 1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, let''s consider this proposition: removing any edge from a tree will
    create two trees with no connection between them. Let''s assume the opposite.
    We have a graph with two vertices A and B and an edge X between them. Let''s assume
    that even if we remove X, the tree still remains connected. This means a path
    P exists between A and B even if you delete X. This means in the original graph,
    we can walk from A to B through P and use X to come back to A. This means the
    original graph has a cycle. But the original graph was assumed to be a tree, so
    this is impossible. Therefore, my original proposition that removing any edge
    from the tree will create two trees with no connection between them is true.'
  prefs: []
  type: TYPE_NORMAL
- en: Now let's start with a graph G that has a set of edges E and vertices V. If
    we remove all the edges, we would of course be left with only V. These set of
    vertices without edges are actually single vertex trees with no connections between
    themselves.
  prefs: []
  type: TYPE_NORMAL
- en: We start with one tree, say G, and remove one edge. Now we have two trees. We
    can now remove another edge, and this will split one of these trees into two so
    we have three trees. This way, after the removal of each edge, we will have one
    more tree. Therefore, after the removal of all the edges, we will have *|E| +
    1* trees (because there was one tree before any edge was removed). These must
    be *|V|* single vertex trees. So, it is either *|V| = |E|+1* or *|E| = |V| - 1*.
  prefs: []
  type: TYPE_NORMAL
- en: Any connected undirected graph has a spanning tree
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s take an undirected graph. If there are loops and cycles. First, we simply
    delete all the loops. Consider A and B as two vertices that are neighbors and
    part of a cycle. This means if we walk through the edge from A to B, we can use
    another path: B to A (this is what makes it a cycle). So if we delete the B to
    A edge, we will still have a connected graph. We do this operation for every cycle.
    At the end of these operations, we will have a connected graph with no loops or
    cycles; this is a tree. This tree connects all the vertices, so it is a spanning
    tree.'
  prefs: []
  type: TYPE_NORMAL
- en: Any undirected connected graph with the property |V| = |E| + 1 is a tree
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now let's check the reverse of the preceding theorem. Suppose there is a connected
    graph where *|V| = |E| + 1*. We assume it is not a tree. This graph must have
    a spanning tree, which is a subgraph, with fewer edges. This spanning tree will
    have the same number of vertices (because we never deleted any vertices) but fewer
    edges. Therefore, if the spanning tree has the set of edges *E* ¹, we have *|
    E* ¹*|| < |E| => | E* ¹*|| + 1 < |E| + 1 => | E* ¹*|| + 1 < |V|*. But this is
    not possible because the new graph is a tree. So the original proposition that
    any undirected connected graph with the property *|V| = |E| +1* is a tree.
  prefs: []
  type: TYPE_NORMAL
- en: Cut property
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cut refers to a minimum set of edges that when removed would split a connected
    undirected graph into two separate connected graphs with no connections between
    them. There can be many cuts in a given graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'The cut property can be defined as this: if an edge is an element of a cut
    and has a minimum cost associated with it within the cut, it is part of the minimum
    spanning tree of the graph. To check this out, first note that for any cut of
    an undirected connected graph, a spanning tree will always have exactly one member
    of the cut in it.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's have a cut X that divides the graph G into subgraphs H and J. Let G have
    a spanning tree called S. Since G is a connected graph and X is a cut, this means
    H and J are connected with each other. If X is empty, it means G was not connected;
    this is not possible. Now we have the Y subset of X where all the members of Y
    are part of the spanning tree S. If Y is empty, the vertices of H and J will be
    disconnected in S, so this is impossible. Now as a contradiction to *|Y| = 1*,
    let's assume *|Y| > 1*. This means there is more than one edge in S, between H
    and J. Let's pick two of them. Let the first is between vertex A in H and vertex
    B in J, and the second one between vertex C in H and vertex D in J. Now since
    the spanning tree S has all the vertices of H and J connected, there is a path
    from A to C and D to B in S outside of Y. So we have a cycle from A to C and C
    to D using one of our selected edges and we have D to B and B to A using the other
    selected edge. This means S has a cycle and hence S is not a tree, which is a
    contradiction. Therefore, *|Y| = 1*. Thus, the spanning tree has exactly one member
    of any cut in an undirected connected graph.
  prefs: []
  type: TYPE_NORMAL
- en: If S is the minimum spanning tree of G and X is a cut in G dividing G into H
    and J, S has exactly one member for X, as proved in the preceding section. Let
    it be any edge other than the one with minimum cost. Since S is a spanning tree,
    if we remove the edge that is in X, we will have two disconnected subtrees, which
    are spanning trees of H and J. If we insert any other edge from X now, this new
    edge will connect these subtrees back to the single spanning tree. This is because
    all the edges of X are between one vertex in H and another in J. So we can replace
    the edge in S that is a member of X along with the edge in X with minimum cost,
    and we can thus create another spanning tree of G. But the edges of the new tree
    will be the same as in S, except the one that has a lesser cost than the one in
    S. So the sum of the costs of edges of the new spanning tree must be lesser than
    that of S, which is a contradiction as S is a minimum spanning tree. Therefore,
    the minimum spanning tree S must have an edge with the least cost within the cut
    X.
  prefs: []
  type: TYPE_NORMAL
- en: Minimum spanning tree is unique for a graph that has all the edges whose costs
    are different from one another
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s assume that we have a connected undirected graph G for which there are
    two different minimum spanning trees, namely S and T. Since S and T are different
    and have the same number of edges (because for a spanning tree, the calculation
    is *|V| = |E| + 1*), there is an edge E in S that is not in T. Let this edge be
    there between the vertices A and B. Now let''s create a partition of the set of
    vertices in G so that there are two partitions: Y and Z. Create this such that
    A belongs to Y, B belongs to Z, and Y and Z are disjointed and together contain
    all the vertices. Let X be the cut that would divide G into two subgraphs with
    vertices in Y and Z. Since A belongs to Y and B belongs to Z, the edge E between
    A and B belongs to X. Since X is a cut and S is a spanning tree, there must be
    exactly one edge in X that is part of S; in this case, it has to be the edge E.
    Now, since T is also a spanning tree and E is not a member of T, there must be
    another member of X that is in T; let it be **f**.'
  prefs: []
  type: TYPE_NORMAL
- en: If we remove the edge E from S, we will have two different trees, which would
    be joined again if we insert f. This is because f is an edge between the vertices
    in Y and Z, and the two parts are already trees. So now we are left with another
    spanning tree.
  prefs: []
  type: TYPE_NORMAL
- en: All the costs are different; the cost of E is different from the cost of f.
    If the cost of f is lower than that of E, the total cost of the new spanning tree
    is lower than that of S. Although, this is not possible because S is a minimum
    spanning tree. So, the cost of f is higher than that of E.
  prefs: []
  type: TYPE_NORMAL
- en: We can do this for every edge in S that is not in T; S will transform into T
    when no more edges are available. In every step of this process, the total cost
    of edges will increase. This means the total cost of edges in T must be higher
    than that in S. However, this is impossible because S and T are both minimum spanning
    trees. So our original assumption that there can be two different minimum spanning
    trees is wrong. Therefore, each minimum spanning tree is unique in a graph where
    all the costs of the edges are different.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the minimum spanning tree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the properties we just discussed, we can now define an algorithm for finding
    the minimum spanning tree of a graph. Suppose a set of edges F is already given
    and they are members of the minimum spanning tree G. Now we are trying to find
    another edge that is also a member of the minimum spanning tree. First, we choose
    an edge e whose cost is minimum when compared to the rest of the edges, E and
    F in this case. Since some of the edges are already given, some of the vertices
    are already connected. If the chosen edge e is between two vertices that are already
    connected, we simply reject this edge and find the next edge with minimum cost.
    We do this until we find an edge f between two vertices that are not already connected.
    Our claim is that f is a new member of the minimum spanning tree. To confirm this,
    let''s assume that f is between the vertices A and B. From the description of
    our procedure, A and B are not connected. Let''s make two partitions of the vertices:
    H and J. Let''s have all the vertices that are connected to A, including A in
    H, and all the vertices connected to B, including B in J. The rest of the vertices
    are assigned to the set H. Since H and J are partitions of the vertices in the
    original graph G, we have a cut X in the original graph G that splits the graph
    G in a way that all the vertices in H are placed in one of the subgraphs and all
    the vertices in J in the other. We know that the member of X that has the minimum
    cost is a member of the minimum spanning tree G. Now, of course, f is a member
    of X as it connects A to B. It is also the edge with the minimum cost among all
    the edges in X. This is because all the edges in X are in the remaining edges
    (otherwise some vertices in H and some in J would be connected, which cannot be
    true because of the way we have created the two sets), and f is the minimum cost
    in all the remaining edges. This means f is a new member of the spanning tree.
    Therefore, we use the following steps to build the minimum spanning tree:'
  prefs: []
  type: TYPE_NORMAL
- en: Start with an empty set of edges as the spanning tree.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If more edges are remaining and all the vertices are not connected, choose the
    one with the minimum cost.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the edge is between two connected vertices, discard it and go back to step
    2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Otherwise, add the edge to the set of edges of the minimum spanning tree.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat from step 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The problem now is how to efficiently know whether the two vertices are connected.
    The solution is a data structure called a union set forest.
  prefs: []
  type: TYPE_NORMAL
- en: Union find
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The purpose of union find is to be able to tell whether the two given objects
    are members of the same set. This data structure allows you to first specify all
    the members of a universal set and then specify which ones are members of the
    same partition, thus joining the two partitions to make a single partition. It
    represents a collection of partitions of the universal set, and it lets us query
    whether the two members of the universal set are members of the same partition.
  prefs: []
  type: TYPE_NORMAL
- en: A tree is kept in an opposite pointer form, that is, the child knows its parent;
    however, the parent does not have any pointers to the children. The idea is to
    have connected values in the same tree. Each tree in a forest has a representative
    node that is its root. If two nodes have the same representative roots, they are
    in the same partition; otherwise, they are not.
  prefs: []
  type: TYPE_NORMAL
- en: 'This data structure has three important operations:'
  prefs: []
  type: TYPE_NORMAL
- en: Add a new object to the universal set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Union two objects**: This will result in the partitions those objects belong
    to joining together to make a single partition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Find**: This will return the representative object of the partition that
    the object passed belongs to. If the result of the find operations of two different
    objects is the same, the object would belong to the same partition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is an implementation of a `Union` find that can hold comparable
    objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Each node holds a reference to its parent. If there is no parent, that is,
    if the node is the root of its tree, the parent is null. All nodes also store
    its rank, which is the height of the tree rooted by itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'All the nodes are stored in a red black tree so they have a logarithmic search:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Additionally, we want to keep a count of the number of partitions available:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The `add` operation adds a new object to the universal set, which is implemented
    using a red black tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'This is an internal method that traverses the parents one by one until it finds
    the root of the tree that the object passed belongs to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '![Union find](img/00076.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6\. Union operation in a union find forest. The partitions it represents
    are shown on the side.
  prefs: []
  type: TYPE_NORMAL
- en: 'The union operation merges two trees. This is achieved by setting one of the
    roots of the two trees as the parent of the root of the other tree. When merging
    two trees of unequal height, the root of the taller tree is set as the parent
    of the root of the shorter tree; otherwise, any one of the two is chosen as the
    root. The rank of the root increases only when two equal trees are merged. When
    unequal trees are merged, the height of the merged tree is the same as the height
    of the taller tree. *Figure 6* shows the union operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The `find` operation involves looking up the node related to the object first
    and then finding the root node. The object contained in the root node is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: Complexity of operations in UnionFind
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let's consider the complexity of finding the root node of any node; this
    is an internal operation. The complexity of this operation is *θ(h)*, where *h*
    is the height of the tree. Now what is the upper bound of the height of the tree?
    Let *f(h)* be the minimum number of nodes in a tree of height *h*. Trees are always
    created by merging two smaller trees. If the trees being merged have unequal heights,
    the height of the merged tree is the same as the taller of the two initial trees,
    and now it has more nodes than the original taller tree. This is not the way to
    create the worst tree, which is the tree with minimum nodes with the same height.
    The worst tree must be created by merging two equal trees, both of which are worst
    trees themselves. After you merge them, the height of the merged tree is one more
    than the height of either of the trees being merged. So, for creating a worst
    tree of height *h+1*, we must merge two worst trees of height h. The operation
    to do this is *f(h+1) = 2 f(h)*. So, if *f(0) = C*, where *C* is some constant,
    *f(1) = 2C, f(2)=4C, …, f(h) = 2* ^h *C*. Therefore, if the number of nodes is
    *n*, then *n ≥ f(h) = 2* ^h *C => lg n ≥ lg (2* ^h *C) = h + lg C => h ≤ lg n
    – lg C => h = O(lg n)*. This means the complexity of finding the root of a given
    node is also *O(lg n)*.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a new object involves inserting a new node in the red black tree, so
    the complexity is *θ(lg n)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Find**: This operation involves looking up the node that corresponds to the
    object first. This is a search operation in the red black tree; hence it is *θ(lg
    n)*. After this, it involves looking up the root of this node, which is *O(lg
    n)*. And at the end, we return the object in the node, which is constant time.
    Hence, the complexity of the entire find operation is *θ(lg n)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Union involves three operations. The first is to search the nodes for the objects,
    which is *θ(lg n)*. The second is to find the roots of each of the trees associated
    with the nodes, which is also *O(lg n)*. And finally, it involves the merging
    of the trees, which is a constant time operation. So the complexity of the entire
    operation is *θ(lg n)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation of the minimum spanning tree algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now we can implement our minimum spanning tree algorithm. First, we create
    a class that we will use for the implantation. The `CostEdge` class represents
    an edge along with its cost. The `compareTo` method is overridden to compare the
    costs instead of IDs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'The argument `costFinder` is a lambda that returns the cost of an edge from
    the value that is stored in it. `edgeQueue` is a priority queue that lets us consider
    the edges in the order of their costs. We can dequeue the edge with the minimum
    cost every time, as our algorithm requires. The purpose of `unionFind` is to keep
    track of which vertices are connected after some edges are already chosen. First,
    we traverse through all the edges and enqueue them to the priority queue, then
    we traverse through all the vertices to add them to `unionFind`. After this, as
    described in our algorithm, we pick the edges in the order of their costs and
    add them only when they are not between the vertices that are already connected.
    The `unionFind` keeps track of which vertices are connected. The edges of the
    spanning tree are returned in a linked list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: Complexity of the minimum spanning tree algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Visiting all the edges and adding them to the priority queue can be as low as
    *Ө* *(|V| + |E| + |E| lg |E|)* because traversing through the edges is *Ө* *(|V|
    + |E| )* and adding all of them to the priority queue is *Ө* *(|E| lg |E|)*. Since
    a connected graph has *|E| ≥|V| -1*, *Ө* *(|V| + |E| + |E| lg |E|) =* *Ө* *(|E|
    lg |E|)*. Inserting all the vertices to the union find is done through *Ө* *(|V|
    lg |V|)* because adding each vertex has the complexity *Ө* *(lg |V|)*.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's consider the core of the algorithm. For each edge, dequeueing the
    minimum edge is *Ө* *(lg |E|)*, finding each of the source and the target in `unionFind`
    is *Ө* *(lg |V|)*, adding to the linked list is constant time, and doing a union
    on `union find` is *Ө* *(lg |V|)*. So, for each edge, the complexity is *Ө* *(lg
    |V| + lg |E|)*. This is *Ө* *(lg |E|)* for each edge, as *|E| ≥|V| -1*. Therefore,
    the complexity of the core part is *Ө* *(|V| lg |E|)* because we stop after *|V|
    - 1* number of edges are added and all the vertices are already connected.
  prefs: []
  type: TYPE_NORMAL
- en: Adding the complexity of all the preceding steps, we get the total complexity
    of the minimum spanning tree algorithm as *Ө* *(|E| lg |E|) +* *Ө* *(lg |V|) +*
    *Ө* *(|V| lg |E|) =* *Ө* *(|E| lg |E| + |V| lg* *|V|) =* *Ө* *(|E| lg |E| )* as
    *|E| ≥|V| -1*.
  prefs: []
  type: TYPE_NORMAL
- en: This algorithm is called Kruskal's algorithm, invented by Joseph Kruskal. Kruskal's
    algorithm works with the complexity *Ө* *(|V| lg |E| )* if a sorted list of edges
    is already available. Since we have checked until all the edges are processed,
    if a graph is passed that is not connected, it will give a set of minimum spanning
    trees, one for each connected subgraph.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw what a graph is and some real-world scenarios where
    they can be applicable. We saw a few ways of implementing a graph data structure
    in memory. We then studied ways to traverse a graph, in both BFT and DFT. We used
    traversals to detect cycles in a graph. Finally, we saw what spanning trees are,
    what minimum spanning trees are, and how to find them in a graph.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will drift a bit to explore a simple and elegant way
    of implementing some concurrent programming, called reactive programming.
  prefs: []
  type: TYPE_NORMAL
