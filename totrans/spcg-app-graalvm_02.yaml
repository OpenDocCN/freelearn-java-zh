- en: '*Chapter 1*: Evolution of Java Virtual Machine'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第一章*：Java 虚拟机演变'
- en: This chapter will walk you through the evolution of **Java Virtual Machine**
    (**JVM**), and how it optimized the interpreter and compiler. We will learn about
    C1 and C2 compilers and various types of code optimizations that the JVM performs
    to run Java programs faster.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将向您介绍 **Java 虚拟机**（**JVM**）的演变过程以及它是如何优化解释器和编译器的。我们将了解 C1 和 C2 编译器以及 JVM 执行的多种代码优化类型，以使
    Java 程序运行得更快。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Introduction to GraalVM
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GraalVM 简介
- en: Learning how JVM works
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习 JVM 的工作原理
- en: Understanding the JVM architecture
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 JVM 架构
- en: Understanding the kind of optimizations JVM performs with **Just-In-Time** (**JIT**)
    compilers
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 JVM 使用 **即时编译器**（**JIT**）执行的优化类型
- en: Learning the pros and cons of the JVM approach
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习 JVM 方法的优缺点
- en: By the end of this chapter, you will have a clear understanding of the JVM architecture.
    This is critical in understanding the GraalVM architecture and how GraalVM further
    optimizes and builds on top of JVM best practices.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将对 JVM 架构有一个清晰的理解。这对于理解 GraalVM 架构以及 GraalVM 如何进一步优化并建立在 JVM 最佳实践之上至关重要。
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter does not require any specific software/hardware.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章不需要任何特定的软件/硬件。
- en: Introduction to GraalVM
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GraalVM 简介
- en: GraalVM is a high-performance VM that provides the runtime for modern cloud-native
    applications. Cloud-native applications are built based on the service architecture.
    The microservice architecture changes the paradigm of building micro applications,
    which challenges the fundamental way we build and run applications. The microservices
    runtimes demand a different set of requirements.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: GraalVM 是一个高性能虚拟机，为现代云原生应用程序提供运行时。云原生应用程序是基于服务架构构建的。微服务架构改变了构建微应用程序的范式，这挑战了构建和运行应用程序的基本方式。微服务运行时需要一套不同的要求。
- en: 'Here are some of the key requirements of a cloud-native application built on
    the microservice architecture:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些基于微服务架构构建的云原生应用程序的关键要求：
- en: '**Smaller footprint**: Cloud-native applications run on the "pay for what we
    use" model. This means that the cloud-native runtimes need to have a smaller memory
    footprint and should run with the optimum CPU cycles. This will help run more
    workloads with fewer cloud resources.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更小的内存占用**：云原生应用程序运行在“按使用付费”的模式上。这意味着云原生运行时需要具有更小的内存占用，并且应该以最佳 CPU 循环运行。这将有助于使用更少的云资源运行更多的工作负载。'
- en: '**Quicker bootstrap**: Scalability is one of the most important aspects of
    container-based microservices architecture. The faster the application''s bootup,
    the faster it can scale the clusters. This is even more important for serverless
    architectures, where the code is initialized and run and then shut down on request.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快速启动**：可扩展性是容器化微服务架构最重要的方面之一。应用程序启动越快，它就能更快地扩展集群。这对于无服务器架构来说尤为重要，在无服务器架构中，代码在请求初始化和运行后关闭。'
- en: '**Polyglot and interoperability**: Polyglot is the reality; each language has
    its strengths and will continue to. Cloud-native microservices are being built
    with different languages. It''s very important to have an architecture that embraces
    the polyglot requirements and provides interoperability across languages. As we
    move to modern architectures, it''s important to reuse as much code and logic
    as possible, that is time-tested and critical for business.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多语言和互操作性**：多语言是现实；每种语言都有其优势，并将继续如此。云原生微服务正在用不同的语言构建。拥有一个能够接纳多语言需求并提供跨语言互操作性的架构非常重要。随着我们转向现代架构，尽可能重用代码和逻辑至关重要，这些代码和逻辑是经过时间考验的，对业务至关重要。'
- en: GraalVM provides a solution to all these requirements and provides a common
    platform to embed and run polyglot cloud-native applications. It is built on JVM
    and brings in further optimizations. Before understanding how GraalVM works, it's
    important to understand the internal workings of JVM.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: GraalVM 为所有这些需求提供了解决方案，并为嵌入和运行多语言云原生应用程序提供了一个通用平台。它是基于 JVM 构建的，并带来了进一步的优化。在了解
    GraalVM 的工作原理之前，了解 JVM 的内部工作原理非常重要。
- en: Traditional JVM (before GraalVM) has evolved into the most mature runtime implementation.
    While it has some of the previously listed requirements, it is not built for cloud-native
    applications, and it comes with its baggage of monolith design principles. It
    is not an ideal runtime for cloud-native applications.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will walk you through in detail how JVM works and the key components
    of the JVM architecture.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Learning how JVM works
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Java is one of the most successful and widely used languages. Java has been
    very successful because of its *write once, run anywhere* design principle. JVM
    realizes this design principle by sitting between the application code and the
    machine code and interpreting the application code to machine code.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditionally, there two ways of running application code:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '**Compilers**: Application code is directly compiled to machine code (in C,
    C++). Compilers go through a build process of converting the application code
    to machine code. Compilers generate the most optimized code for a specific target
    architecture. The application code has to be compiled to target architectures.
    In general, the compiled code always runs faster than interpreted code, and issues
    with code semantics can be identified during compilation time rather than runtime.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interpreters**: Application code is interpreted to machine code line by line
    (JavaScript and so on). Since interpreters run line by line, the code may not
    be optimized to the target architecture, and run slowly, compared to the compiled
    code. Interpreters have the flexibility of writing once and running anywhere.
    A good example is the JavaScript code that is predominantly used for web applications.
    This runs pretty much on different target browsers with minimal or no changes
    in the application code. Interpreters are generally slow and are good for running
    small applications.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'JVM has taken the best of both interpreters and compilers. The following diagram
    illustrates how JVM runs the Java code using both the interpreter and compiler
    approaches:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.1 – Java compiler and interpreter'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_1.1.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.1 – Java compiler and interpreter
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how this works:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Java Compiler (**javac**) compiles the Java application source code to **bytecode**
    (intermediate format).
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JVM interprets the bytecode to machine code line by line at runtime. This helps
    in translating the optimized bytecode to target machine code, helping in running
    the same application code on different target machines, without re-programming
    or re-compiling.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JVM also has a Just-In-Time (**JIT)** compiler to further optimize the code
    at runtime by profiling the code.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we looked at how Java Compiler and JIT work together to run
    Java code on JVM at a higher level. In the next section, we will learn about the
    architecture of JVM.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the JVM architecture
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the years, JVM has evolved into the most mature VM runtime. It has a very
    structured and sophisticated implementation of a runtime. This is one of the reasons
    why GraalVM is built to utilize all the best features of the JVM and provide further
    optimizations required for the cloud-native world. To better appreciate the GraalVM
    architecture and optimizations that it brings on top of the JVM, it's important
    to understand the JVM architecture.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: 'This section walks you through the JVM architecture in detail. The following
    diagram shows the high-level architecture of various subsystems in JVM:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.2 – High-level architecture of JVM'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_1.2.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.2 – High-level architecture of JVM
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: The rest of this section will walk you through each of these subsystems in detail.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Class loader subsystem
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The class loader subsystem is responsible for allocating all the relevant `.class`
    files and loading these classes to the memory. The class loader subsystem is also
    responsible for linking and verifying the schematics of the `.class` file before
    the classes are initialized and loaded to memory. The class loader subsystem has
    the following three key functionalities:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Loading
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linking
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Initializing
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows the various components of the class loader subsystem:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.3 – Components of the class loader subsystem'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_1.3.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.3 – Components of the class loader subsystem
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Let's now look at what each of these components does.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Loading
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In traditional compiler-based languages such as C/C++, the source code is compiled
    to object code, and then all the dependent object code is linked by a linker before
    the final executable is built. All this is part of the build process. Once the
    final executable is built, it is then loaded into the memory by the loader. Java
    works differently.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Java source code (`.java`) is compiled by Java Compiler (`javac`) to bytecode
    (`.class`) files. Class loader is one of the key subsystems of the JVM, which
    is responsible for loading all the dependent classes that are required to run
    the application. This includes the classes that are written by the application
    developer, the libraries, and the **Java Software Development Kit** (**SDK**)
    classes.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three types of class loaders as part of this system:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '`rt.jar`, which contains all the Java Standard Edition JDK classes, such as
    `java.lang`, `java.net`, `java.util`, and `java.io`. Bootstrap is responsible
    for loading all the classes that are required to run any Java application. This
    is a core part of the JVM and is implemented in the native language.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`jre`/`lib`/`ext` directory. Extension class loader classes are typically extension
    classes of the bootstrap implemented in Java. The extension class loader is implemented
    in Java (`sun.misc.Launcher$ExtClassLoader.class`).'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CLASSPATH` env variable). This is also implemented in Java (`sun.misc.Launcher$AppClassLoader.class`).'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bootstrap, extension, and application class loaders are responsible for loading
    all the classes that are required to run the application. In the event where the
    class loaders do not find the required classes, `ClassNotFoundException` is thrown.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'Class loaders implement the delegation hierarchy algorithm. The following diagram
    shows how the class loader implements the delegation hierarchy algorithm to load
    all the required classes:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.4 – Class loader delegation hierarchy algorithm implementation flowchart'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_1.4.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.4 – Class loader delegation hierarchy algorithm implementation flowchart
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s understand how this algorithm works:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: JVM looks for the class in the method area (this will be discussed in detail
    later in this section). If it does not find the class, it will ask the application
    class loader to load the class into memory.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The application class loader delegates the call to the extension class loader,
    which in turn delegates to the bootstrap class loader.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bootstrap class loader looks for the class in the bootstrap `CLASSPATH`.
    If it finds the class, it will load to the memory. If it does not find the class,
    control is delegated to the extension class loader.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The extension class loader will try to find the class in the extension `CLASSPATH`.
    If it finds the class, it will load to the memory. If it does not find the class,
    control is delegated to the application class loader.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The application class loader will try to look for the class in `CLASSPATH`.
    If it does not find it, it will raise `ClassNotFoundException`, otherwise, the
    class is loaded into the method area, and the JVM will start using it.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Linking
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once the classes are loaded into the memory (into the method area, discussed
    further in the *Memory subsystem* section), the class loader subsystem will perform
    linking. The linking process consists of the following steps:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '`java.lang.Object`. The verification phase validates and ensures that the methods
    run without any issues.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Preparation**: Once all the classes are loaded and verified, JVM allocates
    memory for class variables (static variables). This also includes calling static
    initializations (static blocks).'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resolution**: JVM then resolves by locating the classes, interfaces, fields,
    and methods referenced in the symbol table. The JVM might resolve the symbol during
    initial verification (static resolution) or may resolve when the class is being
    verified (lazy resolution).'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The class loader subsystem raises various exceptions, including the following:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '`ClassNotFoundException`'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`NoClassDefFoundError`'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ClassCastException`'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`UnsatisfiedLinkError`'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ClassCircularityError`'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ClassFormatError`'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ExceptionInInitializerError`'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can refer to the Java specifications for more details: [https://docs.oracle.com/en/java/javase](https://docs.oracle.com/en/java/javase).'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Initializing
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once all the classes are loaded and symbols are resolved, the initialization
    phase starts. During this phase, the classes are initialized (new). This includes
    initializing the static variables, executing static blocks, and invocating reflective
    methods (`java.lang.reflect`). This might also result in loading those classes.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Class loaders load all the classes into the memory before the application can
    run. Most of the time, the class loader has to load the full hierarchy of classes
    and dependent classes (though there is lazy resolution) to validate the schematics.
    This is time-consuming and also takes up a lot of memory footprint. It's even
    slower if the application uses reflection and the reflected classes need to be
    loaded.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: After learning about the class loader subsystem, let's now understand how the
    memory subsystem works.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Memory subsystem
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The memory subsystem is one of the most critical subsystems of the JVM. The
    memory subsystem, as the name suggests, is responsible for managing the allocated
    memory of method variables, heaps, stacks, and registers. The following diagram
    shows the architecture of the memory subsystem:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.5 – Memory subsystem architecture'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_1.5.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.5 – Memory subsystem architecture
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: 'The memory subsystem has two areas: JVM level and thread level. Let''s discuss
    each in detail.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: JVM level
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'JVM-level memory, as the name suggests, is where the objects are stored at
    the JVM level. This is not thread-safe, as multiple threads might be accessing
    these objects. This explains why programmers are recommended to code thread-safe
    (synchronization) when they update the objects in this area. There are two areas
    of JVM-level memory:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '**Method**: The method area is where all the class-level data is stored. This
    includes the class names, hierarchy, methods, variables, and static variables.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heap**: The heap is where all the objects and the instance variables are
    stored.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread level
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Thread-level memory is where all the thread-local objects are stored. This
    is accessible/visible to the respective threads, hence it is thread-safe. There
    are three areas of the thread-level memory:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '**Stack**: For each method call, a stack frame is created, which stores all
    the method-level data. The stack frame consists of all the variables/objects that
    are created within the method scope, operand stack (used to perform intermediate
    operations), the frame data (which stores all the symbols corresponding to the
    method), and exception catch block information.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Registers**: PC registers keep track of the instruction execution and point
    to the current instruction that is being executed. This is maintained for each
    thread that is executing.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Native Method Stack**: The native method stack is a special type of stack
    that stores the native method information, which is useful when calling and executing
    the native methods.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that the classes are loaded into the memory, let's look at how the JVM execution
    engine works.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: JVM execution engine subsystem
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The JVM execution engine is the core of the JVM, where all the execution happens.
    This is where the bytecodes are interpreted and executed. The JVM execution engine
    uses the memory subsystem to store and retrieve the objects. There are three key
    components of the JVM execution engine, as shown:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.6 – JVM execution engine architecture'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_1.6.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.6 – JVM execution engine architecture
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: We will talk about each component in detail in the following sections.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Bytecode interpreter
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As mentioned earlier in this chapter, bytecode (`.class`) is the input to the
    JVM. The JVM bytecode interpreter picks each instruction from the `.class` file
    and converts it to machine code and executes it. The obvious disadvantage of interpreters
    is that they are not optimized. The instructions are executed in sequence, and
    even if the same method is called several times, it goes through each instruction,
    interprets it, and then executes.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: JIT compiler
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The JIT compiler saves the day by profiling the code that is being executed
    by interpreters, identifies areas where the code can be optimized and compiles
    them to target machine code, so that they can be executed faster. A combination
    of bytecode and compiled code snippets provide the optimum way to execute the
    class files.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the detailed workings of JVM, along with
    the various types of JIT compilers that the JVM uses to optimize the code:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.7 – The detailed working of JVM with JIT compilers'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_1.7.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.7 – The detailed working of JVM with JIT compilers
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s understand the workings shown in the previous diagram:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: The JVM interpreter steps through each bytecode and interprets it with machine
    code, using the bytecode to machine code mapping.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: JVM profiles the code consistently using a counter, to count the number of times
    a code is executed, and if the counter reaches a threshold, it uses the JIT compiler
    to compile that code for optimization and stores it in the code cache.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: JVM then checks whether that compilation unit (block) is already compiled. If
    JVM finds a compiled code in the code cache, it will use the compiled code for
    faster execution.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: JVM uses two types of compilers, the C1 compiler and the C2 compiler, to compile
    the code.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As illustrated in *Figure 1.7*, the JIT compiler brings in optimizations by
    profiling the code that is running and, over a period of time, it identifies the
    code that can be compiled. The JVM runs the compiled snippets of code instead
    of interpreting the code. It is a hybrid method of running interpreted code and
    compiled code.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 'JVM introduced two types of compilers, C1 (client) and C2 (server), and the
    recent versions of JVM use the best of both for optimizing and compiling the code
    at runtime. Let''s understand these types better:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '**C1 compiler**: A performance counter was introduced, which counted the number
    of times a particular method/snippet of code is executed. Once a method/code snippet
    is used a particular number of times (threshold), then that particular code snippet
    is compiled, optimized, and cached by the C1 compiler. The next time that code
    snippet is called, it directly executes the compiled machine instructions from
    the cache, rather than going through the interpreter. This brought in the first
    level of optimization.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**C2 compiler**: While the code is getting executed, the JVM will perform runtime
    code profiling and come up with code paths and hotspots. It then runs the C2 compiler
    to further optimize the hot code paths. This is also known as a hotspot.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: C1 is faster and good for short-running applications, while C2 is slower and
    heavy, but is ideal for long-running processes such as daemons and servers, so
    the code performs better over time.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: In Java 6, there is a command-line option to use either C1 or C2 methods (with
    the command-line arguments `-client` (for C1) and `-server` (for C2)). In Java
    7, there is a command-line option to use both. Since Java 8, both C1 and C2 compilers
    are used for optimization as the default behavior.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'There are five tiers/levels of compilation. Compilation logs can be generated
    to understand which Java method is compiled using which compiler tier/level. The
    following are the five tiers/levels of compilation:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Interpreted code (level 0)
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple C1 compiled code (level 1)
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limited C1 compiled code (level 2)
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Full C1 compiled code (level 3)
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: C2 compiled code (level 4)
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's now look at the various types of code optimizations that the JVM applies
    during compilation.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Code optimizations
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The JIT compiler generates the internal representation of the code that is being
    compiled to understand the semantics and syntax. These internal representations
    are tree data structures, on which the JIT will then run the code optimization
    (as multiple threads, which can be controlled with the `XcompilationThreads` options
    from the command line).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some of the optimizations that the JIT compilers perform
    on the code:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '`-XX:MaxFreqInlineSize` flag (by default, it is 325 bytes).'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Escape analysis**: The JVM profiles the variables to analyze the scope of
    the usage of the variables. If the variables don''t escape the local scope, it
    then performs local optimization. Lock Elision is one such optimization, where
    the JVM decided whether a synchronization lock is really required for the variable.
    Synchronization locks are very expensive to the processor. The JVM also decides
    to move the object from the heap to the stack. This has a positive impact on memory
    usage and garbage collection, as the objects are destroyed once the method is
    executed.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DeOptimization**: DeOptimization is another critical optimization technique.
    The JVM profiles the code after optimization and may decide to deoptimize the
    code. Deoptimizations will have a momentary impact on performance. The JIT compiler
    decides to deoptimize in two cases:'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a. **Not Entrant Code**: This is very prominent in inherited classes or interface
    implementations. JIT may have optimized, assuming a particular class in the hierarchy,
    but over time when it learns otherwise, it will deoptimize and profile for further
    optimization of more specific class implementations.'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b. **Zombie Code**: During Not Entrant code analysis, some of the objects get
    garbage collected, leading into code that may never be called. This code is marked
    as zombie code. This code is removed from the code cache.'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Apart from this, the JIT compiler performs other optimizations, such as control
    flow optimization, which includes rearranging code paths to improve efficiency
    and native code generation to the target machine code for faster execution.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: JIT compiler optimizations are performed over a period of time, and they are
    good for long-running processes. We will be going into a detailed explanation
    on JIT compilation in [*Chapter 2*](B16878_02_Final_SK_ePub.xhtml#_idTextAnchor028)*,
    JIT, Hotspot, and GraalVM*.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Java ahead-of-time compilation
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The ahead-of-time compilation option was introduced with Java 9 with `jaotc`,
    where a Java application code can be directly compiled to generate final machine
    code. The code is compiled to a target architecture, so it is not portable.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'Java supports running both Java bytecode and AOT compiled code together in
    an x86 architecture. The following diagram illustrates how it works. This is the
    most optimum code that Java can generate:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.8 – The detailed workings of JVM JIT time compilers along with the
    ahead-of-time compiler'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_1.8.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.8 – The detailed workings of JVM JIT time compilers along with the
    ahead-of-time compiler
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: The bytecode will go through the approach that was explained previously (C1,
    C2). `jaotc` compiles the most used java code (like libraries) into machine code,
    ahead of time, and this is directly loaded into the code cache. This will reduce
    the load on JVM. The Java byte code goes through the usual interpreter, and uses
    the code from the code cache, if available. This reduces a lot of load on JVM
    to compile the code at runtime. Typically, the most frequently used libraries
    can be AOT compiled for faster responses.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Garbage collector
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the sophistication of Java is its in-built memory management. In languages
    such as C/C++, the programmer is expected to allocate and de-allocate the memory.
    In Java, JVM takes care of cleaning up the unreferenced objects and reclaims the
    memory. The garbage collector is a daemon thread that performs the cleanup either
    automatically or can also be invoked by the programmer (`System.gc()` and `Runtime.getRuntime().gc()`).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Native subsystem
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Java allows programmers to access native libraries. Native libraries are typically
    those libraries that are built (using languages such as C/C++) and used for a
    specific target architecture. **Java Native Interface** (**JNI**) provides an
    abstraction layer and interface specification for implementing the bridge to access
    the native libraries. Each JVM implements JNI for the specific target system.
    Programmers can also use JNI to call the native methods. The following diagram
    illustrates the components of the native subsystem:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.9 – Native subsystem architecture'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_1.9.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.9 – Native subsystem architecture
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: The native subsystem provides the implementation to access and manage the native
    libraries.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: JVM has evolved and has one of the most sophisticated implementations of a language
    VM runtime.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we started by learning what GraalVM is, followed by understanding
    how JVM works and its architecture, along with its various subsystems and components.
    Later on, we also learned how JVM combines the best of interpreters and the compiler
    approach to run Java code on various target architectures, along with how a code
    is compiled just-in-time with C1 and C2 compilers. Lastly, we learned about various
    types of code optimizations that the JVM performs.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: This chapter provided a good understanding of the architecture of JVM, which
    will help us understand how the GraalVM architecture works and how it is built
    on top of JVM.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will cover the details of how JIT compilers work and help you
    understand how Graal JIT builds on top of JVM JIT.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why is Java code interpreted to bytecode and later compiled at runtime?
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does JVM load the appropriate class files and link them?
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the various types of memory areas in JVM?
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between the C1 compiler and the C2 compiler?
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a code cache in JVM?
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the various types of code optimizations that are performed just in
    time?
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Introduction to JVM Languages*, by Vincent van der Leun, Packt Publishing
    ([https://www.packtpub.com/product/introduction-to-jvm-languages/9781787127944](https://www.packtpub.com/product/introduction-to-jvm-languages/9781787127944))'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Java Documentation and Specification*, by Oracle ([https://docs.oracle.com/en/java/](https://docs.oracle.com/en/java/))'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
