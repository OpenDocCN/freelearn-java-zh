- en: Serialization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序列化
- en: In modern (internet) computing, we often forget that entities must be transmitted
    from one computer to another. In order to be able to transmit the entities, they
    must first be serialized.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代（互联网）计算中，我们常常忘记实体必须从一台计算机传输到另一台计算机。为了能够传输实体，它们必须首先进行序列化。
- en: Serialization is the process of transforming an object into a stream of bytes
    commonly used to transmit it from one computer to another.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 序列化是将对象转换成字节流的过程，通常用于从一台计算机传输到另一台计算机。
- en: Deserialization, as the name implies, is the opposite of serialization, that
    is, to convert a stream of bytes into an object (for didactic purposes, we can
    say that the object is inflated or rehydrated), normally from the side that receives
    the message. Kafka provides **Serializer**/**Deserializer** (**SerDe**) for the
    primitive data types (byte, integer, long, double, String, and so on).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，反序列化是序列化的相反，即把字节流转换成对象（为了教学目的，我们可以说对象是被膨胀或再水化的），通常是从接收消息的一侧进行。Kafka 为原始数据类型（字节、整数、长整型、双精度浮点型、字符串等）提供了
    **Serializer**/**Deserializer**（**SerDe**）。
- en: 'In this chapter, a new company is introduced: Kioto (standing for Kafka Internet
    of Things). This chapter covers the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，介绍了一家新公司：Kioto（代表 Kafka 物联网）。本章涵盖了以下主题：
- en: How to build a Java `PlainProducer`, a consumer, and a processor
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建 Java `PlainProducer`、消费者和处理器
- en: How to run a Java `PlainProducer` and a processor
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何运行 Java `PlainProducer` 和处理器
- en: How to build a custom serializer and a custom deserializer
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建自定义序列化和反序列化器
- en: How to build a Java `CustomProducer`, a consumer, and a processor
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建 Java `CustomProducer`、消费者和处理器
- en: How to run a Java `CustomProducer` and a processor
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何运行 Java `CustomProducer` 和处理器
- en: Kioto, a Kafka IoT company
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kioto，一家 Kafka 物联网公司
- en: Kioto is a fictional company dedicated to energy production and distribution.
    To operate, Kioto has several **Internet of Things** (**IoT**) devices.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Kioto 是一家致力于能源生产和分配的虚构公司。为了运营，Kioto 有几个 **物联网**（**IoT**）设备。
- en: Kioto also wants to build an enterprise service bus with Apache Kafka. Its goal
    is to manage all of the messages received by all of the machines' IoT sensors
    every minute. Kioto has hundreds of machines in several locations, sending thousands
    of different messages per minute to the enterprise service bus.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Kioto 还想使用 Apache Kafka 构建一个企业服务总线。其目标是管理每分钟所有机器的物联网传感器接收到的所有消息。Kioto 在几个地点有数百台机器，每分钟向企业服务总线发送数千条不同的消息。
- en: As mentioned, Kioto has a lot of IoT on its machines that continuously send
    status messages to a control center. These machines generate electricity, so it
    is very important for Kioto to know exactly the machines' uptime and their state
    (running, shutting down, shutdown, starting, and so on).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Kioto 的机器上有大量的物联网设备，这些设备会持续向控制中心发送状态消息。这些机器产生电力，因此对于 Kioto 来说，确切知道机器的运行时间和它们的状态（运行、关闭、已关闭、启动等）非常重要。
- en: Kioto also needs to know the weather forecast, because some machines should
    not operate over certain temperatures. Some machines display different behavior
    based on the environmental temperature. It is different starting a machine in
    cold rather than in warm conditions, so the start up time is important when calculating
    the uptime. To warrant the continuous electricity supply, the information has
    to be precise. It is always better to face an electrical power failure having
    to start the machines from a warm temperature rather than from cold temperature.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 京都也需要知道天气预报，因为一些机器在超过特定温度时不能运行。一些机器会根据环境温度表现出不同的行为。在冷环境中启动机器与在温暖环境中启动机器是不同的，因此在计算正常运行时间时，启动时间很重要。为了保证持续供电，信息必须精确。面对电力故障时，从温暖温度而不是从寒冷温度启动机器总是更好的。
- en: '*Listing 4.1* shows the health check event in JSON format.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 4.1* 展示了以 JSON 格式的健康检查事件。'
- en: 'The following is the content of *Listing 4.1*,`healthcheck.json`:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为 *列表 4.1* 的内容，`healthcheck.json`：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Listing 4.1: healthcheck.json'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '列表 4.1: healthcheck.json'
- en: 'The proposed representation of this message in JSON has the following properties:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 该消息在 JSON 中的提议表示具有以下属性：
- en: '`event`: The string with the message''s type (in this case, `HEALTH_CHECK`)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`event`：消息类型的字符串（在这种情况下，`HEALTH_CHECK`）'
- en: '`factory`: The name of the city where the plant is physically located'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`factory`：工厂实际所在城市的名称'
- en: '`serialNumber`: The machine''s serial number'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`serialNumber`：机器的序列号'
- en: '`type`: Represents the machine''s type, which could be `GEOTHERMAL`, `HYDROELECTRIC`,
    `NUCLEAR`, `WIND`, or `SOLAR`'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type`: 表示机器的类型，可能是`GEOTHERMAL`、`HYDROELECTRIC`、`NUCLEAR`、`WIND`或`SOLAR`'
- en: '`status`: The point on the life cycle: `RUNNING`, `SHUTTING-DOWN`, `SHUT-DOWN`,
    `STARTING`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`status`: 生命周期中的点：`RUNNING`, `SHUTTING-DOWN`, `SHUT-DOWN`, `STARTING`'
- en: '`lastStartedAt`: The last start time'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lastStartedAt`: 最后启动时间'
- en: '`temperature`: A float representing the machine''s temperature in degrees celsius'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temperature`: 表示机器的温度，单位为摄氏度'
- en: '`ipAddress`: The machine''s IP address'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ipAddress`: 机器的IP地址'
- en: As we can see, JSON is a human-readable message format.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，JSON是一种人类可读的消息格式。
- en: Project setup
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目设置
- en: 'The first step is to create the Kioto project. Create a directory called `kioto`.
    Go to that directory and execute the following command:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是创建Kioto项目。创建一个名为`kioto`的目录。进入该目录并执行以下命令：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output is something like the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下内容：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Gradle creates a default project in the directory, including two Java files
    called `Library.java` and `LibraryTest.java`; delete both files.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Gradle在目录中创建了一个默认项目，包括两个名为`Library.java`和`LibraryTest.java`的Java文件；删除这两个文件。
- en: 'Your directory should be similar to the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 您的目录应类似于以下内容：
- en: '`- build.gradle`'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`- build.gradle`'
- en: '`- gradle`'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`- gradle`'
- en: '`-- wrapper`'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-- wrapper`'
- en: '`--- gradle-wrapper.jar`'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--- gradle-wrapper.jar`'
- en: '`--- gradle-vreapper.properties`'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--- gradle-vreapper.properties`'
- en: '`- gradlew`'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`- gradlew`'
- en: '`- gradle.bat`'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`- gradle.bat`'
- en: '`- settings.gradle`'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`- settings.gradle`'
- en: '`- src`'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`- src`'
- en: '`-- main`'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-- main`'
- en: '`--- java`'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--- java`'
- en: '`----- Library.java`'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`----- Library.java`'
- en: '`-- test`'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-- test`'
- en: '`--- java`'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--- java`'
- en: '`----- LibraryTest.java`'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`----- LibraryTest.java`'
- en: Modify the `build.gradle` file and replace it with *Listing 4.2*.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 修改`build.gradle`文件，并用*Listing 4.2*替换它。
- en: 'The following is the content of *Listing 4.2*, the Kioto Gradle build file:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为*Listing 4.2*的内容，Kioto Gradle构建文件：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Some library dependencies added to the application are as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 添加到应用程序的一些库依赖如下：
- en: '`kafka_2.12`, the necessary dependencies for Apache Kafka'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kafka_2.12`，Apache Kafka所需的依赖项'
- en: '`javafaker`, the necessary dependencies for JavaFaker'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`javafaker`，JavaFaker所需的依赖项'
- en: '`jackson-core`, for JSON parsing and manipulation'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jackson-core`，用于JSON解析和处理'
- en: '`kafka-avro-serializer`, to serialize in Kafka with Apache Avro'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kafka-avro-serializer`，用于使用Apache Avro在Kafka中进行序列化'
- en: Note that to use the `kafka-avro-serializer` function, we added the Confluent
    repository in the repositories section.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，为了使用`kafka-avro-serializer`函数，我们在仓库部分添加了Confluent仓库。
- en: 'To compile the project and download the required dependencies, type the following
    command:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 要编译项目并下载所需的依赖项，请输入以下命令：
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output should be similar to the following:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应类似于以下内容：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The project can also be created with Maven, SBT, or even from the IDE. But
    for simplicity, it was created with Gradle. For more information about these projects,
    visit the following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 项目也可以使用Maven、SBT或甚至从IDE创建。但为了简单起见，它使用Gradle创建。有关这些项目的更多信息，请访问以下链接：
- en: 'Gradle''s main page: [http://www.gradle.org](http://www.gradle.org)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gradle的主页：[http://www.gradle.org](http://www.gradle.org)
- en: 'Maven''s main page: [http://maven.apache.org](http://maven.apache.org)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maven的主页：[http://maven.apache.org](http://maven.apache.org)
- en: 'SBT''s main page: [http://www.scala-sbt.org/](http://www.scala-sbt.org/)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SBT的主页：[http://www.scala-sbt.org/](http://www.scala-sbt.org/)
- en: 'Jackson''s main page: [https://github.com/FasterXML](https://github.com/FasterXML)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jackson的主页：[https://github.com/FasterXML](https://github.com/FasterXML)
- en: 'JavaFaker''s main page: [https://github.com/DiUS/java-faker](https://github.com/DiUS/java-faker)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JavaFaker的主页：[https://github.com/DiUS/java-faker](https://github.com/DiUS/java-faker)
- en: The constants
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常量
- en: The first step is to code our `Constants` class. This class is a static class
    with all of the `Constants` needed in our project.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是编写我们的`Constants`类。这个类是一个静态类，包含我们项目中需要的所有`Constants`。
- en: Open the project with your favorite IDE and, under the `src/main/java/kioto`
    directory, create a file called `Constants.java` with the content of *Listing
    4.3*.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 使用您喜欢的IDE打开项目，并在`src/main/java/kioto`目录下创建一个名为`Constants.java`的文件，其内容为*Listing
    4.3*。
- en: 'The following is the content of *Listing 4.3*, `Constants.java`:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为*Listing 4.3*的内容，`Constants.java`：
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In our `Constants` class, there are some methods that we will need later. These
    are as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`Constants`类中，有一些我们稍后会用到的方法。如下所示：
- en: '`getHealthChecksTopic`: It returns the name of the health checks input topic'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getHealthChecksTopic`: 返回健康检查输入主题的名称'
- en: '`getHealthChecksAvroTopic`: It returns the name of the topic with the health
    checks in Avro'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getHealthChecksAvroTopic`: 返回包含健康检查的Avro主题的名称'
- en: '`getUptimesTopic`: It returns the name of the `uptimes` topic'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getUptimesTopic`：它返回 `uptimes` 主题的名称'
- en: '`machineType`: This is an `enum` with the types of the Kioto energy producing
    machines types'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`machineType`：这是一个 `enum`，包含 Kioto 产生能源机器的类型'
- en: '`machineType`: This is an `enum` with the types of the Kioto machines'' possible
    statuses'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`machineType`：这是一个 `enum`，包含 Kioto 机器可能的类型'
- en: '`getJsonMapper`: It returns the object mapper for JSON serialization and we
    set the serialization format for dates'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getJsonMapper`：它返回用于 JSON 序列化的对象映射器，并且我们设置了日期的序列化格式'
- en: This is a `Constants` class; in languages such as Kotlin, the constants don't
    require an independent class, but we are using Java. Some purists of object-oriented
    programming argue that to code constant classes is an object-oriented anti-pattern.
    However, for simplicity here, we need some constants in our system.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个 `Constants` 类；在 Kotlin 等语言中，常量不需要独立的类，但我们使用 Java。一些面向对象编程的纯粹主义者认为编写常量类是面向对象的反模式。然而，为了简单起见，我们需要在我们的系统中有一些常量。
- en: HealthCheck message
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 健康检查消息
- en: The second step is to code the `HealthCheck` class. This class is a **Plain
    Old Java Object** (**POJO**). The `model` class is the template for the value
    object.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是编写 `HealthCheck` 类。这个类是一个 **普通的 Java 对象**（**POJO**）。`model` 类是值对象的模板。
- en: Open the project with your favorite IDE and, in the `src/main/java/kioto` directory,
    create a file called `HealthCheck.java` with the content of *Listing 4.4*.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 使用您最喜欢的 IDE 打开项目，在 `src/main/java/kioto` 目录下，创建一个名为 `HealthCheck.java` 的文件，其内容为
    *列表 4.4*。
- en: 'The following is the content of *Listing 4.4*,`HealthCheck.java`:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的内容是 *列表 4.4*，`HealthCheck.java` 的内容：
- en: '[PRE7]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Listing 4.4:HealthCheck.java
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.4：HealthCheck.java
- en: 'With your IDE, generate the following:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 使用您的 IDE，生成以下内容：
- en: A no-parameter constructor
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个无参数构造函数
- en: A constructor with all of the attributes passed as parameters
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个带有所有属性作为参数的构造函数
- en: The getters and the setters for each attribute
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个属性的获取器和设置器
- en: This is a data class, a POJO in Java. In languages such as Kotlin, the model
    classes require so much less boilerplate code, but now we are in Java. Some purists
    of object-oriented programming argue that value objects is an object-oriented
    anti-pattern. However, the serialization libraries to produce messages need these
    classes.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个数据类，Java 中的 POJO。在 Kotlin 等语言中，模型类需要的样板代码要少得多，但现在我们是在 Java 中。一些面向对象编程的纯粹主义者认为值对象是面向对象的反模式。然而，用于生成消息的序列化库需要这些类。
- en: To generate fake data with JavaFaker, our code should be as shown in *Listing
    4.5*.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 JavaFaker 生成假数据，我们的代码应如 *列表 4.5* 所示。
- en: 'The following is the content of *Listing 4.5*, a health check mock generator
    with JavaFaker:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的内容是 *列表 4.5*，一个使用 JavaFaker 的健康检查模拟生成器：
- en: '[PRE8]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following is an analysis of how to generate fake health check data:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的内容是对如何生成假健康检查数据的分析：
- en: In line `//1`, `address().city()` generates a fictitious city name
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第 `//1` 行，`address().city()` 生成一个虚构的城市名称
- en: In line `//2`, in the expression `?` for alpha `#` for numeric, `true` if alpha
    is uppercase
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第 `//2` 行，在表达式 `?` 用于字母，`#` 用于数字，如果字母是大写则为 `true`
- en: In line `//3`, we use the machine type `enum` in `Constants` , and a fake number
    between `0` and `` `4` ``
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第 `//3` 行，我们使用 `Constants` 中的机器类型 `enum`，以及一个介于 `0` 和 `4` 之间的假数字
- en: In line `//4`, we use the machine status `enum` in `Constants` and a fake number
    between `0` and `3`, inclusively
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第 `//4` 行，我们使用 `Constants` 中的机器状态 `enum`，以及一个介于 `0` 和 `3` 之间的假数字，包括 `3`
- en: In line `//5`, we are saying that we want a fake date between the past `100`
    days from today
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第 `//5` 行，我们表示我们想要一个从今天起过去 `100` 天的假日期
- en: In line `//6`, we build a fake IP address
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第 `//6` 行，我们构建一个假 IP 地址
- en: Here, we depend on the attributes order of the constructor. Other languages,
    such as Kotlin, allow specifying each assigned attribute name.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们依赖于构造函数的属性顺序。其他语言，如 Kotlin，允许指定每个分配的属性名称。
- en: 'Now, to transform our Java POJO into a JSON string, we use the method in the
    `Constants` class—something like the following:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，要将我们的 Java POJO 转换为 JSON 字符串，我们使用 `Constants` 类中的方法——类似于以下内容：
- en: '[PRE9]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Don't forget that this method throws a JSON processing exception.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记这个方法会抛出一个 JSON 处理异常。
- en: Java PlainProducer
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java 纯生产者
- en: As we already know, to build a Kafka Message producer that we use the Java client
    library, in particular the producer API (in the following chapters, we will see
    how to use Kafka Streams and KSQL).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，要构建一个 Kafka 消息生产者，我们使用 Java 客户端库，特别是生产者 API（在接下来的章节中，我们将看到如何使用 Kafka Streams
    和 KSQL）。
- en: 'The first thing we need is a data source; to make it simple we need to produce
    our mock data. Each message will be a health message with all of its attributes.
    The first step is to build a producer to send these messages in JSON format to
    a topic, as in the example:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要的是一个数据源；为了简单起见，我们需要生成我们的模拟数据。每条消息都将是一条健康消息，包含所有其属性。第一步是构建一个生产者，以JSON格式将这些消息发送到主题，如下例所示：
- en: '[PRE10]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Let's start by creating a Kafka producer that we will use to send the input
    messages.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先创建一个Kafka生产者，我们将使用它来发送输入消息。
- en: 'As we already know, there are two requisites that all of the Kafka producers
    should have: they must be `KafkaProducer` and have specific properties set, as
    shown in *Listing 4.6*.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，所有Kafka生产者都应该有两个必备条件：它们必须是`KafkaProducer`，并且设置了特定的属性，如*列表4.6*所示。
- en: 'The following is the content of *Listing 4.6,* the constructor method for `PlainProducer`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为*列表4.6*的内容，`PlainProducer`的构造方法：
- en: '[PRE11]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'An analysis of the `PlainProducer` constructor includes the following:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 对`PlainProducer`构造函数的分析包括以下内容：
- en: In line `//1`, the list of the brokers where our producer will be running
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//1`行，我们的生产者将运行的代理列表
- en: In line `//2`, the serializer type for the messages' keys (we will see serializers
    later)
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//2`行，消息键的序列化类型（我们稍后会看到序列化器）
- en: In line `//3`, the serializer type for the messages' values (in this case, the
    values are strings)
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//3`行，消息值的序列化类型（在这种情况下，值是字符串）
- en: In line `//4`, with these properties we build a `KafkaProducer` with string
    keys and string values, for example, `<String, String>`
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//4`行，使用这些属性构建一个具有字符串键和字符串值的`KafkaProducer`，例如`<String, String>`
- en: Note that properties behave like a HashMap; in languages such as Kotlin, the
    properties assignment could be made using the `=` operator, rather than by calling
    a method
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意，属性的行为类似于HashMap；在像Kotlin这样的语言中，可以使用`=`运算符而不是调用方法来执行属性赋值
- en: 'We are using a string serializer for both keys and values: in this first approach,
    we will serialize the values to JSON manually using Jackson. We will see later
    how to write a custom serializer.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用字符串序列化器来序列化键和值：在这个第一个方法中，我们将手动使用Jackson将值序列化为JSON。我们稍后会看到如何编写自定义序列化器。
- en: Now, in the `src/main/java/kioto/plain` directory, create a file called `PlainProducer.java`
    with the content of *Listing 4.7*.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在`src/main/java/kioto/plain`目录下，创建一个名为`PlainProducer.java`的文件，内容为*列表4.7*。
- en: 'The following is the content of *Listing 4.7*,`PlainProducer.java`:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为*列表4.7*的内容，`PlainProducer.java`：
- en: '[PRE12]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'An analysis of the `PlainProducer` class includes the following:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 对`PlainProducer`类的分析包括以下内容：
- en: In line `//1`, `ratePerSecond` is the number of messages to send in a one second
    period
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//1`行，`ratePerSecond`是在一秒内要发送的消息数量
- en: In line `//2`, to simulate repetition, we use an infinite loop (try to avoid
    this in production)
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//2`行，为了模拟重复，我们使用无限循环（在生产环境中尽量避免这样做）
- en: In line `//3`, the code to serialize as JSON a Java POJO
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//3`行，将Java POJO序列化为JSON的代码
- en: In line `//4`, we use a Java Future to send the message to `HealthChecksTopic`
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//4`行，我们使用Java Future将消息发送到`HealthChecksTopic`
- en: In line `//5`, we wait this time to send messages again
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//5`行，这次我们等待再次发送消息
- en: In line `//6`, we read the result of the future created previously
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//6`行，我们读取之前创建的future的结果
- en: In line `//7`, everything runs on the broker in localhost in port `9092`, sending
    two messages at intervals of one second
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//7`行，所有操作都在本地的`9092`端口上的代理上运行，每隔一秒发送两条消息
- en: 'It is important to note that here we are sending records without a key; we
    only specified the value (a JSON string), so the key is `null`. We are also calling
    the `get()` method on the result in order to wait for the write acknowledgment:
    without that, messages could be sent to Kafka but are lost without our program
    noticing the failure.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，在这里我们发送没有键的记录；我们只指定了值（一个JSON字符串），因此键是`null`。我们还对结果调用了`get()`方法，以便等待写入确认：没有这个，消息可能会发送到Kafka，但如果没有我们的程序注意到失败，消息可能会丢失。
- en: Running the PlainProducer
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行PlainProducer
- en: 'To build the project, run this command from the `kioto` directory:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建项目，从`kioto`目录运行以下命令：
- en: '[PRE13]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'If everything is okay, the output is something like the following:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切正常，输出如下：
- en: '[PRE14]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'From a command-line terminal, move to the `confluent` directory and start it
    by typing the following:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从命令行终端，移动到`confluent`目录，并按以下方式启动：
- en: '[PRE15]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The broker is running on port `9092`. To create the `healthchecks` topic, execute
    the following:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代理正在`9092`端口上运行。要创建`healthchecks`主题，执行以下命令：
- en: '[PRE16]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Run a console consumer for the `healthchecks` topic by typing the following:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过键入以下内容运行`healthchecks`主题的控制台消费者：
- en: '[PRE17]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: From our IDE, run the main method of the `PlainProducer`
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从我们的IDE中运行`PlainProducer`的`main`方法
- en: 'The output on the console consumer should be similar to the following:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 控制台消费者的输出应类似于以下内容：
- en: '[PRE18]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Remember that, when producing data, there are several write guarantees that
    we could achieve.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，在产生数据时，我们可以实现几种写入保证。
- en: For example, in case of a network failure or a broker failure, is our system
    ready to lose data?
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在出现网络故障或代理故障的情况下，我们的系统是否准备好丢失数据？
- en: 'There is a trade-off among three factors: the availability to produce messages,
    the latency in the production, and the guarantee of the safe write.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在三个因素之间存在着权衡：产生消息的可用性、生产中的延迟以及安全写入的保证。
- en: In this example, we just have one broker, and we use the default value for `acks`
    of 1\. When we call the `get()` method in the future, we are waiting for the broker
    acknowledgment, that is, we have a guarantee that the message is persisted before
    sending another message. In this configuration, we don't lose messages, but our
    latency is higher than in a fire and forget schema.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们只有一个代理，我们使用默认的`acks`值为1。当我们将来调用`get()`方法时，我们正在等待代理的确认，也就是说，我们在发送另一条消息之前确保消息已持久化。在这个配置中，我们不丢失消息，但我们的延迟比在fire
    and forget模式中更高。
- en: Java plain consumer
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java普通消费者
- en: As we already know, to build a Kafka message consumer, we use the Java client
    library—in particular, the consumer API (in the following chapters, we will see
    how to use Kafka Streams and KSQL).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已知的，要构建一个Kafka消息消费者，我们使用Java客户端库——特别是消费者API（在接下来的章节中，我们将看到如何使用Kafka Streams和KSQL）。
- en: Let's create a Kafka consumer that we will use to receive the input messages.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个Kafka消费者，我们将使用它来接收输入消息。
- en: 'As we already know, there are two requisites that all of the Kafka consumers
    should have: to be a `KafkaConsumer` and to set the specific properties, such
    as those shown in *Listing 4.8*.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已知的，所有Kafka消费者都应该有两个必备条件：成为一个`KafkaConsumer`并设置特定的属性，例如*列表4.8*中所示。
- en: 'The following is the content of *Listing 4.8*, the constructor method for plain
    consumer:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为*列表4.8*的内容，普通消费者的构造函数：
- en: '[PRE19]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'An analysis of the plain consumer constructor includes the following:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 对普通消费者构造函数的分析包括以下内容：
- en: In line `//1`, the group ID of our consumer, in this case, `healthcheck-processor`
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//1`中，消费者的组ID，在这种情况下，`healthcheck-processor`
- en: In line `//2`, the list of `brokers` where our consumer will be running
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//2`中，消费者将运行的`brokers`列表
- en: In line `//3`, the deserializer type for the messages' keys (we will see deserializers
    later)
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//3`中，消息键的解序列化类型（我们将在后面看到解序列化器）
- en: In line `//4`, the deserializer type for the messages' values, in this case,
    values are strings
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//4`中，消息值的解序列化类型，在这种情况下，值是字符串
- en: In line `//5`, with these properties, we build a `KafkaConsumer` with string
    keys and string values, for example, `<String, String>`
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//5`中，使用这些属性，我们构建了一个具有字符串键和字符串值的`KafkaConsumer`，例如`<String, String>`
- en: For the customers, we need to provide a group ID to specify the consumer group
    that our consumer will join.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对于客户来说，我们需要提供一个组ID来指定消费者将加入的消费者组。
- en: In the case that multiple consumers are started in parallel, through different
    threads or through different processes, each consumer will be assigned with a
    subset of the topic partitions. In our example, we created our topic with four
    partitions, which means that, to consume the data in parallel, we could create
    up to four consumers.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在多个消费者并行启动的情况下，无论是通过不同的线程还是通过不同的进程，每个消费者都将被分配到主题分区的一个子集。在我们的例子中，我们创建了具有四个分区的主题，这意味着为了并行消费数据，我们可以创建多达四个消费者。
- en: For a consumer, we provide deserializers rather than serializers. Although we
    don't use the key deserializer (because if you remember, it is `null`), the key
    deserializer is a mandatory parameter for the consumer specification. On the other
    hand, we need the deserializer for the value, because we are reading our data
    in a JSON string, whereas here we deserialize the object manually with Jackson.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 对于消费者，我们提供解序列化器而不是序列化器。尽管我们不使用键解序列化器（因为如果你记得，它是`null`），但键解序列化器是消费者指定的强制参数。另一方面，我们需要值的解序列化器，因为我们正在以JSON字符串的形式读取我们的数据，而在这里我们使用Jackson手动解序列化对象。
- en: Java PlainProcessor
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java普通处理器
- en: Now, in the `src/main/java/kioto/plain` directory, create a file called `PlainProcessor.java`
    with the content of *Listing 4.9*.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在`src/main/java/kioto/plain`目录下，创建一个名为`PlainProcessor.java`的文件，内容为*列表4.9*。
- en: 'The following is the content of *Listing 4.9*, `PlainProcessor.java` (part
    1):'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的内容是*列表4.9*，`PlainProcessor.java`（第一部分）：
- en: '[PRE20]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'An analysis of the first part of the `PlainProcessor` class includes the following:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 对`PlainProcessor`类第一部分的解析包括以下内容：
- en: In the first part, we declare a consumer, as in *Listing 4.8*
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第一部分，我们声明了一个消费者，如*列表4.8*所示
- en: In the second part, we declare a producer, as in *Listing 4.6*
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第二部分，我们声明了一个生产者，如*列表4.6*所示
- en: Before continuing to write code, let's remember the project requirements for
    the Kioto stream processing engine.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续编写代码之前，让我们记住Kioto流处理引擎的项目需求。
- en: 'Putting it all together, the specification is to create a stream engine that
    does the following:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有这些放在一起，规范是要创建一个流引擎，执行以下操作：
- en: Generates messages to a Kafka topic called **healthchecks**
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向名为**healthchecks**的Kafka主题生成消息
- en: Reads messages from the Kafka topic called **healthchecks**
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从名为**healthchecks**的Kafka主题读取消息
- en: Calculates the uptime based on the start up time
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据启动时间计算正常运行时间
- en: Writes the messages in a Kafka topic called **uptimes**
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将消息写入名为**uptimes**的Kafka主题
- en: 'This entire process is detailed in *Figure 4.1*, that is, the Kioto stream
    processing application:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程在*图4.1*中有详细说明，即Kioto流处理应用程序：
- en: '![](img/e950097d-1b87-4c2d-b542-1ae7a2c74fef.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e950097d-1b87-4c2d-b542-1ae7a2c74fef.png)'
- en: 'Figure 4.1: The messages are generated into HealthChecksTopic, then read, and
    finally the calculated uptimes are written it in the uptimes topic.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1：消息被生成到HealthChecksTopic，然后读取，最后将计算出的正常运行时间写入uptimes主题。
- en: Now that we're in the `src/main/java/kioto/plain` directory, let's complete
    the `PlainProcessor.java` file with the content of *Listing 4.10*.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们处于`src/main/java/kioto/plain`目录中，让我们用*列表4.10*的内容完成`PlainProcessor.java`文件。
- en: 'The following is the content of *Listing 4.10*, `PlainProcessor.java` (part
    2):'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的内容是*列表4.10*，`PlainProcessor.java`（第二部分）：
- en: '[PRE21]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Listing 4.10: PlainProcessor.java (part 2)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.10：PlainProcessor.java（第二部分）
- en: 'An analysis of the `PlainProcessor` includes the following:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 对`PlainProcessor`的分析包括以下内容：
- en: In line `//1`, the consumer is created and subscribed to the source topic. This
    is a dynamic assignment of the partitions to our customer and join to the customer
    group.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//1`行，创建了消费者并订阅了源主题。这是将分区动态分配给我们的客户并加入客户组的操作。
- en: In line `//2`, an infinite loop to consume the records, the pool duration is
    passed as a parameter to the method pool. The customer waits no longer than one
    second before return.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//2`行，一个无限循环用于消费记录，将池持续时间作为参数传递给方法池。客户在返回前最多等待一秒钟。
- en: In line `//3`, we iterate over the records.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//3`行，我们遍历记录。
- en: In line `//4`, the JSON string is deserialized to extract the health check object.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//4`行，将JSON字符串反序列化以提取健康检查对象。
- en: In line `//5`, the start time is transformed formatted at the current time zone.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//5`行，开始时间被转换并格式化为当前时区。
- en: In line `//6`, the uptime is calculated.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//6`行，计算正常运行时间。
- en: In line `//7`, the uptime is written to the `uptimes` topic, using the serial
    number as the key and the uptime as value. Both values are written as normal strings.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`//7`行，使用序列号作为键和正常运行时间作为值，将正常运行时间写入`uptimes`主题。两个值都作为普通字符串写入。
- en: The moment at which the broker returns records to the client also depends on
    the `fetch.min.bytes` value; its default is 1, and is the minimum data amount
    to wait before the broker is available to the client. Our broker returns as soon
    as 1 byte of data is available, while waiting a maximum of one second.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 代理将记录返回给客户端的时刻也取决于`fetch.min.bytes`值；其默认值为1，是等待代理对客户端可用之前的最小数据量。我们的代理在1字节数据可用时立即返回，同时最多等待一秒钟。
- en: The other configuration property is `fetch.max.bytes`, which defines the amount
    of data returned at once. With our configuration, the broker will return all of
    the available records (without exceeding the maximum of 50 MB).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个配置属性是`fetch.max.bytes`，它定义了一次返回的数据量。根据我们的配置，代理将返回所有可用的记录（不超过50 MB的最大值）。
- en: If there are no records available, the broker returns an empty list.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有可用的记录，代理返回一个空列表。
- en: Note that we could reuse the producer that generates the mock data, but it is
    clearer to use another producer to write `uptimes`.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们可以重用生成模拟数据的代理，但使用另一个代理来写入`uptimes`更清晰。
- en: Running the PlainProcessor
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行PlainProcessor
- en: 'To build the project, run the following command from the `kioto` directory:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建项目，从`kioto`目录运行以下命令：
- en: '[PRE22]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'If everything is correct, the output is something like the following:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切正确，输出将类似于以下内容：
- en: '[PRE23]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Our broker is running on port `9092`, so to create the `uptimes` topic, execute
    the following command:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的代理正在端口`9092`上运行，因此要创建`uptimes`主题，执行以下命令：
- en: '[PRE24]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Run a console consumer for the `uptimes` topic, as follows:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`uptimes`主题的控制台消费者，如下所示：
- en: '[PRE25]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: From our IDE, run the main method of `PlainProcessor`
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从我们的IDE中运行`PlainProcessor`的main方法
- en: From our IDE, run the main method of `PlainProducer`
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从我们的IDE中运行`PlainProducer`的main方法
- en: 'The output on the console consumer for the `uptimes` topic should be similar
    to the following:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 控制台消费者对于`uptimes`主题的输出应类似于以下内容：
- en: '[PRE26]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We have said that, when producing data, there are two factors to think about;
    one is the delivery guarantee, and the other is the partitioning.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经说过，在产生数据时，有两个因素需要考虑；一个是交付保证，另一个是分区。
- en: 'When consuming data, we have to think about the following four factors:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在消费数据时，我们必须考虑以下四个因素：
- en: The number of consumers to run in parallel (in parallel threads and/or parallel
    processes)
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行运行的消费者数量（并行线程和/或并行进程）
- en: The amount of data to consume at once (think in terms of memory)
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一次要消费的数据量（从内存的角度考虑）
- en: The time to wait to receive messages (throughput and latency)
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等待接收消息的时间（吞吐量和延迟）
- en: When to mark a message as processed (committing offset)
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 何时标记消息为已处理（提交偏移量）
- en: If `enable.auto.commit` is set to `true` (the default is `true`), the consumer
    automatically will commit the offsets in the next call to the poll method.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`enable.auto.commit`设置为`true`（默认为`true`），消费者将在下一次调用poll方法时自动提交偏移量。
- en: Note that the whole batch of records is committed; if something fails and the
    application crashes after processing only some messages, but not all of the batch,
    the events are not committed and they will be reprocessed by other consumer; this
    way to process data is called at least once processing.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，整个批次记录都会被提交；如果处理了一些消息但未处理整个批次后应用程序崩溃，则事件不会被提交，它们将被其他消费者重新处理；这种处理数据的方式称为至少一次处理。
- en: Custom serializer
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义序列化器
- en: So far, we have seen how to produce and consume JSON messages using plain Java
    and Jackson. We will see here how to create our custom serializers and deserializers.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了如何使用纯Java和Jackson产生和消费JSON消息。在这里，我们将看到如何创建我们自己的序列化器和反序列化器。
- en: We have seen how to use `StringSerializer` in the producer and `StringDeserializer`
    in the consumer. Now, we will see how to build our own SerDe to abstract the serialization/deserialization
    processes away from the core code of the application.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何在生产者中使用`StringSerializer`，在消费者中使用`StringDeserializer`。现在，我们将看到如何构建我们自己的SerDe，以将序列化/反序列化过程从应用程序的核心代码中抽象出来。
- en: To build a custom serializer, we need to create a class that implements the
    `org.apache.kafka.common.serialization.Serializer` interface. This is a generic
    type, so we can indicate the custom type to be converted into an array of bytes
    (serialization).
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建自定义序列化器，我们需要创建一个实现`org.apache.kafka.common.serialization.Serializer`接口的类。这是一个泛型类型，因此我们可以指定要转换为字节数组的自定义类型（序列化）。
- en: In the `src/main/java/kioto/serde` directory, create a file called `HealthCheckSerializer.java`
    with the content of *Listing 4.11*.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在`src/main/java/kioto/serde`目录下，创建一个名为`HealthCheckSerializer.java`的文件，其内容为*列表4.11*。
- en: 'The following is the content of *Listing 4.11*, `HealthCheckSerializer.java`:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为*列表4.11*，`HealthCheckSerializer.java`的内容：
- en: '[PRE27]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Listing 4.11: HealthCheckSerializer.java'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.11：HealthCheckSerializer.java
- en: Note that the serializer class is located in a special module called **kafka-clients**
    in the `org.apache.kafka` route. The objective here is to use the serializer class
    instead of Jackson (manually).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，序列化器类位于名为**kafka-clients**的特殊模块中，位于`org.apache.kafka`路径。这里的目的是使用序列化器类而不是Jackson（手动）。
- en: Also note that the important method to implement is the `serialize` method.
    The `close` and `configure` methods can be left with an empty body.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，需要实现的重要方法是`serialize`方法。`close`和`configure`方法可以留空体。
- en: We import the `JsonProcessingException` of Jackson just because the `writeValueAsBytes`
    method throws this exception, but we don't use Jackson for serialization.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们导入Jackson的`JsonProcessingException`只是因为`writeValueAsBytes`方法会抛出这个异常，但我们不使用Jackson进行序列化。
- en: Java CustomProducer
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java自定义生产者
- en: 'Now, to incorporate the serializer in our producer, there are two requisites
    that all Kafka producers should fulfill: to be a `KafkaProducer`, and to set the
    specific properties, such as *Listing 4.12*.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了将序列化器纳入我们的生产者，所有Kafka生产者都必须满足两个要求：成为一个`KafkaProducer`，并设置特定的属性，如*列表4.12*。
- en: 'The following is the content of *Listing 4.12*,the constructor method for `CustomProducer`:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为*列表4.12*，`CustomProducer`的构造方法内容：
- en: '[PRE28]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'An analysis of the `CustomProducer` constructor includes the following:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 对`CustomProducer`构造函数的分析包括以下内容：
- en: In line `//1`, this is the list of the brokers where our producer will be running.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//1`中，这是我们的生产者将运行在的代理列表。
- en: In line `//2`, the serializer type for the messages' keys in this case keys
    remains as strings. In line `//3`, this is the serializer type for the messages'
    values, in this case, the values are `HealthCheck`.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//2`中，消息键的序列化器类型保持为字符串。在行`//3`中，这是消息值的序列化器类型，在这种情况下，值是`HealthCheck`。
- en: In line `//4`, with these properties we build a `KafkaProducer` with string
    keys and `HealthCheck` values, for example, `<String, HealthCheck>`.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//4`中，我们使用这些属性构建了一个带有字符串键和`HealthCheck`值的`KafkaProducer`，例如，`<String, HealthCheck>`。
- en: Now, in the `src/main/java/kioto/custom` directory, create a file called `CustomProducer.java`
    with the content of *Listing 4.13*.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在`src/main/java/kioto/custom`目录中，创建一个名为`CustomProducer.java`的文件，内容为*列表4.13*。
- en: 'The following is the content of *Listing 4.13*, `CustomProducer.java`:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为*列表4.13*，`CustomProducer.java`的内容：
- en: '[PRE29]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Listing 4.13: CustomProducer.java'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '列表4.13: CustomProducer.java'
- en: 'An analysis of the `CustomProducer` class includes the following:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 对`CustomProducer`类的分析包括以下内容：
- en: In line `//1`, `ratePerSecond` is the number of messages to send in a one-second
    period
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//1`中，`ratePerSecond`是一秒内要发送的消息数量
- en: In line `//2`, to simulate repetition, we use a infinite loop (try to avoid
    this in production)
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//2`中，为了模拟重复，我们使用了一个无限循环（在生产环境中尽量避免这样做）
- en: In line `//3`, we use a Java future to send the message to `HealthChecksTopic`
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//3`中，我们使用Java future将消息发送到`HealthChecksTopic`
- en: In line `//4`, we wait this time to send messages again
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//4`中，这次我们等待再次发送消息
- en: In line `//5`, we read the result of the future created previously
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//5`中，我们读取之前创建的future的结果
- en: In line `//6`, everything runs on the broker in localhost in port `9092`, sending
    two messages in an interval of one second
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//6`中，所有操作都在本地的`9092`端口上的代理上运行，以一秒的间隔发送两条消息
- en: Running the CustomProducer
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行CustomProducer
- en: 'To build the project, run the following command from the `kioto` directory:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建项目，请在`kioto`目录中运行以下命令：
- en: '[PRE30]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'If everything is okay, the output is something like the following:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切正常，输出将类似于以下内容：
- en: '[PRE31]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Run a console consumer for `HealthChecksTopic` as follows:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按如下方式运行`HealthChecksTopic`的控制台消费者：
- en: '[PRE32]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: From our IDE, run the main method of the `CustomProducer`
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从我们的IDE中，运行`CustomProducer`的`main`方法
- en: 'The output on the console consumer should be similar to the following:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 控制台消费者的输出应类似于以下内容：
- en: '[PRE33]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Custom deserializer
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义反序列化器
- en: In a similar way, to build a custom deserializer, we need to create a class
    that implements the `org.apache.kafka.common.serialization.Deserializer` interface.
    We must indicate how to convert an array of bytes into a custom type (deserialization).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 以类似的方式，要构建自定义反序列化器，我们需要创建一个实现`org.apache.kafka.common.serialization.Deserializer`接口的类。我们必须指明如何将字节数组转换为自定义类型（反序列化）。
- en: In the `src/main/java/kioto/serde` directory, create a file called `HealthCheckDeserializer.java`
    with the content of *Listing 4.14*.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在`src/main/java/kioto/serde`目录中，创建一个名为`HealthCheckDeserializer.java`的文件，内容为*列表4.14*。
- en: 'The following is the content of *Listing 4.14*, `HealthCheckDeserializer.java`:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为*列表4.14*，`HealthCheckDeserializer.java`的内容：
- en: '[PRE34]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Listing 4.14: HealthCheckDeserializer.java'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '列表4.14: HealthCheckDeserializer.java'
- en: Note that the deserializer class is located in a module called kafka-clients
    in the `org.apache.kafka` route. The objective here is to use the deserializer
    class instead of Jackson (manually).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，反序列化器类位于名为kafka-clients的模块中，位于`org.apache.kafka`路径下。这里的目的是使用反序列化器类而不是Jackson（手动）。
- en: Also note that the important method to implement is the `deserialize` method.
    The `close` and `configure` methods can be left with an empty body.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，需要实现的重要方法是`deserialize`方法。`close`和`configure`方法可以留空。
- en: We import the `HealthCheck` class because the `readValue` method requires a
    POJO (a class with public constructor and public getters and setters). Note also
    that all of the POJO attributes should be serializables.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们导入`HealthCheck`类，因为`readValue`方法需要一个POJO（具有公共构造函数和公共getter和setter的类）。注意，所有POJO属性都应该是可序列化的。
- en: Java custom consumer
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java自定义消费者
- en: Let's create a Kafka consumer that we will use to receive the custom input messages.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个Kafka消费者，我们将使用它来接收自定义输入消息。
- en: 'Now, in order to incorporate the deserializer in our consumer, there are two
    requisites that all of the Kafka consumers should have: to be a `KafkaConsumer`,
    and to set the specific properties, such as those in *Listing 4.15*.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了在我们的消费者中包含反序列化器，所有Kafka消费者都应该满足两个要求：成为一个`KafkaConsumer`，并设置特定的属性，如*列表4.15*中所示。
- en: 'The following is the content of *Listing 4.15*, the constructor method for
    `CustomConsumer`:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为*列表4.15*的内容，`CustomConsumer`的构造方法：
- en: '[PRE35]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'An analysis of the `CustomConsumer` constructor includes the following:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 对`CustomConsumer`构造函数的以下分析：
- en: In line `//1`, the group ID of our consumer, in this case, `healthcheck- processor`
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//1`中，我们消费者的组ID，在这种情况下，`healthcheck-processor`
- en: In line `//2`, the list of the brokers where our consumer will be running
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//2`中，消费者将运行在其上的代理列表
- en: In line `//3`, the deserializer type for the messages' keys; in this case, the
    keys remains as strings
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//3`中，消息键的反序列化类型；在这种情况下，键保持为字符串
- en: In line `//4`, the deserializer type for the messages' values; in this case,
    the values are `HealthChecks`
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//4`中，消息值的反序列化类型；在这种情况下，值是`HealthChecks`
- en: In line `//5`, with these properties, we build a `KafkaConsumer` with string
    keys and `HealthChecks` values, for example, `<String, HealthCheck>`
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//5`中，使用这些属性，我们构建了一个具有字符串键和`HealthChecks`值的`KafkaConsumer`，例如`<String, HealthCheck>`
- en: For a consumer, we provide deserializers rather than serializers. Although we
    don't use the key deserializer (because if you remember, it is `null`), the key
    deserializer is a mandatory parameter for the consumer specification. On the other
    hand, we need the deserializer for the value, because we are reading our data
    in a JSON string; here, we deserialize the object with the custom deserializer.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 对于消费者，我们提供反序列化器而不是序列化器。尽管我们不使用键反序列化器（因为如果你记得，它是`null`），但键反序列化器是消费者指定的强制参数。另一方面，我们需要值反序列化器，因为我们正在以JSON字符串的形式读取我们的数据；在这里，我们使用自定义反序列化器反序列化对象。
- en: Java custom processor
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java自定义处理器
- en: Now, in the `src/main/java/kioto/custom` directory, create a file called `CustomProcessor.java`
    with the content of *Listing 4.16*.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在`src/main/java/kioto/custom`目录下，创建一个名为`CustomProcessor.java`的文件，其内容为*列表4.16*。
- en: 'The following is the content of *Listing 4.16*, `CustomProcessor.java` (part
    1):'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为*列表4.16*的内容，`CustomProcessor.java`（第一部分）：
- en: '[PRE36]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'An analysis of the first part of the custom processor class includes the following:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 对自定义处理器类第一部分的分析如下：
- en: In the first part, we declare a consumer, as in *Listing 4.15*
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第一部分，我们声明了一个消费者，如*列表4.15*所示
- en: In the second part, we declare a producer, as in *Listing 4.13*
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第二部分，我们声明了一个生产者，如*列表4.13*所示
- en: Now, in the `src/main/java/kioto/custom` directory, let's complete the `CustomProcessor.java`
    file with the content of *Listing 4.17*.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在`src/main/java/kioto/custom`目录下，让我们用*列表4.17*的内容完成`CustomProcessor.java`文件。
- en: 'The following is the content of *Listing 4.17*, `CustomProcessor.java` (part
    2):'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为*列表4.17*的内容，`CustomProcessor.java`（第二部分）：
- en: '[PRE37]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'An analysis of the `CustomProcessor` process method includes the following:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 对`CustomProcessor`处理方法的以下分析：
- en: In line `//1`, here the consumer is created and subscribed to the source topic.
    This is a dynamic assignment of the partitions to our customer and join to the
    customer group.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//1`中，这里创建了消费者并订阅了源主题。这是将分区动态分配给我们的客户并加入客户组的操作。
- en: In line `//2`, an infinite loop to consume the records, the pool duration is
    passed as a parameter to the method pool. The customer waits no longer than one
    second before return.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//2`中，一个无限循环来消费记录，将池持续时间作为参数传递给方法池。客户在返回之前不会等待超过一秒钟。
- en: In line `//3`, we iterate over the records.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//3`中，我们遍历记录。
- en: In line `//4`, the JSON string is deserialized to extract the `HealthCheck`
    object.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//4`中，将JSON字符串反序列化以提取`HealthCheck`对象。
- en: In line `//5`, the start time is transformed in format at the current time zone.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//5`中，将开始时间转换为当前时区的格式。
- en: In line `//6`, the uptime is calculated.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//6`中，计算了运行时间。
- en: In line `//7`, the uptime is written to the `uptimes` topic, using the serial
    number as the key and the uptime as the value. Both values are written as normal
    strings.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行`//7`中，使用序列号作为键，将运行时间（uptime）写入`uptimes`主题，这两个值都作为普通字符串写入。
- en: Running the custom processor
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行自定义处理器
- en: 'To build the project, run the following command from the `kioto` directory:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建项目，请从`kioto`目录中运行以下命令：
- en: '[PRE38]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'If everything is correct, the output is something like the following:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切正常，输出将类似于以下内容：
- en: '[PRE39]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Run a console consumer for the `uptimes` topic as follows:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下方式运行`uptimes`主题的控制台消费者：
- en: '[PRE40]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: From our IDE, run the main method of `CustomProcessor`
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从我们的集成开发环境（IDE）中运行`CustomProcessor`的主方法
- en: From our IDE, run the main method of `CustomProducer`
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从我们的IDE中运行`CustomProducer`的主方法
- en: 'The output on the console consumer for the `uptimes` topic should be similar
    to the following:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 控制台消费者对于`uptimes`主题的输出应类似于以下内容：
- en: '[PRE41]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Now, we have seen how to create our own SerDe to abstract the serialization
    code from our application's main logic. Now you know how a Kafka SerDe works.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经看到了如何创建我们自己的SerDe，以将序列化代码从应用程序的主要逻辑中抽象出来。现在你知道了Kafka SerDe是如何工作的。
- en: Summary
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned how to build a Java PlainProducer, a consumer, and
    a processor, and we have shown how to build a custom serializer and a custom deserializer.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何构建Java PlainProducer、消费者和处理器，并展示了如何构建自定义序列化和反序列化器。
- en: Also, we learned how to build a Java CustomProducer, a consumer, and a processor,
    and how to run the Java CustomProducer and the processor.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还学习了如何构建Java CustomProducer、消费者和处理器，以及如何运行Java CustomProducer和处理器。
- en: In this chapter, we have seen how to serialize/deserialize with Kafka using
    JSON, plain, and binary formats. Avro is a common serialization type for Kafka.
    We will see how to use Avro in [Chapter 5](f7fa5729-8bf7-41c8-aba6-aa5f8663394f.xhtml),
    *S**chema Registry*, along with the use of the Kafka schema registry.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到了如何使用JSON、纯文本和二进制格式通过Kafka进行序列化和反序列化。Avro是Kafka的常见序列化类型。我们将在[第5章](f7fa5729-8bf7-41c8-aba6-aa5f8663394f.xhtml)
    *模式注册表*中看到如何使用Avro，以及如何使用Kafka模式注册表。
