<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Implementing Concurrency Patterns</h1>
                </header>
            
            <article>
                
<p>In <a href="313a6506-6bc8-4785-a51b-1637f219bd00.xhtml">Chapter 11</a>, <em>Implementing Reactive Design Patterns</em>, we discussed the Reactive Design Pattern and how it fulfills the requirements of today's applications. Spring 5 Framework has introduced the Reactive Web Application Modules for the web application. In this chapter, we will explore some of the Concurrency Design Patterns and how these patterns solve the common problems of the multithreaded application. Spring 5 Framework's reactive modules also provide the solution for the multithreaded application.</p>
<p>If you are a software engineer or are in the process of becoming one, you must be aware of the term <em>concurrency</em>. In geometric properties, concurrent circles or shapes are those shapes that have a common center point. These shapes can differ in dimensions but have a common center or midpoint.</p>
<p>The concept is similar in terms of software programming as well. The term <em>concurrent programming</em> in the technical or programming means the ability of a program to carry out multiple computations in parallel and also the capability of a program to handle multiple external activities taking place in a single time interval.</p>
<p>As we are talking in terms of software engineering and programming, concurrency patterns are those design patterns that help in dealing with multi-threaded programming models. Some of the concurrency patterns are as follows:</p>
<ul>
<li>Handling concurrency with concurrency patterns</li>
<li>Active object pattern</li>
<li>Monitor object pattern</li>
<li>Half-Sync/Half-Async patterns</li>
<li>Leader/followers pattern</li>
<li>Thread-specific storage</li>
<li>Reactor pattern</li>
<li>Best practices for concurrency module</li>
</ul>
<p>Let's now explore each of these five concurrency design patterns in depth.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Active object pattern</h1>
                </header>
            
            <article>
                
<p>The active object type of concurrency design pattern differentiates/distinguishes the method execution from the method invocation. The job of this pattern is the enhancement of concurrency along with simplification in the synchronized access to objects that reside in separate and distinguishable threads of control. It is used for dealing with the multiple client requests that arrive all at once, and also for improving the quality of the service. Let's see the following diagrams, which illustrates the active object design pattern in the concurrency and multithread-based application:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/57d27554-470b-4014-8f1f-3aac617b382f.jpg"/></div>
<p class="packt_figure">As you can see in the preceding diagram, the following components of this concurrency design pattern:</p>
<ul>
<li><strong>Proxy</strong>: This is the active object that is visible to the client. The proxy advertises its interface.</li>
<li><strong>Servant</strong>: There is a method that is defined in the interface of the proxy. The servant is the provider of its implementation.</li>
<li><strong>Activation list</strong>: This is a serialized list that contains method request objects that the proxy inserts. This list allows the servant to run concurrently.</li>
</ul>
<p>So, how does this design pattern work? Well, the answer to this is that every concurrent object belongs to or resides in a separate thread of control. This is also independent of the thread of control of the client. This invokes one of its methods, which means that both the method execution and method invocation take place in separate threads of control. However, the client sees this process as an ordinary method. In order for the proxy to pass the requests of the client to the servant at runtime, both must be run in separate threads.</p>
<p>In this design pattern, what the proxy does after receiving a request is that it sets up a method request object and inserts it in an activation list. This method carries out two jobs; holds the method request objects and keeps track of on which method request it can execute. Request parameters and any other information are contained in the method request object for executing the desired method later. This activation list in return helps the proxy and the servant to run concurrently.</p>
<p>Let's see another concurrency design pattern in the upcoming section, which is the monitor object pattern.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monitor object pattern</h1>
                </header>
            
            <article>
                
<p>Th<span>e monitor object pattern</span> is another concurrency design pattern that helps in the execution of multi-threaded programs. It is a design pattern implemented to make sure that at a single time interval, only one method runs in a single object, and for this purpose, it synchronizes concurrent method execution.</p>
<p>Unlike the active object design pattern, the monitor object pattern does not have a separate thread of control. Every request received is executed in the thread of control of the client itself, and until the time the method returns, the access is blocked. At a single time interval, a single synchronized method can be executed in one monitor.</p>
<p>The following solutions are offered by the monitor object pattern:</p>
<ul>
<li>The synchronization boundaries are defined by the interface of the object, and it also makes sure that a single method is active in a single object.</li>
<li>It must be ensured that all the objects keep a check on every method that needs synchronization and serialize them transparently without letting the client know. Operations, on the other hand, are mutually exclusive, but they are invoked like ordinary method calls. Wait and signal primitives are used for the realization of condition synchronization.</li>
<li>To prevent the deadlock and use the concurrency mechanisms available, other clients must be allowed to access the object when the method of the object blocks during execution.</li>
<li>The invariants must always hold when the thread of control is interrupted voluntarily by the method.</li>
</ul>
<p>Let's see the following diagram, which illustrates more about the monitor object design pattern in the concurrency application:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="183" width="298" class=" image-border" src="assets/ad5ee399-9e8f-4e4b-b51b-373ad439dbe3.png"/></div>
<p>In this preceding diagram, the client object calls the monitor object that has several synchronized methods and the monitor object associated with the monitor conditions and monitor locks. Let's explore each component of this concurrency design pattern as follows:</p>
<ul>
<li><strong>Monitor object</strong>: This component exposes the methods that are synchronized to the clients</li>
<li><strong>Synchronized methods</strong>: The thread-safe functions that are exported by the interface of the object are implemented by these methods</li>
<li><strong>Monitor conditions</strong>: This component along with the monitor lock decides whether the synchronized method should resume its processing or suspend it</li>
</ul>
<p>The active object and the monitor object patterns are the branches of design patterns of concurrency.</p>
<p>Now, the other type of concurrency patterns that we will discuss are the branches of architectural patterns for concurrency.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Half-Sync/Half-Async patterns</h1>
                </header>
            
            <article>
                
<p>The job of Half-Sync and Half-Async is to distinguish between the two types of processing called asynchronous and synchronous, for the simplification of the program without hindering its performance.</p>
<p>The two layers intercommunicating are introduced for both asynchronous and synchronous services for the purpose of processing with a queuing layer in between.</p>
<p>Every concurrent system contains both asynchronous and synchronous services. To enable these services to communicate with each other, the Half-Sync/Half-Async pattern decomposes the services in the system into layers. Using the queuing layer, both these services pass messages to each other for intercommunication.</p>
<p>Let's see the following diagram that illustrates these design patterns:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" src="assets/3ac500d9-772d-4adc-b337-c409fd5c7b19.png"/></div>
<p>As you can see in the preceding diagram, there are three layers--<strong>Synchronous Service Layer</strong>, <strong>Queuing Layer</strong>, and <strong>Asynchronous Service Layer</strong>. Synchronous layer contains the services that are working synchronously to the queue at the <strong>Queuing Layer</strong>, and this query performs asynchronously using Asynchronous services at the <strong>Asynchronous Service Layer</strong>. These Asynchronous Services at this layer are using the external event-based resources.</p>
<p>As you can see in the preceding diagram, there are three layers included here. Let's look at these layers:</p>
<ul>
<li><strong>Synchronous Task Layer</strong>: The tasks in this layer are active objects. High-level input and output operations are carried by these tasks, which transfer the data synchronously towards the queuing layer.</li>
<li><strong>Queuing Layer</strong>: This layer provides the synchronization and buffering required between the synchronous and asynchronous task layers.</li>
<li><strong>Asynchronous Task Layer</strong>: The events from the external sources are handled by the tasks present in this layer. These tasks do not contain a separate thread of control.</li>
</ul>
<p>We have discussed the Half-Sync and Half-Async design patterns of the concurrency pattern. Let's move to another concurrency pattern, that is, the leader/follower Pattern.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Leader/follower pattern</h1>
                </header>
            
            <article>
                
<p>Detection, demultiplexing, dispatching, and processing of service requests in the event sources is carried out in an efficient way in a concurrency model, in which many multiple threads process one by one to use the set on event sources. Another replacement for the Half-Sync/Half-Async is the leader/follower pattern. This pattern can be used instead of the <span>Half-Sync/Half-Async</span> and active object patterns for improvement in the performance. The condition of using this is that there must be neither ordering nor synchronization constraints while processing multiple threads of requests:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="178" width="485" src="assets/4a208fe3-b0fc-44b4-92f7-39a0d103bfd5.jpg"/></div>
<p>The focused job of this pattern is to process multiple events concurrently or simultaneously. Due to concurrency-related overheads, it might not be possible to connect a separate thread with each single socket handle. The highlighted feature of this design is that by using this pattern, demultiplexing the associations between threads and event source becomes possible. When the events arrive on the event sources, this pattern builds up a pool of threads. This is done to share a set of event sources efficiently. These event sources demultiplex the arriving events turn by turn. Also, the events are synchronously dispatched to application services for processing. Out of the pool of threads structured by the leader/follower pattern, only a single thread waits for the occurrence of the event; other threads queue up waiting. A follower is promoted as the leader when a thread detects an event. It then processes the thread and dispatches the event to the application handler.</p>
<p>In this type of pattern, processing threads can be run concurrently, but only one thread is allowed to wait for the upcoming new events.</p>
<p>Let's see another concurrency-based design pattern in the upcoming section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reactor pattern</h1>
                </header>
            
            <article>
                
<p>The reactor pattern is used to handle service requests that are received concurrently by a service handler from a single or multiple input sources. The received service requests are then demultiplexed by the service handler and dispatched to the associated request handlers. All the reactor systems are commonly found in single threads, but they are also said to exist in a multi-threaded environment.</p>
<p>The key benefit of using this pattern is that the application components can be divided into multiple parts such as modular or reusable. Furthermore, this allows simple coarse-grain concurrency without the additional complexity of multiple threads to the system.</p>
<p>Let's see the following diagram about the reactor design pattern:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="247" width="381" class=" image-border" src="assets/134addef-7c54-433a-9106-abe5fd104dd4.png"/></div>
<p>As you can see in the preceding diagram, the dispatcher uses the demultiplexer to notify handler and the handler performs the actual work to be done with an I/O event. A reactor responds to I/O events by dispatching the appropriate handler. Handlers perform non-blocking actions. The preceding diagram has the following components of this design pattern:</p>
<ul>
<li><strong>Resources:</strong> These are the resources through which input is provided or output is consumed.</li>
<li><strong>Synchronous event demultiplexer:</strong> This blocks all resources via an event loop. When there is a possibility that a synchronous operation will start, the resource is sent to the dispatcher through the demultiplexer without blocking.</li>
<li><strong>Dispatcher:</strong> The registering or unregistering of request handler is handled by this component. Resources are dispatched to the respective request handler through the dispatcher.</li>
<li><strong>Request Handler:</strong> This handles the request dispatched by the dispatcher.</li>
</ul>
<p>Now, we are moving on to our next and the last concurrency pattern that is the thread-specific storage pattern.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Thread-specific storage pattern</h1>
                </header>
            
            <article>
                
<p>A single logical global access point can be used to retrieve an object local to the thread. This concurrency design pattern allows multiple threads to carry this function out. This is done without incurring locking overhead on each access to the object. Sometimes, this particular pattern can be viewed as an antithesis among all the concurrency design patterns. This is due to the fact that several complexities are addressed by the thread-specific storage by prevention of sharing of the available resources among the threads.</p>
<p>The method appears to be invoked on an ordinary object by the application thread. Actually, it is invoked on a thread-specific object. A single thread-specific object proxy can be used by multiple application threads for accessing the unique thread-specific objects associated to each of them. The proxy to distinguish between the thread-specific object it encapsulates uses the application thread identifier.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Best practices for concurrency module</h1>
                </header>
            
            <article>
                
<p>Here is a list of considerations that a programmer must look into when carrying out concurrency. Let's look at the following best practices to consider when you to get a chance to work with the concurrent application module.</p>
<ul>
<li><strong>Obtaining an executor</strong>: The Executor Framework for obtaining an executor supplies the executors utility class. Various types of executors offer specific thread executions policies. Here are three examples:
<ul>
<li><strong>ExecutorService newCachedThreadPool()</strong>: This creates a thread pool using the previously constructed threads if available. The performance of the programs that make use of the short-lived asynchronous tasks is enhanced using this type of thread pool.</li>
<li><strong>ExecutorService newSingleThreadExecutor()</strong>: A worker thread that is operating in an unbounded queue is used here to create an executor. In this type, the tasks are added to the queue that is then executed one by one. In case, this thread fails during the execution, a new thread will be created and replace the failed thread so that the tasks can be executed without interruption.</li>
<li><strong>ExecutorService newFixedThreadPool(int nThreads)</strong>: A fixed number of threads that are operating in a shared unbounded queue are reused in this case for the creation of a thread pool. At threads, the tasks are being actively processed. While all the threads in the pool are active and new tasks are submitted, the tasks will be added in the queue until a thread becomes available for the processing of the new task. If before the shutdown of the executor, the thread fails, a new thread will be created for carrying out the execution of the task. Note that these thread pools exist only when the executor is active or on.</li>
</ul>
</li>
<li><strong>Use of cooperative synchronized constructs</strong>: It is recommended to use cooperative synchronized constructs when possible.</li>
<li><strong>No unnecessary lengthy tasks and oversubscription</strong>: Lengthy tasks are known to cause deadlock, starvation, and even prevent other tasks from functioning properly. Larger tasks can be broken down into smaller tasks for proper performance. Oversubscription is also a way to avoid the deadlock, starvation, and so on. Using this, more threads than the available number of threads can be created. This is highly efficient when a lengthy task contains a lot of latency.</li>
<li><strong>Use of concurrent memory-management functions</strong>: If in a situation, ensuing <span>concurrent memory management functions can be used, it is highly recommended to use it. These can be used when objects with a short lifetime are used. The functions such as <kbd>Allot</kbd> and <kbd>Free</kbd> are used to free memory and allocate, without memory barriers or using locks.</span></li>
<li><strong>Use of RAII to manage the lifetime of concurrency objects</strong>: RAII is the abbreviation for <strong>Resource Acquisition Is Initialization</strong>. This is an efficient way to manage the lifetime of a concurrency object.</li>
</ul>
<p>This was all about the concurrency and it's design patterns that can be used to handle and implement concurrency. These are the most common five design patterns for concurrency programs. Also, some of the best practices for carrying out concurrency modules were discussed. Hope this was an informative a piece and helped you understand how concurrency patterns work!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, you learned several concurrency design patterns and also saw the use cases of these patterns. In this book, I have covered only the basic of the concurrency design patterns. We have included the active object, monitor object, Half-Sync/Half-Async, leader/followers, thread-specific storage, and reactor patterns. These all are the part of the concurrency design patterns in the multithreaded environment of the application. We also discussed some best practices consideration to use the concurrency design pattern in the application.</p>


            </article>

            
        </section>
    </body></html>