<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Playing with Server-Sent Events</h1>
                </header>
            
            <article>
                
<p class="mce-root">In <a href="4286f9d7-1fe5-49c7-9201-49f9c9bdddf6.xhtml">Chapter 4</a><span>, Kotlin Basics and Spring Data Redis and</span> <a href="eb1d7de5-c93b-49c2-a1a5-2c5e8b65cddc.xhtml" target="_blank">Chapter 5</a>, <em>Reactive Web Clients</em>, we created two microservices. The first one is responsible for keeping tracked data on Redis and triggering the second microservice which one will consume the Twitter stream. This process happens asynchronously.</p>
<p>In this chapter, we will create another microservice which will consume the data produced by Twitter Gathering and expose it via a REST API. It will be possible to filter Tweets by text content.</p>
<p>We have consumed the Twitter stream using the <strong>Server-Sent Events</strong> (<strong>SSE</strong>); we created a reactive REST client to consume that. Now, it is time to create our implementation for SSE. We will consume the RabbitMQ queue and push the data to our connected clients.</p>
<p>We will take a look at the SSE and understand why this solution fits well for our couple of microservices.</p>
<p>At the end of the chapter, we will be confident about using SSE in the Spring ecosystem.</p>
<p>In this chapter, we will learn the following:</p>
<ul>
<li>I<span>mplementation of SSE endpoints with the Spring Framework</span></li>
<li>Consuming RabbitMQ using the Reactor Rabbit client</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating the Tweet Dispatcher project</h1>
                </header>
            
            <article>
                
<p>Now, we will create our last microservice. It will push the Tweets filtered by Twitter Gathering for our connected clients, in this case, consumers.</p>
<p>In this chapter, we will use the Spring Initializr page to help us create our pretty new project. Let's create.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using Spring Initializr once again</h1>
                </header>
            
            <article>
                
<p>As you can see, the Spring Initializr page is a kind of partner for creating Spring projects. Let's use it one more time and create a project:</p>
<p>Go to <a href="https://start.spring.io">https://start.spring.io</a> and fill in the data using the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/57bc2578-b33b-401b-8b6d-aa0e113e2c8e.png"/></div>
<p>We have selected the <span class="packt_screen">Reactive Web</span> dependencies; we will also keep using Kotlin as a programming language. Finally, click on the <span class="packt_screen">Generate Project</span> button. Good, it is enough for us.</p>
<p>There are some missing dependencies which are not displayed in the Spring Initializr. We need to set these dependencies manually. We will do that task in the next section. Let's go there.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Additional dependencies</h1>
                </header>
            
            <article>
                
<p>We need to use the Jackson Kotlin Module as a dependency to handle JSON properly in our new microservice. Also, we will use the Reactor RabbitMQ dependency, which allows us to interact in the reactive paradigm with the RabbitMQ Broker.</p>
<p>To add these dependencies, we need to add the following snippet to <kbd>pom.xml</kbd>:</p>
<pre style="padding-left: 30px"><span>&lt;dependency&gt;<br/></span><span>  &lt;groupId&gt;</span>com.fasterxml.jackson.module<span>&lt;/groupId&gt;<br/></span><span>  &lt;artifactId&gt;</span><strong>jackson-module-kotlin</strong><span>&lt;/artifactId&gt;<br/></span><span>  &lt;version&gt;</span>${jackson.version}<span>&lt;/version&gt;<br/></span><span>&lt;/dependency&gt;<br/></span><span><br/></span><span>&lt;dependency&gt;<br/></span><span>  &lt;groupId&gt;</span>io.projectreactor<span>&lt;/groupId&gt;<br/></span><span>  &lt;artifactId&gt;</span><strong>reactor-test</strong><span>&lt;/artifactId&gt;<br/></span><span>  &lt;scope&gt;</span>test<span>&lt;/scope&gt;<br/></span><span>&lt;/dependency&gt;<br/></span><span><br/></span><span>&lt;dependency&gt;<br/></span><span>  &lt;groupId&gt;</span>io.projectreactor.rabbitmq<span>&lt;/groupId&gt;<br/></span><span>  &lt;artifactId&gt;</span><strong>reactor-rabbitmq</strong><span>&lt;/artifactId&gt;<br/></span><span>  &lt;version&gt;</span>1.0.0.M1<span>&lt;/version&gt;<br/></span><span>&lt;/dependency&gt;</span></pre>
<p>Awesome. Our dependencies are configured. Our project is ready to start.</p>
<p>Before we start, we need to understand, in depth, the concept of SSE. We will learn this in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Server-Sent Events</h1>
                </header>
            
            <article>
                
<p>Server-Sent Events (SSE) is a standard way to send data streams from a server to clients. In this next section, we will learn how to implement it using the Spring Framework.</p>
<p>Also, we will understand the main differences between SSE and WebSockets.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">A few words about the HTTP protocol</h1>
                </header>
            
            <article>
                
<p>HTTP is an application layer protocol in the OSI model. The application layer is the last layer represented in the OSI model. It means this layer is closer to the user interface. The main purpose of this layer is to send and receive the data input by the user. In general, it happens by the user interface, also known as applications, such as file transfer and sending an email.</p>
<p>There are several protocols on the application layer such as <span>Domain Name Service</span> <span>(</span>DNS<span>),</span> which translates the domain names to IP address, or SMTP, whose main purpose is to deliver an email to a mail manager application.</p>
<p>The application layer interacts directly with software such as email clients, for instance; there are no interactions with the hardware parts. It is the last layer of the OSI model and the closest to the end user as well.</p>
<p>All these layers deal with software, which means there are no concerns about the physical parts represented in the OSI model.</p>
<div class="packt_tip">A more detailed explanation of the OSI model can be found at: <a href="https://support.microsoft.com/en-us/help/103884/the-osi-model-s-seven-layers-defined-and-functions-explained">https://support.microsoft.com/en-us/help/103884/the-osi-model-s-seven-layers-defined-and-functions-explained</a>.<a href="https://support.microsoft.com/en-us/help/103884/the-osi-model-s-seven-layers-defined-and-functions-explained"/></div>
<p>The following is an OSI model representation:</p>
<div class="CDPAlignCenter CDPAlign"><img height="217" src="assets/ea0ff23f-16c7-4bd9-835f-e196d6d8487d.png" width="406"/></div>
<p>The HTTP protocol uses the TCP protocol as a transportation channel. Then, it will establish a connection and start to flow the data on the channel.</p>
<p>The TCP protocol is a stream protocol and a full duplex channel. This means the server and clients can send data across the connection.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">HTTP and persistent connections</h1>
                </header>
            
            <article>
                
<p>The HTTP protocol is a request-response model, where the client submits the message (HTTP Request) and the server processes this message and sends the response (HTTP Response) to the client. The connection will be closed after the response is sent.</p>
<p>Look at the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img height="79" src="assets/677329f9-078d-4ff4-b3d4-fc042251f6aa.png" width="340"/></div>
<p>It's pretty simple to understand. The client will send the request, and in this case, the connection will be opened. After that, the server will receive the request to process something and it will send the answer to the client. The connection will be closed after the whole process. If the client needs to send a new request, the connection should be opened again and the flow happens in the same order.</p>
<p>There is a perceived drawback here, the clients need to open the new connection per-request. From the server's eyes, the server needs to process a lot of new connections simultaneously. This consumes a lot of CPU and memory.</p>
<p>On HTTP's 1.0 version, the connections are not persistent. To enable it, the <kbd>keep-alive</kbd> header should be included on the request. The header should look like this:</p>
<pre><strong>Connection: keep-alive</strong></pre>
<p>This is the only way to make an HTTP connection persistent on the 1.0 version, as described previously; when it happens, the connection will not be dropped by the server and the client is able to reuse the opened connection.</p>
<p>On HTTP 1.1, the connections are persistent by default; in this case, as opposed to the first version, the connection is kept opened and the client can use it normally.</p>
<p>There is a perceived improvement here and it can bring some advantages. The server needs to manage fewer connections, and it reduces a lot of CPU time. The HTTP Requests and Responses can be pipelined in the same connection.</p>
<p>As we know, <em>there is no such thing as a free lunch</em>. There are some disadvantages to this as well; the server needs to keep the connection opened and the server will reserve the required connection for the client. This may cause server unavailability in some scenarios.</p>
<p><span> Persistent connections can be useful to maintain a stream between the server and clients.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">WebSockets</h1>
                </header>
            
            <article>
                
<p>In the HTTP protocol, the communication supports full-duplex, which means the client and server can send data through the channel. The standard way to support this kind of communication is WebSockets. In this specification, both client and server can send data to each other in the persistent connection. Look at the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img height="136" src="assets/1d3d89ff-2d73-426b-ad8d-95d5bfb0448a.png" width="365"/></div>
<p>As we can see, the data can be sent and received by the two actors, client, and server—this is how WebSockets works.</p>
<p>In our case, we do not need to send any data to the server during the connection. Because of this characteristic, we will choose SSE. We will learn about them in the following section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Server-Sent Events</h1>
                </header>
            
            <article>
                
<p>As opposed to the full-duplex communication implemented by WebSockets, the SSE uses a half-duplex communication.</p>
<p>The client sends a request to the server, and when necessary, the server will push the data to the client. Remember the active actor here is the server; the data can be sent only by the server. This is a half-duplex behavior. Look at the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img height="131" src="assets/92b99972-42e9-4a44-9346-60df700f5518.png" width="354"/></div>
<p>A piece of cake. It is the base of the SSE technology. SSE is self-explanatory. We will use it with the Spring Framework. However, before we do that, let's look at a Reactor RabbitMQ project.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reactor RabbitMQ</h1>
                </header>
            
            <article>
                
<p>Our solution is fully reactive, so we need to use Reactor RabbitMQ, which allows us to interact with the RabbitMQ broker using the reactive paradigm.</p>
<p>On this new microservice, we do not need to send messages through the message broker. Our solution will listen to the RabbitMQ queues and push the received Tweets for the connected clients.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding the Reactor RabbitMQ</h1>
                </header>
            
            <article>
                
<p>The Reactor RabbitMQ tries to provide a reactive library to interact with the RabbitMQ rboker. It enables developers to create non-blocking applications based on the reactive stream, using RabbitMQ as a message-broker solution.</p>
<p>As we learned before, this kind of solution, in general, does not use a lot of memory. The project was based on the RabbitMQ Java client and has similar functionalities, if we compare it to the blocking solution.</p>
<p>We are not using the <kbd>spring-amqp-starter</kbd>, so the magic will not happen. We will need to code the beans declarations for the Spring context and we will do that in the following section.  </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Configuring RabbitMQ Reactor beans</h1>
                </header>
            
            <article>
                
<p>In this section, we will configure the RabbitMQ infrastructure classes in the Spring context. We will use a <kbd>@Configuration</kbd> class to declare it. </p>
<p>The configuration class should look like the following:</p>
<pre style="padding-left: 30px"><span>package </span>springfive.twitterdispatcher.infra.rabbitmq<br/><br/><span>import </span>com.fasterxml.jackson.databind.ObjectMapper<br/><span>import </span>com.fasterxml.jackson.module.kotlin.KotlinModule<br/><span>import </span>com.rabbitmq.client.ConnectionFactory<br/><span>import </span>org.springframework.beans.factory.annotation.<span>Value<br/></span><span>import </span>org.springframework.context.annotation.<span>Bean<br/></span><span>import </span>org.springframework.context.annotation.<span>Configuration<br/></span><span>import </span>reactor.rabbitmq.ReactorRabbitMq<br/><span>import </span>reactor.rabbitmq.Receiver<br/><span>import </span>reactor.rabbitmq.ReceiverOptions<br/><br/><span>@Configuration<br/></span><span>class </span>RabbitMQConfiguration(<span>private @Value</span>(<span>"</span><span>\$</span><span>{spring.rabbitmq.host}"</span>)  <span>val </span><span>host</span>:String<span>,<br/></span><span>                            private @Value</span>(<span>"</span><span>\$</span><span>{spring.rabbitmq.port}"</span>)  <span>val </span><span>port</span>:Int<span>,<br/></span><span>                            private @Value</span>(<span>"</span><span>\$</span><span>{spring.rabbitmq.username}"</span>)  <span>val </span><span>username</span>:String<span>,<br/></span><span>                            private @Value</span>(<span>"</span><span>\$</span><span>{spring.rabbitmq.password}"</span>)  <span>val </span><span>password</span>:String){<br/><br/><span>  @Bean<br/></span><span>  fun </span><span>mapper</span>(): ObjectMapper = ObjectMapper().registerModule(KotlinModule())<br/><br/><span>  @Bean<br/></span><span>  fun </span><span>connectionFactory</span>():ConnectionFactory{<br/><span>    val </span>connectionFactory = ConnectionFactory()<br/>    connectionFactory.<span>username </span>= <span>this</span>.<span>username<br/></span>    connectionFactory.<span>password </span>= <span>this</span>.<span>password<br/></span><span>    </span>connectionFactory.<span>host </span>= <span>this</span>.<span>host<br/></span><span>    </span>connectionFactory.<span>port </span>= <span>this</span>.<span>port<br/></span><span>    </span>connectionFactory.useNio()<br/>    <strong>return connectionFactory</strong><br/>  }<br/><br/>  <span>@Bean<br/></span><span>  fun </span><span>receiver</span>(<strong>connectionFactory: ConnectionFactory</strong>):Receiver{<br/>      <span>val </span>options = ReceiverOptions()<br/>      options.connectionFactory(connectionFactory)<br/>      <strong>return ReactorRabbitMq.createReceiver(options)</strong><br/>  }<br/><br/>}</pre>
<p>There are two important things here. The first one is that we configured the Jackson support for Kotlin. It allows us to inject the <kbd>ObjectMapper</kbd> into our Spring beans. The next important thing is related to the RabbitMQ connections' configuration.</p>
<p>We have declared a <kbd>ConnectionFactory</kbd> bean for the Spring Context. We injected the configurations with <kbd>@Value</kbd> annotations and received the values on the constructor. We can set the value directly in the attributes, in the Kotlin language; look at the <kbd>ConnectionFactory</kbd> attributes assignments.</p>
<p>After the <kbd>ConnectionFactory</kbd> configuration, we are able to declare a receiver, which is a <kbd>Reactive</kbd> abstraction to consume the queues, using reactive programming. We receive the <kbd>ConnectionFactory</kbd> previously created and set it as the <kbd>ReceiverOptions</kbd>.</p>
<p>That is all for the Reactor RabbitMQ configuration.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Consuming the RabbitMQ queues reactively</h1>
                </header>
            
            <article>
                
<p>Now, we will consume the RabbitMQ queues. The implementation is quite similar to what we have seen in the blocking implementation, and the names of the functions are similar as well.</p>
<p>We have consumed some RabbitMQ messages in the previous chapters, but this solution is quite different. Now, we will use the Reactive RabbitMQ implementation. The main idea here is to consume the stream of events; these events represent the messages that have arrived in the broker. These messages arrive and the Reactor RabbitMQ converts these messages to Flux, to enable us to consume in the reactive paradigm.</p>
<p>In the reactive paradigm, the representation of a stream of events (we can think of messages in the queue), is the <kbd>Flux</kbd>.</p>
<p>Then our function, which is listening to the RabbitMQ, should return <kbd>Flux</kbd>, an infinite representation of events. The Receiver implementation returns the <kbd>Flux</kbd> of messages, which is enough for us and fits well with our needs.</p>
<p>Our implementation should look like the following:</p>
<pre style="padding-left: 30px"><span>package </span>springfive.twitterdispatcher.domain.service<br/><br/><span>import </span>com.fasterxml.jackson.annotation.<span>JsonIgnoreProperties<br/></span><span>import </span>com.fasterxml.jackson.annotation.<span>JsonProperty<br/></span><span>import </span>com.fasterxml.jackson.databind.ObjectMapper<br/><span>import </span>com.fasterxml.jackson.module.kotlin.readValue<br/><span>import </span>org.springframework.beans.factory.annotation.<span>Value<br/></span><span>import </span>org.springframework.stereotype.<span>Service<br/></span><span>import </span>reactor.core.publisher.Flux<br/><span>import </span>reactor.core.publisher.Mono<br/><span>import </span>reactor.rabbitmq.Receiver<br/><span><br/></span><span>@Service<br/></span><span>class </span>TwitterDispatcher(<span>private @Value</span>(<span>"</span><span>\$</span><span>{queue.twitter}"</span>) <span>val </span><span>queue</span>: String<span>,<br/></span><span>       private val </span><span>receiver</span>: Receiver<span>,<br/></span><span>       private val </span><span>mapper</span>: ObjectMapper) {<br/><br/>    <span>fun </span><span>dispatch</span>(): Flux&lt;Tweet&gt; {<br/>        <span>return this</span>.<span>receiver</span>.consumeAutoAck(<span>this</span>.<span>queue</span>).flatMap <span>{ </span>message <span>-&gt;<br/></span><span>            </span>Mono.just(<span>mapper</span>.<span>readValue</span>&lt;Tweet&gt;(<span>String</span>(message.<span>body</span>)))<br/>        <span>}<br/></span><span>    </span>}<br/><br/>}<br/><br/><span>@JsonIgnoreProperties</span>(<span>ignoreUnknown = </span><span>true</span>)<br/><span>data class </span>Tweet(<span>val </span><span>id</span>: String = <span>""</span><span>, <br/>   val </span><span>text</span>: String = <span>""</span><span>, @JsonProperty</span>(<span>"created_at"</span>) <br/><span>   val </span><span>createdAt</span>: String = <span>""</span><span>, val </span><span>user</span>: TwitterUser = TwitterUser(<span>""</span><span>, </span><span>""</span>))<br/><br/><span>@JsonIgnoreProperties</span>(<span>ignoreUnknown = </span><span>true</span>)<br/><span>data class </span>TwitterUser(<span>val </span><span>id</span>: String<span>, val </span><span>name</span>: String)</pre>
<p>Let's understand a little bit more. We received the <kbd>Receiver</kbd> as an injection in our constructor. When someone invokes the <kbd>dispatch()</kbd> function, the <kbd>Receiver</kbd> will start to consume the queue, which was injected in the constructor as well.</p>
<p>The <kbd>Receiver</kbd> produces <kbd>Flux&lt;Delivery&gt;</kbd>. Now, we need to convert the instance of <kbd>Flux&lt;Delivery&gt;</kbd>, which represents a message abstraction,  to our domain model Tweet. The <kbd>flatMap()</kbd> function can do it for us, but first, we will convert the <kbd>message.body</kbd> to string and then we have used Jackson to read JSON and convert to our Tweet domain model.</p>
<p>Take a look at how simple the code is to read; the API is fluent and really readable.</p>
<p>The consumer will not terminate until the connected client disconnects. We will be able to see this behavior soon.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Filtering streams</h1>
                </header>
            
            <article>
                
<p>We are receiving the messages from RabbitMQ. Now, we need to return the messages to the connected customer.</p>
<p>For that, we will use SSE with Spring WebFlux. The solution is a good fit for us because we will produce a <kbd>Flux&lt;Tweet&gt;</kbd> and start to push the Tweets for our clients. The clients will send a query to filter the desired Tweets.</p>
<p>The application will be fully reactive. Let's take a look at our code:</p>
<pre><span>package </span>springfive.twitterdispatcher.domain.controller<br/><br/><span>import </span>org.springframework.http.MediaType<br/><span>import </span>org.springframework.web.bind.annotation.<span>GetMapping<br/></span><span>import </span>org.springframework.web.bind.annotation.<span>RequestMapping<br/></span><span>import </span>org.springframework.web.bind.annotation.<span>RequestParam<br/></span><span>import </span>org.springframework.web.bind.annotation.<span>RestController<br/></span><span>import </span>reactor.core.publisher.Flux<br/><span>import </span>springfive.twitterdispatcher.domain.service.Tweet<br/><span>import </span>springfive.twitterdispatcher.domain.service.TwitterDispatcher<br/><span><br/></span><span>@RestController<br/></span><span>@RequestMapping</span>(<span>"/tweets"</span>)<br/><span>class </span>TweetResource(<span>private val </span><span>dispatcher</span>: TwitterDispatcher) {<br/><br/>  <strong>@GetMapping(produces = [MediaType.TEXT_EVENT_STREAM_VALUE])</strong><br/><span>  fun </span><span>tweets</span>(<span>@RequestParam</span>(<span>"q"</span>)query:String):Flux&lt;Tweet&gt;{<br/><span>    return </span><span>dispatcher</span>.dispatch()<br/>       .filter(<span>{ </span>tweet: Tweet? <span>-&gt; </span>tweet!!.<span>text</span>.<span>contains</span>(query<span>,</span><span>ignoreCase = </span><span>true</span>) <span>}</span>)<br/>    }<br/>}</pre>
<p>Pretty easy and simple to understand. We have declared the <kbd>tweets()</kbd> function; this function is mapped to a GET HTTP Request and produces a <kbd>MediaType.TEXT_EVENT_STREAM_VALUE</kbd>. When the client connects to the endpoint, the server will start to send Tweets accordingly with the desired argument.</p>
<p>When the client disconnects, the Reactor RabbitMQ will close the requested RabbitMQ connection.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dockerizing the whole solution</h1>
                </header>
            
            <article>
                
<p>Now, it is time to wrap the whole solution and create a Docker image for all projects. It is useful to run the projects anywhere we want.</p>
<p>We will configure all the projects step by step and then run the solution in Docker containers. As a challenge, we can use <kbd>docker-compose</kbd> to orchestrate the whole solution in a single <kbd>yaml</kbd> file.</p>
<p>For the Tracked Hashtag Service, we have created the docker image. Then, we will start to configure the Tweet Gathering, and the last one is Tweet Dispatcher. Let's do that right now.</p>
<div class="packt_tip">You can find more <kbd>docker-compose</kbd> project details at: <a href="https://docs.docker.com/compose/">https://docs.docker.com/compose/</a>. Also, in the new versions, <kbd>docker-compose</kbd> supports Docker Swarm to orchestrate the stack between cluster nodes. It can be really useful to deploy Docker containers in production.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tweet Gathering</h1>
                </header>
            
            <article>
                
<p>Let's configure our <kbd>pom.xml</kbd> for the Tweet Gathering project.</p>
<p>The build node should look like the following:</p>
<pre style="padding-left: 30px"><span>&lt;plugin&gt;<br/></span><span>  &lt;groupId&gt;</span>io.fabric8<span>&lt;/groupId&gt;<br/></span><span>  &lt;artifactId&gt;</span>docker-maven-plugin<span>&lt;/artifactId&gt;<br/></span><span>  &lt;version&gt;</span>0.21.0<span>&lt;/version&gt;<br/></span><span>  &lt;configuration&gt;<br/></span><span>    &lt;images&gt;<br/></span><span>      &lt;image&gt;<br/></span><span>        &lt;name&gt;</span>springfivebyexample/${project.build.finalName}<span>&lt;/name&gt;<br/></span><span>        &lt;build&gt;<br/></span><span>          &lt;from&gt;</span>openjdk:latest<span>&lt;/from&gt;<br/></span><span>          &lt;entryPoint&gt;</span>java -Dspring.profiles.active=container -jar <br/>             /application/${project.build.finalName}.jar<span>&lt;/entryPoint&gt;<br/></span><span>          &lt;assembly&gt;<br/></span><span>            &lt;basedir&gt;</span>/application<span>&lt;/basedir&gt;<br/></span><span>            &lt;descriptorRef&gt;</span>artifact<span>&lt;/descriptorRef&gt;<br/></span><span>            &lt;inline&gt;<br/></span><span>              &lt;id&gt;</span>assembly<span>&lt;/id&gt;<br/></span><span>              &lt;files&gt;<br/></span><span>                &lt;file&gt;<br/></span><span>        &lt;source&gt;</span>target/${project.build.finalName}.jar<span>&lt;/source&gt;<br/></span><span>                &lt;/file&gt;<br/></span><span>              &lt;/files&gt;<br/></span><span>            &lt;/inline&gt;<br/></span><span>          &lt;/assembly&gt;<br/></span><span>          &lt;tags&gt;<br/></span><span>            &lt;tag&gt;</span>latest<span>&lt;/tag&gt;<br/></span><span>          &lt;/tags&gt;<br/></span><span>          &lt;ports&gt;<br/></span><strong>            &lt;port&gt;8081</strong><span><strong>&lt;/port&gt;</strong><br/></span><span>          &lt;/ports&gt;<br/></span><span>        &lt;/build&gt;<br/></span><span>        &lt;run&gt;<br/></span><span>          &lt;namingStrategy&gt;</span>alias<span>&lt;/namingStrategy&gt;<br/></span><span>        &lt;/run&gt;<br/></span><span>        &lt;alias&gt;</span>${project.build.finalName}<span>&lt;/alias&gt;<br/></span><span>      &lt;/image&gt;<br/></span><span>    &lt;/images&gt;<br/></span><span>  &lt;/configuration&gt;<br/></span><span>&lt;/plugin&gt;</span></pre>
<p>Take a look at the port configuration; it should be the same as what we have configured in the <kbd>application.yaml</kbd>. The configuration is done, so let's create our Docker image:</p>
<pre><strong>mvn clean install docker:build</strong></pre>
<p>The command output should look like the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img height="121" src="assets/066d006d-c69c-43aa-a631-fca3b0b82cdc.png" width="674"/></div>
<p>There is an image recently created and tagged as a latest; the image is ready to run. Let's do the same thing for our Tweet Dispatcher project.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tweet Dispatcher</h1>
                </header>
            
            <article>
                
<p>Our new plugin entry should look like this:</p>
<pre style="padding-left: 30px"><span>&lt;plugin&gt;<br/></span><span>  &lt;groupId&gt;</span>io.fabric8<span>&lt;/groupId&gt;<br/></span><span>  &lt;artifactId&gt;</span>docker-maven-plugin<span>&lt;/artifactId&gt;<br/></span><span>  &lt;version&gt;</span>0.21.0<span>&lt;/version&gt;<br/></span><span>  &lt;configuration&gt;<br/></span><span>    &lt;images&gt;<br/></span><span>      &lt;image&gt;<br/></span><span>        &lt;name&gt;</span>springfivebyexample/${project.build.finalName}<span>&lt;/name&gt;<br/></span><span>        &lt;build&gt;<br/></span><span>          &lt;from&gt;</span>openjdk:latest<span>&lt;/from&gt;<br/></span><span>          &lt;entryPoint&gt;</span>java -Dspring.profiles.active=container -jar <br/>          /application/${project.build.finalName}.jar<span>&lt;/entryPoint&gt;<br/></span><span>          &lt;assembly&gt;<br/></span><span>            &lt;basedir&gt;</span>/application<span>&lt;/basedir&gt;<br/></span><span>            &lt;descriptorRef&gt;</span>artifact<span>&lt;/descriptorRef&gt;<br/></span><span>            &lt;inline&gt;<br/></span><span>              &lt;id&gt;</span>assembly<span>&lt;/id&gt;<br/></span><span>              &lt;files&gt;<br/></span><span>                &lt;file&gt;<br/></span><span>          &lt;source&gt;</span>target/${project.build.finalName}.jar<span>&lt;/source&gt;<br/></span><span>                &lt;/file&gt;<br/></span><span>              &lt;/files&gt;<br/></span><span>            &lt;/inline&gt;<br/></span><span>          &lt;/assembly&gt;<br/></span><span>          &lt;tags&gt;<br/></span><span>            &lt;tag&gt;</span>latest<span>&lt;/tag&gt;<br/></span><span>          &lt;/tags&gt;<br/></span><strong>          &lt;ports&gt;<br/>            &lt;port&gt;9099&lt;/port&gt;<br/></strong><span><strong>          &lt;/ports&gt;</strong><br/></span><span>        &lt;/build&gt;<br/></span><span>        &lt;run&gt;<br/></span><span>          &lt;namingStrategy&gt;</span>alias<span>&lt;/namingStrategy&gt;<br/></span><span>        &lt;/run&gt;<br/></span><span>        &lt;alias&gt;</span>${project.build.finalName}<span>&lt;/alias&gt;<br/></span><span>      &lt;/image&gt;<br/></span><span>    &lt;/images&gt;<br/></span><span>  &lt;/configuration&gt;<br/></span><span>&lt;/plugin&gt;</span></pre>
<p>Take a look at the port configuration, one more time. It will be used by Docker to expose the correct port. Now, we can run the image creation command:</p>
<pre><strong>mvn clean install docker:build</strong></pre>
<p>Then, we can see the command's output, as shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img height="141" src="assets/8e56bd22-6248-48d4-8e60-d489613bec65.png" width="737"/></div>
<p>Awesome, all images are ready. Let's run it.</p>
<div class="packt_infobox">We need to create Docker images for all the projects. The process is the same; configure the maven Docker plugin and then use <kbd>mvn clean install docker:build</kbd> on the project. The full source code can be found at GitHub. The Tracked Hashtag Service can be found here (<a href="https://github.com/PacktPublishing/Spring-5.0-By-Example/tree/master/Chapter04">https://github.com/PacktPublishing/Spring-5.0-By-Example/tree/master/Chapter04</a>), the Tweet Gathering can be found here (<a href="https://github.com/PacktPublishing/Spring-5.0-By-Example/tree/master/Chapter05">https://github.com/PacktPublishing/Spring-5.0-By-Example/tree/master/Chapter05</a>) and finally, the Tweet Dispatcher can be found here (<a href="https://github.com/PacktPublishing/Spring-5.0-By-Example/tree/master/Chapter06">https://github.com/PacktPublishing/Spring-5.0-By-Example/tree/master/Chapter06</a>).</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the containerized solution</h1>
                </header>
            
            <article>
                
<p>We are ready to run the solution in Docker containers. We have been running the solution with the IDE or command line, but now we will spin up some container and test the solution and Spring profiles as well.</p>
<p>Before that, let's do a quick recap of the solution:</p>
<div class="CDPAlignCenter CDPAlign"><img height="274" src="assets/149f2c98-e8b7-409e-89db-dd70f590dd30.png" width="440"/></div>
<ol>
<li>The first operation, the <strong>Tracked Hashtag Service</strong>, will persist the hashtag in the <strong>Redis</strong> database.</li>
<li>After that, the <strong>Tracked Hashtag Service</strong> will send the newly tracked hashtag to a queue in the <strong>RabbitMQ</strong> Broker.</li>
<li><strong>Tweet Gathering</strong> is listening to the queue to track Tweets and trigger the event and starts by listening to the <strong>Twitter stream</strong>.</li>
<li><strong>Tweet Gathering</strong> starts to get Tweets from the <strong>Twitter stream.</strong></li>
<li><strong>Tweet Gathering</strong> publishes Tweets to a queue in the <strong>RabbitMQ broker</strong>.</li>
<li><strong>Tweet Dispatcher</strong> consumes the message.</li>
<li><strong>Tweet Dispatcher</strong> sends the message to the <strong>Client</strong> using SSE.</li>
</ol>
<p>Now that we have understood the solution, let's starts the containers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the Tracked Hashtag Service container</h1>
                </header>
            
            <article>
                
<p>The image has been created in the previous section, so now we are able to spin up the container. The command to start the container should look like this:</p>
<pre><strong>docker run -d --name tracked --net twitter -p 9090:9090 springfivebyexample/tracked_hashtag</strong></pre>
<p>Let's explain the instruction. <kbd>-d</kbd> tells the Docker engine to run the container in background mode or detached.  The other important parameter is <kbd>--net</kbd>, which attaches the container to the desired network.</p>
<p>We can use the following command to tail the container logs at runtime:</p>
<pre><strong>docker logs tracked -f</strong></pre>
<p>This command is like the <kbd>tail -f</kbd> command on Linux, which looks at the last part of the log stream. We can remove the flag <kbd>-f</kbd> to see the last lines of the log.</p>
<p>The output of docker logs should look like this:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/4bb29b84-2014-4993-8b77-d956cc33554b.png"/></div>
<p>Look at the profile selected, in the logs:</p>
<pre><strong>INFO 7 --- [           main] s.t.TrackedHashTagApplication$Companion  : The following profiles are active: docker</strong></pre>
<p>Remember, we have parameterized it in the <kbd>pom.xml</kbd> file from the Tracked Hash Tag Service. Let's look at the following snippet:</p>
<pre><span>&lt;entryPoint&gt;</span>java <strong>-Dspring.profiles.active=docker</strong> -jar /application/${project.build.finalName}.jar<span>&lt;/entryPoint&gt;</span></pre>
<p>Awesome job. Our first service is running properly. Let's run Tweet Gathering; there is some interesting configuration here.  </p>
<div class="packt_infobox">We have created the Twitter network in <a href="4286f9d7-1fe5-49c7-9201-49f9c9bdddf6.xhtml">chapter 4</a>, <em>Kotlin Basics and Spring Data Redis</em>, and we need to use this network to enable the containers to see each other by container name in our custom network.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the Tweet Gathering container</h1>
                </header>
            
            <article>
                
<p>To run the <strong>Tweet Gathering</strong> application is slightly different. This container needs environment variables which are used to interact with the Twitter API. We can use the <kbd>-e</kbd> argument on the <kbd>docker run</kbd> command. Let's do that:</p>
<pre><strong>docker run -d --name gathering --net twitter -e CONSUMER_KEY=gupfxwn43NBTdxCD3Tsf1JgMu \</strong><br/><strong>-e CONSUMER_SECRET=pH4uM5LlYxKzfJ7huYRwFbaFXn7ooK01LmqCP69QV9a9kZrHw5 \</strong><br/><strong>-e ACCESS_TOKEN=940015005860290560-m0WwSyxGvp5ufff9KW2zm5LGXLaFLov \</strong><br/><strong>-e ACCESS_TOKEN_SECRET=KSofGB8aIwDmewceKXLbN8d5chvZkZyB31VZa09pNBhLo \</strong><br/><strong>-p 8081:8081 springfivebyexample/tweet_gathering</strong></pre>
<p>Take a look at the environment variables we have configured in the <kbd>application.yaml</kbd> file. The Docker run command will inject these variables into the system and then we can use them in our Java application.</p>
<p>Let's inspect our container logs. We can do that using the following command:</p>
<div class="CDPAlignCenter CDPAlign"><img height="153" src="assets/95db63ca-5835-4b1b-abf9-15be39543f26.png" width="804"/></div>
<p>Awesome, our application is up and running. As you can see, the application is connected to the RabbitMQ Broker.</p>
<div class="packt_tip"><strong>RabbitMQ</strong> and <strong>Redis</strong> should be running to enable you to run Tweet Gathering. We can check it using the <kbd>docker ps</kbd> command; it will list the running containers, RabbitMQ and Redis need to be on this list.</div>
<p>Now, we can run the Dispatcher application to complete the whole solution. Let's do that.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the Tweet Dispatcher container</h1>
                </header>
            
            <article>
                
<p>There is no secret to running the Tweet Dispatcher container. We can use the following command to run it:</p>
<pre><strong>docker run -d --name dispatcher --net twitter -p 9099:9099 springfivebyexample/tweet_dispatcher</strong></pre>
<p>It will spin up the container, it is a good idea to name the container during the run. It can help us manage the container with command-line tools, such as <kbd>docker container ls</kbd> or <kbd>docker ps</kbd>, because it shows the container name in the last column. Then, let's check if our container is running, so type the following command:</p>
<pre><strong>docker container ls</strong></pre>
<p>Or, you can run the following command:</p>
<pre><strong>docker ps</strong></pre>
<p>We should be able to see the Gathering container running, like in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/b4171847-c894-4bc1-a929-c35cbd234983.png"/></div>
<p>There are five containers, three applications, and two infrastructure services, <strong>RabbitMQ</strong> and <strong>Redis</strong>. </p>
<p>At any time, we can stop the desired container using the following command:</p>
<pre><strong>docker stop gathering</strong></pre>
<p>The <kbd>docker stop</kbd> will only stop the container; the information will be kept in the container volume. We can use the container name or container ID as well, we named it before. It is easy for us. If we use the <kbd>docker ps</kbd> command, the image recently stopped will never appear on the list. To show all the containers, we can use <kbd>docker ps -a</kbd> or <kbd>docker container ls -a</kbd>.</p>
<p>Now, we will start the container again; the command is self-explanatory:</p>
<pre><strong>docker start gathering</strong></pre>
<p>The container is running again. We have practiced more with Docker.  </p>
<p>Awesome job, guys. The whole application is containerized. Well done.</p>
<div class="packt_tip">We can use the Linux instruction and execute some batch instructions. For instance, we can use <kbd>docker stop $(docker ps -q)</kbd> — it will stop all containers running. The <kbd>docker ps -q</kbd> command will bring only the container's IDs.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The docker-compose tool</h1>
                </header>
            
            <article>
                
<p>In the microservices architectural style, the whole solution is decoupled in small and well-defined services. Usually, when we adopt these styles, we have more than one artifact to deploy.</p>
<p>Let's analyze our solution; we have three components to deploy. We have used the Docker containers and we have run these containers using the <kbd>docker run</kbd> command. One by one, we have used <kbd>docker run</kbd> three times. It is quite complex and very hard to do in the development routine.</p>
<p><kbd>docker-compose</kbd> can help us in this scenario. It is a tool which helps to orchestrate Docker containers in complex scenarios like ours.</p>
<p>Let's imagine our application is growing fast and we need to build four more microservices to achieve the desired business case, it will implicate on four more <kbd>docker run</kbd> commands and will probably be painful to maintain, especially during the development life cycle. Sometimes, we need to promote the artifacts to test the environment and we probably need to modify our command line to achieve this.</p>
<p><kbd>docker-compose</kbd> enables us to deploy multiple containers with a single <kbd>yaml</kbd> file. This <kbd>yaml</kbd> file has a defined structure which allows us to define and configure several containers in the same file. Moreover, we can run the solution configured in this <kbd>yaml</kbd> file with a single command, it makes development life easy.</p>
<p>The tool can work on the local machine or we can integrate it with the Docker Swarm tool which can manage clusters of Docker hosts.</p>
<div class="packt_infobox">Docker Swarm is a native tool to manage docker clusters. It makes it easy to deploy a container on the Docker cluster. In the new version, <kbd>docker-compose</kbd> is fully integrated with Docker Swarm. We can define it from Docker Swarm properties in <kbd>docker-compose.yaml</kbd>. The Docker Swarm documentation can be found at: <a href="https://docs.docker.com/engine/swarm/">https://docs.docker.com/engine/swarm/</a>.<a href="https://docs.docker.com/engine/swarm/"/></div>
<p>The <kbd>docker-compose</kbd> <kbd>yaml</kbd> has a defined structure to follow; the documentation can be found here: <a href="https://docs.docker.com/compose/compose-file/#compose-and-docker-compatibility-matrix">https://docs.docker.com/compose/compose-file/#compose-and-docker-compatibility-matrix.</a> We will create a simple file to understand the <kbd>docker-compose</kbd> behaviors. Let's create our simple <kbd>yaml</kbd>— the <kbd>yaml</kbd> should look like this:</p>
<pre style="padding-left: 30px">version: '3'<br/>services:<br/>  <strong>rabbitmq</strong>:<br/>    image: rabbitmq:3.7.0-management-alpine<br/>    ports:<br/>      - "5672:5672"<br/>      - "15672:15672"<br/>  <strong>redis</strong>:<br/>    image: "redis:alpine"<br/>    ports:<br/>      - "6379:6379"</pre>
<p>The <kbd>yaml</kbd> in the <span>preceding code </span>will create the structure detailed in the following diagram:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="122" src="assets/6aaa3300-e91e-4e0e-b96a-00849ed0f940.png" width="275"/></div>
<p>It simplifies the development time. Now, we will learn how to install <kbd>docker-compose</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing docker-compose</h1>
                </header>
            
            <article>
                
<p>The <kbd>docker-compose</kbd> installation is pretty simple and well-documented. We are using Linux, so we will use the Linux instructions.</p>
<p>Open the terminal and use the following command:</p>
<pre><strong>sudo curl -L https://github.com/docker/compose/releases/download/1.18.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose</strong></pre>
<p>Wait for the download and then we can execute the following instructions to give executable permissions for the program. Let's do this by executing the following command:</p>
<pre><strong>sudo chmod +x /usr/local/bin/docker-compose</strong></pre>
<p>As you may know, you may be asked for the administrator password. Our <kbd>docker-compose</kbd> is now installed. Let's check it:</p>
<pre><strong>docker-compose --version</strong></pre>
<p>The prompt will display the installed version, like the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img height="23" src="assets/777e6b4a-0f3e-400b-9859-eb04c5b5172b.png" width="430"/></div>
<p><kbd>docker-compose</kbd> is up and running, so let's jump to the next section and start to create our <kbd>yaml</kbd> file and deploy the whole stack with one single command.</p>
<div class="packt_infobox">For different operating systems, the instructions can be found here: <a href="https://docs.docker.com/compose/install/#install-compose">https://docs.docker.com/compose/install/#install-compose</a>. Then, you can navigate around the instructions and click on the desired operating system.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a docker-compose file</h1>
                </header>
            
            <article>
                
<p>Now, we have <kbd>docker-compose</kbd> installed and we can try to work with the tool. We want to run the whole stack with a single command. We will create the <kbd>yaml</kbd> file to represent the stack. Our <kbd>yaml</kbd> file should have the Redis container, the RabbitMQ container, the Tracked Hashtag application, the Gathering application, and finally, the Dispatcher application.</p>
<p>We can create a <kbd>docker-compose.yaml</kbd> file wherever we want, there is no restriction for that.</p>
<p>Our <kbd>docker-compose.yaml</kbd> file should look like the following:</p>
<pre style="padding-left: 30px"><strong>version: '3'</strong><br/>services:<br/>  rabbitmq:<br/>    image: rabbitmq:3.7.0-management-alpine<br/>    hostname: rabbitmq<br/>    ports:<br/>      - "5672:5672"<br/>      - "15672:15672"<br/>    networks:<br/>      - solution <br/>  redis:<br/>    image: "redis:4.0.6-alpine"<br/>    hostname: redis<br/>    ports:<br/>      - "6379:6379"<br/>    networks:<br/>      - solution <br/>  tracked:<br/>    image: springfivebyexample/tracked_hashtag<br/>    ports:<br/>      - "9090:9090"<br/>    networks:<br/>      - solution <br/>  gathering:<br/>    image: springfivebyexample/tweet_gathering<br/>    ports:<br/>      - "8081:8081"<br/>    networks:<br/>      - solution<br/>    environment:<br/>      - CONSUMER_KEY=gupfxwn43NBTdxCD3Tsf1JgMu<br/>      - CONSUMER_SECRET=pH4uM5LlYxKzfJ7huYRwFbaFXn7ooK01LmqCP69QV9a9kZrHw5<br/>      - ACCESS_TOKEN=940015005860290560-m0WwSyxGvp5ufff9KW2zm5LGXLaFLov<br/>      - ACCESS_TOKEN_SECRET=KSofGB8aIwDmewceKXLbN8d5chvZkZyB31VZa09pNBhLo<br/>  dispatcher:<br/>    image: springfivebyexample/tweet_dispatcher<br/>    ports:<br/>      - "9099:9099"<br/>    networks:<br/>      - solution<br/><strong>networks</strong>:<br/>  solution:<br/>    driver: bridge</pre>
<p>As you can see, we have defined the whole stack in the <kbd>yaml</kbd>. Something to note is that we can find some similarities with the <kbd>docker run</kbd> command, in fact, it will use the Docker engine to run. The <kbd>environment</kbd> node in yaml has the same behavior as <kbd>-e</kbd> in the Docker run command.</p>
<p>We have defined the application ports, docker images, and have also connected the containers to the same network. This is really important because when we use the <kbd>docker-compose</kbd> file name on the network, it can find that the container name has a kind of DNS behavior.</p>
<p>For instance, inside the defined network <kbd>solution</kbd>, the container can find the Redis container instance by the name <kbd>redis</kbd>. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the solution</h1>
                </header>
            
            <article>
                
<p><kbd>docker-compose</kbd> simplifies the process to run the whole stack. Our <kbd>yaml</kbd> file was configured and defined properly.</p>
<p>Let's start the solution. Run the following command:</p>
<pre><strong>docker-compose up -d</strong></pre>
<p>The command is pretty simple, the <kbd>-d</kbd> parameter instructs Docker to run the command in the background. As we did on the Docker run command.</p>
<p>The output of this command should be the following:</p>
<div class="CDPAlignCenter CDPAlign"><img height="99" src="assets/c8203e6b-2c71-488d-973b-8a4117d43d28.png" width="468"/></div>
<p>Take a look, <kbd>docker-compose</kbd> has created a network for our stack. In our case, the network driver is a bridge, after the network creation, the containers are started.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Testing the network</h1>
                </header>
            
            <article>
                
<p>Let's test it, find the Gathering container – the container name in <kbd>docker-compose</kbd> is prefixed by the folder name, where <kbd>docker-compose</kbd> was started.</p>
<p>For instance, I have started my <kbd>docker-compose</kbd> stack in the compose folder. My container name will be <kbd>compose_gathering_1</kbd> because of the folder name.</p>
<p>Then, we will connect the Gathering container. It can be achieved using the following command:</p>
<pre><strong>docker exec -it compose_gathering_1  /bin/bash</strong></pre>
<p>The <kbd>docker exec</kbd> command allows us to execute something inside the container. In our case, we will execute the <kbd>/bin/bash</kbd> program.</p>
<p>The command structure is like this:</p>
<pre class="mce-root"><strong>docker exec -it &lt;container name or container id&gt; &lt;program or instruction&gt;</strong></pre>
<p>Awesome, pay attention to the command line. It should be changed because now we are in the container command line:</p>
<div class="CDPAlignCenter CDPAlign"><img height="66" src="assets/f34083e9-fde1-47af-af2a-945b3d067aa3.png" width="439"/></div>
<p>We are not connected as a root on our host, but now we are a root on the container. This container is on the same network as the Redis container instance, which is called <kbd>redis</kbd>.</p>
<p>Let's test with the <kbd>ping</kbd> command; we should be able to find the <kbd>redis</kbd> container by the name <kbd>redis</kbd>, let's do it. Type the following:</p>
<pre><strong>ping redis</strong></pre>
<p>The command output should be the following:</p>
<div class="CDPAlignCenter CDPAlign"><img height="138" src="assets/150fa99d-cf12-40d7-9162-a7eb0e640f09.png" width="386"/></div>
<p>Awesome, our container can find the Redis container by the name. The <kbd>yaml</kbd> file is fully working.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we completed our second solution. We were introduced to the RabbitMQ Reactor library, which enables us to connect to RabbitMQ, using the reactive paradigm.</p>
<p>We have prepared the whole solution in Docker containers and connected it to the same network to enable the applications to talk to each other.</p>
<p>We also learned the important pattern for pushing data from server to client through the HTTP persistent connection, and we learned the difference between WebSockets and Server-Sent Events, as well.</p>
<p>Finally, we learned how <kbd>docker-compose</kbd> helps us to create the stack and run the whole solution with a couple of commands.</p>
<p>In the following chapters, we will build a fully microservice solution, using some important patterns such as Service Discovery, API Gateway, Circuit Breakers, and much more.</p>


            </article>

            
        </section>
    </body></html>