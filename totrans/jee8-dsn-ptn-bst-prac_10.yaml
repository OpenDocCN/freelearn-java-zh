- en: Deployment Patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will be looking at deployment patterns, why we use them,
    and how they impact the delivery of applications. We will also cover the concepts
    of canary deployment, blue/green deployment, A/B deployment, and continuous deployment.
    After reading this chapter, we should be familiar with the concept of deployment
    patterns. The topics we will cover in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The concept of deployment patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The concept of canary deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The concept of blue/green deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The concept of A/B testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The concept of continuous deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explaining the concept of deployment patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Applications constantly receive updates that function to create new features
    or correct any problems. These new features and updates need to be promoted to
    a production-level without causing any problems or delays to a service. Furthermore,
    it is sometimes necessary to deliver a new version of an application to a select
    group of users, such as those in certain countries or certain business areas.
  prefs: []
  type: TYPE_NORMAL
- en: When we talk about *delivery* in this context, we are referring to releasing
    a new version of an application into the production environment. A software project
    has various steps that need to be evaluated and considered in order to permit
    the delivery of good software.
  prefs: []
  type: TYPE_NORMAL
- en: These steps include following a good process to get the business role, a good
    process for testing the application, a good process for developing the code of
    the application, and a good process for delivering the project to production,
    which is the aim of the project. All software projects have one important common objective—to
    deliver good, high-quality software without causing any collateral effects. The
    deployment step is a very important step in particular, as this is when the software
    is delivered; the overall goal of the project will be achieved here, but if any
    errors occur, then all projects can be impaired. As a result of this step, deployment
    patterns were created.
  prefs: []
  type: TYPE_NORMAL
- en: 'Deployment patterns (also known as **deployment strategies**) are a set of
    solutions for common deployment-related problems. These patterns make the deployment
    process safer and mitigate the chance of errors occurring in new releases. Some
    examples of deployment patterns include:'
  prefs: []
  type: TYPE_NORMAL
- en: Canary deployment
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: Blue/green deployment
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A/B testing
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Continuous deployment is also a deployment pattern, but we did not include
    this in the list because it is the most comprehensive method, one that creates
    a pipeline and works at all steps of the delivery. Furthermore, continuous deployment
    more accurately describes the solution of automating the development stages, and
    this can be used with any of the deployment patterns listed previously. With this,
    the patterns we mentioned work in reduced scope and the continuous deployment
    pattern works on a large scope. In the following diagram, you can see how these
    two types of deployment patterns work, as well as the stages they follow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5771a09c-d28f-4246-85b1-1ff5570dd062.png)'
  prefs: []
  type: TYPE_IMG
- en: In some literature, the concept of continuous deployment is covered together
    with the concept of continuous delivery. This is because these two concepts are
    very similar, with only some small differences between them. The difference between
    these concepts will be shown in detail in the *Explaining the concept of continuous
    deployment* section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Explaining the concept of canary deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As previously mentioned, when we write a new version of an application, we need
    to deliver it without stopping or delaying the service in any way. An important
    step, therefore, is to deploy and test the new version first. If an error occurs,
    we will then need to rollback the deployments and maintain the old version of
    the application until any problems with the new version are solved. The canary
    deployment was created to so solve deployment-related problems such as this.
  prefs: []
  type: TYPE_NORMAL
- en: 'The canary deployment is a deployment pattern that allows us to deliver a new
    version of an application to the subset of a server. Then, the new version of
    the application can be tested, and, if an error occurs, then the delivery rolls
    back and keeps the old version, propagating a new version for the remaining servers.
    In this pattern, we can define some servers as canary servers. The deployment
    first occurs in the canary server, after which a test is done on the canary server.
    If satisfied, the new version is propagated (or deployed) to the remaining servers.
    This pattern consists of the following four basic steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Defining the canary servers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploying the application to canary servers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Testing the application and verifying whether it satisfies our criteria
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploying the application to the remaining servers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following diagram shows a visual representation of these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9dfe427c-2e3e-4013-96d7-be57c20f6979.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To implement the canary deployment as a solution for delivering an application,
    you will first need to configure a proxy that redirects the requests to servers
    that are not canary servers. The following diagram demonstrates how canary deployment
    works:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/be3223dc-d22e-4d4f-8083-6349e31cc926.png)'
  prefs: []
  type: TYPE_IMG
- en: Defining the canary servers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this step, some servers will be selected as a canary server, which is the
    server used to test a new version after deploying an application in the remaining
    servers. Here, we select which servers should be the canary servers. It is very
    important to ensure that all steps of canary deployment are completed without
    impacting the users who access the application. Some important questions to consider
    when creating definitions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Do we want to test the behavior of an application in multiple instances of a
    server?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many servers can I use as canary servers without impacting user access?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How well does my application work with the new version and the old version of
    an application in the same environment?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What tests will be executed?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The amount of canary servers used is very important, so we recommend that the
    number of canary servers does not exceed 50% of the total servers in the production
    environment. Furthermore, when defining the number of canary servers, we need
    to decide what kind of scenarios we will be testing for. Whether we test the application's
    ability to work well with multiple servers or not, we will still need at least
    two canary servers. Using two canary servers is often a good idea, as the number
    is rarely larger than 50% of the total servers in the production environment.
    In other words, the total number of servers in the production environment is usually
    bigger than four. If we imagine that the total of servers in a production environment
    is four when we use two servers as canary servers, then the other two servers
    will be used to access the old version of the application. Depending on the number
    of users with access, the application should not have any performance problems.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the application to canary servers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When an application is deployed in a canary server, the canary server cannot
    be accessed by users and the proxy cannot redirect a request to these servers.
    At this moment, the production environment stays with two versions of the application—the
    old version and the new version. The application needs to prepare to work with
    two versions in the same environment. Note that users don't lose access to the
    application in this scenario, and the deployment of newer versions is done with
    transparent behavior and without impacting users.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the application and verifying whether it satisfies our criteria
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this step, the application is tested to verify whether or not our criteria
    are satisfied. This is done by evaluating certain processes, such as integrating
    with other applications, CPU, memory, disk usage, and database connection. These
    tests can be done through an automation test, an internal user, or through a few
    end users. If an error is found in this step, the deployment is aborted and rolled
    back and the canary servers receive the old version, which is then made available
    to end users.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the application to remaining servers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This step is only initialized if an application has been approved and verified
    as satisfactory. When this step is started, the canary server becomes a server
    for the end user access; the other servers do not receive a new request here because
    the process of deployment will have been started. The proxy then redirects all
    end users' requests to servers with a new version (in other words, the canary
    servers) and the deployment of another server is started. Once deployment is complete,
    all servers are able to receive access to the end users.
  prefs: []
  type: TYPE_NORMAL
- en: With canary deployment, the end user should not be aware that deployment is
    occurring. Users will only be aware if an interface is changed, or if some functionality
    is made available or unavailable to them.
  prefs: []
  type: TYPE_NORMAL
- en: Explaining the concept of blue/green deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Blue/green deployment is very similar to canary deployment in the sense that
    it deploys new versions of an application using the process of partition. The
    blue/green method deploys the application into a subset of servers in the production
    environment and then propagates the new version to the remaining servers. This
    deployment pattern differs from canary deployment with regard to its goals, because
    the blue/green deployment aims to reduce an application's downtime during deployment.
    With canary deployment, however, the goal is to reduce the occurrence of an error
    in the production environment associated with the new version. Furthermore, with
    canary deployment, the production environment can stay with both a new version
    and an old version and receive requests simultaneously, while in a blue/green
    deployment, only one version responds to requests.
  prefs: []
  type: TYPE_NORMAL
- en: The **blue/green deployment** is a deployment pattern that makes it possible
    to deploy a new version of an application without making the application inactive
    to the end user. With this pattern, the deployment is effected with a group of
    servers. If the deployment is completed successfully, then the remaining servers
    are deployed.
  prefs: []
  type: TYPE_NORMAL
- en: 'This pattern has the following three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Defining a group of servers to receive the first deployment
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploying the application to a group of servers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploying the application to the remaining server
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Defining the group of servers to receive the first deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: On the blue/green deployment, defining the group of servers to receive the first
    deployment is very easy because no tests will run and nothing will be checked;
    the process of deployment simply needs to be completed successfully. A good practice
    is to divide the production environment into two groups of servers and select
    one group to receive the deployment first. Each group will generally have approximately
    50% of production servers.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the application to a group of servers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this step, the requests are redirected to the server of the group in order
    for it to deploy, and the group to deploy receives the deployment of a new version
    of an application. All servers of the group to deploy will be dead in this time
    and will only respond to requests once the process of deployment in the group
    has finished. The following diagram illustrates an example of this process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/694a306f-f915-4d48-978d-78615fdda8b5.png)'
  prefs: []
  type: TYPE_IMG
- en: Deploying the application to the remaining server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This step is started only if the deployment process was successfully completed
    with the group that was selected to receive the first deployment. When this step
    is started, the group of servers selected to receive the first deployment returns
    to the activity, and all requests sent by the end user are processed by servers
    of this group with a new version deployed. The deployment of the remaining servers
    is then initialized, and, until deployment is complete, the remaining servers are
    dead. When deployment is finished, all servers will be able to receive and process
    requests, and all servers will stay with the new version of the application. This
    process is illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/80e628d2-3fb3-4d54-8513-65fbcb3eb404.png)'
  prefs: []
  type: TYPE_IMG
- en: Explaining the concept of A/B testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We may sometimes update something in our application and want to check its impact
    on end users and their behavior. Generally, these kinds of updates relate to the
    usability or popularity of an application and are associated with UI changes.
    To allow us to check the impact of an update on an application, we need to create
    groups of end users, who will be thrown the new updates and asked to evaluate
    them. The deployment patterns we've already discussed don't solve this problem
    for us as they're unable to throw a new version of the application to a separate
    group of end users. Although they allow us to test the functionality of the application
    in a separated group, that group doesn't persist for very long.
  prefs: []
  type: TYPE_NORMAL
- en: 'A/B testing, however, is a deployment pattern that allows us to throw a new
    version of an application to a selected group of end users only. This makes it
    possible to evaluate the impact of a new version of an application on end users
    and therefore decide whether or not it will be thrown to all end users. This deployment
    pattern is commonly used by popular applications such as Facebook, LinkedIn, and
    Twitter, as these applications are most successful when their features are popular
    among users. This pattern can be implemented with application-level switches or
    with a proxy that redirects end users to a respective application. The following
    diagram illustrates an example of the A/B testing pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e53a2846-5f73-4cf0-8a8c-dd691a948fca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This pattern requires the four following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Defining a group of end users to receive the new version of the application
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Defining the servers to receive a new version
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploying the new version of an application to selected servers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluating the impact of the new version of the application
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Defining a group of end users
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this step, we select a group of end users to receive a new version of an
    application. To define this group, a number of things need to be evaluated. Some
    of these evaluations include:'
  prefs: []
  type: TYPE_NORMAL
- en: The new features existing in a new version
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The localization of end users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Business roles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The end users selected for A/B testing need to be defined and marked by the
    application in order to allow it to distinguish between end users with access
    to the new version and those without. This can be done using a cookie, filtering
    by IP address if the group is location-related, or by using another mechanism
    that grants an end user access to the new version.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the servers to receive a new version
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this step, we define the group of servers that will receive the deployment
    of a new version. The selection and amount of servers to receive the deployment
    needs to be evaluated by the percentage of end users that will be able to access
    the new version. Depending on various scenarios, we should also evaluate the localization
    of users.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the new version
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this step, we deploy the new version of an application to the selected group
    of servers. These servers will then become dead and deployment will start. In
    this step, it is advisable to use either the canary deployment or the blue/green
    deployment to minimize the chance of error. Once deployment is complete, we will
    grant access to the new version of the application to the selected group of end
    users.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the impact of a new version
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this step, we evaluate the impact of the new version of an application. This
    step can be done using many different tools and techniques, the use of which depends
    on what our goals for the new features are, what the roles involved with these
    new features are, and any other questions that may arise according to business
    logic. This task generally consists of collecting data and analyzing it to verify
    the way end users behave with new features. After the evaluation is complete,
    we can then decide whether to throw the new version to the remaining end users
    or to remove them from the application.
  prefs: []
  type: TYPE_NORMAL
- en: Explaining the concept of continuous deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The process of delivery release to users consists of important steps, and we
    can sometimes pass these steps with a manual process. The world is moving on apace,
    and so the delivery of a release needs to be swift as well. With this in mind,
    automating processes is a great solution for increasing the speed of release delivery;
    continuous deployment was therefore created as an evolution of continuous delivery,
    which itself is an evolution of continuous integration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuous deployment is a deployment pattern that creates a pipeline where
    each step is executed through an automated process. All steps are then executed
    without human intervention. If a new release enters the pipeline, all steps will
    be executed automatically unless an error occurs. It is important to know that
    continuous deployment is not continuous delivery or continuous integration—although
    these deployment patterns have many similarities, they are all different. The
    main difference between them is the level of automation present; for example,
    continuous integration is more automated than continuous delivery, which, in turn,
    is more automated than continuous deployment. The following diagram illustrates
    the pipeline of both deployment patterns and the level of automation they have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/57ae1445-e53b-4b6b-a454-00ec0083fb4b.png)'
  prefs: []
  type: TYPE_IMG
- en: The main goal of continuous deployment is to minimize the time between the development
    of a release and its delivery in a production environment. It automates the steps
    of the developer so as to minimize the scope for human error and make the delivery
    safer. As discussed, continuous deployment can be used together with blue/green
    deployment, canary deployment, and A/B testing, and these patterns will work in
    both the *Deploy to production* and *Post deploy test* steps.
  prefs: []
  type: TYPE_NORMAL
- en: To implement continuous deployment, it is necessary to have a good testing culture.
    This is because the quality of tests will define the quality of the releases,
    as well as the success of its implementation. Furthermore, the documentation needs
    to update any new releases together, with all updates in the application reflected
    in the documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered deployment patterns, including canary deployment,
    blue/green deployment, A/B testing, and continuous deployment. We also covered
    the reasons to use these deployment patterns and how to decide how they're best
    used.
  prefs: []
  type: TYPE_NORMAL
- en: In the *Explaining the concept of deployment patterns* section, we looked at
    the principal concepts of deployment patterns and looked at their uses in a business
    environment. Similarly, in the *Explaining the concept of canary deployment*, *Explaining
    the concept of blue/green deployment*, *Explaining the concept of A/B testing,*
    and *Explaining the concept of continuous deployment* sections, we explored what
    each of the patterns are and why we use them. Finally, in the *Explaining the
    concept of continuous deployment* section, we covered the differences between
    continuous integration, continuous delivery, and continuous deployment.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will cover the concepts of operational patterns, performance
    and scalability patterns, and management and monitoring patterns.
  prefs: []
  type: TYPE_NORMAL
