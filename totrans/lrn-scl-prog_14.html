<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Project 1 - Building Microservices with Scala</h1>
                </header>
            
            <article>
                
<p>During this book, we have gradually increased the scope of our interests. In the first part, we started with language constructs and small building blocks, such as types and functions. The second part was dedicated to the <span>patterns of </span>functional programming. In the third part, we looked at even bigger abstractions—the actor model and streaming.</p>
<p>In this section, we'll zoom out once again, this time moving from design aspects up to the architectural level. We will use what we've learned so far to build two fully-scoped projects.</p>
<p>Nowadays, it goes without saying that all server-side software should provide an API, specifically an HTTP RESTful API. Software providing an API is called a <strong>service</strong> and if it conforms to a set of principles, it is often called a <strong>microservice</strong>. We will follow the crowd and design our projects as microservices.</p>
<p>In this chapter, we'll cover two topics. First, we'll discuss the concept of microservices and describe their advantages and building principles. We'll also take a look at few technical and organizational challenges related to the microservice-based approach.<span class="Apple-converted-space"> </span></p>
<p>Second, we'll use the knowledge gained from the rest of the book to build two real projects from scratch. Both represent simple microservices implementing stateful REST APIs, which represent the grocery shop you're familiar with from the third section of the book. This time, we'll provide not only an opportunity to place orders, but also to create and delete articles, and to replenish items in stock and get the current status of the stock.</p>
<p>The first project will be built on principles covered in the second section of this book. We will build it using open source functional programming libraries—http4s and circe for the client API, and doobie for database access.<span class="Apple-converted-space"> </span></p>
<p>The second project will be built using reactive programming libraries and techniques covered in the third section of this book. We'll use Akka-HTTP to construct an API layer, and Akka Persistence to implement the stateful part of it.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>Essentials of microservices</li>
<li>Purely functional HTTP APIs with http4s</li>
<li><span>Purely functional </span>database access with doobie</li>
<li>API integration testing with Http1Client</li>
<li>Reactive HTTP API with Akka-HTTP</li>
<li>Event-sourced persistent state with Akka Persistence</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>Before we begin, make sure you have the following installed:</p>
<ul>
<li>SBT 1.2+</li>
<li>Java 1.8+</li>
</ul>
<p>The source code for this chapter is available on GitHub at <a href="https://github.com/PacktPublishing/Learn-Scala-Programming/tree/master/Chapter14" target="_blank">https://github.com/PacktPublishing/Learn-Scala-Programming/tree/master/Chapter14</a>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Essentials of microservices</h1>
                </header>
            
            <article>
                
<p>When discussing microservices, it is better to start with the question of size. Evidently, software systems are growing in size in response to increasing demands from users. The number of features, their complexity and sophistication grow and so do the lines of code in software projects. Even in well-structured living systems, the size of components and their number is getting bigger over time. Given limited human mental capabilities, the proportion of the system that is understood by a single programmer shrinks, which leads to the increased number for developers in the team. Bigger team size leads to the growth of the communication overhead and so less time for writing code, leading to the need for additional developers, which introduces a self-reinforced cycle. </p>
<p>The <em>traditional</em> monolithic way to build systems as a single project with a single deployment module or executable and a single database is therefore becoming less and less efficient, and ultimately just makes it impossible to deliver working software in a timely manner. An alternative approach is to split the monolith into separate projects, called microservices, that can be developed independently.</p>
<p class="p1">Microservices look like the only feasible alternative to the monolithic approach, and are therefore becoming more and more popular. But, what are they precisely? According to <a href="http://microservices.io">http://microservices.io</a>, microservices—also known as the microservice architecture—is an architectural style that structures an application as a collection of loosely-coupled services, which implement business capabilities.</p>
<p class="p1">What does it mean? In essence, this is what would happen to the well-structured application if one would tear it apart and make an <span>autonomous application</span> from each module responsible for single business feature.</p>
<p class="p1">The <em>autonomy</em> in this definition applies on multiple levels:</p>
<ul>
<li class="p1"><strong>Codebase and technological stack</strong>: The code of the service should not be shared with other services.</li>
<li class="p1"><strong>Deployment:</strong> The service is deployed independently of other services both in terms of time and underlying infrastructure.</li>
<li class="p1"><strong>State:</strong> The service has its own persistent store and the only way for other services to access the data is by calling the owning service.</li>
<li class="p1"><strong>Failure-handling:</strong> Microservices are expected to be resilient. In the case of failures of downstream services, the one in question is expected to isolate failure.</li>
</ul>
<p class="p1">These aspects of autonomy allow us to reap a number of benefits from a microservice-based architecture:</p>
<ul>
<li class="p1">Continuous delivery even for very complex applications</li>
<li class="p1">The complexity of each service is low because it is limited to a single business capability</li>
<li class="p1">Independent deployment implies independent scalability for services with different loads</li>
<li class="p1">Code-independence enables polyglot environments and makes the adoption of new technologies easier</li>
<li class="p1">Teams can be scaled down in size, which reduces communication overhead and speeds up decision-making</li>
</ul>
<p class="p1">Of course, there are downsides to this approach as well. The most obvious drawbacks are related to the fact that microservices need to communicate with each other. To name a few important difficulties:</p>
<ul>
<li class="p1">Unavailability of habitual transactions</li>
<li class="p1">Debugging, testing, and tracing calls involving multiple microservices</li>
<li class="p1">The complexity shifts from the individual service into the space between them</li>
<li class="p1">Service location and protocol discovery require lots of effort</li>
</ul>
<p>But don't be scared! In the reminder of this chapter, we'll build just a single microservice so we won't be affected by these weaknesses. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Building a microservice with http4s and doobie</h1>
                </header>
            
            <article>
                
<p>Let's take a look at how a microservice with a RESTful interface will look if implemented with open source libraries based on the principles we've learned in first two sections of the book.</p>
<p>We will start with the discussion of the building blocks that constitute the application and how they connect together. Speaking of <span>blocks</span>, we'll need to briefly talk about the FS2 library, which is a foundation of other libraries we will use and thus shapes the ways we join them together. After that, we'll go over database migrations, project configurations, the implementation of the database logic, and the service layer. Naturally we conclude our <span>discourse with the implementation of integration testing for the service we've built.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Project structure</h1>
                </header>
            
            <article>
                
<p>Our project will include the following components:</p>
<ul>
<li>Database repository represents an abstraction layer over the database</li>
<li>Database migrator contains initialization logic for the database table</li>
<li>The REST API defines available HTTP calls and associated business logic</li>
<li>The configuration consolidates application parameters, such as server binding and database properties</li>
<li>The server wires all other components together, and spawns and binds an HTTP server to the configured address</li>
</ul>
<p>We'll start by adding following dependencies to <kbd>build.sbt</kbd> (the exact versions can be found in the GitHub repository):</p>
<pre>libraryDependencies ++= Seq(<br/>  <span>"org.http4s" </span>%% <span>"http4s-blaze-server" </span>% http4sVersion,<br/>  <span>"org.http4s" </span>%% <span>"http4s-circe" </span>% http4sVersion,<br/>  <span>"org.http4s" </span>%% <span>"http4s-dsl" </span>% http4sVersion,<br/>  <span>"org.tpolecat" </span>%% <span>"doobie-core" </span>% doobieVersion,<br/>  <span>"org.tpolecat" </span>%% <span>"doobie-h2" </span>% doobieVersion,<br/>  <span>"org.tpolecat" </span>%% <span>"doobie-hikari" </span>% doobieVersion,<br/>  <span>"com.h2database" </span>% <span>"h2" </span>% h2Version,<br/>  <span>"org.flywaydb" </span>% <span>"flyway-core" </span>% flywayVersion,<br/>  <span>"io.circe" </span>%% <span>"circe-generic" </span>% circeVersion,<br/>  <span>"com.github.pureconfig" </span>%% <span>"pureconfig" </span>% pureConfigVersion,<br/>  <span>"ch.qos.logback" </span>% <span>"logback-classic" </span>% logbackVersion,<br/>  <span>"org.typelevel" </span>%% <span>"cats-core" </span>% catsVersion,<br/><br/>  <span>"org.http4s" </span>%% <span>"http4s-blaze-client" </span>% http4sVersion % <span>"it,test"</span>,<br/>  <span>"io.circe" </span>%% <span>"circe-literal" </span>% circeVersion % <span>"it,test"</span>,<br/>  <span>"org.scalatest" </span>%% <span>"scalatest" </span>% scalaTestVersion % <span>"it,test"</span>,<br/>  <span>"org.scalamock" </span>%% <span>"scalamock" </span>% scalaMockVersion % Test<br/>)</pre>
<p>This list definitely looks longer than what you would expect for an example project. Let's inspect carefully why we need each of the dependencies we've put into it:</p>
<ul>
<li>http4s is the library we will be using for the HTTP layer</li>
<li>doobie is a functional JDBC (Java DataBase Connectivity) decorator</li>
<li>H2 is an embedded database which we will use to avoid installing a standalone instance</li>
<li>Flyway is for database migrations (versioned SQL statements used to change the database structure)</li>
<li>Circe is a JSON Swiss Army knife</li>
<li><kbd>PureConfig</kbd> is a typed configuration wrapper</li>
<li><kbd>Cats</kbd> is a library containing general functional programming abstractions</li>
</ul>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">FS2 – functional streams</h1>
                </header>
            
            <article>
                
<p>You may be wondering why we have a section about the FS2 library if we're not using it as a component for our application. Well, in fact, we are. It is an underlying building block for the database and HTTP libraries we're using, and therefore it is important to briefly discuss it to give you an understanding of how the other building blocks are connected. </p>
<p><a href="https://github.com/functional-streams-for-scala/fs2">FS2</a> is a streaming library that allows us to construct and transform complex streams. The streams in FS2 do not only contain elements, but also can embody effects such as IO. This feature makes it possible to describe almost everything as an FS2 stream. Libraries such as <kbd>http4s</kbd> and <kbd>doobie</kbd> are built upon this and give a higher-level API to the user. But this API is still a streaming one.</p>
<p>The stream is represented as <span><kbd>Stream[F,O]</kbd>, where <kbd>F</kbd> describes a possible effect of the stream and <kbd>O</kbd> is a type of its elements or output. This definition needs to be given two type parameters in order to fully specify it. If the stream has no effects, it will be pure: </span><kbd>Stream[Pure, O]</kbd>.</p>
<p>Let's construct a stream of <kbd>chars</kbd>:</p>
<pre>val chars: fs2.Stream[fs2.Pure,Char] = Stream.emits(List('a','b','c'))</pre>
<p>Pure streams can be converted to the <kbd>List</kbd> or <kbd>Vector</kbd> without evaluation: <kbd>chars<span class="o">.</span><span class="n">toList</span></kbd></p>
<p>Streams with effects can't be converted the same way because of the presence of effects. The effects first need to be <em>reduced</em> to a single effect. At the same time, we need to define how the output of the stream should be dealt with. Finally, we can execute the effect and get the output of the stream. This process is similar to the definition and materialization of the Akka streams we looked at in <a href="8b5e55e4-de37-4ab1-8baa-7e0c3ad3a6ed.xhtml" target="_blank">Chapter 13</a>, <em>Basics of Akka Streams</em>. Because we have quite a number of things to define, the syntax is a bit cumbersome, but it reflects the logic we described:</p>
<pre><span>object </span>Test <span>extends </span>App {<br/>  <span>import </span>fs2.Stream<br/>  <span>import </span>cats.effect.IO <span>// 1<br/></span><span>  </span><span>val </span><span>io</span>: IO[<span>String</span>] = <span>IO </span>{ <span>println</span>(<span>"IO effect"</span>); <span>"a" </span>* <span>2 </span>} <span>// 2<br/></span><span>  </span><span>val </span><span>as</span>: Stream[IO, <span>String</span>] = Stream.<span>eval</span>(<span>io</span>) <span>// 3<br/></span><span>  </span><span>val </span><span>c</span>: Stream.ToEffect[IO, <span>String</span>] = <span>as</span>.compile <span>// 4<br/></span><span>  </span><span>val </span><span>v</span>: IO[<span>Vector</span>[<span>String</span>]] = <span>c</span>.toVector <span>// 5<br/></span><span>  </span><span>val </span><span>l</span>: IO[<span>List</span>[<span>String</span>]] = <span>c</span>.to[List] <span>// 6<br/></span><span>  </span><span>val </span><span>d</span>: IO[Unit] = <span>c</span>.drain <span>// 7<br/></span><span>  </span><span>val </span><span>e</span>: IO[Option[<span>String</span>]] = <span>c</span>.last <span>// 8<br/></span><span>  </span><span>println</span>(<span>v</span>.unsafeRunSync()) <span>// 9<br/></span><span>  </span><span>println</span>(<span>e</span>.unsafeRunSync()) <span>// 10<br/></span><span>  </span>Stream.<span>eval</span>(<span>IO </span>{ 4<span>2 </span>}).compile.toList.unsafeRunSync() <span>// 11<br/></span>}</pre>
<p class="mce-root"/>
<p>Let's go over this snippet line by line and look at what is happening. The numbers in the code will correspond to the numbers in the following explanation:</p>
<ol>
<li>We are using the cats <kbd>IO</kbd> as type of our effect.</li>
<li>We define an <kbd>IO</kbd> as a by-name parameter to write to the console and return <kbd>aa</kbd>.</li>
<li>We <kbd>eval</kbd> our <kbd>IO</kbd>. This creates a single-element stream.</li>
<li>By compiling the stream, we create its projection to a single effect.</li>
</ol>
<ol start="5">
<li>By converting a <kbd>ToEffect</kbd> projection to <kbd>Vector</kbd> it is compiled to the expected effect type. The process can be thought of as executing a stream of effects and logging emitted results into the desired structure.</li>
<li>We demonstrate another way to define conversion to collection.</li>
<li><kbd>drain</kbd> is used to discard any emitted values and is useful if we are only interested in executing effects.</li>
<li>There are also other possibilities to define what should happen with output elements of the stream, for example, just collecting the <kbd>last</kbd> one.</li>
<li><kbd>unsafeRunSync()</kbd> runs the definition, synchronously producing effects and emitting output. This is the first moment anything appears in the console because so far we've just created and modified the definition of the<span> stream.</span></li>
<li>The definition is immutable and can be shared. Because of this, we can run the same stream description multiple times (with respect to the kind effects).</li>
<li>All of this is usually defined as a one-liner: eval the effect, compile the stream to the single effect, define the type of the output for the elements, run the stream later.</li>
</ol>
<p>Now let's see how FS2 are utilized by <kbd>http4s</kbd> and <kbd>doobie</kbd>. We'll start with the database layer as its implementation will guide the structure of other layers.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Database migrations</h1>
                </header>
            
            <article>
                
<p>In order for the database to be used in the application, it needs to contain all required tables, indexes, and other definitions.</p>
<p>We'll represent our store as a simple table with the name of the item serving as a primary key and a non-negative count of each item:</p>
<pre><span>CREATE TABLE </span>article (<br/>  <span>name  </span><span>VARCHAR </span><span>PRIMARY KEY</span>,<br/>  <span>count </span><span>INTEGER </span><span>NOT NULL CHECK </span>(<span>count </span>&gt;= <span>0</span>)<br/>);</pre>
<p>We'll place this definition into <kbd>db_migrations/V1__inventory_table.sql</kbd> and use Flyway to check that our database is in the correct state during startup time.</p>
<div class="packt_tip packt_infobox">Flyway provides a mechanism to define and change database schema in well-defined steps by adhering to specific naming conventions while placing  schema migrations <span>SQL </span>in the project folder. You can learn more about it at <a href="https://flywaydb.org">https://flywaydb.org</a>.</div>
<p>The Flyway code for migrations is straightforward:</p>
<pre><span>def </span>initialize(transactor: <span>HikariTransactor</span>[IO]): IO[Unit] = {<br/>  transactor.configure { dataSource =&gt;<br/>    <span>IO </span>{<br/>      <span>val </span>flyWay = <span>new </span>Flyway()<br/>      flyWay.setLocations(<span>"classpath:db_migrations"</span>)<br/>      flyWay.setDataSource(dataSource)<br/>      flyWay.migrate()<br/>    }<br/>  }<br/>}</pre>
<p>Given a <kbd>transactor</kbd> (which we'll describe a bit later, at the moment we'll talk about <kbd>doobie</kbd>), we use the datasource it provides to create an instance of <kbd>Flyway</kbd>, configure it to use proper migrations location, and perform the migration. Please note that the initialization logic is wrapped into the <kbd>IO</kbd> effect and thus delayed until the effect is evaluated.</p>
<p>The transactor is created using the utility provided by doobie from the configuration:</p>
<pre><span>def </span>transactor(c: DBConfig): IO[<span>HikariTransactor</span>[IO]] = {<br/>  HikariTransactor<br/>   .<span>newHikariTransactor</span>[IO](c.driver, c.url, c.user, c.password)<br/>}</pre>
<p>Again it is wrapped in <kbd>IO</kbd> so no effects will be evaluated until we run the result of this function.</p>
<p>Before going over to the definition of the database repository, let's have a quick look at the configuration abstraction we've used in the <kbd>transactor</kbd> method.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Configuration with PureConfig</h1>
                </header>
            
            <article>
                
<p>We're already familiar with the Typesafe Config library, which we actively used in our bakery examples. It is a very useful and flexible library. Unfortunately, because of this flexibility, it has one shortcoming: each configuration bit needs to be read and converted to the appropriate type individually. Ideally, we'd like our configuration to be represented as case classes and rely on naming conventions to map the structure of the configuration file to the structure of the (typed) configuration we have in the application. Ideally, we'd like to fail fast at startup time if the configuration file can't be mapped to the case classes that describe the configuration at the code level. </p>
<p>The <kbd><span>pureconfig</span></kbd> library makes this possible. This library can be found at <a href="https://github.com/pureconfig/pureconfig">https://github.com/pureconfig/pureconfig</a>.</p>
<p>Using it, we can define the configuration structure in Scala like the following:</p>
<pre><span>case class </span>ServerConfig(host: <span>String</span>, port: Int)<br/><span>case class </span>DBConfig(driver: <span>String</span>, url: <span>String</span>, user: <span>String</span>, password: <span>String</span>)<br/><span>case class </span>Config(server: ServerConfig, database: DBConfig)</pre>
<p>This definition reflects the structure of the configuration in <a href="https://github.com/lightbend/config/blob/master/HOCON.md">HOCON</a> format:</p>
<pre>server {<br/>  host = <span>"0.0.0.0"<br/></span><span>  </span>port = <span>8080<br/></span>}<br/>database {<br/>  driver = <span>"org.h2.Driver"<br/></span><span>  </span>url = <span>"jdbc:h2:mem:ch14;DB_CLOSE_DELAY=-1"<br/></span><span>  </span>user = <span>"sa"<br/></span><span>  </span>password = <span>""<br/></span>}</pre>
<p>Now we can load and map it to the case classes directly using <kbd>pureconfig</kbd>:</p>
<pre><span>object </span>Config {<br/>  <span>def </span>load(fileName: <span>String</span>): IO[Config] = {<br/>    <span>IO </span>{<br/>      <span>val </span>config = ConfigFactory.<span>load</span>(fileName)<br/>      pureconfig.<span>loadConfig</span>[Config](config)<br/>    }.flatMap {<br/>      <span>case </span><span>Left</span>(e) =&gt;<br/>        IO.<span>raiseError</span>[Config](<span>new </span>ConfigReaderException[Config](e))<br/>      <span>case </span><span>Right</span>(config) =&gt;<br/>        IO.<span>pure</span>(config)<br/>    }<br/>  }<br/>}</pre>
<p>Again, wrapped in <kbd>IO</kbd> and thus delayed, we're trying to load and map the configuration and raise an appropriate error in the context of an <kbd>IO</kbd> in the case this attempt has failed.</p>
<p>The configuration bit concludes the infrastructural part of the example and we can finally turn to the core—the database repository.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Doobie – functional database access</h1>
                </header>
            
            <article>
                
<p class="mce-root">The database layer in our example is implemented with the Doobie library. Its official website describes it as <span><em>a pure functional JDBC layer for Scala and Cats</em>.</span> It allows us to abstract existing JDBC functionality in a nice functional way. Let's show how this is done. The library can be found at<a href="https://tpolecat.github.io/doobie/"> https://tpolecat.github.io/doobie/</a>. In the following examples, please assume the following imports to be in scope: </p>
<pre><span>import </span>cats.effect.IO<br/><span>import </span>fs2.Stream<br/><span>import </span>doobie._<br/><span>import </span>doobie.implicits._<br/><span>import </span>doobie.util.transactor.Transactor<br/><span>import </span>cats.implicits._</pre>
<p>We also need some model classes to persist, and for the purpose of the example, we'll keep the ADT as small as possible:</p>
<pre><span>object </span>Model {<br/>  <span>type </span><span>Inventory </span>= <span>Map</span>[<span>String</span>, Int]<br/>  <span>abstract sealed class </span>Operation(<span>val </span>inventory: <span>Inventory</span>)<br/><br/>  <span>final case class </span>Purchase(order: <span>Inventory</span>)<br/>      <span>extends </span>Operation(order.mapValues(_ * -<span>1</span>))<br/><br/>  <span>final case class </span>Restock(<span>override val </span>inventory: <span>Inventory</span>)<br/>      <span>extends </span>Operation(inventory)<br/>}</pre>
<p>This model will allow us to represent the inventory of our shop as a map with keys referring to the article name and a values denoting number of the respective items in stock. We'll also have two operations that can be applied to the inventory—the Purchase operation will reduce the number of corresponding items and the Restock operation will increase number of respective items by combining our existing stocks together.</p>
<p>Now we can define our repository for this model. We'll do this in the same pure functional way we did before:</p>
<pre><span>class </span>Repository(transactor: Transactor[IO]) { ... }</pre>
<p>The repository is given <kbd>Transactor[IO]</kbd> as a constructor parameter. The <kbd>IO</kbd> in this example is <kbd>cats.effect.IO</kbd>. The transactor knows how to work with database connections. It can manage connections in the same logical way a connection pool does. In our implementation, <kbd>Transactor</kbd> is used to convert an FS2 <kbd>Stream[IO, ?]</kbd> into the <kbd>IO</kbd>, which will connect to the database and execute SQL statements if run. Let's see in detail how this is done for article-creation:</p>
<pre><span>def </span>createArticle(name: <span>String</span>): IO[Boolean] = {<br/>  <span>val </span>sql: <span>Fragment </span>= <span>sql"INSERT INTO article (name, count) VALUES (</span><span>$</span>name<span>, 0)"   // 1<br/></span><span>  </span><span>val </span>update: <span>Update0 </span>= sql.update  // 2<br/>  <span>val </span>conn: <span>ConnectionIO</span>[Int] = update.run //3<br/>  <span>val </span>att: <span>ConnectionIO</span>[<span>Either</span>[<span>Throwable</span>, Int]] = conn.attempt //4<br/>  <span>val </span>transact: IO[<span>Either</span>[<span>Throwable</span>, Int]] = att.transact(transactor) // 5<br/>  transact.map { // 6<br/>    <span>case </span><span>Right</span>(affectedRows) =&gt; affectedRows == <span>1<br/></span><span>    </span><span>case </span><span>Left</span>(_)             =&gt; <span>false<br/></span><span>  </span>}<br/>}</pre>
<p>Let's go over this definition line by line to see what is going on here:</p>
<ol>
<li>We define a <kbd>Fragment</kbd>, which is an SQL statement that can include interpolated values. Fragments can be combined together. </li>
<li>From <kbd>Fragment</kbd>, we construct an <kbd>Update</kbd>. <kbd>Update</kbd> can be used to construct a <kbd>ConnectionIO</kbd> later.</li>
<li>We construct a <kbd><span>ConnectionIO</span></kbd> by calling the <kbd>run</kbd> method on  <kbd>update</kbd>. <span><kbd>ConnectionIO</kbd> is basically an abstraction over the possible operations available on the JDBC connection. </span></li>
<li>By calling an <kbd>attempt</kbd> method, we're adding error-handling to our <kbd>ConnectionIO</kbd>. This is the reason the type parameter of <kbd>ConnectionIO</kbd> has changed from <kbd>Int</kbd> to <kbd>Either[Throwable, Int]</kbd>. </li>
<li>By providing a <kbd>transactor</kbd> to the <kbd>transact</kbd> method, we convert <kbd>ConnectionIO</kbd> into <kbd>IO</kbd>, which represents a runnable doobie program.</li>
<li>We coerce different sides of <kbd>Either</kbd> to a single Boolean value. We expect the number of created rows to be exactly one, in which case the call was a success. If we failed to create a row or if there was an exception thrown, it is a failure.</li>
</ol>
<div class="packt_tip">It would be more appropriate in the erroneous case to differentiate between the <em>unique index or primary key violation</em> and other cases but unfortunately different database drivers have different encoding for that, so it is not possible to provide concise generic implementation.</div>
<p>Other methods in our repository will follow the same pattern. <kbd>deleteArticle</kbd> is a one-liner and we don't bother to handle errors in this case (exceptions will bubble up to the upper layers and be propagated to the client if they will be thrown), so we can just check whether the number of affected rows was exactly one:</p>
<pre><span>def </span>deleteArticle(name: <span>String</span>): IO[Boolean] =<br/><span>sql"DELETE FROM article WHERE name = </span><span>$</span>name<span>"<br/></span>.update.run.transact(transactor).map { _ == <span>1 </span>}</pre>
<p><kbd>getInventory</kbd> is a bit different because it needs to return the results of the query:</p>
<pre><span>def </span>getInventory: Stream[IO, <span>Inventory</span>] = {<br/>  <span>val </span>query: doobie.<span>Query0</span>[(<span>String</span>, Int)] = <br/><span>      sql"SELECT name, count FROM article"</span>.query[(<span>String</span>, Int)]<br/>  <span>val </span>stream: Stream[IO, (<span>String</span>, Int)] = <br/>      query.stream.transact(transactor)<br/>  stream.fold(<span>Map</span>.<span>empty</span>[<span>String</span>, Int])(_ + _)<br/>}</pre>
<p>Here, we see that the query is of the <kbd>doobie.Query0[(String, Int)]</kbd> type with the type parameter representing the column types of the result. We convert the query to <kbd>Stream[ConnectionIO, (String, Int)]</kbd> (an FS2 stream with the <kbd>ConnectionIO</kbd> effect type and the tuple as a type of elements) by calling a <kbd>stream</kbd> method and then convert <kbd>ConnectionIO</kbd> to <kbd>IO</kbd> by providing a transactor. At last, we fold elements of the stream into <kbd>Map</kbd>, thus constructing the inventory state at the present moment from individual rows.</p>
<p>Updating the inventory has another caveat. We would like to update multiple articles at once so that if there is insufficient supply for some of the articles, we discard the whole purchase.</p>
<p>This is a design decision.<span> We could decide to return a partially-fulfilled order to the client.</span></p>
<p>The count of every article needs to be updated separately, therefore we need to have multiple update statements running in a single transaction. This is how it is done:</p>
<pre><span>def </span>updateStock(inventory: <span>Inventory</span>): Stream[IO, <span>Either</span>[<span>Throwable</span>, Unit]] = {<br/>  <span>val </span>updates = inventory.map { <span>case </span>(name, count) =&gt;<br/>      <span>sql"UPDATE article SET count = count + </span><span>$</span>count<span> WHERE name = </span><span>$</span>name<span>"</span>.update.run<br/>  }.reduce(_ *&gt; _)<br/>  Stream<br/>    .<span>eval</span>(<br/><span>      FC</span>.<span>setAutoCommit</span>(<span>false</span>) *&gt; updates *&gt; <span>FC</span>.<span>setAutoCommit</span>(<span>true</span>)<br/>    )<br/>    .attempt.transact(transactor)<br/>}</pre>
<p>We're given a map of <kbd>name -&gt; count</kbd> pairs as a parameter. The first thing we do is to convert each of these pairs into an update operation by mapping over them. This leaves us with a collection of <kbd>CollectionIO[Int]</kbd>. We then combine these updates together by using the cats <kbd>Apply</kbd> operator, which produces a single <span><kbd>CollectionIO[Int]</kbd>.</span></p>
<p>JDBC by default has auto-commit enabled, which will lead to the effect that our updates in the batch will be executed and committed one by one. This can lead to partially-fulfilled orders. In order to avoid that, we wrap the updates into the stream, which will disable auto-commits before the updates and enable auto-commits again after all of them are executed. We then lift the error-handling of the result and convert it into the runnable <kbd>IO</kbd> as before. </p>
<p>The result of the method is the <kbd>Stream[IO, Either[Throwable, Unit]]</kbd> type. The type of the elements of the stream encodes the possibilities to have both updates that weren't possible because there were insufficient articles in the inventory as <kbd>Left</kbd> and a successful update as <kbd>Right</kbd> .</p>
<p>With these four methods, we actually have all the required basic functionality and can start to use it in the API layer. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">http4s – streaming HTTP</h1>
                </header>
            
            <article>
                
<p>The implementation of the HTTP interface in our project is based on the http4s (<a href="https://http4s.org)">https://http4s.org)</a> library. http4s is built on top of the FS2 and Cats IO and therefore we have a nice interplay with the persistence layer implemented with doobie. With http4s, it is possible to build functional server-side services using high-level DSL, as well as use it on the client-side to call HTTP APIs. We will use the client functionality to build an integration test for our API later in this chapter.</p>
<p>The server side is represented by <span><kbd>HttpService[F]</kbd>, which is essentially just a mapping from <kbd>Request</kbd> to <kbd>F[Response]</kbd> and <kbd>F</kbd> is a cats <kbd>IO</kbd> in our case. http4s DSL helps to construct such RESTful services by using pattern-matching.</span></p>
<p><span>This is how it looks in practice. First we need to have following imports for <kbd>fs2</kbd> and <kbd>IO</kbd>, and http4s DSL and circe in scope:</span></p>
<pre><span>import </span>cats.effect.IO<br/><span>import </span>fs2.Stream<br/><span>import </span>org.http4s._<br/><span>import </span>org.http4s.dsl.Http4sDsl<br/><span>import </span>org.http4s.circe._<br/><span>import </span>org.http4s.headers.`Content-Type`<br/><span>import </span>io.circe.generic.auto._<br/><span>import </span>io.circe.syntax._</pre>
<p>With these imports in place, we can start to build up our service definition:</p>
<pre><span>class </span>Service(repo: Repository) <span>extends </span>Http4sDsl[IO] { ... }</pre>
<p>The service is given a database repository as a parameter. </p>
<p>The routes are defined separately for each HTTP verb and a URL template. We start with the definition of the service method, which takes a partial function from request to response:</p>
<pre><span>val </span><span>service</span>: <span>HttpService</span>[IO] = <span>HttpService</span>[IO] {</pre>
<p>Then we follow with the simple route for article deletion:</p>
<pre><span>case </span><span>DELETE </span><span>-&gt; </span><span>Root </span><span>/ </span><span>"articles" </span><span>/ </span>name <span>if </span>name.nonEmpty =&gt;<br/>  <span>val </span>repoResult: IO[Boolean] = repo.deleteArticle(name)<br/>  <span>val </span>toResponse: Boolean =&gt; IO[Response[IO]] = <span>if </span>(_) <span>NoContent</span>() <span>else </span><span>NotFound</span>()<br/>  <span>val </span>response: IO[Response[IO]] = repoResult.flatMap(toResponse)<br/>  response</pre>
<p>Here we are using <kbd>http4s</kbd> DSL in order to deconstruct <kbd>Request</kbd> into parts and pattern-match against these parts. The <kbd>-&gt;</kbd> object extracts the path from the request and the <kbd>/</kbd> class allows us to represent the concatenation of subpaths of the request URL (there is also <kbd>/:</kbd>, which matches the URL from the point of application and to the end of the url). The pattern-match itself is just a normal Scala case, hence we can use its full power. In this case, we're mapping the last part of the URL to <kbd>name</kbd> and have a guardian to make sure the path only matches if <kbd>name</kbd> is not empty (because we don't want to have anonymous articles in our shop!).</p>
<p>The expected result of the function is the <kbd>IO[Response[IO]]</kbd> type. Luckily, the return type of the <kbd>deleteArticle</kbd> method of our repository is <kbd>IO[Boolean]</kbd>, so we can just <kbd>flatMap</kbd> the returned boolean value into the response body <em>inside</em> of an <kbd>IO</kbd>. In this case, we don't want to respond with the body, but just inform the caller about the success of the operation, which is represented with the respective response codes: <kbd>204 No Content</kbd> and <kbd>404 Not Found</kbd>. http4s provides a nice constructors for this with a bit of a verbose type: <kbd>IO[Response[IO]]</kbd>. In our case, we define a function from <kbd>Boolean</kbd> to this type and use this function to <kbd>flatMap</kbd> the result of the repository call, which leaves us with <kbd>IO[<span>Response[IO]</span>]</kbd> as an end result, which is exactly the type expected to be returned.</p>
<p>Of course, all of this logic can be written in a succinct manner. Here is an example for the API call to create an article:</p>
<pre><span>case </span><span>POST </span><span>-&gt; </span><span>Root </span><span>/ </span><span>"articles" </span><span>/ </span>name <span>if </span>name.nonEmpty =&gt;<br/>  repo.createArticle(name).flatMap { <span>if </span>(_) <span>NoContent</span>() <span>else </span><span>Conflict</span>() }</pre>
<p> The approach is absolutely the same as the one we had for article deletion.</p>
<div class="packt_infobox">The API we're building is not a principle RESTful API. For this example to be a valid, level two API, we need to also implement a <kbd>GET</kbd> call that retrieves a representation for the individual articles. This can be done by adding a corresponding method to the repository and a <kbd>case</kbd> to the service. The implementation is left to the reader as an exercise.</div>
<p>Now that we have created a few articles in the repository, we would like to be able to retrieve the current state of it. We can implement it as follows:</p>
<pre><span>case </span><span>GET </span><span>-&gt; </span><span>Root </span><span>/ </span><span>"inventory" </span>=&gt;<br/>  <span>val </span>inventory: Stream[IO, <span>Inventory</span>] = repo.getInventory<br/>  renderInventory(inventory)</pre>
<p>The above pattern-match is straightforward and so is the call to the <kbd>getInventory</kbd> method of the repository. But it returns the result of the <kbd>Stream[IO, Inventory]</kbd> type and we need to convert it to the matching type for <kbd>HttpService[IO]</kbd>. <kbd>http4s</kbd> has a concept of <kbd>EntityEncoder</kbd> for this.</p>
<p>Here is the corresponding implementation:</p>
<pre><span>private def </span>renderInventory(inventory: Stream[IO, <span>Inventory</span>]): IO[Response[IO]] = {<br/>  <span>val </span>json: Stream[IO, <span>String</span>] = inventory.map(_.asJson.noSpaces)<br/>  <span>val </span>response: IO[Response[IO]] = <br/><span>           Ok</span>(json, <span>`Content-Type`</span>(MediaType.<span>`application/json`</span>))<br/>  response<br/>}</pre>
<p>Here, we prepare the inventory to be represented as an HTTP response by converting the returned <kbd>Map[String, Int]</kbd> to JSON. We rely on circe (<a href="https://github.com/circe/circe">https://github.com/circe/circe</a>) to perform automatic conversion. Next, the stream is converted to the appropriate response type by the <kbd>Ok</kbd> status constructor and an implicit <kbd>EntityEncoder[IO, String]</kbd>. We explicitly force the content type of the response to be <kbd>application/json</kbd> in order to have it correctly represented in the response.</p>
<p>Finally, we want to provide a way to modify the state of the inventory like we did with the repository. We'll implement two API calls, one for replenishing the inventory and another for purchases. They are implemented similarly, so we'll cover only one of them; the other can be found in the <a href="https://github.com/PacktPublishing/Learn-Scala---Fundamentals-of-Scala-2.12/blob/master/ch14/http4s-doobie/src/main/scala/ch14/Service.scala#L22">GitHub</a> repository. Here is the implementation for the restock call:</p>
<pre><span>case </span>req @ <span>POST </span><span>-&gt; </span><span>Root </span><span>/ </span><span>"restock" </span>=&gt;<br/>  <span>val </span>newState = <span>for </span>{<br/>    purchase &lt;- Stream.<span>eval</span>(req.decodeJson[Restock])<br/>    _ &lt;- repo.updateStock(purchase.inventory)<br/>    inventory &lt;- repo.getInventory<br/>  } <span>yield </span>inventory<br/>  renderInventory(newState)</pre>
<p>We need a request to read its body, therefore we bind it to the <kbd>req</kbd> variable in the pattern match. Next, we decode the JSON body of the request and map it to our model. Here we rely on circe to do the heavy lifting again. The <kbd>updateStock</kbd> repository method returns the stream, so we need to bring our parameter in the same context in order to be able to use it nicely in the <kbd>for</kbd> comprehension. We're doing this by wrapping the result of the decoding into <kbd>Stream.eval</kbd>.</p>
<p>Then we call the repository and provide the required changes in the form of <kbd>Inventory</kbd>. This method returns <kbd>Stream[IO, Either[Throwable, Unit]]</kbd>, so we ignore the result (it will shortcut the for comprehension in the case of an error). Finally, we read the new state of the repository and render it for the caller as before. </p>
<div class="packt_tip">The read-after-write is a known database anti-pattern. We used this approach to illustrate how streaming calls can be nicely chained in a for comprehension. In a real project, it might be better to formulate SQL statements in a way that the new state is returned immediately after the update.</div>
<p>The service layer is implemented now. We can wire our application together and see how it works.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Bringing it all together</h1>
                </header>
            
            <article>
                
<p>The server code will require a few new imports in addition to our usual set:</p>
<pre><span>import </span>org.http4s.server.blaze.BlazeBuilder<br/><span>import </span>scala.concurrent.ExecutionContext.Implicits.<span>global<br/></span></pre>
<p><kbd>BlazeBuilder</kbd> is a server factory, and <kbd>ExecutionContext</kbd> will be needed at the moment we start the server. The server is defined as follows:</p>
<pre><span>object </span>Server <span>extends </span>StreamApp[IO] { ... }</pre>
<p><kbd>StreamApp</kbd> requires us to implement a <kbd>stream</kbd> method, with the solely purpose to produce side-effects and provides cleanup hooks for this stream. This is our implementation:</p>
<pre><span>override def </span>stream(args: <span>List</span>[<span>String</span>],<br/>           requestShutdown: IO[Unit]): Stream[IO, ExitCode] = {<br/>  <span>val </span>config: IO[Config] = Config.<span>load</span>(<span>"application.conf"</span>)<br/>  <span>new </span>ServerInstance(config).create().flatMap(_.serve)<br/>}</pre>
<p>We just read the configuration and delegate the actual server creation to <kbd>ServerInstance</kbd>. Let's have a look at it:</p>
<pre><span>class </span>ServerInstance(config: IO[Config]) {<br/>  <span>def </span>create(): Stream[IO, BlazeBuilder[IO]] = {<br/>    <span>for </span>{<br/>      config &lt;- Stream.<span>eval</span>(config)<br/>      transactor &lt;- Stream.<span>eval</span>(DB.<span>transactor</span>(config.database))<br/>      _ &lt;- Stream.<span>eval</span>(DB.<span>initialize</span>(transactor))<br/>    } <span>yield </span><span>BlazeBuilder</span>[IO]<br/>      .bindHttp(config.server.port, config.server.host)<br/>      .mountService(<span>new </span>Service(<span>new </span>Repository(transactor)).<span>service</span>, <span>"/"</span>)<br/>  }<br/>}</pre>
<p>Here again we see the same approach: we lift <kbd>config</kbd> into the context of <kbd>Stream</kbd>, create a transactor, initialize the database, build the repository from the transactor and the service from the repository, and finally mount the service by using the <kbd>BlazeBuilder</kbd> factory.</p>
<p>The caller method will then execute the serve method of the server, starting the whole IO program we've built so far. </p>
<div class="packt_infobox"><span>We were following a pattern for providing dependencies as we've build up this example—we gave them as constructor parameters at the moment we constructed class instances. The approach of passing dependencies as </span><span>constructor</span><span> parameters is called </span><span>constructor</span><span>-based dependency-injection in Scala.</span></div>
<p>Now our application can be started and played with. But we want to be sure that it behaves correctly by testing it.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Testing</h1>
                </header>
            
            <article>
                
<p>This example is quite simple and basically just an HTTP facade over the database, so we won't test components in isolation. Instead, we'll use integration-testing to check the system as a whole.</p>
<div class="packt_infobox">In order to have SBT properly recognize our integration tests, we need to add the proper configurations to <kbd>build.sbt</kbd>. Please refer to the chapter code on GitHub (<a href="https://github.com/PacktPublishing/Learn-Scala-Programming">https://github.com/PacktPublishing/Learn-Scala-Programming</a>) to see how this is done.</div>
<p>In our integration test, we will let our system run normally (but with the test database) and use an HTTP client to call the API and inspect the responses it will return.</p>
<p>First, we need to prepare our HTTP client and server:</p>
<pre><span>class </span>ServerSpec <span>extends </span>WordSpec <span>with </span>Matchers <span>with </span>BeforeAndAfterAll {<br/>  <span>private lazy val </span><span>client </span>= <span>Http1Client</span>[IO]().unsafeRunSync()<br/>  <span>private lazy val </span><span>configIO </span>= Config.<span>load</span>(<span>"test.conf"</span>)<br/>  <span>private lazy val </span><span>config </span>= <span>configIO</span>.unsafeRunSync()<br/><span>  </span><span>private val </span><span>server</span>: Option[Http4sServer[IO]] = (<span>for </span>{<br/>    builder &lt;- <span>new </span>ServerInstance(<span>configIO</span>).create()<br/>  } <span>yield </span>builder.start.unsafeRunSync()).compile.last.unsafeRunSync()</pre>
<p>Here we create the client we'll be using to query our API by instantiating the <kbd>Http1Client</kbd> provided by the <kbd>http4s</kbd> library. We also read a test config that overrides database settings so that we can freely modify the data. We're using an in-memory H2 database, which is destroyed after our test finishes so that we don't need to clean up the state after the test. Then we're building a server by re-using <kbd>ServerInstance</kbd>. In contrast to the production code, we're starting it with the <kbd>start</kbd> method, which returns a server instance. We'll use this instance after the test to shut down the server. </p>
<p>Please note how we use <kbd>unsafeRunSync()</kbd> in multiple places to evaluate the contents of <kbd>IO</kbd>. For the server, we're even doing this twice, once for <kbd>IO</kbd> and once for <kbd>Stream[IO, ...]</kbd>. This is okay to do in the test code as it helps to keep the testing logic concise.</p>
<p>We need to shut down the client and the server after the test:</p>
<pre><span>override def </span>afterAll(): Unit = {<br/>  <span>client</span>.shutdown.unsafeRunSync()<br/>  <span>server</span>.foreach(_.shutdown.unsafeRunSync())<br/>}</pre>
<p>Again, we're running an IO here because we want the have the shutdown happen right now.</p>
<p>Now, let's take a look at one of the test methods:</p>
<pre><span>"create articles" </span>in {<br/>  <span>val </span>eggs = <span>Request</span>[IO](method = Method.<span>POST</span>, uri = Uri.<span>unsafeFromString</span>(<span>s"</span><span>$</span><span>rootUrl</span><span>/articles/eggs"</span>))<br/>  <span>client</span>.status(eggs).unsafeRunSync() shouldBe Status.<span>NoContent<br/></span><span>  </span><span>val </span>chocolate = <span>Request</span>[IO](method = Method.<span>POST</span>, uri = Uri.<span>unsafeFromString</span>(<span>s"</span><span>$</span><span>rootUrl</span><span>/articles/chocolate"</span>))<br/>  <span>client</span>.status(chocolate).unsafeRunSync() shouldBe Status.<span>NoContent<br/></span><span>  </span><span>val </span>json = <span>client</span>.expect[Json](<span>s"</span><span>$</span>rootUrl<span>/inventory"</span>).unsafeRunSync()<br/>  json shouldBe <span>json"""{"eggs" : 0,"chocolate" : 0}"""<br/></span>}</pre>
<p>Here we first create a test request using a factory provided by http4s. We then check that the API returns the correct <kbd>NoContent</kbd> status if we send this request with the client we created earlier in this section. We then create the second article by using the same approach. </p>
<p>Finally, we're using the client to call the URL directly and let it parse the response to the JSON form. Finally, we check that the inventory has a correct state by comparing the JSON response with circe's JSON literal.</p>
<p>For testing other API calls, we could also provide a request body using circe JSON literals. Please refer to the chapter's source code placed on GitHub to see how this is done.</p>
<p>It is absolutely possible to implement the same testing logic using other HTTP clients or even command-line tools. The <kbd>Http1Client</kbd> provided by <kbd>http4s</kbd> allows for nice syntax and concise expectation definitions.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Running the application</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>The easiest way to run our API is in the SBT shell by issuing a <kbd>run</kbd> command. The project for this chapter is configured as a multi-module SBT project. Because of this, the <kbd>run</kbd> command has to be prefixed by the module name so that it is fully spelled as <kbd>http4s/run</kbd> as shown in the next screenshot:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/2401065b-ee26-436e-9bd8-a7ba24222d2a.png" width="1950" height="1074"/></p>
<p>Different components of our API will output lots of information. The application is started after the address of the HTTP server is shown. You can see how this looks on the bottom of the next screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/0d09d8e4-e358-4398-aa5f-3a2cf2fc00c7.png" width="1950" height="1019"/></p>
<p class="CDPAlignLeft CDPAlign">After that, the API should serve HTTP requests, for example, issued with curl in another terminal window as the <span>following screenshot demonstrates:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/dbf77382-7def-433e-a4d5-22c0b15f4c32.png" style="width:42.42em;height:37.50em;" width="1168" height="1032"/></p>
<p>As our example uses in-memory database, it will lose its state after restart.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Building microservices with Akka-HTTP and Akka Persistence</h1>
                </header>
            
            <article>
                
<p>Now that we've seen how the principle functional approach to the implementation of the microservice works, let's change our technological stack and implement the same shop with Akka-HTTP and Akka Persistence. The flow of the discussion for this example will be similar to the one we had about the functional approach—we will start with looking at the way to persist the state of the service and the configuration needed for that. We'll then address the task of actually persisting the data and providing access to it via the HTTP service. As before, we'll conclude our journey by testing the implementation we'll come up with. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Project structure</h1>
                </header>
            
            <article>
                
<p>The project structure, in this case, will be almost the same as we had before.</p>
<p>We'll have an API layer responsible for the interaction with HTTP clients. We'll also inevitably have some configuration and a database initialization code that will be implemented in a similar, or identical, way to what we did as we've built the previous microservice.</p>
<p>The persistence layer will be represented by a persistent actor. This will affect the definition of the model as well as the structure of the database tables. </p>
<p>Akka Persistence introduces different paradigms of how the state of the system is stored and represented. The approach is called <strong>Event-Sourcing</strong> and it makes sense to take a minute to discuss it.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Event-Sourcing and CQRS</h1>
                </header>
            
            <article>
                
<p>Event-sourcing is about how the state of the system is stored. Normally the state of the system is persisted into the database as a number of related tables. Changes to the state are reflected in the database by modifying, adding, or deleting table rows. The database contains the current state of the system with this approach.</p>
<p>Event-sourcing provides an alternative method. It handles updates of the state very much like functional programming handles effects. Instead of executing a computation, it just describes it so that it is possible to execute it later. Descriptions of computations can be combined, as we saw in the second section of this book. The same way the changes of the state can be combined in an event-sourced approach to produce current state. In essence, event-sourcing is to the state what functional programming is to the computations and effects.</p>
<p>This description of the state change is called <strong>event</strong> and it usually (but not necessarily!) corresponds to some user action, called <strong>command</strong>. The system receives commands, validates them, and if the command makes sense in the context of current system state, respective event(s) is created and persisted into the event journal. The event is then applied to the in-memory representation(s) of the state and the required side-effects are executed.</p>
<p>When the event-sourced system is restarted, the events are read from the journal and applied to the initial state one by one, modifying it but not executing side-effects. At the end, after all events are applied, the internal state of the system should be the same as it was before the restart. Hence, <em>events</em> are the <em>source</em> of the state representation of the system in this scenario. The reconstructed state often represents only one aspect of the whole system and is called <strong>view</strong>.</p>
<p>The event journal is used only for appending events. Because of this, it is usually seen as an append-only storage, and often solutions <span>other </span>than relational databases are used. </p>
<p>CQRS is another name that goes hand in hand with Event-Sourcing. This is an abbreviation for <span>Command Query Responsibility Segregation, which in turn is just a fancy way to name a principle of</span> <em>Command–Query Separation</em><span> implemented with Command and Query entities (as opposed to the method calls). The CQS principle states that every method should be either <em>command</em>, which modifies the state, or <em>query</em>, which returns the state, and these responsibilities should not be mixed. With Event-Sourcing, this separation comes naturally from the definition of the <em>Event</em> (which is the Command in the CQS definition) and the concept of internal state as a <em>View</em> that needs to be queried separately.</span></p>
<p>Event-Sourcing has a lots of advantages over the traditional database-mutating approach:</p>
<ul>
<li>Append-only approach to store data scales much better than traditional relational databases.</li>
<li>Events provide audit, traceability, and in the case of special storages, security for free.</li>
<li>No need to use an ORM.</li>
<li>The domain model and event model can evolve at a different pace.</li>
<li>It is possible to recover the state of the system to any specific moment in the past.</li>
<li>Events can be combined in different ways, allowing us to construct different representations of state. Combined with the previous advantage, it gives us the ability to analyze past data in ways that weren't known at the time of the event's creation.</li>
</ul>
<p>Of course, there are some drawbacks as well:</p>
<ul>
<li>The state does not exists until it is reconstructed from events. Depending on the format of the journal, it might even impossible to analyze the events without writing special code for this purpose. In any case, it requires some effort to build the state representation from events.</li>
<li>Explosion of domain model in complex projects. Implementing new use-cases always requires the introduction of new commands and events.</li>
<li>Changes in the model as the project evolves. Changes in existing use-cases often mean changes in the structure of existing evens, which need to be done in the code because the event journal is append-only.</li>
<li>The number of events can grow rapidly. In actively-used systems, there may be millions of events produced daily, which can affect the time needed to build the state representation. Snapshotting is used to work around this issue. </li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Configuring Akka Persistence</h1>
                </header>
            
            <article>
                
<p>Akka Persistence allows us to store and replay messages sent to <span><kbd>PersistentActor</kbd> and thus implements an event-sourcing approach. Before going into the details of the actors implementation, let's look at the arrangements we need to make in the project configuration. </span></p>
<p>We're going to use the H2 relational database for this project. Akka Persistence supports many different storage plugins, including a local filesystem for storing snapshots, and in our case, it appears to be a good idea to use the same database we used with doobie to underline the differences in the architectural style.</p>
<p>Again, we're using Flyway to create the structure of the database. The tables will be different though. This is the table that will store events:</p>
<pre><span>CREATE TABLE </span>IF <span>NOT EXISTS PUBLIC</span>."journal" (<br/>  "ordering" BIGINT AUTO_INCREMENT,<br/>  "persistence_id" <span>VARCHAR</span>(<span>255</span>) <span>NOT NULL</span>,<br/>  "sequence_number" BIGINT <span>NOT NULL</span>,<br/>  "deleted" BOOLEAN <span>DEFAULT FALSE</span>,<br/>  "tags" <span>VARCHAR</span>(<span>255</span>) <span>DEFAULT NULL</span>,<br/>  "message" BYTEA <span>NOT NULL</span>,<br/>  <span>PRIMARY KEY</span>("persistence_id", "sequence_number")<br/>);</pre>
<p><kbd>persistence_id</kbd> is an ID of a specific persistent actor, which needs to be unique for the whole actor system (we'll see in a minute how this maps to the code), the <kbd>tags</kbd> field holds tags assigned to the events (this makes constructing views easier). <kbd>message</kbd> holds an event in serialized form. The serialization mechanism is decoupled from the storage. Akka supports different flavours, including Java serialization, Google Protobuf, Apache Thrift, or Avro and JSON. We'll use the JSON format in order to keep the example small.</p>
<p>The snapshots table is even simpler:</p>
<pre><span>CREATE TABLE </span>IF <span>NOT EXISTS PUBLIC</span>."snapshot" (<br/>  "persistence_id" <span>VARCHAR</span>(<span>255</span>) <span>NOT NULL</span>,<br/>  "sequence_number" BIGINT <span>NOT NULL</span>,<br/>  "created" BIGINT <span>NOT NULL</span>,<br/>  "snapshot" BYTEA <span>NOT NULL</span>,<br/>  <span>PRIMARY KEY</span>("persistence_id", "sequence_number")<br/>);</pre>
<p>Basically, it's just a snapshot in serialized form, with a timestamp and the <kbd>persistence_id</kbd> of the actor it belongs to.</p>
<p>With these tables in the migrations file, we now need to add following dependencies to <kbd>build.sbt</kbd>: </p>
<pre><span>"com.typesafe.akka"   </span>%% <span>"akka-persistence"       </span>% akkaVersion,<br/><span>"com.github.dnvriend" </span>%% <span>"akka-persistence-jdbc"  </span>% akkaPersistenceVersion,<br/><span>"com.scalapenos"      </span>%% <span>"stamina-json"           </span>% staminaVersion,<br/><span>"com.h2database"      </span>%  <span>"h2"                     </span>% h2Version,<br/><span>"org.flywaydb"        </span>%  <span>"flyway-core"            </span>% flywayVersion,</pre>
<p>The <kbd>akka-persistence</kbd> dependency is obvious. <kbd>akka-persistence-jdbc</kbd> is an implementation of the JDBC storage for the h2 database. <kbd>Flyway-core</kbd> is used to set up the database like in the previous example. <kbd>stamina-json</kbd> allows for schema migrations—it gives us a way to describe how the events stored in the old format in the database should be converted to the new format used in the code if needed. </p>
<p>We also need to put quite a bit of configuration for the Akka persistence in <kbd>application.conf</kbd> to configure journals. This configuration is quite verbose, so we will not discuss it here in full, but we will take a look at one part of it that describes serialization:</p>
<pre>akka.actor {<br/>    serializers.serializer = <span>"ch14.EventSerializer"<br/></span><span>    </span>serialization-bindings {<br/>      <span>"stamina.Persistable" </span>= serializer<br/>    }<br/>}</pre>
<p>Here, we configure serialization for the stamina. Let's take a look at <kbd>EventSerializer</kbd>:</p>
<pre><span>class </span>EventSerializer<br/>    <span>extends stamina.</span>StaminaAkkaSerializer(<span>v1createdPersister</span>,<br/>                                  <span>v1deletedPersister</span>,<br/>                                  <span>v1purchasedPersister</span>,<br/>                                  <span>v1restockedPersister</span>,<br/>                                  <span>v1inventoryPersister</span>)</pre>
<p>Here, we tell stamina which serializers to use. The serializers are defined as follows:</p>
<pre><span>import stamina.json._<br/><br/>object </span>PersistenceSupport <span>extends </span>JsonSupport {<br/>  <span>val </span><span>v1createdPersister </span>= <span>persister</span>[ArticleCreated](<span>"article-created"</span>)<br/>  <span>val </span><span>v1deletedPersister </span>= <span>persister</span>[ArticleDeleted](<span>"article-deleted"</span>)<br/>  <span>val </span><span>v1purchasedPersister </span>= <span>persister</span>[ArticlesPurchased](<span>"articles-purchased"</span>)<br/>  <span>val </span><span>v1restockedPersister </span>= <span>persister</span>[ArticlesRestocked](<span>"articles-restocked"</span>)<br/>  <span>val </span><span>v1inventoryPersister </span>= <span>persister</span>[Inventory](<span>"inventory"</span>)<br/>}</pre>
<p>In the <kbd>PersistenceSupport</kbd> object, we define persisters for our events. We don't need any migrations yet, but in the case we would, the migrations would be described here. Persister requires implicit <kbd>RootJsonFormat</kbd> to be available and we provide them in the <kbd>JsonSupport</kbd> trait:</p>
<pre><span>import </span>akka.http.scaladsl.marshallers.sprayjson.SprayJsonSupport<br/><span>import </span>spray.json.{DefaultJsonProtocol, RootJsonFormat}<br/><span>import </span>DefaultJsonProtocol._<br/><br/><span>trait </span>JsonSupport <span>extends </span>SprayJsonSupport {<br/><span>  implicit val </span><span>invJF</span>: RootJsonFormat[Inventory] =<br/>    jsonFormat1(Inventory)<br/>  <br/>  <span>implicit val </span><span>createArticleJF </span>= jsonFormat2(CreateArticle)<br/>  <span>implicit val </span><span>deleteArticleJF </span>= jsonFormat1(DeleteArticle)<br/>  <span>implicit val </span><span>purchaseJF </span>= jsonFormat1(PurchaseArticles)<br/>  <span>implicit val </span><span>restockJF </span>= jsonFormat1(RestockArticles)<br/><br/>  <span>implicit val </span><span>createdJF </span>= jsonFormat2(ArticleCreated)<br/>  <span>implicit val </span><span>deletedJF </span>= jsonFormat1(ArticleDeleted)<br/>  <span>implicit val </span><span>pJF </span>= jsonFormat1(ArticlesPurchased)<br/>  <span>implicit val </span><span>reJF </span>= jsonFormat1(ArticlesRestocked)<br/>}</pre>
<p>We extend <kbd>SprayJsonSupport</kbd> and import <kbd>DefaultJsonProtocol._</kbd> to get implicit formats for basic types already defined by <kbd>spray-json</kbd>. Then we define <kbd>RootJsonFormat</kbd> for all of our commands (these formats will be used by the API layer to un-marshall request bodies), events (which will be used by both the API layer to marshall responses, and the persistence layer to serialize events), and an Inventory (which is required for <span>snapshots </span>to be serializable). Here we're not relying on circe's auto-derivation and hence describe each case class individually.</p>
<p>Now we have persisters and formats for the model, but what is that model? It reflects the event-sourcing approach!</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Domain models</h1>
                </header>
            
            <article>
                
<p>With event-sourcing, we want to store changes of the state as events. Not every interaction with the client is an event. Until we know that we can comply, we're modeling it as a command. Specifically, in our example it is represented as sealed traits:</p>
<pre><span>sealed trait </span>Command<br/><span>sealed trait </span>Query<br/><br/><span>object </span>Commands {<br/>  <span>final case class </span>CreateArticle(name: <span>String</span>, count: Int) <span>extends </span>Command<br/>  <span>final case class </span>DeleteArticle(name: <span>String</span>) <span>extends </span>Command<br/>  <span>final case class </span>PurchaseArticles(order: <span>Map</span>[<span>String</span>, Int]) <span>extends </span>Command<br/>  <span>final case class </span>RestockArticles(stock: <span>Map</span>[<span>String</span>, Int]) <span>extends </span>Command<br/>  <span>final case object </span>GetInventory <span>extends </span>Query<br/>}</pre>
<p>In the spirit of CQRS, we model incoming data as four commands and one query. The commands can be made into the events if the current state allows that:</p>
<pre><span>object </span>Events {<br/>  <span>final case class </span>ArticleCreated(name: <span>String</span>, count: Int) <span>extends </span>Event<br/>  <span>final case class </span>ArticleDeleted(name: <span>String</span>) <span>extends </span>Event<br/>  <span>final case class </span>ArticlesPurchased(order: <span>Map</span>[<span>String</span>, Int]) <span>extends </span>Event<br/>  <span>final case class </span>ArticlesRestocked(stock: <span>Map</span>[<span>String</span>, Int]) <span>extends </span>Event<br/>}</pre>
<p>In our simple case, commands and events correspond to each other, but in the real project, this won't always be the case. </p>
<p>We also have a representation of the current state of the store:</p>
<pre><span>final case class </span>Inventory(state: <span>Map</span>[<span>String</span>, Int]) <span>extends </span>Persistable { ... }</pre>
<p><kbd>Inventory</kbd> extends <kbd>Persistable</kbd> so that we can make snapshots later. We will keep the business logic separate from the actor-related code. Because of this, our inventory should be able to handle events itself:</p>
<pre><span>def </span>update(event: Event): Inventory = event <span>match </span>{<br/>  <span>case </span><span>ArticleCreated</span>(name, cnt) =&gt; create(name, cnt).get<br/>  <span>case </span><span>ArticleDeleted</span>(name)      =&gt; delete(name).get<br/>  <span>case </span><span>ArticlesPurchased</span>(order)  =&gt; add(order.mapValues(_ * -<span>1</span>))<br/>  <span>case </span><span>ArticlesRestocked</span>(stock)  =&gt; add(stock)<br/>}</pre>
<p>The <kbd>create</kbd> method adds an article to the store and assigns some initial counts to it if possible. It returns an inventory in the new state in the case of success:</p>
<pre><span>def </span>create(name: <span>String</span>, count: Int): Option[Inventory] =<br/>  state.get(name) <span>match </span>{<br/>    <span>case </span>None =&gt; <span>Some</span>(<span>Inventory</span>(state.updated(name, count)))<br/>    <span>case </span>_    =&gt; None<br/>  }</pre>
<p>The <kbd>delete</kbd> method tries to delete an article from the inventory:</p>
<pre><span>def </span>delete(name: <span>String</span>): Option[Inventory] =<br/>  <span>if </span>(state.contains(name))<br/>    <span>Some</span>(<span>Inventory</span>(state.filterKeys(k =&gt; !(k == name))))<br/>  <span>else </span>None</pre>
<p>The <kbd>add</kbd> method sums the count of articles from another inventory with counts of all articles existing in this inventory:</p>
<pre><span>def </span>add(o: <span>Map</span>[<span>String</span>, Int]): Inventory = {<br/>  <span>val </span>newState = state.foldLeft(<span>Map</span>.<span>empty</span>[<span>String</span>, Int]) {<br/>    <span>case </span>(acc, (k, v)) =&gt; acc.updated(k, v + o.getOrElse(k, <span>0</span>))<br/>  }<br/>  <span>Inventory</span>(newState)<br/>}</pre>
<p>Now our inventory can accept events and return itself in an updated state, but we still have to deal with commands first. One possible implementation of the logic for command-handling could look like this:</p>
<pre><span>def </span>canUpdate(cmd: Command): Option[Event] = cmd <span>match </span>{<br/>  <span>case </span><span>CreateArticle</span>(name, cnt) =&gt;<br/>    create(name, cnt).map(_ =&gt; <span>ArticleCreated</span>(name, cnt))<br/>  <span>case </span><span>DeleteArticle</span>(name)     =&gt; delete(name).map(_ =&gt; <span>ArticleDeleted</span>(name))<br/>  <span>case </span><span>PurchaseArticles</span>(order) =&gt;<br/>    <span>val </span>updated = add(order.mapValues(_ * -<span>1</span>))<br/>    <span>if </span>(updated.state.forall(_._2 &gt;=  <span>0</span>)) <span>Some</span>(<span>ArticlesPurchased</span>(order)) <span>else </span>None<br/>  <span>case </span><span>RestockArticles</span>(stock)  =&gt; <span>Some</span>(<span>ArticlesRestocked</span>(stock))<br/>}</pre>
<p>The <kbd>canUpdate</kbd> method takes a command and returns a corresponding event in the case that it is possible to apply the command successfully. For creating and deleting articles, we're checking that the operation will produce a valid result; for purchases, we're checking that there are enough articles in stock, and restock should always succeed.</p>
<p>Our Inventory is not synchronized and hence it is not safe to work within a concurrent scenario. Moreover, if one thread makes modifications to the inventory at the time another thread already called <kbd>canUpdate</kbd>, but has not called <kbd>update</kbd> yet, we might end up with the incorrect state because of this race condition. But we don't need to worry about that because we're going to use our inventory inside of an actor.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The persistent actor</h1>
                </header>
            
            <article>
                
<p>The persistent actor in Akka extends the normal <kbd>Actor</kbd> and mixes in a <kbd>PersistentActor</kbd>. <kbd>PersistentActor</kbd> implements the <kbd>receive</kbd> method but requires a few other methods to be implemented by us:</p>
<pre><span>class </span>InventoryActor <span>extends </span>Actor <span>with </span>PersistentActor {<br/>  private var inventory: Inventory = Inventory(Map.empty)<br/><br/>  <span>override def </span>persistenceId: <span>String </span>= InventoryActor.<span>persistenceId</span><span><br/></span><br/>  <span>override def </span>receiveRecover: <span>Receive </span>= ???<br/><br/>  <span>override def </span>receiveCommand: <span>Receive </span>= ???<br/>}</pre>
<p>Besides the <kbd>inventory</kbd> that we need as a representation of state, we need to define a unique <kbd>persistenceId</kbd> and two methods: <kbd>receiveRecover</kbd> and <kbd>receiveCommand</kbd>. The former is called during the recovery time, for example at startup or if the persistent actor is restarted, and it receives all events from the journal. It is expected to modify the internal state but not to execute any side-effects. The latter is called during the normal lifetime and it receives all the commands. It is supposed to convert valid commands to events, persist the events, modify the internal state, and execute side-effecting code after that.</p>
<p class="mce-root">In our example, <kbd>receiveRecover</kbd> just delegates the event processing to <kbd>inventory</kbd>:</p>
<pre><span>override def </span>receiveRecover: <span>Receive </span>= {<br/>  <span>case </span><span>SnapshotOffer</span>(_, snapshot: Inventory) =&gt; <span>inventory </span>= snapshot<br/>  case event: Event =&gt; inventory = inventory.update(event)<br/>  <span>case </span>RecoveryCompleted =&gt; saveSnapshot(<span>inventory</span>)<br/>}</pre>
<p>Additionally, it handles instances of <kbd>SnapshotOffer</kbd> by restoring the inventory as a whole from the latest snapshot. <kbd>SnapshotOffer</kbd> will be the first message the actor receives if there are snapshots available, and it will contain the latest snapshot so it is safe to restore the inventory from it. The events in the journal before the snapshot will not be replayed. Finally, after receiving the <kbd>RecoveryCompleted</kbd> event, we save the current state as a snapshot for use after the next restart.</p>
<p>The <kbd>receiveCommand</kbd> implementation is a bit more involved:</p>
<pre><span>override def </span>receiveCommand: <span>Receive </span>= {<br/>  <span>case </span>GetInventory =&gt;<br/>    sender() ! <span>inventory<br/></span><span><br/></span><span>  </span><span>case </span>cmd: Command =&gt;<br/>    <span>inventory</span>.canUpdate(cmd) <span>match </span>{<br/>      <span>case </span>None =&gt;<br/>        sender() ! None<br/>      <span>case </span><span>Some</span>(event) =&gt;<br/>        persistAsync(event) { ev =&gt;<br/>          <span>inventory </span>= <span>inventory</span>.update(ev)<br/>          sender() ! <span>Some</span>(ev)<br/>        }<br/>    }<br/>}</pre>
<p>We handle the <kbd>GetInventory</kbd> query by sending a current state to the sender. Inventory is a wrapper over an immutable map, so it is safe to share.</p>
<p>We handle all <kbd>Commands</kbd> the same way, by letting Inventory do the actual work. If a command cannot be applied, we respond to the sender with <kbd>None</kbd>. In the opposite case, we asynchronously persist corresponding events and provide a callback that will be executed after the event is persisted. In the callback, we apply the event to the internal state and send the new state to the sender. In contrast to the normal actor, it is safe to use <kbd>sender()</kbd> in an async block.</p>
<p>And this is it, we now have a persistent actor that will restore its state after the restart. Time to make it available for HTTP clients.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Akka-HTTP</h1>
                </header>
            
            <article>
                
<p>Akka-HTTP provides a nice DSL to describe a server-side API similar to doobie. But Akka's language flows a bit differently. Instead of pattern-matching the request by applying rules one by one, it works more like a sieve. It filters requests by providing a number of directives, each matching some aspect of the request. The directives are nested so that each request travels deeper and deeper into matching branches until it reaches the processing logic. Such a combination of directives is called route. This is the inventory route:</p>
<pre><span>lazy val </span><span>inventoryRoutes</span>: <span>Route </span>=<br/>  path(<span>"inventory"</span>) {<br/>    get {<br/>      ???<br/>    }<br/>  } ~<br/>    path(<span>"purchase"</span>) {<br/>      post {<br/>        entity(as[PurchaseArticles]) { order =&gt;<br/>            ???<br/>        }<br/>      }<br/>    } ~<br/>    path(<span>"restock"</span>) {<br/>      post {<br/>        entity(as[RestockArticles]) { stock =&gt;<br/>            ???<br/>        }<br/>      }<br/>    }</pre>
<p>This route contains three smaller routes, one matching <kbd>GET /inventory</kbd>, another <kbd>POST /purchase</kbd>, and the third <kbd>POST /restock</kbd>. The second and third routes also define that the request entity must be parseable as <kbd>PurchaseArticles</kbd> and <kbd>RestockArticles</kbd> respectively and provide the result of the parsing as a parameter to the body. Let's see how the internals of these routes are implemented. We know that the inventory route should return the current state so we ask the inventory actor about that:</p>
<pre>complete((inventory ? GetInventory).mapTo[Inventory])</pre>
<p>The <kbd>complete</kbd> method takes <kbd>ToResponseMarshallable</kbd>, and we rely on the Akka-HTTP and JSON serializers we defined earlier to do the implicit conversion from the <kbd>Future[Inventory]</kbd> that we're getting as the result of the application of the ask pattern here.</p>
<p><kbd>inventory</kbd> is provided as an abstract field for now. This is how it looks in the definition of <kbd>Routes</kbd>:</p>
<pre><span>trait </span>Routes <span>extends </span>JsonSupport {<br/>  <span>implicit def </span>system: ActorSystem<br/>  <span>def </span>inventory: ActorRef<br/>  <span>def </span>config: Config<br/><br/>  <span>implicit lazy val </span><span>timeout</span>: Timeout = config.timeout<br/>  <span>implicit lazy val </span><span>ec</span>: ExecutionContext = system.dispatcher</pre>
<p>We define an abstract <kbd>config</kbd> that we then use to define an <kbd>implicit timeout</kbd> for the ask. We also define <kbd>ExecutionContext</kbd> in order to be able to map over <kbd>Future</kbd> in other routes.</p>
<p>The implementation of the other two routes is similar. This is the purchase route:</p>
<pre><span>val </span>response: Future[Option[ArticlesPurchased]] =<br/>  (inventory ? order).mapTo[Option[ArticlesPurchased]]<br/>onSuccess(response) {<br/>  <span>case </span>None        =&gt; complete(StatusCodes.<span>Conflict</span>)<br/>  <span>case </span><span>Some</span>(event) =&gt; complete(event)</pre>
<p>The logic is almost the same with differences related to the situation we can't satisfy the requirements. In this case, we return the <kbd>409 Conflict</kbd> error code.</p>
<p>The restock route is even simpler because it always succeeds:</p>
<pre><span>val </span>response: Future[Option[ArticlesRestocked]] =<br/>  (inventory ? stock).mapTo[Option[ArticlesRestocked]]<br/>complete(response)</pre>
<p>The definition of <kbd>articleRoute</kbd> for article creation and <span>deletion</span> is very similar and is available on GitHub so we will omit it here. </p>
<p>The routes are combined together using <kbd>~</kbd>, the same way we already did inline:</p>
<pre><span>lazy val </span><span>routes</span>: <span>Route </span>= <span>articlesRoutes </span>~ <span>inventoryRoutes</span></pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Bringing it all together</h1>
                </header>
            
            <article>
                
<p>Having the routes implemented, we can now go on with the server definition:</p>
<pre><span>object </span>Server <span>extends </span>App <span>with </span>Routes <span>with </span>JsonSupport {<br/><br/>  <span>val </span><span>config </span>= Config.<span>load</span>()<br/><br/>  <span>implicit val </span><span>system</span>: ActorSystem = <span>ActorSystem</span>(<span>"ch14"</span>)<br/>  <span>implicit val </span><span>materializer</span>: ActorMaterializer = <span>ActorMaterializer</span>()<br/><br/>  DB.initialize(config.database)<br/><br/>  <span>lazy val </span><span>inventory</span>: ActorRef = <span>system</span>.actorOf(InventoryActor.<span>props</span>, InventoryActor.<span>persistenceId</span>)<br/><br/><br/>  <span>Http</span>().bindAndHandle(<span>routes</span>, <span>config</span>.server.host, <span>config</span>.server.port)<br/>  Await.<span>result</span>(<span>system</span>.whenTerminated, Duration.<span>Inf</span>)<br/>}</pre>
<p>We mix together the <kbd>Routes</kbd> and <kbd>JsonSupport</kbd> traits and define abstract fields. The actor system is needed in order to instantiate the materializer, and a <span>materializer is a machine driving Akka-HTTP. Then we initialize the database, instantiate our persistent actor (which starts to receive events from the journal and restore its state), bind and start the server, and wait for the termination of the actor system.</span></p>
<div class="packt_infobox">The way we injected dependencies by defining abstract members and then mixing traits together is called trait-based DI or the thin cake pattern. Usually, in simple cases, we would prefer constructor-based DI, like in the http4s example.</div>
<p>Compared to the http4s implementation, this server is eager. Every statement is executed the moment it is defined (with respect for laziness).</p>
<p>Now we have another version of our store done and can test it as well.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Testing</h1>
                </header>
            
            <article>
                
<p>Of course, Akka would not be Akka if it did not provide a nice DSL for testing HTTP routes. The DSL allows us to test routes in a way that it is not needed to start a real server. It is possible to provide a mock implementation of the business logic to test routes in isolation. In our case, the logic is so simple that it actually makes sense to test the app as a whole, the same way we did in the http4s case.</p>
<p>The definition of the specification should not be surprising:</p>
<pre><span>class </span>RoutesSpec <span>extends </span>WordSpec <span>with </span>Matchers <span>with </span>ScalaFutures <span>with </span>ScalatestRouteTest <span>with </span>Routes {<br/><br/>  <span>override lazy val </span><span>config</span>: Config = Config.<span>load</span>()<br/><br/>  DB.<span>initialize</span>(<span>config</span>.database)<br/><br/>  <span>override lazy val </span><span>inventory</span>: ActorRef = <span>system</span>.actorOf(InventoryActor.<span>props</span>, <span>"inventory"</span>)<br/>  ...<br/>}</pre>
<p>The good news is that <kbd>ScalatestRouteTest</kbd> already provides a definition for the actor system and <kbd>materializer</kbd> so we don't need to initialize them before the test and close after the test. The <kbd>Routes</kbd> are the same <kbd>Routes</kbd> we defined earlier and are about to test now. We still have abstract definitions of <kbd>config</kbd> and <kbd>inventory</kbd> here, so provide an implementation for them.</p>
<p class="mce-root"/>
<p>And this is how we can test a route:</p>
<pre><span>"Routes" </span>should { <span>"be able to add article (POST /articles/eggs)" </span>in {<br/>  <span>val </span>request = <span>Post</span>(<span>"/articles/eggs"</span>)<br/>  request ~&gt; routes ~&gt; check {<br/>    status shouldBe StatusCodes.Created<br/>    contentType shouldBe ContentTypes.`application/json`<br/>    entityAs[String] shouldBe <span>"""{"name":"eggs","count":0}"""<br/></span><span>  </span>}<br/>}}</pre>
<p>First, we define the <kbd>request</kbd> we want the route to be checked against. Then we transform it with the <kbd>route</kbd> to the response, which in turn gets transformed into <kbd>check</kbd>. In the body of <kbd>check</kbd>, we can refer to the properties of the response in a simple way. </p>
<p>The<span> </span><kbd>routes</kbd><span> in </span><kbd>request ~&gt; routes ~&gt; check</kbd><span> refer to the field defined in the </span><kbd>Routes</kbd><span> trait.</span></p>
<p>Similarly, it is possible to create a request with a body and use it to test a route that expects such request:</p>
<pre><span>"be able to restock articles (POST /restock)" </span>in {<br/>  <span>val </span>restock = <span>RestockArticles</span>(<span>Map</span>(<span>"eggs" </span>-&gt; <span>10</span>, <span>"chocolate" </span>-&gt; <span>20</span>))<br/>  <span>val </span>entity  = <span>Marshal</span>(restock).to[<span>MessageEntity</span>].futureValue<span><br/></span><span>  </span><span>val </span>request = <span>Post</span>(<span>"/restock"</span>).withEntity(entity)<br/>  request ~&gt; routes ~&gt; check {<br/>    status shouldBe StatusCodes.OK<br/>    contentType shouldBe ContentTypes.`application/json`<br/>    entityAs[String] shouldBe <span>"""{"stock":{"eggs":10,"chocolate":20}}"""<br/></span><span>  </span>}<br/>}</pre>
<p>Here we <kbd>Marshal</kbd> the restock case class to <kbd>Entity</kbd> the same way it worked on routes. <kbd>.futureValue</kbd> is from the ScalaTest's <kbd>ScalaFutures</kbd> helper. The rest of the snippet is very similar to the previous example.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Running the application</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>To run the Akka-HTTP API, we have to use the same approach as we used for the http4s version. The name of the module will be, well, <kbd>akkaHttp</kbd>, but the principle is the same. The next screenshot shows the output in the console after <kbd>akkaHttp/run</kbd> was entered in the SBT shell:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/a81ae74e-a962-4552-9ad7-ccab8e778ce6.png" width="1950" height="701"/></p>
<p>The application outputs a few lines and then waits for incoming requests. It is now safe to play with it the same way we did with the http4s version:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/86d8f174-f069-4e6c-a926-3748f9f4f257.png" width="1950" height="384"/></p>
<p>One subtle but important difference is that the Akka version persists the database into the filesystem and retains the state between restarts, as shown by the first request on the previous screen.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="p1">In this chapter, we briefly discussed the pros and cons of the microservice-based approach.</p>
<p class="p1">We've built two small examples with similar functionality but different technological stacks.</p>
<p class="p1">The first project was built using a purely functional approach with wrapping effects in IO monad and functional streams. This allowed us to describe a system as a computation that is only started at the <em>end of the world</em>. We used the ORM approach in this case by mapping the state of the system to the database table and modifying it in response to the required changes. Finally, we demonstrated how to use the http4s client to test the system as a whole by building an integration test.</p>
<p class="p1">The basis for the second project was the "<em>official</em>" Lightbend stack. We looked at how well Akka-HTTP and Akka Persistence play together. We demonstrated that the event-sourced approach allows us to reconstruct state in memory by recombining it from persistent events. This helped us to avoid writing any SQL statements. We also looked at how the Akka-HTTP test kit can be used to test routes without the need to start the real HTTP server.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li>What is a database migration?</li>
<li>Describe what could be an alternative approach to discard an order completely in the case of insufficient stock for some articles.</li>
<li>Describe the conceptual difference between http4s and Akka-HTTP with regard to defining routes.</li>
<li>Name a reason why event-sourced data storage can scale better than traditional relational databases.</li>
<li>Implement a<span> </span><kbd>GET /articles/:name</kbd><span> </span>call with http4s and doobie.</li>
<li><span>Implement a </span><kbd>GET /articles/:name</kbd><span> call with Akka-HTTP and Akka Persistence.</span></li>
</ol>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<ul>
<li><span>Vinicius Feitosa Pacheco, </span><em>Microservice Patterns and Best Practices[ </em><span><em>Explore the concepts and tools you need to discover the world of microservices with various design patterns</em>.</span></li>
<li><span>Jatin Puri, Selvam Palanimalai, </span><em>Scala Microservices: </em><span><span><em>Design,</em> <em>build</em>, <em>and run microservices elegantly using Scala</em>.</span></span></li>
<li><span>Héctor Veiga Ortiz, Piyush Mishra, </span><em>Akka Cookbook: </em><span><em>Learn how to use the Akka framework to build effective applications in Scala</em>.</span></li>
<li><span>Rambabu Posa, </span><em>Scala Reactive Programming: Build fault-tolerant, robust, and distributed applications in Scala</em>.</li>
<li><span>Christian Baxter, </span><em>Mastering Akka: </em><span><em>Master the art of creating scalable, concurrent, and reactive applications using Akka</em>.</span></li>
</ul>


            </article>

            
        </section>
    </div>



  </body></html>