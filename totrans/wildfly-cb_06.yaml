- en: Chapter 6. Clustering WildFly
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a cluster in standalone mode
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating separate clusters in standalone mode
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a cluster in domain mode
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating separate clusters in domain mode
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a cluster via TCP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing the UDP protocol with the JGroups tool
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will learn how to create a cluster for a web application
    spread across two or more WildFly nodes. Clustering is the capability to continue
    serving a client, even in case of failures (that is, a server crash), and is also
    known as failover.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Clustering is meant to be at the application level and not at the OS level.
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose you are filling in a long form, in a large number of steps
    (where steps are meant to be pages). Now suppose that in the last step, the server
    or the WildFly node crashes, you would have to refill all the information again.
    Surely, you will not use that site anymore, if you can choose to do so. By the
    way, how would you address such a problem? Clustering is the answer.
  prefs: []
  type: TYPE_NORMAL
- en: In clustering, you get the user's session replicated to your cluster nodes.
    So in case of a failure, in the next HTTP request, you will land on a different
    server/node, which will continue serving you just as though nothing happened—obviously,
    the end user will not see that his/her request has been served by a different
    server/node.
  prefs: []
  type: TYPE_NORMAL
- en: In WildFly, we have two components (from a configuration file point of view,
    they are subsystems) that accomplish this job; they are *infinispan* (for caching
    the data session) and *JGroups* (to spread HTTP sessions across cluster nodes).
    Infinispan is the component that stores the data, whilst JGroups is the component
    that orchestrates the communication between the nodes forming the application
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will see how clustering can be achieved using different protocols: UDP (multicast
    and also the default one) and TCP (unicast). This can be configured in the `jgroups`
    subsystem. The default one is UDP.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the sake of completeness, we will try our configuration in both the operational
    modes: standalone and domain.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember that clustering is a service provided by WildFly, as such, it is activated
    on demand. Thus, you will need to provide a `cluster-aware` application in order
    to activate clustering. That means having the `<distributable/>` XML tag inside
    your `web.xml` file.
  prefs: []
  type: TYPE_NORMAL
- en: Within this chapter, you will need a standard WildFly installation and a settled
    management user. If you are starting from here, take a look at [Chapter 1](ch01.html
    "Chapter 1. Welcome to WildFly!"), *Welcome to WildFly!*
  prefs: []
  type: TYPE_NORMAL
- en: Creating a cluster in standalone mode
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to cluster two WildFly nodes locally, that
    is, on your PC. We will try this using the standalone mode and the `ha` profile.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this recipe, we will need the `cluster-aware` application named `cluster-test`,
    that you can find in my GitHub repository. If you skipped the *Managing applications
    using the deployments folder* recipe in [Chapter 2](ch02.html "Chapter 2. Running
    WildFly in Standalone Mode"), *Running WildFly in Standalone Mode*, please refer
    to it to download all the source code and projects that you will need.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build the application, give the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'From the WildFly installation directory `$WILDFLY_HOME`, let''s create two
    folders, each one representing a server node:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s copy the `cluster-test.war` application into the `deployments`
    folder of each node that we have just created. Execute the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We are almost ready to test our cluster. We need some configuration, but without
    editing much, we will just pass a command-line parameter to the `standalone.sh`
    script. Let''s do it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding command, I've emphasized only the relevant outputs; this is
    to give you a clear view of the clustering service.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let's open a browser and point it to the URL `http://127.0.0.1:8180/cluster-test`.
    Now refresh the page a few times. You should see something like the following
    screenshot:![How to do it...](img/3744_06_01.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '"cluster-test" application running on "node-1"'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the log, you should find the following statements:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that everything has gone well, let's start the second node and see what
    happens.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In a new terminal, execute the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the preceding command-line output, I''ve emphasized only the relevant outputs;
    this is to give you a clear view of the clustering service. Unlike `node-1`, we
    can see that now the cluster is composed of two members: `node-1` and `node-2`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, let's try pointing the same browser window to the URL `http://127.0.0.1:8280/cluster-test`.
    You should see something like this:![How to do it...](img/3744_06_02.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '"cluster-test" application running on "node-2"'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As you can see, the second node continued counting exactly from where we stopped
    in `node-1`. Great, our cluster is working!!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s analyze what we have done and why it is working without much configuration.
    Along with `standalone.sh` script for `node-1`, we specified a few parameters
    such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '`jboss.server.base.dir=cl-std-node-1`: Needed to specify our base directory
    as a starting folder to retrieve all the configuration files.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--server-config=standalone-ha.xml`: Needed to specify the server configuration
    file with `ha` profile.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`jboss.socket.binding.port-offset=100`: Needed to specify the port offset (`200`
    for `node-2`). We could have skipped this for the first node, but I like seeing
    the series: `1`,`2`,`3`,`4`..`n`, which in this case would have been `8180`, `8280`,
    `8380,` and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`jboss.node.name=node-1`: Needed to uniquely identify the node within the cluster
    (obviously, `node-2` for the second node).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'That''s all we need to do to make our cluster. This is because of the default
    WildFly''s configuration, especially the configuration of the subsystem, `jgroups`.
    Let''s see its defaults:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'So, the default protocol used for cluster transportation is the UDP (see the
    emphasized code). This UDP setting has additional configuration within the `socket-binding-group`
    specified in the `standalone-ha.xml` file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: So, by default, every member of the cluster advertises itself at the `230.0.0.4`
    address. Also, every port specified in the configuration is altered along with
    the `jboss.socket.binding.port-offset` parameter specified by the command-line
    script.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We could have made our cluster without the `port-offset` directive, and by using
    different IPs for each node instead, but this wouldn't have worked properly. This
    is because of the HTTP session reference stored in a cookie. Generally speaking,
    a cookie consists of a name (typically `JSESSIONID`), a value (which is an ID
    used to reference the HTTP session on the server), a domain, and a context path.
  prefs: []
  type: TYPE_NORMAL
- en: All these properties must be the same in order to send requests to the same
    HTTP session on the server, which will not be the case with nodes bound to different
    IPs. The IP is the domain of the cookie, thus it will not work—unless you balance
    all the properties—but that's the subject of the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have any problem with this configuration, you might have network problems,
    which you can troubleshoot with the last recipe of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Creating separate clusters in standalone mode
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to configure different and isolated clusters,
    running locally. We will try this using the standalone mode and the `ha` profile.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this recipe, we will need the `cluster-aware` application named `cluster-test`,
    that you can find in my GitHub repository. If you skipped the *Managing applications
    using the deployments folder* recipe of [Chapter 2](ch02.html "Chapter 2. Running
    WildFly in Standalone Mode"), *Running WildFly in Standalone Mode*, please refer
    to it to download all the source code and projects that you will need.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build the application, execute the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: From the WildFly installation directory `$WILDFLY_HOME`, let's create four folders,
    each one representing a server node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s copy the `cluster-test.war` application into the `deployments`
    folder of each node that we have just created. Give the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We are almost ready to test our cluster. We just need some configuration to
    pass to the `standalone.sh` script, through the command line.
  prefs: []
  type: TYPE_NORMAL
- en: Node-A1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the following log output, you can see that a cluster was formed and a member
    named `node-A1` joined it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Node-A2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the following log output, you can see that a member named `node-A2` joined
    a cluster along with the other member named `node-A1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Node-B1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the following log output, you can see that a cluster was formed and a member
    named `node-B1` joined it. We do not see any `node-Ax` members, so we have formed
    a different cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Node-B2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the following log output, you can see that a member named `node-B2` joined
    a cluster along with the other member named `node-B1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have launched all the WildFly nodes and formed two different clusters,
    let''s test them with our great `cluster-test` application:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open your browser and point it to the following location: `http://127.0.0.1:8180/cluster-test`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Refresh the page a few times. In the browser window, you should see something
    similar to the following screenshot:![How to do it…](img/3744_06_01.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '"cluster-test" application running on "node-A1"'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the `node-A1` log, you should find the following statements:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, let's try pointing the same browser window to the URL `http://127.0.0.1:8280/cluster-test`.
    You should see something like the following screenshot:![How to do it…](img/3744_06_02.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '"cluster-test" application running on "node-A2"'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'As you can see, the second node continued counting exactly from where we stopped
    in `node-A1`. In the `node-A2` log, you should find the following statements:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: OK, cluster `A` is working.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now let''s try the other URLs for nodes `B`:'
  prefs: []
  type: TYPE_NORMAL
- en: Within the same browser window, point to the address `http://127.0.0.1:8380/cluster-test`.
    In the browser window, you should see something similar to the following image:![How
    to do it…](img/3744_06_03.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '"cluster-test" application running on "node-B1"'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'As you can see, the application started counting from `0` (zero). The `node-B1`
    log should have the following statements:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s try pointing the same browser window to the following URL: `http://127.0.0.1:8480/cluster-test`.
    You should see the following screenshot:![How to do it…](img/3744_06_04.jpg)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '"cluster-test" application running on "node-B2"'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the `node-B2` log, you should find the following statements:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Great, cluster `B` is working too! Now, try switching from one URL to another
    and see if the cluster responds correctly.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s analyze what we have done and why it is working without much configuration.
    Along with the `standalone.sh` script for `node-A1` and `node-A2`, we specified
    a few parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`jboss.server.base.dir=cl-std-node-A1`: Needed to specify our base directory
    as a starting folder to retrieve all the configuration files (`cl-std-node-A2`
    for `node-A2`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--server-config=standalone-ha.xml`: Needed to specify the server configuration
    file with `ha` profile'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'jboss.socket.binding.port-offset=100: Needed to specify the port offset (200
    for "node-2")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`jboss.node.name=node-A1`: Needed to uniquely identify the node within the
    cluster (obviously `node-A2` for the second `A` node)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That's all we need to do to make the cluster for nodes `A`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create the nodes `B` cluster, we needed to specify pretty much the same
    parameters, plus the `jboss.default.multicast.address` one, valued to `230.0.0.5`.
    The default multicast address value is `230.0.0.4`, which is then used by the
    `A` nodes. This enabled us to create two different clusters: members of cluster
    `A` will communicate through the `230.0.0.4` address, while members of cluster
    `B` will communicate through the *230.0.0.5* address.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a cluster in domain mode
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to cluster two WildFly nodes locally, that
    is, on your PC. We will try this using the domain mode and the `ha` profile.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this recipe, we will need the `cluster-aware` application named `cluster-test`,
    that you can find in my GitHub repository. If you skipped the *Managing applications
    using the deployments folder* recipe in [Chapter 2](ch02.html "Chapter 2. Running
    WildFly in Standalone Mode"), *Running WildFly in Standalone Mode*, please refer
    to it to download all the source code and projects that you will need.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build the application, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From the WildFly installation directory `$WILDFLY_HOME`, let's create two folders;
    one representing the `domain-controller` and the other one representing the hosts
    (we will have two instances running within the same host).
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Master
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now, let's configure our domain controller using the `domain.xml` and `host.xml`
    files placed in the `cl-dmn-master` folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the `domain.xml` file and replace the `<server-groups>...</server-groups>`
    tag definition with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Again, to use cluster, we need to use the `ha` profile, which I referenced within
    the `profile` attribute of `server-group`. Also, we need to reference the appropriate
    `socket-binding-group` by the `ref` attribute, in this case valued to `ha-sockets`.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Follow this rule: always name server groups properly; do not name them "server-A",
    "*server-1*", or similar or you will get confused as soon as you start managing
    more and more servers.'
  prefs: []
  type: TYPE_NORMAL
- en: Now let's edit the `host.xml` file in order to just have `domain-controller`
    without any running hosts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following are the steps that are to be taken:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Name the host as `master`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Replace the `<domain-controller>...</domain-controller>` tag definition with
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Remove the `<servers>` tag definition.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: OK, we are done with `domain-controller`. Let's have a run.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now we can configure our hosts that will form a part of the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Host-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: First of all, let's disable `domain.xml`, present in the `cl-dmn-host-1` folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: By doing so, the file will not be read at startup. Now, let's configure our
    host controller using the `host.xml` file placed in the `cl-dmn-host-1` folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the `host.xml` file and follow the steps listed next:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Name the host as `host-1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Replace the `<management-interfaces>...</management-interfaces>` tag definition,
    inside the `<management>` tag, with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Replace the `<domain-controller>...</domain-controller>` tag definition with
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Replace the `<servers>...</servers>` tag definition with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this case, naming the servers with an indexed prefix helps because it gives
    you more information. For example, if you have five servers, each one running
    two instances, and you catch an error statement within your log files about `REST-server-7`,
    then you know you have to look into the machine number `4`, right?
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Now, if you looked at the `host-1` log output, you should have noticed that
    there is nothing about our cluster. Why? (You should know; anyway, the answer
    will be explained in a little while.)
  prefs: []
  type: TYPE_NORMAL
- en: Now that everything is up and running, let's deploy our application (did you
    get the answer?).
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s first check the logs. In `domain-controller`, you should see a statement
    asserting that the content has been uploaded, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In **host-1** you should see the following statements:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'See, now that we''ve got a statements log about the cluster, we know the the
    answer: the cluster will be activated once an application requires it.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Time to test our cluster using our application!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Open you browser and point it to the following location: `http://127.0.0.1:8180/cluster-test`.
    Refresh the page a few times. In the browser window, you should see something
    similar to the following screenshot:![Host-1](img/3744_06_13.jpg)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '"cluster-test" application running on "host-1" with "REST-server-1"'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the `host-1` log, you should find the following statements:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Notice the suffix of the log statements indicating the server name.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, let's try pointing the same browser window to the URL `http://127.0.0.1:8280/cluster-test`.
    You should see something like the following screenshot:![Host-1](img/3744_06_14.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '"cluster-test" application running on "host-1" with "REST-server-2"'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As you can see, the second node continued counting exactly from where we stopped
    in `REST-server-1`. In the `host-1` log, you should find the following statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The suffix of the log changed to `REST-server-2`. OK, our cluster is working
    properly.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Skipping the details of domain mode configuration (see [Chapter 3](ch03.html
    "Chapter 3. Running WildFly in Domain Mode"), *Running WildFly in Domain Mode*),
    let's analyze what we have done and why it is working without much configuration.
    Along with the `domain.sh` script for the `master` node, we specified the `-Djboss.domain.base.dir=cl-dmn-master`
    parameter, indicating our base directory as a starting folder to retrieve the
    entire configuration file.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, within `domain.xml` we specified a reference to the `ha` profile
    and `ha-sockets`, in the definition of `server-groups`. These configurations enabled
    clustering capabilities. Remember, only the `ha` and `full-ha` profiles enable
    the clustering feature.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the `host-1` side, along with `domain.sh` script, we specified the
    `-Djboss.domain.base.dir=cl-dmn-host-1` and `-Djboss.domain.master.address=127.0.0.1`
    properties, setting our base directory as a starting folder to retrieve the entire
    configuration file, and the address of `domain-controller`, relatively.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember, the domain-controller pushes out the configuration to the hosts, through
    the host-controller. That's why we don't have a configuration counterpart in `host-1`.
  prefs: []
  type: TYPE_NORMAL
- en: 'That''s all we needed to do to make our cluster. This is because of the default
    WildFly configuration, especially the configuration of the subsystem, `jgroups`.
    Let''s see its defaults:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'So, the default protocol used for cluster transportation is the UDP (see the
    emphasized code). This UDP setting has additional configuration, within `socket-binding-group`
    named `ha-sockets`, specified in the `domain.xml` file as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: So, by default, every member of the cluster advertises itself at the `230.0.0.4`
    address. Also, every port specified in the configuration is altered along with
    the `<socket-bindings port-offset="XXX"/>` settings specified in the `host.xml`
    file in the `host-1` server.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We could have made our cluster without the `port-offset` directive, and by using
    different IPs for each node instead, but this wouldn't have worked properly. This
    is because of the HTTP-session reference stored in a cookie. Generally speaking,
    a cookie consists of a name (typically `JSESSIONID`), a value (which is an ID
    used to reference the HTTP session on the server), a domain, and a context path.
  prefs: []
  type: TYPE_NORMAL
- en: All these properties must be the same in order to make a request to the same
    HTTP session on the server, which will not be the case with nodes bound to different
    IPs. The IP is the domain of the cookie, thus it will not work—unless you balance—
    but that's covered in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have any problem with this configuration, you might have network problems,
    which you can troubleshoot with the *Testing the UDP protocol with the JGroups
    tool* recipe of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Creating separate clusters in domain mode
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous recipe, we learned how to create a cluster. What if we need
    to manage more applications, each one having its own cluster? This is exactly
    what you will learn in this recipe. We will learn to manage more applications
    using the `ha` profile.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this recipe, we will need the `cluster-aware` application named `example`,
    that you can find in my GitHub repository. If you skipped the *Managing applications
    using the deployments folder* recipe in [Chapter 2](ch02.html "Chapter 2. Running
    WildFly in Standalone Mode"), *Running WildFly in Standalone Mode*, please refer
    to it to download all the source code and projects that you will need.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build the application, execute the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From the WildFly installation directory `$WILDFLY_HOME`, let's create three
    folders, one for the domain-controller (always run the domain-controller per se,
    without any other hosts), and two folders representing two different hosts with
    their own `host-controller`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands (if you followed the steps
    in the previous recipe, you can skip the first two `cp` commands):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Master
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now, let's configure our domain controller using the `domain.xml` and `host.xml`
    files placed in the `cl-dmn-master` folder. This will be exactly the same as the
    previous recipe, just in case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the `domain.xml` file and replace the `<server-groups>...</server-groups>`
    tag definition with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Again, to use cluster, we need to use the `ha` profile, which I referenced within
    the `profile` attribute of the `server-group` element. Also, we need to reference
    the appropriate `socket-binding-group` by the `ref` attribute, in this case valued
    to `ha-sockets`.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Follow this rule: always name server-groups properly, do not name them as "server-A",
    "`server-1`", or similar.'
  prefs: []
  type: TYPE_NORMAL
- en: Now let's edit the `host.xml` file in order to just have `domain-controller`
    without any running hosts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the steps that are to be followed:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Name the host as `master`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Replace the `<domain-controller>...</domain-controller>` tag definition with
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Remove the `<servers>` tag definition.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Okay, we are done with the domain-controller. Let's have a run.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now we can configure our hosts that will be a part of the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Host-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: First of all, let's disable the `domain.xml` file present in the `cl-dmn-host-1`
    folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: By doing so, the file will not be read at startup. Now, let's configure our
    host controller using `host.xml` placed in the `cl-dmn-host-1` folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the `host.xml` file and follow the steps listed next:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Name the host as `host-1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Replace the `<management-interfaces>...</management-interfaces>` tag definition
    inside the `<management>` tag, with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is only needed when more management interfaces are running on the same
    server.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Replace the `<domain-controller>...</domain-controller>` tag definition with
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, there is no default for the `jboss.domain.master.address` property,
    so we need to pass it somehow.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Replace the `<servers>...</servers>` tag definition with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Open a terminal and execute the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember that a cluster is activated on demand, that is, after we installed
    a `cluster-aware` application.
  prefs: []
  type: TYPE_NORMAL
- en: Host-2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's do exactly the same thing for `host-2` with just a few adjustments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Edit the `host.xml` file and follow the steps listed below:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Name the host as `host-2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Replace the `<management-interfaces>...</management-interfaces>` tag definition
    inside the `<management>` tag, with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Replace the `<domain-controller>...</domain-controller>` tag definition with
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Replace the `<servers>...</servers>` tag definition with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Open a terminal and execute the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember that cluster is activated on demand, that is, after we installed a
    `cluster-aware` application.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s deploy the application as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Testing the clusters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that all the hosts are up and running, let's test our two clusters!
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a browser and point to the following URLs, using different windows:'
  prefs: []
  type: TYPE_NORMAL
- en: The URL `http://127.0.0.1:8180/cluster-test` will depict the following output:![Testing
    the clusters](img/3744_06_05.jpg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The URL `http://127.0.0.1:8280/cluster-test` will depict the following output:![Testing
    the clusters](img/3744_06_06.jpg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The URL `http://127.0.0.1:8380/cluster-test` will depict the following output:![Testing
    the clusters](img/3744_06_07.jpg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The URL `http://127.0.0.1:8480/cluster-test` will depict the following output:![Testing
    the clusters](img/3744_06_08.jpg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oops! We were not expecting this, were we? What did we miss?
  prefs: []
  type: TYPE_NORMAL
- en: Okay, we got the same application, but still, the cluster should have worked.
    I mean two separate clusters. We got different ports for all the hosts. So what's
    wrong?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A server group does not define a cluster. A cluster is defined at the network
    level. To have a second cluster, thus a separate cluster, we need to specify a
    different multicast address for the servers we want to form a second cluster with.
    Both server-groups are sharing the same socket-binding-group `ha-sockets`, so
    all the information, cache, and cluster pings go onto the same network.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we do that? Passing the multicast address as a parameter along with the
    `domain.sh` script for the `host-2`? Nope! That way, we set a different multicast
    address for the `REST-server-2` server, which should be present in the first cluster,
    `cluster-REST-app`.
  prefs: []
  type: TYPE_NORMAL
- en: We need to define a multicast address for the first cluster and another one
    for the second cluster. Our clusters are logically represented by the `cluster-REST-app`
    server group and the `cluster-SOAP-app` server group, we can just define those
    multicast addresses at the server group level, hence in `domain.xml`.
  prefs: []
  type: TYPE_NORMAL
- en: Now, stop everything!
  prefs: []
  type: TYPE_NORMAL
- en: Master
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Edit the `domain.xml` file and replace the `<server-groups>...</server-groups>`
    tag definition with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Open a terminal and execute the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Host-1
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Host-2
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Re-testing the clusters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s open two windows of the same browser and point them to the following
    URLs:'
  prefs: []
  type: TYPE_NORMAL
- en: The URL `http://127.0.0.1:8180/cluster-test` will depict the following output:![Re-testing
    the clusters](img/3744_06_05.jpg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The URL `http://127.0.0.1:8380/cluster-test` will depict the following output:![Re-testing
    the clusters](img/3744_06_10.jpg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now open two other windows of a different browser and point them to the following
    URLs:'
  prefs: []
  type: TYPE_NORMAL
- en: The URL `http://127.0.0.1:8280/cluster-test` will depict the following output:![Re-testing
    the clusters](img/3744_06_11.jpg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The URL `http://127.0.0.1:8480/cluster-test` will depict the following output:![Re-testing
    the clusters](img/3744_06_12.jpg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There we go!
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We explained what was wrong in the first test, along the way. The second test,
    though, is a bit different; it seems that having different browsers does the magic.
    Well, kind of.
  prefs: []
  type: TYPE_NORMAL
- en: First of all, we effectively split the cluster in two, each one with its own
    network, which is right by design and implementation.
  prefs: []
  type: TYPE_NORMAL
- en: The different browser is needed for just one reason— because we are testing
    on the same IP (but different ports), and because the hostname (that is, the IP)
    matches the domain of the session cookie on the browser, having all four windows
    sharing the same cookie would end up in a totally wrong behavior—from our point
    of view.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s describe the "same-four-windows-browser" scenario and see if it fits
    our thinking:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Client makes a request on server 8180**: This responds with a `set-cookie`
    header with name `JSESSIONID`, domain `127.0.0.1`, path `/cluster-test` and a
    value `0o0hPhIZ73unAtIMDCb0zR2h.host-1:REST-server-1`. Visitor number `0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Client makes a request on server 8380**: This responds without a `set-cookie`
    header, because the browser finds the cookie on itself and sends it to the server,
    along with the request. As the server `8180` and `8380` are in the same cluster,
    and the HTTP session is replicated across them, the server finds the session and
    increments our visitors number. Visitor number `1`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Client makes a request on the server 8280**: This we configured to be on
    a separate cluster. The browser sends the cookie along with the request itself.
    The server can''t find the session, thus it responds with a `set-cookie` header
    with newly created values: name `JSESSIONID`, domain `127.0.0.1`, path `/cluster-test`
    and a value `8X1gLkCbr5RsmELxwTlI0izj.host-1:SOAP-server-1`. Visitor number `0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Client makes a request on the server 8480**: The browser sends the cookie
    along with the request itself. The server can''t find the session, thus it responds
    with a `set-cookie` header with newly created values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, using the same browser— at least the same session's browser—
    could not work.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have any problem with this configuration, you might have network problems,
    which you can troubleshoot with the last recipe of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a cluster via TCP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Often times, especially in enterprise and cloud environments where there are
    several restrictions among networks, you are not able to use multicast addresses,
    even in the same network. Fortunately, the `jgroups` subsystem helps you out with
    this by providing an easy way to switch between UDP and TCP clustering, and this
    is exactly what you will learn in this recipe. We will work using the standalone
    mode with the `ha` profile.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this recipe, we will need the "cluster-aware" application named "example",
    that you can find in my GitHub repository. If you skipped the *Managing applications
    using the deployments folder* recipe in [Chapter 2](ch02.html "Chapter 2. Running
    WildFly in Standalone Mode"), *Running WildFly in Standalone Mode*, please refer
    to it to download all the source code and projects that you will need.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build the application, do as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From the WildFly installation directory `$WILDFLY_HOME`, let's create two folders,
    each one representing a server node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s copy the `cluster-test.war` application into the `deployments`
    folder of each node that we have just created. Run the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We are almost ready to test our cluster. We just need some configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Node-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Edit the `standalone-ha.xml` file and replace the `jgroups` subsystem with
    the following definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Open a terminal and execute the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: Node-2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Edit the `standalone-ha.xml` file and replace the `jgroups` subsystem as we
    have done for `node-1`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: Testing the TCP cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that all the nodes are up and running, let's test our TCP cluster!
  prefs: []
  type: TYPE_NORMAL
- en: Open a browser and point to `http://127.0.0.1:8180/cluster-test`. Refresh the
    page a few times and you should see something like the following image:![Testing
    the TCP cluster](img/3744_06_13.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '"cluster-test" application running on "node-1" in the TCP cluster—standalone
    mode with "ha" profile'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the `node-1` logs, you should catch the following statements:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, try pointing the browser to `http://127.0.0.1:8280/cluster-test`. You should
    see something like the following image:![Testing the TCP cluster](img/3744_06_14.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '"cluster-test" application running on "node-2" in the TCP cluster—standalone
    mode with "ha" profile'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'And in the `node-2` logs, you should catch the following statements:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Our TCP cluster is working! Let''s also try and see if it scales well:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s copy the `cluster-test.war` application into the `deployments`
    folder of `node-3`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Edit the `standalone-ha.xml` file and replace the `jgroups` subsystem as we
    have done for `node-1` and `node-2`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open a terminal and execute the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the logs of the first two nodes, you should see the following entries:'
  prefs: []
  type: TYPE_NORMAL
- en: '`23:14:24,466 INFO [org.infinispan.remoting.transport.jgroups.JGroupsTransport]
    (Incoming-8,ee,node-1) ISPN000094: Received new cluster view for channel web:
    [node-1|2] (3) [node-1, node-2, node-3]`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`23:14:24,468 INFO [org.infinispan.remoting.transport.jgroups.JGroupsTransport]
    (Incoming-9,ee,node-2) ISPN000094: Received new cluster view for channel web:
    [node-1|2] (3) [node-1, node-2, node-3]`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s test it in the browser by pointing it to `http://127.0.0.1:8380/cluster-test`.
    You should see something like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Testing the TCP cluster](img/3744_06_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Scaling "cluster-test" application running on "node-3" in the TCP cluster—standalone
    mode with "ha" profile
  prefs: []
  type: TYPE_NORMAL
- en: Okay, everything worked as expected!
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's analyze what we have done.
  prefs: []
  type: TYPE_NORMAL
- en: The main configuration, despite few parameters for the `standalone.sh` script,
    consists of properly setting the `default` attribute of the `stack` element for
    the JGroups subsystem, to TCP. Furthermore, we had to set how cluster members
    ping each other. Default is the `MPING` protocol (the `M` stands for multicast).
    Hence, we defined the ping protocol, named `TCPPING`, and defined the well-known
    hosts (the `initial_hosts` property).
  prefs: []
  type: TYPE_NORMAL
- en: The concept is that every host which wants to join the cluster will ask the
    well-known hosts for membership information. If those are not running, the new
    node cannot join the cluster. By the way, if all cluster members are up and the
    well-known hosts go down, nothing happens to the cluster; they are just seen as
    two members who left the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a matter of fact, while testing the TCP cluster scaling by adding `node-3`
    and stopping the first two nodes, we would have just seen those entries in the
    `node-3` logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'The properties we defined with regard to the `<protocol type="TCPPING">...</protocol>`
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`num_initial_members`: The number of nodes before the cluster is considered
    as complete.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`port_range`: The port range to try in case a well-known host is not responding.
    For example, with a `port_range` of `50` and a well-known host `10.0.0.1[7600]`,
    a new member would try with port `7600`, `7601`, 7602 to port `7650`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeout`: The timeout which a member will wait before joining the cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing the UDP protocol with the JGroups tool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Often times, you need to validate and/or certify a configuration, and in case
    of issues regarding UDP clustering, the first thing to check is if the UDP is
    working properly.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to check if the UDP is working, testing it
    with a graphical tool and using java applications (thus without UI—which is the
    case of enterprise environment).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First of all, let's check if we have the JGroups library in our WildFly installation
    folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open your command-line tool and execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: Great! Now we can test it.
  prefs: []
  type: TYPE_NORMAL
- en: Graphical test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Open your command-line tool.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should see an application like the following image:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Graphical test](img/3744_06_16.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: First JGroups draw application
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If you get a network problem because of the IPv6, try forcing IPv4 by adding
    the following parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now in a different terminal, execute the same command as mentioned previously:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'From this second command, I emphasized the cluster view which is counting two
    members, and you now see the same application running (the number within parenthesis
    also indicates cluster members):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Graphical test](img/3744_06_17.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Second JGroups draw application
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Draw something on it, and if your UDP works, your sketch should come up on the
    other canvas, just like mine:![Graphical test](img/3744_06_18.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: JGroups draw application reflecting changes
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you have problems with the graphical test, try to test the UDP via command
    line, as explained in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Shell test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Open your command-line tool:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will start a JGroups application as a receiver, so it will be listening
    for incoming messages.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Again, if you get a network problem because of the IPv6, try forcing IPv4 by
    adding the following parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, in a different terminal, let''s call it `sender`, execute the following
    commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This second terminal will wait for standard input. As I didn''t specify any
    interface or multicast address, it will bind to any available interface, which
    in my case is more than a couple. By the way, let''s try typing something and
    hitting *Enter*, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now look at the first terminal, the one where we launched the `receiver` application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Yeah! We received everything, from all available and configured interfaces.
  prefs: []
  type: TYPE_NORMAL
