<html><head></head><body>
<div id="page" style="height:0pt"/><div class="book" title="Chapter&#xA0;4.&#xA0;Introduction to core.async"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch04" class="calibre1"/>Chapter 4. Introduction to core.async</h1></div></div></div><p class="calibre7">Long gone are the days when programs were required to do only one thing at a time. Being able to perform several tasks concurrently is at the core of the vast majority of modern business applications. This is where asynchronous programming comes in.</p><p class="calibre7">Asynchronous programming—and, more generally, concurrency—is about doing more with your hardware resources than you previously could. It means fetching data from the network or a database connection without having to wait for the result. Or, perhaps, reading an Excel spreadsheet into memory while the user can still operate the graphical interface. In general, it improves a system's responsiveness.</p><p class="calibre7">In this chapter, we will look at how different platforms handle this style of programming. More specifically, we will:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Be introduced to core.async's background and API</li><li class="listitem">Solidify our understanding of core.async by re-implementing the stock market application in terms of its abstractions</li><li class="listitem">Understand how core.async deals with error handling and backpressure</li><li class="listitem">Take a brief tour on transducers</li></ul></div></div>

<div class="book" title="Chapter&#xA0;4.&#xA0;Introduction to core.async">
<div class="book" title="Asynchronous programming and concurrency"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch04lvl1sec26" class="calibre1"/>Asynchronous <a id="id166" class="calibre1"/>programming and concurrency
</h1></div></div></div><p class="calibre7">Different <a id="id167" class="calibre1"/>platforms have different programming <a id="id168" class="calibre1"/>models. For instance, JavaScript applications are single-threaded and have an event loop. When making a network call, it is common to register a callback that will be invoked at a later stage, when that network call completes either successfully or with an error.</p><p class="calibre7">In contrast, when we're on the JVM, we can take full advantage of multithreading to achieve concurrency. It is simple to spawn new threads via one of the many concurrency primitives provided by Clojure, such as futures.</p><p class="calibre7">However, asynchronous programming becomes cumbersome. Clojure futures don't provide a<a id="id169" class="calibre1"/> native way for us to be notified of their<a id="id170" class="calibre1"/> completion at a later stage. In addition, retrieving values from a not-yet-completed future is a blocking operation. This can be seen clearly in the following snippet:</p><div class="informalexample"><pre class="programlisting">(defn do-something-important []
  (let [f (future (do (prn "Calculating...")
                      (Thread/sleep 10000)))]
    (prn "Perhaps the future has done its job?")
    (prn @f)
    (prn "You will only see this in about 10 seconds...")))

(do-something-important)</pre></div><p class="calibre7">The second call to print dereferences the future, causing the main thread to block since it hasn't finished yet. This is why you only see the last print after the thread in which the future is running has finished. Callbacks can, of course, be simulated by spawning a separate thread to monitor the first one, but this solution is clunky at best.</p><p class="calibre7">An exception to the lack of callbacks is GUI programming in Clojure. Much like JavaScript, Clojure Swing applications also possess an event loop and can respond to user input and invoke listeners (callbacks) to handle them.</p><p class="calibre7">Another option is rewriting the previous example with a custom callback that is passed into the future:</p><div class="informalexample"><pre class="programlisting">(defn do-something-important [callback]
  (let [f (future (let [answer 42]
                    (Thread/sleep 10000)
                    (callback answer)))]
    (prn "Perhaps the future has done its job?")
    (prn "You should see this almost immediately and then in 10 secs...")
     f))

(do-something-important (fn [answer]
                          (prn "Future is done. Answer is " answer)))</pre></div><p class="calibre7">This time the order of the outputs should make more sense. However, if we return the future from this function, we have no way to give it another callback. We have lost the ability to perform an action when the future ends and are back to having to dereference it, thus blocking the main thread again—exactly what we wanted to avoid.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="tip16" class="calibre1"/>Tip</h3><p class="calibre7">Java 8 introduces a new class, <code class="email">CompletableFuture</code>, that allows registering a callback to be invoked once the future completes. If that's an option for you, you can use interop to make Clojure leverage the new class.</p></div><p class="calibre7">As you might have realized, CES is closely related to asynchronous programming: the stock market application we built in the previous chapter is an example of such a program. The main—or UI—thread is never blocked by the Observables fetching data from the network. Additionally, we were also able to register callbacks when subscribing to them.</p><p class="calibre7">In many <a id="id171" class="calibre1"/>asynchronous applications, however, callbacks are <a id="id172" class="calibre1"/>not the best way to go. Heavy use of callbacks can lead to what is known as callback hell. Clojure provides a more powerful and elegant solution.</p><p class="calibre7">In the next few sections, we will  explore <code class="email">core.async</code>, a Clojure library for asynchronous programming, and how it relates to Reactive Programming.</p></div></div>

<div id="page" style="height:0pt"/><div class="book" title="core.async"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec27" class="calibre1"/>core.async</h1></div></div></div><p class="calibre7">If you've <a id="id173" class="calibre1"/>ever done any amount of JavaScript programming, you have probably experienced callback hell. If you haven't, the following code should give you a good idea:</p><div class="informalexample"><pre class="programlisting">http.get('api/users/find?name=' + name, function(user){
  http.get('api/orders?userId=' + user.id, function(orders){
    orders.forEach(function(order){
      container.append(order);
    });
  });
});</pre></div><p class="calibre7">This style of programming can easily get out of hand—instead of writing more natural, sequential steps to achieving a task, that logic is instead scattered across multiple callbacks, increasing the developer's cognitive load.</p><p class="calibre7">In response to this issue, the JavaScript community released several promises libraries that are meant to solve the issue. We can think of promises as empty boxes we can pass into and return from our functions. At some point in the future, another process might put a value inside this box.</p><p class="calibre7">As an example, the preceding snippet can be written with promises like the following:</p><div class="informalexample"><pre class="programlisting">http.get('api/users/find?name=' + name)
  .then(function(user){
    return http.get('api/orders?userId=' + user.id);
  })
  .then(function(orders){
    orders.forEach(function(order){
      container.append(order);
    });
  });  </pre></div><p class="calibre7">The<a id="id174" class="calibre1"/> preceding snippet shows how using promises can flatten your callback pyramid, but they don't eliminate callbacks. The <code class="email">then</code> function is a public function of the promises API. It is definitely a step in the right direction as the code is composable and easier to read.</p><p class="calibre7">As we tend to think in sequences of steps, however, we would like to write the following:</p><div class="informalexample"><pre class="programlisting">user   = http.get('api/users/find?name=' + name);
orders = http.get('api/orders?userId=' + user.id);
orders.forEach(function(order){
  container.append(order);
});</pre></div><p class="calibre7">Even though the code looks synchronous, the behavior should be no different from the previous examples. This is exactly what <code class="email">core.async</code> lets us do in both Clojure and ClojureScript.</p></div>

<div class="book" title="core.async">
<div class="book" title="Communicating sequential processes"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch04lvl2sec31" class="calibre1"/>Communicating sequential processes</h2></div></div></div><p class="calibre7">The <code class="email">core.async</code> library is built on an old idea. The foundation upon which it lies was first described by Tony Hoare—of Quicksort fame—in his 1978 paper <span class="strong"><em class="calibre8">Communicating Sequential Processes</em></span> (<span class="strong"><em class="calibre8">CSP</em></span>; see <a class="calibre1" href="http://www.cs.ucf.edu/courses/cop4020/sum2009/CSP-hoare.pdf">http://www.cs.ucf.edu/courses/cop4020/sum2009/CSP-hoare.pdf</a>). CSP has since <a id="id175" class="calibre1"/>been <a id="id176" class="calibre1"/>extended and implemented in several languages, the latest of which being<a id="id177" class="calibre1"/> Google's <span class="strong"><strong class="calibre2">Go</strong></span> programming language.</p><p class="calibre7">It is beyond the scope of this book to go into the details of this seminal paper, so what follows is a simplified description of the main ideas.</p><p class="calibre7">In CSP, work is modeled using two main abstractions: channels and processes. CSP is also message-driven and, as such, it completely decouples the producer from the consumer of the message. It is useful to think of channels as blocking queues.</p><p class="calibre7">A simplistic approach demonstrating these basic abstractions is as follows:</p><div class="informalexample"><pre class="programlisting">(import 'java.util.concurrent.ArrayBlockingQueue)

(defn producer [c]
  (prn "Taking a nap")
  (Thread/sleep 5000)
  (prn "Now putting a name in queue...")
  (.put c "Leo"))

(defn consumer [c]
  (prn "Attempting to take value from queue now...")
  (prn (str "Got it. Hello " (.take c) "!")))

(def chan (ArrayBlockingQueue. 10))

(future (consumer chan))
(future (producer chan))</pre></div><p class="calibre7">Running this code in the REPL should show us output similar to the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">"Attempting to take value from queue now..."</strong></span>
<span class="strong"><strong class="calibre2">"Taking a nap"</strong></span>
<span class="strong"><strong class="calibre2">;; then 5 seconds later</strong></span>
<span class="strong"><strong class="calibre2">"Now putting a name in que queue..."</strong></span>
<span class="strong"><strong class="calibre2">"Got it. Hello Leo!"</strong></span>
</pre></div><p class="calibre7">In order<a id="id178" class="calibre1"/> not to block our program, we start both the consumer and the producer<a id="id179" class="calibre1"/> in their own threads using a future. Since the consumer was started first, we most likely will see its output immediately. However, as soon as it attempts to take a value from the channel—or queue—it will block. It will wait for a value to become available and will only proceed after the producer is done taking its nap—clearly a very important task.</p><p class="calibre7">Now, let's compare it with a solution using core.async. First, create a new leiningen project and add a dependency on it:</p><div class="informalexample"><pre class="programlisting">[org.clojure/core.async "0.1.278.0-76b25b-alpha"]</pre></div><p class="calibre7">Now, type this in the REPL or in your core namespace:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">(ns core-async-playground.core</strong></span>
<span class="strong"><strong class="calibre2">  (:require [clojure.core.async :refer [go chan &lt;! &gt;! timeout]]))</strong></span>

<span class="strong"><strong class="calibre2">(defn prn-with-thread-id [s]</strong></span>
<span class="strong"><strong class="calibre2">  (prn (str s " - Thread id: " (.getId (Thread/currentThread)))))</strong></span>

<span class="strong"><strong class="calibre2">(defn producer [c]</strong></span>
<span class="strong"><strong class="calibre2">  (go (prn-with-thread-id "Taking a nap ")</strong></span>
<span class="strong"><strong class="calibre2">      (&lt;! (timeout 5000))</strong></span>
<span class="strong"><strong class="calibre2">      (prn-with-thread-id "Now putting a name in que queue...")</strong></span>
<span class="strong"><strong class="calibre2">      (&gt;! c "Leo")))</strong></span>

<span class="strong"><strong class="calibre2">(defn consumer [c]</strong></span>
<span class="strong"><strong class="calibre2">  (go (prn-with-thread-id "Attempting to take value from queue now...")</strong></span>
<span class="strong"><strong class="calibre2">      (prn-with-thread-id (str "Got it. Hello " (&lt;! c) "!"))))</strong></span>

<span class="strong"><strong class="calibre2">(def c (chan))</strong></span>

<span class="strong"><strong class="calibre2">(consumer c)</strong></span>
<span class="strong"><strong class="calibre2">(producer c)</strong></span>
</pre></div><p class="calibre7">This time <a id="id180" class="calibre1"/>we are using a helper function, <code class="email">prn-with-thread-id</code>, which appends <a id="id181" class="calibre1"/>the current thread ID to the output string. I will explain why shortly, but apart from that, the output will have been equivalent to the previous one:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">"Attempting to take value from queue now... - Thread id: 43"</strong></span>
<span class="strong"><strong class="calibre2">"Taking a nap  - Thread id: 44"</strong></span>
<span class="strong"><strong class="calibre2">"Now putting a name in que queue... - Thread id: 48"</strong></span>
<span class="strong"><strong class="calibre2">"Got it. Hello Leo! - Thread id: 48"</strong></span>
</pre></div><p class="calibre7">Structurally, both solutions look fairly similar, but since we are using quite a few new functions here, let's break it down:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">chan</code> is a function that creates a <code class="email">core.async</code> channel. As mentioned previously, it can be thought of as a concurrent blocking queue and is the main abstraction in the library. By default <code class="email">chan</code> creates an unbounded channel, but <code class="email">core.async</code> provides many more useful channel constructors, a few of which we'll be using later.</li><li class="listitem"><code class="email">timeout</code> is another such channel constructor. It gives us a <span class="strong"><em class="calibre8">channel</em></span> that will <span class="strong"><em class="calibre8">wait</em></span> for a given amount of time before returning nil to the taking process, closing itself immediately afterward. This is the <code class="email">core.async</code> equivalent of <span class="strong"><strong class="calibre2">Thread/sleep</strong></span>.</li><li class="listitem">The functions <code class="email">&gt;!</code> and <code class="email">&lt;!</code> are used to put and take values from a channel, respectively. The caveat is that they have to be used inside a <code class="email">go</code> block, as we will explain later.</li><li class="listitem"><code class="email">go</code> is a macro that takes a body of expressions—which form a <code class="email">go</code> block—and creates lightweight processes. This is where the magic happens. Inside a <code class="email">go</code> block, any calls to <code class="email">&gt;!</code> and <code class="email">&lt;!</code> that would ordinarily block waiting for values to be available in channels are instead parked. Parking is a special type of blocking used internally in the state machine of <code class="email">core.async</code>. The blog post by Huey Petersen covers this state machine in depth (see <a class="calibre1" href="http://hueypetersen.com/posts/2013/08/02/the-state-machines-of-core-async/">http://hueypetersen.com/posts/2013/08/02/the-state-machines-of-core-async/</a>).</li></ul></div><p class="calibre7">Go blocks are the very reason for which I chose to print the thread IDs in our example. If we look<a id="id182" class="calibre1"/> closely, we'll realize that the last two statements were executed in the <a id="id183" class="calibre1"/>same thread—this isn't true 100 percent of the time as concurrency is inherently non-deterministic. This is a fundamental difference between <code class="email">core.async</code> and solutions using threads/futures.</p><p class="calibre7">Threads can be expensive. On the JVM, their default stack size is 512 kilobytes—configurable via the <code class="email">-Xss</code> JVM startup option. When developing a highly concurrent system, creating thousands of threads can quickly drain the resources of the machine the application is running on.</p><p class="calibre7">
<code class="email">core.async</code> acknowledges this limitation and gives us lightweight processes. Internally, they do share a thread pool, but instead of wastefully creating a thread per go block, threads are recycled and reused when a put/take operation is waiting for a value to become available.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="tip17" class="calibre1"/>Tip</h3><p class="calibre7">At the time of writing, the thread pool used by <code class="email">core.async</code> defaults to the number of available processors x 2, + 42. So, a machine with eight processors will have a pool with 58 threads.</p></div><p class="calibre7">Therefore, it is common for <code class="email">core.async</code> applications to have dozens of thousands of lightweight processes. They are extremely cheap to create.</p><p class="calibre7">Since this is a book on Reactive Programming, the question that might be in your head now is: can we build reactive applications using <code class="email">core.async</code>? The short answer is yes, we can! To prove it, we will revisit our stock market application and rewrite it using <code class="email">core.async</code>.</p></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Rewriting the stock market application with core.async"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec28" class="calibre1"/>Rewriting the stock market application with core.async</h1></div></div></div><p class="calibre7">By using<a id="id184" class="calibre1"/> an example we are familiar with, <a id="id185" class="calibre1"/>we are able to focus on the differences between all approaches discussed so far, without getting side tracked with new, specific domain rules.</p><p class="calibre7">Before we dive into the implementation, let's quickly do an overview of how our solution should work.</p><p class="calibre7">Just like in our previous implementations, we have a service from which we can query share prices. Where our approach differs, however, is a direct consequence of how <code class="email">core.async</code> channels work.</p><p class="calibre7">On a<a id="id186" class="calibre1"/> given schedule, we would<a id="id187" class="calibre1"/> like to write the current price to a <code class="email">core.async</code> channel. This might look like so:</p><div class="mediaobject"><img src="../images/00014.jpeg" alt="Rewriting the stock market application with core.async" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre7">This process will continuously put prices in the <code class="email">out</code> channel. We need to do two things with each price: display it and display the calculated sliding window. Since we like our functions decoupled, we will use two <code class="email">go</code> blocks, one for each task: </p><div class="mediaobject"><img src="../images/00015.jpeg" alt="Rewriting the stock market application with core.async" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre7">Hold on. There seems to be something off with our approach. Once we take a price from the output channel, it is not available any longer to be taken by other go blocks, so, instead of calculating the sliding window starting with 10, our function ends up getting the second value, 20. With this approach, we will end up with a sliding window that calculates a sliding window with roughly every other item, depending on how consistent the interleaving between the go blocks is.</p><p class="calibre7">Clearly, this is not what we want, but it helps us think about the problem a little more. The <a id="id188" class="calibre1"/>semantics of <code class="email">core.async</code> prevent us from reading a value from a channel more than once. Most of the time, this<a id="id189" class="calibre1"/> behavior is just fine—especially if you think of them as queues. So how can we provide the same value to both functions?</p><p class="calibre7">To solve this problem, we will take advantage of another channel constructor provided by <code class="email">core.async</code> called <code class="email">broadcast</code>. As the name implies, <code class="email">broadcast</code> returns a channel, which, when written to, writes its value into the channels passed to it as arguments. Effectively, this changes our high-level picture to something like the following:</p><div class="mediaobject"><img src="../images/00016.jpeg" alt="Rewriting the stock market application with core.async" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre7">In summary, we will have a go loop writing prices to this broadcast channel, which will then forward its values to the two channels from which we will be operating: prices and the sliding window.</p><p class="calibre7">With the general idea in place, we are ready to dive into the code.</p></div>

<div class="book" title="Rewriting the stock market application with core.async">
<div class="book" title="Implementing the application code"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch04lvl2sec32" class="calibre1"/>Implementing the application code</h2></div></div></div><p class="calibre7">We already <a id="id190" class="calibre1"/>have a project depending on <code class="email">core.async</code> that we created in the previous section, so we'll be working off that. Let's start by adding an extra dependency on seesaw to your <code class="email">project.clj</code> file:</p><div class="informalexample"><pre class="programlisting">  :dependencies [[org.clojure/clojure "1.5.1"]
                 [org.clojure/core.async "0.1.278.0-76b25b-alpha"]
                 [seesaw "1.4.4"]]</pre></div><p class="calibre7">Next, create a file called <code class="email">stock_market.clj</code> in the <code class="email">src</code> directory and add this namespace declaration:</p><div class="informalexample"><pre class="programlisting">(ns core-async-playground.stock-market
  (:require [clojure.core.async
             :refer [go chan &lt;! &gt;! timeout go-loop map&gt;] :as async])
  (:require [clojure.core.async.lab :refer [broadcast]])
  (:use [seesaw.core]))</pre></div><p class="calibre7">This<a id="id191" class="calibre1"/> might be a good point to restart your REPL if you haven't done so. Don't worry about any functions we haven't seen yet. We'll get a feel for them in this section.</p><p class="calibre7">The GUI code remains largely unchanged, so no explanation should be necessary for the next snippet:</p><div class="informalexample"><pre class="programlisting">(native!)

(def main-frame (frame :title "Stock price monitor"
                       :width 200 :height 100
                       :on-close :exit))

(def price-label       (label "Price: -"))
(def running-avg-label (label "Running average: -"))

(config! main-frame :content
         (border-panel
          :north  price-label
          :center running-avg-label
          :border 5))

(defn share-price [company-code]
  (Thread/sleep 200)
  (rand-int 1000))

(defn avg [numbers]
  (float (/ (reduce + numbers)
            (count numbers))))

(defn roll-buffer [buffer val buffer-size]
  (let [buffer (conj buffer val)]
    (if (&gt; (count buffer) buffer-size)
      (pop buffer)
      buffer)))

(defn make-sliding-buffer [buffer-size]
  (let [buffer (atom clojure.lang.PersistentQueue/EMPTY)]
    (fn [n]
      (swap! buffer roll-buffer n buffer-size))))

(def sliding-buffer (make-sliding-buffer 5))</pre></div><p class="calibre7">The<a id="id192" class="calibre1"/> only difference is that now we have a <code class="email">sliding-buffer</code> function that returns a window of data. This is in contrast with our original application, where the <code class="email">rolling-avg</code> function was responsible for both creating the window and calculating the average. This new design is more general as it makes this function easier to reuse. The sliding logic is the same, however.</p><p class="calibre7">Next, we have our main application logic using <code class="email">core.async</code>:</p><div class="informalexample"><pre class="programlisting">(defn broadcast-at-interval [msecs task &amp; ports]
  (go-loop [out (apply broadcast ports)]
    (&lt;! (timeout msecs))
    (&gt;! out (task))
    (recur out)))

(defn -main [&amp; args]
  (show! main-frame)
  (let [prices-ch         (chan)
        sliding-buffer-ch (map&gt; sliding-buffer (chan))]
    (broadcast-at-interval 500 #(share-price "XYZ") prices-ch sliding-buffer-ch)
    (go-loop []
      (when-let [price (&lt;! prices-ch)]
        (text! price-label (str "Price: " price))
        (recur)))
    (go-loop []
      (when-let [buffer (&lt;! sliding-buffer-ch)]
        (text! running-avg-label (str "Running average: " (avg buffer)))
        (recur)))))</pre></div><p class="calibre7">Let's walk through the code.</p><p class="calibre7">The first function, <code class="email">broadcast-at-interval</code>, is responsible for creating the broadcasting channel. It receives a variable number of arguments: a number of milliseconds describing the interval, the function representing the task to be executed, and a sequence of one of more output channels. These channels are used to create the broadcasting channel to which the go loop will be writing prices.</p><p class="calibre7">Next, we have our main function. The <code class="email">let</code> block is where the interesting bits are. As we discussed in our high-level diagrams, we need two output channels: one for prices and one<a id="id193" class="calibre1"/> for the sliding window. They are both created in the following:</p><div class="informalexample"><pre class="programlisting">...
  (let [prices-ch         (chan)
        sliding-buffer-ch (map&gt; sliding-buffer (chan))]
...</pre></div><p class="calibre7">
<code class="email">prices-ch</code> should be self-explanatory; however, <code class="email">sliding-buffer-ch</code> is using a function we haven't encountered before: <code class="email">map&gt;</code>. This is yet another useful channel constructor in <code class="email">core.async</code>. It takes two arguments: a function and a target channel. It returns a channel that applies this function to each value before writing it to the target channel. An example will help illustrate how it works:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">(def c (map&gt; sliding-buffer (chan 10)))</strong></span>
<span class="strong"><strong class="calibre2">(go (doseq [n (range 10)]</strong></span>
<span class="strong"><strong class="calibre2">      (&gt;! c n)))</strong></span>
<span class="strong"><strong class="calibre2">(go (doseq [n (range 10)]</strong></span>
<span class="strong"><strong class="calibre2">      (prn  (vec (&lt;! c)))))</strong></span>

<span class="strong"><strong class="calibre2">;; [0]</strong></span>
<span class="strong"><strong class="calibre2">;; [0 1]</strong></span>
<span class="strong"><strong class="calibre2">;; [0 1 2]</strong></span>
<span class="strong"><strong class="calibre2">;; [0 1 2 3]</strong></span>
<span class="strong"><strong class="calibre2">;; [0 1 2 3 4]</strong></span>
<span class="strong"><strong class="calibre2">;; [1 2 3 4 5]</strong></span>
<span class="strong"><strong class="calibre2">;; [2 3 4 5 6]</strong></span>
<span class="strong"><strong class="calibre2">;; [3 4 5 6 7]</strong></span>
<span class="strong"><strong class="calibre2">;; [4 5 6 7 8]</strong></span>
<span class="strong"><strong class="calibre2">;; [5 6 7 8 9]</strong></span>
</pre></div><p class="calibre7">That is, we write a price to the channel and get a sliding window on the other end. Finally, we create the two go blocks containing the side effects. They loop indefinitely, getting values from both channels and updating the user interface.</p><p class="calibre7">You can see it in action by running the program from the terminal:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ lein run -m core-async-playground.stock-market</strong></span>
</pre></div></div></div>
<div class="book" title="Error handling"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec29" class="calibre1"/>Error handling</h1></div></div></div><p class="calibre7">Back in <a class="calibre1" title="Chapter 2. A Look at Reactive Extensions" href="part0021_split_000.html#page">Chapter 2</a>, <span class="strong"><em class="calibre8">A Look at Reactive Extensions</em></span>, we learned how Reactive Extensions treats errors and exceptions. It <a id="id194" class="calibre1"/>provides a rich set of combinators to deal with <a id="id195" class="calibre1"/>exceptional cases and are straightforward to use.</p><p class="calibre7">Despite being a pleasure to work with, <code class="email">core.async</code> doesn't ship with much support for exception handling. In fact, if we write our code with only the happy path in mind we don't even know an error occurred!</p><p class="calibre7">Let's have a look at an example:</p><div class="informalexample"><pre class="programlisting">(defn get-data []
  (throw (Exception. "Bad things happen!")))

(defn process []
  (let [result (chan)]
    ;; do some processing...
    (go (&gt;! result (get-data)))
    result))</pre></div><p class="calibre7">In the preceding snippet, we introduced two functions:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">get-data</code> simulates a function that fetches data from the network or an in-memory cache. In this case it simply throws an exception.</li><li class="listitem"><code class="email">process</code> is a function that depends on <code class="email">get-data</code> to do something interesting and puts the result into a channel, which is returned at the end.</li></ul></div><p class="calibre7">Let's watch what happens when we put this together:</p><div class="informalexample"><pre class="programlisting"> (go (let [result  (&lt;! (-&gt;&gt; (process "data")
                           (map&gt; #(* % %))
                           (map&gt; #(prn %))))]
      (prn "result is: " result)))</pre></div><p class="calibre7">Nothing happens. Zero, zip, zilch, nada.</p><p class="calibre7">This is precisely the problem with error handling in <code class="email">core.async</code>: by default, our exceptions are swallowed by the go block as it runs on a separate thread. We are left in this state where we don't really know what happened.</p><p class="calibre7">Not all is lost, however. David Nolen outlined on his blog a pattern for dealing with such asynchronous exceptions. It only requires a few extra lines of code.</p><p class="calibre7">We start by defining a helper function and macro—this would probably live in a utility namespace we require anywhere we use <code class="email">core.async</code>:</p><div class="informalexample"><pre class="programlisting">(defn throw-err [e]
  (when (instance? Throwable e) (throw e))
  e)

(defmacro &lt;? [ch]
  `(throw-err (async/&lt;! ~ch)))</pre></div><p class="calibre7">The <code class="email">throw-err</code> function receives a value and, if it's a subclass of <code class="email">Throwable</code>, it is thrown. Otherwise, it is simply returned.</p><p class="calibre7">The macro <code class="email">&lt;?</code> is essentially a drop-in replacement for <code class="email">&lt;!</code>. In fact, it uses <code class="email">&lt;!</code> to get the value out of the channel but passes it to <code class="email">throw-err</code> first.</p><p class="calibre7">With these utilities in place, we need to make a couple of changes, first to our <code class="email">process</code> function:</p><div class="informalexample"><pre class="programlisting">(defn process []
  (let [result (chan)]
    ;; do some processing...
    (go (&gt;! result (try (get-data)
                        (catch Exception e
                          e))))
    result))</pre></div><p class="calibre7">The only change is that we wrapped <code class="email">get-data</code> in a <code class="email">try</code>/<code class="email">catch</code> block. Look closely at the <code class="email">catch</code> block: it simply returns the exception.</p><p class="calibre7">This is<a id="id196" class="calibre1"/> important as we need to ensure the exception gets<a id="id197" class="calibre1"/> put into the channel.</p><p class="calibre7">Next, we update our consumer code:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">(go (try (let [result  (&lt;? (-&gt;&gt; (process "data")</strong></span>
<span class="strong"><strong class="calibre2">                                (map&gt; #(* % %))</strong></span>
<span class="strong"><strong class="calibre2">                                (map&gt; #(prn %))))]</strong></span>
<span class="strong"><strong class="calibre2">           (prn "result is: " result))</strong></span>
<span class="strong"><strong class="calibre2">         (catch Exception e</strong></span>
<span class="strong"><strong class="calibre2">           (prn "Oops, an error happened! We better do something about it here!"))))</strong></span>
<span class="strong"><strong class="calibre2">;; "Oops, an error happened! We better do something about it here!"</strong></span>
</pre></div><p class="calibre7">This time we use <code class="email">&lt;?</code> in place of <code class="email">&lt;!</code>. This makes sense as it will rethrow any exceptions found in the channel. As a result we can now use a simple <code class="email">try</code>/<code class="email">catch</code> to regain control over our exceptions.</p></div>

<div id="page" style="height:0pt"/><div class="book" title="Backpressure"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec30" class="calibre1"/>Backpressure</h1></div></div></div><p class="calibre7">The main<a id="id198" class="calibre1"/> mechanism by which <code class="email">core.async</code> allows for coordinating backpressure is buffering. <code class="email">core.async</code> doesn't allow unbounded buffers as this can be a source of bugs and a resource hog.</p><p class="calibre7">Instead, we are <a id="id199" class="calibre1"/>required to think hard about our application's unique needs and choose an appropriate buffering strategy.</p></div>

<div class="book" title="Backpressure">
<div class="book" title="Fixed buffer"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch04lvl2sec33" class="calibre1"/>Fixed buffer</h2></div></div></div><p class="calibre7">This is the <a id="id200" class="calibre1"/>simplest form of buffering. It is fixed to a chosen number <code class="email">n</code>, allowing <a id="id201" class="calibre1"/>producers to put items in the channel without having to wait for consumers:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">(def result (chan (buffer 5)))</strong></span>
<span class="strong"><strong class="calibre2">(go-loop []</strong></span>
<span class="strong"><strong class="calibre2">  (&lt;! (async/timeout 1000))</strong></span>
<span class="strong"><strong class="calibre2">  (when-let [x (&lt;! result)]</strong></span>
<span class="strong"><strong class="calibre2">    (prn "Got value: " x)</strong></span>
<span class="strong"><strong class="calibre2">    (recur)))</strong></span>

<span class="strong"><strong class="calibre2">(go  (doseq [n (range 5)]</strong></span>
<span class="strong"><strong class="calibre2">       (&gt;! result n))</strong></span>
<span class="strong"><strong class="calibre2">     (prn "Done putting values!")</strong></span>
<span class="strong"><strong class="calibre2">     (close! result))</strong></span>

<span class="strong"><strong class="calibre2">;; "Done putting values!"</strong></span>
<span class="strong"><strong class="calibre2">;; "Got value: " 0</strong></span>
<span class="strong"><strong class="calibre2">;; "Got value: " 1</strong></span>
<span class="strong"><strong class="calibre2">;; "Got value: " 2</strong></span>
<span class="strong"><strong class="calibre2">;; "Got value: " 3</strong></span>
<span class="strong"><strong class="calibre2">;; "Got value: " 4</strong></span>
</pre></div><p class="calibre7">In the preceding example, we created a buffer of size <code class="email">5</code> and started a <code class="email">go</code> loop to consume values from it. The <code class="email">go</code> loop uses a <code class="email">timeout</code> channel to delay its start.</p><p class="calibre7">Then, we start another go block that puts numbers from 0 to 4 into the result channel and prints to the console once it's done.</p><p class="calibre7">By then, the first timeout will have expired and we will see the values printed to the REPL.</p><p class="calibre7">Now let's watch what happens if the buffer isn't large enough:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">(def result (chan (buffer 2)))</strong></span>
<span class="strong"><strong class="calibre2">(go-loop []</strong></span>
<span class="strong"><strong class="calibre2">  (&lt;! (async/timeout 1000))</strong></span>
<span class="strong"><strong class="calibre2">  (when-let [x (&lt;! result)]</strong></span>
<span class="strong"><strong class="calibre2">    (prn "Got value: " x)</strong></span>
<span class="strong"><strong class="calibre2">    (recur)))</strong></span>

<span class="strong"><strong class="calibre2">(go  (doseq [n (range 5)]</strong></span>
<span class="strong"><strong class="calibre2">       (&gt;! result n))</strong></span>
<span class="strong"><strong class="calibre2">     (prn "Done putting values!")</strong></span>
<span class="strong"><strong class="calibre2">     (close! Result))</strong></span>
<span class="strong"><strong class="calibre2">;; "Got value: " 0</strong></span>
<span class="strong"><strong class="calibre2">;; "Got value: " 1</strong></span>
<span class="strong"><strong class="calibre2">;; "Got value: " 2</strong></span>
<span class="strong"><strong class="calibre2">;; "Done putting values!"</strong></span>
<span class="strong"><strong class="calibre2">;; "Got value: " 3</strong></span>
<span class="strong"><strong class="calibre2">;; "Got value: " 4</strong></span>
</pre></div><p class="calibre7">This time <a id="id202" class="calibre1"/>our buffer size is <code class="email">2</code> but everything else is the same. As you can see <a id="id203" class="calibre1"/>the <code class="email">go</code> loop finishes much later as it attempted to put another value in the result channel and was blocked/parked since its buffer was full.</p><p class="calibre7">As with most things, this might be OK but if we are not willing to block a fast producer just because we can't consume its items fast enough, we must look for another option.</p></div></div>

<div class="book" title="Backpressure">
<div class="book" title="Dropping buffer"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch04lvl2sec34" class="calibre1"/>Dropping buffer</h2></div></div></div><p class="calibre7">A dropping buffer<a id="id204" class="calibre1"/> also has a fixed size. However, instead of blocking <a id="id205" class="calibre1"/>producers when it is full, it simply ignores any new items as shown here:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">(def result (chan (dropping-buffer 2)))</strong></span>
<span class="strong"><strong class="calibre2">(go-loop []</strong></span>
<span class="strong"><strong class="calibre2">  (&lt;! (async/timeout 1000))</strong></span>
<span class="strong"><strong class="calibre2">  (when-let [x (&lt;! result)]</strong></span>
<span class="strong"><strong class="calibre2">    (prn "Got value: " x)</strong></span>
<span class="strong"><strong class="calibre2">    (recur)))</strong></span>

<span class="strong"><strong class="calibre2">(go  (doseq [n (range 5)]</strong></span>
<span class="strong"><strong class="calibre2">       (&gt;! result n))</strong></span>
<span class="strong"><strong class="calibre2">     (prn "Done putting values!")</strong></span>
<span class="strong"><strong class="calibre2">     (close! result))</strong></span>

<span class="strong"><strong class="calibre2">;; "Done putting values!"</strong></span>
<span class="strong"><strong class="calibre2">;; "Got value: " 0</strong></span>
<span class="strong"><strong class="calibre2">;; "Got value: " 1</strong></span>
</pre></div><p class="calibre7">As before, we <a id="id206" class="calibre1"/>still have a buffer of size two, but this time the producer <a id="id207" class="calibre1"/>ends quickly without ever getting blocked. The <code class="email">dropping-buffer</code> simply ignored all items over its limit.</p></div></div>

<div class="book" title="Backpressure">
<div class="book" title="Sliding buffer"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch04lvl2sec35" class="calibre1"/>Sliding buffer</h2></div></div></div><p class="calibre7">A drawback <a id="id208" class="calibre1"/>of dropping buffers is that we might not be processing the latest items at a given time. For the times where processing the latest information is <a id="id209" class="calibre1"/>a must, we can use a sliding buffer:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">(def result (chan (sliding-buffer 2)))</strong></span>
<span class="strong"><strong class="calibre2">(go-loop []</strong></span>
<span class="strong"><strong class="calibre2">  (&lt;! (async/timeout 1000))</strong></span>
<span class="strong"><strong class="calibre2">  (when-let [x (&lt;! result)]</strong></span>
<span class="strong"><strong class="calibre2">    (prn "Got value: " x)</strong></span>
<span class="strong"><strong class="calibre2">    (recur)))</strong></span>

<span class="strong"><strong class="calibre2">(go  (doseq [n (range 5)]</strong></span>
<span class="strong"><strong class="calibre2">       (&gt;! result n))</strong></span>
<span class="strong"><strong class="calibre2">     (prn "Done putting values!")</strong></span>
<span class="strong"><strong class="calibre2">     (close! result))</strong></span>

<span class="strong"><strong class="calibre2">;; "Done putting values!"</strong></span>
<span class="strong"><strong class="calibre2">;; "Got value: " 3</strong></span>
<span class="strong"><strong class="calibre2">;; "Got value: " 4</strong></span>
</pre></div><p class="calibre7">As before, we only get two values but they are the latest ones produced by the <code class="email">go</code> loop.</p><p class="calibre7">When the limit of the sliding buffer is overrun, <code class="email">core.async</code> drops the oldest items to make room for the newest ones. I end up using this buffering strategy most of the time.</p></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Transducers"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec31" class="calibre1"/>Transducers</h1></div></div></div><p class="calibre7">Before we <a id="id210" class="calibre1"/>finish up with our <code class="email">core.async</code> portion of the book, it would be unwise of me not to mention what is coming up in Clojure 1.7 as well as how this affects <code class="email">core.async</code>.</p><p class="calibre7">At the time of this writing, Clojure's latest release is <code class="email">1.7.0-alpha5</code>—and even though it is an alpha release, a lot of people—myself included—are already using it in production.</p><p class="calibre7">As such, a final version could be just around the corner and perhaps by the time you read this, 1.7 final will be out already.</p><p class="calibre7">One of the big <a id="id211" class="calibre1"/>changes in this upcoming release is the introduction of <code class="email">transducers</code>. We will not cover the nuts and bolts of it here but rather focus on what it means at a high-level with examples using both Clojure sequences and <code class="email">core.async</code> channels.</p><p class="calibre7">If you would like to know more I recommend Carin Meier's <span class="strong"><em class="calibre8">Green Eggs and Transducers</em></span> blog post (<a class="calibre1" href="http://gigasquidsoftware.com/blog/2014/09/06/green-eggs-and-transducers/">http://gigasquidsoftware.com/blog/2014/09/06/green-eggs-and-transducers/</a>). It's a<a id="id212" class="calibre1"/> great place to start.</p><p class="calibre7">Additionally, the official Clojure documentation site on the subject is another useful resource (<a class="calibre1" href="http://clojure.org/transducers">http://clojure.org/transducers</a>).</p><p class="calibre7">Let's get started by creating a new leiningen project:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ lein new core-async-transducers</strong></span>
</pre></div><p class="calibre7">Now, open your <code class="email">project.clj</code> file and make sure you have the right dependencies:</p><div class="informalexample"><pre class="programlisting">...
  :dependencies [[org.clojure/clojure "1.7.0-alpha5"]
                 [org.clojure/core.async "0.1.346.0-17112a-alpha"]]
...</pre></div><p class="calibre7">Next, fire up a REPL session in the project root and require <code class="email">core.async</code>, which we will be using shortly:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ lein repl</strong></span>
<span class="strong"><strong class="calibre2">user&gt; (require '[clojure.core.async :refer [go chan map&lt; filter&lt; into &gt;! &lt;! go-loop close! pipe]])</strong></span>
</pre></div><p class="calibre7">We will start with a familiar example:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">(-&gt;&gt; (range 10)</strong></span>
<span class="strong"><strong class="calibre2">     (map inc)           ;; creates a new sequence</strong></span>
<span class="strong"><strong class="calibre2">     (filter even?)      ;; creates a new sequence</strong></span>
<span class="strong"><strong class="calibre2">     (prn "result is "))</strong></span>
<span class="strong"><strong class="calibre2">;; "result is " (2 4 6 8 10)</strong></span>
</pre></div><p class="calibre7">The preceding snippet is straightforward and highlights an interesting property of what happens when we apply combinators to Clojure sequences: each combinator creates an intermediate sequence.</p><p class="calibre7">In the previous example, we ended up with three in total: the one created by <code class="email">range</code>, the one created by <code class="email">map</code>, and finally the one created by <code class="email">filter</code>. Most of the time, this won't really be an issue but for large sequences this means a lot of unnecessary allocation.</p><p class="calibre7">Starting in Clojure 1.7, the previous example can be written like so:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">(def xform</strong></span>
<span class="strong"><strong class="calibre2">  (comp (map inc)</strong></span>
<span class="strong"><strong class="calibre2">        (filter even?)))  ;; no intermediate sequence created</strong></span>

<span class="strong"><strong class="calibre2">(-&gt;&gt; (range 10)</strong></span>
<span class="strong"><strong class="calibre2">     (sequence xform)</strong></span>
<span class="strong"><strong class="calibre2">     (prn "result is "))</strong></span>
<span class="strong"><strong class="calibre2">;; "result is " (2 4 6 8 10)</strong></span>
</pre></div><p class="calibre7">The Clojure <a id="id213" class="calibre1"/>documentation describes transducers as composable algorithmic transformations. Let's see why that is.</p><p class="calibre7">In the new version, a whole range of the core sequence combinators, such as <code class="email">map</code> and <code class="email">filter</code>, have gained an extra arity: if you don't pass it a collection, it instead returns a transducer.</p><p class="calibre7">In the previous example, <code class="email">(map inc)</code> returns a transducer that knows how to apply the function <code class="email">inc</code> to elements of a sequence. Similarly, <code class="email">(filter even?)</code> returns a transducer that will eventually filter elements of a sequence. Neither of them do anything yet, they simply return functions.</p><p class="calibre7">This is interesting because transducers are composable. We build larger and more complex transducers by using simple function composition:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">(def xform</strong></span>
<span class="strong"><strong class="calibre2">  (comp (map inc)</strong></span>
<span class="strong"><strong class="calibre2">        (filter even?)))</strong></span>
</pre></div><p class="calibre7">Once we have our transducer ready, we can apply it to a collection in a few different ways. For this example, we chose <code class="email">sequence</code> as it will return a lazy sequence of the applications of the given transducer to the input sequence:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">(-&gt;&gt; (range 10)</strong></span>
<span class="strong"><strong class="calibre2">     (sequence xform)</strong></span>
<span class="strong"><strong class="calibre2">     (prn "result is "))</strong></span>
<span class="strong"><strong class="calibre2">;; "result is " (2 4 6 8 10)</strong></span>
</pre></div><p class="calibre7">As previously highlighted, this code does not create intermediate sequences; transducers extract the very core of the algorithmic transformation at hand and abstracts it away from having to deal with sequences directly.</p></div>

<div class="book" title="Transducers">
<div class="book" title="Transducers and core.async"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch04lvl2sec36" class="calibre1"/>Transducers and core.async</h2></div></div></div><p class="calibre7">We<a id="id214" class="calibre1"/> might <a id="id215" class="calibre1"/>now be asking ourselves "What do transducers have to do with <code class="email">core.async</code>?" </p><p class="calibre7">It turns out that once we're able to extract the core of these transformations and put them together <a id="id216" class="calibre1"/>using simple function composition, there is nothing <a id="id217" class="calibre1"/>stopping us from using transducers with data structures other than sequences!</p><p class="calibre7">Let's revisit our first example using standard <code class="email">core.async</code> functions:</p><div class="informalexample"><pre class="programlisting">(def result (chan 10))

(def transformed
  (-&gt;&gt; result
       (map&lt; inc)      ;; creates a new channel
       (filter&lt; even?) ;; creates a new channel
       (into [])))     


(go
  (prn "result is " (&lt;! transformed)))

(go
  (doseq [n (range 10)]
    (&gt;! result n))
  (close! result))

;; "result is " [2 4 6 8 10] </pre></div><p class="calibre7">This code should look familiar by now: it's the <code class="email">core.async</code> equivalent of the sequence-only version shown earlier. As before, we have unnecessary allocations here as well, except that this time we're allocating channels.</p><p class="calibre7">With the new support for transducers, <code class="email">core.async</code> can take advantage of the same transformation defined earlier:</p><div class="informalexample"><pre class="programlisting">(def result (chan 10))

(def xform 
     (comp (map inc)
           (filter even?)))  ;; no intermediate channels created

(def transformed (-&gt;&gt; (pipe result (chan 10 xform))
                      (into [])))


(go
  (prn "result is " (&lt;! transformed)))

(go
  (doseq [n (range 10)]
    (&gt;! result n))
  (close! result))

<span class="strong"><strong class="calibre2">;; "result is " [2 4 6 8 10]</strong></span>
</pre></div><p class="calibre7">The code<a id="id218" class="calibre1"/> remains largely unchanged except we now use the <a id="id219" class="calibre1"/>same <code class="email">xform</code> transformation defined earlier when creating a new channel. It's important to note that we did not have to use <code class="email">core.async</code> combinators—in fact a lot of these combinators have been deprecated and will be removed in future versions of <code class="email">core.async</code>.</p><p class="calibre7">The functions <code class="email">map</code> and <code class="email">filter</code> used to define <code class="email">xform</code> are the same ones we used previously, that is, they are core Clojure functions.</p><p class="calibre7">This is the next big advantage of using transducers: by removing the underlying data structure from the equation via transducers, libraries such as <code class="email">core.async</code> can reuse Clojure's core combinators to prevent unnecessary allocation and code duplication.</p><p class="calibre7">It's not too far fetched to imagine other frameworks like RxClojure could take advantage of transducers as well. All of them would be able to use the same core function across substantially different data structures and contexts: sequences, channels, and Obervables.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="tip18" class="calibre1"/>Tip</h3><p class="calibre7">The concept of extracting the essence of computations disregarding their underlying data structures is an exciting topic and has been seen before in the Haskell community, although they deal with lists specifically.</p><p class="calibre7">Two papers worth mentioning on the subject are <span class="strong"><em class="calibre8">Stream Fusion</em></span> [11] by Duncan Coutts, Roman Leshchinskiy and Don Stewart and <span class="strong"><em class="calibre8">Transforming programs to eliminate trees</em></span> [12] by Philip Wadler. There are some overlaps so the reader might find these interesting.</p></div></div></div>
<div class="book" title="Summary"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec32" class="calibre1"/>Summary</h1></div></div></div><p class="calibre7">By now, I hope to have proved that you can write reactive applications using <code class="email">core.async</code>. It's an extremely powerful and flexible concurrency model with a rich API. If you can <a id="id220" class="calibre1"/>design your solution in terms of queues, most likely <code class="email">core.async</code> is the tool you want to reach for.</p><p class="calibre7">This version of the stock market application is shorter and simpler than the version using only the standard Java API we developed earlier in this book—for instance, we didn't have to worry about thread pools. On the other hand, it feels like it is a little more complex than the version implemented using Reactive Extensions in <a class="calibre1" title="Chapter 3. Asynchronous Programming and Networking" href="part0028_split_000.html#page">Chapter 3</a>, <span class="strong"><em class="calibre8">Asynchronous Programming and Networking</em></span>.</p><p class="calibre7">This is <a id="id221" class="calibre1"/>because <code class="email">core.async</code> operates at a lower level of abstraction when compared to other frameworks. This becomes especially obvious in our application as we had to worry about creating broadcasting channels, go loops, and so on—all of which can be considered incidental complexity, not directly related to the problem at hand.</p><p class="calibre7">
<code class="email">core.async</code> does, however, provide an excellent foundation for building our own CES abstractions. This is what we will be exploring next.</p></div></body></html>