- en: Chapter 4. Exploring the Collection API
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章。探索集合API
- en: In this chapter, we return to MVT in order to take on challenges that span multiple
    MVT teams. The market data team requires improved critical path order book performance
    to handle increased cancel request volume. The data science team wants better
    ad hoc data analysis tools to research trading strategies. Everyone has a problem
    that had to be solved yesterday. That's the start-up lifestyle!
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们回到MVT，以应对跨越多个MVT团队的多重挑战。市场数据团队需要改进关键路径订单簿性能以处理增加的取消请求量。数据科学团队希望有更好的临时数据分析工具来研究交易策略。每个人都面临一个昨天就必须解决的问题。这就是创业生活！
- en: 'We use the functional paradigm, our existing knowledge, and the Scala collections
    API to our advantage to solve these challenges. The power of the Scala language
    and its collections API allow you to approach problems in ways that you may not
    have thought possible before. As we work through these challenges and encounter
    new Scala collection usage, we detail collection implementation and tradeoffs
    to consider. We will consider the following collections in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用函数式范式、现有知识和Scala集合API的优势来解决这些挑战。Scala语言及其集合API的力量允许你以前未曾想到的方式处理问题。随着我们解决这些挑战并遇到新的Scala集合使用，我们将详细说明集合实现和需要考虑的权衡。在本章中，我们将考虑以下集合：
- en: List
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: List
- en: TreeMap
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TreeMap
- en: Queue
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Queue
- en: Set
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Set
- en: Vector
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vector
- en: Array
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Array
- en: High-throughput systems – improving the order book
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高吞吐量系统 - 提高订单簿性能
- en: In [Chapter 1](ch01.html "Chapter 1.  The Road to Performance"), *The Road to
    Performance*, you met MVT's head trader, Dave, under tense circumstances. The
    financial markets underwent a period of extreme volatility that exposed a weakness
    in the order book design. After speaking to Dave, you learned that in volatile
    markets, order volume is dominated by cancels because traders are reacting to
    quickly changing market conditions. Through order book benchmarking and profiling,
    you confirmed the suspicion that under high volume, cancel performance causes
    high order book response latency.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第一章](ch01.html "第一章。通往绩效之路")《通往绩效之路》中，你在紧张的情境下遇到了MVT的首席交易员Dave。金融市场经历了一段极端波动的时期，暴露了订单簿设计的弱点。在与Dave交谈后，你了解到在波动市场中，订单量主要由取消订单组成，因为交易员正在对快速变化的市场条件做出反应。通过订单簿基准测试和配置文件分析，你证实了在高成交量下，取消性能导致高订单簿响应延迟的怀疑。
- en: Although the market volatility that caused trading losses has passed, Dave recognizes
    the risk that future volatility poses for MVT's returns. Dave wants to invest
    engineering effort into making the order book more performant when cancelations
    frequently occur. By working with the data science team, Dave analyzed historical
    order book activity over a three month period and discovered interesting market
    characteristics. He shares with you that in the three months analyzed, on a per
    trading day basis, cancels comprised, on average, 70% of order book commands.
    The analysis also revealed that on the most volatile market days, cancel activity
    represents about 85% of order book activity. Known for his puns, Dave concludes
    with, "Now, you know everything I know. Like the order book, we are counting on
    you to execute!"
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管导致交易损失的波动市场已经过去，Dave认识到未来波动对MVT回报的风险。Dave希望投入工程力量，使订单簿在频繁取消时更具性能。通过与数据科学团队合作，Dave分析了三个月的订单簿历史活动，并发现了有趣的市场特征。他与你分享，在分析的三个月中，按每个交易日计算，取消订单平均占订单簿命令的70%。分析还显示，在波动最大的市场日，取消活动占订单簿活动的约85%。以他的双关语而闻名，Dave总结道：“现在，你知道了我所知道的一切。就像订单簿一样，我们依赖你来执行！”
- en: Understanding historical trade-offs – list implementation
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解历史权衡 - 列实现
- en: Excited to improve order book performance, your first step is to familiarize
    yourself with the order book implementation. As you open up the order book repository,
    you ping Gary, a fellow engineer who has prior order book development experience.
    As Gary knows the history of order book development, he tells you to check out
    `ListOrderBook`. "This was our first attempt at modeling the order book. I think
    you can learn from our design by seeing its first incarnation," he adds, "Once
    you understand the implementation, check out `QueueOrderBook`. That's the next
    version of the order book. You profiled an older iteration of this implementation
    when we had the volatility wave. Let me know if you have any questions!" After
    thanking him, you dig into the repository to find `ListOrderBook`.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ListOrderBook` class defines the following state to manage buys (bids)
    and sells (offers):'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To refresh our memory, here are definitions of `Price`, `BuyLimitOrder`, and `SellLimitOrder`:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The `LimitOrder` is an **algebraic data type** (**ADT**) that represents the
    two possible order sides. The `Price` class is a strongly-typed wrapper for `BigDecimal`.
    Recalling the performance boost that value classes provide, you modify the definition
    of `Price`, as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `ListOrderBook` class uses two Scala collection types to maintain its state: `List`
    and `TreeMap`. Let's have a deeper look at these data structures to understand
    the tradeoffs that they present.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: List
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Scala implements `List` as an immutable singly-linked list. A `List` is an
    ordered collection of elements of the same type. A `List` is a sealed abstract
    class with two implementations: `Nil`, which represents the empty list, and `::`
    (often called cons), which is used to represent an element and a tail. To make
    things more concrete, let''s look at some pseudocode, which is close to the actual
    implementation:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'A `List` of three integers can be constructed using the following notation:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Note the plus sign in the definition of the `List` trait. The plus (`+`) sign
    indicates that `List` is covariant on its type parameter, `A`. Covariance allows
    you to express polymorphic constraints with generic types. To make this more concrete,
    consider the following definitions:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '`sealed trait Base`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '`case class Impl(value: Int) extends Base`'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, a relationship is expressed between `Base` and `Impl`. The `Impl` class
    is a subtype of `Base`. When used with `List`, covariance allows us to express
    that `List[Impl]` is a subtype of `List[Base]`. Expressed with an example, covariance
    is what allows the following snippet to compile:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '`val bases: List[Base] = List[Impl](Impl(1))`'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Covariance belongs to the broader topic of variances. If you wish to learn more
    about variances in Scala, refer to this excellent blog post by Andreas Schroeder
    at [https://blog.codecentric.de/en/2015/03/scala-type-system-parameterized-types-variances-part-1/](https://blog.codecentric.de/en/2015/03/scala-type-system-parameterized-types-variances-part-1/).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike most other Scala collections, `List` supports pattern matching on its
    content. This is a powerful way to write expressive code that handles multiple
    scenarios while retaining compile-time safety that all possible cases are handled.
    Consider the following snippet:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this simple pattern match, we are able to express several concerns. Here,
    `1` is `1`, `x` is `2`, and `rest` is `List(3,4)`. When compiled, this snippet
    elicits a compiler warning because the Scala compiler infers that there are possible `List`
    patterns that were unmatched (for example, empty `List`). Compiler-provided warnings
    minimize the chance of your forgetting to handle a valid input.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: 'A `List` is optimized for prepend operations. Adding 0 to the previous list
    is as easy as doing this:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This is a constant-time operation, and it has almost no memory cost, as `List`
    implements data sharing. In other words, the new list, `listWithZero`, is not
    a deep copy of `list`. Instead, it re-uses all its allocated elements and allocates
    only one new element, the cell containing `0`:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![List](img/image_04_001.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: 'In contrast to prepend operations, append operations (that is, adding an element
    to the end of the list) are computationally expensive because the entire `List`
    must be copied:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '![List](img/image_04_002.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
- en: Given the poor append performance of List, you may wonder whether it is safe
    to use a `map` transform. A `map` transform occurs by applying a function to successive
    elements in the `List`, which can be logically represented by appending transformed
    values to a new `List`. To avoid this performance pitfall, `List.map` overrides
    the default implementation provided by the trait `TraversableOnce` to apply the
    transform using prepend operations. This provides improved `List.map` performance
    while retaining the same API. Overriding default behavior to provide a specialized
    implementation is a common Scala collections pattern. Constant time head operations
    make `List` ideal for algorithms involving last-in, first-out (LIFO) operations.
    For random access and first-in, first-out (FIFO) behaviors, you should employ `List`
    selectively.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we investigate `TreeMap`. The `TreeMap` class is the implementation
    of the `SortedMap` trait that is used to maintain bids and offers.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: TreeMap
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `TreeMap` class is a map that orders keys according to a provided ordering
    strategy. The following snippet of its class definition makes the ordering requirement
    clear:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `Ordering` class is a type class that defines a contract for the natural
    ordering of elements of the `A` type.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If type classes are a concept that is new to you, we encourage you to read Daniel
    Westheide's well-written blog post on the topic at [http://danielwestheide.com/blog/2013/02/06/the-neophytes-guide-to-scala-part-12-type-classes.html](http://danielwestheide.com/blog/2013/02/06/the-neophytes-guide-to-scala-part-12-type-classes.html).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'In `ListOrderBook`, we see that `Price` is the key. Looking at the companion
    object of `Price`, we see that the ordering is defined by delegating to the underlying
    `BigDecimal` type''s ordering definition:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `TreeMap `class referenced by `ListOrderBook`, like `List`, is immutable.
    Immutability provides strong reasoning guarantees. We can be certain that there
    are no side effects because the effect of adding or removing a value from the
    map is always reflected as a new map.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: The `TreeMap` class implementation is a special type of binary search tree,
    the red-black tree. This tree implementation provides logarithmic operation time
    for lookups, additions, and removals. You might be surprised to see `TreeMap`
    in place of `HashMap`. As documented in the Scala collections performance overview
    ([http://docs.scala-lang.org/overviews/collections/performance-characteristics.html](http://docs.scala-lang.org/overviews/collections/performance-characteristics.html)), `HashMap`
    provides constant time lookups, additions, and removals, which is faster than `TreeMap`.
    However, `TreeMap` offers superior performance when performing ordered traversals.
    For example, finding the largest key in the map can be done in logarithmic time
    with `TreeMap`, while this is done in linear time for `HashMap`. This difference
    is an indicator that the order book implementation requires efficient ordered `Price`
    traversals.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Adding limit orders
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Coming back to the `ListOrderBook` implementation, we see the following partial
    method definition reflects the heart of the order book:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It might seem curious that a function is supplied as an argument to retrieve
    the current time. A potentially simpler way to achieve the same effect is to invoke
    `System.currentTimeMillis()`. The shortcoming of this approach is that accessing
    the system clock is a side-effect, which means that the function is no longer
    referentially transparent. By providing a function to retrieve the current time,
    we are able to control how this side-effect happens and produce repeatable test
    cases.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'Given a `Command`, an order book instance, and a way to obtain the current
    time for event timestamps, an `Event` and a new state are produced. To refresh
    our memory, here are the commands the order book can process:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following are the possible events created by processing commands:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s focus on supporting the `AddLimitOrder` command to better understand
    the algorithmic properties of historical design choices. When adding a limit order,
    one of two outcomes is possible:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: The incoming order price crosses the book resulting in `OrderExecuted`
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The oncoming order rests on the book resulting in `LimitOrderAdded`
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deducing whether or not the order crosses the book requires looking at the
    best price on the opposing side. Returning to the definition of `LimitOrderBook`
    with complete implementation of `bestBid` and `bestOffer`, we see the following:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The implementation shows that we are taking advantage of the logarithmic ordered
    search property of `TreeMap`. The best bid is the key with the highest price,
    which is the last value in the tree because the ordering is ascending. The best
    offer is the key with the lowest price, which is the first value in the tree.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 实现显示我们正在利用`TreeMap`的对数有序搜索属性。最佳买入价是具有最高价格的键，它是树中的最后一个值，因为排序是升序的。最佳卖出价是具有最低价格的键，它是树中的第一个值。
- en: 'Focusing specifically on the addition of a buy limit order and given the best
    offer, the following comparison occurs to determine whether the incoming buy order
    crosses the book or rests on the book:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 专注于买入限价订单的添加以及最佳出价，以下比较发生以确定即将到来的买入订单是穿过订单簿还是停留在订单簿上：
- en: '[PRE13]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s first assume that the incoming buy order''s price is lower than the
    best offer, which means the order is added to the book (that is, rests on the
    book). The question we are trying to answer is, "where in the book should the
    order be added?" The order book performs a logarithmic search to find the price
    level associated with the order price. From the definition of `ListOrderBook`,
    you know that each value in the map (the price level) is represented as a `List`
    of orders. Recalling a discussion with the head trader, Dave, you remember that
    orders within a price level are executed based on time priority. The first order
    added to a price level is the first order to be executed. Conceptually, a price
    level is a first-in, first-out (FIFO) queue. The implication is that adding an
    order to a price level is a linear time operation because the order is appended
    to the end. The following snippet confirms your hypothesis:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先假设即将到来的买入订单的价格低于最佳出价，这意味着订单被添加到订单簿中（即停留在订单簿上）。我们试图回答的问题是，“订单应该添加到订单簿的哪个位置？”订单簿执行对数搜索以找到与订单价格相关的价格水平。根据`ListOrderBook`的定义，你知道映射中的每个值（价格水平）都表示为一个订单的`List`。回忆与首席交易员Dave的讨论，你记得在同一价格水平内的订单是按照时间优先级执行的。首先添加到价格水平的订单是首先被执行的。从概念上讲，价格水平是一个先进先出（FIFO）队列。这意味着向价格水平添加订单是一个线性时间操作，因为订单被追加到末尾。下面的摘要是确认你的假设：
- en: '[PRE14]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The snippet shows that adding a resting limit order to the book involves a linear
    time append operation to `List` of `BuyLimitOrder`. In your mind, you are beginning
    to wonder how MVT was able to trade profitably at all with this order book. Before
    leaping to this harsh judgment, you consider how crossing the book is handled.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要显示，向订单簿中添加一个休息限价订单涉及到对`BuyLimitOrder`的`List`进行线性时间追加操作。在你的脑海中，你开始怀疑MVT如何能够利用这个订单簿进行有利可图的交易。在做出这样的严厉判断之前，你考虑了如何处理订单簿的交叉。
- en: 'Assuming that the incoming buy order''s price is greater than or equal to the
    best offer price, then the buy order crosses the book, causing an execution. Time
    priority dictates that the first sell order received is executed against the incoming
    buy order, which translates to taking the first sell order in the price level.
    When generating an execution, you realize that modeling a price level with a `List`
    provides constant time performance. The following snippet shows how a price level
    is modified on a buy execution:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 假设即将到来的买入订单的价格大于或等于最佳出价，那么买入订单将穿过订单簿，导致执行。时间优先级规定，首先收到的卖出订单将与即将到来的买入订单执行，这相当于取价格水平中的第一个卖出订单。在生成执行时，你意识到使用`List`来模拟价格水平提供了常数时间性能。以下摘要是如何修改买入执行中的价格水平的：
- en: '[PRE15]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `ListOrderBook` takes advantage of the `List` pattern matching to handle
    the two possible cross scenarios:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`ListOrderBook`利用`List`模式匹配来处理两种可能的交叉场景：'
- en: The executed sell order is the only order available in the price level
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行的卖出订单是该价格水平中唯一可用的订单
- en: Additional sell orders remain at the price level
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 额外的卖出订单仍然停留在价格水平
- en: In the former scenario, the price level is removed from the book by removing
    the key from the offers `TreeMap`. In the latter scenario, the remaining orders
    form the new price level. Clearly, the order book is optimized for executions
    over adding resting orders. You wonder why this bias exists in the order book
    implementation. You wonder to yourself, "perhaps, executions are more much more
    prevalent than resting orders?" You are unsure and make a mental note to chat
    with Dave.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一种情况下，通过从 `offers` `TreeMap` 中移除键来从订单簿中删除价格层级。在后一种情况下，剩余的订单形成新的价格层级。显然，订单簿是针对执行操作而不是添加挂起订单进行优化的。你想知道为什么订单簿实现中存在这种偏见。你自问，“也许，执行操作比挂起订单更普遍？”你不确定，并在心里记下要和
    Dave 聊聊。
- en: Note
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Pause for a moment to consider biases in systems that you have designed. Did
    you optimize operations proportional to usage or latency constraints? Looking
    back, did your design choices lead you towards the best possible performance for
    the most important operations? Of course, hindsight makes it easy to call out
    suboptimal design choices. By reflecting on how you made these choices, you might
    be better able to avoid similar deficiencies in future systems.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 休息一下，考虑一下你设计的系统中存在的偏见。你是否优化了与使用量或延迟约束成比例的操作？回顾过去，你的设计选择是否使你朝着最重要的操作的最佳性能迈进？当然，事后诸葛亮很容易指出次优的设计选择。通过反思你如何做出这些选择，你可能能够更好地避免未来系统中类似的缺陷。
- en: Canceling orders
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 取消订单
- en: The `ListOrderBook` also supports the `CancelOrder` command to remove an existing
    order by ID. Cancel requests pose an algorithmic challenge to `ListOrderBook`.
    As only the order ID is provided, `ListOrderBook` cannot efficiently determine
    which side the order rests on (that is, buy or sell). To determine the side, the
    buy and sell price levels are swept to find the order ID. This is an operation
    that is proportional to the number of price levels per side and the length of
    each price level. The worst case scenario is submitting an order ID that does
    not exist in the order book. The entire book must be swept to identify the absence
    of the provided order ID. A malicious trader could slow down MVT order book operations
    by submitting a constant stream of nonexistent order IDs. You make a note to talk
    with Dave about malicious trading activities and what MVT can do to defend against
    them.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`ListOrderBook` 也支持使用 `CancelOrder` 命令通过 ID 删除现有订单。取消请求对 `ListOrderBook` 构成了算法挑战。因为只提供了订单
    ID，`ListOrderBook` 无法高效地确定订单位于哪一侧（即买入或卖出）。为了确定侧边，需要遍历买入和卖出的价格层级以找到订单 ID。这是一个与每侧价格层级数量和每个价格层级的长度成比例的操作。最坏的情况是提交一个在订单簿中不存在的订单
    ID。整个订单簿必须被遍历以识别提供的订单 ID 是否缺失。恶意交易者可以通过提交一系列不存在的订单 ID 来减缓 MVT 订单簿的操作。你记下笔记，打算和
    Dave 谈谈恶意交易活动以及 MVT 可以如何防御这些活动。'
- en: 'Assuming that the order referenced by the cancel request exists in the book
    and its price level is discovered, the act of removing the cancelled order from
    the book is also expensive. Canceling is a linear time operation that requires
    traversing the linked list of orders and removing the node with the matching order
    ID. The following snippet implements canceling a sell order in `ListOrderBook`:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 假设取消请求中引用的订单存在于订单簿中，并且其价格层级已被发现，从订单簿中移除已取消订单的操作也是昂贵的。取消是一个线性时间操作，需要遍历订单的链表并移除匹配订单
    ID 的节点。以下代码片段实现了在 `ListOrderBook` 中取消卖出订单：
- en: '[PRE16]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Studying this snippet, it is unsurprising to you that cancelation performance
    is the least performant order book operation. There are two linear time passes
    performed per price level to cancel the order. First, `exists` traverses the list
    of price level orders to determine whether the ID to be canceled exists in the
    price level. Once the price level containing the ID is found, there is a second
    traversal via `filter` to update the state of the order book.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 研究这个代码片段，取消性能是最低效的订单簿操作，这并不让你感到惊讶。取消订单需要在每个价格层级上执行两次线性时间遍历。首先，`exists` 遍历价格层级订单列表以确定要取消的
    ID 是否存在于价格层级中。一旦找到包含该 ID 的价格层级，就会通过 `filter` 执行第二次遍历来更新订单簿的状态。
- en: The cancelation implementation in `ListOrderBook` is an illustration of the
    double-edged sword of Scala's expressive collection API. By virtue of being expressive,
    the cancelation logic is simple to understand and to maintain. However, its expressiveness
    also makes it easy to hide that the runtime performance of removing an order from
    a price level is *2 * N*, where *N* is the number of orders in a price level.
    This simple example makes it clear that in a performance-sensitive environment,
    it is important to take a step back from the code to consider the runtime overhead
    of the data structure that is being used.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: The current order book – queue implementation
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You refrain from judging `ListOrderBook` too harshly because you know from
    your prior software development experiences that there were likely extenuating
    circumstances that led to this implementation. You turn your attention to the
    current order book implementation, which is in `QueueOrderBook`. Looking over
    the source code, you are surprised to discover the implementation appears to match `ListOrderBook`
    except for the price level data structure:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The only difference between the two implementations is the use of `scala.collection.immutable.Queue`
    in place of `List` to represent a price level. From a modeling perspective, using
    a FIFO queue makes sense. As time priority dictates execution order, a FIFO queue
    is a natural fit to store resting orders. You begin wondering whether switching
    out `List` for `Queue` was done purely for modeling purposes. The question on
    your mind is, "how does replacing `List` with `Queue` improve order book performance?"
    Understanding this change requires digging deeper into Scala's `Queue` implementation.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Queue
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This snippet of a `Queue` definition reveals an interesting insight:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Without reading deeply into the `Queue` implementation, we see that it uses
    two `Lists` to manage state. Given the usage of `List` to model a FIFO queue in `ListOrderBook`,
    it should not be surprising to see the usage of `List` to build an immutable FIFO
    queue data structure. Let''s look at the enqueue and dequeue operations to understand
    how in and out impact `Queue` performance. The following snippet shows the implementation
    of enqueue:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'As the element is prepended to `in`, enqueueing is a constant time operation.
    Recall that the analogous `ListOrderBook` operation is adding a resting order,
    which has linear runtime performance. This is a clear performance win for `QueueOrderBook`.
    Next, we consider dequeue implementation:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Note
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As the implementation shows, dequeue throws an exception when invoked with an
    empty `Queue`. The exception is an unexpected outcome to invoking `dequeue` and
    feels out of place in the functional programming paradigm. For this reason, `Queue`
    also provides `dequeueOption` that returns an `Option`. This makes the handling
    of an empty `Queue` explicit and easier to reason about. We recommend using `dequeueOption`
    in any situation where you cannot guarantee that `dequeue` will always be called
    on a nonempty `Queue`.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: 'The `dequeue` operation is more involved than `enqueue` due to the interaction
    between `in` and `out`. To understand how the `Queue` state is managed with the `dequeue`
    operations, review the following table. This table walks through a series of the `enqueue`
    and `dequeue` operations, listing the state of `in` and `out` at each step. As
    you review the table, consider which  `dequeue` patterns match statements that
    are invoked:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '| **Operation** | **In** | **Out** |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
- en: '| enqueue(1) | List(1) | Nil |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
- en: '| enqueue(2) | List(1, 2) | Nil |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
- en: '| enqueue(3) | List(1, 2, 3) | Nil |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
- en: '| dequeue | Nil | List(2, 3) |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
- en: '| dequeue | Nil | List(3) |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
- en: '| enqueue(4) | List(4) | List(3) |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
- en: '| dequeue | List(4) | Nil |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
- en: '| dequeue | Nil | Nil |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
- en: As the `enqueue` and `dequeue` invocations are intermingled, both `in` and `out`
    retain state. In the final sequence displayed, the queue returns to its initial
    state (that is, both `in` and `out` empty). The key insight from this implementation
    is that `Queue` amortizes the cost of `dequeue` to be constant time by deferring
    transfers from `in` and `out`. Each element transfer from `in` and `out` is a
    linear time `reverse` operation to maintain first-in, first-out ordering. Deferring
    the cost of this expensive operation until `out` is empty is a form of lazy evaluation.
    This is an illustrative example of how lazy evaluation can be used to improve
    runtime performance.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you have an understanding of how `Queue` is implemented, you can reason
    about the performance improvements delivered by `QueueOrderBook`. The following
    table itemizes the runtime performance of each scenario to modify a price level:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '| **Scenario** | **ListOrderBook** | **QueueOrderBook** |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
- en: '| Add resting limit order | Linear | Constant |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
- en: '| Generate execution | Constant | Amortized constant |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
- en: '| Cancel order | Linear | Linear |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
- en: This table illustrates how understanding the runtime characteristics of the
    Scala collection API can result in tangible performance wins with small changes
    to your implementation. Recall that when `QueueOrderBook` was introduced, it was
    noted that its implementation is identical to `ListOrderBook`, the module changes
    to replace `List` operations with analogous `Queue` operations. This is a comparatively
    simple change for the performance boost shown previously.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: You are excited to see the performance win to handle limit orders with `QueueOrderBook`,
    but you are left wondering about what can be done about cancelation performance.
    It remains unsettling to you that `QueueOrderBook` retains the same cancelation
    performance. In particular, because of the recent market volatility that exposed
    order book cancelation performance's weakness that caused MVT to trade unprofitably.
    Lazy evaluation was a big performance win to handle limit orders. Can this principle
    also be applied to cancel requests?
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: Improved cancellation performance through lazy evaluation
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Queue provides high-performance `enqueue` and `dequeue` operations using the
    additional state, the second `List`, to defer and to batch expensive operations.
    This principle can be applied to the order book. When canceling an order, there
    are two expensive operations:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Identifying the price level containing the order-to-be-canceled
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traversing a `Queue` or `List` to remove the canceled order
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Focusing on the second operation, the motivating question is, "how can the
    order book defer the cost of linear traversal to modify internal state?" To answer
    this question, it is often helpful to consider the strengths of your implementation.
    With either order book implementation, we know there is excellent execution performance.
    One strategy that takes advantage of this insight is to defer cancellation until
    order execution occurs. The approach is to use additional state to maintain the
    intent to cancel without removing the order from order book state until it is
    performant to do so. This approach could look like the following:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `LazyCancelOrderBook` class adds additional state in the form of a `scala.collection.immutable.Set`
    to manage the IDs of canceled requests that have not been reflected into the the
    state of `bids` and `offers`. Before diving into how `pendingCancelIds` is used,
    let's investigate the Scala implementation of `Set`.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Set
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Scala''s implementation of `Set` is neither an ADT, such as `List`, nor a concrete
    implementation, such as `TreeMap`. Instead, it is a trait, as shown in this snippet
    of its definition:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The reason the standard library defines it is as a trait is to support specific
    implementations depending upon the element count. The `Set` companion object defines
    five implementations for sizes zero to four. Each implementation contains a fixed
    number of elements, as shown in `Set3`, as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'When the number of elements is small, the runtime performance is faster with
    hand-rolled `Set` implementations. With this technique, additions and removals
    point to the next or previous hand-rolled implementation. For example, consider `+`
    and `-` from `Set3`:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'After `Set4`, the standard library uses an implementation named `HashSet`.
    This is visible when adding an element to `Set4`:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The `HashSet` is analogous to `TreeMap` because it is backed by an efficient
    data structure to manage internal state. For `HashSet`, the backing data structure
    is a hash trie. The hash trie provides amortized constant time performance for
    additions, removals, and contains operations as per the Scala collections performance
    overview ([http://docs.scala-lang.org/overviews/collections/performance-characteristics.html](http://docs.scala-lang.org/overviews/collections/performance-characteristics.html)).
    If you want to dig deeper into how a hash trie works, the Scala hash trie overview
    ([http://docs.scala-lang.org/overviews/collections/concrete-immutable-collection-classes.html#hash-tries](http://docs.scala-lang.org/overviews/collections/concrete-immutable-collection-classes.html#hash-tries))
    is a good starting point.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'Returning to the `LazyCancelOrderBook`, we now know that common set operations
    with `pendingCancelIds` are completed in amortized constant time. Provided that
    we focus on additions and removals, and contains operations, this suggests there
    will be minimal overhead as the size of the set increases. We can use `pendingCancelIds`
    to represent the intent to remove an order from the order book without paying
    the cost of performing the removal. This simplifies the handling of a cancel order
    to be a constant time addition to `pendingCancelIds`:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The implementation of `handleCancelOrder` becomes trivial because the work
    to remove the order from the book is deferred. While this is a performance win,
    this implementation suffers from a serious deficiency. This implementation is
    no longer able to identify order IDs that are absent from the order book, which
    result in `OrderCancelRejected`. One way to account for this requirement is to
    maintain an additional `Set` containing order IDs actively resting on the book.
    Now, the `LazyCancelOrderBook` state looks like the following:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'With this definition, we can rewrite `handleCancelOrder` to account for nonexistent
    order IDs:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: This implementation involves three amortized, constant time operations when
    the order ID exists in the book. First, there is an operation to identify whether
    or not the order ID exists in the order book. Then, the provided order ID is removed
    from the active ID set and added to the pending cancel set. Previously, this scenario
    required two linear runtime operations. The degenerate scenario of handling a
    nonexistent order ID now shrinks to a single amortized constant time operation.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Before celebrating performance wins, bear in mind that we still need to remove
    canceled orders from the book. To reduce the cost of cancelations, two potentially
    large sets were added to the order book, which increases the size of the memory
    footprint and garbage collection pressure. Additionally, benchmarking is needed
    to prove that theoretical performance improvements translate to real-world performance.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'To complete `LazyCancelOrderBook` implementation, we need to account for `activeIds`
    when handling a limit order and `pendingCancelIds` when generating an execution.
    As you may recall, handling a limit order involved two scenarios:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Adding a resting limit order
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Crossing the book to generate an execution
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is a partially implemented snippet that prepares us to handle these two
    scenarios for a `BuyLimitOrder`:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'To support resting buy orders, the provided buy order must be enqueued and
    additionally, the buy order ID must be added to the `activeOrderIds` set:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The logic to add a resting limit order is shown in the preceding code and extracted
    into a method named `restLimitOrder`. This logic resembles the analogous scenario
    for `ListOrderBook` with the added amortized constant time active order ID addition
    operation. This change is straightforward and adds little processing time overhead.
    Finally, we consider the more complicated order crossing scenario. This scenario
    is analogous to `Queue.dequeue` in that this implementation pays the cost of the
    deferred action. The first dilemma to solve is identifying which order can be
    executed and which orders must be removed because they are canceled. `findActiveOrder`
    supplies this functionality and is shown with the assumption that `orderBook`
    is lexically in scope, as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '`findActiveOrder` recursively inspects a sell price level until an executable
    order is found or the price level is empty. In addition to optionally resolving
    a sell order that can be executed, the method returns the remaining price level.
    These order IDs have been canceled and must be removed from `pendingCancelIds`.
    Here, we see the bulk of the canceled work deferred when the cancel request was
    handled. Execution is now amortized to be a constant time operation when executions
    occur repeatedly without a cancelation in-between. The worst case scenario is
    a linear runtime that is proportional to the number of canceled orders in the
    price level. Let''s look at how `findActiveOrder` is used to update the state
    of the order book:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Order crossing implementation is now arguably more complicated than in `ListOrderBook`
    or `QueueOrderBook` due to the work to remove canceled orders and to remove the
    removed order IDs from `pendingCancelIds`. In all three pattern match statements,
    the set of returned order IDs returned as the final tuple member is removed from
    `pendingCancelIds` to indicate that the order is now removed from the book. The
    first two pattern match statements handle the distinction between finding an active
    order with one or more remaining orders in the price level and finding an active
    order with zero remaining orders in the price level. In the latter scenario, the
    price level is removed from the book. The third pattern match statement accounts
    for the scenario where an active order is not found. If an active order is not
    found because all orders were pending cancelation, then, by definition, the entire
    price level was searched, and it is, therefore, now empty.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking LazyCancelOrderBook
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As a rigorous performance engineer, you realize that although your code compiles
    and your tests pass, your work is not yet complete. You begin pondering how to
    benchmark `LazyCancelOrderBook` to determine whether or not your changes have
    improved real-world performance. Your first idea is to test cancelation in isolation
    to confirm that this operation has indeed been optimized. To do this, you rework `CancelBenchmarks`,
    which was introduced in [Chapter 2](ch02.html "Chapter 2.  Measuring Performance
    on the JVM"), *Measuring Performance on the JVM*, to work with `QueueOrderBook`
    and `LazyCancelOrderBook`. This benchmark sweeps different price level sizes canceling
    the first order, the last order, and a nonexistent order. We omit the source code
    because it is identical to the previous implementation and instead consider the
    results. These results were produced by running the following:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The benchmark provides us with the following results:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '| **Benchmark** | **Enqueued order count** | **Throughput (ops per second)**
    | **Error as percentage of throughput** |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
- en: '| `eagerCancelFirstOrderInLine` | 1 | 6,912,696.09 | ± 0.44 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
- en: '| `lazyCancelFirstOrderInLine` | 1 | 25,676,031.5 | ± 0.22 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
- en: '| `eagerCancelFirstOrderInLine` | 10 | 2,332,046.09 | ± 0.96 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
- en: '| `lazyCancelFirstOrderInLine` | 10 | 12,656,750.43 | ± 0.31 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
- en: '| `eagerCancelFirstOrderInLine` | 1 | 5,641,784.63 | ± 0.49 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
- en: '| `lazyCancelFirstOrderInLine` | 1 | 25,619,665.34 | ± 0.48 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
- en: '| `eagerCancelFirstOrderInLine` | 10 | 1,788,885.62 | ± 0.39 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
- en: '| `lazyCancelFirstOrderInLine` | 10 | 13,269,215.32 | ± 0.30 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
- en: '| `eagerCancelFirstOrderInLine` | 1 | 9,351,630.96 | ± 0.19 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
- en: '| `lazyCancelFirstOrderInLine` | 1 | 31,742,147.67 | ± 0.65 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
- en: '| `eagerCancelFirstOrderInLine` | 10 | 6,897,164.11 | ± 0.25 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
- en: '| `lazyCancelFirstOrderInLine` | 10 | 24,102,925.78 | ± 0.24 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
- en: This test demonstrates that `LazyCancelOrderBook` consistently outperforms `QueueOrderBook`
    when canceling the first order, the last order, and a nonexistent order across
    order queue sizes of one and ten. This is exactly as expected because `LazyCancelOrderBook`
    defers the most expensive work until an order is executed. We see constant performance
    independent of the position of the order-to-be-canceled, which is further proof
    that the removal work is deferred. Also as expected, we see that canceling a nonexistent
    order results in improved performance because a linear traversal is no longer
    required to ascertain the absence of an order. However, we notice the performance
    hit as the enqueued order count increases from one to ten for `LazyCancelOrderBook`.
    We can hypothesize that the nearly 50% throughput reduction is due to the overhead
    of managing the state of active and pending cancel order IDs.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 'This result is a promising sign that your changes are indeed improving the
    real-world performance. As the new implementation passed the initial litmus test,
    you think about how to representatively simulate a combination of executions and
    cancelations. You decide to focus on creating a microbenchmark that combines executions
    and cancelations to exercise `LazyCancelOrderBook` in scenarios that more closely
    resemble production. You think back to a recent lunch conversation you had with
    Dave about market trading flows and recall that he said it is common to see about
    two cancelations per execution. Running with this idea, you create a benchmark
    that interleaves trades and cancelations. For both order book implementations,
    you want to test performance when during the following scenarios:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Two trades per cancelation
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One trade per cancelation
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two cancelations per trade
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These three scenarios will help reveal shortcomings in `LazyCancelOrderBook`
    by focusing on production-like order book activities. The benchmark requires initializing
    each order book with a set of resting orders to be canceled or executed against.
    The following snippet demonstrates how to initialize the order books in a JMH
    test:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Before each trial, both order books will be filled with `maxOrderCount` (defined
    to be 30) resting bids. As there are three scenarios to test and two order books,
    there are six benchmarks defined for this test. Each set of three scenarios is
    the same per order book implementation. To avoid duplication, the following snippet
    shows the three benchmarks implemented for `LazyCancelOrderBook`:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'These benchmarks follow the convention of denoting the cancelation frequency
    ("C") first and the trade frequency ("T") second. For example, the final benchmark
    implements the scenario that represents one cancelation for every two trades.
    The commands are defined as values out-of-scope to avoid generating garbage during
    benchmark invocation. The benchmark invocation looks like the following:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'This invocation produces the following results:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '| **Benchmark** | **Throughput (ops per second)** | **Error as percentage of
    throughput** |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
- en: '| `eagerOneToTwoCT` | 797,339.08 | ± 2.63 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
- en: '| `lazyOneToTwoCT` | 1,123,157.94 | ± 1.26 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
- en: '| `eagerOneToOneCT` | 854,635.26 | ± 2.48 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
- en: '| `lazyOneToOneCT` | 1,469,338.46 | ± 1.85 |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
- en: '| `eagerTwoToOneCT` | 497,368.11 | ± 0.72 |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
- en: '| `lazyTwoToOneCT` | 1,208,671.60 | ± 1.69 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
- en: 'Across the board, `LazyCancelOrderBook` outperforms `QueueOrderBook`. The relative
    difference between lazy and eager performance shows an interesting relationship.
    The following table captures the relative performance difference:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '| **Benchmark** | **LazyCancelOrderBook percentage performance improvement**
    |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
- en: '| `OneToTwoCT` | 141.00% |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
- en: '| `OneToOneCT` | 172.00% |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
- en: '| `TwoToOneCT` | 243.00% |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
- en: Studying the preceding table, we observe that `LazyCancelOrderBook` shows the
    greatest performance win when there are two cancelations per trade. This result
    demonstrates the benefit of deferring the cost of processing a cancelation request.
    The next trend that we see is that as the frequency of trades increases and the
    frequency of cancelations decreases, `QueueOrderBook` performance improves relative
    to `LazyCancelOrderBook`. This result makes sense because `LazyCancelOrderBook`
    incurs extra costs when performing a trade. In addition to searching for canceled
    orders, `LazyCancelOrderBook` must update `activeIds`. The `QueueOrderBook` avoids
    these costs, but we see the overwhelming cost of cancelation processing continues
    to overshadow `QueueOrderBook` performance. Summarizing these results, we have
    more confidence that `LazyCancelOrderBook` is a stand-in replacement for `QueueOrderBook`.
    In scenarios involving heavy volumes of cancelations, it appears to be a clear
    winner, and in other scenarios, it appears to maintain parity with `QueueOrderBook`.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Lessons learned
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we leveraged Scala collections, in conjunction with the judicious
    use of lazy evaluation, to improve the performance of a critical component in
    MVT's infrastructure. By working through several order book implementations, you
    learned first-hand how a well-suited data structure can improve performance while
    a less optimal choice can derail performance. This exercise also exposed you to
    how Scala implements several of its collections, which you can now use to your
    advantage when working on a performance problem.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '`LazyCancelOrderBook` illustrates how valuable deferred evaluation can be in
    a performance-sensitive environment. When faced with a performance challenge,
    ask yourself the following questions to see whether it is possible to defer work
    (CPU work, not your actual work!). The following table lists each question and
    how it was answered with the order book:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '| **Question** | **Application to order book example** |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
- en: '| How can I decompose into smaller discrete chunks? | The act of canceling
    was decomposed into identifying the event that was sent to the requester and removing
    the canceled order from the book state. |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
- en: '| Why am I performing all of these steps now? | Originally, order removal happened
    eagerly because it was the most logical way to model the process. |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
- en: '| Can I change any constraints to allow me to model the problem differently?
    | Ideally, we would have liked to remove the constraint requiring rejection of
    nonexistent orders. Unfortunately, this was out of our control. |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
- en: '| What operations in my system are most performant? | Executing an order and
    resting an order on the book are the most performant operations. We leveraged
    fast execution time to perform removals of canceled orders from the book. |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
- en: Like any approach, deferred evaluation is not a panacea. Diligent benchmarking
    and profiling are necessary to validate the benefit delivered by the change. Arguably
    the implementation of `LazyCancelOrderBook` is more complicated than `QueueOrderBook`,
    which will increase the cost to maintain the system. In addition to making implementation
    more complicated, it is now more difficult to reason about runtime performance
    due to the variable cost of order execution. For the scenarios that we tested, `LazyCancelOrderBook`
    remained at parity with or better than `QueueOrderBook`. However, we only exercised
    a few of the many possible scenarios, and we did so with only a single price level
    in the order book. In a real-world environment, additional benchmarking and profiling
    are needed to build enough confidence that this new implementation delivers better
    performance.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Historical data analysis
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have done great work with the order book, and we hope, have learned valuable
    skills along the way! It is now time to explore a new facet of MVT's activities.
    A group of expert traders and data scientists are constantly studying historical
    market data to design performant trading strategies. Until now, the company has
    not had the luxury of allocating technical resources to this team. As a result,
    this group has been using clunky, unreliable, and under-performing tools to analyze
    market data and build elaborate trading strategies. With a performant order book,
    the top priority is to focus on improving the strategies implemented by the company.
    Your new best friend, Dave, has explicitly asked for you to join the team and
    help them modernize their infrastructure.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Lagged time series returns
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The main tool used by the team is a simple program designed to compute lagged
    time series returns from historical trade execution data. So far, this tool has
    been a big disappointment. Not only does it return mostly invalid results, it
    is also slow and fragile. Before diving into the code, Dave gives you a short
    presentation of the business rules involved. Return time series are derived from
    midpoint time series. A midpoint is calculated on each minute, and it is based
    on the bid and ask prices of each trade execution. Consider the following table
    as a simple example:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '| **Execution time** | **Bid price** | **Ask price** | **Midpoint** |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
- en: '| 01/29/16 07:45 | 2.3 | 2.5 | 2.55 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
- en: '| 01/29/16 07:46 | 2.1 | 2.4 | 2.25 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
- en: '| 01/29/16 07:47 | 2.9 | 3.4 | 3.15 |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
- en: '| 01/29/16 07:48 | 3.2 | 3.4 | 3.3 |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
- en: '| 01/29/16 07:49 | 3.1 | 3.3 | 3.2 |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
- en: The formula to calculate a midpoint is *(bid_price + ask_price) / 2*. For example,
    the midpoint at 01/29/16 07:47 is *(2.9 + 3.4) / 2*, that is, 3.15.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the real world, a midpoint would be weighed by the volume of the transaction,
    and the time series would use a more fine-grained time unit, such as seconds or
    even milliseconds. To keep the example simple, we disregard the volume dimension
    by assuming a volume of 1 for all executions. We also focus on calculating one
    data point per minute instead of a more granular time series that would use seconds
    or even milliseconds.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: 'A series of midpoints is used to compute a series of returns. A series of returns
    is defined for a certain rollup value in minutes. To calculate the three minute
    return at time t[3], the formula is: (midpoint_at_t[3] - midpoint_at_t[0]) / midpoint_at_t[0].
    We also multiply the result by 100 to use percentages. If we use the previous
    midpoint series to calculate a three minute return series, we obtain the following
    table:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '| **Time** | **Midpoint** | **3 minute return** |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
- en: '| 01/29/16 07:45 | 2.55 | N/A |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
- en: '| 01/29/16 07:46 | 2.25 | N/A |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
- en: '| 01/29/16 07:47 | 3.15 | N/A |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
- en: '| 01/29/16 07:48 | 3.3 | 22.73 |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
- en: '| 01/29/16 07:49 | 3.2 | 29.69 |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
- en: Note that the first three midpoints do not have a corresponding three minute
    return as there is no midpoint that is old enough to be used.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: 'You are now familiar with the domain and can have a look at the existing code.
    Starting with this model:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Everything looks straightforward. Note that prices, midpoints, and returns are
    represented as `Int` and `Double`. We assume that our system is able to normalize
    the prices as integers instead of decimals. This simplifies our code, and also
    improves the performance of the program since we use primitive `Double` instead
    of, for example, `BigDecimal` instances. `TimestampMinutes` is similar to the
    more commonly used Epoch timestamp, but only down to the minute (see [https://en.wikipedia.org/wiki/Unix_time](https://en.wikipedia.org/wiki/Unix_time)).
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'After studying the model, we look at the existing implementation of the `computeReturnsWithList`
    method:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This method assumes that the list of midpoint received as input is already
    sorted by execution time. This randomly accesses various indices of the list to
    read the midpoints that are required to compute each return. To compute the second
    return value (index 1 in the returned list) with a rollup value of three minutes,
    we access elements at index 4 and 1 in the input list. The following diagram provides
    a visual reference for how returns are computed:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '![Lagged time series returns](img/image_04_003.jpg)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
- en: 'You have been warned that this method is slow, but it is also incorrect. Dave
    has verified many times that it returns incorrect results. Before tackling the
    performance issue, you have to handle the correctness problem. Optimizing an incorrect
    approach would not be a good use of your time and, therefore, of the company''s
    money! Rapidly, you realize that this method puts too much trust in the data that
    it is fed. For this algorithm to work, the input list of midpoints has to do the
    following:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: This has to be properly sorted by execution time, from the oldest to the newest
    execution
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This has to have no more than one midpoint per minute
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This has to not contain any minutes without a midpoint, that is, it has no missing
    data points
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You bring this up to Dave to better understand how the midpoint series is generated.
    He explains that it is loaded from sequential logs that are recorded by the order
    book. It is certain that the list is sorted by execution time. Also, he assures
    you that considering the large volume of trades handled by the order book, it
    is impossible to have a minute without a single execution. However, he acknowledges
    that it is more than likely that more than one midpoint is computed for the same
    execution time. It looks like you have found the problem causing invalid returns.
    Fixing it should not be too complicated, and you think that it is now time to
    reflect on the performance issue.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: 'We spent time studying the structure of a singly-linked list in the previous
    section. You know that it is optimized for operations involving the head and the
    tail of the list. On the contrary, randomly accessing an element by its index
    is an expensive operation requiring linear time. To improve midpoint execution
    performance, we turn to a data structure with improved random access performance:
    `Vector`.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Vector
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To improve the performance of our system, we should reconsider the data structure
    that stores `Midpoint` values. A good option is to replace `List` with `Vector`,
    another Scala collection provided by the standard library. The `Vector` is an
    efficient collection that provides effectively constant time random access. The
    cost of random access operations depends on various assumptions, such as, the
    maximum length of the `Vector`. The `Vector` is implemented as an ordered tree
    data structure called a trie. In a trie, the keys are the indices of the values
    stored in the `Vector` (to learn more about tries and their use cases, see [https://en.wikipedia.org/wiki/Trie](https://en.wikipedia.org/wiki/Trie)).
    As `Vector` implements the `Seq` trait, just like `List`, modifying the existing
    method is straightforward:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Changing the type of the collection is enough to switch to a more performant
    implementation. To make sure that we actually improved the performance, we devise
    a simple benchmark that is designed to use a few hours of historical trade executions
    and measure the throughput of each implementation. The results are as follows:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '| **Benchmark** | **Return rollup in minutes** | **Throughput (ops per second)**
    | **Error as percentage of throughput** |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
- en: '| `computeReturnsWithList` | 10 | 534.12 | ± 1.69 |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
- en: '| `computeReturnsWithVector` | 10 | 49,016.77 | ± 0.98 |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
- en: '| `computeReturnsWithList` | 60 | 621.28 | ± 0.64 |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
- en: '| `computeReturnsWithVector` | 60 | 51,666.50 | ± 1.64 |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
- en: '| `computeReturnsWithList` | 120 | 657.44 | ± 1.07 |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
- en: '| `computeReturnsWithVector` | 120 | 43,297.88 | ± 0.99 |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
- en: Not only does `Vector` yield significantly better performance, it delivers the
    same throughput regardless of the size of the rollup. As a general rule, it is
    better to use `Vector` as a default implementation for immutable indexed sequences. Vector
    effectively provides constant time complexity not only for element random access
    but also for head and tail operations, as well as to append and prepend elements
    to an existing `Vector`.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: The implementation of `Vector` is a tree structure of parity 32\. Each node
    is implemented as an array of size 32, and it can store either up to 32 references
    to child nodes or up to 32 values. This 32-ary tree structure explains why the
    complexity of `Vector` is "effectively constant" instead of "constant". The real
    complexity of the implementation is log(32, N), where N is the size of the vector.
    This is considered close enough to actual constant time. This collection is a
    good choice to store very large sequences because the memory is allocated in chunks
    of 32 elements. These chunks are not preallocated for all levels of the tree,
    but only allocated as needed.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: 'Until Scala 2.10, one downside of `Vector` as compared to `List` was the lack
    of pattern matching support. This is now fixed and you can pattern-match an instance
    of `Vector` in the same way you pattern match a `List`. Consider this short example
    of a method pattern matching a `Vector` to access and return its third element
    or return `None` if it contains fewer than three elements:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Invoking this method in the REPL demonstrates that pattern matching can be
    applied, as follows:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Data clean up
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The return algorithm is now blazingly fast. That is, blazingly fast to return
    incorrect results! Remember that we still have to handle some edge cases and clean
    up the input data. Our algorithm only works if there is exactly one midpoint per
    minute, and Dave informed us that we are likely to see more than one midpoint
    computed for the same minute.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: 'To handle this problem, we create a dedicated `MidpointSeries` module and make
    sure that an instance of `MidpointSeries`, wrapping a series of `Midpoint` instances,
    is properly created without duplicates:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Our `removeDuplicates` method uses a tail recursive method (Refer to [Chapter
    3](ch03.html "Chapter 3. Unleashing Scala Performance"), *Unleashing Scala Performance*).
    This groups all the midpoints with the same execution time, calculates the average
    value of these data points, and builds a new series with these average values.
    Our module provides a `fromExecution` factory method to build an instance of `MidpointSeries`
    from a `Vector` of `Execution`. This factory method calls `removeDuplicates` to
    clean up the data.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: 'To improve our module, we add our previous `computeReturns` method to the `MidpointSeries`
    class. That way, once constructed, an instance of `MidpointSeries` can be used
    to compute any return series:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: This is the same code that we previously wrote, but this time, we are confident
    that `points` does not contain duplicates. Note that the constructor is marked `private`,
    so the only way to instantiate an instance of `MidpointSeries` is via our factory
    method. This guarantees that it is impossible to create an instance of `MidpointSeries`
    with a "dirty" `Vector`. You release this new version of the program, wish good
    luck to Dave and his team, and leave for a well deserved lunch break.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: 'As you return, you are surprised to find Vanessa, one of the data scientists,
    waiting at your desk. "The return series code still doesn''t work", she says.
    The team was so excited to finally be given a working algorithm that they decided
    to skip lunch to play with it. Unfortunately, they discovered some inconsistencies
    with the results. You try to collect as much data as possible, and spend an hour
    looking at the invalid results that Vanessa is talking about. You noticed that
    they all involved trade executions for two specific symbols: FOO and BAR. A surprisingly
    small amount of trades is recorded for these symbols, and it is not unusual for
    several minutes to elapse between trade executions. You questioned Dave about
    these symbols. He explains that these are thinly traded tickers, and it is expected
    to see a lower trading volume for them. The problem is now clear to you. The midpoint
    series recorded for these symbols do not fulfill one of the prerequisite of your
    algorithm: at least one execution per minute. You refrain from reminding Dave
    that he assured you this situation was impossible and start working on a fix.
    The trader is always right!'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: 'You are not confident that you can rework the algorithm to make it more robust
    while preserving the current throughput. A better option would be to find a way
    to clean up the data to generate the missing data points. You seek advice from
    Vanessa. She explains that it would not disturb the trading algorithm to perform
    a linear extrapolation of the missing data points, based on the surrounding existing
    points. You write a short method to extrapolate a midpoint at a certain time using
    the previous and following points (respectively, `a` and `b` in the following
    snippet):'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'With this method, we can write a clean up method that follows the model of
    the previously mentioned `removeDuplicates` function to preprocess the data:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Our internal tail-recursive method handles the case where two points are already
    consecutive, and the case where a point is missing. In the latter case, we create
    a new point with our `extrapolate` method and insert it in the result `Vector`.
    Note that we use this new point to extrapolate consecutive missing points. We
    update our factory method to perform this additional clean up after removing possible
    duplicates:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: We now have the assurance that our input data is clean and ready to be used
    by our return series algorithm.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: Handling multiple return series
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The team is impressed by the improvements that you implemented, and by how quickly
    you were able to fix the existing code. They mention a project they have had in
    mind for a while without knowing how to approach it. A couple of weeks ago, Vanessa
    designed a machine learning algorithm to evaluate trading strategies over several
    tickers, based on their return series. This algorithm requires that all the return
    series involved contain the same amount of data points. Your previous changes
    already took care of this requirement. However, another condition is that the
    return values must be normalized or scaled. A feature is a machine learning term
    for an individual measurable property. In our example, each return data point
    is a feature. Feature scaling is used to standardize the range of possible values
    to ensure that broad ranges of values do not distort a learning algorithm. Vanessa
    explains that scaling features will help her algorithm to deliver better results.
    Our program will handle a set of return series, compute a scaling vector, and
    calculate a new set of normalized return series.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: Array
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For this system, we consider switching from `Vector` to `Array`. `Array` is
    a mutable, indexed collection of values. It provides real constant complexity
    for random access, as opposed to `Vector`, which implements this operation in
    effectively constant time. However, contrary to `Vector`,  `Array` is allocated
    once as a single and contiguous chunk of memory. Furthermore, it does not permit
    append and prepend operations. A Scala `Array` is implemented with a Java `Array`,
    which is memory optimized. A Scala `Array` is more user-friendly than the native
    Java `Array`. Most methods that are available on other Scala collections are made
    available when using `Array`. Implicit conversions are used to augment `Array`
    with `ArrayOps` and `WrappedArray`. `ArrayOps` is a simple wrapper for `Array`
    to temporarily enrich `Array` with all the operations found in indexed sequences.
    Methods called on `ArrayOps` will yield an `Array`. On the contrary, a conversion
    from `Array` to `WrappedArray` is permanent. Transformer methods called on `WrappedArray`
    yield another `WrappedArray`. We see this in the standard library documentation,
    as follows:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Having decided to use `Array` for our new module, we start working on the code
    to scale the features of each return series:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'A scaling vector is computed for a set of series. The first value of the vector
    is used to scale the first series, the second value for the second series, and
    so on. The scaling value is simply the greatest value in the series. We can now
    write the code to use the scaling vector and compute the normalized version of
    the frame:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We zip each series with its scaling value, and create a new scaled return series.
    We can compare the presented version of the code using `Array` with another, almost
    identical, implementation using `Vector` (this code is omitted here for brevity,
    but it can be found in the source code attached to the book):'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '| **Benchmark** | **Series Size** | **Throughput in operations per second**
    | **Error as percentage of throughput** |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
- en: '| `normalizeWithVector` | 60 | 101,116.50 | ± 0.85 |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
- en: '| `normalizeWithArray` | 60 | 176,260.52 | ± 0.68 |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
- en: '| `normalizeWithVector` | 1,440 | 4,077.74 | ± 0.71 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
- en: '| `normalizeWithArray` | 1,440 | 7,865.85 | ± 1.39 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
- en: '| `normalizeWithVector` | 28,800 | 282.90 | ± 1.06 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
- en: '| `normalizeWithArray` | 28,800 | 270.36 | ± 1.85 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
- en: These results show that `Array` performs better than `Vector` for shorter series.
    As the size of the series increases, their respective performances are on-par.
    We can even see that the throughput is identical for a series containing 20 days
    of data (28,800 minutes). For larger sequences, the locality of `Vector` and its
    memory allocation model alleviate the difference with `Array`.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: 'Our implementation is idiomatic: it uses higher-order functions and immutable
    structures. However, using transform functions, such as `zip` and `map`, creates
    new instances of `Array`. An alternative is to leverage the mutable nature of `Array`
    to limit the amount of garbage generated by our program.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: Looping with the Spire cfor macro
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Scala supports two loop constructs: the `for` loop and the `while` loop. The
    latter, in spite of its good performance characteristics, is usually avoided in
    functional programming. It requires the usage of mutable state and `var` to keep
    track of the looping condition. In this section, we will show you a technique
    to take advantage of `while` loop performance that prevents mutable references
    from leaking into application code.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Spire is a numeric library written for Scala that allows developers to write
    efficient numeric code. Spire leverages patterns, such as, type classes, macros,
    and specialization (remember specialization from [Chapter 3](ch03.html "Chapter 3. Unleashing
    Scala Performance"), *Unleashing Scala Performance*). You can learn more about
    Spire at [https://github.com/non/spire](https://github.com/non/spire).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the macros made available by Spire is `cfor`. Its syntax is inspired
    from the more traditional for loop that is encountered in Java. In the following
    implementation of feature scaling, we use the `cfor` macro to iterate over our
    series and normalize the values:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'This example highlights that `cfor` macros can be nested. The macro is essentially
    syntactic sugar that compiles to a Scala `while` loop. We can examine the following
    generated bytecode to prove this:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We notice the two `goto` statements, instructions `96` and `84`, which are
    used to loop back respectively to the beginning of the outer loop and the inner
    loop (which respectively begin with instructions `11` and `39`). We can run a
    benchmark of this new implementation to confirm the performance gain:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '| **Benchmark** | **Series size** | **Throughput (ops per second)** | **Error
    as percentage of throughput** |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
- en: '| `normalizeWithArray` | 60 | 176,260.52 | ± 0.68 |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
- en: '| `normalizeWithCfor` | 60 | 256,303.49 | ± 1.33 |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
- en: '| `normalizeWithArray` | 1,440 | 7,865.85 | ± 1.39 |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
- en: '| `normalizeWithCfor` | 1,440 | 11,446.47 | ± 0.89 |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
- en: '| `normalizeWithArray` | 28,800 | 270.36 | ± 1.85 |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
- en: '| `normalizeWithCfor` | 28,800 | 463.56 | ± 1.51 |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
- en: The macro, which is compiled to a while loop, is able to deliver better performance.
    Using the `cfor` construct, we are able to retain performance while avoiding the
    introduction of multiple vars. Although this approach sacrifices immutability,
    the scope of mutability is limited and less error-prone than an equivalent implementation
    using an imperative `while` or `for` loop.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored and experimented with various collection implementations.
    We discussed the underlying representation, complexity, and use cases of each
    data structure. We also introduced a third-party library, Spire, to improve the
    performance of our programs. Some of the implementations presented drifted away
    from typical functional programming practices, but we were able to restrict the
    use of mutable state to internal modules, while still exposing functional public
    APIs. We expect that you are eager to learn more, but in the next chapter, we
    will become lazy! In contrast to this chapter, which focused on eager collections,
    we turn our attention to lazy collections in the next chapter.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
