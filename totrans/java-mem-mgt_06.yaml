- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Configuring and Monitoring the Memory Management of the JVM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have looked at the different areas of memory and how it is deallocated,
    but we have yet to look at optimizing the way a **Java Virtual Machine** (**JVM**)
    does this. The approach that the JVM uses to manage memory can be configured in
    different ways.
  prefs: []
  type: TYPE_NORMAL
- en: There is not one obvious way to configure the JVM though. The best configuration
    really depends on the application and the requirements. Getting the best configuration
    will improve the performance of your application and minimize the memory requirements.
    Monitoring performance and memory will help discover problems before users do.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to have a look at how to configure the JVM and
    monitor memory management. Changing the configurations of the JVM is typically
    done by tuning, meaning that you have an idea of where to start, then make small
    adjustments, and carefully measure their impact. Here are the topics that will
    be discussed:'
  prefs: []
  type: TYPE_NORMAL
- en: The basics of JVM tuning for memory management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Obtaining relevant metrics for memory management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling of the Java application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tuning the configurations of the JVM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The code for this chapter can be found on GitHub at [https://github.com/PacktPublishing/B18762_Java-Memory-Management](https://github.com/PacktPublishing/B18762_Java-Memory-Management).
  prefs: []
  type: TYPE_NORMAL
- en: The basics of JVM tuning for memory management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first rule of JVM tuning for performance improvement is probably that it
    should be the last option for improvement. Look at this code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Will JVM tuning help? No, because we’re stuck in an infinite loop, since `i`
    never gets increased. Of course, there are a lot of less obvious examples, but
    when code can be improved and optimized, this must be done first before thinking
    about JVM tuning.
  prefs: []
  type: TYPE_NORMAL
- en: If the hardware can realistically be optimized, this should be done before JVM
    tuning as well. By this, I don’t mean that you should fix a memory leak by just
    adding more memory; of course, that’s not a fix. But when your application accidentally
    gets very successful and things get slow, chances are that you are better off
    upgrading the hardware than diving into JVM tuning to fix this. When all the other
    factors that come into play for performance are optimized, this is when JVM tuning
    can be applied for performance improvement.
  prefs: []
  type: TYPE_NORMAL
- en: When we are tuning the JVM, we are setting parameters. And that’s not it; this
    needs to be carefully monitored. Before changing any settings, we must make sure
    to have a good idea of the metrics of our application. These new settings need
    to be monitored carefully. If the performance improves, you could try to change
    the parameters a bit more; if it gets worse, you should probably change it back
    at least a little to gauge the difference.
  prefs: []
  type: TYPE_NORMAL
- en: It might sound like trial and error at this point, and to some extent it is
    – professionally conducted trial and error, that is. Let’s have a look at the
    relevant metrics to tune the memory management of the JVM.
  prefs: []
  type: TYPE_NORMAL
- en: Obtaining relevant metrics for memory management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are several important metrics for knowing how the memory of an application
    is doing. Understanding the following three important concepts that define the
    performance of the application is the first step here:'
  prefs: []
  type: TYPE_NORMAL
- en: Memory that is functioning well
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normal latency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A normal level of throughput
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s take a look at each one of these.
  prefs: []
  type: TYPE_NORMAL
- en: Well-functioning memory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you have experience with a specific application, you may know its stable
    memory-usage point. There needs to be more memory available than just the stable
    usage point though. Instead, a safe amount of memory needs to be available for
    the Java application, and this reserved memory should not be almost full. Conversely,
    having too much memory allocated for the Java application is also not the way
    to go. This is because the rest of the system will also need some memory for other
    processes, since the operating system is also running.
  prefs: []
  type: TYPE_NORMAL
- en: If you have an idea of the normal memory metrics of your application when it’s
    performing well, this will help you measure the outcome of any adjustments that
    you might be making later.
  prefs: []
  type: TYPE_NORMAL
- en: Normal latency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Latency is also called the responsiveness of the application. An application
    with normal latency responds as expected and required. This can be measured in
    time – for example, the time the application takes to process a certain request
    such as processing an incoming HTTP request.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, measuring latency is not always as easy. If we have a standalone
    Java application, this is somewhat trivial. We know that we are measuring the
    latency of our application. If we are trying to measure the latency of an enterprise
    application, it becomes tricky. We need to make sure we are measuring the latency
    of our application and not network issues, the server side of another application,
    or any layer that we have in our enterprise application landscape. In those cases,
    issues with the latency results are likely not related to the memory management
    of our application.
  prefs: []
  type: TYPE_NORMAL
- en: Level of throughput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Throughput is the amount of work that can be done by the application in a certain
    amount of time. High throughput is typically what you want to aim for, but it
    does require more memory and might affect latency.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling Java applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Profiling is used to make an analysis of the runtime performance of an application.
    This is something that needs to be done carefully, since it usually has an impact
    on the application that is being profiled. It is, therefore, advisable to profile
    the development environment if possible. We are going to have a look at profiling
    with the `jstat` and `jmap` command-line tools, and the **VisualVM** application.
    The first two come with your **Java Development Kit** (**JDK**); the latter used
    to come with it but now it can be downloaded separately.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download VisualVM here: [https://visualvm.github.io/download.xhtml.](https://visualvm.github.io/download.xhtml.)'
  prefs: []
  type: TYPE_NORMAL
- en: There are other profiles out there; some IDEs even have their own profilers
    built in, which work in a similar way.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling with jstat and jmap
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the two command-line utilities, `jstat` and `jmap`, we can analyze and
    profile memory. We are going to explore how to do that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s say we have a simple Java application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This application is not doing a lot of interesting things, just adding a lot
    of `String` objects to our `stringList` static list.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can run this program and see what is going on with the memory. In order
    to do this, we need to compile the program first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command assumes that you are in the same folder as Command Prompt
    or Terminal, since we access the file directly without any folders in front. This
    command compiles the code and stores the result in `ExampleAnalysis.class`. Let’s
    run this file by executing the following command (make sure to be one level above
    the [*Chapter* *6*](B18762_06.xhtml#_idTextAnchor086) directory):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we’ll first need the process ID to analyze our code using `jstat`. We
    can get the process IDs of all Java processes by running the following command
    in the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The command produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Our program can be easily recognized, as it has the name of the class written
    after it. So, our process ID is `35384`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need this process ID to run the `jstat` analysis. This command-line tool
    has several options. We are going to start by running it like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'This will produce the result for our process with an ID of `35384`. The `-gc`
    option is one of the options available to get statistics about the garbage collected
    heap. It makes sure that it shows the behavior of the garbage collected heap.
    There are a few other flags that you could use as well; here are a few examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '`gccapacity`: Show data about the capacities of the generations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gcnew`: Show data about the behavior of the young generations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gcnewcapacity`: Show data about the size of the young generations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gcold`: Show data about the old generation and the Metaspace'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gcoldcapacity`: Show data about the old generation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gcutil`: Show a summary of the garbage collection data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-t` indicates that it should print the timestamp. `1000` means that it will
    show the statistics every 1,000 milliseconds and `10` means that it will show
    10 iterations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output will look as shown in *Figure 6**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Output showing the jstat command with options](img/Figure_6.1_B18762.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – Output showing the jstat command with options
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, it displays many columns. Let us see what these columns mean;
    the exact values aren’t too important for the discussion. We’ll go over them from
    left to right:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Timestamp**: The time since the program started running. You can see that
    it increases with seconds, which makes sense, as we asked for iterations of 1,000
    milliseconds.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**S0C**: The current capacity of the survivor space 0 in KB.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**S1C**: The current capacity of the survivor space 1 in KB.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**S0U**: The part of the survivor space 0 that is being used in KB.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**S1U**: The part of the survivor space 1 that is being used in KB.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**EC**: The current capacity of the Eden space in KB. You can see that the
    capacity scales up when the Eden space gets fuller.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**EU**: The part of the Eden space that is being used in KB. At the seventh
    row, it drops, and the data gets moved to the old space.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**OC**: The current capacity of the old space in KB.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**OU**: The part of the old space that is being used in KB. You can see it
    increase during the program.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MC**: The current capacity of the Metaspace in KB.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MU**: The part of the Metaspace that is being used in KB.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CCSC**: **Compressed Class Space Capacity** in KB.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CCSU**: **Compressed Class Space Utilized** in KB.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**YGC**: The number of young generation garbage collection events that happened.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**YGCT**: The total time of the young generation garbage collection events.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FGC**: The total number of full garbage collection events.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FGCT**: The total time the full garbage collection events took.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CGC**: **Concurrent** **Garbage Collection**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CGCT**: The total time of concurrent garbage collection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GCT**: The total garbage collection time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With the `jmap` command, we can get more insights into the heap memory usage
    of our current process. Here is how to use it (Java 9 and later):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '`jhsdb` is a JDK tool that can attach to a running Java process, perform snapshot
    debugging, and inspect the content of the core dump of a crashed JVM. This outputs
    the current heap configuration and usage. Let’s have a look at how to get a more
    visual result while Java profiling with the help of VisualVM.'
  prefs: []
  type: TYPE_NORMAL
- en: Profiling with VisualVM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are many profilers out there that will give a visual representation of
    memory. One of them is VisualVM. It is a tool that is suitable for getting detailed
    information about the Java applications that are running. VisualVM does not come
    by default with the JDK anymore, so it needs to be installed separately here:
    [https://visualvm.github.io/.](https://visualvm.github.io/.)'
  prefs: []
  type: TYPE_NORMAL
- en: If your IDE supports profiling, you could work with that one too. However, the
    following examples use VisualVM, since it’s a free tool that can be easily downloaded.
    Profiling an application with VisualVM is easy. First, you start VisualVM. You
    will see a screen similar to the one in *Figure 6**.2*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – The startup screen of VisualVM](img/Figure_6.2_B18762.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 – The startup screen of VisualVM
  prefs: []
  type: TYPE_NORMAL
- en: On the screen of *Figure 6**.2*, we can check the applications that are running.
    The **Applications** tab can be found on the top left, positioned vertically.
    Here, we can see the local Java processes that are running, from where we can
    simply select the one that we need. Let’s start our example Java application,
    where we will create a huge list of strings.
  prefs: []
  type: TYPE_NORMAL
- en: In the **Applications** tab, we can see the processes, as shown in *Figure 6**.3*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – An overview of the Java processes](img/Figure_6.3_B18762.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 – An overview of the Java processes
  prefs: []
  type: TYPE_NORMAL
- en: We can now pick the process we want to examine. In this case, we would like
    to analyze the process with the **6450** PID. Once we click on it, we get an overview
    of the process, as shown in *Figure 6**.4*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4 – An overview of the Java process](img/Figure_6.4_B18762.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 – An overview of the Java process
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see a summary of the data in the overview shown in *Figure 6**.4*. We
    see the process that we are analyzing, the JVM and Java version that we are running,
    and the JVM arguments used to start the application. There is also a lot more
    detailed data we can get from VisualVM. At the top, we have several tabs: **Overview**,
    **Monitor**, **Threads**, **Sampler**, and **Profiler**. We have seen the **Overview**
    tab; in *Figure 6**.5*, let’s look at the data under the **Monitor** tab.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5 – Monitoring the Java process using VisualVM](img/Figure_6.5_B18762.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5 – Monitoring the Java process using VisualVM
  prefs: []
  type: TYPE_NORMAL
- en: 'This is where we get some serious details of what is going on in our application.
    We see four graphs. The top-left one shows **CPU usage**, and as you can see,
    we are using quite a bit of CPU for this program. This graph also shows the garbage
    collection activity, which is very low overall. This makes sense, as there is
    not a lot to be garbage-collected anyway. The garbage collection activity combined
    with the memory graph at the top right gives some great insights into how healthy
    our application is in terms of memory. If the garbage collector works really hard
    (as you can see, there is a lot of GC activity in the top-left graph) and the
    memory keeps increasing (the lower line representing **Used heap** in the top-right
    graph), it means that we are having a problem with a memory leak. Basically, if
    there are too frequent GC cycles, then it is an indication that you need to do
    some digging to see whether there is something wrong with GC and memory. After
    doing that, if there are still too frequent GC cycles and memory is also not coming
    down, then it is a red alert and you must investigate. In fact, **OutOfMemoryError:
    GC Overhead limit exceeded** is thrown by the JVM if it is spending more than
    98% of the time on GC and recovering less than 2% of the heap.'
  prefs: []
  type: TYPE_NORMAL
- en: The two bottom graphs show the loaded Java classes (left) and the threads in
    the application (right). We can get more details on threads by moving to the **Threads**
    tab. In *Figure 6**.6*, we see an overview of the threads in our application.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6 – Threads in our application](img/Figure_6.6_B18762.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.6 – Threads in our application
  prefs: []
  type: TYPE_NORMAL
- en: We can see the name of our threads on the far left. The bars indicate what the
    state of our threads is over time – for example, running or waiting. We can then
    see the time they have been running.
  prefs: []
  type: TYPE_NORMAL
- en: In the **Sampler** tab, shown in *Figure 6**.7*, we can see how the CPU or memory
    is doing.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – The Sampler tab in VisualVM](img/Figure_6.7_B18762.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 – The Sampler tab in VisualVM
  prefs: []
  type: TYPE_NORMAL
- en: We are now looking at memory sampling, which shows how many live objects there
    are and how much space is being occupied by a certain class. Here, the `byte`
    array is the biggest one. This makes sense because the value of a string is stored
    in a byte array. You can also filter this overview per thread or have a look at
    how the CPU is performing.
  prefs: []
  type: TYPE_NORMAL
- en: In the last tab, we can see profiling. Profiling and sampling are used for similar
    purposes, but the process is different. Sampling is done by making thread dumps
    and analyzing these thread dumps. Profiling requires adding a bit of logic to
    an application so that it gives a signal when something happens. This affects
    the performance of the application quite a bit. Therefore, this is not something
    you’d want to be doing on applications that are running in production. It can
    give a lot of insights though.
  prefs: []
  type: TYPE_NORMAL
- en: You can see the result of profiling all the classes in *Figure 6**.8*. Here,
    you can see a similar result to what we were getting for the sampling (though
    it had fewer objects being allocated at that point in time). In this case, sampling
    would have worked just as well.
  prefs: []
  type: TYPE_NORMAL
- en: VisualVM is great to get quick, visual insights on what is going on with the
    memory of your application. This is going to be especially useful while tuning
    the JVM and checking the results. In the next section, we are going to do exactly
    that – learn how to adjust the configuration of the JVM and see the impact of
    these adjustments.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – Profiling all the classes](img/Figure_6.8_B18762.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 – Profiling all the classes
  prefs: []
  type: TYPE_NORMAL
- en: Tuning the configurations of the JVM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The settings of JVM can be adjusted. The process of adjusting the settings of
    JVM is called **tuning**. The idea of these adjustments is to boost the performance
    of the JVM. Once again, tuning should not be the first step in improving performance.
    Good code should always come first.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to have a look at the settings that are related to memory management:
    the heap size, Metaspace, and the garbage collector.'
  prefs: []
  type: TYPE_NORMAL
- en: Tuning the heap size and thread stack size
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The heap size can be changed. It is generally best practice to not set the heap
    size to more than half of what is available on the server. This could lead to
    performance issues, as the server will be having other processes running as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'The default size depends on the system. This command will show the defaults
    on a Windows system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This command shows the default output for a macOS system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The output is displayed in bytes. You can see the output for my computer in
    *Figure 6**.9*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9 – Output as seen on the macOS system](img/Figure_6.9_B18762.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.9 – Output as seen on the macOS system
  prefs: []
  type: TYPE_NORMAL
- en: The size of the heap influences garbage collection. This might seem counterintuitive
    at first, but let’s do a little thought experiment here. If we had unlimited heap
    memory, would we need garbage collection? No, right? Why run such an expensive
    process if we don’t need to free up memory anyway?
  prefs: []
  type: TYPE_NORMAL
- en: The smaller the heap, the more we will need the garbage collector active because
    it would need to work harder to have space available, since memory gets filled
    up easier. However, the bigger the heap, the longer one full cycle of garbage
    collection takes. There’s simply more to scan for garbage. A good rule of thumb
    is that you want to have less than 5% of application execution time spent on garbage
    collection.
  prefs: []
  type: TYPE_NORMAL
- en: The actual tuning works differently for different servers. Here, we are going
    to see how to do so using the command line when starting the application. Please
    note that the names of the options that we are setting are the same between different
    servers, but how or where to set them might vary.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we start the Java application, we can work with different options for
    the memory. We can specify a memory pool start size, a maximum memory pool, and
    the thread stack size. Here’s how to set all to 1,024 MB:'
  prefs: []
  type: TYPE_NORMAL
- en: '`-Xms1024m` (initial size heap)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-Xmx1024m` (maximum size heap)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-Xss1024m` (thread stack size)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you want to set it to a different size, choose a different size and just
    adjust the option accordingly. You can use the following command to start a Java
    application with adjusted memory settings (on a 64-bit system):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This will start our example Java application with an initial heap size of 4
    GB and a maximum of 6 GB.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the way you can bind the total heap size using `–Xmx` and `–Xms`,
    you can bind the young generation size using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`-XX:MaxNewSize=1024m` (maximum new size)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-XX:NewSize=1024m` (minimum new size)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, we are setting the minimum and the maximum size to 1,024 MB. We may run
    out of memory. This will result in `OutOfMemoryError`. Let’s see how to get a
    heap dump when this happens so that we can inspect what went wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Logging low memory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is very helpful to get a **heap dump** when an application ends with an out-of-memory
    error. A heap dump is a snapshot of the objects in the memory of the application.
    In this case, we can inspect the objects in the application that were present
    at the moment we ran out of memory. This way, we can use it to see which object
    is likely to overflow the memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want the JVM to create the heap dump whenever there is an `OutOfMemoryError`
    exception, then you can use the following JVM argument while starting the JVM:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also specify the path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: With this, the heap dumps will be stored in the specified path. There are different
    ways to create a heap dump – for example, `jmap` can also be used to create a
    heap dump of the application, if it didn’t crash because of `OutOfMemoryError`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s see how to configure the Metaspace.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning the Metaspace
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The default behavior of Metaspace is quite peculiar, as it seems to have a
    limit. This is easy to interpret in the wrong way because this limit is not a
    real limit. If it reaches this limit, it will see what it can do in terms of garbage
    collection, and then it expands. Therefore, it is important to set the following
    variables carefully:'
  prefs: []
  type: TYPE_NORMAL
- en: Maximum size, using `-XX:MaxMetaspaceSize=2048m`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Threshold for garbage collection, using `-XX:MetaspaceSize=1024m`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Minimum and maximum free ratio, using the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-``XX:MinMetaspaceFreeRatio=50`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-``XX:MaxMetaspaceFreeRatio=50`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The minimum and maximum free ratios are great for when you are planning to load
    a lot of classes dynamically. By making sure there is enough memory available,
    you can increase the speed to load classes dynamically. This is because the freeing
    up of memory for classes that need to be loaded takes some CPU time. We can skip
    the step that requires assigning additional memory by choosing a large enough
    free ratio and making sure memory is available. In the preceding example, they
    are set to 50%.
  prefs: []
  type: TYPE_NORMAL
- en: Garbage collection tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As you may have realized by now, garbage collection is an expensive process.
    Optimizing it can really help the performance of an application. You cannot trigger
    garbage collection yourself; this is the decision of the JVM. You may have heard
    of the following way to suggest garbage collection to the JVM:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This does not guarantee that garbage collection will take place. So, you cannot
    trigger garbage collection, but you can influence the way the JVM deals with it.
  prefs: []
  type: TYPE_NORMAL
- en: However, before tweaking anything in relation to garbage collection, it is important
    to make sure that you understand what you are doing exactly. For this, you’ll
    need solid knowledge about the garbage collector.
  prefs: []
  type: TYPE_NORMAL
- en: Also, before adjusting anything, you must have a look at memory usage. Make
    sure to know what spaces are filled and when this is happening. A heap that’s
    healthy will look a bit like a saw in VisualVM. It goes up and down, creating
    spikes, resembling the teeth of a saw. It has a certain amount of used memory,
    and then the garbage collection comes around and decreases the used memory to
    a certain base level. It grows again, and then at around the same usage level,
    the garbage collection comes around and decreases it to its base level, and so
    on.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you see the memory growing over time and garbage collection ends at a slightly
    higher base level every time, you probably have a memory leak that needs to be
    dealt with. As we saw in [*Chapter 4*](B18762_04.xhtml#_idTextAnchor057), there
    are several different garbage collector implementations available. When starting
    the JVM, we can also choose which garbage collector we want it to use:'
  prefs: []
  type: TYPE_NORMAL
- en: '`-``XX:+UseSerialGC`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-``XX:-UseParallelGC`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-``XX:+UseConcMarkSweepGC`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-``XX:+G1GC`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-``XX:+UseZGC`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This is not possible for every system, and all these garbage collection choices
    come with their own extra options as well. For example, we can choose the parallel
    garbage collector and specify the number of threads for the garbage collector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This is how to start an application using the parallel garbage collector and
    giving it four threads to work with. The options for all the garbage collectors
    are too elaborate to discuss in detail. Details can be found in the official documentation
    of the Java implementation that you are using. Here is the link to the Oracle
    implementation, although it’s possible that newer versions will have been released
    by the time you are reading this book: [https://docs.oracle.com/javase/9/gctuning/introduction-garbage-collection-tuning.htm.](https://docs.oracle.com/javase/9/gctuning/introduction-garbage-collection-tuning.htm.)'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we saw what to keep in mind when tuning the JVM. We need to
    focus on memory functioning, latency, and throughput.
  prefs: []
  type: TYPE_NORMAL
- en: In order to monitor how our application is doing, we can use profiles. We have
    seen how to use the `jstat` command-line tool that comes with the JDK by default.
    After that, we saw how to use VisualVM to get a better visual representation of
    what is going on.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we saw how we could adjust the heap, Metaspace, and the garbage collector
    of our application. We also saw the effects for our simple example application.
  prefs: []
  type: TYPE_NORMAL
- en: To reiterate, please bear in mind that adjusting the JVM to boost performance
    should always be the last step, and more obvious actions, such as improving code,
    should always be taken first.
  prefs: []
  type: TYPE_NORMAL
- en: Having covered this, you are now ready to look at how to avoid memory leaks
    in the next chapter.
  prefs: []
  type: TYPE_NORMAL
