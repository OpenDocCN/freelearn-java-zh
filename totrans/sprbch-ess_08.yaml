- en: Chapter 8. Scaling with Spring Batch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned about monitoring, accessing the execution
    information and administering the configurations, using listeners, reporting the
    batch job problems, and understanding the Spring Batch Administration features.
    The Spring Batch job execution deals with huge data that changes time-to-time.
    This detailed processing consumes huge infrastructure. It is obvious to expect
    these jobs to perform efficiently and meet the scaling needs with the growing
    size of the organization's data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The batch scaling model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The thread model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallel processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remote chunking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Partitioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The batch scaling model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far we have seen how to handle different types of batch jobs, configurations,
    and executions. As the organization size is growing day-by-day, the data to be
    processed per batch job also gets increased accordingly. It is important to design
    and configure our batch jobs to meet these performance and scaling expectations.
  prefs: []
  type: TYPE_NORMAL
- en: The batch jobs we write with certain business logic, keeping different resources
    interacting in between, cannot be changed every time we see change in data load
    or performance issues. Spring Batch offers rich configuration infrastructure to
    be able to scale jobs without altering them, by just tuning the configuration
    information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scaling the infrastructure can be done in either of the following two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**By increasing the capacity of the system hardware**: In this way of scaling,
    we can replace the existing slow infrastructure with more powerful infrastructure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adding more servers**: In this way of scaling, we can add more processing
    systems of the same capacity in parallel to the existing infrastructure. These
    additional nodes share the work and increase the scaling of the total system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Spring Batch offers the following ways to scale the batch applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Thread model**: This is a multithreaded step with a single process'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parallel processing**: This is a parallel step execution with a single process'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Remote chunking**: This is the remote chunking of a step with multi process'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Partitioning**: This is the partitioning of a step; it can be a single or
    multi process'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The thread model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By default, step execution is a single-thread model. Spring Batch lets us configure
    the step to execute in multiple chunks to let the single step execute in a multithread
    model with the help of `org.springframework.core.task.TaskExecutor`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram depicts the multithread model of a step execution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The thread model](img/3372OS_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following is the sample configuration for the multithread step with `TaskExecutor`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: With the preceding configuration, the `employeePayProcessing` step considers
    the configured reader, processor, and writers for the tasklets and task execution,
    with the help of `org.springframework.core.task.SimpleAsyncTaskExecutor` having
    a thread pool of 20 threads, each executing in parallel with chunks of data being
    processed in each thread.
  prefs: []
  type: TYPE_NORMAL
- en: Just like any other multithread model, the Spring Batch multithread models also
    take into account the resources used by the multiple threads, and whether they
    are thread safe. `ItemReader` is one such process that is not thread safe.
  prefs: []
  type: TYPE_NORMAL
- en: To configure a thread-safe operation, the recommendation is to synchronize the
    `ItemReader` process by synchronizing the read method.
  prefs: []
  type: TYPE_NORMAL
- en: Parallel processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While multithreading allows a single step to be processed in multiple threads
    of chunks, Spring Batch allows us to process multiple steps and flows simultaneously
    with the help of parallel processing. This feature enables the independent steps
    to execute in parallel and ensures a faster processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows the multiple steps under execution in parallel:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Parallel processing](img/3372OS_08_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: With parallel processing, the independent steps need not wait for the other
    steps to complete before execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the sample configuration for the parallel steps in processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding configuration, the `readEmployeeData` and `processEmployeeData`
    steps get executed in parallel with `organizationDataSetup`. By default, the `taskExecutor`
    is `SyncTaskExecutor`; with the preceding configuration we changed it to `SimpleAsyncTaskExecutor`
    to support parallel step processing.
  prefs: []
  type: TYPE_NORMAL
- en: Remote chunking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Remote chunking is the process in which the original step reads the data calls
    from remote process to process and writes or receives the processed data back
    to write on to the system. As the remote chunking deals with the data transmission
    to another system that is remotely located, we should also consider the cost in
    building this infrastructure versus the advantage we are getting in remote processing.
    The actual step (master) executes the read process, and the remote slaves (listeners)
    could be the JMS listeners that execute the process and write steps, or return
    the processed information to the master.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure depicts the steps in remote chunking:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Remote chunking](img/3372OS_08_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The `ChunkProvider` interface returns chunks from `ItemReader`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ChunkProcessor` interface processes the chunks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: To be able to effectively perform the remote interactions, the remote chunking
    process can have the Spring Integration project included to deal with the integration
    of resources.
  prefs: []
  type: TYPE_NORMAL
- en: Partitioning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the remote chunking reads the data at master node and handles the processing
    to another remote system (slave), partitioning executes the entire process (reading,
    processing, and writing) in parallel, by having the multiple systems having the
    entire processing ability. Here, the master step takes care of understanding the
    job and handing over the task to multiple slaves, and slaves have to take care
    of the rest of the tasks (reading, processing, and writing). Essentially, the
    slaves constitute the steps that take care of the read, process, and write in
    their own world.
  prefs: []
  type: TYPE_NORMAL
- en: The advantages of partitioning over remote chunking include the data transmission
    not being there, as the slave system takes care of the read step as well.
  prefs: []
  type: TYPE_NORMAL
- en: '![Partitioning](img/3372OS_08_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Even though the communication sent by the master to the slaves in this pattern
    fails to deliver, batch metadata in the `JobRepository` ensures that each slave
    gets executed only once per job execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Spring Batch partitioning **Service** **Provider Interface** (**SPI**)
    has the following infrastructure for effective partitioning:'
  prefs: []
  type: TYPE_NORMAL
- en: '`PartitionHandler`: This sends `StepExecution` a request to the remote steps.
    It doesn''t have to know how to split or integrate the data, and `TaskExecutorPartitionHandler`
    is the default implementation of `PartitionHandler`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Partitioner`: This generates the step executions for the partitioned steps
    (only for new step executions). `SimplePartitioner` is the default implementation
    of `Partitioner`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`StepExecutionSplitter`: This generates the input execution contexts for the
    partitioned step execution, and `SimpleStepExecutionSplitter` is the default implementation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is the sample partitioned step execution configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The preceding configuration starts its execution with `initialStep` and hands
    over the execution to the partitioned step. The grid size indicates the number
    of different steps to be created.
  prefs: []
  type: TYPE_NORMAL
- en: While the multithread model fits for the basic tuning of chunk processing, parallel
    processing lets us configure independent steps to execute in parallel. Remote
    chunking needs comparatively larger infrastructure and configuration but fits
    for distributed nodes processing. Partitioning helps quickly replicate the batch
    infrastructure and configure the entire process to execute in parallel nodes,
    with a single point of the repository acting as master.
  prefs: []
  type: TYPE_NORMAL
- en: Based on the system requirement and feasibility of the available infrastructure,
    one can choose either of the earlier mentioned scaling strategies for batch job
    execution.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Through this chapter we learned the importance of performance and scaling of
    the batch. We also learned Spring Batch offerings to scale the batch applications.
    In addition, we learned about the details and configurations of a thread model,
    parallel processing, remote chunking, and partitioning techniques. We finished
    this chapter with an understanding of choosing the right strategy to scale the
    batch application with the available infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn in detail about performing different types
    of testing on Spring Batch applications.
  prefs: []
  type: TYPE_NORMAL
