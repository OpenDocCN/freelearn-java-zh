- en: Basics of Akka Streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ll take a closer look at Akka Streams. We will start with
    a basic description of streams in general, and Reactive Streams in particular.
    We'll touch on the concept of back pressure and provide some motivation for you
    to use Akka Streams as a concrete implementation of the Reactive Streams standard.
    We'll reimplement our bakery yet again, this time using streams as a design abstraction.
    This will allow us to examine in detail the basics of Akka Streams, such as flows
    and graphs, error handling, and testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Reactive Streams
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Back pressure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Akka Streams philosophy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Akka Streams essential concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sources and sinks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graphs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Materialization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Failure handling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Installed Scala
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installed SBT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Source code for this chapter is available on GitHub: [https://github.com/PacktPublishing/Learn-Scala-Programming/tree/master/Chapter13](https://github.com/PacktPublishing/Learn-Scala-Programming/tree/master/Chapter13).'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Akka Streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The word *stream* is vastly overloaded in meaning in modern computing. It carries
    many different meanings depending on the context. For instance, in Java, in different
    times streaming meant an abstraction over blocking IO, non-blocking IO, and later,
    a way to express data processing queries.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, a stream in computing is just a flow of data or instructions. Usually,
    the content of a stream is not loaded into memory fully. This possibility to process
    basically unlimited amounts of information on devices with limited memory capacity
    is a motivating factor for the rise of streams, popularity that has been happening
    recently.
  prefs: []
  type: TYPE_NORMAL
- en: The definition of the stream as a flow implies that it should have some source
    and a destination of data elements. In computing, these concepts are naturally
    expressed in the code in a way that on one side of the flow the code emits data
    and on another side other code consumes this data. The emitting side is usually
    called the **producer** and the receiving side is respectively a **consumer**.
    Usually, there will be a portion of data in the memory which was already issued
    by the producer but not yet ingested by the consumer.
  prefs: []
  type: TYPE_NORMAL
- en: 'This aspect of the stream brings up the next idea: it should be possible to
    manipulate data in-flight by code in-between, the same way a water heater is plugged
    in between the inlet and a water tap and *changes* cold water into hot water.
    Interestingly, the presence of a water heater in this scenario is not known to
    the producer or to the consumer. If the scenario is that the water flow increases
    in intensity, we could easily imagine having another heater plugged in or replacing
    the existing one with a more powerful model. The water heater becomes the property
    of the flow in the sense that the quantity of the water received by the consumer
    depends on the amounts emitted by the producer, but the temperature depends on
    properties of the pipe system, or in essence, of the flow.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the basic idea behind using streams: a stream is usually seen as a
    combination of producer, consumer, and transformation steps in between. In a streaming
    scenario, the producer and consumer become less interesting and the main focus
    shifts to the transformation steps in the middle. For the sake of modularity and
    code reuse, defining many tiny transformations is usually considered to be a preferable
    approach.'
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the art of transferring data between the parts of the stream, we
    distinguish between pushing and pulling elements of the stream.
  prefs: []
  type: TYPE_NORMAL
- en: With the push, it is the producer who controls the process. The data is pushed
    to the stream as soon as it becomes available and the rest of the stream is supposed
    to be able to absorb it. Naturally, it is not always possible to consume data
    which is produced at an unpredictable rate. In the case of streaming, it is dealt
    with by dropping data or using buffers. Dropping data is sometimes appropriate
    but more often is undesired. Buffers have limited size and thus can become full
    if data is produced faster than it is consumed for a long period of time. A full
    buffer yet again leads to memory overflow or the need to drop data. Visibly, with
    the push model, a combination of a fast producer and a slow consumer is a problem.
  prefs: []
  type: TYPE_NORMAL
- en: With the pull model, it is the consumer who drives the process. It tries to
    read the data from the stream as soon as it needs it. If there is some data, it
    is taken. If there is no data, the consumer has a choice between waiting for it
    or trying again at a later moment. Usually, both possibilities are less than ideal.
    Waiting for the data is usually done by blocking and polling data, which means
    excessive consumption of resources and delays between the moment the data becomes
    available and its consumption. Evidently, the pull model is not optimal in the
    case of a slow producer and fast consumer.
  prefs: []
  type: TYPE_NORMAL
- en: This dichotomy led to the creation of the dynamic pull-push concept named Reactive
    Streams and an initiative of the same name in 2013 by engineers at Lightbend,
    Netflix, and Pivotal.
  prefs: []
  type: TYPE_NORMAL
- en: Reactive Streams and backpressure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reactive Streams ([http://www.reactive-streams.org](http://www.reactive-streams.org)) is
    an initiative to provide a standard for asynchronous stream processing with non-blocking
    backpressure.
  prefs: []
  type: TYPE_NORMAL
- en: The non-blocking back pressure is a mechanism to deal with deficiencies of both
    pull and push semantics in the streaming environment. It is better explained by
    an example.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a building site with a foreman responsible for timely delivery of building
    materials among other duties. The site can only accommodate as much as 100 tons
    of materials. The foreman can order materials from another company but the orders
    are taken by one of the truck drivers as soon as one is in the company's office
    and not bringing materials to the customer.
  prefs: []
  type: TYPE_NORMAL
- en: The pull behavior for the foreman would be to call a contractor and wait until
    a truck driver is in the office and answers the call (blocking pull) or make calls
    periodically with the hope that this time somebody will pick up the phone (polling).
    In our case, the foreman sends a voice message to the contractor asking for 100
    tons of materials and returns to his daily work instead. This is a non-blocking
    pull.
  prefs: []
  type: TYPE_NORMAL
- en: The contractor accepts the order as soon as they have the capacity to do so.
    They are about to send a couple of trucks with the capacity of 32 tons each but
    realize they cannot send more than 100 tons because the building site won't be
    able to receive such volume. Therefore, only three trucks and 96 tons of materials
    are sent.
  prefs: []
  type: TYPE_NORMAL
- en: After 30 tons of materials are consumed, the foreman realizes that they can
    order more from the contractor to avoid the building site becoming idle later
    if the rest of materials are quickly consumed. They order another 30 tons. But
    the contractor remembers that there are still another 4 tons remaining from the
    previous order so it is safe to send another full truck with 32 tons which can
    fit in the single truck. We reflect the fact that some demand in the first request
    was satisfied later by consecutive delivery and saying that requests are additive.
  prefs: []
  type: TYPE_NORMAL
- en: And this is basically how the backpressure concept of Reactive Streams works.
    It is arguable that in reality the approach would be better reflected by the name
    *forward ease* but probably this name wouldn't take off as *back-pressure* did.
  prefs: []
  type: TYPE_NORMAL
- en: The Reactive Stream specification strives to define a low-level API which can
    be implemented by different libraries in order to achieve interoperability between
    implementation. The standard defines the API and the **Technology Compatibility
    Kit** (**TCK**) which is a standard test suite for the API implementations.
  prefs: []
  type: TYPE_NORMAL
- en: TCK purpose is to help library authors to validate that their implementations
    adhere to the standard.
  prefs: []
  type: TYPE_NORMAL
- en: 'The API contains the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: Publisher
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subscriber
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subscription
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Publisher` represents the source, the `Subscriber` relates to the consumer,
    the Processor is a processing stage of the stream, and the `Subscription` is a
    representation of the back-pressure.
  prefs: []
  type: TYPE_NORMAL
- en: All of the methods defined in the API return `void` which means they are intended
    to be executed without the caller waiting for the result, hence the *async**hronous
    stream processing* in the definition of the Reactive Streams standard.
  prefs: []
  type: TYPE_NORMAL
- en: Reactive Streams is a library standard and defines how libraries are expected
    to communicate with each other in order to be able to interoperate. It is expected
    that libraries will offer different, higher-level APIs to the user, likely reflecting
    some aspects of the implementation details.
  prefs: []
  type: TYPE_NORMAL
- en: Akka Streams is one of such libraries built using Akka actors as the underlying
    technology. It implements the Reactive Streams standard and has a rich, high-level
    API which allows you to describe streams using high-level DSL and also exhibits
    the underlying Akka machinery.
  prefs: []
  type: TYPE_NORMAL
- en: Akka Streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The purpose of Akka Streams ([https://doc.akka.io/docs/akka/2.5.13/stream/stream-introduction.html](https://doc.akka.io/docs/akka/2.5.13/stream/stream-introduction.html))
    is to offer an intuitive and safe way to formulate stream processing setups such
    that we can execute them efficiently and with bounded resource usage.
  prefs: []
  type: TYPE_NORMAL
- en: Akka Streams fully implements a Reactive Stream standard in order to interoperate
    with another compliant Reactive Streams library, but this fact is usually considered
    to be an implementation detail.
  prefs: []
  type: TYPE_NORMAL
- en: The initial motivation for Akka Streams was the fact that all Akka actor systems
    share the same sets of technical problems, which adds accidental complexity and
    needs to be solved for almost every single project separately over and over again.
    For example, Akka does not have any general flow control mechanism, and in order
    to prevent an actor's mailboxes from overflowing, it needs to be implemented as
    a home-grown solution within every application. Another common pain point is the
    at-most-once messaging semantics, which is less than ideal in most cases, but
    also dealt with on an individual basis. Yet another inconvenience Akka is criticized
    for is its untyped nature. The absence of types makes it impossible to check the
    soundness of possible interactions between actors at the compile time.
  prefs: []
  type: TYPE_NORMAL
- en: Akka Streams aim to solve this problem by placing a streaming layer on top of
    the actor system. This layer adheres to the small set of architectural principles
    to provide a consistent user experience. These principles are a comprehensive
    domain model for stream processing and compositionally. The focus of the library
    lies in modular data transformation. In this sense, Reactive Streams are just
    an implementation detail for how data is passed between steps of the flow and
    Akka actors are the implementation detail for individual steps.
  prefs: []
  type: TYPE_NORMAL
- en: The principle of the completeness of the domain model for distributed bounded
    stream processing means that Akka Streams has a rich DSL that allows you to express
    all aspects of the domain, such as single processing and transformation steps
    and their interconnections, streams with complex graph topologies, back-pressure,
    error and failure handling, buffering and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'The modularity principle means that the definition of single transformations,
    multiple transformations connected in specific ways, or even whole graphs must
    be freely shareable. This principle leads to the design decision to make the description
    of the stream separate from the execution of the stream. Therefore, a user of
    Akka Streams has to go over the following three steps to execute a stream:'
  prefs: []
  type: TYPE_NORMAL
- en: Describe the stream in the form of building blocks and connections between them.
    The result of this step is usually called a *blueprint* in Akka documentation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Materialize the blueprint which creates an instance of the flow. The materialization
    is done by providing a materializer which in Akka takes the form of using an actor
    system or an actor context to create actors for each processing stage.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Execute a materialized stream using one of the `run` methods.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In practice, usually the last two steps are combined and the materializer is
    provided as an implicit parameter.
  prefs: []
  type: TYPE_NORMAL
- en: With this theory in mind, let's take a look at what building and executing streams
    with Akka Streams looks like in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Setup and dependency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to make Akka Streams available in our project, we need to put the
    following dependency into the `build.sbt` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the possibility to import related classes in our examples using
    the following import statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: These import statements are assumed to be present in every example later in
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will also need a wrapper which would provide an actor system in order for
    us to be able to create materializers for our streams. The wrapper will need to
    terminate the actor system as soon as stream processing is finished:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now, before we dive into the code, we need some vocabulary to be able to describe
    what we are doing in our examples.
  prefs: []
  type: TYPE_NORMAL
- en: Essential concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's take a look at the vocabulary Akka Streams uses to describe streams and
    their elements.
  prefs: []
  type: TYPE_NORMAL
- en: As described earlier, every stream has producer, consumer, and transformation
    steps. In Akka Streams they are named `Source`, `Sink`, and `Flow` respectively.
  prefs: []
  type: TYPE_NORMAL
- en: More formally, in Akka Streams any building block of a stream is named a **processing
    stage**. A processing stage with a single output is a `Source`, a single input
    is a `Sink` and with one input, and one output is a `Flow`. By connecting a source
    and a sink to the flow we build a *Runnable Graph* which can be executed.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are also special processing stages:'
  prefs: []
  type: TYPE_NORMAL
- en: Fan-in with two or more inputs and one output
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fan-out with one input and two or more outputs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bidiflow with two inputs and two outputs pointing in opposite directions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We made up the following diagram with all processing stages interconnected
    to simplify grasping the concept. The dotted lines represent the backpressure
    we mentioned earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5c4245c1-3382-4c1f-b4ba-2979973eee88.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1\. Different processing stages interconnected in runnable graph
  prefs: []
  type: TYPE_NORMAL
- en: Structure of the example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how the streaming implementation changes the shape of our bakery
    app we''ve built [Chapter 11](87c2e446-3730-49ae-b86b-fc8269678399.xhtml), *An
    Introduction to the Akka and Actor Models*, and [Chapter 12](caabef7a-c854-4b39-b8fb-ac17b8ba6eee.xhtml),
    *Building Reactive Applications with Akka Typed*. To recap, this is the design
    of the bakery represented with actors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d52ca074-5c4e-4cc6-9483-44fc2e9966af.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Actors in this hierarchy had the following responsibilities:'
  prefs: []
  type: TYPE_NORMAL
- en: The **Manager** initiated new baking rounds and performed the transfer of work
    packages between subordinates and supervised them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Boy** was given a shopping list and acquired groceries from the remote
    system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Chef** created and used a number of mixers of limited capacity in order
    to convert given groceries into dough.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Cook** formed a number of raw cookies from the given dough.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Baker** baked raw cookies in the **Oven** of fixed size. It maintained
    an internal queue of raw cookies in case the rest of the bakery was making them
    quicker than the **Oven** was able to bake them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Oven** and **Mixers** represent hardware resources. They convert raw cookies
    into edible cookies and groceries into dough respectively but do so after some
    delay and with possible failures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we have the possibility of defining relationships between participants in
    a more static way, so we will only keep initiating the behavior of the **Manager**
    and organize the work transfer at the flow level by connecting involved transformation
    steps directly together.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what the structure of our bakery will look like, represented in processing
    stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/44f816ea-b937-4c20-bb97-a0d330b85555.png)'
  prefs: []
  type: TYPE_IMG
- en: The hierarchical structure of the actor system has transformed into the flat
    data flow. Obviously, there are no `Mixers` and `Oven` anymore in this diagram.
    What happened to them? Well, we're cheating a bit by hiding the internal details
    of transformation steps here. In reality, some of these steps are composite blocks
    constructed from smaller components. Let's describe how it looks in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Manager** only kept his initiating behavior. This will be represented
    by a timer source which will tick every now and then and push others to bake some
    cookies. The **Boy** can''t work with just the **Manager**''s desire so we need
    the **Manager** to give a proper shopping list to it. Thus we''ll have to convert
    the ticking urge into the **Shopping List** as represented in the next diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/607a425b-dd5f-4dd2-b1e6-27e99fedde2a.png)'
  prefs: []
  type: TYPE_IMG
- en: This composite block has exactly one output and no inputs and therefore it is
    clearly a `Source[ShoppingList]`.
  prefs: []
  type: TYPE_NORMAL
- en: The real type of the source is `Source[+Out, +Mat]` as it is also taken into
    the account the materialization aspect. The materialization is non-essential for
    us for now so we'll talk about simplified pseudo-types as we describe the structure
    of the flow.
  prefs: []
  type: TYPE_NORMAL
- en: The `Boy` and the `Cook` are simple steps; both of them can be seen as a transformation
    of input into the output, and we'll look at the details of this transformation
    in a moment. From this description, we can conclude that the `Boy` is a `Flow[ShoppingList,
    Groceries]` and a `Cook` is just a `Flow[Dough, RawCookies].`
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Chef` is clearly not as simple as his siblings. It needs to create a number
    of **Mixer** corresponding to the amount of groceries, use them in parallel to
    mix the dough, and combine the results together before sending them further. We''ll
    represent this with the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c939d6b8-f579-4a1c-bb76-6e1d6781e2e7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There is more going on in this diagram than we described before. This is because
    we combine the flow from building blocks with a single responsibility and we need
    to do transformations:'
  prefs: []
  type: TYPE_NORMAL
- en: We need to divide incoming groceries into portions suitable for a single mixer;
    this is the **Divide** step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we need to be sure that work is evenly distributed among the mixers to
    avoid the situation where we need to wait for one of the mixers because it got
    multiple work packages. This is where **Balance** comes in play.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The involvement of multiple mixers is obvious.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **Merge** step's responsibility is to be a fan-in block; it merges multiple
    streams of small portions of dough into a single stream of the same pieces.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally we **Combine** small pieces into one big bowl before we give it further
    to process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The kinds of internal sub-flows are as following the **Divide**, **Combine**
    and all of the **Mixer**s are just Flows, the **Balance** is fan-out and the **Merge**
    is fan-in. The resulting type is the `Flow[Groceries, Dough]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Baker is also not as simple as it appears in the previous diagram because
    it hides an oven and the interactions with it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e11fc87c-6ccb-487b-8f62-4cc3c052b5b5.png)'
  prefs: []
  type: TYPE_IMG
- en: The **Oven** in this diagram has one input and one output so this is just a
    `Flow[RawCookies,ReadyCookies]`. The **Baker** has two inputs and two outputs
    and its shape is a `BidiFlow[RawCookies, RawCookies, ReadyCookies, ReadyCookies]`.
  prefs: []
  type: TYPE_NORMAL
- en: The resulting type of combination is `Flow[RawCookies,ReadyCookies]`.
  prefs: []
  type: TYPE_NORMAL
- en: In the example built earlier, with an actor system the **Baker** maintained
    an internal queue of raw cookies as they arrived if the oven was not empty. This
    has a disadvantage that in the case of a really eager `Manager` the baking process
    could be initiated quite often and the raw cookies could arrive at the baker at
    much quicker pace than the oven can possibly bake them. The queue of the raw cookies
    can thus grow indefinitely large until it occupies all available space, and we'll
    need to either throw away raw cookies to free some space or close the bakery because
    there is no place for other actors to work.
  prefs: []
  type: TYPE_NORMAL
- en: In this version of the bakery we decided not to implement any queue but rely
    on the back pressure instead. We would expect the `Oven` to communicate with the
    `Baker` if it can't accept more work. The `Baker` will do the same, all the way
    back to the `Manger`, so that it won't be possible to even express the desire
    to have more cookies baked until there is more oven capacity available. With different
    buffering strategies, it is possible to manage how much work in progress there
    is at the bakery at any moment. For the purpose of the example, we'll set this
    limit low to demonstrate back pressure in action.
  prefs: []
  type: TYPE_NORMAL
- en: The last step of our flow is a `Customer`, which is of type `Sink[ReadyCookies]`.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's switch gears and set in the code the structure we came up with.
  prefs: []
  type: TYPE_NORMAL
- en: Basics of Akka Streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Elements of the Akka Streams flow are usually defined using constructors of
    the appropriate type. We'll implement building blocks which constitute our diagram
    one by one, starting with the simplest and moving on to the increasingly complex
    as we go over them.
  prefs: []
  type: TYPE_NORMAL
- en: Sources and sinks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The simplest component of our flow is possibly the `Consumer`. It is just a
    sink which is supposed to print out information about incoming data. To construct
    it, we''ll use the `Sink` factory, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `Sink` factory offers more than two dozens different constructors to define
    a sink. We're utilizing one of the simplest, which invokes a provided function
    for each element of the stream.
  prefs: []
  type: TYPE_NORMAL
- en: Here we see that the real type of it is the `Sink[ReadyCookies, Future[Done]]`.
    This reflects the type `ReadyCookies` elements and the type the `Sink` is materialized
    to. In this case, it is materialized into `Success` if stream ends by reaching
    its end and to the `Failure` if there is a failure in the stream.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we''ll take a look at the opposite end of the stream and define a source. 
    The `Source` factory similarly provides almost three dozens of different methods
    to create a source. We don''t want to overwhelm our bakery''s team with work so
    we decided to use a timed source of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This represents the first block in our composite `Source` and its type is no-fit
    for our `Boy`, so we need to implement the second block of the diagram, the generator,
    and connect both together. This is more easily done than explained:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We basically just map over the input but ignore it and return a `shoppingList`
    instead. Now our `Source` has a proper type so that we can connect a `Boy` to
    it later.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a subtle aspect of this implementation which we didn''t take into
    the account. We have a predefined interval with the intention that the rest of
    the flow is not overwhelmed with requests. But at the same time, we''re about
    to rely on the back pressure from the `Oven` for the same purpose. This is not
    optimal because if we pick too big an interval, our bakery will be under-utilized
    and if we pick too small an interval, this will be the back pressure which will
    manage the flow. We can simplify our source to the form that will just produce
    shopping lists and put them into the pipeline as soon as there is some downstream
    capacity available:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here, we just repeat the `NotUsed` element (which provides a nice syntax) and
    then replace it with the random shopping list as before. The difference is that
    the manager will generate a shopping list every time there is a demand for that
    without potentially waiting too long because of the timer settings.
  prefs: []
  type: TYPE_NORMAL
- en: Flows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have the source and the sink, let's implement the flow itself. Again,
    we will start with the simplest parts and switch to the more complex as we progress.
  prefs: []
  type: TYPE_NORMAL
- en: The easiest flow building block is surely the `Cook`. It could be implemented
    as a map function called on the preceding flow definition but for composing reasons,
    we'd like to define it separately.
  prefs: []
  type: TYPE_NORMAL
- en: 'The approach of the flow definition is consistent with the previous two—the
    `Flow` constructor is the way to go. The flow is defined in terms of operations
    on the input but the definition itself is decoupled from this input. Again there
    are lots of methods to choose from; for our purposes, we pick the simple `map`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `cook`'s flow is just mapping over the input dough and converting it to
    the output, raw cookies, as it represented by the type annotation.
  prefs: []
  type: TYPE_NORMAL
- en: The Boy is quite similar to the `Cook` in the sense that it is a simple building
    block which transforms its input into the output. There is one caveat though—our
    `Boy` needs to communicate with the remote actor in order to do this.
  prefs: []
  type: TYPE_NORMAL
- en: Akka Streams is built upon Akka and thus offers some possibilities to utilize
    and communicate with actors at different stages; for instance, it is possible
    to use an `ActorRef` as a source or sink. The remoting aspect in this situation
    turns out to be just an implementation and configuration detail because of Akka's
    location transparency.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our use case, the most appropriate way to communicate with a Seller deployed
    in the remote shop system will be an ask pattern. Let''s do this step by step.
    First, we''ll look up a remote actor in order to be able to communicate with it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Given an `ActorSystem`, we look up an actor using an address of the remote system
    and an actor path. We know there should be exactly one actor, therefore we resolve
    one reference. Depending on the result of the lookup it will return either `Success`
    with the reference we need or a `Failure[ActorNotFound]`. The failure will be
    propagated via the error flow and will lead to the termination of the stream because
    we don't define how to handle it. Let's call this the desired behavior because
    without a seller we won't be able to convert a shopping list into groceries.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use a `Future[ActorRef]` to talk to the actor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Here, we not only need an `ActorSystem` but also an `ExecutionContext` in order
    to be able to map over the `Future` we acquire from the `lookupSeller`. We're
    using the actor reference (if there is one) as a parameter to call `Flow.ask`. 
    The type of the `Flow` corresponds to the expected input type and the type of
    the `ask`—to the expected output type.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can use another `Flow` constructor to convert a `Future[Flow]` to the
    `Flow`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The `lazyInitAsync` translates an internal `Flow` of the `Future` into the normal
    `Flow`. This sub-flow has a proper type of input and output and thus we can plug
    it into our flow definition later.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to extend the configuration in the `application.conf` with properties,
    needed for the Akka remoting as described in [Chapter 11](87c2e446-3730-49ae-b86b-fc8269678399.xhtml),
    *An Introduction to the Akka and Actor Models*.
  prefs: []
  type: TYPE_NORMAL
- en: The next composite step we're going to implement is a `Baker`, including its
    constituent `Oven`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Oven` needs to spend some time turning raw cookies into edible cookies
    and we could implement this by introducing a bit of blocking behavior. But doing
    so will affect the rest of the system by needlessly consuming available threads.
    Because of this, we''ll use another feature of Akka Streams, `Flow.delay`, which
    allows us to shift the emission of elements in time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: As we only have one `Oven`, we define a buffer size to be of the initial and
    maximum size of 1\. We also don't want to drop arriving raw cookies or release
    cookies which are not ready yet, therefore we define an overflow strategy to be
    a back pressure.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `bake` method is a trivial conversion once again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, with this `Oven` we can define a `Baker` which we planned to give a type
    of `BidiFlow`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In order to do this, we need to separately define the `inFlow` and `outFlow`
    for both flow directions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `outFlow` is just passing cookies that are ready to the consumer and we
    already know how to do that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The `inFlow` is a bit more involving because we need to regroup incoming raw
    cookies from groups of some random quantity to groups with the size of the oven.
    We''ll do this by defining a sub-source of single cookies and then grouping them
    as desired. Here is the first step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We''re creating a source: the number of single cookies. The regrouping logic
    looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The `flatMapConcat` consumes one source after another and concatenates the results.
    We then group the stream of single cookies to the stream of `List[RawCookie]`
    of `ovenSize`. Lastly, we reduce this list of single cookies into `RawCookie(ovenSize)`
    as `Oven` expects it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can combine a baker''s `BidiFlow` and oven''s Flow into the composite
    Flow by joining them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The `join` method adds a given `Flow` as a final transformation to the stack
    of `BidiFlows`. In our case, the size of the stack is one and the type of the
    resulting flow is `Flow[RawCookies, ReadyCookies, NotUsed]`. The resulting sub-flow
    hides all of the details of regrouping the cookies and waiting for their readiness,
    leaving us with a nice definition.
  prefs: []
  type: TYPE_NORMAL
- en: Graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The final piece of our flow is a `Chef`. It incorporates work management across
    Mixers. Let's implement `Mixers` first.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mixing behavior itself is straightforward but to mimic real hardware we
    include a block for the time of mixing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Because of the mixing behavior, we need to use a special async flow constructor
    to start a separate thread for every mixer. In order to better control how threads
    are assigned, we''ll put into the configuration a definition of the separate pinned
    thread dispatcher which assigns one thread per sub-flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'With this definition in place, we are now able to define the blocking mixing
    behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The `async` constructor takes a buffer size as a parameter and we want our mixers
    not to have any large buffers assigned to them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The work management can be implemented as a separate concept which closely
    resembles one of the recipes from the Akka Streams documentation cookbook—the
    Balancer. It takes a worker `subFlow` and a count of workers and constructs a
    graph with the given number of workers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The `Balance` block is a fan-out flow with several outputs. It distributes stream
    elements evenly between the workers. With `waitForAllDownstreams = false` we specify
    that the distribution can start as soon as at least one of the workers demands
    a job. With `false` we change the behavior to wait for all of the workers to demand
    a job before it will be distributed. The `Merge` is a fan-in block with a specified
    number of inputs. By specifying `eagerComplete = false` we tell it to wait for
    all down streams to complete as compared to completing as soon as one of the workers
    is done.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we construct a graph using `GraphDSL.create()` and provide actual graph
    building logic as a parameter. First, we convert `balanceBlock` and `mergeBlock`
    into Shapes by adding them to the `builder`. Then we connect as many sub-flows
    as needed to the balancer and merge using the `~>` syntax provided by the `import
    GraphDSL.Implicits._`. The `for` comprehension for five workers would be equivalent
    to the following plain definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Having this graph defined, we can specify the rest of the `Balancer` flow using
    another `Flow` constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use it to construct our `Chef` sub-flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Here, again we split `Groceries` into a stream of smaller portions, mix each
    of these portions using a dedicated mixer in parallel, and combine them using
    the same technique we used before with the `Baker` and `Oven`.
  prefs: []
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In `Cook`'s flow, we used two `print` statements in order to see how the `Cook`
    was doing. It's OK for our example but we would be better off with proper logging.
    Let's improve on that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Akka provides a `log` method which takes a logger name as a parameter and can
    be called on any processing stage in the flow. Let''s use it instead of our `print`
    statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Here, we're writing into the log elements of the flow before and after transformation
    and also providing an optional logging configuration in order to specify log levels
    for different types of events.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the effect of these changes we need to extend the `application.conf`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, after starting our example, we''ll see the following entries in the log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: With logging in place, we have finished defining all of the parts of our flow
    and can try to bring them together.
  prefs: []
  type: TYPE_NORMAL
- en: Materialization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we can specify the whole flow for our bakery:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Here, we first construct the full flow by combining sub-flows we defined before.
    Then we convert the flow to runnable graph by attaching the `manager` Source and
    the `consumer` Sink.
  prefs: []
  type: TYPE_NORMAL
- en: We also specify that we want to keep the right materialized value. The left
    materialized value would be the result of the stream, which is `NotUsed` in our
    case because we just writing produced cookies to the console. The right value
    is a future which is completed when the flow has finished running and we want
    to use it to shut down our actor system as soon is it happens.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we run the graph by bringing an `ActorMaterializer` in scope and calling
    the corresponding `run` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our system runs and bakes tasty cookies, but unfortunately, we forgot to take
    an important aspect into account: Mixers in our setup are liable to hardware failure.'
  prefs: []
  type: TYPE_NORMAL
- en: Handling failure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to make the mixing step more realistic we''ll add a couple of exceptions
    and throw them in randomly at the mixing stage. This will simulate hardware failures
    appearing at unpredicted times. The mixer can throw one of the three exceptions
    the same way it did before in the actor-based examples in the previous two chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The realistic `mix` method could look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'There are a couple of different ways the exceptions can be dealt with. The
    most straightforward approach would be to catch them directly in the logic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: In the case of slow rotation, we decide to ignore the issue, keep the mixed
    stuff, and just give the mixer double the time to finish the mixing.
  prefs: []
  type: TYPE_NORMAL
- en: This works but it has an obvious disadvantage that we tangle our business and
    error-handling implementations. More often then not this is undesirable because
    the code for both aspects usually have different natures. The happy path contains
    business-related code and error handling is of a technical essence. Therefore
    it is usually preferred to separate these code paths. In our case, it is justified
    to handle the failure at the stage level because we don't want to drop the element
    of the stream.
  prefs: []
  type: TYPE_NORMAL
- en: 'Akka offers alternative ways to specify failure handling. One of them is recovery
    logic which can be defined for the stage so that failure is converted into the
    final element of the stream:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Here we decide to return an empty bowl of dough in the case of motor failure.
    The stream is then completed but this is fine in our case because our mixers are
    one-off sub-flows anyway.
  prefs: []
  type: TYPE_NORMAL
- en: The `recover` method is a special case of the `recoverWithRetries`. The latter
    accepts not only a partial function for decision-making but also a number of retries
    in the case multiple failures happen in the same processing stage.
  prefs: []
  type: TYPE_NORMAL
- en: Now we are only missing a decision as to how to handle the `StrongVibrationException`.
    If we decide not to handle it, the default behavior will be able to stop the whole
    stream. If that happens, the downstream stages will get informed about the failure
    and upstream stages will be cancelled.
  prefs: []
  type: TYPE_NORMAL
- en: 'We definitely don''t want to close our bakery in case one of our mixers vibrates
    too much. Quite the opposite; we''d like to ignore this completely. Some stages
    support a defining supervision strategy the same way actors do. We can use this
    possibility to define a common error-handling behavior. First, we need to define
    a decision strategy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'There are three strategies available—stop, restart, and resume:'
  prefs: []
  type: TYPE_NORMAL
- en: The stopping strategy is the default one and it will stop the processing stage
    and propagate the failure of up and downstream stages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The resuming strategy just drops the current element and the stream continues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Restart is similar to resume—it drops current element and the stream continues
    but before that the stage is restarted and so any internal state is cleared.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our decider, we just want the stream to continue in the case of strong vibrations,
    but stop in the case of any other failure. We handle both other types of exceptions
    in addition to a supervision strategy and therefore we're safe with this decision.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how we apply our supervision strategy to the definition of the processing
    stage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Now, if we start our example, it will run and deal with hardware failures as
    expected.
  prefs: []
  type: TYPE_NORMAL
- en: It looks good but we're not done because we haven't tested our bakery yet.
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing stream-based code might look complex because of the interconnectedness
    of all of the parts of the system. But more often than not testing streams boils
    down to unit-testing processing stages in isolation and relying on the Akka Streams
    that data flow between this stages will happen as expected.
  prefs: []
  type: TYPE_NORMAL
- en: 'Frequently, no special testing library is needed. Let''s demonstrate this by
    testing our source:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to run this test snippet we need an implicit materializer to be in
    scope:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The general approach is that in order to test a `Sink` it can be attached to
    the special `Source`, and for a `Source` under test, we'll need a special `Sink`.
  prefs: []
  type: TYPE_NORMAL
- en: In both cases, sequence-based `Source`s and Sinks are probably the most useful
    ones. In our example, we're testing that our source emits at least one hundred
    shopping lists and does this in a timely manner. The results are available as
    a `Seq[ShoppingList]` and can be inspected if needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to test a flow, we need to provide both a test `Source` and `Sink`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Here, we see the same approach. After defining the test input and output we
    drive the flow under test and verify that the output has expected properties.
  prefs: []
  type: TYPE_NORMAL
- en: There is an undesirable call to `Await.result` in both cases which relates to
    the fact that running the Akka Streams flow produces a `Future`. We can improve
    on that by using testing techniques as described in [Chapter 5](dba6e932-4169-4b60-9bde-26ac2073a1ab.xhtml),
    *Property-Based Testing in Scala*.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, it is also possible to use test toolkits provided by other Akka
    libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Akka TestKit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Akka Streams offers integration with Akka actors via the `actorRef` method.
    It is available as a Sink constructor so we can use an actor to receive elements
    of the flow which are then represented as messages received by the actor. It is
    convenient to use `TestProbe` from the Akka `TestKit` to verify assumptions about
    the flow. First, we need to add a dependency to the Akka `TestKit` in `build.sbt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an example of how the `TestProbe` can be employed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: We test that there will be one message coming from the flow if one message goes
    into it. This time we're not waiting for the future to complete but formulate
    our assumptions with the syntax the `TestProbe` supports.
  prefs: []
  type: TYPE_NORMAL
- en: By now, you should have recognized the pattern we're using. First, set up the
    source and/or the sink, then wait for the flow to complete, and finally verify
    assumptions about the output of the flow. Surely enough, the Akka team abstracted
    this in a special test kit provided for Akka Streams.
  prefs: []
  type: TYPE_NORMAL
- en: Streams TestKit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to use the Akka Streams `TestKit`, we need to add another dependency
    to our project configuration to `build.sbt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see how the `TestSink` and `TestSource` provided by this module can
    simplify the way we formulate our testing logic. Now we''ll test the whole flow
    from the `Boy` to the `Baker`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: In this scenario, we first create `TestSink` and `TestSource` probes using constructors
    provided by the testing toolkit. Then we materialize them to `publisher` and `subscriber`
    in order to be able to drive the flow. Here, we're using the `toMat` syntax again.
    Until now, we implicitly used the default value (`Keep.left`) but now we want
    to keep both materialized results of the flow and of the sink. Running the flow
    returns its materialized instance which is a pair: `TestPublisher` and `TestSubscriber`.
  prefs: []
  type: TYPE_NORMAL
- en: We then use `subscriber` to request 10 messages from the flow. In Reactive Streams,
    the producer is not supposed to send anything downstream until there is demand,
    and we express the demand with this call. We expect the flow to output elements
    representing `RawCookies(12)`. Thus, our `subscriber.request` translates to 120
    cookies to be produced.
  prefs: []
  type: TYPE_NORMAL
- en: Having this demand, we then initiate the flow by sending the next shopping list
    from the source.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we expect at least two batches of cookies to arrive at the sink. We
    provide sufficient time for the stream to push messages through all of the stages,
    accounting for delays in the mixing and baking stage.
  prefs: []
  type: TYPE_NORMAL
- en: We also cannot reliably predict how many cookies will be made because of the
    way we drop messages at the mixing stage in the case of `MotorOverheatException`
    and `SlowRotationSpeedException`.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we barely scratched the surface of all of the possibilities
    provided by the Akka Streams `TestKit`. As you develop Akka Streams-based systems
    it is worth revisiting both the documentation and the source code of the library
    and keeping in mind the different testing approaches they offer.
  prefs: []
  type: TYPE_NORMAL
- en: Running the application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Please refer to [Appendix A](bc164888-625c-460a-9b0b-e6c45c9eb074.xhtml), *Preparing
    the Environment and Running Code Samples*, if you still have to install Java and/or
    SBT.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will run our application in the terminal the same way we did in [Chapter
    11](87c2e446-3730-49ae-b86b-fc8269678399.xhtml), *An Introduction to the Akka
    and Actor Models* and [Chapter 12](caabef7a-c854-4b39-b8fb-ac17b8ba6eee.xhtml), *Building
    Reactive Applications with Akka Typed*, using two separate terminal sessions for
    `Store` and `BakeryApp` using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`sbt "runMain ch13.BakeryApp"`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sbt "runMain ch13.Store"`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We prefer this method because of its conciseness. If you're about to run the
    app in interactive mode, please consult [Chapter 11](87c2e446-3730-49ae-b86b-fc8269678399.xhtml), *An
    Introduction to the Akka and Actor Models*, for a detailed explanation of this
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our examples, we expect the remote `Store` app to be available at the moment
    we start the main `Bakery` stream. Because of this, we have to start the `Store`
    first or the `BakeryApp` will exit with an exception at the moment it fails to
    connect to the store. The next screenshot shows two terminal windows with commands
    to run the `Store` entered in the left window and the `BakeryApp` started in the
    right window. In the following screenshot, we can see that the `Store` has already
    been running for some time and the BakeryApp has just started to execute:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/471c2012-abc6-46db-87a0-284f5147748a.png)'
  prefs: []
  type: TYPE_IMG
- en: The `Bakery` in the right terminal will now run until stopped with the *Ctrl*
    + *C* shortcut or the terminal window is closed.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Traditional streaming solutions suffer from one of two issues. In the case of
    pulling, there is a need for locking or extensive use of resources on the side
    of the quick consumer. In the case of pushing, there is a possibility that a number
    of messages to process will grow bigger than the available memory, requiring a
    slow consumer to drop messages or terminate because of the memory overflow. Reactive
    Streams solves this problem by defining dynamic asynchronous pull-push with back
    pressure. Akka Streams implements the Reactive Streams standard using Akka which
    allows for seamless integration with both technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Streams in Akka are built from blocks called stages or flows. These blocks can
    be nested and connected to each other, forming graphs. Graphs with single input
    and single output can be made runnable by connecting them to the source and sink.
    Graph definitions can be freely shared and reused.
  prefs: []
  type: TYPE_NORMAL
- en: Running a graph requires a materializer and produces a materialized value depending
    on the graph and sink definition.
  prefs: []
  type: TYPE_NORMAL
- en: Error handling in Akka Streams can be done in different ways including catching
    errors directly in the flow definition, defining a recovery method with optional
    retries and/or overriding a supervision strategy for processing stages which support
    it.
  prefs: []
  type: TYPE_NORMAL
- en: The modular nature of the flow definition allows for straightforward testing
    of single stages and their combinations. In order to reduce boilerplate for recurring
    test setup and expectation definitions, Akka Streams offers special test toolkit.
  prefs: []
  type: TYPE_NORMAL
- en: The reader is encouraged to take a look at the official Akka documentation at [https://doc.akka.io/docs/akka/current/stream/index.html ](https://doc.akka.io/docs/akka/current/stream/index.html)to
    explore the possibilities offered by Akka Streams in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Name two different modes associated with "classic" streams. What is problematic
    with them?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why are Reactive Streams considered as workable in dynamic pull-push mode?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the typical building blocks of Akka Stream's graph?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do we convert a graph into a runnable graph?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the main goal of having materialization as a separate explicit step?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe the effects of applying different supervision strategies.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which main abstractions provide an Akka Streams `TestKit`? Why are they useful?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Christian Baxter, *Mastering Akka: **Master the art of creating scalable, concurrent,
    and reactive applications using Akka*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Héctor Veiga Ortiz, Piyush Mishra,*Akka Cookbook: Learn how to use the Akka
    framework to build effective applications in Scala*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rambabu Posa, *Scala Reactive Programming: Build fault-tolerant, robust, and
    distributed applications in Scala*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
