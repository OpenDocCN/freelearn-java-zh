- en: Chapter 3. Traditional Building Blocks of Concurrency
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 3 章。并发的传统构建块
- en: '|   | *"There''s an old story about the person who wished his computer were
    as easy to use as his telephone. That wish has come true, since I no longer know
    how to use my telephone."* |   |'
  id: totrans-1
  prefs: []
  type: TYPE_TB
  zh: '|   | *"有这样一个关于希望自己的电脑像电话一样容易使用的老人的故事。这个愿望已经实现了，因为我现在不知道怎么使用我的电话了。" |   |'
- en: '|   | --*Bjarne Stroustrup* |'
  id: totrans-2
  prefs: []
  type: TYPE_TB
  zh: '|   | --*Bjarne Stroustrup* |'
- en: The concurrency primitives shown in [Chapter 2](ch02.html "Chapter 2. Concurrency
    on the JVM and the Java Memory Model"), *Concurrency on the JVM and the Java Memory
    Model*, are the basics of concurrent programming on JVM. Nevertheless, we usually
    avoid using them directly, as their low-level nature makes them delicate and prone
    to errors. As we saw, low-level concurrency is susceptible to effects such as
    data races, reordering, visibility, deadlocks, and non-determinism. Fortunately,
    people have come up with more advanced building blocks of concurrency, that capture
    common patterns in concurrent programs and are a lot safer to use. Although these
    building blocks do not solve all the issues of concurrent programming, they simplify
    the reasoning about concurrent programs and can be found across concurrency frameworks
    and libraries in many languages, including Scala. This chapter extends the fundamental
    concurrent programming model from [Chapter 2](ch02.html "Chapter 2. Concurrency
    on the JVM and the Java Memory Model"), *Concurrency on the JVM and the Java Memory
    Model*, with traditional building blocks of concurrency and shows how to use them
    in practice.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第 2 章](ch02.html "第 2 章。JVM 和 Java 内存模型的并发") 中展示的并发原语，*JVM 和 Java 内存模型的并发*，是
    JVM 上并发编程的基础。尽管如此，我们通常避免直接使用它们，因为它们低级性质使得它们容易出错。正如我们所见，低级并发容易受到数据竞争、重排序、可见性、死锁和非确定性等影响。幸运的是，人们已经提出了更高级的并发构建块，它们捕捉并发程序中的常见模式，并且使用起来更加安全。尽管这些构建块不能解决并发编程的所有问题，但它们简化了对并发程序推理，并且可以在许多语言的并发框架和库中找到，包括
    Scala。本章扩展了 [第 2 章](ch02.html "第 2 章。JVM 和 Java 内存模型的并发") 中的基本并发编程模型，即 *JVM 和
    Java 内存模型的并发*，并展示了如何在实际中应用这些传统的并发构建块。
- en: 'In general, there are two aspects of a concurrent programming model. The first
    deals with expressing concurrency in a program. Given a program, which of its
    parts can execute concurrently and under which conditions? In the previous chapter,
    we saw that JVM allows declaring and starting separate threads of control. In
    this chapter, we will visit a more lightweight mechanism for starting concurrent
    executions. The second important aspect of concurrency is data access. Given a
    set of concurrent executions, how can these executions correctly access and modify
    the program data? Having seen a low-level answer to these questions in the previous
    chapter, such as the `synchronized` statement and volatile variables, we will
    now dive into more complex abstractions. We will study the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，并发编程模型有两个方面。第一个方面是处理程序中的并发表达。给定一个程序，它的哪些部分可以并发执行，以及在什么条件下可以并发执行？在前一章中，我们看到了
    JVM 允许声明和启动独立的控制线程。在本章中，我们将探讨一种更轻量级的并发执行启动机制。并发的第二个重要方面是数据访问。给定一组并发执行，这些执行如何正确地访问和修改程序数据？在前一章中，我们已经看到了对这些问题的低级答案，例如
    `synchronized` 语句和 `volatile` 变量，现在我们将深入研究更复杂的抽象。我们将研究以下主题：
- en: Using the `Executor` and `ExecutionContext` objects
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `Executor` 和 `ExecutionContext` 对象
- en: Atomic primitives for non-blocking synchronization
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于非阻塞同步的原子原语
- en: The interaction of lazy values and concurrency
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 懒值和并发之间的交互
- en: Using concurrent queues, sets, and maps
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用并发队列、集合和映射
- en: How to create processes and communicate with them
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何创建进程并与它们通信
- en: The ultimate goal of this chapter will be to implement a safe API for concurrent
    file handling. We will use the abstractions in this chapter to implement a simple,
    reusable file-handling API for applications such as filesystem managers or FTP
    servers. We will thus see how the traditional building blocks of concurrency work
    separately and how they all fit together in a larger use case.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的最终目标将是实现一个安全的并发文件处理 API。我们将使用本章中的抽象来实现一个简单、可重用的文件处理 API，用于文件系统管理器或 FTP 服务器等应用程序。因此，我们将看到传统的并发构建块是如何单独工作的，以及它们如何在更大的用例中协同工作。
- en: The Executor and ExecutionContext objects
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Executor 和 ExecutionContext 对象
- en: As discussed in [Chapter 2](ch02.html "Chapter 2. Concurrency on the JVM and
    the Java Memory Model"), *Concurrency on the JVM and the Java Memory Model*, although
    creating a new thread in a Scala program takes orders of magnitude less computational
    time compared to creating a new JVM process, thread creation is still much more
    expensive than allocating a single object, acquiring a monitor lock, or updating
    an entry in a collection. If an application performs a large number of small concurrent
    tasks and requires high throughput, we cannot afford to create a fresh thread
    for each of these tasks. Starting a thread requires us to allocate a memory region
    for its call stack and a context switch from one thread to another, which can
    be much more time-consuming than the amount of work in the concurrent task. For
    this reason, most concurrency frameworks have facilities that maintain a set of
    threads in a waiting state and start running when concurrently executable work
    tasks become available. Generally, we call such facilities **thread pools**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [第 2 章](ch02.html "第 2 章。JVM 和 Java 内存模型上的并发") 中所述，*JVM 和 Java 内存模型上的并发*，尽管在
    Scala 程序中创建新线程所需的计算时间比创建新的 JVM 进程少几个数量级，但线程创建的成本仍然比分配单个对象、获取监视器锁或在集合中更新条目要高得多。如果一个应用程序执行大量的小型并发任务并且需要高吞吐量，我们无法为这些任务中的每一个都创建一个新的线程。启动线程需要我们为其调用栈分配一个内存区域，并从一个线程切换到另一个线程，这可能会比并发任务中的工作量消耗更多的时间。因此，大多数并发框架都有维护一组处于等待状态的线程的设施，并在并发可执行的工作任务可用时启动运行。通常，我们称这样的设施为
    **线程池**。
- en: To allow programmers to encapsulate the decision of how to run concurrently
    executable work tasks, JDK comes with an abstraction called `Executor`. The `Executor`
    interface is a simple interface that defines a single `execute` method. This method
    takes a `Runnable` object and eventually calls the `Runnable` object's `run` method.
    The `Executor` object decides on which thread and when to call the `run` method.
    An `Executor` object can start a new thread specifically for this invocation of
    `execute` or even execute the `Runnable` object directly on the caller thread.
    Usually, the `Executor` executes the `Runnable` object concurrently to the execution
    of the thread that called the `execute` method, and it is implemented as a thread
    pool.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让程序员能够封装如何并发执行工作任务的决策，JDK 提供了一个名为 `Executor` 的抽象。`Executor` 接口是一个简单的接口，它定义了一个单一的
    `execute` 方法。此方法接受一个 `Runnable` 对象，并最终调用该 `Runnable` 对象的 `run` 方法。`Executor` 对象决定在哪个线程以及何时调用
    `run` 方法。一个 `Executor` 对象可以为此次 `execute` 调用专门启动一个新线程，甚至可以直接在调用线程上执行 `Runnable`
    对象。通常，`Executor` 会将 `Runnable` 对象与调用 `execute` 方法的线程并发执行，并且它被实现为一个线程池。
- en: 'One `Executor` implementation, introduced in JDK 7, is `ForkJoinPool` and it
    is available in the `java.util.concurrent` package. Scala programs can use it
    in JDK 6 as well by importing the contents of the `scala.concurrent.forkjoin`
    package. In the following code snippet, we show you how to instantiate a `ForkJoinPool`
    class implementation and submit a task that can be asynchronously executed:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: JDK 7 中引入的一个 `Executor` 实现是 `ForkJoinPool`，它位于 `java.util.concurrent` 包中。Scala
    程序可以通过导入 `scala.concurrent.forkjoin` 包的内容在 JDK 6 中使用它。在下面的代码片段中，我们展示了如何实例化一个 `ForkJoinPool`
    类实现并提交一个可以异步执行的任务：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We start by importing the `scala.concurrent` package. In later examples, we
    implicitly assume that this package is imported. We then call the `ForkJoinPool`
    class and assign it to a value called the `executor` method. Once instantiated,
    the `executor` value is sent a task in the form of a `Runnable` object that prints
    to the standard output. Finally, we invoke the `sleep` statement in order to prevent
    the daemon threads in the `ForkJoinPool` instance from being terminated before
    they call the `run` method on the `Runnable` object. Note that the `sleep` statement
    is not required if you are running the example from SBT with the `fork` setting
    set to `false`.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入 `scala.concurrent` 包。在后续的示例中，我们隐式地假设已导入此包。然后我们调用 `ForkJoinPool` 类并将其分配给一个名为
    `executor` 的值。一旦实例化，`executor` 值就会发送一个以 `Runnable` 对象形式打印到标准输出的任务。最后，我们调用 `sleep`
    语句以防止在 `ForkJoinPool` 实例在调用 `Runnable` 对象的 `run` 方法之前终止守护线程。请注意，如果您使用具有 `fork`
    设置为 `false` 的 SBT 运行示例，则不需要 `sleep` 语句。
- en: Why do we need `Executor` objects in the first place? In the previous example,
    we can easily change the `Executor` implementation without affecting the code
    in the `Runnable` object. The `Executor` objects serve to decouple the logic in
    the concurrent computations from how these computations are executed. The programmer
    can focus on specifying parts of the code that potentially execute concurrently,
    separately from where and when to execute those parts of the code.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为什么一开始就需要 `Executor` 对象呢？在先前的示例中，我们可以轻松地更改 `Executor` 实现而不影响 `Runnable` 对象中的代码。`Executor`
    对象的作用是将并发计算中的逻辑与这些计算的执行方式解耦。程序员可以专注于指定可能并发执行的代码部分，而无需考虑这些部分代码在哪里以及何时执行。
- en: The more elaborate subtype of the `Executor` interface, also implemented by
    the `ForkJoinPool` class, is called `ExecutorService`. This extended `Executor`
    interface defines several convenience methods, the most prominent being the `shutdown`
    method. The `shutdown` method makes sure that the `Executor` object gracefully
    terminates by executing all the submitted tasks and then stopping all the worker
    threads. Fortunately, our `ForkJoinPool` implementation is benign with respect
    to termination. Its threads are daemons by default, so there is no need to shut
    it down explicitly at the end of the program. In general, however, programmers
    should call the `shutdown` method on the `ExecutorService` objects they created,
    typically before the program terminates.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`Executor` 接口的更复杂子类型，也由 `ForkJoinPool` 类实现，被称为 `ExecutorService`。这个扩展的 `Executor`
    接口定义了几个便利方法，其中最突出的是 `shutdown` 方法。`shutdown` 方法确保 `Executor` 对象通过执行所有提交的任务然后停止所有工作线程来优雅地终止。幸运的是，我们的
    `ForkJoinPool` 实现对终止是良性的。它的线程默认是守护线程，因此不需要在程序结束时显式地关闭它。然而，通常程序员应该在程序终止之前调用他们创建的
    `ExecutorService` 对象上的 `shutdown` 方法。'
- en: Tip
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: When your program no longer needs the `ExecutorService` object you created,
    you should ensure that the `shutdown` method is called.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的程序不再需要你创建的 `ExecutorService` 对象时，你应该确保调用 `shutdown` 方法。
- en: 'To ensure that all the tasks submitted to the `ForkJoinPool` object are complete,
    we need to additionally call the `awaitTermination` method, specifying the maximum
    amount of time to wait for their completion. Instead of calling the `sleep` statement,
    we can do the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保提交给 `ForkJoinPool` 对象的所有任务都已完成，我们需要额外调用 `awaitTermination` 方法，指定等待任务完成的最大时间。我们不必调用
    `sleep` 语句，可以这样做：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The `scala.concurrent` package defines the `ExecutionContext` trait that offers
    a similar functionality to that of `Executor` objects but is more specific to
    Scala. We will later learn that many Scala methods take `ExecutionContext` objects
    as implicit parameters. Execution contexts implement the abstract `execute` method,
    which exactly corresponds to the `execute` method on the `Executor` interface,
    and the `reportFailure` method, which takes a `Throwable` object and is called
    whenever some task throws an exception. The `ExecutionContext` companion object
    contains the default execution context called `global`, which internally uses
    a `ForkJoinPool` instance:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`scala.concurrent` 包定义了 `ExecutionContext` 特质，它提供了与 `Executor` 对象类似的功能，但更具体于
    Scala。我们稍后将会了解到，许多 Scala 方法将 `ExecutionContext` 对象作为隐式参数。执行上下文实现了抽象的 `execute`
    方法，它与 `Executor` 接口上的 `execute` 方法相对应，以及 `reportFailure` 方法，它接受一个 `Throwable`
    对象，并在某些任务抛出异常时被调用。`ExecutionContext` 伴随对象包含默认的执行上下文 `global`，它内部使用一个 `ForkJoinPool`
    实例：'
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The `ExecutionContext` companion object defines a pair of methods, `fromExecutor`
    and `fromExecutorService`, which create an `ExecutionContext` object from an `Executor`
    or `ExecutorService` interface, respectively:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`ExecutionContext` 伴随对象定义了一对方法，`fromExecutor` 和 `fromExecutorService`，它们分别从一个
    `Executor` 或 `ExecutorService` 接口创建一个 `ExecutionContext` 对象：'
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the preceding example, we will create an `ExecutionContext` object from a
    `ForkJoinPool` instance with a parallelism level of `2`. This means that the `ForkJoinPool`
    instance will usually keep two worker threads in its pool.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们将从一个具有并行级别 `2` 的 `ForkJoinPool` 实例创建一个 `ExecutionContext` 对象。这意味着
    `ForkJoinPool` 实例通常会保持其池中的两个工作线程。
- en: 'In the examples that follow, we will rely on the global `ExecutionContext`
    object. To make the code more concise, we will introduce the `execute` convenience
    method in the package object of this chapter, which executes a block of code on
    the global `ExecutionContext` object:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的示例中，我们将依赖于全局的`ExecutionContext`对象。为了使代码更加简洁，我们将在本章的包对象中引入`execute`便捷方法，该方法将在全局`ExecutionContext`对象上执行代码块：
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `Executor` and `ExecutionContext` objects are a nifty concurrent programming
    abstraction, but they are not a silver bullets. They can improve throughput by
    reusing the same set of threads for different tasks, but they are unable to execute
    tasks if those threads become unavailable, because all the threads are busy with
    running other tasks. In the following example, we declare `32` independent executions,
    each of which lasts two seconds, and wait `10` seconds for their completion:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`Executor`和`ExecutionContext`对象是一种巧妙的并发编程抽象，但它们并非万能的银弹。它们可以通过重用同一组线程来执行不同的任务从而提高吞吐量，但如果这些线程变得不可用，它们将无法执行任务，因为所有线程都在忙于运行其他任务。在下面的示例中，我们声明了`32`个独立的执行，每个执行持续两秒，并等待`10`秒以完成它们：'
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: You would expect that all the executions terminate after two seconds, but this
    is not the case. Instead, on our quad-core CPU with hyper threading, the global
    `ExecutionContext` object has eight threads in the thread pool, so it executes
    work tasks in batches of eight. After two seconds, a batch of eight tasks print
    that they are completed, after two more seconds another batch prints, and so on.
    This is because the global `ExecutionContext` object internally maintains a pool
    of eight worker threads, and calling `sleep` puts all of them into a timed waiting
    state. Only once the `sleep` method call in these worker threads is completed
    can another batch of eight tasks be executed. Things can be much worse. We could
    start eight tasks that execute the guarded block idiom seen in [Chapter 2](ch02.html
    "Chapter 2. Concurrency on the JVM and the Java Memory Model"), *Concurrency on
    the JVM and the Java Memory Model*, and another task that calls the `notify` method
    to wake them up. As the `ExecutionContext` object can execute only eight tasks
    concurrently, the worker threads would, in this case, be blocked forever. We say
    that executing blocking operations on `ExecutionContext` objects can cause starvation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会预期所有执行在两秒后都会终止，但这并非事实。相反，在我们的四核CPU和超线程技术下，全局`ExecutionContext`对象在线程池中有八个线程，因此它以八个任务为一组批量执行工作任务。两秒后，一组八个任务会打印出它们已完成，再过两秒另一组任务会打印，以此类推。这是因为全局`ExecutionContext`对象内部维护了一个包含八个工作线程的线程池，调用`sleep`会将它们全部置于定时等待状态。只有当这些工作线程中的`sleep`方法调用完成后，才能执行下一批八个任务。情况可能会更糟。我们可以启动八个执行[第2章](ch02.html
    "第2章. JVM和Java内存模型的并发")中看到的受保护代码块语法的任务，以及另一个调用`notify`方法唤醒它们的任务。由于`ExecutionContext`对象只能并发执行八个任务，在这种情况下，工作线程将永远阻塞。我们说在`ExecutionContext`对象上执行阻塞操作可能导致饥饿。
- en: Tip
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Avoid executing operations that might block indefinitely on `ExecutionContext`
    and `Executor` objects.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 避免在`ExecutionContext`和`Executor`对象上执行可能无限阻塞的操作。
- en: Having seen how to declare concurrent executions, we turn our attention to how
    these concurrent executions interact by manipulating program data.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了如何声明并发执行之后，我们将关注这些并发执行如何通过操作程序数据来相互交互。
- en: Atomic primitives
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原子操作
- en: In [Chapter 2](ch02.html "Chapter 2. Concurrency on the JVM and the Java Memory
    Model"), *Concurrency on the JVM and the Java Memory Model*, we learned that memory
    writes do not happen immediately unless proper synchronization is applied. A set
    of memory writes is not executed at once, that is, atomically. We saw that visibility
    is ensured by the happens-before relationship, and we relied on the `synchronized`
    statement to achieve it. Volatile fields were a more lightweight way of ensuring
    happens-before relationships, but a less powerful synchronization construct. Recall
    how volatile fields alone could not implement the `getUniqueId` method correctly.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](ch02.html "第2章. JVM和Java内存模型的并发")中，我们了解到除非应用了适当的同步，否则内存写入不会立即发生。一组内存写入不会一次性执行，即原子性地执行。我们了解到通过happens-before关系确保了可见性，并且我们依赖于`synchronized`语句来实现它。`volatile`字段是确保happens-before关系的一种更轻量级的方式，但是一种功能较弱的同步结构。回想一下，仅使用`volatile`字段本身无法正确实现`getUniqueId`方法。
- en: In this section, we study atomic variables that provide basic support for executing
    multiple memory reads and writes at once. Atomic variables are close cousins of
    volatile variables, but are more expressive than them; they are used to build
    complex concurrent operations without relying on the `synchronized` statement.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们研究提供一次性执行多个内存读取和写入基本支持的原子变量。原子变量是volatile变量的近亲，但比它们更具有表现力；它们用于构建复杂的并发操作，而不依赖于`synchronized`语句。
- en: Atomic variables
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 原子变量
- en: An atomic variable is a memory location that supports complex *linearizable*
    operations. A linearizable operation is any operation that appears to occur instantaneously
    to the rest of the system. For example, a volatile write is a linearizable operation.
    A complex linearizable operation is a linearizable operation equivalent to at
    least two reads and/or writes. We will use the term *atomically* to refer to complex
    linearizable operations.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 原子变量是一个支持复杂*可线性化*操作的内存位置。可线性化操作是指对系统其他部分来说似乎瞬间发生的任何操作。例如，一个volatile写操作就是一个可线性化操作。复杂的可线性化操作是至少相当于两个读取和/或写入的可线性化操作。我们将使用术语*原子性地*来指代复杂的可线性化操作。
- en: 'Various atomic variables defined in the `java.util.concurrent.atomic` package
    support some complex linearizable operations on the Boolean, integer, long, and
    reference types with the `AtomicBoolean`, `AtomicInteger`, `AtomicLong`, and `AtomicReference`
    classes, respectively. Recall that the `getUniqueId` method from [Chapter 2](ch02.html
    "Chapter 2. Concurrency on the JVM and the Java Memory Model"), *Concurrency on
    the JVM and the Java Memory Model*, needs to return a unique numeric identifier
    each time a thread invokes it. We previously implemented this method using the
    `synchronized` statement, and we now reimplement it using atomic long variables:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在`java.util.concurrent.atomic`包中定义的各种原子变量，分别通过`AtomicBoolean`、`AtomicInteger`、`AtomicLong`和`AtomicReference`类支持布尔、整数、长和引用类型的一些复杂可线性化操作。回想一下，[第2章](ch02.html
    "第2章. JVM和Java内存模型上的并发")中`getUniqueId`方法，*JVM和Java内存模型上的并发*，每次线程调用它时都需要返回一个唯一的数字标识符。我们之前使用`synchronized`语句实现了这个方法，现在我们使用原子长变量重新实现它：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, we declare an atomic long variable, which is `uid`, with an initial value
    `0` and call its `incrementAndGet` method from `getUniqueId`. The `incrementAndGet`
    method is a complex linearizable operation. It simultaneously reads the current
    value `x` of `uid`, computes `x + 1`, writes `x + 1` back to `uid`, and returns
    `x + 1`. These steps cannot be interleaved with steps in other invocations of
    the `incrementAndGet` method, so each invocation of the `getUniqueId` method returns
    a unique number.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们声明一个原子长变量`uid`，其初始值为`0`，并从`getUniqueId`调用其`incrementAndGet`方法。`incrementAndGet`方法是一个复杂的可线性化操作。它同时读取`uid`的当前值`x`，计算`x
    + 1`，将`x + 1`写回`uid`，并返回`x + 1`。这些步骤不能与其他`incrementAndGet`方法的步骤交织，因此每次`getUniqueId`方法的调用都返回一个唯一的数字。
- en: Atomic variables define other methods such as the `getAndSet` method, which
    atomically reads the value of the variable, sets the new value, and returns its
    previous value. Numeric atomic variables additionally have methods such as `decrementAndGet`
    and `addAndGet`. It turns out that all these atomic operations are implemented
    in terms of a fundamental atomic operation, which is `compareAndSet`. The compare-and-set
    operation, sometimes called **compare-and-swap** (**CAS**), takes the expected
    previous value and the new value for the atomic variable and atomically replaces
    the current value with the new value only if the current value is equal to the
    expected value.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 原子变量定义了其他方法，例如`getAndSet`方法，它原子性地读取变量的值，设置新值，并返回其旧值。数值原子变量还有`decrementAndGet`和`addAndGet`等方法。结果证明，所有这些原子操作都是基于一个基本原子操作实现的，即`compareAndSet`。比较并设置操作，有时称为**比较并交换**（**CAS**），接受原子变量的预期旧值和新值，并且仅在当前值等于预期值时原子性地将当前值替换为新值。
- en: Note
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The CAS operation is a fundamental building block for lock-free programming.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: CAS操作是锁免费编程的基本构建块。
- en: 'The CAS operation is conceptually equivalent to the following `synchronized`
    block, but is more efficient and does not get blocked on most JVMs, as it is implemented
    in terms of a processor instruction:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: CAS操作在概念上等同于以下`synchronized`块，但更高效，并且不会在大多数JVM上阻塞，因为它是以处理器指令的形式实现的：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The CAS operation is available on all types of atomic variables; `compareAndSet`
    also exists in the generic `AtomicReference[T]` class used to store object references
    of an arbitrary object of type `T`, and is equivalent to the following:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: CAS操作适用于所有类型的原子变量；`compareAndSet`也存在于用于存储任意类型`T`的对象引用的通用`AtomicReference[T]`类中，并且等同于以下：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: If CAS does replace the old value with the new value, it returns the value `true`.
    Otherwise, CAS returns `false`. When using CAS, we usually start by calling the
    `get` method on the atomic variable to read its value. We then compute a new value
    based on the value we read. Finally, we invoke the CAS operation to change the
    value we previously read with the new value. If the CAS operation returns `true`,
    we are done. If the CAS operation returns `false`, then some other thread must
    have changed the atomic variable since we last read it using the `get` variable.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果CAS将旧值替换为新值，则返回值`true`。否则，CAS返回`false`。在使用CAS时，我们通常首先在原子变量上调用`get`方法来读取其值。然后，我们根据读取的值计算新值。最后，我们调用CAS操作来更改之前读取的值。如果CAS操作返回`true`，则操作完成。如果CAS操作返回`false`，那么在最后一次使用`get`变量读取原子变量之后，另一个线程必须已经更改了原子变量。
- en: 'Let''s see how CAS works in a concrete example. We will re-implement the `getUniqueId`
    method using the `get` and `compareAndSet` methods:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看CAS在具体示例中的工作方式。我们将使用`get`和`compareAndSet`方法重新实现`getUniqueId`方法：
- en: '[PRE9]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This time, the thread`T` calls the `get` method to read the value of `uid`
    into a local variable `oldUid`. Note that local variables such as `oldUid` are
    only used by a single thread that initialized them, so no other thread can see
    the version of the `oldUid` variable in thread T. The thread `T` then computes
    the new value `newUid`. This does not happen atomically, and at this point, another
    thread S might concurrently change the value of the `uid` variable. The `compareAndSet`
    call by T changes `uid` successfully only if no other thread S modified the value
    of the `uid` variable since thread `T` called the `get` method in the first line.
    If the `compareAndSet` method is not successful, the method is called again tail-recursively.
    Hence, we use the `@tailrec` annotation to force the compiler to generate a tail-recursive
    call. We say that thread `T` needs to retry the operation. This is illustrated
    in the following figure:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，线程`T`调用`get`方法将`uid`的值读取到局部变量`oldUid`中。请注意，像`oldUid`这样的局部变量仅由初始化它们的单个线程使用，因此没有其他线程可以看到线程T中`oldUid`变量的版本。然后，线程`T`计算新值`newUid`。这不会原子性地发生，在此点，另一个线程S可能并发地更改`uid`变量的值。T的`compareAndSet`调用只有在没有其他线程S在T调用第一行的`get`方法后修改`uid`变量的值时才能成功更改`uid`。如果`compareAndSet`方法不成功，则方法会再次尾递归调用。因此，我们使用`@tailrec`注解来强制编译器生成尾递归调用。我们说线程`T`需要重试操作。这在下图中表示：
- en: '![Atomic variables](img/image_03_001.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![原子变量](img/image_03_001.jpg)'
- en: Tip
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Always use the `@tailrec` annotation for these functions, which are intended
    to be tail-recursive. The compiler will check all the annotated functions to see
    whether or not they are tail-recursive.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 总是为这些预期为尾递归的函数使用`@tailrec`注解，编译器将检查所有注解函数以确定它们是否为尾递归。
- en: Retrying is a common pattern when programming with CAS operations. This retry
    can happen infinitely many times. The good news is that a CAS in thread **T**
    can fail only when another thread **S** completes the operation successfully;
    if our part of the system does not progress, at least some other part of the system
    does. In fact, the `getUniqueId` method is fair to all the threads in practice,
    and most JDKs implement the `incrementAndGet` method in a very similar manner
    to our CAS-based implementation of the `getUniqueId` method.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 重试是在使用CAS操作编程时的一种常见模式。这种重试可能发生无限多次。好消息是，线程**T**中的CAS可以失败，只有当另一个线程**S**成功完成操作时；如果我们的系统部分没有进展，至少系统的其他部分有所进展。实际上，`getUniqueId`方法在实践中对所有线程都是公平的，并且大多数JDK以与我们基于CAS实现的`getUniqueId`方法非常相似的方式实现了`incrementAndGet`方法。
- en: Lock-free programming
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无锁编程
- en: A **lock** is a synchronization mechanism used to limit access to a resource
    that can be used by multiple threads. In [Chapter 2](ch02.html "Chapter 2. Concurrency
    on the JVM and the Java Memory Model"), *Concurrency on the JVM and the Java Memory
    Model*, we learned that every JVM object has an intrinsic lock that is used when
    invoking the `synchronized` statement on the object. Recall that an intrinsic
    lock makes sure that at most one thread executes the `synchronized` statement
    on the object. The intrinsic lock accomplishes this by blocking all the threads
    that try to acquire it when it is unavailable. We will study other examples of
    locks in this section.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**锁**是一种同步机制，用于限制多个线程可以使用的资源的访问。在[第2章](ch02.html "第2章。JVM和Java内存模型上的并发")《JVM和Java内存模型上的并发》中，我们了解到每个JVM对象都有一个内在的锁，当在对象上调用`synchronized`语句时使用。回想一下，内在锁确保最多只有一个线程在对象上执行`synchronized`语句。内在锁通过在不可用的情况下阻止所有尝试获取它的线程来实现这一点。我们将在本节中研究其他锁的示例。'
- en: As we already learned, programming using locks is susceptible to deadlocks.
    Also, if the OS pre-empts a thread that is holding a lock, it might arbitrarily
    delay the execution of other threads. In lock-free programs, these effects are
    less likely to compromise the program's performance.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所学的，使用锁进行编程容易发生死锁。此外，如果操作系统抢占了一个持有锁的线程，它可能会任意延迟其他线程的执行。在无锁程序中，这些影响不太可能损害程序的性能。
- en: Why do we need atomic variables? Atomic variables allow us to implement *lock-free
    operations*. As the name implies, a thread that executes a lock-free operation
    does not acquire any locks. Consequently, many lock-free algorithms have an improved
    throughput. A thread executing a lock-free algorithm does not hold any locks when
    it gets pre-empted by the OS, so it cannot temporarily block other threads. Furthermore,
    lock-free operations are impervious to deadlocks, because threads cannot get blocked
    indefinitely without locks.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为什么需要原子变量？原子变量使我们能够实现*无锁操作*。正如其名所示，执行无锁操作的线程不会获取任何锁。因此，许多无锁算法的吞吐量得到了提高。当线程被操作系统抢占时，执行无锁算法的线程不会持有任何锁，因此它不能暂时阻塞其他线程。此外，无锁操作对死锁免疫，因为线程在没有锁的情况下不能无限期地被阻塞。
- en: Our CAS-based implementation of the `getUniqueId` method is an example of a
    lock-free operation. It acquires no locks that can permanently suspend other threads.
    If one thread fails due to concurrent CAS operations, it immediately restarts
    and tries to execute the `getUniqueId` method again.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们基于CAS实现的`getUniqueId`方法是一个无锁操作的例子。它不会永久挂起其他线程的任何锁。如果一个线程由于并发CAS操作而失败，它会立即重新启动并尝试再次执行`getUniqueId`方法。
- en: 'However, not all operations composed from atomic primitives are lock-free.
    Using atomic variables is a necessary precondition for lock-freedom, but it is
    not sufficient. To show this, we will implement our own simple `synchronized`
    statement, which will use atomic variables:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并非所有由原子原语组成的操作都是无锁的。使用原子变量是实现无锁的必要前提条件，但它并不充分。为了证明这一点，我们将实现我们自己的简单`synchronized`语句，它将使用原子变量：
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `mySynchronized` statement executes a block of code `body` in isolation.
    It uses the atomic `lock` Boolean variable to decide whether some thread is currently
    calling the `mySynchronized` method or not. The first thread that changes the
    `lock` variable from `false` to `true` using the `compareAndSet` method can proceed
    with executing the body. While the thread is executing the body, other threads
    calling the `mySynchronized` method repetitively invoke the `compareAndSet` method
    on the `lock` variable but fail. Once `body` completes executing, the thread unconditionally
    sets the `lock` variable back to `false` in the `finally` block. A `compareAndSet`
    method in some other thread can then succeed, and the process is repeated again.
    After all the tasks are completed, the value of the `count` variable is always
    `10`. The main difference with respect to the `synchronized` statement is that
    threads calling `mySynchronized` busy-wait in the `while` loop until the lock
    becomes available. Such locks are dangerous and much worse than the `synchronized`
    statement. This example shows you that we need to define lock-freedom more carefully,
    because a lock can implicitly exist in the program without the programmer being
    aware of it.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`mySynchronized`语句在隔离中执行代码块`body`。它使用原子的`lock`布尔变量来决定是否有线程当前正在调用`mySynchronized`方法。第一个将`lock`变量从`false`更改为`true`的线程可以使用`compareAndSet`方法继续执行代码块。当线程执行代码块时，其他调用`mySynchronized`方法的线程反复在`lock`变量上调用`compareAndSet`方法但失败。一旦`body`执行完成，线程在`finally`块中无条件地将`lock`变量设置回`false`。然后，某个其他线程中的`compareAndSet`方法可以成功，并且过程再次重复。在所有任务完成后，`count`变量的值总是`10`。与`synchronized`语句相比，主要的不同之处在于调用`mySynchronized`的线程在`while`循环中忙等待，直到锁可用。这样的锁是危险的，并且比`synchronized`语句要糟糕得多。这个例子表明，我们需要更仔细地定义锁免费，因为锁可以在程序员没有意识到的情况下隐式地存在于程序中。'
- en: In [Chapter 2](ch02.html "Chapter 2. Concurrency on the JVM and the Java Memory
    Model"), *Concurrency on the JVM and the Java Memory Model*, we learned that most
    modern operating systems use pre-emptive multitasking, where a thread `T` can
    be temporarily suspended by the operating system at any point in time. If this
    happens while thread `T` is holding a lock, other threads waiting for the same
    lock cannot proceed until the lock is released. These other threads have to wait
    until the operating system continues executing the thread `T` and the thread `T`
    releases the lock. This is unfortunate, as these threads could be doing useful
    work while the thread `T` is suspended. We say that a slow thread `T` blocked
    the execution of other threads. In a lock-free operation, a slow thread cannot
    block the execution of other threads. If multiple threads execute an operation
    concurrently, then at least one of these threads must complete in a finite amount
    of time.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第二章](ch02.html "第二章。JVM和Java内存模型中的并发")中，我们学习了大多数现代操作系统使用抢占式多任务处理，其中线程`T`可以在任何时间点被操作系统临时挂起。如果这种情况发生在线程`T`持有锁的时候，等待同一锁的其他线程无法继续执行，直到锁被释放。这些其他线程必须等待操作系统继续执行线程`T`并且线程`T`释放锁。这是不幸的，因为这些线程在线程`T`挂起时本可以执行有用的工作。我们说慢线程`T`阻塞了其他线程的执行。在一个锁免费的操作中，慢线程不能阻塞其他线程的执行。如果多个线程并发执行一个操作，那么至少有一个线程必须在有限的时间内完成。
- en: Note
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Given a set of threads executing an operation, an operation is lock-free if
    at least one thread always completes the operation after a finite number of steps,
    regardless of the speed at which different threads progress.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一组执行操作的线程，如果一个操作是锁免费的，那么至少有一个线程在有限步骤后总是能够完成该操作，无论不同线程的进度速度如何。
- en: 'With this more formal definition of lock-freedom, you can get a feel for why
    lock-free programming is hard. It is not easy to prove that an operation is lock-free,
    and implementing more complex lock-free operations is notoriously difficult. The
    CAS-based `getUniqueId` implementation is indeed lock-free. Threads only loop
    if the CAS fails, and the CAS can only fail if some thread successfully computed
    the unique identifier: this means that some other thread executed `getUniqueId`
    method successfully in a finite number of steps between the `get` and `compareAndSet`
    method calls. This fact proves lock-freedom.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个更正式的锁自由定义，你可以感受到为什么锁自由编程很难。证明一个操作是锁自由的并不容易，实现更复杂的锁自由操作更是出了名的困难。基于CAS的`getUniqueId`实现确实是锁自由的。线程只有在CAS失败时才会循环，而CAS只有在某些线程成功计算出唯一标识符时才会失败：这意味着在`get`和`compareAndSet`方法调用之间，某些其他线程在有限步骤内成功执行了`getUniqueId`方法。这一事实证明了锁自由。
- en: Implementing locks explicitly
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 显式实现锁
- en: In some cases, we really do want locks, and atomic variables allow us to implement
    locks that do not have to block the caller. The trouble with intrinsic object
    locks from [Chapter 2](ch02.html "Chapter 2. Concurrency on the JVM and the Java
    Memory Model"), *Concurrency on the JVM and the Java Memory Model*, is that a
    thread cannot inspect whether the object's intrinsic lock is currently acquired.
    Instead, a thread that calls `synchronized` is immediately blocked until the monitor
    becomes available. Sometimes, we would like our threads to execute a different
    action when a lock is unavailable.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，我们确实需要锁，原子变量允许我们实现不需要阻塞调用者的锁。来自[第2章](ch02.html "第2章。JVM和Java内存模型中的并发")，“JVM和Java内存模型中的并发”，的内置对象锁的问题是，线程无法检查对象的基本锁是否当前已被获取。相反，调用`synchronized`的线程会立即阻塞，直到监视器可用。有时，我们希望当锁不可用时，我们的线程执行不同的操作。
- en: 'We now turn to the concurrent filesystem API mentioned at the beginning of
    this chapter. Inspecting the state of a lock is something we need to do in an
    application such as a file manager. In the good old days of DOS and Norton Commander,
    starting a file copy blocked the entire user interface, so you could sit back,
    relax, and grab your Game Boy until the file transfer completes. Times change;
    modern file managers need to start multiple file transfers simultaneously, cancel
    existing transfers, or delete different files simultaneously. Our filesystem API
    must ensure that:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们转向本章开头提到的并发文件系统API。在文件管理器等应用程序中检查锁的状态是我们需要做的事情。在DOS和Norton Commander的黄金时代，开始文件复制会阻塞整个用户界面，所以你可以坐下来放松，拿起你的Game
    Boy，直到文件传输完成。时代在变化；现代文件管理器需要同时启动多个文件传输，取消现有传输或同时删除不同的文件。我们的文件系统API必须确保：
- en: If a thread is creating a new file, then that file cannot be copied or deleted
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个线程正在创建新文件，则该文件不能被复制或删除
- en: If one or more threads are copying a file, then the file cannot be deleted
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个或多个线程正在复制文件，则文件不能被删除
- en: If a thread is deleting a file, then the file cannot be copied
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个线程正在删除文件，则文件不能被复制
- en: Only a single thread in the file manager is deleting a file at a time
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件管理器中一次只有一个线程在删除文件
- en: 'The filesystem API will allow the concurrent copying and deleting of files.
    In this section, we will start by ensuring that only a single thread gets to delete
    a file. We model a single file or directory with the `Entry` class:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 文件系统API将允许文件的同时复制和删除。在本节中，我们将首先确保只有一个线程能够删除文件。我们使用`Entry`类来模拟单个文件或目录：
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The `isDir` field of the `Entry` class denotes whether the respective path
    is a file or a directory. The `state` field describes the file state: whether
    the file is idle, currently being created, copied, or is scheduled for deletion.
    We model these states with a sealed trait called `State`:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`Entry`类的`isDir`字段表示相应的路径是文件还是目录。`state`字段描述文件状态：文件是空闲的、正在创建、正在复制还是已计划删除。我们使用一个名为`State`的密封特质来模拟这些状态：'
- en: '[PRE12]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note that, in the case of the `Copying` state, the `n` field also tracks how
    many concurrent copies are in progress. When using atomic variables, it is often
    useful to draw a diagram of the different states that an atomic variable can be
    in. As illustrated in the following figure, `state` is set to `Creating` immediately
    after an `Entry` class is created and then becomes the `Idle` state. After that,
    an `Entry` object can jump between the `Copying` and `Idle` states indefinitely
    and, eventually, get from `Idle` to `Deleting`. After getting into the `Deleting`
    state, the `Entry` class can no longer be modified; this indicates that we are
    about to delete the file.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在`Copying`状态的情况下，`n`字段还跟踪正在进行中的并发副本数量。在使用原子变量时，通常很有用绘制一个图，展示原子变量可以处于的不同状态。如图所示，`state`在创建`Entry`类后立即设置为`Creating`状态，然后变为`Idle`状态。之后，`Entry`对象可以在`Copying`和`Idle`状态之间无限跳跃，并最终从`Idle`状态变为`Deleting`状态。进入`Deleting`状态后，`Entry`类将不能再被修改；这表明我们即将删除文件。
- en: '![Implementing locks explicitly](img/image_03_002.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![显式实现锁](img/image_03_002.jpg)'
- en: 'Let''s assume that we want to delete a file. There might be many threads running
    inside our file manager, and we want to avoid having two threads delete the same
    file. We will require the file being deleted to be in the `Idle` state and atomically
    change it to the `Deleting` state. If the file is not in the `Idle` state, we
    report an error. We will use the `logMessage` method, which is defined later;
    for now, we can assume that this method just calls our `log` statement:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要删除一个文件。在我们的文件管理器内部可能运行着许多线程，我们希望避免两个线程删除同一个文件。我们需要确保被删除的文件处于`Idle`状态，并且原子性地将其状态更改为`Deleting`状态。如果文件不在`Idle`状态，我们将报告一个错误。我们将使用`logMessage`方法，该方法将在后面定义；现在，我们可以假设这个方法只是调用我们的`log`语句：
- en: '[PRE13]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The `prepareForDelete` method starts by reading the `state` atomic reference
    variable and stores its value into a local variable, `s0`. It then checks whether
    the `s0` variable is the `Idle` state and attempts to atomically change the state
    to the `Deleting` state. Just like in the `getUniqueId` method example, a failed
    CAS indicates that another thread changed the `state` variable and the operation
    needs to be repeated. The file cannot be deleted if another thread is creating
    or copying it, so we report an error and return `false`. If another thread is
    already deleting the file, we only return `false`.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`prepareForDelete`方法首先读取`state`原子引用变量，并将其值存储到局部变量`s0`中。然后它检查`s0`变量是否是`Idle`状态，并尝试原子性地将状态更改为`Deleting`状态。就像在`getUniqueId`方法示例中一样，失败的CAS表明另一个线程已经更改了`state`变量，操作需要重复。如果另一个线程正在创建或复制文件，则文件不能被删除，因此我们报告一个错误并返回`false`。如果另一个线程已经在删除文件，我们只返回`false`。'
- en: The `state` atomic variable implicitly acts like a lock in this example, although
    it neither blocks the other threads nor busy-waits. If the `prepareForDelete`
    method returns `true`, we know that our thread can safely delete the file, as
    it is the only thread that changed the `state` variable value to `Deleting`. However,
    if the method returns `false`, we report an error in the file manager UI instead
    of blocking it.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，`state`原子变量隐式地充当锁，尽管它既不会阻塞其他线程也不会忙等待。如果`prepareForDelete`方法返回`true`，我们知道我们的线程可以安全地删除文件，因为它是唯一一个将`state`变量值更改为`Deleting`的线程。然而，如果方法返回`false`，我们将在文件管理器UI中报告错误而不是阻塞它。
- en: An important thing to note about the `AtomicReference` class is that it always
    uses reference equality when comparing the old object and the new object assigned
    to `state`.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 关于`AtomicReference`类的一个重要注意事项是，它在比较分配给`state`的旧对象和新对象时始终使用引用相等性。
- en: Note
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The CAS instructions on atomic reference variables always use reference equality
    and never call the `equals` method, even when the `equals` method is overridden.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在原子引用变量上的CAS指令始终使用引用相等性，并且永远不会调用`equals`方法，即使`equals`方法被重写。
- en: As an expert in sequential Scala programming, you might be tempted to implement
    `State` subtypes as case classes in order to get the `equals` method for free,
    but this does not affect the `compareAndSet` method operation.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 作为顺序Scala编程的专家，你可能会倾向于将`State`子类型实现为case类，以便免费获得`equals`方法，但这不会影响`compareAndSet`方法的操作。
- en: The ABA problem
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ABA问题
- en: The **ABA problem** is a situation in concurrent programming where two reads
    of the same memory location yield the same value A, which is used to indicate
    that the value of the memory location did not change between the two reads. This
    conclusion can be violated if other threads concurrently write some value B to
    the memory location, followed by the write of value A again. The ABA problem is
    usually a type of a race condition. In some cases, it leads to program errors.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**ABA问题** 是一种在并发编程中出现的情况，其中两次读取同一内存位置的值都得到相同的值 A，该值用于指示在这两次读取之间内存位置的值没有改变。如果其他线程并发地将某个值
    B 写入内存位置，然后再次写入值 A，则这个结论可能会被违反。ABA问题通常是竞争条件的一种类型。在某些情况下，它会导致程序错误。'
- en: Suppose that we implemented `Copying` as a class with a mutable field `n`. We
    might then be tempted to reuse the same `Copying` object for subsequent calls
    to `release` and `acquire`. This is almost certainly not a good idea!
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们将 `Copying` 实现为一个具有可变字段 `n` 的类。我们可能会倾向于为随后的 `release` 和 `acquire` 调用重用相同的
    `Copying` 对象。这几乎肯定不是一个好主意！
- en: 'Let''s assume that we have a hypothetical pair of methods called `releaseCopy`
    and `acquireCopy`. The `releaseCopy` method assumes that the `Entry` class is
    in the `Copying` state and changes the state from `Copying` to another `Copying`
    or `Idle` state. It then returns the old `Copying` object associated with the
    previous state:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一对假设的方法，称为 `releaseCopy` 和 `acquireCopy`。`releaseCopy` 方法假设 `Entry` 类处于
    `Copying` 状态，并将状态从 `Copying` 改变为另一个 `Copying` 或 `Idle` 状态。然后，它返回与先前状态关联的旧 `Copying`
    对象：
- en: '[PRE14]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The `acquireCopy` method takes a currently unused `Copying` object and attempts
    to replace the old state with the previously used `Copying` object:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`acquireCopy` 方法接受一个当前未使用的 `Copying` 对象，并尝试用之前使用的 `Copying` 对象替换旧状态：'
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Upon calling the `releaseCopy` method, a thread might store the old `Copying`
    object. Later, the same thread can reuse the old `Copying` object in the call
    to the `acquireCopy` method. Here, the programmer's intent could be to reduce
    the pressure on the garbage collector by allocating fewer `Copying` objects. However,
    this leads to the ABA problem, as we will describe further.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用 `releaseCopy` 方法时，一个线程可能会存储旧的 `Copying` 对象。稍后，同一个线程可以在调用 `acquireCopy` 方法时重用旧的
    `Copying` 对象。在这里，程序员的意图可能是通过分配较少的 `Copying` 对象来减少垃圾收集器的压力。然而，这会导致我们下面将要描述的ABA问题。
- en: We consider two threads **T1** and **T2**, which call the `releaseCopy` method.
    They both read the state of the `Entry` object and create a new state object `nstate`,
    which is `Idle`. Let's assume that the thread **T1** executes the `compareAndSet`
    operation first and returns the old `Copying` object `c` from the `releaseCopy`
    method. Next, let's assume that a third thread **T3** calls the `acquireCopy`
    method and changes the state of the `Entry` object to `Copying(1)`. If the thread
    **T1** now calls the `acquireCopy` method with the old `Copying` object `c`, the
    state of the `Entry` object becomes `Copying(2)`. Note that, at this point, the
    old `Copying` object `c` is once again stored inside the atomic variable `state`.
    If the thread **T1** now attempts to call `compareAndSet`, it will succeed and
    set the state of the `Entry` object to `Idle`. Effectively, the last `compareAndSet`
    operation changes the state from `Copying(2)` to `Idle`, so one acquire is lost.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑两个线程 **T1** 和 **T2**，它们都调用了 `releaseCopy` 方法。它们都读取 `Entry` 对象的状态，并创建一个新的状态对象
    `nstate`，它是 `Idle`。假设线程 **T1** 首先执行 `compareAndSet` 操作，并从 `releaseCopy` 方法返回旧的
    `Copying` 对象 `c`。接下来，假设第三个线程 **T3** 调用 `acquireCopy` 方法并将 `Entry` 对象的状态更改为 `Copying(1)`。如果线程
    **T1** 现在用旧的 `Copying` 对象 `c` 调用 `acquireCopy` 方法，则 `Entry` 对象的状态变为 `Copying(2)`。请注意，在这个时候，旧的
    `Copying` 对象 `c` 再次存储在原子变量 `state` 中。如果线程 **T1** 现在尝试调用 `compareAndSet`，它将成功并将
    `Entry` 对象的状态设置为 `Idle`。实际上，最后的 `compareAndSet` 操作将状态从 `Copying(2)` 改变为 `Idle`，因此丢失了一个获取操作。
- en: 'This scenario is shown in the following figure:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了这种情况：
- en: '![The ABA problem](img/image_03_003.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![ABA问题](img/image_03_003.jpg)'
- en: In the preceding example, the ABA problem manifests itself in the execution
    of thread **T2**. Having first read the value of the `state` field in the `Entry`
    object with the `get` method and with the `compareAndSet` method later, thread
    **T2** assumes that the value of the `state` field has not changed between these
    two writes. In this case, this leads to a program error.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，ABA 问题在线程 **T2** 的执行中表现出来。线程 **T2** 首先使用 `get` 方法读取 `Entry` 对象中 `state`
    字段的值，然后使用 `compareAndSet` 方法读取，假设在这两次写入之间 `state` 字段的值没有改变。在这种情况下，这会导致程序错误。
- en: 'There is no general technique to avoid the ABA problem, so we need to guard
    the program against it on a per-problem basis. Still, the following guidelines
    are useful when avoiding the ABA problem in a managed runtime, such as JVM:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 没有一套通用的技术可以避免ABA问题，因此我们需要针对每个问题对程序进行保护。尽管如此，以下指南在避免管理运行时（如JVM）中的ABA问题时非常有用：
- en: Create new objects before assigning them to the `AtomicReference` objects
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在将对象分配给`AtomicReference`对象之前创建新对象
- en: Store immutable objects inside the `AtomicReference` objects
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`AtomicReference`对象内部存储不可变对象
- en: Avoid assigning a value that was previously already assigned to an atomic variable
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免将之前已分配给原子变量的值分配给原子变量
- en: If possible, make updates to numeric atomic variables monotonic, that is, either
    strictly decreasing or strictly increasing with respect to the previous value
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果可能，使数值原子变量的更新单调，即相对于前一个值严格递减或严格递增
- en: There are other techniques in order to avoid the ABA problem, such as pointer
    masking and hazard pointers, but these are not applicable to JVM.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免ABA问题，还有其他技术，例如指针屏蔽和危害指针，但这些技术不适用于JVM。
- en: In some cases, the ABA problem does not affect the correctness of the algorithm;
    for example, if we change the `Idle` class to a singleton object, the `prepareForDelete`
    method will continue to work correctly. Still, it is a good practice to follow
    the preceding guidelines, because they simplify the reasoning about lock-free
    algorithms.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，ABA问题不会影响算法的正确性；例如，如果我们将`Idle`类改为单例对象，`prepareForDelete`方法将继续正常工作。尽管如此，遵循前面的指南是一个好的实践，因为它们简化了对无锁算法的推理。
- en: Lazy values
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 懒值
- en: You should be familiar with lazy values from sequential programming in Scala.
    Lazy values are the value declarations that are initialized with their right-hand
    side expression when the lazy value is read for the first time. This is unlike
    regular values, which are initialized the moment they are created. If a lazy value
    is never read inside the program, it is never initialized and it is not necessary
    to pay the cost of its initialization. Lazy values allow you to implement data
    structures such as lazy streams; they improve complexities of persistent data
    structures, can boost the program's performance, and help avoid initialization
    order problems in Scala's mix-in composition.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该熟悉Scala中的顺序编程中的懒值。懒值是在懒值首次被读取时使用其右侧表达式初始化的值声明。这与常规值不同，常规值在创建时立即初始化。如果一个懒值在程序内部从未被读取，它就不会被初始化，也不需要支付其初始化的成本。懒值允许你实现如懒流等数据结构；它们提高了持久数据结构的复杂度，可以提高程序的性能，并帮助避免Scala混合组合中的初始化顺序问题。
- en: 'Lazy values are extremely useful in practice, and you will often deal with
    them in Scala. However, using them in concurrent programs can have some unexpected
    interactions, and this is the topic of this section. Note that lazy values must
    retain the same semantics in a multithreaded program; a lazy value is initialized
    only when a thread accesses it, and it is initialized at most once. Consider the
    following motivating example in which two threads access two lazy values, which
    are `obj` and `non`:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 懒值在实践中非常有用，你将在Scala中经常处理它们。然而，在并发程序中使用它们可能会产生一些意外的交互，这正是本节的主题。请注意，懒值在多线程程序中必须保持相同的语义；懒值仅在线程访问它时初始化，并且最多初始化一次。考虑以下激励示例，其中两个线程访问两个懒值，分别是`obj`和`non`：
- en: '[PRE16]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You know from sequential Scala programming that it is a good practice to initialize
    the lazy value with an expression that does not depend on the current state of
    the program. The lazy value `obj` follows this practice, but the lazy value `non`
    does not. If you run this program once, you might notice that `non` lazy value
    is initialized with the name of the main thread:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 你从顺序Scala编程中知道，使用不依赖于程序当前状态的表达式初始化懒值是一个好的实践。懒值`obj`遵循这一实践，但懒值`non`则不遵循。如果你运行这个程序一次，你可能会注意到`non`懒值被初始化为主线程的名称：
- en: '[PRE17]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Running the program again shows you that `non` is initialized by the worker
    thread:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 再次运行程序会显示`non`是由工作线程初始化的：
- en: '[PRE18]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'As the previous example shows you, lazy values are affected by non-determinism.
    Non-deterministic lazy values are a recipe for trouble, but we cannot always avoid
    them. Lazy values are deeply tied into Scala, because singleton objects are implemented
    as lazy values under the hood:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如前例所示，懒值会受到非确定性的影响。非确定性的懒值是麻烦的根源，但我们无法总是避免它们。懒值与 Scala 深度绑定，因为单例对象在底层被实现为懒值：
- en: '[PRE19]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Running this program reveals that the `Lazy` initializer runs when the object
    is first referenced in the third line and not when it is declared. Getting rid
    of singleton objects in your Scala code would be too restrictive, and singleton
    objects are often large; they can contain all kinds of potentially non-deterministic
    code.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此程序会揭示 `Lazy` 初始化器是在对象在第三行首次引用时运行的，而不是在声明时。在 Scala 代码中去除单例对象会过于限制，而且单例对象通常很大；它们可以包含各种可能具有非确定性的代码。
- en: 'You might think that a little bit of non-determinism is something we can live
    with. However, this non-determinism can be dangerous. In the existing Scala versions,
    lazy values and singleton objects are implemented with the so-called *double-checked
    locking idiom* under the hood. This concurrent programming pattern ensures that
    a lazy value is initialized by at most one thread when it is first accessed. Thanks
    to this pattern, upon initializing the lazy value, its subsequent reads are cheap
    and do not need to acquire any locks. Using this idiom, a single lazy value declaration,
    which is `obj` from the previous example, is translated by the Scala compiler
    as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会认为一点非确定性是可以接受的。然而，这种非确定性可能很危险。在现有的 Scala 版本中，懒值和单例对象在底层使用所谓的 *双重检查锁定模式*
    实现。这种并发编程模式确保当懒值首次被访问时，最多只有一个线程对其进行初始化。多亏了这个模式，初始化懒值后，后续的读取操作既便宜又不需要获取任何锁。使用这个模式，上一个例子中的单个懒值声明
    `obj` 被Scala编译器翻译如下：
- en: '[PRE20]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The Scala compiler introduces an additional volatile field, `_bitmap`, when
    a class contains lazy fields. The private `_obj` field that holds the value is
    uninitialized at first. After the `obj` getter assigns a value to the `_obj` field,
    it sets the `_bitmap` field to `true` to indicate that the lazy value was initialized.
    Other subsequent invocations of the getter know whether they can read the lazy
    value from the `_obj` field by checking the `_bitmap` field.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个类包含懒加载字段时，Scala 编译器会引入一个额外的 volatile 字段，即 `_bitmap`。用于存储值的私有 `_obj` 字段最初未初始化。在
    `obj` 获取器将值赋给 `_obj` 字段之后，它会将 `_bitmap` 字段设置为 `true` 以指示懒值已被初始化。后续对获取器的调用通过检查
    `_bitmap` 字段来了解它们是否可以从 `_obj` 字段中读取懒值。
- en: The getter `obj` starts by checking whether the `_bitmap` field is `true`. If
    `_bitmap` field is `true`, then the lazy value was already initialized and the
    getter returns `_obj`. Otherwise, the getter `obj` attempts to obtain the intrinsic
    lock of the enclosing object, in this case, `LazyValsUnderTheHood`. If the `_bitmap`
    field is still not set from within the `synchronized` block, the getter evaluates
    the `new AnyRef` expression, assigns it to `_obj`, and sets `_bitmap` to `true`.
    After this point, the lazy value is considered initialized. Note that the `synchronized`
    statement, together with the check that the `_bitmap` field is `false`, ensure
    that a single thread at most initializes the lazy value.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 获取器 `obj` 首先检查 `_bitmap` 字段是否为 `true`。如果 `_bitmap` 字段为 `true`，则懒值已被初始化，获取器返回
    `_obj`。否则，获取器 `obj` 尝试获取封装对象的内在锁，在本例中为 `LazyValsUnderTheHood`。如果 `_bitmap` 字段在
    `synchronized` 块内部仍未设置，获取器将评估 `new AnyRef` 表达式，将其赋给 `_obj`，并将 `_bitmap` 设置为 `true`。在此之后，懒值被认为是已初始化的。请注意，`synchronized`
    语句以及检查 `_bitmap` 字段是否为 `false` 确保最多只有一个线程初始化懒值。
- en: Note
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The double-checked locking idiom ensures that every lazy value is initialized
    by at most a single thread.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 双重检查锁定模式确保每个懒值最多由一个线程初始化。
- en: 'This mechanism is robust and ensures that lazy values are both thread-safe
    and efficient. However, synchronization on the enclosing object can cause problems.
    Consider the following example in which two threads attempt to initialize lazy
    values `A.x` and `B.y` at the same time:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 此机制是健壮的，并确保懒值既线程安全又高效。然而，对封装对象的同步可能会导致问题。考虑以下示例，其中两个线程试图同时初始化懒值 `A.x` 和 `B.y`：
- en: '[PRE21]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In a sequential setting, accessing either `A.x` or `B.y` results in a stack
    overflow. Initializing `A.x` requires calling the getter for `B.y`, which is not
    initialized. Initialization of `B.y` calls the getter for `A.x` and continues
    in infinite recursion. However, this example was carefully tuned to access both
    `A.x` and `B.y` at the same time by both the main thread and the worker thread.
    Prepare to restart SBT. After both `A` and `B` are initialized, their monitors
    are acquired simultaneously by two different threads. Each of these threads needs
    to acquire a monitor owned by the other thread. Neither thread lets go of its
    own monitor, and this results in a deadlock.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在顺序设置中，访问`A.x`或`B.y`会导致栈溢出。初始化`A.x`需要调用`B.y`的getter，而`B.y`尚未初始化。`B.y`的初始化会调用`A.x`的getter，并继续无限递归。然而，这个例子被仔细调整，使得主线程和工作者线程同时访问`A.x`和`B.y`。准备重启SBT。当`A`和`B`都初始化后，它们的监视器同时被两个不同的线程获取。每个线程都需要获取另一个线程拥有的监视器。两个线程都不愿意释放自己的监视器，这导致了死锁。
- en: Cyclic dependencies between lazy values are unsupported in both sequential and
    concurrent Scala programs. The difference is that they potentially manifest themselves
    as deadlocks instead of stack overflows in concurrent programming.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在顺序和并发Scala程序中，都不支持懒值之间的循环依赖。区别在于，它们可能会在并发编程中表现为死锁，而不是栈溢出。
- en: Tip
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Avoid cyclic dependencies between lazy values, as they can cause deadlocks.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 避免在懒值之间产生循环依赖，因为它们可能导致死锁。
- en: 'The previous example is not something you are likely to do in your code, but
    cyclic dependencies between lazy values and singleton objects can be much more
    devious and harder to spot. In fact, there are other ways to create dependencies
    between lazy values besides directly accessing them. A lazy value initialization
    expression can block a thread until some other value becomes available. In the
    following example, the initialization expression uses the `thread` statement from
    [Chapter 2](ch02.html "Chapter 2. Concurrency on the JVM and the Java Memory Model"),
    *Concurrency on the JVM and the Java Memory Model*, to start a new thread and
    join it:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的例子不太可能在你的代码中实现，但懒值和单例对象之间的循环依赖可能更加隐蔽和难以发现。实际上，除了直接访问它们之外，还有其他方法可以在懒值之间创建依赖。懒值初始化表达式可以阻塞一个线程，直到某个其他值可用。在以下示例中，初始化表达式使用[第2章](ch02.html
    "第2章。JVM和Java内存模型上的并发")中的`thread`语句，*JVM和Java内存模型上的并发*，来启动一个新线程并与之连接：
- en: '[PRE22]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Although there is only a single lazy value in this example, running it inevitably
    results in a deadlock. The new thread attempts to access `x`, which is not initialized,
    so it attempts to call the `synchronized` statement on the `LazyValsAndBlocking`
    object and blocks, because the main thread already holds this lock. On the other
    hand, the main thread waits for the other thread to terminate, so neither thread
    can progress.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个例子中只有一个懒值，但运行它不可避免地会导致死锁。新线程试图访问尚未初始化的`x`，因此它试图在`LazyValsAndBlocking`对象上调用`synchronized`语句并阻塞，因为主线程已经持有这个锁。另一方面，主线程等待其他线程终止，因此两个线程都无法继续。
- en: While the deadlock is relatively obvious in this example, in a larger code base,
    circular dependencies can easily sneak past your guard. In some cases, they might
    even be non-deterministic and occur only in particular system states. To guard
    against them, avoid blocking in the lazy value expression altogether.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在这个例子中死锁相对明显，但在更大的代码库中，循环依赖可能很容易悄悄绕过你的防线。在某些情况下，它们甚至可能是非确定性的，只在特定的系统状态下发生。为了防止它们，完全避免在懒值表达式中进行阻塞。
- en: Tip
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Never invoke blocking operations inside lazy value initialization expressions
    or singleton object constructors.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 永远不要在懒值初始化表达式或单例对象构造函数中调用阻塞操作。
- en: 'Lazy values cause deadlocks even when they do not block themselves. In the
    following example, the main thread calls the `synchronized` statement on the enclosing
    object, starts a new thread, and waits for its termination. The new thread attempts
    to initialize the lazy value `x`, but it cannot acquire the monitor until the
    main thread releases it:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 即使懒值本身不阻塞，它们也可能导致死锁。在以下示例中，主线程在封装对象上调用`synchronized`语句，启动一个新线程，并等待其终止。新线程试图初始化懒值`x`，但它在主线程释放它之前无法获取监视器：
- en: '[PRE23]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This kind of deadlock is not inherent to lazy values and can happen with arbitrary
    code that uses `synchronized` statements. The problem is that the `LazyValsAndMonitors`
    lock is used in two different contexts: as a lazy value initialization lock and
    as the lock for some custom logic in the main thread. To prevent two unrelated
    software components from using the same lock, always call `synchronized` on separate
    private objects that exist solely for this purpose.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这种死锁并非固有于懒值，并且可以发生在使用`synchronized`语句的任意代码中。问题是`LazyValsAndMonitors`锁在两个不同的上下文中使用：作为懒值初始化锁以及作为主线程中某些自定义逻辑的锁。为了防止两个不相关的软件组件使用相同的锁，始终在仅为此目的存在的单独私有对象上调用`synchronized`。
- en: Tip
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Never call `synchronized` on publicly available objects; always use a dedicated,
    private dummy object for synchronization.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 从不调用`synchronized`在公开可用的对象上；始终使用一个专用、私有的虚拟对象进行同步。
- en: Although we rarely use separate objects for synchronization in this book, to
    keep the examples concise, you should strongly consider doing this in your programs.
    This tip is useful outside the context of lazy values; keeping your locks private
    reduces the possibility of deadlocks.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在这本书中很少使用单独的对象进行同步，但为了使示例简洁，您应该强烈考虑在您的程序中这样做。这个技巧在懒值之外的环境中也很有用；保持您的锁私有可以减少死锁的可能性。
- en: Concurrent collections
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发集合
- en: 'As you can conclude from the discussion on the Java Memory Model in [Chapter
    2](ch02.html "Chapter 2. Concurrency on the JVM and the Java Memory Model"), *Concurrency
    on the JVM and the Java Memory Model*, modifying the Scala standard library collections
    from different threads can result in arbitrary data corruption. Standard collection
    implementations do not use any synchronization. Data structures underlying mutable
    collections can be quite complex; predicting how multiple threads affect the collection
    state in the absence of synchronization is neither recommended nor possible. We
    will demonstrate this by letting two threads add numbers to the `mutable.ArrayBuffer`
    collection:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可以从[第2章](ch02.html "第2章。JVM和Java内存模型上的并发")中关于Java内存模型的讨论中得出结论，*JVM和Java内存模型上的并发*，从不同的线程修改Scala标准库集合可能会导致任意数据损坏。标准集合实现不使用任何同步。可变集合底层的结构可能相当复杂；在没有同步的情况下预测多个线程如何影响集合状态既不推荐也不可行。我们将通过让两个线程向`mutable.ArrayBuffer`集合添加数字来演示这一点：
- en: '[PRE24]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Instead of printing an array buffer with 20 different elements, this example
    arbitrarily prints different results or throws exceptions each time it runs. The
    two threads modify the internal array buffer state simultaneously and cause data
    corruption.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 与打印包含20个不同元素的数组缓冲区不同，这个示例在每次运行时都会任意打印不同的结果或抛出异常。两个线程同时修改内部数组缓冲区状态，导致数据损坏。
- en: Tip
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Never use mutable collections from several different threads without applying
    proper synchronization.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 从不使用适当同步的情况下从多个不同的线程使用可变集合。
- en: 'We can restore synchronization in several ways. First, we can use **immutable
    collections** along with synchronization to share them between threads. For example,
    we can store immutable data structures inside atomic reference variables. In the
    following code snippet, we introduce an `AtomicBuffer` class that allows concurrent
    `+=` operations. Appending reads the current immutable `List` value from the atomic
    reference buffer and creates a new `List` object containing `x`. It then invokes
    a CAS operation to atomically update the buffer, retrying the operation if the
    CAS operation is not successful:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过几种方式恢复同步。首先，我们可以使用**不可变集合**以及同步来在线程之间共享它们。例如，我们可以将不可变数据结构存储在原子引用变量中。在下面的代码片段中，我们引入了一个`AtomicBuffer`类，它允许并发`+=`操作。追加操作从原子引用缓冲区中读取当前的不可变`List`值，并创建一个新的包含`x`的`List`对象。然后它调用CAS操作以原子方式更新缓冲区，如果CAS操作不成功则重试操作：
- en: '[PRE25]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: While using atomic variables or the `synchronized` statements with immutable
    collections is simple, it can lead to scalability problems when many threads access
    an atomic variable at once.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然使用原子变量或与不可变集合一起使用`synchronized`语句很简单，但当许多线程同时访问原子变量时，它可能导致可伸缩性问题。
- en: 'If we intend to continue using mutable collections, we need to add `synchronized`
    statements around calls to collection operations:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们打算继续使用可变集合，我们需要在调用集合操作周围添加`synchronized`语句：
- en: '[PRE26]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This approach can be satisfactory, provided that collection operations do not
    block inside `synchronized`. In fact, this approach allows you to implement guarded
    blocks around collection operations, as we saw in the `SynchronizedPool` example
    in [Chapter 2](ch02.html "Chapter 2. Concurrency on the JVM and the Java Memory
    Model"), *Concurrency on the JVM and the Java Memory Model*. However, using the `synchronized`
    statement can also lead to scalability problems when many threads attempt to acquire
    the lock at once.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法在集合操作不会在`synchronized`内部阻塞的情况下是可以接受的。事实上，这种方法允许你在集合操作周围实现受保护块，正如我们在[第2章](ch02.html
    "第2章。JVM和Java内存模型上的并发")中看到的`SynchronizedPool`示例，*JVM和Java内存模型上的并发*。然而，当许多线程同时尝试获取锁时，使用`synchronized`语句也可能导致可伸缩性问题。
- en: Finally, concurrent collections are collection implementations with operations
    that can be safely invoked from different threads without synchronization. In
    addition to the thread-safe versions of basic collection operations, some concurrent
    collections provide more expressive operations. Conceptually, the same operations
    can be achieved using atomic primitives, `synchronized` statements, and guarded
    blocks, but concurrent collections ensure far better performance and scalability.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，并发集合是一组具有操作，这些操作可以在不同线程中安全调用的集合实现，无需同步。除了基本集合操作的线程安全版本之外，一些并发集合还提供了更丰富的操作。从概念上讲，相同的操作可以使用原子原语、`synchronized`语句和受保护块来实现，但并发集合确保了更好的性能和可伸缩性。
- en: Concurrent queues
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发队列
- en: A common pattern used in concurrent programming is the **producer-consumer pattern**.
    In this pattern, the responsibility for different parts of the computational workload
    is divided across several threads. In an FTP server, one or more threads can be
    responsible for reading chunks of a large file from the disk. Such threads are
    called producers. Another dedicated set of threads can bear the responsibility
    of sending file chunks through the network. We call these threads consumers. In
    their relationship, consumers must react to work elements created by the producers.
    Often, the two are not perfectly synchronized, so work elements need to be buffered
    somewhere.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在并发编程中常用的一个模式是**生产者-消费者模式**。在这个模式中，计算工作负载的不同部分被分配到多个线程。在一个FTP服务器中，一个或多个线程可能负责从磁盘读取大文件的块。这样的线程被称为生产者。另一组专门的线程可以承担通过网络发送文件块的责任。我们称这些线程为消费者。在这些线程的关系中，消费者必须对生产者创建的工作元素做出反应。通常，这两个部分并不完全同步，因此需要在工作元素被缓冲的地方。
- en: The concurrent collection that supports this kind of buffering is called a **concurrent
    queue**. There are three main operations we expect from a concurrent queue. The
    enqueue operation allows producers to add work elements to the queue, and the
    dequeue operation allows consumers to remove them. Finally, sometimes we want
    to check whether the queue is empty or inspect the value of the next item without
    changing the queue's contents. Concurrent queues can be **bounded**, which means
    that they can only contain a maximum number of elements, or they can be **unbounded**,
    which means that they can grow indefinitely. When a bounded queue contains the
    maximum number of elements, we say it is full. The semantics of the various versions
    of enqueue and dequeue operations differ with respect to what happens when we
    try to enqueue to a full queue or dequeue from an empty queue. This special case
    needs to be handled differently by the concurrent queue. In single-threaded programming,
    sequential queues usually return a special value such as `null` or `false` when
    they are full or empty, or simply throw an exception. In concurrent programming,
    the absence of elements in the queue can indicate that the producer has not yet
    enqueued an element, although it might enqueue it in the future. Similarly, a
    full queue means that the consumer did not yet remove elements but will do so
    later. For this reason, some concurrent queues have *blocking* enqueue and dequeue
    implementations, which block the caller until the queue is non-full or non-empty,
    respectively.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 支持这种缓冲的并发集合被称为 **并发队列**。我们期望从并发队列中得到三个主要操作。入队操作允许生产者向队列添加工作元素，而出队操作允许消费者移除它们。最后，有时我们想要检查队列是否为空或检查下一个元素的值而不改变队列的内容。并发队列可以是
    **有界** 的，这意味着它们只能包含最大数量的元素，或者它们可以是 **无界** 的，这意味着它们可以无限增长。当一个有界队列包含最大数量的元素时，我们称其为满。各种入队和出队操作的语义在尝试向满队列入队或从空队列出队时有所不同。这个特殊情况需要由并发队列以不同的方式处理。在单线程编程中，当队列满或空时，顺序队列通常会返回特殊值，如
    `null` 或 `false`，或者简单地抛出异常。在并发编程中，队列中元素的不存在可能表明生产者尚未入队元素，尽管它可能在将来入队。同样，满队列意味着消费者尚未移除元素，但稍后将会这样做。因此，一些并发队列具有
    *阻塞* 的入队和出队实现，分别阻塞调用者直到队列非满或非空。
- en: JDK represents multiple efficient concurrent queue implementations in the `java.util.concurrent`
    package with the `BlockingQueue` interface. Rather than reinventing the wheel
    with its own concurrent queue implementations, Scala adopts these concurrent queues
    as part of its concurrency utilities and it does not currently have a dedicated
    trait for blocking queues.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: JDK 使用 `java.util.concurrent` 包中的 `BlockingQueue` 接口表示多个高效的并发队列实现。Scala 而不是重新发明轮子，使用自己的并发队列实现，它将并发队列作为其并发工具的一部分采用，并且目前没有为阻塞队列提供专门的特质。
- en: The `BlockingQueue` interface contains several versions of the basic concurrent
    queue operations, each with slightly different semantics. Different variants of
    their enqueue, dequeue, and inspect-next methods are summarized in the following
    table. The inspect, dequeue, and enqueue versions are called `element`, `remove`,
    and `add` in the first column; they throw an exception when the queue is empty
    or full. Methods such as `poll` and `offer` return special values such as `null`
    or `false`. Timed versions of these methods block the caller for a specified duration
    before returning an element or a special value, and blocking methods block the
    calling thread until the queue becomes non-empty or non-full.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`BlockingQueue` 接口包含了几种基本并发队列操作的不同版本，每个版本都有略微不同的语义。它们的入队、出队和查看下一个元素的各个不同变体总结在下表中。第一列中的
    `inspect`、`dequeue` 和 `enqueue` 版本分别称为 `element`、`remove` 和 `add`；当队列空或满时，它们会抛出异常。例如
    `poll` 和 `offer` 这样的方法会返回特殊值，如 `null` 或 `false`。这些方法的定时版本在返回元素或特殊值之前会阻塞调用者指定的时间长度，而阻塞方法会阻塞调用线程，直到队列非空或非满。'
- en: '| **Operation** | **Exception** | **Special value** | **Timed** | **Blocking**
    |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| **操作** | **异常** | **特殊值** | **定时** | **阻塞** |'
- en: '| Dequeue | remove(): T | poll(): T | poll(t: Long, u:  TimeUnit): T | take():
    T |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 出队 | remove(): T | poll(): T | poll(t: Long, u: TimeUnit): T | take(): T
    |'
- en: '| Enqueue | add(x: T) | offer(x: T):  Boolean | offer(x: T, t: Long,  u: TimeUnit)
    | put(x: T) |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 入队 | add(x: T) | offer(x: T): Boolean | offer(x: T, t: Long, u: TimeUnit)
    | put(x: T) |'
- en: '| Inspect | element: T | peek: T | N/A | N/A |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 查看 | element: T | peek: T | N/A | N/A |'
- en: The `ArrayBlockingQueue` class is a concrete implementation of a bounded blocking
    queue. When creating the `ArrayBlockingQueue` class, we need to specify its capacity,
    which is the number of elements in the queue when it is full. If producers can
    potentially create elements faster than the consumers can process them, we need
    to use bounded queues. Otherwise, the queue size can potentially grow to the point
    where it consumes all the available memory in the program.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '`ArrayBlockingQueue`类是有界阻塞队列的具体实现。在创建`ArrayBlockingQueue`类时，我们需要指定其容量，即队列满时的元素数量。如果生产者可能比消费者更快地创建元素，我们需要使用有界队列。否则，队列大小可能会增长到消耗程序中所有可用内存的程度。'
- en: Another concurrent queue implementation is called `LinkedBlockingQueue`. This
    queue is unbounded, and we can use it when we are sure that the consumers work
    much faster than the producers. This queue is an ideal candidate for the logging
    component of our filesystem's API. Logging must return feedback about the execution
    to the user. In a file manager, logging produces messages to the user inside the
    UI, while in an FTP server it sends feedback over the network. To keep the example
    simple, we just print the messages to the standard output.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个并发队列实现称为`LinkedBlockingQueue`。这个队列是无界的，当我们确信消费者比生产者工作得更快时，我们可以使用它。这个队列是我们文件系统API的日志组件的理想候选者。日志必须向用户返回关于执行的反馈。在文件管理器中，日志向用户在UI中产生消息，而在FTP服务器中，它通过网络发送反馈。为了使示例简单，我们只需将消息打印到标准输出。
- en: 'We use the `LinkedBlockingQueue` collection to buffer various messages from
    different components of the filesystem API. We declare the queue to a private
    variable called `messages`. A separate daemon thread, called `logger`, repetitively
    calls the `take` method on messages. Recall from the previous table that the `take`
    method is blocking; it blocks the `logger` thread until there is a message in
    the queue. The `logger` thread then calls `log` to print the message. The `logMessage`
    method, which we used in the `prepareForDelete` method earlier, simply calls the
    `offer` method on the `messages` queue. We could have alternatively called `add`
    or `put`. We know that the queue is unbounded, so these methods never throw or
    block:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`LinkedBlockingQueue`集合来缓冲来自文件系统API不同组件的各种消息。我们将队列声明为一个名为`messages`的私有变量。一个单独的守护线程，称为`logger`，重复调用消息上的`take`方法。回想一下，从之前的表中我们知道`take`方法是阻塞的；它会在队列中有消息之前阻塞`logger`线程。然后`logger`线程调用`log`来打印消息。我们之前在`prepareForDelete`方法中使用的`logMessage`方法只是简单地调用`messages`队列上的`offer`方法。我们也可以调用`add`或`put`。我们知道队列是无界的，所以这些方法永远不会抛出异常或阻塞：
- en: '[PRE27]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We place these methods and the previously defined `prepareForDelete` method
    into the `FileSystem` class. To test this, we can simply instantiate our `FileSystem`
    class and call the `logMessage` method. Once the main thread terminates, the `logger`
    thread automatically stops:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些方法和之前定义的`prepareForDelete`方法放入`FileSystem`类中。为了测试这一点，我们可以简单地实例化我们的`FileSystem`类并调用`logMessage`方法。一旦主线程终止，`logger`线程会自动停止：
- en: '[PRE28]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'An important difference between sequential queues and concurrent queues is
    that concurrent queues have **weakly consistent iterators**. An iterator created
    with the `iterator` method traverses the elements that were in the queue at the
    moment the `iterator` method was created. However, if there is an enqueue or dequeue
    operation before the traversal is over, all bets are off, and the iterator might
    or might not reflect any modifications. Consider the following example, in which
    one thread traverses the concurrent queue while another thread dequeues its elements:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序队列和并发队列之间的重要区别在于，并发队列有**弱一致性迭代器**。使用`iterator`方法创建的迭代器遍历的是在创建迭代器方法时的队列中的元素。然而，如果在遍历完成之前有入队或出队操作，所有假设都不成立，迭代器可能或可能不会反映任何修改。考虑以下示例，其中一个线程遍历并发队列，而另一个线程正在出队其元素：
- en: '[PRE29]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The main thread creates a queue with 5,500 elements. It then starts a concurrent
    task that creates an iterator and prints the elements one by one. At the same
    time, the main thread starts removing all the elements from the queue in the same
    order. In one of our thread runs, the iterator returns `1`, `4,779`, and `5,442`.
    This does not make sense, because the queue never contained these three elements
    alone; we would expect to see a suffix that has the range of `1` to `5,500`. We
    say that the iterator is not consistent. It is never corrupt and does not throw
    exceptions, but it fails to return a consistent set of elements that were in the
    queue at some point. With a few notable exceptions, this effect can happen when
    using any concurrent data structure.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 主线程创建了一个包含5,500个元素的队列。然后它启动一个并发任务，创建一个迭代器并逐个打印元素。与此同时，主线程以相同的顺序开始从队列中移除所有元素。在我们的一次线程运行中，迭代器返回了`1`、`4,779`和`5,442`。这没有意义，因为队列从未单独包含这三个元素；我们预计会看到一个范围从`1`到`5,500`的后缀。我们说迭代器是不一致的。它从未损坏且不抛出异常，但它未能返回在某个时刻队列中存在的元素的一致集合。除了少数明显的例外，这种效果在使用任何并发数据结构时都可能发生。
- en: Tip
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Use iterators on concurrent data structures only when you can ensure that no
    other thread will modify the data structure from the point where the iterator
    was created until the point where the iterator's `hasNext` method returns `false`.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在你能够确保没有其他线程将在迭代器创建点和迭代器的`hasNext`方法返回`false`点之间修改数据结构时，才应在并发数据结构上使用迭代器。
- en: The `CopyOnWriteArrayList` and `CopyOnWriteArraySet` collections in JDK are
    exceptions to this rule, but they copy the underlying data whenever the collection
    is mutated and can be slow. Later in this section, we will see a concurrent collection
    from the `scala.collection.concurrent` package called `TrieMap`, which creates
    consistent iterators without copying the underlying dataset and allows arbitrary
    modifications during the traversal.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: JDK中的`CopyOnWriteArrayList`和`CopyOnWriteArraySet`集合是这一规则的例外，但每当集合被修改时，它们都会复制底层数据，这可能很慢。在本节的后面，我们将看到来自`scala.collection.concurrent`包的并发集合`TrieMap`，它创建一致的迭代器，而不复制底层数据集，并在遍历期间允许任意修改。
- en: Concurrent sets and maps
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发集合和映射
- en: Concurrent API designers strive to provide programmers with interfaces that
    resemble those from sequential programming. We have seen that this is the case
    with concurrent queues. As the main use case for concurrent queues is the producer-consumer
    pattern, the `BlockingQueue` interface additionally provides blocking versions
    of methods that are already known from sequential queues. Concurrent maps and
    concurrent sets are map and set collections, respectively, that can be safely
    accessed and modified by multiple threads. Like concurrent queues, they retain
    the API from the corresponding sequential collections. Unlike concurrent queues,
    they do not have blocking operations. The reason is that their principal use case
    is not the producer-consumer pattern, but encoding the program state.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 并发API设计者努力为程序员提供类似于顺序编程的接口。我们已经看到，这在并发队列中是成立的。由于并发队列的主要用例是生产者-消费者模式，`BlockingQueue`接口还提供了来自顺序队列的已知方法的阻塞版本。并发映射和并发集合分别是可以安全访问和修改的映射和集合集合。与并发队列一样，它们保留了相应顺序集合的API。与并发队列不同，它们没有阻塞操作。原因是它们的主要用例不是生产者-消费者模式，而是编码程序状态。
- en: 'The `concurrent.Map` trait in the `scala.collection` package represents different
    concurrent map implementations. In our filesystem API, we use it to track the
    files that exist in the filesystem as follows:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '`scala.collection`包中的`concurrent.Map`特质代表了不同的并发映射实现。在我们的文件系统API中，我们用它来跟踪文件系统中的文件，如下所示：'
- en: '[PRE30]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This concurrent map contains paths and their corresponding `Entry` objects.
    These are the same `Entry` objects that `prepareForDelete` used earlier. The concurrent
    `files` map is populated when the `FileSystem` object is created.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这个并发映射包含路径及其对应的`Entry`对象。这些是之前`prepareForDelete`使用的相同的`Entry`对象。当创建`FileSystem`对象时，并发`files`映射被填充。
- en: 'For the examples in this section, we add the following dependency to our `build.sbt`
    file. This will allow us to use the Apache `Commons IO` library in order to handle
    files:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本节中的示例，我们在`build.sbt`文件中添加了以下依赖项。这将允许我们使用Apache `Commons IO`库来处理文件：
- en: '[PRE31]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We will allow `FileSystem` objects to only track files in a certain directory
    called `root`. By instantiating the `FileSystem` object with the `"."` string,
    we set the `root` directory to the root of our project with the example code.
    This way, the worst thing that can happen is that you delete all your examples
    by accident and have to rewrite them once more. However, that''s okay, as practice
    makes perfect! The `FileSystem` class is shown in the following snippet:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将允许`FileSystem`对象只跟踪名为`root`的特定目录中的文件。通过使用示例代码中的`"."`字符串实例化`FileSystem`对象，我们将`root`目录设置为项目根目录。这样，最坏的情况是您不小心删除了所有示例，并需要重新编写它们。然而，这没关系，因为熟能生巧！下面的代码片段显示了`FileSystem`类：
- en: '[PRE32]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We first create a new `ConcurrentHashMap` method from the `java.util.concurrent`
    package and wrap it to a Scala `concurrent.Map` trait by calling `asScala`. This
    method can be called to wrap most Java collections, provided the contents of the
    `decorateAsScala` object are imported like they are in our example. The `asScala`
    method ensures that Java collections obtain the Scala collection API. The `iterateFiles`
    method in the `FileUtils` class returns a Java iterator that traverses the files
    in a specific folder; we can only use Scala iterators in `for` comprehensions,
    so we call `asScala` again. The first argument for the `iterateFiles` method specifies
    the `root` folder, and the second method specifies an optional filter for the
    files. The final `false` argument for the `iterateFiles` method denotes that we
    do not scan files recursively in the subdirectories of `root`. We play it safe
    and expose only files in our `root` project directory to the `FileSystem` class.
    We place each `f` file along with a fresh `Entry` object into `files` by calling
    `put` on the concurrent map. There is no need to use a `synchronized` statement
    around `put`, as the concurrent map takes care of synchronization and thread-safety.
    The `put` operation is atomic, and it establishes a happens-before relationship
    with subsequent `get` operations.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先从`java.util.concurrent`包中创建一个新的`ConcurrentHashMap`方法，并通过调用`asScala`将其包装成Scala的`concurrent.Map`特质。这个方法可以被用来包装大多数Java集合，前提是`decorateAsScala`对象的内容像我们的示例中那样被导入。`asScala`方法确保Java集合获得Scala集合API。`FileUtils`类中的`iterateFiles`方法返回一个Java迭代器，它遍历特定文件夹中的文件；我们只能在`for`循环中使用Scala迭代器，所以我们需要再次调用`asScala`。`iterateFiles`方法的第一个参数指定了`root`文件夹，第二个参数指定了一个可选的文件过滤器。`iterateFiles`方法的最后一个`false`参数表示我们不会在`root`的子目录中递归扫描文件。我们采取安全措施，只将`root`项目目录中的文件暴露给`FileSystem`类。我们通过在并发映射上调用`put`方法，将每个`f`文件连同一个新的`Entry`对象一起放入`files`中。在`put`操作周围不需要使用`synchronized`语句，因为并发映射负责同步和线程安全。`put`操作是原子的，并且与随后的`get`操作建立了happens-before关系。
- en: 'The same is true for the other methods such as `remove`, which removes key-value
    pairs from a concurrent map. We can now use the `prepareForDelete` method implemented
    earlier to atomically lock a file for deletion and then remove it from the `files`
    map. We implement the `deleteFile` method for this purpose:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他方法，如`remove`，它从并发映射中删除键值对，情况也是一样的。我们现在可以使用之前实现的`prepareForDelete`方法来原子性地锁定文件以供删除，然后从`files`映射中删除它。为此，我们实现了`deleteFile`方法：
- en: '[PRE33]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'If the `deleteFile` method finds that the concurrent map contains the file
    with the given name, it calls the `execute` method to asynchronously delete it,
    as we prefer not to block the caller thread. The concurrent task, started by the
    `execute` invocation, calls the `prepareForDelete` method. If the `prepareForDelete`
    method returns `true`, then it is safe to call the `deleteQuietly` method from
    the `Commons IO` library. This method physically removes the file from the disk.
    If the deletion is successful, the file entry is removed from the `files` map.
    We create a new file called `test.txt` and use it to test the `deleteFile` method.
    We prefer not to experiment with the build definition file. The following code
    shows the deletion of the file:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`deleteFile`方法发现并发映射中包含给定名称的文件，它将调用`execute`方法异步删除它，因为我们更喜欢不阻塞调用线程。由`execute`调用启动的并发任务调用`prepareForDelete`方法。如果`prepareForDelete`方法返回`true`，那么调用`Commons
    IO`库中的`deleteQuietly`方法是安全的。此方法从磁盘上物理删除文件。如果删除成功，文件条目将从`files`映射中删除。我们创建了一个名为`test.txt`的新文件，并使用它来测试`deleteFile`方法。我们更喜欢不实验构建定义文件。以下代码显示了文件的删除操作：
- en: '[PRE34]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The second time we run this line, our logger thread from before complains that
    the file does not exist. A quick check in our file manager reveals that the `test.txt`
    file is no longer there.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 第二次运行此行时，我们之前的日志线程抱怨文件不存在。在我们的文件管理器中快速检查后，发现`test.txt`文件已经不再存在。
- en: The `concurrent.Map` trait also defines several complex linearizable methods.
    Recall that complex linearizable operations involve multiple reads and writes.
    In the context of concurrent maps, methods are complex linearizable operations
    if they involve multiple instances of the `get` and `put` methods, but appear
    to get executed at a single point in time. Such methods are a powerful tool in
    our concurrency arsenal. We have already seen that volatile reads and writes do
    not allow us to implement the `getUniqueId` method; we need the `compareAndSet`
    method for that. Similar methods on concurrent maps have comparable advantages.
    Different atomic methods on atomic maps are summarized in the following table.
    Note that, unlike the CAS instruction, these methods use structural equality to
    compare keys and values, and they call the `equals` method.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '`concurrent.Map`特质还定义了几个复杂的可线性化方法。回想一下，复杂的可线性化操作涉及多个读取和写入。在并发映射的上下文中，如果方法涉及多个`get`和`put`方法的实例，但看起来似乎在单一点时间执行，则这些方法是并发工具库中的强大工具。我们已经看到，volatile读取和写入不允许我们实现`getUniqueId`方法；我们需要`compareAndSet`方法来实现这一点。并发映射上的类似方法具有相似的优势。原子映射上的不同原子方法总结在下表中。请注意，与CAS指令不同，这些方法使用结构相等来比较键和值，并调用`equals`方法。'
- en: '| Signature | Description |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 签名 | 描述 |'
- en: '| --- | --- |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| putIfAbsent (k: K,  v: V):        Option[V] | This atomically assigns the
    value `v` to the key `k` if `k` is not in the map. Otherwise, it returns the value
    associated with `k`. |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| putIfAbsent (k: K,  v: V):        Option[V] | 如果键`k`不在映射中，则原子地将值`v`分配给键`k`。否则，它返回与`k`关联的值。
    |'
- en: '| remove (k: K, v: V):  Boolean | This atomically removes the key `k` if it
    is associated to the value equal to `v` and returns `true` if successful. |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| remove (k: K, v: V):  Boolean | 如果键`k`与值`v`相等，则原子地删除键`k`，如果成功则返回`true`。 |'
- en: '| replace (k: K, v: V):  Option[V] | This atomically assigns the value `v`
    to the key `k` and returns the value previously associated with `k`. |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| replace (k: K, v: V):  Option[V] | 这将原子地将值`v`分配给键`k`，并返回之前与`k`关联的值。 |'
- en: '| replace (k: K, ov: V, nv: V):  Boolean | This atomically assigns the key
    `k` to the value `nv` if `k` was previously associated with `ov` and returns `true`
    if successful. |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| replace (k: K, ov: V, nv: V):  Boolean | 如果`k`之前与`ov`关联，则原子地将键`k`分配给值`nv`，如果成功则返回`true`。
    |'
- en: 'Coming back to our filesystem API, let''s see how these methods work to our
    advantage. We will now implement the `copyFile` method in the `FileSystem` class.
    Recall the diagram from the section on atomic variables. A copy operation can
    start only if the file is either in the `Idle` state or already in the `Copying`
    state, so we need to atomically switch the file state from `Idle` to `Copying`
    or from the `Copying` state to another `Copying` state with the value `n` incremented.
    We do this with the `acquire` method:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的文件系统API，让我们看看这些方法是如何为我们带来优势的。我们现在将在`FileSystem`类中实现`copyFile`方法。回想一下关于原子变量的章节中的图。复制操作只有在文件处于`Idle`状态或已经处于`Copying`状态时才能开始，因此我们需要原子地将文件状态从`Idle`切换到`Copying`状态，或者从`Copying`状态切换到另一个带有值`n`增加的`Copying`状态。我们使用`acquire`方法来完成这个操作：
- en: '[PRE35]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'After a thread completes copying a file, it needs to release the `Copying`
    lock. This is done by a similar `release` method, which decreases the `Copying`
    count or changes the state to `Idle`. Importantly, this method must be called
    after files are newly created in order to switch from the `Creating` state to
    the `Idle` state. By now, the retry pattern following unsuccessful CAS operations
    should be child''s play for you. The following code shows this:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个线程完成文件复制后，它需要释放`Copying`锁。这是通过类似的`release`方法完成的，该方法减少`Copying`计数或将状态更改为`Idle`。重要的是，在文件新创建后，必须调用此方法，以便从`Creating`状态切换到`Idle`状态。到目前为止，跟随不成功的CAS操作的重试模式对你来说应该是小菜一碟。以下代码展示了这一点：
- en: '[PRE36]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We now have all the machinery required to implement the `copyFile` method.
    This method checks whether an `src` entry exists in the `files` map. If the entry
    exists, the `copyFile` method starts a concurrent task to copy the file. The concurrent
    task attempts to acquire the file for copying and creates a new `destEntry` file
    entry in the `Creating` state. It then calls the `putIfAbsent` method, which atomically
    checks whether the file path `dest` is a key in the map and adds the `dest` and
    `destEntry` pair if it is not. Both the `srcEntry` and `destEntry` value pair
    are locked at this point, so the `FileUtils.copyFile` method from the `Commons
    IO` library is called to copy the file on the disk. Once the copying is complete,
    both the `srcEntry` and `destEntry` value pair are released:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拥有了实现`copyFile`方法所需的所有工具。此方法检查`src`条目是否存在于`files`映射中。如果条目存在，`copyFile`方法启动一个并发任务来复制文件。并发任务尝试获取用于复制的文件，并在`Creating`状态下创建一个新的`destEntry`文件条目。然后它调用`putIfAbsent`方法，该方法是原子地检查文件路径`dest`是否是映射中的键，如果不是，则添加`dest`和`destEntry`对。此时，`srcEntry`和`destEntry`值对都被锁定，因此调用来自`Commons
    IO`库的`FileUtils.copyFile`方法在磁盘上复制文件。一旦复制完成，`srcEntry`和`destEntry`值对都会被释放：
- en: '[PRE37]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: You should convince yourself that the `copyFile` method would be incorrect if
    it first called `get` to check whether `dest` is in the map and then called `put`
    to place `dest` in the map. This would allow another thread's `get` and `put`
    steps to interleave and potentially overwrite an entry in the `files` map. This
    demonstrates the importance of the `putIfAbsent` method.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该确信，如果`copyFile`方法首先调用`get`来检查`dest`是否在映射中，然后调用`put`将`dest`放入映射中，那么这个方法将是错误的。这将允许另一个线程的`get`和`put`步骤交织，并可能覆盖`files`映射中的一个条目。这证明了`putIfAbsent`方法的重要性。
- en: There are some methods that the `concurrent.Map` trait inherits from the `mutable.Map`
    trait and that are not atomic. An example is the `getOrElseUpdate` method, which
    retrieves an element if it is present in the map and updates it with a different
    element otherwise. This method is not atomic, while its individual steps are atomic;
    they can be interleaved arbitrarily with concurrent calls to the `getOrElseUpdate`
    method. Another example is `clear`, which does not have to be atomic on concurrent
    collections in general and can behave like the concurrent data structure iterators
    we studied before.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 有些方法是从`mutable.Map`特质继承的`concurrent.Map`特质的方法，并且不是原子的。一个例子是`getOrElseUpdate`方法，如果元素存在于映射中，则检索该元素，否则使用不同的元素更新它。此方法不是原子的，而其各个步骤是原子的；它们可以与对`getOrElseUpdate`方法的并发调用任意交织。另一个例子是`clear`，在并发集合中通常不需要是原子的，可以表现得像我们之前研究过的并发数据结构迭代器。
- en: Note
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The`+=`, `-=`, `put`, `update`, `get`, `apply`, and `remove` methods in the
    `concurrent.Map` trait are linearizable methods. The `putIfAbsent`, conditional
    `remove`, and `replace` methods in the `concurrent.Map` trait are the only complex
    methods guaranteed to be linearizable.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '`concurrent.Map`特质中的`+=`、`-=`、`put`、`update`、`get`、`apply`和`remove`方法是可线性化的方法。`concurrent.Map`特质中的`putIfAbsent`、条件`remove`和`replace`方法是唯一保证可线性化的复杂方法。'
- en: Just like the Java concurrency library, Scala currently does not have a dedicated
    trait for concurrent sets. A concurrent set of the `Set[T]` type can be emulated
    with a concurrent map with the `ConcurrentMap[T, Unit]` type, which ignores the
    values assigned to keys. This is the reason why concrete concurrent set implementations
    appear less often in concurrency frameworks. In rare situations, where a Java
    concurrent set, such as the `ConcurrentSkipListSet[T]` class, needs to be converted
    to a Scala concurrent set, we can use the `asScala` method, which converts it
    to a `mutable.Set[T]` class.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 就像Java并发库一样，Scala目前还没有一个专门的特质用于并发集合。`Set[T]`类型的并发集合可以用`ConcurrentMap[T, Unit]`类型的并发映射来模拟，它忽略了分配给键的值。这就是为什么具体并发集合实现出现在并发框架中较少的原因。在罕见的情况下，如果需要将Java并发集合（如`ConcurrentSkipListSet[T]`类）转换为Scala并发集合，我们可以使用`asScala`方法，该方法将其转换为`mutable.Set[T]`类。
- en: As a final note, you should never use `null` as a key or value in a concurrent
    map or a concurrent set. Many concurrent data structure implementations on JVM
    rely on using `null` as a special indicator of the absence of an element.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一点，你永远不应该在并发映射或并发集中使用`null`作为键或值。许多在JVM上运行的并发数据结构实现依赖于使用`null`作为元素缺失的特殊指示符。
- en: Tip
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Avoid using the `null` value as a key or a value in a concurrent data structure.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 避免在并发数据结构中将`null`值用作键或值。
- en: Some implementations are defensive and will throw an exception; for others,
    the results might be undefined. Even when a concurrent collection specifies that
    `null` is allowed, you should avoid coupling `null` with your program logic in
    order to make potential refactoring easier.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 一些实现是防御性的，会抛出异常；对于其他实现，结果可能是未定义的。即使并发集合指定允许 `null`，你也应该避免将 `null` 与你的程序逻辑耦合，以便使潜在的重构更容易。
- en: Concurrent traversals
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发遍历
- en: As you had a chance to witness, Scala directly inherits many of its basic concurrency
    utilities from the Java concurrency packages. After all, these facilities were
    implemented by JVM's concurrency experts. Apart from providing conversions that
    make Java's traditional concurrency utilities feel Scala-idiomatic, there is no
    need to reinvent what's already there. When it comes to concurrent collections,
    a particularly bothersome limitation is that you cannot safely traverse most concurrent
    collections and modify them in the same time. This is not so problematic for sequential
    collections where we control the thread that calls the `foreach` loop or uses
    iterators. In a concurrent system where threads are not perfectly synchronized
    with each other, it is much harder to guarantee that there will be no modifications
    during the traversal.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见证的，Scala 直接从 Java 并发包中继承了其许多基本并发工具。毕竟，这些设施是由 JVM 的并发专家实现的。除了提供使 Java 的传统并发工具感觉像
    Scala 习惯用法的方法之外，没有必要重新发明已经存在的东西。当涉及到并发集合时，一个特别令人烦恼的限制是，你不能安全地遍历大多数并发集合并在同一时间修改它们。对于顺序集合来说，我们控制调用
    `foreach` 循环或使用迭代器的线程，这并不成问题。在一个线程之间没有完美同步的并发系统中，保证遍历期间没有修改要困难得多。
- en: Fortunately, Scala has an answer for concurrent collection traversals. The `TrieMap`
    collection from the `scala.collection.concurrent` package, which is based on the
    concurrent **Ctrie** data structure, is a concurrent map implementation that produces
    consistent iterators. When its `iterator` method is called, the `TrieMap` collection
    atomically takes a snapshot of all the elements. A **snapshot** is complete information
    about the state of a data structure. The iterator then uses this snapshot to traverse
    the elements. If the `TrieMap` collection is later modified during the traversal,
    the modifications are not visible in the snapshot and the iterator does not reflect
    them. You might conclude that taking a snapshot is expensive and requires copying
    all the elements, but this is not the case. The `snapshot` method of the `TrieMap`
    class incrementally rebuilds parts of the `TrieMap` collection when they are first
    accessed by some thread. The `readOnlySnapshot` method, internally used by the
    `iterator` method, is even more efficient. It ensures that only the modified parts
    of the `TrieMap` collection are lazily copied. If there are no subsequent concurrent
    modifications, then no part of the `TrieMap` collection is ever copied.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Scala 为并发集合遍历提供了一个解决方案。`scala.collection.concurrent` 包中的 `TrieMap` 集合，它基于并发的
    **Ctrie** 数据结构，是一个产生一致迭代器的并发映射实现。当调用其 `iterator` 方法时，`TrieMap` 集合原子性地获取所有元素的一个快照。**快照**是关于数据结构状态的完整信息。迭代器随后使用这个快照来遍历元素。如果在遍历过程中
    `TrieMap` 集合被修改，这些修改在快照中是不可见的，并且迭代器不会反映它们。你可能会得出结论，获取快照是昂贵的，需要复制所有元素，但事实并非如此。`TrieMap`
    类的 `snapshot` 方法在第一次被某些线程访问时，会增量地重建 `TrieMap` 集合的部分。`readOnlySnapshot` 方法，由 `iterator`
    方法内部使用，效率更高。它确保只懒性地复制 `TrieMap` 集合中被修改的部分。如果没有后续的并发修改，那么 `TrieMap` 集合的任何部分都不会被复制。
- en: 'Let''s study the difference between the Java `ConcurrentHashMap` and the Scala
    `concurrent.TrieMap` collections in an example. Assume that we have a concurrent
    map that maps names to numerals in these names. For example, `"Jane"` will be
    mapped to `0`, but `"John"` will be mapped to `4`, and so on. In one concurrent
    task, we add different names for John in the order of `0` to `10` to the `ConcurrentHashMap`
    collection. We concurrently traverse the map and output these names:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来研究 Java `ConcurrentHashMap` 和 Scala `concurrent.TrieMap` 集合之间的区别。假设我们有一个将名称映射到这些名称中的数字的并发映射。例如，`"Jane"`
    将被映射到 `0`，但 `"John"` 将被映射到 `4`，依此类推。在一个并发任务中，我们将 `0` 到 `10` 的不同名称按顺序添加到 `ConcurrentHashMap`
    集合中。我们并发地遍历映射并输出这些名称：
- en: '[PRE38]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'If the iterator was consistent, we would expect to see the three names `Johnny`,
    `Jane`, and `Jack` that were initially in the map and the name `John` in the interval
    from `0` to an `n` value, depending on how many names the first task added; this
    could be `John 1`, `John 2`, or `John 3`. Instead, the output shows you random
    nonconsecutive names such as `John 8` and `John 5`, which does not make sense.
    `John 8` should never appear in the map without `John 7`, and other entries inserted
    earlier by the other task. This never happens in a concurrent `TrieMap` collection.
    We can run the same experiment with the `TrieMap` collection and sort the names
    lexicographically before outputting them. Running the following program always
    prints all the `John` names in the interval of `0` and some value `n`:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如果迭代器是一致的，我们预计会看到最初在映射中存在的三个名字`Johnny`、`Jane`和`Jack`，以及从`0`到某个`n`值的`John`名字，这取决于第一个任务添加了多少名字；这可能是`John
    1`、`John 2`或`John 3`。相反，输出显示的是随机的不连续名字，例如`John 8`和`John 5`，这没有意义。`John 8`不应该在没有`John
    7`和其他任务之前插入的条目的情况下出现在映射中。这在并发的`TrieMap`集合中永远不会发生。我们可以用`TrieMap`集合进行相同的实验，并在输出之前按字典顺序排序名字。运行以下程序总是打印出`0`和某个值`n`之间的所有`John`名字：
- en: '[PRE39]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'How is this useful in practice? Imagine that we need to return a consistent
    snapshot of the filesystem; all the files are as seen by the file manager or an
    FTP server at a point in time. A `TrieMap` collection ensures that other threads
    that delete or copy files cannot interfere with the thread that is extracting
    the files. We thus use the `TrieMap` collection to store files in our filesystem
    API and define a simple `allFiles` method that returns all the files. At the point
    where we start using the `files` map in a `for` comprehension, a snapshot with
    the filesystem contents is created:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这在实际中有什么用？想象一下，我们需要返回文件系统的持续快照；所有文件都是文件管理器或FTP服务器在某个时间点看到的。`TrieMap`集合确保其他删除或复制文件的线程不会干扰正在提取文件的线程。因此，我们使用`TrieMap`集合在我们的文件系统API中存储文件，并定义一个简单的`allFiles`方法来返回所有文件。当我们开始在`for`理解中使用`files`映射时，就会创建一个包含文件系统内容的快照：
- en: '[PRE40]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We use the `allFiles` method to display all the files in the `root` directory:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`allFiles`方法来显示`root`目录中的所有文件：
- en: '[PRE41]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: After having seen both these concurrent maps, you might be wondering about which
    one to use. This mainly depends on the use case. If the application requires consistent
    iterators, then you should definitely use the `TrieMap` collections. On the other
    hand, if the application does not require consistent iterators and rarely modifies
    the concurrent map, you can consider using `ConcurrentHashMap` collections, as
    their lookup operations are slightly faster.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在看到这两个并发映射之后，你可能想知道该使用哪一个。这主要取决于用例。如果应用程序需要一致的迭代器，那么你绝对应该使用`TrieMap`集合。另一方面，如果应用程序不需要一致的迭代器并且很少修改并发映射，你可以考虑使用`ConcurrentHashMap`集合，因为它们的查找操作稍微快一些。
- en: Tip
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Use `TrieMap` collections if you require consistent iterators and `ConcurrentHashMap`
    collections when the `get` and `apply` operations are the bottlenecks in your
    program.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要一致的迭代器，请使用`TrieMap`集合；当`get`和`apply`操作是程序中的瓶颈时，请使用`ConcurrentHashMap`集合。
- en: From a performance point of view, this tip is only applicable if your application
    is exclusively accessing a concurrent map all the time and doing nothing else.
    In practice, this is rarely the case, and in most situations, you can use either
    of these collections.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 从性能的角度来看，这个提示仅适用于你的应用程序始终专门访问并发映射并且不做其他任何事情的情况。在实践中，这种情况很少见，在大多数情况下，你可以使用这两个集合中的任何一个。
- en: Custom concurrent data structures
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义并发数据结构
- en: In this section, we will show how to design a concurrent data structure. The
    data structure we will use as a running example will be simple, but sufficient
    to demonstrate the general approach. You will be able to apply the same principles
    to more complex data structures.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示如何设计一个并发数据结构。我们将用作运行示例的数据结构将很简单，但足以展示一般方法。你将能够将这些相同的原理应用到更复杂的数据结构中。
- en: Before we start, there is a disclaimer. Designing a concurrent data structure
    is hard, and, as a rule of the thumb, you should almost never do it. Even if you
    manage to implement a correct and efficient concurrent data structure, the cost
    of doing so is usually high.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，有一个免责声明。设计一个并发数据结构是困难的，并且，作为一个经验法则，你几乎永远不应该这样做。即使你设法实现了一个正确且高效的并发数据结构，其成本通常也是很高的。
- en: 'There are several reasons why designing a concurrent data structure is hard.
    The first is achieving correctness: errors are much harder to notice, reproduce,
    or analyze due to inherent non-determinism. Then, operations must not slow down
    when more processors use the data structure. In other words, the data structure
    must be scalable. Finally, a concurrent data structure must be efficient in absolute
    terms, and it must not be much slower than its sequential counterpart when used
    with a single processor.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 设计并发数据结构之所以困难，有几个原因。首先是实现正确性：由于固有的非确定性，错误很难被发现、重现或分析。其次，当更多处理器使用数据结构时，操作不能减慢。换句话说，数据结构必须是可扩展的。最后，并发数据结构在绝对意义上必须高效，并且在使用单个处理器时，它不应比其顺序对应物慢得多。
- en: 'That said, we proceed to designing a concrete data structure: a concurrent
    pool.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，我们继续设计一个具体的数据结构：一个并发池。
- en: Implementing a lock-free concurrent pool
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现无锁并发池
- en: In this section, we will implement a concurrent lock-free pool as an example
    of how to design a concurrent data structure. A **pool** is one of the simplest
    data structure abstractions, and only has two methods--the `add` and the `remove`
    operations. The `add` operation simply adds an element into the pool, but the
    `remove` operation is more limited than in a set or a map of elements. Instead
    of removing a specific element from the pool, the `remove` operation removes any
    element, as long as the pool is non-empty. A lock-free pool is a pool whose operations
    are lock-free.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将实现一个并发无锁池，作为如何设计并发数据结构的示例。**池**是数据结构抽象中最简单的一种，只有两个方法--`add`和`remove`操作。`add`操作简单地将元素添加到池中，但`remove`操作比集合或元素映射中的操作更有限。`remove`操作不是从池中移除特定元素，而是移除任何元素，只要池不为空即可。无锁池是一个其操作是无锁的池。
- en: Although simple, the pool abstraction is very useful, as it allows temporarily
    storing expensive objects (for example, worker threads or database connectors).
    For this use-case, we do not care about which exact element the `remove` operation
    returns, as long as it returns some element.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然简单，但池抽象非常有用，因为它允许临时存储昂贵的对象（例如，工作线程或数据库连接器）。对于这种用例，我们不在乎`remove`操作返回哪个确切元素，只要它返回某个元素即可。
- en: Determining its operations is the first step in designing a concurrent data
    structure. Knowing the operations and their exact semantics drives the rest of
    the design, and adding supplementary operations later is likely to break the invariants
    of the data structure. It is usually hard to correctly extend a concurrent data
    structure once it has already been implemented.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 确定其操作是设计并发数据结构的第一步。了解操作及其精确语义将驱动设计的其余部分，并且后来添加补充操作很可能会破坏数据结构的不可变性。一旦实现，通常很难正确扩展并发数据结构。
- en: 'Having determined the operations that a concurrent data structure must support,
    the next step is to think about data representation. Since we decided that the
    operations must be lock-free, one seemingly reasonable choice is to encode the
    state as an `AtomicReference` object holding a pointer to an immutable list:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 确定了并发数据结构必须支持的运算之后，下一步是考虑数据表示。由于我们决定操作必须是无锁的，一个看似合理的选项是将状态编码为一个包含指向不可变列表指针的`AtomicReference`对象：
- en: '[PRE42]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Both, the `add` and `remove` operations follow naturally from this choice. To
    add an element, we read the old list, use it to append the element at the head
    of the list, and then invoke a `compareAndSet` operation to replace the old list,
    retrying if necessary. Elements would be removed in a similar fashion.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是`add`还是`remove`操作，都自然地从这个选择中产生。要添加一个元素，我们读取旧列表，使用它将元素追加到列表的头部，然后调用`compareAndSet`操作来替换旧列表，如果需要则重试。元素将以类似的方式被移除。
- en: However, such an implementation would not be very scalable. Multiple processors
    would need to access the same memory location, and retrying would occur frequently.
    The expected time to complete the operation would then be *O(P)*, where *P* is
    the number of processors that are concurrently executing `add` and `remove` operations.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这样的实现不会非常可扩展。多个处理器需要访问相同的内存位置，并且重试会频繁发生。完成操作预期的耗时将是*O(P)*，其中*P*是同时执行`add`和`remove`操作的处理器数量。
- en: To improve this, we will need to allow different processors to pick different
    memory locations in the data structure when updating it. The fact that we are
    implementing a pool mitigates this decision, since the `remove` operation will
    not have to search for specific elements, and just needs to return any element.
    Therefore, the `add` operation can append the element to any location in the data
    structure.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 为了改进这一点，我们需要允许不同的处理器在更新数据结构时选择不同的内存位置。我们正在实现一个池的事实减轻了这一决策，因为`remove`操作不需要搜索特定元素，只需要返回任何元素。因此，`add`操作可以将元素添加到数据结构中的任何位置。
- en: 'With this in mind, we choose an array of atomic references, each holding an
    immutable list, as our internal representation. Having many atomic references
    allows each processor to pick an arbitrary slot to perform the update. This is
    shown in the following snippet:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，我们选择一个原子引用数组作为我们的内部表示，每个原子引用都持有不可变列表。拥有多个原子引用允许每个处理器选择任意槽位来执行更新。这在上面的代码片段中有所展示：
- en: '[PRE43]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Note that each atomic reference holds not only a list of values in the respective
    bucket, but also a `Long` value. This unique numeric value will serve as a timestamp
    that must be incremented each time the bucket is modified. Before we see why having
    the timestamp is important, we will implement the `add` operation.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，每个原子引用不仅包含相应桶中的值列表，还包含一个`Long`类型的值。这个独特的数值将作为时间戳使用，每次修改桶时都必须递增。在我们看到为什么有时间戳很重要之前，我们将实现`add`操作。
- en: 'The `add` operation must pick one of the atomic references in the `buckets`
    array, create a new version of the list that contains the new element, and then
    invoke the CAS instruction until the respective atomic reference is updated. When
    picking a bucket, the processor must aim for a bucket that no other processor
    is currently using, to prevent contention and retries. There are many ways to
    achieve this, but we will settle for a relatively simple strategy--we compute
    the bucket from the thread ID, and the hash code of the element. Once the bucket
    is picked, the `add` operation follows the standard retry pattern that we saw
    earlier. This is shown in the following snippet:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '`add`操作必须从`buckets`数组中选择一个原子引用，创建一个包含新元素的新列表版本，然后调用CAS指令直到相应的原子引用被更新。在挑选桶时，处理器必须选择一个当前没有其他处理器使用的桶，以防止竞争和重试。实现这一点有许多方法，但我们将采用相对简单的策略——我们根据线程ID和元素的哈希码来计算桶。一旦选择了桶，`add`操作将遵循我们之前看到的标准的重试模式。这在上面的代码片段中有所展示：'
- en: '[PRE44]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The `remove` operation is more complex. Unlike the `add` operation, which can
    pick any bucket when inserting an element, the `remove` operation must pick a
    non-empty bucket. The current design of the data structure offers no apriori way
    of knowing which bucket is non-empty, so the best we can do is pick some bucket,
    and scan the other buckets linearly until finding a non-empty bucket. This has
    two consequences. First, if our concurrent pool is nearly empty, we will need
    to scan all the buckets in the worst case scenario. The `remove` operation is
    only scalable if the pool is relatively full. Second, when the pool is almost
    empty, it is impossible to atomically scan all the entries. It can happen that,
    during the scan, one thread inserts an element to a bucket we already traversed,
    and another thread removes an element from a non-traversed bucket. In this case,
    the `remove` operation could falsely conclude that the pool is empty, which was
    never the case.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '`remove`操作更为复杂。与`add`操作不同，后者在插入元素时可以选择任何桶，`remove`操作必须选择一个非空桶。当前数据结构的设计没有提供事先知道哪个桶是非空的方法，所以我们能做的最好的选择是挑选一个桶，然后线性扫描其他桶直到找到一个非空桶。这有两个后果。首先，如果我们的并发池几乎为空，在最坏的情况下，我们需要扫描所有桶。`remove`操作只有在池相对满的情况下才是可扩展的。其次，当池几乎为空时，原子性地扫描所有条目是不可能的。在扫描过程中，可能发生一个线程向已经遍历过的桶中插入元素，而另一个线程从未遍历过的桶中删除元素。在这种情况下，`remove`操作可能会错误地得出池为空的结论，而这根本不是事实。'
- en: To address the second issue, we use the timestamps associated with each bucket.
    Recall that each timestamp is incremented when the respective bucket is modified.
    Therefore, if the sum of the timestamps remains constant, then no operation was
    executed on the pool. We can use this fact as follows. If we scan the bucket array
    twice, and see that the timestamp sum did not change, we can conclude that there
    have been no updates to the pool. This is crucial for the `remove` operation,
    which will use this information to know when to terminate.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决第二个问题，我们使用与每个桶关联的时间戳。回想一下，每当相应的桶被修改时，时间戳都会增加。因此，如果时间戳的总和保持不变，那么池上没有执行任何操作。我们可以用以下事实来利用这一点。如果我们扫描桶数组两次，并且看到时间戳总和没有变化，我们可以得出结论，池上没有进行任何更新。这对于`remove`操作至关重要，它将使用这些信息来知道何时终止。
- en: 'The `remove` operation starts by picking a bucket based on the current thread
    ID, and then starting a tail-recursive `scan` method. The `scan` method traverses
    the array, searching for non-empty buckets. When an empty bucket is observed,
    its timestamp is added to the `sum` local variable. When a non-empty bucket is
    found, the standard CAS pattern attempts to remove an element from the bucket
    in the `retry` method. If successful, the element is immediately removed from
    the `remove` operation. Otherwise, if upon traversing the array the previous timestamp
    sum is equal to the current sum, the `scan` method terminates. This is shown in
    the following snippet:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '`remove`操作首先根据当前线程ID选择一个桶，然后启动一个尾递归的`scan`方法。`scan`方法遍历数组，寻找非空桶。当观察到空桶时，将其时间戳添加到`sum`局部变量中。当找到非空桶时，标准CAS模式在`retry`方法中尝试从桶中移除一个元素。如果成功，该元素将立即从`remove`操作中移除。否则，如果在遍历数组后，前一个时间戳总和等于当前总和，则`scan`方法终止。这将在以下代码片段中展示：'
- en: '[PRE45]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We test the concurrent pool as follows. First, we instantiate a concurrent
    hash map that will track the elements we removed. Then, we create a concurrent
    pool, and set the number of threads `p` and the number of elements `num`:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如下测试并发池。首先，我们实例化一个并发哈希图，它将跟踪我们移除的元素。然后我们创建一个并发池，并设置线程数`p`和元素数`num`：
- en: '[PRE46]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We first start `p` inserter threads, which insert non-overlapping ranges of
    integers into the pool. We then wait for the threads to complete:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先启动`p`个插入器线程，这些线程将非重叠的整数范围插入到池中。然后我们等待线程完成：
- en: '[PRE47]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We similarly start `p` remover threads, which remove the elements from the
    pool, and store the removed elements to the `check` hash map we created earlier.
    Each thread removes `num` elements, so the pool should never be empty until all
    the threads complete:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们同样启动`p`个移除器线程，从池中移除元素，并将移除的元素存储到我们之前创建的`check`哈希图中。每个线程移除`num`个元素，因此池在所有线程完成之前不应为空：
- en: '[PRE48]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'At the end, we sequentially traverse the elements we expect to see in the `check`
    hash map, and assert that they are contained, as shown in the following snippet:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们按顺序遍历`check`哈希图中期望看到的元素，并断言它们包含在内，如下面的代码片段所示：
- en: '[PRE49]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: And this is it! We have verified that our concurrent pool implementation works
    correctly. Although we will not prove this, we loosely claim that the `add` operation
    runs in the expected *O(1)* time, the `remove` operation runs in the expected
    *O(1)* time when the pool has enough elements, and in the expected *O(P)* time
    when the queue is nearly empty. As an exercise, you can try to improve the `remove`
    operation, so that it always runs in the expected *O(1)* time.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我们已经验证了我们的并发池实现是正确的。虽然我们不会证明这一点，但我们粗略地声称`add`操作以预期的*O(1)*时间运行，当池有足够的元素时，`remove`操作以预期的*O(1)*时间运行，当队列几乎为空时，以预期的*O(P)*时间运行。作为一个练习，你可以尝试改进`remove`操作，使其始终以预期的*O(1)*时间运行。
- en: Creating and handling processes
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建和处理进程
- en: So far, we focused on concurrency within a Scala program running in a single
    JVM process. Whenever we wanted to allow multiple computations to proceed concurrently,
    we created new threads or sent `Runnable` objects to `Executor` threads. Another
    route to concurrency is to create separate processes. As explained in [Chapter
    2](ch02.html "Chapter 2. Concurrency on the JVM and the Java Memory Model"), *Concurrency
    on the JVM and the Java Memory Model*, separate processes have separate memory
    spaces and cannot share the memory directly.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们关注的是在单个 JVM 进程中运行的 Scala 程序的并发性。每当我们需要允许多个计算并发执行时，我们就会创建新的线程或将 `Runnable`
    对象发送到 `Executor` 线程。另一种实现并发的途径是创建单独的进程。正如在[第 2 章](ch02.html "第 2 章。JVM 和 Java
    内存模型上的并发")中解释的，“JVM 和 Java 内存模型上的并发”，单独的进程拥有各自的内存空间，不能直接共享内存。
- en: There are several reasons why we occasionally want to do this. First, while
    JVM has a very rich ecosystem with thousands of software libraries for all kinds
    of tasks, sometimes the only available implementation of a certain software component
    is a command-line utility or prepackaged program. Running it in a new process
    could be the only way to harvest its functionality. Second, sometimes we want
    to put Scala or Java code that we do not trust in a sandbox. A third-party plugin
    might have to run with a reduced set of permissions. Third, sometimes we just
    don't want to run in the same JVM process for performance reasons. Garbage collection
    or JIT compilation in a separate process should not affect the execution of our
    process, given that the machine has sufficient CPUs.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个原因使我们偶尔想要这样做。首先，虽然 JVM 拥有一个非常丰富的生态系统，有成千上万的软件库用于各种任务，但有时某个软件组件的唯一可用实现是命令行工具或预包装程序。在新的进程中运行它可能是唯一获取其功能的方法。其次，有时我们想把不信任的
    Scala 或 Java 代码放入沙盒中。第三方插件可能需要以减少的权限集运行。第三，有时出于性能原因，我们根本不想在同一个 JVM 进程中运行。如果机器有足够的
    CPU，那么在单独的进程中进行的垃圾收集或 JIT 编译不应该影响我们进程的执行。
- en: 'The `scala.sys.process` package contains a concise API for dealing with other
    processes. We can run the child process synchronously, in which case the thread
    from the parent process that runs it waits until the child process terminates,
    or asynchronously, in which case, the child process runs concurrently with the
    calling thread from the parent process. We will first show you how to run a new
    process synchronously:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '`scala.sys.process` 包含了一个简洁的 API，用于处理其他进程。我们可以同步地运行子进程，在这种情况下，运行它的父进程的线程将等待子进程终止，或者异步地运行，在这种情况下，子进程将与父进程的调用线程并发运行。我们首先向您展示如何同步地运行一个新的进程：'
- en: '[PRE50]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Importing the contents of the `scala.sys.process` package allows us to call
    the `!` method on any string. The shell command represented by the string is then
    run from the working directory of the current process. The return value is the
    exit code of the new process--zero when the process exits successfully and a nonzero
    error code otherwise.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 `scala.sys.process` 包的内容，允许我们在任何字符串上调用 `!` 方法。然后，该字符串表示的 shell 命令将从当前进程的工作目录中运行。返回值是新进程的退出代码——当进程成功退出时为零，否则为非零错误代码。
- en: 'Sometimes, we are interested in the standard output of a process rather than
    its exit code. In this case, we start the process with the`!!` method. Let''s
    assume that we want a `lineCount` method for text files in `FileSystem`, but are
    too lazy to implement it from scratch:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们更感兴趣的是进程的标准输出，而不是其退出代码。在这种情况下，我们使用 `!!` 方法启动进程。假设我们想在 `FileSystem` 中为文本文件实现一个
    `lineCount` 方法，但我们懒得从头开始实现：
- en: '[PRE51]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: After removing the white space from the output with the `trim` method on `String`
    type and converting the first part of the output to an integer, we obtain the
    word count of a file.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在 `String` 类型的 `trim` 方法中去除输出中的空白，并将输出的第一部分转换为整数，我们可以获得文件的词数。
- en: 'To start the process asynchronously, we call the `run` method on a string that
    represents the command. This method returns a `Process` object with the `exitValue`
    method, which is blocked until the process terminates, and the `destroy` method,
    which stops the process immediately. Assume that we have a potentially long-running
    process that lists all the files in our filesystem. After one second, we might
    wish to stop it by calling the `destroy` method on the `Process` object:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 要异步启动进程，我们调用表示命令的字符串上的 `run` 方法。此方法返回一个具有 `exitValue` 方法的 `Process` 对象，该方法在进程终止前被阻塞，以及一个
    `destroy` 方法，该方法立即停止进程。假设我们有一个可能运行时间较长的进程，该进程列出我们文件系统中的所有文件。一秒后，我们可能希望通过在 `Process`
    对象上调用 `destroy` 方法来停止它：
- en: '[PRE52]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Overloads of the `run` method allow you to communicate with the process by hooking
    the custom input and output streams or providing a custom `logger` object that
    is called each time the new process outputs a line.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '`run` 方法的重载允许您通过挂钩自定义输入和输出流或提供一个自定义的 `logger` 对象来与进程进行通信，该对象在每次新进程输出一行时被调用。'
- en: The `scala.sys.process` API has additional features such as starting multiple
    processes and piping their outputs together, running a different process if the
    current process fails, or redirecting the output to a file. It strives to mimic
    much of the functionality provided by the Unix shells. For complete information,
    we refer the reader to the Scala standard library's documentation of the `scala.sys.process`
    package.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '`scala.sys.process` API 具有其他一些功能，例如启动多个进程并将它们的输出连接起来，如果当前进程失败则运行不同的进程，或将输出重定向到文件。它力求模仿
    Unix shell 提供的许多功能。有关完整信息，我们建议读者查阅 Scala 标准库中 `scala.sys.process` 包的文档。'
- en: Summary
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter presented the traditional building blocks of concurrent programs
    in Scala. We saw how to use `Executor` objects to run concurrent computations.
    We learned how to use atomic primitives to atomically switch between different
    states in the program and implement locks and lock-free algorithms. We studied
    the implementation of lazy values and their impact on concurrent programs. We
    then showed you important classes of concurrent collections and learned how to
    apply them in practice, and we concluded by visiting the `scala.sys.process` package.
    These insights are not only specific to Scala; but most languages and platforms
    also have concurrency utilities that are similar to the ones presented in this
    chapter.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了 Scala 中并发程序的常规构建块。我们看到了如何使用 `Executor` 对象来运行并发计算。我们学习了如何使用原子原语在程序的不同状态之间原子性地切换，并实现锁和锁免费算法。我们研究了惰性值的实现及其对并发程序的影响。然后我们向您展示了并发集合的重要类别，并学习了如何在实践中应用它们，最后我们通过访问
    `scala.sys.process` 包来结束。这些见解不仅限于 Scala；大多数语言和平台也都有类似于本章中介绍的并发实用工具。
- en: Many other Java concurrency APIs are thoroughly explained in the book *Java
    Concurrency in Practice*, by Brian Goetz, Tim Peierls, Joshua Bloch, Joseph Bowbeer,
    David Holmes, and Doug Lea. To learn more about concepts such as lock-freedom,
    atomic variables, various types of locks, or concurrent data structures, we recommend
    the book *The Art of Multiprocessor Programming* by Maurice Herlihy and Nir Shavit,
    Morgan Kaufmann.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 书籍《Java Concurrency in Practice》由 Brian Goetz、Tim Peierls、Joshua Bloch、Joseph
    Bowbeer、David Holmes 和 Doug Lea 详细解释了许多其他 Java 并发 API。要了解更多关于无锁、原子变量、各种类型的锁或并发数据结构等概念，我们推荐阅读
    Maurice Herlihy 和 Nir Shavit 所著的《The Art of Multiprocessor Programming》。
- en: Although the concurrency building blocks in this chapter are more high level
    than the basic concurrency primitives of [Chapter 2](ch02.html "Chapter 2. Concurrency
    on the JVM and the Java Memory Model"), *Concurrency on the JVM and the Java Memory
    Model*, there are still culprits lurking at every corner. We had to be careful
    not to block when running on the execution context, to steer clear from the ABA
    problem, avoid synchronizing on objects that use lazy values, and ensure that
    concurrent collections are not modified while using their iterators. All this
    imposes quite a burden on the programmer. Couldn't concurrent programming be simpler?
    Fortunately, the answer is yes, as Scala supports styles of expressing concurrency
    that are more high level and declarative; less prone to effects such as deadlocks,
    starvation, or non-determinism; and generally easier to reason about. In the following
    chapters, we will dive into Scala-specific concurrency APIs that are safer and
    more intuitive to use. We will start by studying futures and promises in the next
    chapter, which allow you to compose asynchronous computations in a thread-safe
    and intuitive way.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本章中的并发构建块比第二章（[第二章：JVM和Java内存模型上的并发](ch02.html "第二章：JVM和Java内存模型上的并发"））中的基本并发原语更高级，但在每个角落都潜伏着问题。我们必须小心不要在执行上下文中阻塞，避免ABA问题，避免在使用懒值的对象上同步，并确保在迭代器使用期间并发集合不会被修改。所有这些都给程序员带来了很大的负担。并发编程难道不能更简单吗？幸运的是，答案是肯定的，因为Scala支持更高级和声明式的并发表达方式；更不容易出现死锁、饥饿或非确定性等效果；并且通常更容易推理。在接下来的章节中，我们将深入研究Scala特定的并发API，这些API更安全、更直观。我们将在下一章开始研究未来和承诺，这将允许你以线程安全和直观的方式组合异步计算。
- en: Exercises
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'The following exercises cover the various topics from this chapter. Most of
    the exercises require implementing new concurrent data structures using atomic
    variables and the CAS instruction. These data structures can also be solved using
    the `synchronized` statement, so it is helpful to contrast the advantages of the
    two approaches:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 以下练习涵盖了本章的各个主题。大多数练习都需要使用原子变量和CAS指令实现新的并发数据结构。这些数据结构也可以使用`synchronized`语句来解决，因此对比两种方法的优势是有帮助的：
- en: Implement a custom `ExecutionContext` class called `PiggybackContext`, which
    executes `Runnable` objects on the same thread that calls the `execute` method.
    Ensure that a `Runnable` object executing on the `PiggybackContext` can also call
    the `execute` method and that exceptions are properly reported.
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个名为`PiggybackContext`的自定义`ExecutionContext`类，该类在调用`execute`方法的同一线程上执行`Runnable`对象。确保在`PiggybackContext`上执行的`Runnable`对象也可以调用`execute`方法，并且异常能够得到适当的报告。
- en: 'Implement a `TreiberStack` class, which implements a concurrent stack abstraction:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个`TreiberStack`类，该类实现了一个并发栈抽象：
- en: '[PRE53]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Use an atomic reference variable that points to a linked list of nodes that
    were previously pushed to the stack. Make sure that your implementation is lock-free
    and not susceptible to the ABA problem.
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用一个原子引用变量，该变量指向一个链表节点，这些节点是之前推入栈中的。确保你的实现是无锁的，并且不会受到ABA问题的困扰。
- en: 'Implement a `ConcurrentSortedList` class, which implements a concurrent sorted
    list abstraction:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个`ConcurrentSortedList`类，该类实现了一个并发有序列表抽象：
- en: '[PRE54]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Under the hood, the `ConcurrentSortedList` class should use a linked list of
    atomic references. Ensure that your implementation is lock-free and avoids ABA
    problems.
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在底层，`ConcurrentSortedList`类应该使用原子引用的链表。确保你的实现是无锁的，并避免了ABA问题。
- en: The `Iterator` object returned by the `iterator` method must correctly traverse
    the elements of the list in ascending order under the assumption that there are
    no concurrent invocations of the `add` method.
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由`iterator`方法返回的`Iterator`对象必须在假设没有并发调用`add`方法的情况下，正确地按升序遍历列表中的元素。
- en: If required, modify the `ConcurrentSortedList` class from the previous example
    so that calling the `add` method has the running time linear to the length of
    the list and creates a constant number of new objects when there are no retries
    due to concurrent `add` invocations.
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果需要，修改上一个示例中的`ConcurrentSortedList`类，使得调用`add`方法的时间复杂度与列表长度成线性关系，并且在没有因并发`add`调用而重试的情况下，创建一个固定数量的新对象。
- en: 'Implement a `LazyCell` class with the following interface:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个具有以下接口的`LazyCell`类：
- en: '[PRE55]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Creating a `LazyCell` object and calling the `apply` method must have the same
    semantics as declaring a lazy value and reading it, respectively.
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创建一个`LazyCell`对象并调用`apply`方法必须与声明懒值和读取它具有相同的语义。
- en: You are not allowed to use lazy values in your implementation.
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在你的实现中不允许使用懒值。
- en: Implement a `PureLazyCell` class with the same interface and semantics as the
    `LazyCell` class from the previous exercise. The `PureLazyCell` class assumes
    that the initialization parameter does not cause side effects, so it can be evaluated
    more than once.
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个与之前练习中的`LazyCell`类具有相同接口和语义的`PureLazyCell`类。`PureLazyCell`类假设初始化参数不会引起副作用，因此它可以被评估多次。
- en: The `apply` method must be lock-free and should call the initialization as little
    as possible.
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`apply`方法必须是锁-free的，并且应该尽可能少地调用初始化。'
- en: Implement a `SyncConcurrentMap` class that extends the `Map` interface from
    the `scala.collection.concurrent` package. Use the `synchronized` statement to
    protect the state of the concurrent map.
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个`SyncConcurrentMap`类，它扩展了`scala.collection.concurrent`包中的`Map`接口。使用`synchronized`语句保护并发映射的状态。
- en: 'Implement a method `spawn` that, given a block of Scala code, starts a new
    JVM process and runs the specified block in the new process:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个`spawn`方法，给定一个Scala代码块，启动一个新的JVM进程并在新进程中运行指定的块：
- en: '[PRE56]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Once the block returns a value, the `spawn` method should return the value from
    the child process. If the block throws an exception, the `spawn` method should
    throw the same exception.
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦块返回一个值，`spawn`方法应该从子进程中返回该值。如果块抛出异常，`spawn`方法应该抛出相同的异常。
- en: Tip
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Use Java serialization to transfer the block of code, its return value, and
    the potential exceptions between the parent and the child JVM processes.
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用Java序列化在父进程和子进程JVM之间传输代码块、返回值和潜在的异常。
- en: Augment the lock-free pool implementation from this chapter with a `foreach`
    operation, used to traverse all the elements in the pool. Then make another version
    of `foreach` that is both lock-free and linearizable.
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将本章中的无锁池实现通过一个`foreach`操作进行增强，用于遍历池中的所有元素。然后创建另一个版本的`foreach`，它既无锁又可线性化。
- en: Prove that the lock-free pool implementation from this chapter is correct.
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 证明本章中的无锁池实现是正确的。
- en: Currently, the `remove` operation of the lock-free pool implementation from
    this chapter runs in *O(P)* worst-case time, where *P* is the number of processors
    on the machine. Improve the lock-free pool implementation so that the operations
    run in *O(1)* expected time, both in terms of the number of stored elements and
    the number of processors.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 目前，本章中无锁池实现的`remove`操作在最坏情况下运行时间为*O(P)*，其中*P*是机器上的处理器数量。改进无锁池实现，使得操作在*O(1)*期望时间内运行，无论是存储元素的数量还是处理器的数量。
