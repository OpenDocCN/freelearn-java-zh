- en: Configuring Kafka
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置 Kafka
- en: 'This chapter describes what Kafka is and the concepts related to this technology:
    brokers, topics, producers, and consumers. It also talks about how to build a
    simple producer and consumer from the command line, as well as how to install
    Confluent Platform. The information in this chapter is fundamental to the following
    chapters.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章描述了 Kafka 是什么以及与该技术相关的概念：代理、主题、生产者和消费者。它还讨论了如何从命令行构建简单的生产者和消费者，以及如何安装 Confluent
    平台。本章中的信息对于以下章节是基本的。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Kafka in a nutshell
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kafka 简述
- en: Installing Kafka (Linux and macOS)
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装 Kafka（Linux 和 macOS）
- en: Installing the Confluent Platform
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装 Confluent 平台
- en: Running Kafka
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行 Kafka
- en: Running Confluent Platform
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行 Confluent 平台
- en: Running Kafka brokers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行 Kafka 代理
- en: Running Kafka topics
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行 Kafka 主题
- en: A command–line message producer
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命令行消息生产者
- en: A command–line message consumer
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命令行消息消费者
- en: Using kafkacat
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 kafkacat
- en: Kafka in a nutshell
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kafka 简述
- en: Apache Kafka is an open source streaming platform. If you are reading this book,
    maybe you already know that Kafka scales very well in a horizontal way without
    compromising speed and efficiency.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Kafka 是一个开源的流平台。如果你正在阅读这本书，也许你已经知道 Kafka 在横向扩展方面表现非常出色，而且不会牺牲速度和效率。
- en: 'The Kafka core is written in Scala, and Kafka Streams and KSQL are written
    in Java. A Kafka server can run in several operating systems: Unix, Linux, macOS,
    and even Windows. As it usually runs in production on Linux servers, the examples
    in this book are designed to run on Linux environments. The examples in this book
    also consider bash environment usage.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka 的核心是用 Scala 编写的，Kafka Streams 和 KSQL 是用 Java 编写的。Kafka 服务器可以在多个操作系统上运行：Unix、Linux、macOS，甚至
    Windows。由于它通常在生产环境中运行在 Linux 服务器上，本书中的示例是为 Linux 环境设计的。本书中的示例还考虑了 bash 环境的使用。
- en: 'This chapter explains how to install, configure, and run Kafka. As this is
    a Quick Start Guide, it does not cover Kafka''s theoretical details. At the moment,
    it is appropriate to mention these three points:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章解释了如何安装、配置和运行 Kafka。由于这是一个快速入门指南，它不涵盖 Kafka 的理论细节。目前，提及以下三点是合适的：
- en: '**Kafka is a** **service bus**: To connect heterogeneous applications, we need
    to implement a message publication mechanism to send and receive messages among
    them. A message router is known as message broker. Kafka is a message broker,
    a solution to deal with routing messages among clients in a quick way.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kafka 是一个** **服务总线**: 为了连接异构应用程序，我们需要实现一个消息发布机制，以便在它们之间发送和接收消息。消息路由器被称为消息代理。Kafka
    是一个消息代理，是一种快速处理客户端之间消息路由的解决方案。'
- en: '**Kafka architecture has two directives**: The first is to not block the producers
    (in order to deal with the back pressure). The second is to isolate producers
    and consumers. The producers should not know who their consumers are, hence Kafka
    follows the dumb broker and smart clients model.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kafka 架构有两个指令**: 第一个是不要阻塞生产者（为了处理背压）。第二个是隔离生产者和消费者。生产者不应该知道他们的消费者是谁，因此 Kafka
    遵循愚笨代理和智能客户端模型。'
- en: '**Kafka is a real-time messaging system**:Moreover, Kafka is a software solution
    with a publish-subscribe model: open source, distributed, partitioned, replicated,
    and commit-log-based.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kafka 是一个实时消息系统**: 此外，Kafka 是一个具有发布-订阅模型的软件解决方案：开源、分布式、分区、复制和基于提交日志。'
- en: 'There are some concepts and nomenclature in Apache Kafka:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Kafka 中有一些概念和术语：
- en: '**Cluster**: This is a set of Kafka brokers.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集群**: 这是一组 Kafka 代理。'
- en: '**Zookeeper**: This is a cluster coordinator—a tool with different services
    that are part of the Apache ecosystem.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Zookeeper**: 这是一个集群协调器——一个包含 Apache 生态系统不同服务的工具。'
- en: '**Broker**: This is a Kafka server, also the Kafka server process itself.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代理**: 这是一个 Kafka 服务器，也是 Kafka 服务器进程本身。'
- en: '**Topic**: This is a queue (that has log partitions); a broker can run several
    topics.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主题**: 这是一个队列（具有日志分区）；一个代理可以运行多个主题。'
- en: '**Offset**: This is an identifier for each message.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏移量**: 这是每个消息的标识符。'
- en: '**Partition**: This is an immutable and ordered sequence of records continually
    appended to a structured commit log.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分区**: 这是一个不可变且有序的记录序列，持续追加到一个结构化的提交日志中。'
- en: '**Producer**: This is the program that publishes data to topics.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生产者**: 这是一个将数据发布到主题的程序。'
- en: '**Consumer**: This is the program that processes data from the topics.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消费者**: 这是一个从主题中处理数据的程序。'
- en: '**Retention period**: This is the time to keep messages available for consumption.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**保留期**: 这是保留消息以供消费的时间。'
- en: 'In Kafka, there are three types of clusters:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kafka 中，有三种类型的集群：
- en: Single node–single broker
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单节点-单代理
- en: Single node–multiple broker
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单节点-多代理
- en: Multiple node–multiple broker
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多节点-多代理
- en: 'In Kafka, there are three (and just three) ways to deliver messages:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kafka 中，有三种（仅三种）发送消息的方式：
- en: '**Never redelivered**: The messages may be lost because, once delivered, they
    are not sent again.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**永不重新投递**：消息可能会丢失，因为一旦投递，它们就不会再次发送。'
- en: '**May be redelivered**: The messages are never lost because, if it is not received,
    the message can be sent again.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可能重新投递**：消息永远不会丢失，因为如果未收到，消息可以再次发送。'
- en: '**Delivered once**: The message is delivered exactly once. This is the most
    difficult form of delivery; since the message is only sent once and never redelivered,
    it implies that there is zero loss of any message.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单次投递**：消息正好投递一次。这是最困难的投递形式；由于消息只发送一次且不会重新投递，这意味着不会有任何消息丢失。'
- en: 'The message log can be compacted in two ways:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 消息日志可以以两种方式压缩：
- en: '**Coarse-grained**: Log compacted by time'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**粗粒度**：按时间压缩的日志'
- en: '**Fine-grained**: Log compacted by message'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**细粒度**：按消息压缩的日志'
- en: Kafka installation
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kafka 安装
- en: 'There are three ways to install a Kafka environment:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种方式可以安装 Kafka 环境：
- en: Downloading the executable files
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载可执行文件
- en: Using `brew` (in macOS) or `yum` (in Linux)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `brew`（在 macOS 上）或 `yum`（在 Linux 上）
- en: Installing Confluent Platform
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装 Confluent 平台
- en: 'For all three ways, the first step is to install Java; we need Java 8\. Download
    and install the latest JDK 8 from the Oracle''s website:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有三种方式，第一步是安装 Java；我们需要 Java 8。从 Oracle 的网站下载并安装最新的 JDK 8：
- en: '[http://www.oracle.com/technetwork/java/javase/downloads/index.html](http://www.oracle.com/technetwork/java/javase/downloads/index.html)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.oracle.com/technetwork/java/javase/downloads/index.html](http://www.oracle.com/technetwork/java/javase/downloads/index.html)'
- en: At the time of writing, the latest Java 8 JDK version is 8u191.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，最新的 Java 8 JDK 版本是 8u191。
- en: 'For Linux users :'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Linux 用户：
- en: 'Change the file mode to executable as follows, follows these steps:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按以下步骤更改文件模式为可执行：
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Go to the directory in which you want to install Java:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往您想要安装 Java 的目录：
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Run the `rpm` installer with the following command:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令运行 `rpm` 安装程序：
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Add to your environment the `JAVA_HOME` variable. The following command writes
    the `JAVA_HOME` environment variable to the `/etc/profile` file:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `JAVA_HOME` 变量添加到您的环境中。以下命令将 `JAVA_HOME` 环境变量写入 `/etc/profile` 文件：
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Validate the Java installation as follows:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按以下方式验证 Java 安装：
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'At the time of writing, the latest Scala version is 2.12.6\. To install Scala
    in Linux, perform the following steps:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，最新的 Scala 版本是 2.12.6。要在 Linux 上安装 Scala，请执行以下步骤：
- en: Download the latest Scala binary from [http://www.scala-lang.org/download](http://www.scala-lang.org/download)
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 [http://www.scala-lang.org/download](http://www.scala-lang.org/download) 下载最新的
    Scala 二进制文件
- en: 'Extract the downloaded file, `scala-2.12.6.tgz`, as follows:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按以下方式提取下载的文件，`scala-2.12.6.tgz`：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Add the `SCALA_HOME` variable to your environment as follows:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按以下方式将 `SCALA_HOME` 变量添加到您的环境中：
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Add the Scala bin directory to your `PATH` environment variable as follows:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按以下方式将 Scala 的 bin 目录添加到您的 `PATH` 环境变量中：
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To validate the Scala installation, do the following:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要验证 Scala 安装，请执行以下操作：
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: To install Kafka on your machine, ensure that you have at least 4 GB of RAM,
    and the installation directory will be `/usr/local/kafka/` for macOS users and
    `/opt/kafka/` for Linux users. Create these directories according to your operating
    system.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要在您的机器上安装 Kafka，请确保您至少有 4 GB 的 RAM，并且安装目录对于 macOS 用户将是 `/usr/local/kafka/`，对于
    Linux 用户将是 `/opt/kafka/`。根据您的操作系统创建这些目录。
- en: Kafka installation on Linux
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Linux 上安装 Kafka
- en: 'Open the Apache Kafka download page, [http://kafka.apache.org/downloads](http://kafka.apache.org/downloads),
    as in *Figure 1.1*:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 Apache Kafka 下载页面，[http://kafka.apache.org/downloads](http://kafka.apache.org/downloads)，如图
    *图 1.1* 所示：
- en: '![](img/34e74b94-4c67-4c00-9148-ade9cdd2ddfc.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/34e74b94-4c67-4c00-9148-ade9cdd2ddfc.png)'
- en: 'Figure 1.1: Apache Kafka download page'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1：Apache Kafka 下载页面
- en: At the time of writing, the current Apache Kafka version is 2.0.0 as a stable
    release. Remember that, since version 0.8.x, Kafka is not backward-compatible.
    So, we cannot replace this version for one prior to 0.8\. Once you've downloaded
    the latest available release, let's proceed with the installation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，当前的 Apache Kafka 版本是 2.0.0 作为稳定版本。请记住，自 0.8.x 版本以来，Kafka 不向下兼容。因此，我们不能用低于
    0.8 的版本替换此版本。一旦下载了最新可用的版本，让我们继续进行安装。
- en: Remember for macOS users, replace the directory `/opt/` with `/usr/local`.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，对于 macOS 用户，将目录 `/opt/` 替换为 `/usr/local`。
- en: 'Follow these steps to install Kafka in Linux:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤在 Linux 上安装 Kafka：
- en: 'Extract the downloaded file, `kafka_2.11-2.0.0.tgz`, in the `/opt/` directory
    as follows:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下步骤在 `/opt/` 目录中解压下载的文件 `kafka_2.11-2.0.0.tgz`：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Create the `KAFKA_HOME` environment variable as follows:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下步骤创建 `KAFKA_HOME` 环境变量：
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Add the Kafka bin directory to the `PATH` variable as follows:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下步骤将 Kafka 的 bin 目录添加到 `PATH` 变量中：
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now Java, Scala, and Kafka are installed.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 Java、Scala 和 Kafka 已安装。
- en: To do all of the previous steps from the command line, there is a powerful tool
    for macOS users called `brew` (the equivalent in Linux would be `yum`).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要从命令行执行所有前面的步骤，macOS 用户有一个强大的工具叫做 `brew`（Linux 中的等效工具是 `yum`）。
- en: Kafka installation on macOS
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 macOS 上安装 Kafka
- en: 'To install from the command line in macOS (`brew` must be installed), perform
    the following steps:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在 macOS 上从命令行安装（必须已安装 `brew`），执行以下步骤：
- en: 'To install `sbt` (the Scala build tool) with `brew`, execute the following:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要使用 `brew` 安装 `sbt`（Scala 构建工具），执行以下命令：
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'If already have it in your environment (downloaded previously), run the following
    to upgrade it:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果已经在环境中安装（之前已下载），运行以下命令进行升级：
- en: '[PRE13]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output is similar to that shown in *Figure 1.2*:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于 *图 1.2* 中所示：
- en: '![](img/eb334cc9-9b67-41c5-9757-b1d11ff83232.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eb334cc9-9b67-41c5-9757-b1d11ff83232.png)'
- en: 'Figure 1.2: The Scala build tool installation output'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2：Scala 构建工具安装输出
- en: 'To install Scala with `brew`, execute the following:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要使用 `brew` 安装 Scala，执行以下命令：
- en: '[PRE14]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If you already have it in your environment (downloaded previously), to upgrade
    it, run the following command:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果已经在环境中安装（之前已下载），要升级它，请运行以下命令：
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output is similar to that shown in *Figure 1.3*:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于 *图 1.3* 中所示：
- en: '![](img/a3c6c893-4b71-40a4-88a5-ab8149fdb1b8.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a3c6c893-4b71-40a4-88a5-ab8149fdb1b8.png)'
- en: 'Figure 1.3: The Scala installation output'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3：Scala 安装输出
- en: 'To install Kafka with `brew`, (it also installs Zookeeper), do the following:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `brew` 安装 Kafka（它也会安装 Zookeeper），请执行以下操作：
- en: '[PRE16]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If you already have it (downloaded in the past), upgrade it as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果已经拥有它（以前已下载），按照以下方式升级：
- en: '[PRE17]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output is similar to that shown in *Figure 1.4*:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于 *图 1.4* 中所示：
- en: '![](img/8d8c9dd3-7924-4ab3-b806-d3b568f8f721.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8d8c9dd3-7924-4ab3-b806-d3b568f8f721.png)'
- en: 'Figure 1.4: Kafka installation output'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4：Kafka 安装输出
- en: Visit [https://brew.sh/](https://brew.sh/) for more about `brew`.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 访问 [https://brew.sh/](https://brew.sh/) 了解更多关于 `brew` 的信息。
- en: Confluent Platform installation
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Confluent 平台安装
- en: The third way to install Kafka is through Confluent Platform. In the rest of
    this book, we will be using Confluent Platform open source version.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 Kafka 的第三种方式是通过 Confluent 平台。在本书的其余部分，我们将使用 Confluent 平台的开放源代码版本。
- en: 'Confluent Platform is an integrated platform that includes the following components:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Confluent 平台是一个包含以下组件的集成平台：
- en: Apache Kafka
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Kafka
- en: REST proxy
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: REST 代理
- en: Kafka Connect API
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kafka Connect API
- en: Schema Registry
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模式注册表
- en: Kafka Streams API
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kafka Streams API
- en: Pre-built connectors
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预构建连接器
- en: Non-Java clients
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非Java客户端
- en: KSQL
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: KSQL
- en: If the reader notices, almost every one of the components has its own chapter
    in this book.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果读者注意到，本书中几乎每个组件都有自己的章节。
- en: 'The commercially licensed Confluent Platform includes, in addition to all of
    the components of the open source version, the following:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 商业授权的 Confluent 平台除了包含开源版本的所有组件外，还包括以下内容：
- en: '**Confluent Control Center** (**CCC**)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Confluent 控制中心**（**CCC**）'
- en: Kafka operator (for Kubernetes)
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kafka 操作员（用于 Kubernetes）
- en: JMS client
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JMS 客户端
- en: Replicator
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复制器
- en: MQTT proxy
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MQTT 代理
- en: Auto data balancer
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动数据平衡器
- en: Security features
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全功能
- en: It is important to mention that the training on the components of the non-open
    source version is beyond the scope of this book.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的一点是，非开源版本组件的培训超出了本书的范围。
- en: Confluent Platform is available also in Docker images, but here we are going
    to install it in local.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Confluent 平台也以 Docker 镜像的形式提供，但在这里我们将本地安装它。
- en: 'Open Confluent Platform download page: [https://www.confluent.io/download/](https://www.confluent.io/download/)
    .'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 Confluent 平台下载页面：[https://www.confluent.io/download/](https://www.confluent.io/download/)
    。
- en: 'At the time of this writing, the current version of Confluent Platform is 5.0.0
    as a stable release. Remember that, since the Kafka core runs on Scala, there
    are two versions: for Scala 2.11 and Scala 2.12.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，Confluent 平台的当前版本是 5.0.0，作为稳定版本。请记住，由于 Kafka 核心运行在 Scala 上，因此有两个版本：Scala
    2.11 和 Scala 2.12。
- en: We could run Confluent Platform from our desktop directory, but following this
    book's conventions, let's use `/opt/` for Linux users and `/usr/local` for macOS
    users.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从桌面目录运行 Confluent 平台，但根据本书的约定，让我们为 Linux 用户使用 `/opt/`，为 macOS 用户使用 `/usr/local`。
- en: 'To install Confluent Platform, extract the downloaded file, `confluent-5.0.0-2.11.tar.gz`,
    in the directory, as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 Confluent 平台，将下载的文件 `confluent-5.0.0-2.11.tar.gz` 解压到目录中，如下所示：
- en: '[PRE18]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Running Kafka
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行 Kafka
- en: There are two ways to run Kafka, depending on whether we install it directly
    or through Confluent Platform.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们是直接安装还是通过 Confluent 平台安装 Kafka，有两种运行 Kafka 的方法。
- en: If we install it directly, the steps to run Kafka are as follows.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们直接安装，运行 Kafka 的步骤如下。
- en: For macOS users, your paths might be different if you've installed using `brew`.
    Check the output of `brew install kafka` command for the exact command that you
    can use to start Zookeeper and Kafka.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 macOS 用户，如果您使用 `brew` 安装，您的路径可能不同。检查 `brew install kafka` 命令的输出，以获取可以启动 Zookeeper
    和 Kafka 的确切命令。
- en: 'Go to the Kafka installation directory (`/usr/local/kafka` for macOS users
    and `/opt/kafka/` for Linux users), as in the example:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 前往 Kafka 安装目录（macOS 用户为 `/usr/local/kafka`，Linux 用户为 `/opt/kafka/`），例如：
- en: '[PRE19]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'First of all, we need to start Zookeeper (the Kafka dependency with Zookeeper
    is and will remain strong). Type the following:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要启动 Zookeeper（Kafka 与 Zookeeper 的依赖关系目前很强，并将保持不变）。请输入以下命令：
- en: '[PRE20]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To check whether Zookeeper is running, use the `lsof` command over the `9093`
    port (default port) as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查 Zookeeper 是否正在运行，使用以下命令在 `9093` 端口（默认端口）上运行 `lsof` 命令：
- en: '[PRE21]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now run the Kafka server that comes with the installation by going to `/usr/local/kafka/`
    for macOS users and `/opt/kafka/` for Linux users:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，通过访问 `/usr/local/kafka/`（macOS 用户）和 `/opt/kafka/`（Linux 用户）来运行安装的 Kafka 服务器：
- en: '[PRE22]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Now there is an Apache Kafka broker running in your machine.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您的机器上正在运行一个 Apache Kafka 代理。
- en: Remember that Zookeeper must be running on the machine before starting Kafka.
    If you don't want to start Zookeeper manually every time you need to run Kafka,
    install it as an operation system auto-start service.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，在启动 Kafka 之前，Zookeeper 必须在机器上运行。如果您不希望每次需要运行 Kafka 时都手动启动 Zookeeper，请将其安装为操作系统的自动启动服务。
- en: Running Confluent Platform
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行 Confluent 平台
- en: 'Go to the Confluent Platform installation directory (`/usr/local/kafka/` for
    macOS users and `/opt/kafka/` for Linux users) and type the following:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 前往 Confluent 平台安装目录（macOS 用户为 `/usr/local/kafka/`，Linux 用户为 `/opt/kafka/`），并输入以下命令：
- en: '[PRE23]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'To start Confluent Platform, run the following:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动 Confluent 平台，请运行以下命令：
- en: '[PRE24]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This command-line interface is intended for development only, not for production:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令行界面仅适用于开发，不适用于生产：
- en: '[https://docs.confluent.io/current/cli/index.html](https://docs.confluent.io/current/cli/index.html)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://docs.confluent.io/current/cli/index.html](https://docs.confluent.io/current/cli/index.html)'
- en: 'The output is similar to what is shown in the following code snippet:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于以下代码片段：
- en: '[PRE25]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'As indicated by the command output, Confluent Platform automatically starts
    in this order: Zookeeper, Kafka, Schema Registry, REST proxy, Kafka Connect, KSQL,
    and the Confluent Control Center.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 如命令输出所示，Confluent 平台会按以下顺序自动启动：Zookeeper、Kafka、Schema Registry、REST 代理、Kafka
    Connect、KSQL 和 Confluent 控制中心。
- en: 'To access the Confluent Control Center running in your local, go to `http://localhost:9021`,
    as shown in *Figure 1.5*:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问您本地运行的 Confluent 控制中心，请访问 `http://localhost:9021`，如图 1.5 所示：
- en: '![](img/1bb16534-016c-411f-9dc7-468c78e7e346.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1bb16534-016c-411f-9dc7-468c78e7e346.png)'
- en: 'Figure 1.5: Confluent Control Center main page'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.5：Confluent 控制中心主页面
- en: There are other commands for Confluent Platform.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Confluent 平台还有其他命令。
- en: 'To get the status of all services or the status of a specific service along
    with its dependencies, enter the following:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查所有服务或特定服务及其依赖项的状态，请输入以下命令：
- en: '[PRE26]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To stop all services or a specific service along with the services depending
    on it, enter the following:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 要停止所有服务或停止特定服务及其依赖的服务，请输入以下命令：
- en: '[PRE27]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'To delete the data and logs of the current Confluent Platform, type the following:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除当前 Confluent 平台的数据和日志，请输入以下命令：
- en: '[PRE28]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Running Kafka brokers
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行 Kafka 代理
- en: The real art behind a server is in its configuration. In this section, we will
    examine how to deal with the basic configuration of a Kafka broker in standalone
    mode. Since we are learning, at the moment, we will not review the cluster configuration.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器背后的真正艺术在于其配置。在本节中，我们将探讨如何处理 Kafka 代理在独立模式下的基本配置。由于我们目前在学习，因此我们将不会回顾集群配置。
- en: 'As we can suppose, there are two types of configuration: standalone and cluster.
    The real power of Kafka is unlocked when running with replication in cluster mode
    and all topics are correctly partitioned.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所料，有两种类型的配置：独立和集群。当在集群模式下运行并具有复制功能时，Kafka的真实力量才得以释放，并且所有主题都正确分区。
- en: 'The cluster mode has two main advantages: parallelism and redundancy. Parallelism
    is the capacity to run tasks simultaneously among the cluster members. The redundancy
    warrants that, when a Kafka node goes down, the cluster is safe and accessible
    from the other running nodes.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 集群模式有两个主要优势：并行性和冗余性。并行性是指集群成员之间可以同时运行任务的能力。冗余性确保当Kafka节点故障时，集群仍然安全且可以从其他运行节点访问。
- en: This section shows how to configure a cluster with several nodes on our local
    machine although, in practice, it is always better to have several machines with
    multiple nodes sharing clusters.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 本节展示了如何在我们的本地机器上配置具有多个节点的集群，尽管在实践中，最好有多个机器，多个节点共享集群总是更好的选择。
- en: Go to the Confluent Platform installation directory, referenced from now on
    as `<confluent-path>`.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 进入Confluent平台安装目录，从现在起称为`<confluent-path>`。
- en: As mentioned in the beginning of this chapter, a broker is a server instance.
    A server (or broker) is actually a process running in the operating system and
    starts based on its configuration file.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章开头所述，代理是一个服务器实例。服务器（或代理）实际上是在操作系统上运行的一个进程，它根据其配置文件启动。
- en: 'The people of Confluent have kindly provided us with a template of a standard
    broker configuration. This file, which is called `server.properties`, is located
    in the Kafka installation directory in the `config` subdirectory:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Confluent的人们友好地为我们提供了一个标准代理配置的模板。这个文件名为`server.properties`，位于Kafka安装目录的`config`子目录中：
- en: Inside `<confluent-path>`, make a directory with the name mark.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`<confluent-path>`内部，创建一个名为`mark`的目录。
- en: 'For each Kafka broker (server) that we want to run, we need to make a copy
    of the configuration file template and rename it accordingly. In this example,
    our cluster is going to be called `mark`:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于我们想要运行的每个Kafka代理（服务器），我们需要复制配置文件模板并相应地重命名它。在这个例子中，我们的集群将被命名为`mark`：
- en: '[PRE29]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Modify each properties file accordingly. If the file is called `mark-1`, the
    `broker.id` should be `1`. Then, specify the port in which the server will run;
    the recommendation is `9093` for `mark-1` and `9094` for `mark-2`. Note that the
    port property is not set in the template, so add the line. Finally, specify the
    location of the Kafka logs (a Kafka log is a specific archive to store all of
    the Kafka broker operations); in this case, we use the `/tmp` directory. Here,
    it is common to have problems with write permissions. Do not forget to give write
    and execute permissions to the user with whom these processes are executed over
    the log directory, as in the examples:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据需要修改每个属性文件。如果文件名为`mark-1`，则`broker.id`应为`1`。然后，指定服务器将运行的端口；对于`mark-1`推荐使用`9093`，对于`mark-2`推荐使用`9094`。请注意，端口号属性在模板中未设置，因此需要添加该行。最后，指定Kafka日志的位置（Kafka日志是存储所有Kafka代理操作的特定存档）；在这种情况下，我们使用`/tmp`目录。在这里，常见的问题是写权限问题。不要忘记给在日志目录中执行这些进程的用户授予写和执行权限，如下例所示：
- en: 'In `mark-1.properties`, set the following:'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`mark-1.properties`中设置以下内容：
- en: '[PRE31]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'In `mark-2.properties`, set the following:'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`mark-2.properties`中设置以下内容：
- en: '[PRE32]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Start the Kafka brokers using the `kafka-server-start` command with the corresponding
    configuration file passed as the parameter. Don''t forget that Confluent Platform
    must be already running and the ports should not be in use by another process.
    Start the Kafka brokers as follows:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kafka-server-start`命令启动Kafka代理，并将相应的配置文件作为参数传递。不要忘记Confluent平台必须已经运行，并且端口不应被其他进程使用。以下是如何启动Kafka代理：
- en: '[PRE33]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'And, in another command-line window, run the following command:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一个命令行窗口中，运行以下命令：
- en: '[PRE34]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Don't forget that the trailing `&` is to specify that you want your command
    line back. If you want to see the broker output, it is recommended to run each
    command separately in its own command-line window.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记，尾随的`&`是为了指定你想要命令行返回。如果你想查看代理输出，建议在每个自己的命令行窗口中单独运行每个命令。
- en: Remember that the properties file contains the server configuration and that
    the `server.properties` file located in the `config` directory is just a template.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 记住属性文件包含服务器配置，而位于`config`目录中的`server.properties`文件只是一个模板。
- en: Now there are two brokers, `mark-1` and `mark-2` , running in the same machine
    in the same cluster.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有`mark-1`和`mark-2`两个代理在同一台机器上同一集群中运行。
- en: 'Remember, there are no dumb questions, as in the following examples:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，没有愚蠢的问题，如下面的例子所示：
- en: '**Q**: How does each broker know which cluster it belongs to?'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q**：每个代理如何知道它属于哪个集群？'
- en: '**A**: The brokers know that they belong to the same cluster because, in the
    configuration, both point to the same Zookeeper cluster.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**A**：代理知道它们属于同一个集群，因为在配置中，它们都指向同一个Zookeeper集群。'
- en: '**Q**: How does each broker differ from the others within the same cluster?'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q**：同一集群内的每个代理与其他代理有何不同？'
- en: '**A**: Every broker is identified inside the cluster by the name specified
    in the `broker.id` property.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '**A**：每个代理在集群内部通过`broker.id`属性中指定的名称来标识。'
- en: '**Q**: What happens if the port number is not specified?'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q**：如果没有指定端口号会发生什么？'
- en: '**A**: If the port property is not specified, Zookeeper will assign the same
    port number and will overwrite the data.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '**A**：如果没有指定端口属性，Zookeeper将分配相同的端口号，并将覆盖数据。'
- en: '**Q**: What happens if the log directory is not specified?'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q**：如果没有指定日志目录会发生什么？'
- en: '**A**: If `log.dir` is not specified, all the brokers will write to the same
    default `log.dir`. If the brokers are planned to run in different machines, then
    the port and `log.dir` properties might not be specified (because they run in
    the same port and log file but in different machines).'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '**A**：如果没有指定`log.dir`，所有代理都将写入相同的默认`log.dir`。如果计划在不同的机器上运行代理，则可能不会指定端口和`log.dir`属性（因为它们在相同的端口和日志文件上运行，但在不同的机器上）。'
- en: '**Q**: How can I check that there is not a process already running in the port
    where I want to start my broker?'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q**：我如何检查我想要启动代理的端口上是否没有正在运行进程？'
- en: '**A**: As shown in the previous section, there is a useful command to see what
    process is running on specific port, in this case the `9093` port:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**A**：如前一小节所示，有一个有用的命令可以查看在特定端口上运行什么进程，在这种情况下是`9093`端口：'
- en: '[PRE35]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The output of the previous command is something like this:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 上一条命令的输出类似于以下内容：
- en: '[PRE36]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Your turn: try to run this command before starting the Kafka brokers, and run
    it after starting them to see the change. Also, try to start a broker on a port
    in use to see how it fails.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 您的机会：在启动Kafka代理之前尝试运行此命令，并在启动后运行它以查看变化。此外，尝试在一个正在使用的端口上启动代理，以查看它如何失败。
- en: OK, what if I want my cluster to run on several machines?
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，如果我想要我的集群在多台机器上运行怎么办？
- en: 'To run Kafka nodes on different machines but in the same cluster, adjust the
    Zookeeper connection string in the configuration file; its default value is as
    follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 要在不同的机器上运行Kafka节点但属于同一集群，请调整配置文件中的Zookeeper连接字符串；其默认值如下：
- en: '[PRE37]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Remember that the machines must be able to be found by each other by DNS and
    that there are no network security restrictions between them.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，机器必须能够通过DNS找到彼此，并且它们之间没有网络安全限制。
- en: The default value for Zookeeper connect is correct only if you are running the
    Kafka broker in the same machine as Zookeeper. Depending on the architecture,
    it will be necessary to decide if there will be a broker running on the same Zookeeper
    machine.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: Zookeeper连接的默认值只有在你在同一台机器上运行Kafka代理时才是正确的。根据架构的不同，可能需要决定是否会在同一台Zookeeper机器上运行代理。
- en: 'To specify that Zookeeper might run in other machines, do the following:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 要指定Zookeeper可能在其他机器上运行，请执行以下操作：
- en: '[PRE38]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The previous line specifies that Zookeeper is running in the local host machine
    on port `2181`, in the machine with IP address `192.168.0.2` on port `2183` ,
    and in the machine with IP address, the `192.168.0.3`, on port `2182`. The Zookeeper
    default port is `2181`, so normally it runs there.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 上一行指定Zookeeper在本地主机机器上的端口`2181`运行，在IP地址为`192.168.0.2`的机器上的端口`2183`运行，以及在IP地址为`192.168.0.3`的机器上的端口`2182`运行。Zookeeper的默认端口是`2181`，所以通常它在那里运行。
- en: 'Your turn: as an exercise, try to start a broker with incorrect information
    about the Zookeeper cluster. Also, using the `lsof` command, try to raise Zookeeper
    on a port in use.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 您的机会：作为一个练习，尝试使用关于Zookeeper集群的错误信息启动代理。此外，使用`lsof`命令尝试在一个正在使用的端口上启动Zookeeper。
- en: 'If you have doubts about the configuration, or it is not clear what values
    to change, the `server.properties` template (as all of the Kafka project) is open
    sourced in the following:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对配置有疑问，或者不清楚要更改哪些值，以下`server.properties`模板（以及Kafka项目的所有内容）都是开源的：
- en: '[https://github.com/apache/kafka/blob/trunk/config/server.properties](https://github.com/apache/kafka/blob/trunk/config/server.properties)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/apache/kafka/blob/trunk/config/server.properties](https://github.com/apache/kafka/blob/trunk/config/server.properties)'
- en: Running Kafka topics
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行Kafka主题
- en: The power inside a broker is the topic, namely the queues inside it. Now that
    we have two brokers running, let's create a Kafka topic on them.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 代理内部的力量是主题，即其中的队列。现在我们有两个代理正在运行，让我们在它们上创建一个Kafka主题。
- en: 'Kafka, like almost all modern infrastructure projects, has three ways of building
    things: through the command line, through programming, and through a web console
    (in this case the Confluent Control Center). The management (creation, modification,
    and destruction) of Kafka brokers can be done through programs written in most
    modern programming languages. If the language is not supported, it could be managed
    through the Kafka REST API. The previous section showed how to build a broker
    using the command line. In later chapters, we will see how to do this process
    through programming.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka，就像几乎所有的现代基础设施项目一样，有三种构建事物的方式：通过命令行、通过编程和通过Web控制台（在这种情况下是Confluent控制中心）。Kafka代理的管理（创建、修改和销毁）可以通过大多数现代编程语言编写的程序来完成。如果该语言不受支持，则可以通过Kafka
    REST API进行管理。上一节展示了如何使用命令行构建代理。在后面的章节中，我们将看到如何通过编程来完成这个过程。
- en: Is it possible to only manage (create, modify, or destroy) brokers through programming?
    No, we can also manage the topics. The topics can also be created through the
    command line. Kafka has pre-built utilities to manage brokers as we already saw
    and to manage topics, as we will see next.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 是否可以通过编程仅管理（创建、修改或销毁）代理？不，我们也可以管理主题。主题也可以通过命令行创建。Kafka有预构建的实用工具来管理代理，就像我们之前看到的，以及管理主题，就像我们接下来将要看到的。
- en: 'To create a topic called `amazingTopic` in our running cluster, use the following
    command:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 要在我们的运行集群中创建名为`amazingTopic`的主题，请使用以下命令：
- en: '[PRE39]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output should be as follows:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '[PRE40]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Here, the `kafka-topics` command is used. With the `--create` parameter it is
    specified that we want to create a new topic. The `--topic` parameter sets the
    name of the topic, in this case, `amazingTopic`.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，使用的是`kafka-topics`命令。通过`--create`参数指定我们想要创建一个新的主题。`--topic`参数设置主题的名称，在这种情况下，为`amazingTopic`。
- en: Do you remember the terms parallelism and redundancy? Well, the `–-partitions`
    parameter controls the parallelism and the `--replication-factor` parameter controls
    the redundancy.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 你还记得并行性和冗余这两个术语吗？嗯，`--partitions`参数控制并行性，而`--replication-factor`参数控制冗余。
- en: The `--replication-factor` parameter is fundamental as it specifies in how many
    servers of the cluster the topic is going to replicate (for example, running).
    On the other hand, one broker can run just one replica.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '`--replication-factor`参数是基本的，因为它指定了主题将在集群中的多少个服务器上进行复制（例如，运行）。另一方面，一个代理可以只运行一个副本。'
- en: 'Obviously, if a greater number than the number of running servers on the cluster
    is specified, it will result in an error (you don''t believe me? Try it in your
    environment). The error will be like this:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，如果指定的服务器数量大于集群中运行的服务器数量，将会导致错误（你不相信我？在你的环境中试一试）。错误将类似于以下内容：
- en: '[PRE41]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: To be considered, the broker should be running (don't be shy and test all this
    theory in your environment).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 要考虑的是，代理应该正在运行（不要害羞，在你的环境中测试所有这些理论）。
- en: The `--partitions` parameter, as its name implies, says how many partitions
    the topic will have. The number determines the parallelism that can be achieved
    on the consumer's side. This parameter is very important when doing cluster fine-tuning.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '`--partitions`参数，正如其名称所暗示的，说明了主题将有多少个分区。这个数字决定了消费者侧可以实现的并行性。当进行集群微调时，此参数非常重要。'
- en: Finally, as expected, the `--zookeeper` parameter indicates where the Zookeeper
    cluster is running.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，正如预期的那样，`--zookeeper`参数指示Zookeeper集群正在运行的位置。
- en: 'When a topic is created, the output in the broker log is something like this:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建一个主题时，代理日志中的输出类似于以下内容：
- en: '[PRE42]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: In short, this message reads like a new topic has been born in our cluster.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，这条消息看起来就像在我们的集群中诞生了一个新的主题。
- en: 'How can I check my new and shiny topic? By using the same command: `kafka-topics`.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我如何检查我的新而闪亮的主题？通过使用相同的命令：`kafka-topics`。
- en: 'There are more parameters than `--create`. To check the status of a topic,
    run the `kafka-topics` command with the `--list` parameter, as follows:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`--create`参数之外，还有更多的参数。要检查主题的状态，请使用带有`--list`参数的`kafka-topics`命令，如下所示：
- en: '[PRE43]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The output is the list of topics, as we know, is as follows:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，输出是主题列表，如下所示：
- en: '[PRE44]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: This command returns the list with the names of all of the running topics in
    the cluster.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令返回集群中所有运行主题的名称列表。
- en: 'How can I get details of a topic? Using the same command: `kafka-topics`.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 如何获取主题的详细信息？使用相同的命令：`kafka-topics`。
- en: 'For a particular topic, run the `kafka-topics` command with the `--describe`
    parameter, as follows:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 对于特定主题，使用`--describe`参数运行`kafka-topics`命令，如下所示：
- en: '[PRE45]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The command output is as follows:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 命令输出如下所示：
- en: '[PRE46]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Here is a brief explanation of the output:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出简要说明：
- en: '`PartitionCount`: Number of partitions on the topic (parallelism)'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PartitionCount`：主题上的分区数量（并行性）'
- en: '`ReplicationFactor`: Number of replicas on the topic (redundancy)'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ReplicationFactor`：主题上的副本数量（冗余）'
- en: '`Leader`: Node responsible for reading and writing operations of a given partition'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Leader`：负责读取和写入给定分区操作的节点'
- en: '`Replicas`: List of brokers replicating this topic data; some of these might
    even be dead'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Replicas`：复制此主题数据的代理列表；其中一些甚至可能是已死亡的'
- en: '`Isr`: List of nodes that are currently in-sync replicas'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Isr`：当前同步副本的节点列表'
- en: 'Let''s create a topic with multiple replicas (for example, we will run with
    more brokers in the cluster); we type the following:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个具有多个副本的主题（例如，我们将在集群中运行更多代理）；我们输入以下内容：
- en: '[PRE47]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output is as follows:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '[PRE48]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Now, call the `kafka-topics` command with the `--describe` parameter to check
    the topic details, as follows:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用`--describe`参数调用`kafka-topics`命令来检查主题详情，如下所示：
- en: '[PRE49]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: As you can see, `Replicas` and `Isr` are the same lists; we infer that all of
    the nodes are in-sync.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`Replicas`和`Isr`是相同的列表；我们推断所有节点都是同步的。
- en: 'Your turn: play with the `kafka-topics` command, and try to create replicated
    topics on dead brokers and see the output. Also, create topics on running servers
    and then kill them to see the results. Was the output what you expected?'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 轮到你了：使用`kafka-topics`命令进行实验，尝试在已死亡的代理上创建复制主题，并查看输出。然后，在运行的服务器上创建主题，然后杀死它们以查看结果。输出是否如您预期的那样？
- en: As mentioned before, all of these commands executed through the command line
    can be executed programmatically or performed through the Confluent Control Center
    web console.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，所有这些通过命令行执行的命令都可以通过编程执行或通过Confluent Control Center网络控制台执行。
- en: A command-line message producer
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 命令行消息生产者
- en: Kafka also has a command to send messages through the command line; the input
    can be a text file or the console standard input. Each line typed in the input
    is sent as a single message to the cluster.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka还有一个通过命令行发送消息的命令；输入可以是文本文件或控制台标准输入。输入的每一行都作为单个消息发送到集群。
- en: For this section, the execution of the previous steps is needed. The Kafka brokers
    must be up and running and a topic created inside them.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本节，需要执行前面的步骤。Kafka代理必须处于运行状态，并且在其中创建了一个主题。
- en: 'In a new command-line window, run the following command, followed by the lines
    to be sent as messages to the server:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个新的命令行窗口中，运行以下命令，然后输入要发送到服务器的消息行：
- en: '[PRE50]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: These lines push two messages into the `amazingTopic` running on the localhost
    cluster on the `9093` port.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 这些行将两条消息推送到运行在本机集群`9093`端口的`amazingTopic`。
- en: This command is also the simplest way to check whether a broker with a specific
    topic is up and running as it is expected.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令也是检查具有特定主题的代理是否按预期运行的最简单方式。
- en: 'As we can see, the `kafka-console-producer` command receives the following
    parameters:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，`kafka-console-producer`命令接收以下参数：
- en: '`--broker-list`: This specifies the Zookeeper servers specified as a comma-separated
    list in the form, hostname:port.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--broker-list`：此指定以逗号分隔的列表形式指定的Zookeeper服务器，格式为，hostname:port。'
- en: '`--topic`: This parameter is followed by the name of the target topic.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--topic`：此参数后跟目标主题的名称。'
- en: '`--sync`: This specifies whether the messages should be sent synchronously.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--sync`：此指定消息是否应同步发送。'
- en: '`--compression-codec`: This specifies the compression codec used to produce
    the messages. The possible options are: `none`, `gzip`, `snappy`, or lz4\. If
    not specified, the default is gzip.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--compression-codec`：此指定用于生产消息的压缩编解码器。可能的选项是：`none`、`gzip`、`snappy`或`lz4`。如果未指定，则默认为gzip。'
- en: '`--batch-size`: If the messages are not sent synchronously, but the message
    size is sent in a single batch, this value is specified in bytes.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--batch-size`：如果消息不是同步发送，但消息大小以单个批次发送，则此值以字节为单位指定。'
- en: '`--message-send-max-retries`: As the brokers can fail receiving messages, this
    parameter specifies the number of retries before a producer gives up and drops
    the message. This number must be a positive integer.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--message-send-max-retries`: 由于代理可能会失败接收消息，此参数指定了生产者在放弃并丢弃消息之前重试的次数。此数字必须是一个正整数。'
- en: '`--retry-backoff-ms`: In case of failure, the node leader election might take
    some time. This parameter is the time to wait before producer retries after this
    election. The number is the time in milliseconds.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--retry-backoff-ms`: 在失败的情况下，节点领导者选举可能需要一些时间。此参数是在生产者在选举后重试之前等待的时间。数字是毫秒数。'
- en: '`--timeout`: If the producer is running in asynchronous mode and this parameter
    is set, it indicates the maximum amount of time a message will queue awaiting
    for the sufficient batch size. This value is expressed in milliseconds.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--timeout`: 如果生产者在异步模式下运行且设置了此参数，则表示消息在队列中等待足够大的批次大小时的最大时间。此值以毫秒表示。'
- en: '`--queue-size`: If the producer is running in asynchronous mode and this parameter
    is set, it gives the maximum amount of messages will queue awaiting the sufficient
    batch size.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--queue-size`: 如果生产者在异步模式下运行且设置了此参数，则它给出消息队列的最大容量，等待足够大的批次大小。'
- en: In case of a server fine tuning, `batch-size`, `message-send-max-retries`, and
    `retry-backoff-ms` are very important; take in consideration these parameters
    to achieve the desired behavior.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在服务器微调的情况下，`batch-size`、`message-send-max-retries`和`retry-backoff-ms`非常重要；考虑这些参数以实现所需的行为。
- en: 'If you don''t want to type the messages, the command could receive a file where
    each line is considered a message, as shown in the following example:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不想输入消息，命令可以接收一个文件，其中每行被视为一条消息，如下例所示：
- en: '[PRE51]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: A command-line message consumer
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 命令行消息消费者
- en: The last step is how to read the generated messages. Kafka also has a powerful
    command that enables messages to be consumed from the command line. Remember that
    all of these command-line tasks can also be done programmatically. As the producer,
    each line in the input is considered a message from the producer.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是如何读取生成的消息。Kafka还有一个强大的命令，可以从命令行消费消息。请记住，所有这些命令行任务也可以通过编程方式完成。作为生产者，输入中的每一行都被视为生产者的一条消息。
- en: For this section, the execution of the previous steps is needed. The Kafka brokers
    must be up and running and a topic created inside them. Also, some messages need
    to be produced with the message console producer, to begin consuming these messages
    from the console.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本节，需要执行前面的步骤。Kafka代理必须处于运行状态，并在其中创建一个主题。此外，需要使用消息控制台生产者生成一些消息，以便从控制台开始消费这些消息。
- en: 'Run the following command:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下命令：
- en: '[PRE52]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The output should be as follows:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该是以下内容：
- en: '[PRE53]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The parameters are the topic's name and the name of the broker producer. Also,
    the `--from-beginning` parameter indicates that messages should be consumed from
    the beginning instead of the last messages in the log (now test it, generate many
    more messages, and don't specify this parameter).
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 参数是主题的名称和代理生产者的名称。此外，`--from-beginning`参数表示应从日志的开始而不是最后一条消息消费消息（现在测试它，生成更多消息，不要指定此参数）。
- en: 'There are more useful parameters for this command, some important ones are
    as follows:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令还有更多有用的参数，以下是一些重要的参数：
- en: '`--fetch-size`: This is the amount of data to be fetched in a single request.
    The size in bytes follows as argument. The default value is 1,024 x 1,024.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--fetch-size`: 这是单个请求中要获取的数据量。字节数作为参数跟随。默认值是1,024 x 1,024。'
- en: '`--socket-buffer-size`: This is the size of the TCP RECV. The size in bytes
    follows this parameter. The default value is 2 x 1024 x 1024.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--socket-buffer-size`: 这是TCP RECV的大小。字节数作为此参数跟随。默认值是2 x 1024 x 1024。'
- en: '`--formater`: This is the name of the class to use for formatting messages
    for display. The default value is `NewlineMessageFormatter`.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--formater`: 这是用于格式化消息以显示的类的名称。默认值是`NewlineMessageFormatter`。'
- en: '`--autocommit.interval.ms`: This is the time interval at which to save the
    current offset in milliseconds. The time in milliseconds follows as argument.
    The default value is 10,000.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--autocommit.interval.ms`: 这是保存当前偏移量所用的时间间隔，单位为毫秒。毫秒数作为参数跟随。默认值是10,000。'
- en: '`--max-messages`: This is the maximum number of messages to consume before
    exiting. If not set, the consumption is continuous. The number of messages follows
    as the argument.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--max-messages`: 这是退出前要消费的最大消息数。如果没有设置，则消费是连续的。消息数作为参数跟随。'
- en: '`--skip-message-on-error`: If there is an error while processing a message,
    the system should skip it instead of halting.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--skip-message-on-error`：如果在处理消息时出现错误，系统应跳过它而不是停止。'
- en: 'The most requested forms of this command are as follows:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令最常用的形式如下：
- en: 'To consume just one message, use the following:'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要消费一条消息，请使用以下命令：
- en: '[PRE54]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'To consume one message from an offset, use the following:'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要从偏移量消费一条消息，请使用以下命令：
- en: '[PRE55]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'To consume messages from a specific consumer group, use the following:'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要从特定的消费者组消费消息，请使用以下命令：
- en: '[PRE56]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Using kafkacat
  id: totrans-308
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 kafkacat
- en: kafkacat is a generic command-line non-JVM utility used to test and debug Apache
    Kafka deployments. kafkacat can be used to produce, consume, and list topic and
    partition information for Kafka. kafkacat is netcat for Kafka, and it is a tool
    for inspecting and creating data in Kafka.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: kafkacat 是一个通用的命令行非 JVM 工具，用于测试和调试 Apache Kafka 部署。kafkacat 可以用于生产、消费和列出 Kafka
    的主题和分区信息。kafkacat 是 Kafka 的 netcat，它是一个用于检查和创建 Kafka 中数据的工具。
- en: kafkacat is similar to the Kafka console producer and Kafka console consumer,
    but more powerful.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: kafkacat 类似于 Kafka 控制台生产者和 Kafka 控制台消费者，但功能更强大。
- en: kafkacat is an open source utility and it is not included in Confluent Platform.
    It is available at [https://github.com/edenhill/kafkacat](https://github.com/edenhill/kafkacat).
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: kafkacat 是一个开源实用程序，它不包括在 Confluent 平台中。它可在 [https://github.com/edenhill/kafkacat](https://github.com/edenhill/kafkacat)
    获取。
- en: 'To install `kafkacat` on modern Linux, type the following:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 要在现代 Linux 上安装 `kafkacat`，请输入以下命令：
- en: '[PRE57]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'To install `kafkacat` on macOS with `brew,` type the following:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 macOS 上使用 `brew` 安装 `kafkacat`，请输入以下命令：
- en: '[PRE58]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'To subscribe to `amazingTopic` and `redundantTopic` and print to `stdout`,
    type the following:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 要订阅 `amazingTopic` 和 `redundantTopic` 并打印到 `stdout`，请输入以下命令：
- en: '[PRE59]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Summary
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we've learned what Kafka is, how to install and run Kafka in
    Linux and macOS and how to install and run Confluent Platform.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了 Kafka 是什么，如何在 Linux 和 macOS 上安装和运行 Kafka，以及如何安装和运行 Confluent 平台。
- en: Also, we've reviewed how to run Kafka brokers and topics, how to run a command-line
    message producer and consumer, and how to use kafkacat.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还回顾了如何运行 Kafka 代理和主题，如何运行命令行消息生产者和消费者，以及如何使用 kafkacat。
- en: In [Chapter 2](0f0c3c87-3860-4247-97b7-3ce070640dc3.xhtml), *Message Validation*,
    we will analyze how to build a producer and a consumer from Java.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第 2 章](0f0c3c87-3860-4247-97b7-3ce070640dc3.xhtml) *消息验证* 中，我们将分析如何从 Java
    中构建生产者和消费者。
