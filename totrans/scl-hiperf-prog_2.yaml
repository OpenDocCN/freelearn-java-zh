- en: Chapter 2.  Measuring Performance on the JVM
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章. 在JVM上衡量性能
- en: 'In the previous chapter, we introduced and defined important concepts that
    are related to performance. While extremely valuable, our journey so far has been
    somewhat academic, and you may grow impatient to exercise your newly acquired
    knowledge. Luckily, this second chapter does just this! We will take a close look
    at a real-world scenario and dive head first into the code to profile the application
    and measure its performance characteristics. This hands-on chapter focuses on
    one of MV Trading''s most successful products: the order book. This is a critical
    piece of software that was developed to deliver high throughput while maintaining
    low latency. In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们介绍了与性能相关的重要概念。虽然非常有价值，但到目前为止，我们的旅程多少有些学术性，你可能已经迫不及待地想要运用你新获得的知识。幸运的是，第二章正是这样做的！我们将仔细研究一个真实场景，并深入代码以分析应用程序并测量其性能特征。本章的实战部分专注于MV
    Trading最成功的产品之一：订单簿。这是为了在保持低延迟的同时提供高吞吐量而开发的软件。在本章中，我们将涵盖以下主题：
- en: Benchmarking the latency and throughput of an application
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对应用程序的延迟和吞吐量进行基准测试
- en: Profiling a system with Flight Recorder
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Flight Recorder分析系统
- en: Using JMH to microbenchmark our code
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用JMH进行代码微基准测试
- en: A peek into the financial domain
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 漫步金融领域
- en: This month marks the one year anniversary for **MV Trading** (**MVT**). In the
    last year, the company delivered great returns to its clients by capitalizing
    on novel trading strategies. These strategies work most effectively when trades
    can be placed within milliseconds of receiving new price information. To support
    trading with low latency, the MVT engineering team directly integrated into a
    stock market exchange. Exchange integration involved datacenter work to collocate
    the trading system with the exchange and development effort to build the trading
    system.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本月标志着**MV Trading**（**MVT**）成立一周年的纪念日。在过去的一年里，公司通过利用新颖的交易策略，为客户带来了丰厚的回报。这些策略在能够在新价格信息接收后的毫秒内完成交易时最为有效。为了支持低延迟的交易，MVT工程团队直接集成到股票交易所。交易所集成涉及数据中心工作，将交易系统与交易所协同定位，以及开发工作以构建交易系统。
- en: 'A key component of the trading system, known as the order book, holds the state
    of the exchange. The goal of the exchange is to keep track of how many buyers
    and sellers have an active interest in a stock and at what price each side is
    willing to trade. As traders, such as MVT, submit orders to buy and sell a stock,
    the exchange determines when a trade happens and notifies the buyer and the seller
    about the transaction. The state managed by the exchange and by extension, MVT,
    is interesting because orders do not always execute when they reach the exchange.
    Instead, orders can remain in an open or pending state for up to the length of
    the trading day (on the order of six hours). This first version of the order book
    allows traders to place orders called limit orders. Limit orders include a constraint
    on the minimally-acceptable price. For buys, the limit represents the highest
    price that the trader wishes to pay, and for sells, this indicates the lowest
    price the trader wishes to receive in exchange for the stock. Another operation
    that is supported by the order book is the cancelation of an outstanding limit
    order, which removes its presence from the book. To help summarize the possible
    order states, the following table itemizes possible outcomes to support exchange
    actions:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 交易系统的一个关键组件，称为订单簿，持有交易所的状态。交易所的目标是跟踪有多少买家和卖家对某只股票有活跃的兴趣，以及每一方愿意以什么价格进行交易。作为交易者，例如MVT，提交买卖股票的订单时，交易所会确定何时发生交易，并通知买家和卖家关于交易的信息。交易所和MVT所管理的状态很有趣，因为订单并不总是在达到交易所时执行。相反，订单可以保持开放或挂起状态，直到交易日的长度（大约六小时）。这个订单簿的第一个版本允许交易者放置称为限价订单的订单。限价订单包括对最低可接受价格的约束。对于购买，限价代表交易者愿意支付的最高价格，对于销售，这表示交易者愿意为股票接受的最低价格。订单簿支持的另一个操作是取消未完成的限价订单，这将从簿中移除其存在。为了帮助总结可能的订单状态，以下表格列出了支持交易所动作的可能结果：
- en: '| **Exchange action** | **Outcome** |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| **交换动作** | **结果** |'
- en: '| Limit order with a price worse than best bid or offer submitted. | The order
    rests on the book, meaning that the order remains in a pending state until an
    order from the opposing side generates a trade or the submitted order is canceled.
    |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 提交了价格低于最佳出价或要价的限价订单。 | 订单停留在订单簿上，这意味着订单将保持待处理状态，直到来自对立方的订单生成交易或提交的订单被取消。
    |'
- en: '| Limit order with a price better than or equal to best bid or offer submitted.
    | The order crosses the book. Crossing the book is industry jargon that indicates
    an order caused a trade to happen because its price matched one or more orders
    from the opposing side of the book. A trade consists of two executions, one per
    side. |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| 提交了价格高于或等于最佳出价或要价的限价订单。 | 订单成交。成交是行业术语，表示订单因为其价格与订单簿对立方的订单相匹配而触发了交易。一笔交易包括两次执行，每次一边。
    |'
- en: '| Cancelation submitted for a resting order. | The resting order is removed
    from the book. |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| 提交了取消挂单的请求。 | 挂单从订单簿中移除。 |'
- en: '| Cancelation submitted for an already executed or non-existent order. | The
    cancelation request is rejected. |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 提交了取消已执行或不存在订单的请求。 | 取消请求被拒绝。 |'
- en: Let's suppose that as a newly-hired MVT employee, you just joined the engineering
    team that is in charge of maintaining and improving the order book. Today is your
    first day, and you are planning to take most of the morning to calmly skim through
    the code and get familiar with the application.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你作为新聘用的MVT员工，刚刚加入负责维护和改进订单簿的工程团队。今天是你的第一天，你计划用大部分上午时间平静地浏览代码，熟悉应用程序。
- en: 'After checking out the source code repository, you start with the domain model:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在检出源代码仓库后，你从领域模型开始：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The class and trait definitions in the preceding code represent the business
    concepts. We especially notice the two kinds of orders (`BuyLimitOrder` and `SellLimitOrder`)
    that are identified by their unique ID and the associated price assumed to be
    in USD.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码中的类和特质定义代表了业务概念。我们特别注意到了两种订单（`BuyLimitOrder`和`SellLimitOrder`），它们通过唯一的ID和假设为美元的价格来识别。
- en: Note
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: You may wonder why we decided to create distinct class definitions for `Price`
    and `OrderId` while they only serve as mere wrappers for a unique attribute (respectively
    a `BigDecimal` for the price, and a `Long` for the unique ID). Alternatively,
    we can instead rely directly on the primitive types.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道为什么我们决定为`Price`和`OrderId`创建不同的类定义，尽管它们仅仅作为唯一属性的包装（分别是一个用于价格的`BigDecimal`和一个用于唯一ID的`Long`）。或者，我们也可以直接依赖原始类型。
- en: 'A `BigDecimal` could represent a lot of different things, including a price,
    but also a tax rate or a latitude on the globe. Using a specific type, named `Price`,
    gives contextual meaning to the `BigDecimal` and makes sure that the compiler
    helps us catch possible errors. We believe that it is good practice to always
    define explicit types to represent business concerns. This technique is part of
    the best practices known as domain-driven design, and we often apply these principles
    throughout the book. To learn more about this approach to software development,
    we recommend the excellent book *Domain-Driven Design: Tackling Complexity in
    the Heart of Software* ([http://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215](http://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215))
    by Eric Evans.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '`BigDecimal`可以代表很多不同的事物，包括价格，但也可以是税率或地球上的纬度。使用一个名为`Price`的特定类型，给`BigDecimal`赋予上下文意义，并确保编译器帮助我们捕捉可能的错误。我们相信，始终定义明确的类型来表示业务关注点是良好的实践。这项技术是被称为领域驱动设计的最佳实践之一，我们在整本书中经常应用这些原则。要了解更多关于这种软件开发方法的信息，我们推荐由Eric
    Evans所著的优秀书籍《领域驱动设计：软件核心的复杂性处理》（[http://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215](http://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215)）。'
- en: 'The `OrderBook` module leverages the domain model to define the available commands
    and the resulting events that can be produced by the book:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`OrderBook`模块利用领域模型来定义可用的命令以及由订单产生的结果事件：'
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s suppose that you are about to look at the implementation of the `handle`
    function in detail when you notice a message in your IM client from your technical
    lead, Alice: "Everybody in the conference room. We have a problem in production!"'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正准备详细查看`handle`函数的实现，这时你在即时通讯客户端收到技术负责人Alice的消息：“会议室所有人，生产环境中出现了问题！”
- en: Note
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Readers with financial domain expertise likely realize that the presented actions
    reflect a subset of the functionality of an actual financial exchange. One evident
    example is the absence of quantity from an order. In our examples, we assume each
    order represents a desire to buy an equal number of shares (for example, 100 shares).
    Experienced readers are aware that order volume further complicates order book
    state management, for example, by introducing the notion of partial executions.
    We are deliberately simplifying the domain to balance working on a realistic problem
    while minimizing the barrier to comprehension for readers who are new to the domain.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有金融领域专业知识的读者可能会意识到，所提出的行动反映了实际金融交易所功能的一个子集。一个明显的例子是订单中缺少数量。在我们的例子中，我们假设每个订单代表购买相等数量的股票（例如，100股）。有经验的读者知道，订单量进一步复杂化了订单簿状态管理，例如，通过引入部分执行的概念。我们故意简化了领域，以在处理现实问题的同时，最大限度地减少对领域新手的理解障碍。
- en: Unexpected volatility crushes profits
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 意外的波动摧毁了利润
- en: Alice and the head trader, Dave, kick off the meeting by summarizing the production
    problem. You digested a lot of insight into the problem from the meeting. You
    learned that currently, there is high market volatility and the rapid swings in
    prices amplify opportunities to generate profitable trades. Unfortunately for
    MVT, in recent weeks, the high volatility has brought with it unseen levels of
    order volume. Traders have been flooding the markets with limit orders and cancelations
    to react to the quickly changing price action. The MVT order book is certified
    via load testing to handle a maximum of 15,000 orders per second (OPS) with a
    99^(th) percentile latency of 10 milliseconds (ms). The current market conditions
    are producing sustained levels of 45,000 OPS, which is destroying tail-end order
    book latencies. In production, the deployed version of the order book is now producing
    99^(th) percentile latencies of up to 80 ms and maximum latencies reaching 200
    ms. In the trading business, a slow reaction can quickly turn a profitable trade
    into a sizable loss. This is exactly what has been happening at MVT. Typically,
    in times of volatility, MVT is able to generate healthy returns, but in recent
    weeks, there have been staggering losses. Our goal is to apply the techniques
    that we learned in [Chapter 1](ch01.html "Chapter 1.  The Road to Performance"),
    *The Road to Performance*, to make inroads on the performance woes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Alice和首席交易员Dave通过总结生产问题开始了会议。你在会议中从问题中汲取了很多洞见。你了解到，目前市场波动性很高，价格的快速波动放大了产生盈利交易的机会。不幸的是，对于MVT来说，在最近几周，高波动性带来了前所未有的订单量。交易员们正在向市场大量提交限价订单和取消订单，以应对价格变化的快速行动。MVT的订单簿通过负载测试认证，可以处理每秒最多15,000个订单（OPS），99^(th)百分位延迟为10毫秒（ms）。当前市场条件产生了持续的水平为45,000
    OPS，这正在摧毁尾部订单簿的延迟。在生产中，部署的订单簿版本现在产生99^(th)百分位延迟高达80毫秒，最大延迟达到200毫秒。在交易业务中，反应慢可能会迅速将盈利交易变成巨大的损失。这正是MVT正在发生的事情。通常，在波动时期，MVT能够产生健康的回报，但最近几周，损失惊人。我们的目标是应用我们在[第1章](ch01.html
    "第1章。性能之路")《性能之路》中学到的技术，来克服性能问题。
- en: The traders at MVT are looking for a quick performance win to take advantage
    of the current market environment. The traders believe that the market volatility
    will persist for another week before subsiding. Once the volatility disappears,
    so do money-making opportunities. Therefore, it's been stressed to the engineering
    team that an incremental reduction in 99^(th) percentile latency to 40 ms should
    halt trading strategy losses and actually produce small profits. Once the volatility
    subsides, more in-depth and extensive performance improvements are welcomed. For
    now, the clock is ticking, and we need to find a way to stop the losses by improving
    performance incrementally.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: MVT的交易员正在寻找快速的性能提升，以利用当前的市场环境。交易员们相信市场波动将持续另一周才会平息。一旦波动消失，赚钱的机会也随之消失。因此，已经强调给工程团队，将99^(th)百分位延迟从40毫秒逐步降低，应该能够停止交易策略的损失并实际上产生小额利润。一旦波动平息，更深入和广泛的表现改进将受到欢迎。目前，时间正在流逝，我们需要通过逐步提高性能来找到停止损失的方法。
- en: Reproducing the problem
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重复问题
- en: This is not quite the first day you were expecting, but what an exciting challenge
    ahead of you! We start our investigation of the performance issue by reproducing
    the problem. As we mentioned in the previous chapter, it is always critical to
    properly benchmark an application to establish a baseline. The baseline is used
    to evaluate the effectiveness of any improvement that we may try to implement.
    We create two simple benchmarks to reproduce the load observed in production and
    measure the throughput and latency of the system.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是你预期的第一天，但前方有一个多么激动人心的挑战！我们通过重现问题来开始对性能问题的调查。正如我们在上一章中提到的，正确基准测试一个应用程序以建立基线总是至关重要的。基线用于评估我们可能尝试实施的任何改进的有效性。我们创建了两个简单的基准测试来重现生产中观察到的负载，并测量系统的吞吐量和延迟。
- en: Note
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Note
- en: But wait, I have not finished studying how `OrderBook` is actually implemented!
    You are correct! You still have no idea of the implementation of the module. However,
    production is broken, and we need to act fast! More seriously, this is our way
    of highlighting an important characteristic of benchmarking that we mentioned
    in [Chapter 1](ch01.html "Chapter 1.  The Road to Performance"), *The Road to
    Performance*. Benchmarks treat the application as a black box. You had time to
    study the module interface, and this is enough to write good benchmarks.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 但是等等，我还没有完成对`OrderBook`实际实现的研究！你说得对！你仍然不知道该模块的实现。然而，生产环境已经出现问题，我们需要迅速采取行动！更严重的是，这是我们强调基准测试的一个重要特性的方式，我们在[第1章](ch01.html
    "第1章。性能之路")《性能之路》中提到了这个特性。基准测试将应用程序视为一个黑盒。你有机会研究模块接口，这足以编写好的基准测试。
- en: Throughput benchmark
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Throughput benchmark
- en: Our first benchmark measures the throughput of our application. The operations
    team provided us with historical data that was logged from the production environment.
    This data contains several hundred thousand actual commands that were processed
    by the order book. We use this sample and replay these messages against a testing
    environment to get an accurate idea of the system's behavior.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个基准测试测量我们应用程序的吞吐量。操作团队为我们提供了从生产环境中记录的历史数据。这些数据包含了几十万条实际命令，这些命令由订单簿处理。我们使用这个样本，并在测试环境中重新播放这些消息，以获得对系统行为的准确了解。
- en: Note
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Note
- en: Recall from [Chapter 1](ch01.html "Chapter 1.  The Road to Performance"), *The
    Road to Performance*, that it is important to run all benchmarks under the exact
    same environment to be able to compare them. To ensure consistency across tests,
    we created a command generator that is capable of outputting a static set of commands.
    We encourage you to review it.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从[第1章](ch01.html "第1章。性能之路")《性能之路》中回顾，运行所有基准测试在完全相同的环境下是很重要的，这样才能进行比较。为了确保测试的一致性，我们创建了一个命令生成器，能够输出一组静态的命令。我们鼓励您对其进行审查。
- en: 'Here is the code for our throughput benchmark, which you can find under the
    chapter subproject:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们吞吐量基准测试的代码，您可以在章节子项目中找到：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The code is fairly straightforward, so let's walk through it. First, we read
    our input arguments, the first one being the path to the file that contains our
    historical data, and the second one is the number of commands that we want to
    run. Note that in our implementation, if we ask for more commands than what is
    contained in our static file, the program will just loop through the provided
    commands. We then warm up the JVM by executing up to 100,000 commands without
    recording any throughput information. The point of a warm-up is to give the JVM
    the opportunity to exercise the code and find possible hotspots that can be optimized
    by the **just-in-time** (**JIT**) compiler.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 代码相当直接，让我们来了解一下。首先，我们读取输入参数，第一个是包含我们历史数据的文件路径，第二个是我们想要运行的命令数量。请注意，在我们的实现中，如果我们请求的命令数量超过了静态文件中的数量，程序将只会循环遍历提供的命令。然后，我们通过执行多达100,000条命令而不记录任何吞吐量信息来预热JVM。预热的目的给JVM一个机会来执行代码并找到可以被即时编译器（**JIT**）优化的潜在热点。
- en: Note
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Note
- en: The JIT compiler is a compiler that runs after the application has been started.
    It compiles the bytecode (that is, the result of the first compilation by the
    `javac` compiler) on-the-fly into an optimized form, usually native instructions
    for the operating system. The JIT is able to optimize the code, based on runtime
    usage. This is something that the traditional compiler cannot do because it runs
    before the code can be executed.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: JIT 编译器是在应用程序启动后运行的编译器。它将字节码（即`javac`编译器第一次编译的结果）即时编译成优化的形式，通常是操作系统的原生指令。JIT
    能够根据运行时使用情况优化代码，这是传统编译器无法做到的，因为它在代码可以执行之前运行。
- en: 'The next part of the code is where we actually record the throughput. We save
    the starting timestamp, execute all the commands against an initially empty order
    book, and record the end timestamp. Our throughput in operations per second is
    easily calculated by dividing the command count by the elapsed time to execute
    them all. As our throughput is measured in seconds, millisecond precision is sufficient
    for our benchmarking needs. Lastly, we print out the interesting results. We can
    run this benchmark parameterized with 250,000 commands by issuing:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的下一部分是我们实际记录吞吐量的地方。我们保存了开始时间戳，执行了针对最初为空的订单簿的所有命令，并记录了结束时间戳。通过将命令计数除以执行所有命令的耗时，我们可以轻松计算出每秒的操作吞吐量。由于我们的吞吐量是以秒为单位的，因此对于我们的基准测试需求，毫秒级的精度是足够的。最后，我们打印出有趣的结果。我们可以通过以下命令以250,000个命令为参数运行此基准测试：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Running the benchmark over a range of command counts yields the following results:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在一系列命令计数范围内运行基准测试，得到以下结果：
- en: '| **Command count** | **Processing time (seconds)** | **Throughput (operations
    per second)** |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| **命令计数** | **处理时间（秒）** | **吞吐量（每秒操作数）** |'
- en: '| 250,000 | 2.2 | 112,309 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 25万 | 2.2 | 112,309 |'
- en: '| 500,000 | 6.1 | 81,886 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 50万 | 6.1 | 81,886 |'
- en: '| 750,000 | 12.83 | 58,456 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 75万 | 12.83 | 58,456 |'
- en: '| 1,000,000 | 22.56 | 44,328 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 100万 | 22.56 | 44,328 |'
- en: We can see that when the command count increases, our throughput decreases.
    One explanation could be that the order book grows in size when receiving more
    orders, and thus becomes less efficient. At this point, we are able to evaluate
    the throughput of our application. In the next section, we focus on measuring
    the latency of the program.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，当命令计数增加时，我们的吞吐量下降。一个可能的解释是，当收到更多订单时，订单簿的大小增加，因此效率降低。在此阶段，我们能够评估我们应用程序的吞吐量。在下一节中，我们将专注于测量程序的延迟。
- en: Note
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: Our benchmark and the ones that we will write later in this chapter are naive.
    It runs the test and the order book in the same JVM. A more realistic example
    would involve an order book with a server that maintains TCP connections to clients
    exchanging FIX messages (FIX being the most widely-used protocol in finance) to
    place or cancel orders. Our benchmark would impersonate one of these clients to
    simulate production load on our order book. For the sake of simplicity and to
    allow us to focus on more interesting subjects, we decided to leave this concern
    aside.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的基准测试以及本章后面将要编写的基准测试都是简单的。它在一个 JVM 中运行测试和订单簿。一个更现实的例子将涉及一个与客户端交换 FIX 消息（FIX
    是金融界最广泛使用的协议）以放置或取消订单的维护 TCP 连接的服务器订单簿。我们的基准测试将模拟这些客户端之一，以模拟我们订单簿的生产负载。为了简单起见，并允许我们关注更有趣的主题，我们决定将这个问题放在一边。
- en: Latency benchmark
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 延迟基准测试
- en: Recall from [Chapter 1](ch01.html "Chapter 1.  The Road to Performance"), *The
    Road to Performance*, that the latency is the time that it takes for an operation
    to happen, where the definition of an operation depends on your domain. In our
    case, we define an operation as the processing of a command from the time it is
    received to the time a new order book and a corresponding event are generated.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下[第1章](ch01.html "第1章。性能之路")《性能之路》，延迟是指操作发生所需的时间，而操作的定义取决于你的领域。在我们的情况下，我们将操作定义为从收到命令到生成新的订单簿和相应事件的时间处理。
- en: The first latency benchmark
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 首次延迟基准测试
- en: 'The following listing shows a first version of our latency benchmark:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表展示了我们延迟基准测试的第一个版本：
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The beginning of this code is similar to what we had in our throughput benchmark.
    We use an HdrHistogram to record each operation's latency. The tail-recursive
    method `sendCommands` is where most of the interesting things happen (we take
    a closer look at tail-recursion in a later chapter). Our commands are grouped
    by batches of size and `commandsPerSecond`, meaning that we will send one batch
    per second. We record the current time before sending a command (`operationStart`)
    and after receiving a response (`operationEnd`). These timestamps are used to
    update the histogram.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的开始部分与我们在吞吐量基准测试中使用的类似。我们使用HdrHistogram来记录每个操作的延迟。尾递归方法`sendCommands`是大多数有趣事情发生的地方（我们将在后面的章节中更详细地探讨尾递归）。我们的命令按大小和`commandsPerSecond`的批次分组，这意味着我们将每秒发送一个批次。我们在发送命令之前记录当前时间（`operationStart`）和收到响应之后（`operationEnd`）。这些时间戳用于更新直方图。
- en: Note
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: HdrHistogram is an efficient implementation of a histogram. This is specifically
    designed to be used in latency and performance-sensitive applications. It maintains
    a fixed cost both in space and time. It does not involve memory allocation operations,
    and its memory footprint is constant. To learn more about HdrHistogram, visit
    [http://hdrhistogram.org/](http://hdrhistogram.org/).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: HdrHistogram是直方图的高效实现。它专门设计用于在延迟和性能敏感的应用中。它在空间和时间上保持固定的成本。它不涉及内存分配操作，其内存占用是恒定的。要了解更多关于HdrHistogram的信息，请访问[http://hdrhistogram.org/](http://hdrhistogram.org/)。
- en: 'At the end, after all batches have been processed, we take a snapshot of the
    state of the histogram and print interesting metrics. Let''s give this a run:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在所有批次都处理完毕后，我们会对直方图的状态进行快照并打印有趣的指标。让我们运行一下这个测试：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We exercise our system with a rate of 45,000 operations per second for 10 seconds,
    and we see a latency of 1 ms for the 99.9^(th) percentile. These are outstanding
    results! They are also completely wrong. In our hurry to write a latency benchmark,
    we overlooked a too often ignored issue: the coordinated omission problem.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以每秒45,000次操作的速度对我们的系统进行了10秒的测试，并观察到99.9百分位数的延迟为1毫秒。这些是出色的结果！但它们也是完全错误的。在我们匆忙编写延迟基准测试时，我们忽略了一个经常被忽视的问题：协同遗漏问题。
- en: The coordinated omission problem
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 协同遗漏问题
- en: 'Our benchmark is broken because we measure the time required to process a command
    without taking into account the time the command had to wait to be processed.
    This becomes a problem if the previous command took longer than expected to be
    processed. Take our previous example: we ran 45,000 commands per second, that
    is, 45 commands per millisecond. What if processing the first 45 commands takes
    longer than 1 millisecond? The next 45 commands have to wait before being picked
    up and processed. However, with our current benchmark, we ignore this waiting
    time. Let''s take an example of a web application serving pages over HTTP. A typical
    benchmark may record request latency by measuring the elapsed time between the
    moment a request is handled by the web server and the time a response is ready
    to be sent back. However, this would not account for the time it took for the
    web server to read the request and actually send back the response. A better benchmark
    will measure the latency as the time between the moment the client sent the request
    and the moment it actually received a response. To learn more about the coordinated
    omission problem, refer to the discussion thread containing direct links to articles
    and presentations at [https://groups.google.com/forum/#!msg/mechanical-sympathy/icNZJejUHfE/BfDekfBEs_sJ](https://groups.google.com/forum/#!msg/mechanical-sympathy/icNZJejUHfE/BfDekfBEs_sJ).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的基准测试是错误的，因为我们测量处理命令所需的时间，而没有考虑到命令等待处理的时间。如果之前的命令处理时间超过了预期，这就会成为一个问题。以我们的先前的例子来说：我们每秒运行45,000个命令，即每毫秒45个命令。如果处理前45个命令需要超过1毫秒的时间怎么办？接下来的45个命令必须等待才能被选中并处理。然而，在我们的当前基准测试中，我们忽略了这种等待时间。让我们以一个通过HTTP提供网页的Web应用程序为例。一个典型的基准测试可能会通过测量请求处理和响应准备发送之间的时间来记录请求延迟。然而，这不会考虑到Web服务器读取请求并实际发送响应所需的时间。一个更好的基准测试将测量客户端发送请求和实际收到响应之间的延迟。要了解更多关于协同遗漏问题的信息，请参考包含直接链接到文章和演示文稿的讨论线程[https://groups.google.com/forum/#!msg/mechanical-sympathy/icNZJejUHfE/BfDekfBEs_sJ](https://groups.google.com/forum/#!msg/mechanical-sympathy/icNZJejUHfE/BfDekfBEs_sJ)。
- en: To fix this problem, we need to record `operationStart` not when we start processing
    a batch of commands, but when the batch of commands should have been processed,
    regardless of whether the system is late.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们需要记录 `operationStart`，而不是当我们开始处理一批命令时，而是在这批命令应该被处理时，无论系统是否延迟。
- en: The second latency benchmark
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第二个延迟基准
- en: In our second attempt, we make sure to start the clock to take into account
    when a command is meant to be sent, as opposed to when it is ready to be processed.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的第二次尝试中，我们确保在考虑命令应该发送的时间时启动时钟，而不是它准备好被处理的时间。
- en: 'The benchmark code remains unchanged except for the recording of latency, which
    now uses `shouldStart` instead of `operationStart`:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试代码除了记录延迟外保持不变，现在使用 `shouldStart` 而不是 `operationStart`：
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'After this change, this is the new benchmark output:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 此更改后，这是新的基准输出：
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The results are very different when compared to our first benchmark. Actually,
    this new code also has a flaw. This assumes that all the requests sent in the same
    second are supposed to be processed at the very beginning of this second. While
    technically possible, it is more likely that these commands will be sent at different
    times during the second (a few during the first millisecond, some more during
    the second millisecond, and so on). Our current benchmark probably greatly overestimates
    our latency by starting the timer too soon for most commands.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们的第一次基准测试相比，结果非常不同。实际上，这段新代码也存在一个缺陷。它假设在同一秒内发送的所有请求都应该在这一秒的开始时被处理。虽然技术上可行，但更有可能的是这些命令将在第二秒的不同时间发送（一些在第一毫秒，一些在第二毫秒，依此类推）。我们当前的基准测试可能大大高估了我们的延迟，因为大多数命令的计时器启动得太早。
- en: The final latency benchmark
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最终的延迟基准
- en: We will attempt to fix the latest issue and finally come up with a reliable
    benchmark. At this point, we are trying to address the problem of the distribution
    of the commands over each second. The best way to solve this issue would be to
    use real production data. If the recorded commands that we are using for our benchmark
    had a timestamp attached to them (that is, the moment they were received by the
    production system), we could replicate the distribution of commands observed in
    production.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试修复最新问题，并最终制定一个可靠的基准。在这个阶段，我们正在尝试解决每秒命令分布的问题。解决这个问题的最佳方法就是使用真实的生产数据。如果我们用于基准测试的记录命令附有时间戳（即，它们被生产系统接收的时刻），我们就可以复制在生产中观察到的命令分布。
- en: Unfortunately, our current order book application does not record the timestamp
    when logging data. We could go different routes. One option is to randomly send
    the commands over a second. Another is to assume an even distribution of the commands
    (that is, the same amount is sent on each millisecond).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，我们当前的订单簿应用程序在记录数据时没有记录时间戳。我们可以选择不同的路线。一个选项是随机在第二秒发送命令。另一个选项是假设命令的均匀分布（即，每个毫秒发送相同数量的命令）。
- en: 'We choose to modify the benchmark assuming the latter. To accomplish this goal,
    we modify the generation of events. As our new strategy distributes commands over
    time rather than batching commands, for a single instant, the new command list
    return type changes from `List[(List[Command], Int)]` to `List[(Command, Int)]`.
    The logic to generate the command list changes to account for our new strategy,
    as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择修改基准测试，假设后者。为了实现这个目标，我们修改了事件的生成。由于我们的新策略是在时间上分布命令而不是批量处理命令，对于单个瞬间，新的命令列表返回类型从
    `List[(List[Command], Int)]` 变为 `List[(Command, Int)]`。生成命令列表的逻辑也相应地改变，如下所示：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The creation of our set of commands is a bit more involved. We now calculate
    an offset for each command, taking into account the amount of milliseconds that
    should elapse between each command. Our final results with this benchmark are
    as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建命令集的过程稍微复杂一些。我们现在为每个命令计算一个偏移量，考虑到每个命令之间应该经过的毫秒数。使用这个基准测试，我们的最终结果如下：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We finally established a good latency benchmark for our system, and sure enough,
    our results come close to what is currently being observed in production.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终为我们的系统建立了一个良好的延迟基准，确实，我们的结果接近当前在生产中观察到的结果。
- en: Note
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Hopefully, this exercise made you reflect on your own production system and
    what kind of operation you may want to benchmark. The main thing to take away
    from this section is the importance of properly recording an operation's latency
    and taking into account the coordinated omission problem. What do you think would
    be the best way to measure the latency of your system? If you already have benchmarks
    in place, do they account for the coordinated omission effect?
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这次练习让你反思了自己的生产系统以及你可能想要基准测试的操作类型。本节的主要收获是正确记录操作延迟并考虑协调遗漏问题的重要性。你认为衡量你系统延迟的最佳方法是什么？如果你已经有了基准测试，它们是否考虑了协调遗漏效应？
- en: Locating bottlenecks
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定位瓶颈
- en: Now that we are able to consistently reproduce the bad performance in production
    with our benchmark, we have confidence that the impact of any of the changes that
    we make can be accurately measured. The benchmarks treated the order book as a
    black box, meaning you have no insight into what areas of the order book are causing
    our performance woes. If you were previously familiar with this code, you could
    use your intuitions as a heuristic to make educated guesses about the subcomponents
    that require a deeper focus. As this is day one for you at MVT, you do not have
    previous intuition to rely on. Instead of guessing, we will profile the order
    book to gain deeper insights into various facets of our black box.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们能够一致地通过我们的基准测试在生产环境中重现不良性能，因此我们有信心可以准确测量我们做出的任何更改的影响。基准测试将订单簿视为一个黑盒，这意味着你无法洞察到订单簿的哪些区域导致了我们的性能问题。如果你之前熟悉这段代码，你可以利用你的直觉作为启发式方法，对需要更深入关注的子组件做出有根据的猜测。由于今天是你在MVT的第一天，你没有先前的直觉可以依赖。而不是猜测，我们将对订单簿进行剖析，以深入了解我们黑盒的各个方面。
- en: The JDK bundles an excellent profiler that is named Flight Recorder. Flight
    Recorder is free to use in nonproduction environments. Refer to Oracle's license,
    [http://docs.oracle.com/javacomponents/jmc-5-5/jfr-runtime-guide/about.htm](http://docs.oracle.com/javacomponents/jmc-5-5/jfr-runtime-guide/about.htm),
    to learn more about commercial usage. The existence of a great profiler is another
    reason that Scala is a pragmatic choice for production-quality functional programming.
    Flight Recorder works using internal JVM hooks to record events that are emitted
    by the JVM at runtime. The events that are captured by Flight Recorder cover memory
    allocation, thread state changes, IO activity, and CPU activity. To learn more
    about Flight Recorder internals, refer to Oracle's Flight Recorder documentation: [http://docs.oracle.com/javacomponents/jmc-5-5/jfr-runtime-guide/about.htm#sthref7](http://docs.oracle.com/javacomponents/jmc-5-5/jfr-runtime-guide/about.htm#sthref7).
    In contrast to third-party profilers, which do not have access to JVM internals,
    Flight Recorder is able to access data outside of JVM safepoints. A JVM safepoint
    is a time when all threads are suspended from execution. Safepoints are necessary
    to coordinate global JVM activities, including stop-the-world garbage collection.
    To read more about JVM safepoints, check out this excellent blog article by Alexey
    Ragozin at [http://blog.ragozin.info/2012/10/safepoints-in-hotspot-jvm.html](http://blog.ragozin.info/2012/10/safepoints-in-hotspot-jvm.html).
    If a profiler is only able to inspect at safepoints, it is likely the profiler
    is missing useful data points because only a partial picture emerges.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: JDK捆绑了一个名为Flight Recorder的优秀剖析器。Flight Recorder在非生产环境中免费使用。有关商业使用的更多信息，请参阅Oracle的许可协议，[http://docs.oracle.com/javacomponents/jmc-5-5/jfr-runtime-guide/about.htm](http://docs.oracle.com/javacomponents/jmc-5-5/jfr-runtime-guide/about.htm)。拥有一个优秀的剖析器是Scala成为生产质量函数式编程实用选择的原因之一。Flight
    Recorder通过使用内部JVM钩子来记录JVM在运行时发出的事件。Flight Recorder捕获的事件包括内存分配、线程状态变化、IO活动和CPU活动。要了解更多关于Flight
    Recorder内部的信息，请参阅Oracle的Flight Recorder文档：[http://docs.oracle.com/javacomponents/jmc-5-5/jfr-runtime-guide/about.htm#sthref7](http://docs.oracle.com/javacomponents/jmc-5-5/jfr-runtime-guide/about.htm#sthref7)。与无法访问JVM内部结构的第三方剖析器相比，Flight
    Recorder能够访问JVM安全点之外的数据。JVM安全点是一个所有线程都暂停执行的时间点。安全点是协调全局JVM活动（包括停止世界的垃圾收集）所必需的。要了解更多关于JVM安全点的信息，请查看Alexey
    Ragozin在[http://blog.ragozin.info/2012/10/safepoints-in-hotspot-jvm.html](http://blog.ragozin.info/2012/10/safepoints-in-hotspot-jvm.html)上发表的这篇优秀的博客文章。如果一个剖析器只能检查安全点，那么它很可能是缺少有用的数据点，因为只出现了一个部分画面。
- en: 'Let''s take our first look inside the order book by setting up a Flight Recorder
    trial. To expedite cycle time, we set up the profiler via `sbt` while we execute
    a run of `ThroughputBenchmark` replaying historical data. We set up Flight Recorder
    with the following JVM parameters:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 通过设置飞行记录器试验，让我们首先查看订单簿。为了加快周期时间，我们在执行`ThroughputBenchmark`回放历史数据的运行时，通过`sbt`设置分析器。我们使用以下JVM参数设置飞行记录器：
- en: '[PRE10]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The max JVM heap size is set to match our benchmark runs, followed by four
    JVM parameters. The `-XX:+UnlockCommercialFeatures` and `-XX:+FlightRecorder`
    parameters are required to emit JVM events for Flight Recorder. The Flight Recorder
    documentation references `-XX:+UnlockDiagnosticVMOptions` and `-XX:+DebugNonSafepoints`
    to improve sampling quality. These options instruct the compiler to generate metadata
    that enables Flight Recorder to capture samples that are not at safepoints. The
    final argument configures Flight Recorder to begin recording as soon as the program
    starts and to dump profiling results to the provided path when the program exits.
    In our case, this means that the profile will begin when the benchmark starts
    and terminate when the benchmark concludes. Alternatively, it is possible to configure
    Flight Recorder to delay its start time and to record for a fixed time by the
    following configurations:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最大JVM堆大小设置为与我们的基准测试运行匹配，然后是四个JVM参数。`-XX:+UnlockCommercialFeatures`和`-XX:+FlightRecorder`参数是必需的，以便为飞行记录器发出JVM事件。飞行记录器文档引用`-XX:+UnlockDiagnosticVMOptions`和`-XX:+DebugNonSafepoints`以改善采样质量。这些选项指示编译器生成元数据，使飞行记录器能够捕获不在安全点的样本。最后一个参数配置飞行记录器在程序启动时开始记录，并在程序退出时将配置文件结果输出到提供的路径。在我们的情况下，这意味着配置文件将在基准测试开始时开始，并在基准测试结束时终止。或者，也可以通过以下配置来配置飞行记录器，以延迟其启动时间并记录固定时间：
- en: '[PRE11]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The preceding options configure Flight Recorder to start after five seconds
    (the `delay` option) and record for one minute (the `duration` option). The result
    is stored in `/tmp/order-book.jfr`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的选项配置飞行记录器在五秒后（`delay`选项）启动并记录一分钟（`duration`选项）。结果存储在`/tmp/order-book.jfr`。
- en: 'We are now ready to generate profile results. Next, we run the benchmark configured
    to replay 2,000,000 requests. The more requests played back, the more opportunities
    there are for the profiler to capture JVM events. All other things equal, prefer
    longer profiles over shorter ones. The following output shows the benchmark invocation
    and the resulting output:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以生成配置文件结果了。接下来，我们运行配置为回放2,000,000个请求的基准测试。回放更多请求，分析器就有更多机会捕获JVM事件。在其他条件相同的情况下，应优先选择较长的配置文件而不是较短的配置文件。以下输出显示了基准测试调用及其结果：
- en: '[PRE12]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'To have a look at the profiling results, we use **Java Mission Control** (**JMC**),
    a free, bundled GUI that supports, among other features, inspecting Flight Recorder
    results, and running Flight Recorder profile sessions. JMC exists in the same
    directory as the Java executable, which means that it is accessible on your path
    by just typing the following:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看配置文件结果，我们使用**Java Mission Control**（**JMC**），这是一个免费捆绑的GUI，支持许多功能，包括检查飞行记录器结果和运行飞行记录器配置文件会话。JMC位于Java可执行文件的同一目录中，这意味着只需键入以下内容即可通过路径访问它：
- en: '[PRE13]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Once the GUI loads, open the profiler results by navigating to **File** | **Open**.
    Browse to the profile results and click on **OK** to load them. As we look at
    the results, we will build a checklist of questions to consider when reviewing
    profiler results. These probing questions are intended to make you critically
    analyze the results. These questions ensure that the experiment results truly
    address the hypothesis that led to the profile. At the end of this chapter, we
    will present the questions in a single checklist to make it easier to revisit
    later.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦GUI加载，通过导航到**文件** | **打开**来打开分析器结果。浏览到配置文件结果并点击**确定**以加载它们。在我们查看结果的同时，我们将构建一个清单，列出在审查分析器结果时需要考虑的问题。这些问题旨在让您批判性地分析结果。这些问题确保实验结果真正解决了导致配置文件的假设。在本章结束时，我们将这些问题以单个清单的形式呈现，以便以后更容易回顾。
- en: Did I test with the expected set of resources?
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我是否使用预期的资源集进行了测试？
- en: If the test environment was set up to use incorrect resources, the results are
    invalidated. For this reason, it makes sense to double-check the environment setup
    first. Fortunately, Flight Recorder captures much of this information for you.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果测试环境被设置为使用不正确的资源，则结果无效。因此，首先检查环境设置是有意义的。幸运的是，飞行记录器为您捕获了大部分这些信息。
- en: 'The **General** and **System** tab groups are the areas to focus on for this
    checklist item. In **General**, click on **JVM Information** to identify key JVM
    facts. In this section, confirm the following:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**常规**和**系统**选项卡组是本清单项需要关注的区域。在**常规**中，点击**JVM信息**以识别关键JVM事实。在本节中，确认以下内容：'
- en: '| Areas to focus on | Reason to focus on the area |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 重点关注区域 | 重点关注该区域的原因 |'
- en: '| --- | --- |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| JVM start time | This is a quick spot check that confirms that this test
    executed when you think it did. With a few profile results, ensuring that you
    are reviewing the correct results is trivial. As you collect more information
    and investigate additional hypotheses, this simple check ensures that you are
    not conflating results. |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| JVM启动时间 | 这是一个快速检查点，确认测试是在你认为的时间执行的。凭借一些配置文件结果，确保你正在审查正确的结果变得微不足道。随着你收集更多信息并调查更多假设，这个简单的检查确保你不会混淆结果。|'
- en: '| JVM version | Variations in JVM version can yield different results. Ensure
    that you are using the same JVM version as your production environment. |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| JVM版本 | JVM版本的差异会产生不同的结果。确保你使用的是与生产环境相同的JVM版本。|'
- en: '| JVM command-line arguments and JVM flags | It is common to tune the JVM via
    command-line arguments. Often, the parameterization will change between runs,
    making it difficult to recall later on which run corresponded to which set of
    arguments. Reviewing this information provides useful context to review the results.
    |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| JVM命令行参数和JVM标志 | 通过命令行参数调整JVM是很常见的。通常，参数化会在运行之间发生变化，这使得后来难以回忆起哪个运行对应于哪组参数。审查这些信息为审查结果提供了有用的背景。|'
- en: '| Java application arguments | Similar to the previous concern, the goal is
    to ensure that you are confident that you understand the inputs to your test.
    |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| Java应用程序参数 | 与前面的担忧类似，目标是确保你确信你理解了测试的输入。|'
- en: 'To supplement confirmation of JVM configuration, view the **GC Configuration**
    tab under the **Memory** tab group. This tab details garbage collection configuration,
    which reflects a combination of user-supplied configuration and JVM defaults.
    As you are likely aware, small changes in the garbage collection configuration
    can yield significant runtime performance changes. Given the sensitivity of application
    performance to garbage collection configuration, you should reflect on each parameter
    in this tab. Questions to consider while reviewing are as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 为了补充确认JVM配置，请在**内存**选项卡组下查看**GC配置**选项卡。此选项卡详细说明了垃圾收集配置，它反映了用户提供的配置和JVM默认值的组合。正如你所意识到的，垃圾收集配置的微小变化可能会产生显著的运行时性能变化。鉴于应用程序性能对垃圾收集配置的敏感性，你应该反思此选项卡中的每个参数。在审查时需要考虑的问题如下：
- en: If I configured this parameter, did the configured value take effect?
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我配置了此参数，配置的值是否生效？
- en: If I did not configure this parameter, what effect might tuning this value have?
    This question often helps you to create hypotheses for future profile runs.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我没有配置此参数，调整此值可能会产生什么影响？这个问题经常帮助你为未来的配置文件运行创建假设。
- en: 'Next, we focus on the **System** tab group. The **Overview** tab itemizes non-JVM
    resources to make it clear which resources were used to create this profile. Continuing
    with the theme of questions from the **General** tab group, the overarching goals
    are as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们关注**系统**选项卡组。**概览**选项卡列举了非JVM资源，以便清楚地了解创建此配置文件所使用的资源。继续从**常规**选项卡组的主题出发，总体目标如下：
- en: To confirm whether recorded information matches the resources that you expected
    to use (for example, does the amount of available RAM match how much you thought
    was present?)
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确认记录的信息是否与您预期的资源相匹配（例如，可用的RAM数量是否与您认为存在的数量相匹配？）
- en: To look for unexpected differences between the test resources and a production
    environment (for example, my local machine uses kernel v3.18.x while production
    is on an older minor version, v3.17.x)
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找测试资源和生产环境之间的意外差异（例如，我的本地机器使用内核版本v3.18.x，而生产环境使用较旧的次要版本，v3.17.x）
- en: If you are configuring your system via environment variables, there is an **Environment
    Variables** tab that should be reviewed. Like the **Overview** tab, you are looking
    to ensure your test resources are provisioned and configured as you intended.
    It bears repeating that any unexpected differences in your test resources always
    invalidate test results.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您通过环境变量配置系统，应该检查**环境变量**选项卡。与**概览**选项卡一样，您需要确保您的测试资源已按预期配置和提供。需要重复的是，测试资源中的任何意外差异都会使测试结果无效。
- en: Was the system environment clean during the profiling?
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析期间系统环境是否干净？
- en: 'Once you are comfortable that the appropriate resources were used, the next
    step is to confirm that only the application being profiled used resources. This
    is an important diagnostic step prior to reviewing test results because it ensures
    that the profiled application was truly isolated for the test. Fortunately, Flight
    Recorder catalogs useful information to answer this question. In the **System**
    tab group, the **Processes** tab captures all the processes running during the
    profiling. Scan this list with the following questions in mind:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您确信使用了适当的资源，下一步就是确认只有被分析的程序使用了资源。这是在审查测试结果之前的一个重要诊断步骤，因为它确保了被分析的程序在测试中确实被隔离。幸运的是，飞行记录器收集了有用的信息来回答这个问题。在**系统**选项卡组中，**进程**选项卡捕获了分析期间运行的所有进程。在查看此列表时，请考虑以下问题：
- en: When I scan the list of processes, do I see anything that should not be running?
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我扫描进程列表时，我是否看到任何不应该运行的进程？
- en: When I filter by the command-line column and enter `java`, do I see the expected
    set of JVM applications running?
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我通过命令行列进行筛选并输入`java`时，我是否看到预期的JVM应用程序运行集？
- en: When I scan the list of processes, do I see any duplicate processes?
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我扫描进程列表时，我是否看到任何重复的进程？
- en: Next, inspect the **Recording** tab under the **General** tab group. Flight
    Recorder provides the ability to create concurrent recordings. The profile results
    will contain the union of the concurrent recordings. If there are multiple recordings
    unexpectedly happening in only one of several runs, then you may not have an apples-to-apples
    results comparison between recordings.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在**常规**选项卡组下检查**记录**选项卡。飞行记录器提供了创建并发记录的能力。配置文件结果将包含并发记录的并集。如果只有几个运行中的一个出现了意外的多个记录，那么您可能无法在记录之间进行苹果对苹果的结果比较。
- en: 'The next area to focus on is system CPU usage over the duration of the profiling.
    Within the **General** tab group, select the **Overview** tab. This view displays
    the CPU usage panel, which provides you with the ability to inspect machine CPU
    usage throughout the recording. Here, you are looking for unexpected divergences
    between JVM and machine total CPU usage. The following screenshot depicts a scenario
    where there is a divergence worth investigating:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个需要关注的是在分析期间系统CPU的使用情况。在**常规**选项卡组中，选择**概览**选项卡。此视图显示CPU使用面板，它提供了在整个记录过程中检查机器CPU使用情况的能力。在这里，您正在寻找JVM和机器总CPU使用之间的意外差异。以下截图描述了一个值得调查的差异场景：
- en: '![Was the system environment clean during the profiling?](img/image_02_001.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![分析期间系统环境是否干净？](img/image_02_001.jpg)'
- en: Unexpected non-JVM CPU usage highlighted by the CPU Usage panel
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: CPU使用面板突出显示的意外非JVM CPU使用情况
- en: In the preceding screenshot, the combination of **JVM + Application (User)**
    and **JVM + Application (Kernel)** indicates the JVM-under-test's CPU usage, and
    **Machine Total** indicates machine (that is, JVM-under-test and all other processes)
    CPU usage. For the majority of this recording, the JVM-under-test CPU usage represents
    the majority of machine CPU usage. If your application should be the only process
    using system resources, then the small delta between the small delta between **JVM
    + Application (User)** and **Machine Total** represents the desired state. The
    divergences near the middle of the recording period indicate that another process
    or other processes were using CPU resources. These spikes suggest abnormal behavior
    that can negatively impact profiling results. It is worth considering what other
    processes are using system resources and whether or not your test results remain
    valid.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，**JVM + 应用（用户）**和**JVM + 应用（内核）**的组合表示正在测试的JVM的CPU使用情况，而**机器总**表示机器（即，正在测试的JVM和所有其他进程）的CPU使用情况。在这次记录的大部分时间里，正在测试的JVM的CPU使用情况代表了机器CPU使用情况的大部分。如果你的应用程序应该是唯一使用系统资源的进程，那么**JVM
    + 应用（用户）**和**机器总**之间的小差异就代表了期望的状态。记录期间中间附近的变化表明另一个进程或多个进程正在使用CPU资源。这些峰值表明了可能对分析结果产生负面影响的不正常行为。值得考虑其他进程正在使用系统资源，以及你的测试结果是否仍然有效。
- en: This is a good opportunity to introduce the range navigator, which is the small
    horizontal widget at the top of each tab containing red marks. The range navigator
    is a timeline that displays events from the current tab that happen over time
    with red marks. By default, the entire timeline is selected and the duration of
    the profiling is displayed above the center of the timeline. You can select a
    subset of the timeline to zoom in on an area of interest. For example, you may
    wish to zoom in on CPU usage when the machine CPU usage spikes up. When selecting
    a subset of the timeline and data is only available for a specific point in time
    (for example, at start of recording) or the data does not represent a time series
    (for example, the JVM version), then the data is hidden or replaced with N/A.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个介绍范围导航器的好机会，它是每个标签顶部的小型水平小部件，包含红色标记。范围导航器是一个时间线，它以红色标记显示当前标签中随时间发生的事件。默认情况下，整个时间线被选中，并且分析持续时间显示在时间线的中心上方。你可以选择时间线的一部分来放大感兴趣的区域。例如，你可能希望放大机器CPU使用率激增时的CPU使用情况。当选择时间线的一部分且数据只针对特定时间点（例如，记录开始时）可用，或者数据不表示时间序列（例如，JVM版本）时，则数据被隐藏或替换为N/A。
- en: 'A final spot check is to check the used machine physical memory in the **Memory
    Usage** panel in the **Overview** tab under the **Memory** tab group. During this
    spot, check whether you are trying to assess if the amount of used machine physical
    memory is a sensible value. If there is little machine physical memory remaining
    and the reserved heap is a small fraction of the total machine physical memory,
    you should pause to consider what other processes are using memory. This scenario
    is illustrated in the following screenshot:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在**内存**标签组下的**概览**标签页中的**内存使用**面板中进行最终检查，以检查已使用的机器物理内存。在此检查期间，检查你是否正在尝试评估已使用的机器物理内存量是否是一个合理的值。如果剩余的机器物理内存很少，而保留的堆内存只占总机器物理内存的一小部分，你应该暂停下来考虑其他进程正在使用内存。以下截图展示了这种情况：
- en: '![Was the system environment clean during the profiling?](img/image_02_002.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![分析期间系统环境是否干净？](img/image_02_002.jpg)'
- en: Non-JVM processes using most of the available memory captured by the Memory
    Usage panel
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 使用内存使用面板捕获的大多数可用内存的非JVM进程
- en: In the preceding example, the reserved heap space is 2 GB out of an available
    16 GB system memory, and 13 GB of system memory is used. This implies that 11
    GB of system memory is consumed by processes other than the profiled JVM. Unless
    you expect to have other processes running in your test environment, this type
    of memory-usage discrepancy warrants further investigation. For example, if your
    application makes use of off-heap memory, this discrepancy may invalidate your
    test results because your application may be unable to allocate memory as needed,
    or may result in excessive system swapping.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，预留的堆空间为2 GB，占可用16 GB系统内存的1/8，而系统内存使用了13 GB。这意味着除了被分析JVM之外，还有11 GB的系统内存被其他进程消耗。除非你预期测试环境中会运行其他进程，否则这种内存使用差异需要进一步调查。例如，如果你的应用程序使用了堆外内存，这种差异可能会使你的测试结果无效，因为你的应用程序可能无法按需分配内存，或者可能导致系统交换过度。
- en: Are the JVM's internal resources performing to expectations?
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: JVM的内部资源是否按预期运行？
- en: We began our profiling checklist with the widest possible criterion by verifying
    that the resources are provisioned and configured correctly. We continue to tighten
    the scope of our checklist by focusing on JVM configuration to ensure that test
    results are created from valid configurations. Now, we introspect JVM internals
    to continue verifying that the profile has not been compromised.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从最广泛的准则开始，通过验证资源是否正确配置和分配来构建我们的分析清单。我们继续缩小清单范围，通过关注JVM配置来确保测试结果来自有效的配置。现在，我们通过检查JVM内部来继续验证配置文件是否未受到损害。
- en: 'Nearly all production applications involve multithreading to make better use
    of multiple CPU cores or to separate I/O intensive work from CPU-centric work.
    The **Threads** tab group helps you familiarize yourself with the division of
    labor within the application and provides hints for where it may make sense to
    look deeper. The following table outlines areas of focus within the **Threads**
    tab group and highlights questions that you need to consider when you are new
    or unfamiliar with the application that is being profiled and when you have several
    profile results to compare:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有生产级应用程序都涉及多线程，以更好地利用多个CPU核心或分离I/O密集型工作与CPU中心型工作。**线程**选项卡组帮助你熟悉应用程序内部的劳动分工，并提供了一些深入调查的建议。以下表格概述了**线程**选项卡组中的重点区域，并突出了当你对被分析的应用程序不熟悉或需要比较多个配置文件结果时需要考虑的问题：
- en: '| **Focus area** | **New to the application** | **Familiar with the application**
    |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| **关注区域** | **新接触应用程序** | **熟悉应用程序** |'
- en: '| --- | --- | --- |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Thread Count** panel in the **Overview** tab | How many total threads exist?
    Is this different than the count you might expect? For example, if the application
    is CPU-bound and there are ten times the number of threads than cores, this may
    be a warning sign that the application is poorly tuned. | Are there qualitative
    changes in the thread count across profiles? For example, a doubling or halving
    of the thread count could indicate a configuration error. |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| **线程计数**面板在**概述**选项卡中 | 总共有多少个线程？这与你预期的数量是否不同？例如，如果应用程序是CPU密集型，线程数量是核心数量的十倍，这可能是一个警告信号，表明应用程序的调优不佳。
    | 线程计数在配置文件之间是否有定性变化？例如，线程计数加倍或减半可能表明配置错误。 |'
- en: '| **Hot Threads** panel in the **Hot Threads** tab | Is the distribution of
    sample counts even, or are there a couple of threads that dominate the sample
    count? The hottest threads are likely indicative of threads to dive deeper into
    and also areas of the code you should be most familiar with. | Have there been
    significant changes in thread sample count distribution? If so, do these changes
    seem sensible to you? |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| **热点线程**面板在**热点线程**选项卡中 | 样本计数分布是否均匀，还是有几个线程主导样本计数？最热的线程可能是需要深入调查的线程，也是你应该最熟悉的代码区域。
    | 样本计数分布的线程样本计数是否有显著变化？如果有，这些变化是否合理？ |'
- en: '| **Top Blocking Locks**, **Top Blocked Threads**, and **Top Blocking Threads**
    in the **Contention** tab | Familiarize yourself with where locks exist and which
    threads block most often. This can be useful information to bear in mind when
    considering what factors are affecting critical path performance. | Compared to
    previous profile results, is there an increase in either the frequency or distribution
    of thread blocking? Are there new locks appearing in the results? |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| **顶级阻塞锁**、**顶级阻塞线程**和**顶级阻塞线程**在**竞争**标签中 | 熟悉锁的存在位置以及哪些线程最常阻塞。这些信息在考虑影响关键路径性能的因素时可能很有用。|
    与之前的配置文件结果相比，线程阻塞的频率或分布是否有所增加？结果中是否出现了新的锁？|'
- en: '| **Latency Stack Traces** in the **Latencies** tab | Familiarize yourself
    with the different maximum latencies per event type to better understand which
    operations affect the application most. Make mental notes to dive deeper into
    the more latent sections of the application. | Are maximum latencies qualitatively
    increasing, decreasing, or similar to previous profile results? When multiple
    top-level stack traces exist for an event type, consider the ones affecting critical
    path performance the most. |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| **延迟堆栈跟踪**在**延迟**标签中 | 熟悉不同事件类型的最大延迟，以便更好地理解哪些操作对应用程序影响最大。对应用程序中更延迟的部分进行深入思考。|
    最大延迟是定性增加、减少还是与之前的配置文件结果相似？当存在多个顶级堆栈跟踪的事件类型时，考虑那些对关键路径性能影响最大的。|'
- en: After thoroughly inspecting the **Threads** tab group, you should begin to have
    a mental picture forming about how this application functions and which areas
    are likely to be most interesting for further study. We now turn to a topic that
    links closely to JVM threading: **I/O**.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在彻底检查**线程**标签组之后，你应该开始形成一个关于此应用程序如何运行以及哪些区域可能对进一步研究最有兴趣的心理图像。我们现在转向一个与JVM线程紧密相关的话题：**I/O**。
- en: The **I/O** tab group provides valuable information about the profiled application's
    file and socket access. Like the review of the **Threads** tab group, this section
    may provide hints that your application has unexpected or undesirable behavior.
    Before diving into this tab group, pause to consider when or what causes disk
    reads and writes, and network reads and writes. As you review the **Overview**
    tab, do you see divergences between your thinking and the profiler results? If
    so, you should identify why this discrepancy exists and whether it invalidates
    your test results.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**I/O**标签组提供了有关配置文件应用程序文件和套接字访问的有价值信息。就像对**线程**标签组的审查一样，本节可能提供有关应用程序存在意外或不希望的行为的线索。在深入到这个标签组之前，请停下来考虑何时或什么原因导致磁盘读取和写入，以及网络读取和写入。当你审查**概述**标签时，你是否看到了你的想法与分析结果之间的差异？如果是这样，你应该确定这种差异的原因，以及它是否使你的测试结果无效。'
- en: 'An example of unexpected I/O behavior could be excessive writes to standard
    out. This might happen accidentally when a debugging statement is left behind.
    Imagine if this side-effect occurs on the critical path of your application. This
    will negatively impact profile results and invalidates testing. In Flight Recorder,
    writes to standard out are captured by a blank write path. The following screenshot
    shows file write results from a simple, one-off application that repeatedly writes
    to standard out at a high frequency:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 一个意外的I/O行为示例可能是对标准输出的过度写入。这可能在调试语句被遗留时意外发生。想象一下，如果这种副作用发生在应用程序的关键路径上。这将负面地影响配置文件结果并使测试无效。在Flight
    Recorder中，标准输出的写入通过一个空白的写入路径被捕获。以下截图显示了一个简单的一次性应用程序的文件写入结果，该应用程序以高频率反复写入标准输出：
- en: '![Are the JVM''s internal resources performing to expectations?](img/image_02_003.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![JVM的内部资源是否按预期运行？](img/image_02_003.jpg)'
- en: Identifying unexpected writes to standard out via the I/O tab group
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 通过I/O标签组识别标准输出中的意外写入
- en: This example is exaggerated for effect, which is why there is a continuous block
    of constant writes over time. By inspecting the **File Write** tab, we can also
    see how much time was spent writing to standard out, how much data was written,
    and how many writes occurred. In approximately 15 seconds of execution, a whopping
    40,000 writes took place! The file write stack trace provides invaluable information,
    allowing us to backtrack to identify which parts of the application are responsible
    for the writes. Flight Recorder also allows you to view writes by thread. In a
    production application with dedicated writer threads, you can quickly isolate
    undesired I/O access.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子为了效果夸张了，这就是为什么随着时间的推移会有连续的写操作块。通过检查**文件写入**选项卡，我们还可以看到花费在写入标准输出上的时间、写入的数据量以及发生的写入次数。在约15秒的执行时间内，发生了惊人的40,000次写入！文件写入堆栈跟踪提供了宝贵的情报，使我们能够回溯以确定哪些应用程序部分负责这些写入。飞行记录器还允许您按线程查看写入操作。在生产应用程序中，如果有专门的写入线程，您可以快速隔离不希望的I/O访问。
- en: Monitoring I/O reads and writes presents a good opportunity to discuss how to
    configure Flight Recorder recording parameters. The `-XX:+FlightRecorderOptions`
    accepts a parameter named `settings`, which, by default, points to `$JAVA_HOME/jre/lib/jfr/default.jfc`.
    You can either provide your own configuration file or modify the default file.
    In this configuration file, you can tweak the events that are recorded by Flight
    Recorder and the frequency at which to capture certain events. For example, by
    default, the `java/file_write` event has a threshold of 20 ms. This is a reasonable
    default, but you may wish to tune the value lower if you are focused on profiling
    file writes. Setting the threshold lower means that more event samples are captured.
    Tune carefully because more is not always better. A lower threshold implies higher
    overhead and more information to sift through.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 监控I/O读取和写入是讨论如何配置飞行记录器记录参数的好机会。`-XX:+FlightRecorderOptions`接受一个名为`settings`的参数，默认情况下，它指向`$JAVA_HOME/jre/lib/jfr/default.jfc`。您可以选择提供自己的配置文件或修改默认文件。在这个配置文件中，您可以调整飞行记录器记录的事件以及捕获某些事件的频率。例如，默认情况下，`java/file_write`事件有一个20毫秒的阈值。这是一个合理的默认值，但您可能希望将其调低，如果您专注于分析文件写入。降低阈值意味着捕获更多的事件样本。请仔细调整，因为更多并不总是更好。较低的阈值意味着更高的开销和更多需要筛选的信息。
- en: A final area to investigate is the **Exceptions** tab under the **Code** tab
    group. Even if you are closely monitoring application logs during a profiling,
    you may not be persisting the logs for historical analysis. Fortunately, Flight
    Recorder captures exceptions and errors for review. Scanning the exceptions and
    errors, take note of how many total exceptions and errors occurred and which ones
    happen most frequently. Shrink the time horizon with the range navigator to better
    understand if exceptions and errors are concentrated at application startup, later
    in the profiling, or uniformly occurring. The timing at which exceptions and errors
    occur often provides insight into whether or not the root cause is misconfiguration
    or unexpected runtime behavior. As always, if you notice an alarming number of
    exceptions or errors, consider invalidating the profile results until you have
    a deeper understanding about why they are happening.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个要调查的领域是在**代码**选项卡组下的**异常**选项卡。即使在分析期间您密切监控应用程序日志，您可能也不会持久化日志以进行历史分析。幸运的是，飞行记录器会捕获异常和错误以供审查。扫描异常和错误时，请注意总共发生了多少异常和错误，以及哪些异常发生得最频繁。使用范围导航器缩小时间范围，以更好地了解异常和错误是否集中在应用程序启动时、分析后期或均匀发生。异常和错误发生的时间通常可以提供有关根本原因是配置错误还是意外运行时行为的洞察。始终如一，如果您注意到异常或错误的数量令人担忧，请在深入了解它们发生的原因之前，考虑使分析结果无效。
- en: Where are the CPU bottlenecks?
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CPU瓶颈在哪里？
- en: 'At this stage, we have completed all checks necessary to maximize the likelihood
    that the profiler results are valid and worth investigating further. Now, we begin
    arguably the most fun part of the profiling process: identifying CPU bottlenecks.
    This is an enjoyable process because the profiler gives you a detailed look inside
    the black box of your application. It is an opportunity to objectively test your
    hypotheses and mental model of how the application works by comparing with the
    profiler results. Once you identify the bottlenecks, you will feel a sense of
    relief that you now know where to pinpoint your next set of changes to improve
    application performance.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们已经完成了所有必要的检查，以最大限度地提高分析结果有效并值得进一步调查的可能性。现在，我们开始可能是分析过程中最有意思的部分：识别CPU瓶颈。这是一个令人愉快的过程，因为分析器让您深入了解应用程序的黑盒。这是一个通过将分析结果与您的假设和应用程序工作方式的心理模型进行比较，以客观测试您的假设的机会。一旦您确定了瓶颈，您将感到一种释然，因为您现在知道在哪里定位您的下一组更改以改进应用程序性能。
- en: 'Let''s start on the **Overview** tab of the **Code** tab group. This view is
    useful to sensitize yourself from the bottom-up on which areas of the code are
    most expensive. The following figure displays the **Overview** tab for a sample
    run of the order book:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从**概述**标签页开始，这是**代码**标签组的一部分。这个视图有助于您从底层开始了解代码中哪些区域最昂贵。以下图显示了订单簿样本运行的**概述**标签页：
- en: '![Where are the CPU bottlenecks?](img/image_02_004.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![CPU瓶颈在哪里？](img/image_02_004.jpg)'
- en: The Code Overview tab summarizing expensive packages and classes
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 总结昂贵包和类的**代码概述**标签页
- en: In this view, the initial goal is to get a sense for the distribution of CPU
    time in the application. The **Hot Packages** panel quickly makes it clear to
    us that the order book is heavily reliant upon code from the `scala.collection`
    package. The **Hot Classes** panel shows that the order book is spending a significant
    amount of time, approximately 55% of the time, performing some type of iteration
    operations. In this screenshot, we also see that only a subset of the profile
    duration is selected with the range navigator. It is often helpful to view different
    subsets of the profile period to determine if hot spots remain constant over time.
    In this example, the early part of the profile results are excluded because they
    include time spent preparing requests to be sent to the order book. Selecting
    this subset allows us to focus purely on order book operations without pollution
    from test setup.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个视图中，初始目标是了解应用程序中CPU时间的分布。**热点包**面板迅速使我们清楚，订单簿严重依赖于`scala.collection`包中的代码。**热点类**面板显示，订单簿花费了相当多的时间，大约55%的时间，执行某种类型的迭代操作。在这个屏幕截图中，我们还看到，只有部分配置文件持续时间被范围导航器选中。查看配置文件期间的不同子集通常很有帮助，以确定热点是否随时间保持不变。在这个例子中，配置结果的前部分被排除，因为这些时间包括发送到订单簿的请求的准备工作。选择这个子集使我们能够专注于订单簿操作，而不受测试设置的干扰。
- en: 'It is important to note that the percentage column indicates the amount of
    application time spent executing in the displayed package and class. This means
    that this view, along with the **Hot Methods** tab, are bottom-up views rather
    than top-down views. In a top-down view, the percentage column indicates the sum
    total amount of time spent in part of a stack trace. This view is captured in
    the **Call Tree** tab. This distinction is key because these two views help us
    answer different questions. The following table explores several topics from both
    perspectives to better understand when each view is most helpful:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，百分比列表示在显示的包和类中执行的应用程序时间量。这意味着这个视图，连同**热点方法**标签页，是自下而上的视图，而不是自上而下的视图。在自上而下的视图中，百分比列表示在堆栈跟踪的一部分中花费的总时间量。这个视图在**调用树**标签页中捕获。这种区别是关键的，因为这两个视图帮助我们回答不同的问题。以下表格从两个角度探讨了几个主题，以更好地理解何时每个视图最有帮助：
- en: '| **Topic** | **Top-down view (Call Tree)** | **Bottom-up view (Overview/Hot
    Methods)** |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| **主题** | **自上而下的视图（调用树）** | **自下而上的视图（概述/热点方法）** |'
- en: '| --- | --- | --- |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Point of view | This is from a macro picture to a micro picture | This is
    from a micro picture to a macro picture |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 视角 | 这是从宏观图到微观图 | 这是从微观图到宏观图 |'
- en: '| Determining hot spots | These are areas of the code base that delegate to
    the most expensive function calls | These are the most expensive functions |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 确定热点 | 这些是代码库中委托给最昂贵函数调用的区域 | 这些是最昂贵的函数 |'
- en: '| Example questions best answered by each view |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 每个视图最佳回答的问题 |'
- en: Is the order book cancel operation more expensive than adding a resting limit
    order?
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 订单簿取消操作的成本是否高于添加一个静态限价订单？
- en: Where is CPU time spent on the critical path?
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关键路径上CPU时间花在哪里？
- en: '|'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Did switching from a `Double` price representation to a `BigDecimal` representation
    create any hot spots?
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从`Double`价格表示切换到`BigDecimal`表示是否创建了任何热点？
- en: Relative to the rest of the application, which tree operations are most costly?
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相比于应用的其他部分，哪些树操作成本最高？
- en: '|'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'As a first-time profiler of the order book, you now know from the **Overview**
    tab that the order book makes heavy usage of Scala collections, but you do not
    yet have a feel for which order book operations are causing the performance to
    suffer. To deepen your understanding about the cost of different order book operations,
    you take a top-down view by investigating the **Call Tree** tab:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 作为订单簿的首次分析者，你现在从**概览**标签页了解到订单簿大量使用了Scala集合，但你还没有感受到哪些订单簿操作导致了性能下降。为了深入了解不同订单簿操作的成本，你通过调查**调用树**标签页采取自上而下的视角：
- en: '![Where are the CPU bottlenecks?](img/image_02_005.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![CPU瓶颈在哪里？](img/image_02_005.jpg)'
- en: Investigating order book bottlenecks using Call Tree
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 使用调用树调查订单簿瓶颈
- en: Drilling down **Call Tree**, it becomes abundantly clear that the cancelation
    operation is the bottleneck. Overwhelmingly, CPU time is spent canceling orders
    rather than adding them. You call over the company's sharpest trader, Dave, to
    share this finding. Dave's eyes light up when you mention that cancelations are
    costly. As a trading domain expert, he is well aware that in volatile times, the
    frequency of cancelations increases significantly as compared to calmer market
    periods. Dave explains that traders frequently cancel orders in volatile markets
    to quickly adjust to swinging prices. Cancelations beget cancelations because
    traders are learning valuable pricing information. Ending the conversation, he
    tells you to cancel everything else that you are doing (no pun intended!) and
    focus on improving the performance of order canceling.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 深入分析**调用树**，可以清楚地看出取消操作是瓶颈。绝大多数CPU时间都花在取消订单上，而不是添加订单上。你叫来公司最敏锐的交易员戴夫，与他分享这一发现。当提到取消操作成本高昂时，戴夫的眼睛亮了起来。作为一名交易领域的专家，他深知在波动时期，取消操作的频率相较于平静的市场时期显著增加。戴夫解释说，交易员在波动市场中经常取消订单，以便快速调整摇摆的价格。取消操作导致更多的取消，因为交易员正在学习有价值的定价信息。结束对话时，他告诉你取消你正在做的所有其他事情（没有开玩笑！），并专注于提高订单取消的性能。
- en: 'You walk away from the conversation feeling better knowing that you have identified
    the bottleneck that is likely to be the source of MVT trade losses. To get a better
    feel, you dig a bit deeper into the **Call Tree** to reveal which functions within
    **Cancel Order** are expensive. This is the process of moving from a macro view
    to a micro view. You end up looking at the **Call Tree** tab, which is displayed
    as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 通过确定可能是MVT交易损失来源的瓶颈，你从对话中感到更加安心。为了更好地了解情况，你进一步深入到**调用树**中，揭示**取消订单**中哪些函数是昂贵的。这是从宏观视角转向微观视角的过程。最后，你查看**调用树**标签页，如下所示：
- en: '![Where are the CPU bottlenecks?](img/image_02_006.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![CPU瓶颈在哪里？](img/image_02_006.jpg)'
- en: Understanding which cancel order functions are the slowest via Call Tree
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调用树了解哪些取消订单函数最慢
- en: The **Call Tree** shows that canceling an order involves an invocation of the
    `RedBlackTree find()` function and the `exists()` function. As you look deeper
    into the call, you also notice that the percentage column becomes smaller. This
    is because in a top-down view, the percentage column represents the sum total
    CPU time spent on a particular function and all the functions beneath it. According
    to the results, 84.48% of CPU time was spent `executingOrderBook$$anonfun$handleCancelOrder$1.apply()`
    and the functions deeper in the **Call Tree**. From this view, we also see that
    of the 84.48% of CPU time, 53.24% of the time is spent `withinAbstractIterator.exists()`
    and deeper function calls. This looks like the biggest bottleneck, with the invocation
    of `Queue.iterator()` in second place, taking 31.24% of CPU time.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '**调用树**显示，取消订单涉及对`RedBlackTree find()`函数和`exists()`函数的调用。当你进一步查看调用时，你也会注意到百分比列变得更小。这是因为从自上而下的视角来看，百分比列代表了一个特定函数及其所有下级函数所花费的总CPU时间。根据结果，84.48%的CPU时间被用于`executingOrderBook$$anonfun$handleCancelOrder$1.apply()`以及**调用树**中更深层的函数。从这个视角来看，我们还可以看到，在84.48%的CPU时间中，53.24%的时间被用于`withinAbstractIterator.exists()`以及更深层的函数调用。这看起来是最大的瓶颈，其次是`Queue.iterator()`的调用，占用了31.24%的CPU时间。'
- en: 'Reflecting on this information, you are curious to start at the bottom, so-to-speak,
    with the most expensive functions, and work your way through the backtrace to
    identify affected order book operations. To address your curiosity, you investigate
    the **Hot Methods** tab and see the following view:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 反思这些信息，你好奇地想从最昂贵的函数开始，换句话说，从底部开始，逐步通过回溯来识别受影响的订单簿操作。为了满足你的好奇心，你调查了**热方法**标签页，并看到了以下视图：
- en: '![Where are the CPU bottlenecks?](img/image_02_007.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![CPU瓶颈在哪里？](img/image_02_007.jpg)'
- en: Going from the micro to the macro view with Hot Methods
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 从微观视角到宏观视角，通过热方法
- en: By an order of magnitude, you discover the same two culprits from the **Call
    Tree** investigation are the hottest methods. This is a reassuring finding because
    it builds confidence that changes to the implementation of canceling an order
    are likely to yield qualitative benefits. As you have not spent any time studying
    the source code, there is still a significant amount of mystery about the implementation.
    Taking a step back to consider the situation, you think about the operations being
    modeled in the abstract. Canceling an order involves finding the existing order
    that could have any price and then once found, modifying the state of the order
    book to remove the order. Your intuition suggests that some of these operations
    are likely linear, or possibly logarithmic at best. As you begin considering what
    other implementation could be faster, Dave interrupts your thoughts.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 通过数量级，你发现与**调用树**调查中相同的两个罪魁祸首是热方法。这是一个令人欣慰的发现，因为它增强了信心，认为对取消订单实现的更改可能会带来质的飞跃。由于你没有花时间研究源代码，关于实现的神秘之处仍然很多。退一步考虑情况，你思考在抽象中建模的操作。取消订单涉及找到可能具有任何价格的现有订单，然后一旦找到，修改订单簿的状态以删除订单。你的直觉表明，这些操作中的一些可能是线性的，或者最多是对数级的。当你开始考虑其他可能的更快实现时，Dave打断了你。
- en: In a rushed voice, you hear, "Have you fixed the order book? We need to get
    it deployed now!" Of course, you have no idea how to respond, and the thought
    of deploying code on day one makes you a bit uneasy. You share your findings with
    Dave, hoping that your findings will satisfy his appetite for progress and buy
    you more time to think. Unfortunately, Dave is not thrilled to hear the order
    book performance mystery remains unsolved, "We're losing money everyday because
    of this!" You acknowledge that you understand the gravity of the situation and
    that you are moving as fast as you can. It is your first day, after all! Dave
    sighs and acknowledges he is being a bit tough, and that his exasperation is causing
    him to overreact. As the conversation is winding down, Dave mentions his appreciation
    for how quickly you came up to speed, and he makes some small talk about how he
    cannot understand how his brand new smartphone, loaded with extra memory, still
    runs slowly. "Nothing seems to be working quickly anymore!" he exclaims. His mention
    of memory causes you to have an epiphany.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 你听到一个急促的声音说：“你修复订单簿了吗？我们现在需要部署它！”当然，你不知道如何回应，想到第一天就部署代码让你有些不安。你与Dave分享你的发现，希望你的发现能满足他对进步的渴望，并为你争取更多思考的时间。不幸的是，Dave对订单簿性能之谜仍未解决并不高兴，“我们每天都在因为这个原因而损失金钱！”你承认你理解形势的严重性，并且你正在尽可能快地行动。毕竟，这是你的第一天！Dave叹了口气，承认他有点苛刻，他的沮丧导致他反应过度。随着对话的结束，Dave提到他对你快速掌握情况的感激之情，并就他如何无法理解他新买的智能手机，尽管加载了额外的内存，仍然运行缓慢进行了闲聊。“现在似乎没有什么能快速运行了！”他大声说道。他提到的内存让你有了顿悟。
- en: You remember that you have not yet reviewed memory usage results. You are hoping
    that there are some easy wins available by tuning the garbage collector to improve
    performance without making code changes. Before making any changes, you check
    out the **Memory** tab group for insight into memory allocation patterns.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 你记得你还没有审查内存使用结果。你希望通过调整垃圾收集器来提高性能，而不需要修改代码，可能会有一些容易的胜利。在做出任何更改之前，你查看**内存**标签组以了解内存分配模式。
- en: What are the memory allocation patterns?
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内存分配模式是什么？
- en: The **Memory** tab group is the final area that remains to dive into for our
    analysis. Even though we have not spent time looking at the order book source
    code, the **Code** tab group illustrated the relative costs of the different order
    of operations. Studying the **Hot Methods** provides insight into the types of
    objects that are used by various areas of the order book. Looking into the memory
    allocation patterns, we want to identify young and old generation garbage collection
    trends and which objects are most and least allocated.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '**内存**标签组是我们分析中需要深入的最后区域。尽管我们没有花时间查看订单簿源代码，但**代码**标签组展示了不同操作顺序的相对成本。研究**热点方法**可以了解订单簿各个区域使用的对象类型。查看内存分配模式，我们希望识别年轻和老年代垃圾收集趋势以及哪些对象分配最多和最少。'
- en: 'The default Flight Recorder configuration settings do not track object allocations.
    For a more complete view of memory consumption, the following configuration settings
    should be enabled:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的飞行记录器配置设置不跟踪对象分配。为了更全面地查看内存消耗，应启用以下配置设置：
- en: Allocation-profiling-enabled
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Allocation-profiling-enabled
- en: Heap-statistics-enabled
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heap-statistics-enabled
- en: gc-enabled-all
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: gc-enabled-all
- en: Allocation-profiling-enabled for both `java/object_alloc_in_new_TLAB` and `java/object_alloc_outside_TLAB`
    events
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为`java/object_alloc_in_new_TLAB`和`java/object_alloc_outside_TLAB`事件启用Allocation-profiling-enabled
- en: 'Once a profile is generated with all the preceding parameters enabled, you
    will get a first glimpse into application memory allocation patterns in the **Heap**
    panel on the **Garbage Collections** tab:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦生成包含所有先前参数的配置文件，你将在**垃圾收集**标签页的**堆**面板中首次了解应用程序的内存分配模式：
- en: '![What are the memory allocation patterns?](img/image_02_008.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![内存分配模式是什么？](img/image_02_008.jpg)'
- en: Visualizing memory allocation patterns via the Garbage Collections tab
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 通过垃圾收集标签可视化内存分配模式
- en: This view shows a shape that is commonly referred to as a sawtooth pattern.
    There are frequent garbage collections creating a tooth-like pattern in the data
    as the JVM is constantly freeing young generation memory. Garbage collection tuning
    is a vast topic that is beyond the scope of this book. We encourage you to dig
    deeper into this area by reading through this well-written blog post entitled,
    "Understanding Java Garbage Collection" ([http://www.cubrid.org/blog/dev-platform/understanding-java-garbage-collection/](http://www.cubrid.org/blog/dev-platform/understanding-java-garbage-collection/)).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 此视图显示的形状通常被称为锯齿形模式。由于JVM不断释放年轻代内存，频繁的垃圾回收在数据中创建了一个类似牙齿的模式。垃圾回收调优是一个广泛的话题，超出了本书的范围。我们鼓励您通过阅读这篇名为“理解Java垃圾回收”的精彩博客文章来深入了解这一领域（[http://www.cubrid.org/blog/dev-platform/understanding-java-garbage-collection/](http://www.cubrid.org/blog/dev-platform/understanding-java-garbage-collection/))。
- en: 'As shown in the following screenshot, Flight Recorder also provides summary
    metrics per garbage collection category in the **GC Times** tab:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如下截图所示，飞行记录器在**GC 时间**标签页中也提供了每个垃圾回收类别的摘要指标：
- en: '![What are the memory allocation patterns?](img/image_02_009.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![什么是内存分配模式？](img/image_02_009.jpg)'
- en: Summarizing garbage per collection event type
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 按收集事件类型总结垃圾回收
- en: 'The following are some questions worth considering when inspecting a visualization
    of heap usage and a breakdown of garbage collection per collection type:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查堆使用可视化以及按收集类型拆分的垃圾回收时，以下是一些值得考虑的问题：
- en: '| **Question** | **Thoughts to consider** |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| **问题** | **需要考虑的思考** |'
- en: '| --- | --- |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| On average, does memory usage remain constant, slope downwards, or slope
    upwards? | An upward slope in memory can point to a memory leak. In this scenario,
    the heap will grow until the old generation fills, causing an old generation collection.
    If there is a memory leak, old generation collections will not clear much memory
    and eventually cause an out of memory error. The order book''s memory usage appears
    constant for the profiled period. When making this type of judgement, obtain the
    longest possible profile to ensure you are viewing as complete of a picture as
    possible. |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 平均而言，内存使用量是保持恒定、向下倾斜还是向上倾斜？ | 内存使用量向上倾斜可能表明存在内存泄漏。在这种情况下，堆将增长，直到旧生代填满，导致旧生代收集。如果存在内存泄漏，旧生代收集不会清除很多内存，最终可能导致内存不足错误。在分析此类型问题时，获取尽可能长的分析结果，以确保尽可能全面地查看情况。
    |'
- en: '| Do outlier pause times correlate with other major events? | According to
    the garbage collection breakdown, the maximum collection time is an order of magnitude
    that is larger than the average collection time. Scan the **Heap** panel for collection
    pauses that are qualitatively larger than the average. Do you see a pattern among
    the outliers? Consider your application''s interaction with external systems and
    the machine it is deployed onto. Could there be an explanation for the occurrence
    of extreme pauses? It may also be worthwhile to compare outliers across profiles
    to determine whether the pattern is specific to a single profile or appears to
    be systemic. |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 异常暂停时间是否与其他主要事件相关？ | 根据垃圾回收拆分，最大收集时间是平均收集时间的十倍。在**堆**面板中查找比平均收集时间质上更大的收集暂停。您是否在异常值中看到了某种模式？考虑您的应用程序与外部系统的交互以及它部署到的机器。是否存在解释极端暂停发生的原因？比较不同配置文件中的异常值，以确定该模式是否仅针对单个配置文件或似乎具有系统性。
    |'
- en: '| What is the frequency of collections and how long is a typical collection
    lasting? | All other things being equal, a lower collection count is preferable
    because it suggests garbage is generated at a slower rate. That said, a lower
    collection count can be the result of an increased heap size, which may cause
    an increase in the average collection time. The takeaway is that inspecting collection
    count and latencies should be taken with a grain of salt. For this reason, the
    total garbage collection time metric is insightful. The total collection time
    reflects the effects of collection frequency and duration. Additionally, this
    does not suffer from loss like the average collection duration. |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 收集的频率是多少？典型的收集持续多久？ | 在其他条件相同的情况下，较低的收集次数更可取，因为它表明垃圾生成速度较慢。话虽如此，较低的收集次数可能是由于堆大小增加的结果，这可能导致平均收集时间增加。重要的是要记住，检查收集次数和延迟应该持谨慎态度。因此，总垃圾收集时间指标是有洞察力的。总收集时间反映了收集频率和持续时间的影响。此外，它不会像平均收集持续时间那样遭受损失。|'
- en: '| What is the lifespan of an object for important use cases? | While studying
    these breakdowns of garbage collection performance, it is important to build an
    intuition for how memory is allocated for different use cases in your application.
    Understanding this relationship may help you figure out why certain allocation
    patterns occur. In volatile markets, we expect that the order book has a lot of
    short-lived objects because traders are frequently canceling orders. In less-volatile
    markets, we likely expect that the average age of an order resting on the book
    is higher, which implies more long-lived objects. |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 重要用例中对象的生存周期是多久？ | 在研究垃圾收集性能的分解时，了解您的应用程序中不同用例的内存分配方式是很重要的。理解这种关系可能有助于您找出为什么会出现某些分配模式。在波动较大的市场中，我们预计订单簿中有许多短生存期的对象，因为交易员经常取消订单。在波动较小的市场中，我们可能预计订单簿上休息的订单的平均年龄更高，这意味着有更多长生存期的对象。|'
- en: 'Studying these views of memory allocation provides a summary of memory allocation
    activity. Investigating the **Allocations** tab provides several different ways
    to see which parts of the application are applying memory pressure. Flight Recorder
    provides three allocation views: by class, by thread, and by profile:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 研究这些内存分配的视角提供了内存分配活动的总结。通过调查**分配**标签页，可以以多种不同的方式查看应用程序中哪些部分正在施加内存压力。飞行记录器提供了三种分配视图：按类、按线程和按配置文件：
- en: '![What are the memory allocation patterns?](img/image_02_010.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![内存分配模式是什么？](img/image_02_010.jpg)'
- en: Correlating high-pressure List allocations via Allocations by Class
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 通过按类分配关联高压列表分配
- en: Class and profile allocations are shown in the preceding screenshot. Note that
    Allocations by Thread are skipped in this case because the order book is single-threaded.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 类和配置文件分配在先前的屏幕截图中显示。请注意，由于订单簿是单线程的，因此在此情况下跳过了按线程分配。
- en: '![What are the memory allocation patterns?](img/image_02_011.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![内存分配模式是什么？](img/image_02_011.jpg)'
- en: Confirming memory allocation pressure using top-down Allocation Profile view
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自上而下的分配配置文件视图确认内存分配压力
- en: 'When you are reviewing these allocation views, you should consider the following
    questions. As you read through these questions, reflect on how you would answer
    them to better understand how to improve order book performance:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 当您审查这些分配视图时，应考虑以下问题。在阅读这些问题时，反思您将如何回答它们，以更好地理解如何提高订单簿的性能：
- en: '| **Question** | **Thoughts to consider** |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| **问题** | **需要考虑的思考** |'
- en: '| --- | --- |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| When inspecting **Allocation by Class**, is there a positive correlation
    between classes with heavy collection pressure and classes that are referenced
    on the critical path? | If you determine that the classes creating the most garbage
    collection pressure are also often allocated on the critical path, then you have
    good reason to believe that if you optimize the critical path, there will be both
    algorithm speed and garbage collection benefits. The order book results indicate
    that List allocations is the worst offender. The backtrace shows that the allocations
    are almost entirely coming from handling **Cancel Orders**, which we know to be
    the bottleneck. |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 当检查**按类分配**时，具有重收集压力的类与在关键路径上引用的类之间是否存在正相关？| 如果你确定创建最多垃圾收集压力的类也经常在关键路径上分配，那么你有充分的理由相信，如果你优化关键路径，将带来算法速度和垃圾收集的双重好处。订单簿结果表明，列表分配是最严重的违规者。回溯显示，分配几乎完全来自处理**取消订单**，这是我们已知是瓶颈的地方。|'
- en: '| When inspecting **Allocation by Thread**, what does the distribution of garbage
    collection pressure look like? | Noting which threads are responsible for generating
    the most garbage collection pressure can direct you towards areas of the code
    to focus intently on. Ameliorating garbage collection pressure by the worst offenders
    will be reflected in the total pause time. |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 当检查**按线程分配**时，垃圾收集压力的分布是什么样的？| 注意哪些线程负责生成最多的垃圾收集压力，可以帮助你确定代码中需要集中注意力的区域。通过减轻最严重的违规者的垃圾收集压力，将反映在总的暂停时间上。|'
- en: '| When drilling down the **Allocation Profile** stacktrace, do known CPU time
    bottlenecks correlate with high garbage collection pressure? | The order book
    shows that approximately 99% of garbage is generated when handling **Cancel Orders**.
    This is affirmation that handling **Cancel Orders** is computationally expensive
    and is further slowing down the system due to high object allocation rates. Establishing
    this correlation provides strong evidence that code changes to this section of
    the code will yield qualitative performance improvements. |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 当深入到**分配配置文件**堆栈跟踪时，已知的CPU时间瓶颈是否与高垃圾收集压力相关？| 订单簿显示，大约99%的垃圾是在处理**取消订单**时生成的。这证实了处理**取消订单**是计算密集型的，并且由于高对象分配率，进一步减慢了系统。建立这种相关性提供了强有力的证据，表明对这部分代码的代码更改将带来定性的性能改进。|'
- en: Trying to save the day
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 尝试挽救局面
- en: 'Knowing that Dave will soon ask you again about improvements to order book
    performance, you take a few minutes to reflect on your findings. It is clear that
    handling **Cancel Orders** is both the CPU time and the memory allocation bottleneck.
    With more time to think about the problem, you are confident you can change the
    order book implementation to address either concern or possibly both. Unfortunately,
    time is one thing you do not currently have. One interesting observation from
    the memory allocations is that most garbage tends to be short-lived in a volatile
    market. Two inexpensive options to test come to mind:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 知道Dave很快会再次询问你关于提高订单簿性能的改进，你花了几分钟时间反思你的发现。很明显，处理**取消订单**既是CPU时间也是内存分配的瓶颈。在更多时间思考问题的同时，你自信可以改变订单簿实现来解决这个问题或可能两个问题。不幸的是，时间是你目前没有的东西。从内存分配中有一个有趣的观察：在波动市场中，大多数垃圾通常都是短暂的。有两个低成本的测试选项浮现在脑海中：
- en: '| **JVM memory tuning options** | **Hypothesis** |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| **JVM内存调整选项** | **假设** |'
- en: '| --- | --- |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Switch from the default old generation collection, parallel old, to **Concurrent
    Mark Sweep** (**CMS**). | The CMS collector is designed to keep your application
    responsive. Switching to the CMS collector may not improve order book throughput,
    but it may provide more consistent response latency during highly-volatile market
    movements. |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| 从默认的老一代收集器、并行老收集器切换到**并发标记清除**（**CMS**）。| CMS收集器旨在保持应用程序的响应性。切换到CMS收集器可能不会提高订单簿吞吐量，但在市场波动剧烈时，它可能提供更一致的响应延迟。|'
- en: '| Increase the new size from the default, approximately one-third of maximum
    heap size, to three-fourths of maximum heap size. | The order book has 1 GB of
    heap to store state, and it is currently only using approximately 380 MB to store
    young generation objects. You want to leverage the intuition that frequent cancels
    lead to frequent short-lived objects. Increasing the new generation size is a
    bet that there will be less than 250 MB of tenured objects and that an increased
    young generation heap improves order book throughput due to more infrequent collections.
    |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 将新大小从默认值（大约最大堆大小的三分之一）增加到最大堆大小的四分之三。 | 订单簿有1GB的堆来存储状态，目前只使用大约380MB来存储年轻代对象。你希望利用频繁取消导致频繁短暂对象出现的直觉。增加新代大小是一种赌注，即将不会有超过250MB的持久对象，并且增加年轻代堆大小可以提高订单簿吞吐量，因为收集的频率更低。|'
- en: 'The following table summarizes the results for each experiment:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 下表总结了每个实验的结果：
- en: '| **Setup** | **Command** | **99^(th) percentile in ms** |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| **设置** | **命令** | **99^(th) 百分位（毫秒）** |'
- en: '| Original |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 原始 |'
- en: '[PRE14]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '| 92 |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 92 |'
- en: '| CMS collector |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| CMS收集器 |'
- en: '[PRE15]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '| 118 |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 118 |'
- en: '| 750M new size |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| 750M新大小 |'
- en: '[PRE16]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '| 74 |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| 74 |'
- en: '| CMS collector and 750M new size |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| CMS收集器和750M新大小 |'
- en: '[PRE17]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '| 148 |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| 148 |'
- en: It looks like it will be more complicated than expected to improve the performance
    of the order book. At least one of the options, increasing the new size, seems
    to yield a better overall latency. We suggest that you take the time to go over
    this chapter again and repeat the process of benchmarking and profiling the application
    with these new sets of options. Observe what new behaviors these JVM options introduce,
    and try to understand the resulting increase or decrease in latency.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来提高订单簿性能会比预期更复杂。至少有一种选择，即增加新大小，似乎能带来更好的整体延迟。我们建议你再次阅读本章，并使用这些新的选项集对应用程序进行基准测试和性能分析。观察这些JVM选项引入的新行为，并尝试理解由此产生的延迟增加或减少。
- en: A word of caution
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一点注意事项
- en: We want to take a moment to highlight some context about the profiling results
    that we interpreted in the previous section. We worked through an example that
    exhibited multiple real-world concerns. We laid out a pragmatic approach to working
    through the performance problem that has been applied by your authors at their
    day jobs. The point to be cautious of is that the order book is likely much simpler
    than most applications you work on day-to-day. We deliberately chose an example
    that was complicated enough to illustrate how to work through a performance problem,
    but also simple enough to understand without hours of code review. In practice,
    you will possibly need to repeat profiling numerous times, each time testing out
    a new hypothesis, in order to gain traction with your performance problem. Applying
    the structured approach that we walked through will ensure that you validate your
    results before analyzing them, and it will also ensure that you have well-founded
    evidence to pinpoint where to make changes.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想花点时间强调一下关于我们在上一节中解释的分析结果的一些背景信息。我们通过一个展示了多个现实世界问题的例子进行了分析。我们提出了一种实用方法来处理性能问题，这种方法是作者们在日常工作中应用的。需要注意的是，订单簿的复杂度可能远低于你日常工作中遇到的大多数应用。我们故意选择了一个足够复杂以展示如何处理性能问题的例子，同时也足够简单，无需数小时代码审查就能理解。在实践中，你可能需要多次重复分析，每次测试一个新的假设，以便在性能问题上取得进展。应用我们介绍的结构化方法将确保你在分析结果之前验证它们，并且它还将确保你有充分的证据来确定需要做出改变的地方。
- en: A profiling checklist
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析清单
- en: 'We worked through each item on the profiling checklist throughout the chapter.
    We present the entire checklist for ease of reference, as follows:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中逐项检查了配置清单。为了便于参考，我们在此列出整个清单如下：
- en: Did I test with the expected set of resources?
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我是否测试了预期的资源集？
- en: Was the system environment clean during the profiling?
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在分析过程中，系统环境是否干净？
- en: Are resources internal to the JVM performing as I would expect?
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: JVM内部资源是否按预期运行？
- en: Where are the CPU bottlenecks?
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CPU瓶颈在哪里？
- en: What are the memory allocation patterns?
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 内存分配模式是什么？
- en: Taking big steps with microbenchmarks
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用微基准测试迈出大步
- en: In the coming chapters, we will share techniques from the functional paradigm
    and from the Scala language that enable you to write more performant software.
    However, you should not accept our prescriptions at face value. Measuring the
    performance is the objective way to determine whether the changes improve performance.
    A microbenchmark is a term used to describe a benchmark that exercises a small,
    isolated portion of a larger application. As microbenchmarks, by design, test
    a small piece of code, it is often easier to run a microbenchmark than to benchmark
    an entire application when a nuanced change is made.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将分享来自函数式范式和Scala语言的技巧，这些技巧使你能够编写更高效的软件。然而，你不应该盲目接受我们的建议。衡量性能是确定更改是否提高性能的客观方式。微基准测试是一个术语，用来描述对较大应用程序的一个小部分进行测试的基准。由于微基准测试设计上测试的是一小段代码，当进行细微更改时，运行微基准测试通常比基准测试整个应用程序更容易。
- en: Unfortunately, accurately observing the performance of nuanced changes is difficult,
    particularly on the JVM. Consider these order book-related examples of changes
    that warrant microbenchmarking.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，准确观察细微更改的性能是困难的，尤其是在JVM上。考虑以下这些与订单簿相关的更改示例，这些更改值得进行微基准测试。
- en: Replacing the data structure holding resting limit orders with one that handles
    cancels more efficiently
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用一个更有效地处理取消操作的数据结构替换持有静态限价订单的数据结构
- en: Normalizing stock prices from a double representation to an integer representation
    to perform order matching with a lower overhead
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将股票价格从双精度表示规范化为整数表示，以进行具有较低开销的订单匹配
- en: Determining the performance boost of reordering a set of branch statements to
    reflect the order you perceive to be accessed most frequently
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定重新排序一组分支语句以反映你认为最频繁访问的顺序的性能提升
- en: 'How would you measure the performance before and after each change? You may
    try writing small benchmark programs, which are similar to the `ThroughputBenchmark`.
    This approach is likely to provide you with untrustworthy results due to the JVM''s
    cleverness. The JVM applies a number of heuristics to make runtime optimizations.
    In a production environment, these changes are welcome because improved performance
    is always welcomed. However, in a microbenchmark, these changes are not welcomed
    because they decrease confidence that the microbenchmark is isolating only the
    nuanced change. Examples of changes the JVM is capable of making include the following:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 你会如何衡量每次更改前后的性能？你可以尝试编写小的基准程序，这些程序类似于`ThroughputBenchmark`。由于JVM的智能，这种方法可能提供不可靠的结果。JVM应用了多种启发式方法来进行运行时优化。在生产环境中，这些更改是受欢迎的，因为性能的改进总是受欢迎的。然而，在微基准测试中，这些更改并不受欢迎，因为它们会降低对微基准测试仅隔离细微更改的信心。JVM能够做出的更改示例包括以下内容：
- en: Dead-code elimination
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 死代码消除
- en: Just-in-time optimization (refer to our earlier sidebar regarding the JIT compiler)
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即时编译优化（请参阅我们之前关于JIT编译器的侧边栏）
- en: Constant folding (an optimization to avoid the evaluation on each call of a
    function with constant arguments and a return value dependent on these parameters)
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常量折叠（一种优化，用于避免在每次调用具有常量参数和依赖于这些参数的返回值的函数时进行评估）
- en: We encourage you to read more about JVM optimizations by reading Oracle's *The
    Java HotSpot Performance Engine Architecture* ([http://www.oracle.com/technetwork/java/whitepaper-135217.html](http://www.oracle.com/technetwork/java/whitepaper-135217.html)).
    Given that this is a challenge to isolate small code changes, how can we write
    a proper microbenchmark? Fortunately, the OpenJDK team recognized these same challenges
    and introduced a library for this purpose named JMH, the Java microbenchmarking
    harness ([http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/)).
    JMH is designed for the express purpose of overcoming the limitations that we
    referenced in order to isolate the performance impact of your changes. The process
    to work with JMH is similar to other testing libraries. Similar to JUnit, JMH
    defines a set of annotations to control test setup and execution. Although tests
    can be run in several ways, we focus on executing tests via the sbt plugin, `sbt-jmh`
    ([https://github.com/ktoso/sbt-jmh](https://github.com/ktoso/sbt-jmh)), for ease
    of use. Let's walk through the process of creating, running, and analyzing a microbenchmark
    with the order book. In future chapters, we will leverage our JMH knowledge to
    objectively measure the performance impact of prescribed changes.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们鼓励你通过阅读 Oracle 的《Java HotSpot 性能引擎架构》（[http://www.oracle.com/technetwork/java/whitepaper-135217.html](http://www.oracle.com/technetwork/java/whitepaper-135217.html)）来了解更多关于
    JVM 优化的信息。鉴于这是一个隔离小代码更改的挑战，我们如何编写一个合适的微基准测试？幸运的是，OpenJDK 团队认识到了这些相同的挑战，并引入了一个名为
    JMH 的库，即 Java 微基准测试工具（[http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/)）。JMH
    是专门为克服我们提到的限制而设计的，以便隔离你更改的性能影响。使用 JMH 的过程与其他测试库类似。类似于 JUnit，JMH 定义了一组注解来控制测试设置和执行。尽管测试可以通过多种方式运行，但我们专注于通过
    sbt 插件 `sbt-jmh`（[https://github.com/ktoso/sbt-jmh](https://github.com/ktoso/sbt-jmh)）执行测试，以便于使用。让我们通过创建、运行和分析使用订单簿的微基准测试的过程来一探究竟。在未来的章节中，我们将利用我们的
    JMH 知识来客观地衡量指定更改的性能影响。
- en: Note
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: Are there changes that you made recently to your application that could benefit
    from microbenchmarking? If you did not microbenchmark the change, do you think
    microbenchmarking could have led you towards alternative solutions?
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 你最近是否对应用程序进行了可能从微基准测试中受益的更改？如果你没有对更改进行微基准测试，你认为微基准测试是否可能引导你找到替代解决方案？
- en: Microbenchmarking the order book
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对订单簿进行微基准测试
- en: 'Having made progress towards improving performance by tweaking JVM memory settings,
    you set your eyes towards better understanding cancel performance. Based on the
    existence of a `scala.collection.immutable.Queue` in the profiler results, you
    hypothesize that there may be a linear time traversal of a FIFO queue to support
    order cancels. One way to test this hypothesis is to devise a microbenchmark that
    measures the cancelation performance in different scenarios. You brainstormed
    the following scenarios:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调整 JVM 内存设置来提高性能取得进展后，你开始关注更好地理解取消性能。根据分析器结果中存在 `scala.collection.immutable.Queue`
    的信息，你假设可能存在对 FIFO 队列的线性时间遍历来支持顺序取消。测试这一假设的一种方法是为不同场景设计一个微基准测试来衡量取消性能。你头脑风暴了以下场景：
- en: Canceling a nonexistent order
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 取消一个不存在的订单
- en: Canceling the first order in line for a price level
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 取消价格水平队列中的第一个订单
- en: Canceling the last order in line for a price level
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 取消价格水平队列中的最后一个订单
- en: Canceling a nonexistent order happens in the real world when a resting order
    is crossed before the cancel request arrives. This is an interesting scenario
    because you are unsure whether there is early termination logic to make this operation
    cheaper or whether canceling a nonexistent order requires inspecting the entire
    order book. The remaining two scenarios focus on the fill guarantees that are
    provided by stock exchanges. When multiple orders are placed at the same price,
    they are guaranteed to be filled on a first-come, first-served basis. You are
    speculating that the FIFO queue seen in the profile results is preserving the
    time ordering of resting orders for a price level. You expect canceling the first
    order in line to be faster by a linear factor than canceling the final order in
    line.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，当取消请求到达之前，一个处于休息状态的订单被取消，这种情况就会发生。这是一个有趣的场景，因为你不确定是否存在提前终止逻辑来使这个操作更便宜，或者取消一个不存在的订单是否需要检查整个订单簿。剩下的两个场景关注的是证券交易所提供的填充保证。当以相同价格放置多个订单时，它们保证按照先到先得的原则进行填充。你推测在配置文件结果中看到的FIFO队列正在保留该价格水平上休息订单的时间顺序。你期望取消队列中的第一个订单比取消队列中的最后一个订单快一个线性因子。
- en: 'After reading through the excellent JMH examples at [http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples/](http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples/)
    and some deep thinking, you are able to put together the following tests that
    capture the scenarios that you are interested in. The code is in-full and is followed
    by a walkthrough, displayed as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读了[http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples/](http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples/)上的优秀JMH示例和一些深入思考之后，你能够组合以下测试来捕捉你感兴趣的情景。代码是完整的，并且随后是一个遍历，如下所示：
- en: '[PRE18]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Rather than duplicating JMH documentation, we will focus on the specific segments
    of interest and expect you to also investigate the JMH samples for additional
    context. Surveying the `CancelBenchmarks` class, you see the use of annotations
    to define benchmarks and control the benchmark outputs. Several benchmark modes
    exist. We are using the throughput mode to measure the number of times the benchmark
    completes in a fixed period of time. The implementation of each cancellation benchmark
    differs only by the ID of the order being canceled. Let's switch focus to the `CancelBenchmarks` object,
    which provides the necessary scaffolding to set up each benchmark.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会重复JMH文档，而是将重点放在感兴趣的特定部分，并期望你也调查JMH样本以获取更多背景信息。调查`CancelBenchmarks`类，你看到使用注解来定义基准测试和控制基准测试输出。存在几种基准模式。我们使用吞吐量模式来衡量基准测试在固定时间段内完成的次数。每个取消基准测试的实现仅通过取消订单的ID不同。让我们将重点转向`CancelBenchmarks`对象，它提供了设置每个基准测试所需的必要框架。
- en: The `CancelBenchmarks` object defines the `BookWithLargeQueue` state, which
    we observed is an argument to each benchmark. Defining the state that is required
    by the test is the first step towards parameterizing the benchmark. For this set
    of tests, we simplify the test setup by creating an order book with only a single
    price level at $1.00\. We focus on sweeping the number of orders enqueued for
    the $1.00 price level in order to help identify the runtime behavior that we believe
    to be operating in linear time. The use of the `param` annotation supplies a set
    of default values to sweep for enqueued order count. We use the `setup` annotation
    to instruct JMH to prepare the state of the order book prior to invoking each
    of the three benchmarks. For each enqueued order count value, JMH invokes the
    `setup` method to create an order book with the desired number of resting orders
    at the $1.00 level.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '`CancelBenchmarks`对象定义了`BookWithLargeQueue`状态，这是我们观察到每个基准测试的参数。定义测试所需的州是参数化基准测试的第一步。对于这一组测试，我们通过创建一个只有$1.00价格水平的订单簿来简化测试设置。我们专注于清除$1.00价格水平上入队的订单数量，以帮助我们识别我们认为在线性时间内运行的运行时行为。使用`param`注解提供了一组用于清除入队订单计数的默认值。我们使用`setup`注解来指示JMH在调用每个三个基准测试之前准备订单簿的状态。对于每个入队订单计数值，JMH调用`setup`方法来创建一个在$1.00级别具有所需数量休息订单的订单簿。'
- en: 'Next, we run the benchmarks from sbt. JMH provides a number of command-line
    flags that control test configuration, which can be viewed from `sbt` using the
    following command:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们从sbt运行基准测试。JMH提供了一些命令行标志来控制测试配置，这些标志可以通过以下命令在`sbt`中查看：
- en: '[PRE19]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'All parameters that are configured as annotations can be overridden by supplying
    the associated command-line flag. The following is a sample invocation of `CancelBenchmarks`:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 所有配置为注解的参数都可以通过提供相关的命令行标志来覆盖。以下是一个`CancelBenchmarks`的示例调用：
- en: '[PRE20]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: In this invocation of JMH, we configure three warm-up iterations, each running
    for 5 seconds. Warm-up iterations do not count toward the output throughput result.
    We configure 30 recorded iterations, each lasting 10 seconds to compute throughput.
    We supply a 1 GB heap size for this test and switch on exiting the benchmark on
    uncaught exceptions to defend against a regression in the code. Lastly, we parameterize
    the enqueued order counts that we wish to sweep, indicating that we want to run
    three warm-up iterations and 30 recorded iterations for an enqueued order count
    of 1, 10, 50, and 100 orders.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次JMH调用中，我们配置了三个预热迭代，每个迭代运行5秒。预热迭代不计入输出吞吐量结果。我们配置了30个记录迭代，每个迭代持续10秒以计算吞吐量。我们为这次测试提供了1
    GB的堆大小，并在未捕获异常时退出基准测试以防御代码回归。最后，我们参数化了我们希望扫描的入队订单数量，表明我们希望对1、10、50和100个订单的入队订单数量运行三个预热迭代和30个记录迭代。
- en: With a single order in the book, we hypothesize that all operations should be
    approximately equally expensive. As we believe that cancel operations run in linear
    time, our expectation is that each benchmark should be approximately five times
    slower when the enqueued order count is 50 than when the count is 10\. We cap
    testing at 100 enqueued orders because in discussion with Dave, we learned that
    in his experience, he has never analyzed a book with more than 85 orders in a
    level. Capping at 100 orders ensures that we understand performance characteristics
    at a level that we do not expect to see in production but could conceivably occur.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在书中只有一个订单的情况下，我们假设所有操作的成本大致相等。因为我们认为取消操作运行在线性时间，所以我们的预期是，当入队订单数量为50时，每个基准测试应该比当数量为10时慢大约五倍。我们将测试限制在100个入队订单，因为在与Dave讨论时，我们了解到在他的经验中，他从未分析过超过85个订单的级别。将测试限制在100个订单确保我们了解的性能特征在一个我们预计不会在生产中看到但可能发生的级别。
- en: Note
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Imagine that you are writing a microbenchmark for the most performance-sensitive
    use case in your system. What variables would be important to sweep to have a
    complete understanding of how the system performs in this use case? How would
    you go about identifying a base case, step values, and a maximum value to parameterize
    your tests? Consider speaking with domain experts or using production data to
    guide decision making.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你正在为系统中性能最敏感的使用案例编写一个微基准测试。为了全面了解系统在这个使用案例中的性能，哪些变量是重要的需要扫描的？你将如何确定基准测试的基础案例、步长值和最大值来参数化你的测试？考虑与领域专家交谈或使用生产数据来指导决策。
- en: 'After executing the test, we see the following results summarized, as follows:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 执行测试后，我们看到了以下总结结果：
- en: '| **Benchmark** | **Enqueued order count** | **Throughput (ops per second)**
    | **Error (ops per second)** | **Error as percentage of throughput** |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| **基准测试** | **入队订单数量** | **吞吐量（每秒操作数）** | **误差（每秒操作数）** | **误差占吞吐量的百分比** |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Cancel first order | 1 | 6,688,878.23 | Â±351,518.041 | Â±5.26 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| 取消第一个订单 | 1 | 6,688,878.23 | ±351,518.041 | ±5.26 |'
- en: '| Cancel first order | 10 | 2,202,233.77 | Â±103,557.824 | Â±4.70 |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 取消第一个订单 | 10 | 2,202,233.77 | ±103,557.824 | ±4.70 |'
- en: '| Cancel first order | 50 | 555,592.56 | Â±18,632.547 | Â±3.35 |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| 取消第一个订单 | 50 | 555,592.56 | ±18,632.547 | ±3.35 |'
- en: '| Cancel first order | 100 | 305,615.75 | Â±14,345.296 | Â±4.69 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| 取消第一个订单 | 100 | 305,615.75 | ±14,345.296 | ±4.69 |'
- en: '| Cancel last order | 1 | 7,365,825.52 | Â±284,773.895 | Â±3.87 |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| 取消最后一个订单 | 1 | 7,365,825.52 | ±284,773.895 | ±3.87 |'
- en: '| Cancel last order | 10 | 1,691,196.48 | Â±54,903.319 | Â±3.25 |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| 取消最后一个订单 | 10 | 1,691,196.48 | ±54,903.319 | ±3.25 |'
- en: '| Cancel last order | 50 | 509,339.60 | Â±15,582.846 | Â±3.06 |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 取消最后一个订单 | 50 | 509,339.60 | ±15,582.846 | ±3.06 |'
- en: '| Cancel last order | 100 | 242,049.87 | Â±8,967.785 | Â±3.70 |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 取消最后一个订单 | 100 | 242,049.87 | ±8,967.785 | ±3.70 |'
- en: '| Cancel nonexistent order | 1 | 13,285,699.96 | Â±374,134.340 | Â±2.82 |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 取消不存在的订单 | 1 | 13,285,699.96 | ±374,134.340 | ±2.82 |'
- en: '| Cancel nonexistent order | 10 | 3,048,323.44 | Â±140,983.947 | Â±4.62 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 取消不存在的订单 | 10 | 3,048,323.44 | ±140,983.947 | ±4.62 |'
- en: '| Cancel nonexistent order | 50 | 772,034.39 | Â±16,535.652 | Â±2.14 |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 取消不存在的订单 | 50 | 772,034.39 | Â±16,535.652 | Â±2.14 |'
- en: '| Cancel nonexistent order | 100 | 404,647.90 | Â±3,889.509 | Â±0.96 |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 取消不存在的订单 | 100 | 404,647.90 | Â±3,889.509 | Â±0.96 |'
- en: 'From this result set, we can answer a number of interesting questions that
    help us characterize order book performance. Here are some questions for you to
    answer by inspecting the results:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个结果集中，我们可以回答许多有趣的问题，这些问题有助于我们描述订单簿的性能。以下是一些您可以通过检查结果来回答的问题：
- en: Does the base case of a single enqueued order result in qualitatively similar
    performance across the three benchmarks?
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个入队订单的基本情况是否导致三个基准测试在质量上具有相似的性能？
- en: Does each benchmark exhibit linear throughput degradation as enqueued order
    count increases?
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着入队订单数量的增加，每个基准测试是否表现出线性吞吐量下降？
- en: As enqueued order count increases, are there changes in relative performance
    between benchmarks (for example, between canceling the first and last order when
    the enqueued order count is 100 instead of 10)?
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着入队订单数量的增加，基准测试之间的相对性能是否发生变化（例如，当入队订单数量为100而不是10时，取消第一个和最后一个订单）？
- en: Does it appear that there is early termination logic in place when evaluating
    nonexistent orders?
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在评估不存在的订单时，是否似乎存在提前终止逻辑？
- en: 'In addition to these questions that are specific to the order book, it is critical
    to ask yourself the following questions of any benchmark result:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 除了针对订单簿的特定问题之外，对于任何基准测试结果，还必须问自己以下问题：
- en: Do the results pass a test of reasonableness?
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果是否通过了一个合理性测试？
- en: What could have gone wrong with the test (that is, producing invalid results),
    and have we put in place safeguards to prevent these shortcomings from occurring?
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试可能出了什么问题（即产生无效结果），我们是否已经采取措施防止这些缺点发生？
- en: Errors in measurement or test setup destroy the integrity of your results. These
    questions aim to make you critically analyze the microbenchmark results. The test
    of reasonableness requires you to develop a mental model for the executed test.
    Using the order book, we need to consider what is a plausible number of cancel
    operations per second. One way to answer this question is to take one of the throughput
    results, for example, cancel last order with 50 queued orders, and compute the
    average milliseconds per operation. This is useful because we have a sense for
    the cost on a per-operation basis from earlier benchmarks; 509,339.595 cancels
    per second translates to approximately 0.002 ms per operation. This result might
    be surprisingly low, but bear in mind these results do not account for coordinated
    omission because there is no targeted throughput rate (that is, the test attempts
    to send as many cancels per second as possible). The other reason the cost might
    be lower than expected is because there is only one price level in the book. Typically,
    the book contains numerous price levels on the buying and selling sides. This
    may direct us toward designing benchmarks that sweep the number of price levels
    to better inform our understanding of the cost of managing multiple price levels.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 测量或测试设置中的错误会破坏结果的完整性。这些问题旨在让您批判性地分析微基准测试结果。合理性测试要求您为执行的测试建立心理模型。使用订单簿，我们需要考虑每秒可能的取消操作数量。回答这个问题的方法之一是取一个吞吐量结果，例如，取消最后一个订单，有50个入队订单，并计算每个操作的毫秒数。这很有用，因为我们已经从早期的基准测试中获得了每个操作的成本的感知；每秒509,339.595个取消转换为大约0.002毫秒的操作。这个结果可能出人意料地低，但请注意，这些结果没有考虑到协调的遗漏，因为没有特定的吞吐量速率（即测试试图尽可能每秒发送尽可能多的取消）。成本可能低于预期的另一个原因是，订单簿中只有一个价格水平。通常，书籍在买卖双方包含许多价格水平。这可能会引导我们设计基准测试，以扫描价格水平的数量，从而更好地了解管理多个价格水平的成本。
- en: The second question forces us to critically analyze the test setup and the test
    methodology. For example, how do we know that the setup function produces the
    intended order book? One way to defend against this is to add assertions to enforce
    intended constraints. Another concern to verify is that each cancel invocation
    in the benchmark yields the intended event. Adding assertions to the benchmark
    for a single trial may address this concern. However, leaving assertions in the
    benchmark code is likely to affect performance, and this should be used sparingly,
    if at all. For added safety, it could make sense to write unit tests for the scenarios
    that are being tested to ensure that the desired behavior occurs and ensure that
    the unit test and performance test code are shared.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个问题迫使我们批判性地分析测试设置和测试方法。例如，我们如何知道设置函数产生了预期的订单簿？一种防御方法是添加断言来强制执行预期的约束。另一个需要验证的问题是基准测试中的每个取消调用都产生预期的事件。为单个试验的基准测试添加断言可能解决这个问题。然而，在基准测试代码中留下断言可能会影响性能，并且如果有的话，应该谨慎使用。为了额外的安全性，为正在测试的场景编写单元测试可能是有意义的，以确保期望的行为发生，并确保单元测试和性能测试代码是共享的。
- en: When interpreting JMH results, it is important to consider the significance
    of the computed error. JMH computes error by constructing a confidence interval
    from a benchmark's iterations. The confidence interval assumes that the results
    follow a normal distribution, and the error represents the range of the computed
    99.9% confidence interval. This suggests that all other things being equal, running
    more benchmark iterations improves your confidence in the results. The final column
    in the results table is illustrative of the variability of the results. The lower
    the variability, the more inclined you should be to trust the results. High result
    variability suggests that there is an error in measurement or that there is something
    inhibiting your ability to measure true performance characteristics. This is often
    a warning sign that you need to revisit your testing methodology and that you
    should put little trust in the results.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释JMH结果时，考虑计算错误的显著性很重要。JMH通过从基准测试的迭代中构建置信区间来计算错误。置信区间假设结果遵循正态分布，而错误表示计算出的99.9%置信区间的范围。这表明，在其他条件相同的情况下，运行更多的基准测试迭代可以提高你对结果的信心。结果表中的最后一列说明了结果的变异性。变异性越低，你越应该相信结果。结果的高变异性表明存在测量错误或存在阻碍你测量真实性能特征的因素。这通常是一个警告信号，表明你需要重新审视你的测试方法，并且你应该对结果持怀疑态度。
- en: Note
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For our example, we ran 30 iterations to record throughput information. What
    do you think are the implications of running with fewer iterations? Alternatively,
    consider the effects of running fewer iterations with increased duration. For
    example, 10 iterations, each lasting 30 seconds. Build a hypothesis and then run
    JMH to see the results. Developing awareness for the sensitivity of different
    benchmark parameters is another way to build an intuition for how to approach
    future benchmarks.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的示例，我们运行了30次迭代以记录吞吐量信息。你认为运行较少迭代会有什么影响？或者，考虑运行较少迭代但增加持续时间的效果。例如，10次迭代，每次持续30秒。构建一个假设，然后运行JMH以查看结果。对不同的基准参数敏感性有意识，这是建立如何处理未来基准测试直觉的另一种方法。
- en: As our JMH configuration does not account for coordinated omission and instead
    sends a firehose of cancel requests to the order book, we should focus on the
    relative results rather than the absolute throughput values. The order book-related
    questions that are posed after the results hone in on relative differences that
    should be visible independent of the testing environment (for example, available
    cores or RAM). There is value in focusing on relative concerns because the answers
    should be more robust to change. If future code changes cause significant relative
    changes, for example, causing an exponential instead of linear cancel performance
    degradation, you can have higher confidence that this degradation is due to a
    code change instead of an environmental change.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的JMH配置没有考虑协调的省略，而是向订单簿发送大量取消请求，因此我们应该关注相对结果，而不是绝对吞吐量值。在结果之后提出的相关订单簿问题集中在相对差异上，这些差异应该独立于测试环境（例如，可用核心或RAM）可见。关注相对问题是有价值的，因为答案应该对变化更加稳健。如果未来的代码更改导致显著的相对变化，例如，导致指数而不是线性取消性能下降，那么你可以更有信心地认为这种下降是由于代码更改而不是环境变化。
- en: In this section, we saw how to set up, execute, and interpret a JMH microbenchmark.
    Along the way, we looked at the shortcomings of microbenchmarking without JMH,
    and the concerns to be aware of during benchmark result analysis. We've only scratched
    the surface of the capabilities of JMH. We will build on this introduction to
    JMH in future chapters.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们了解了如何设置、执行和解释一个JMH微基准测试。在这个过程中，我们探讨了没有JMH的微基准测试的不足之处，以及在基准测试结果分析过程中需要注意的问题。我们对JMH的能力只是触及了皮毛。我们将在未来的章节中继续介绍JMH。
- en: Summary
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Congratulations, in this chapter you helped improve MVT order book performance,
    which is going to directly translate to increased company profits and reduced
    losses! Along the way, you took an in-depth look at how to benchmark and profile
    on the JVM and what shortcomings to avoid. You also worked through a JMH microbenchmarking
    primer that will allow you to objectively assess performance improvements in future
    chapters. In the next chapter, we will look at how Scala language features can
    be used to write functional software, and we will assess their performance impacts
    using the skills that we learned in this chapter.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜，在本章中你帮助提升了MVT订单簿的性能，这将直接转化为公司利润的增加和损失的减少！在这个过程中，你深入了解了如何在JVM上进行基准测试和性能分析，以及需要避免的不足之处。你还完成了一个JMH微基准测试入门教程，这将使你能够在未来的章节中客观地评估性能改进。在下一章中，我们将探讨如何使用Scala语言特性来编写函数式软件，并使用本章学到的技能来评估它们对性能的影响。
