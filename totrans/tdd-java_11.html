<html><head></head><body>
<div id="_idContainer086">
<h1 class="chapter-number" id="_idParaDest-225"><a id="_idTextAnchor234"/><span class="koboSpan" id="kobo.1.1">11</span></h1>
<h1 id="_idParaDest-226"><a id="_idTextAnchor235"/><span class="koboSpan" id="kobo.2.1">Exploring TDD with Quality Assurance</span></h1>
<p><span class="koboSpan" id="kobo.3.1">Previous chapters have covered the technical practices needed to design and test well-engineered code. </span><span class="koboSpan" id="kobo.3.2">The approach presented has been primarily for developers to gain rapid feedback on software design. </span><span class="koboSpan" id="kobo.3.3">Testing has been almost a byproduct of </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">these efforts.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">The combination of TDD, continuous integration, and pipelines provides us with a high level of confidence in our code. </span><span class="koboSpan" id="kobo.5.2">But they are not the whole picture when it comes to software </span><strong class="bold"><span class="koboSpan" id="kobo.6.1">Quality Assurance</span></strong><span class="koboSpan" id="kobo.7.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.8.1">QA</span></strong><span class="koboSpan" id="kobo.9.1">). </span><span class="koboSpan" id="kobo.9.2">Creating the highest-quality software needs additional processes, featuring the human touch. </span><span class="koboSpan" id="kobo.9.3">In this chapter, we will highlight the importance of manual exploratory testing, code reviews, user experience, and security testing, together with approaches to adding a human decision point to a </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">software release.</span></span></p>
<p><span class="koboSpan" id="kobo.11.1">In this chapter, we’re going to cover the following </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">main topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.13.1">TDD – its place in the bigger </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">quality picture</span></span></li>
<li><span class="koboSpan" id="kobo.15.1">Manual exploratory testing – discovering </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">the unexpected</span></span></li>
<li><span class="koboSpan" id="kobo.17.1">Code review and </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">ensemble programming</span></span></li>
<li><span class="koboSpan" id="kobo.19.1">User interface and user </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">experience testing</span></span></li>
<li><span class="koboSpan" id="kobo.21.1">Security testing and </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">operations monitoring</span></span></li>
<li><span class="koboSpan" id="kobo.23.1">Incorporating manual elements into </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">CI/CD workflows</span></span></li>
</ul>
<h1 id="_idParaDest-227"><a id="_idTextAnchor236"/><span class="koboSpan" id="kobo.25.1">TDD – its place in the bigger quality picture</span></h1>
<p><span class="koboSpan" id="kobo.26.1">In this section, we will take a critical look at what TDD has brought to the testing table, and what remains human activities. </span><span class="koboSpan" id="kobo.26.2">While TDD undoubtedly has advantages as part of a test strategy, it can never be the entire strategy for a successful </span><span class="No-Break"><span class="koboSpan" id="kobo.27.1">software system.</span></span></p>
<h2 id="_idParaDest-228"><a id="_idTextAnchor237"/><span class="koboSpan" id="kobo.28.1">Understanding the limits of TDD</span></h2>
<p><span class="koboSpan" id="kobo.29.1">TDD is a relatively </span><a id="_idIndexMarker606"/><span class="koboSpan" id="kobo.30.1">recent discipline as far as mainstream development goes. </span><span class="koboSpan" id="kobo.30.2">The modern genesis of TDD lies with Kent Beck in the Chrysler Comprehensive Compensation System (see the </span><em class="italic"><span class="koboSpan" id="kobo.31.1">Further reading</span></em><span class="koboSpan" id="kobo.32.1"> section, where the idea of test-first unit testing came from). </span><span class="koboSpan" id="kobo.32.2">The project began in 1993 and Kent Beck’s involvement commenced </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">in 1996.</span></span></p>
<p><span class="koboSpan" id="kobo.34.1">The Chrysler Comprehensive Compensation project</span><a id="_idIndexMarker607"/><span class="koboSpan" id="kobo.35.1"> was characterized by extensive use of unit tests driving small iterations and frequent releases of code. </span><span class="koboSpan" id="kobo.35.2">Hopefully, we recognize those ideas from the preceding chapters in this book. </span><span class="koboSpan" id="kobo.35.3">Much has changed since then – the deployment options are different, the number of users has increased, and agile approaches are more common – but the goals of testing remain the same. </span><span class="koboSpan" id="kobo.35.4">Those goals are to drive out correct, well-engineered code and ultimately </span><span class="No-Break"><span class="koboSpan" id="kobo.36.1">satisfy users.</span></span></p>
<p><span class="koboSpan" id="kobo.37.1">The alternative to test automation is to run tests without automation – in other words, run them manually. </span><span class="koboSpan" id="kobo.37.2">A better term might be human-driven. </span><span class="koboSpan" id="kobo.37.3">Before test automation became commonplace, an important part of any development plan was a test strategy document. </span><span class="koboSpan" id="kobo.37.4">These lengthy documents defined when testing would be done, how it would be done, and who would be doing </span><span class="No-Break"><span class="koboSpan" id="kobo.38.1">that testing.</span></span></p>
<p><span class="koboSpan" id="kobo.39.1">This strategy document existed alongside detailed test plans. </span><span class="koboSpan" id="kobo.39.2">These would also be written documents, describing each test to be performed – how it would be set up, what steps exactly were to be tested, and what the expected results should be. </span><span class="koboSpan" id="kobo.39.3">The traditional waterfall-style project would spend a lot of time defining these documents. </span><span class="koboSpan" id="kobo.39.4">In some ways, these documents were similar to our TDD test code, only written on paper, rather than </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">source code.</span></span></p>
<p><span class="koboSpan" id="kobo.41.1">Executing these manual test plans was a large effort. </span><span class="koboSpan" id="kobo.41.2">Running a test needs us to set up test data by hand, run the application, then click through user interfaces. </span><span class="koboSpan" id="kobo.41.3">Results must be documented. </span><span class="koboSpan" id="kobo.41.4">Defects found must be recorded in defect reports. </span><span class="koboSpan" id="kobo.41.5">These must be fed back up the waterfall, triggering redesigns and recoding. </span><span class="koboSpan" id="kobo.41.6">This must happen with every single release. </span><em class="italic"><span class="koboSpan" id="kobo.42.1">Human-driven</span></em><span class="koboSpan" id="kobo.43.1"> testing is repeatable, but only at the great cost of preparing, updating, and following test documents. </span><span class="koboSpan" id="kobo.43.2">All of this took time – and a lot of time </span><span class="No-Break"><span class="koboSpan" id="kobo.44.1">at that.</span></span></p>
<p><span class="koboSpan" id="kobo.45.1">Against this</span><a id="_idIndexMarker608"/><span class="koboSpan" id="kobo.46.1"> background, Beck’s TDD ideas seemed remarkable. </span><span class="koboSpan" id="kobo.46.2">Test documents became executable code and could be run as often as desired, for a fraction of the cost of human testing. </span><span class="koboSpan" id="kobo.46.3">This was a compelling vision. </span><span class="koboSpan" id="kobo.46.4">The responsibility of testing code was part of the developer’s world now. </span><span class="koboSpan" id="kobo.46.5">The tests were part of the source code itself. </span><span class="koboSpan" id="kobo.46.6">These tests were automated, capable of being run in full on every build, and kept up to date as the </span><span class="No-Break"><span class="koboSpan" id="kobo.47.1">code changed.</span></span></p>
<h2 id="_idParaDest-229"><a id="_idTextAnchor238"/><span class="koboSpan" id="kobo.48.1">No more need for manual testing?</span></h2>
<p><span class="koboSpan" id="kobo.49.1">It’s tempting to think that using TDD as described in this book might eliminate manual testing. </span><span class="koboSpan" id="kobo.49.2">It does eliminate some manual processes, but certainly not all. </span><span class="koboSpan" id="kobo.49.3">The main manual steps we replace with automation are feature testing during development and regression testing </span><span class="No-Break"><span class="koboSpan" id="kobo.50.1">before release.</span></span></p>
<p><span class="koboSpan" id="kobo.51.1">As we develop a new feature with TDD, we start by writing automated tests for that feature. </span><span class="koboSpan" id="kobo.51.2">Every automated test we write is a test that does not need to be run by hand. </span><span class="koboSpan" id="kobo.51.3">We save all that test setup time, together with the often lengthy process to click through a user interface to trigger the behavior we’re testing. </span><span class="koboSpan" id="kobo.51.4">The main difference TDD brings is replacing test plans written in a word processor with test code written in an IDE. </span><span class="koboSpan" id="kobo.51.5">Development feature manual testing is replaced </span><span class="No-Break"><span class="koboSpan" id="kobo.52.1">by automation.</span></span></p>
<p><span class="koboSpan" id="kobo.53.1">TDD also provides</span><a id="_idIndexMarker609"/><span class="koboSpan" id="kobo.54.1"> us with </span><a id="_idIndexMarker610"/><span class="koboSpan" id="kobo.55.1">automated regression testing, </span><span class="No-Break"><span class="koboSpan" id="kobo.56.1">for free:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer082">
<span class="koboSpan" id="kobo.57.1"><img alt="Figure 11.1 – Regression testing" src="image/Figure_11.1_B18384.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.58.1">Figure 11.1 – Regression testing</span></p>
<p><span class="koboSpan" id="kobo.59.1">Using TDD, we add one or more tests as we build out each feature. </span><span class="koboSpan" id="kobo.59.2">Significantly, we retain all those tests. </span><span class="koboSpan" id="kobo.59.3">We naturally build up a large suite of automated tests, captured in source control and executed on every build automatically. </span><span class="koboSpan" id="kobo.59.4">This is known as a regression test suite. </span><span class="koboSpan" id="kobo.59.5">Regression testing means that we re-check all the tests run to date on every build. </span><span class="koboSpan" id="kobo.59.6">This ensures that as we make changes to the system, we don’t break anything. </span><span class="koboSpan" id="kobo.59.7">Moving fast and not breaking things might be how we describe </span><span class="No-Break"><span class="koboSpan" id="kobo.60.1">this approach.</span></span></p>
<p><span class="koboSpan" id="kobo.61.1">Regression tests</span><a id="_idIndexMarker611"/><span class="koboSpan" id="kobo.62.1"> also include tests for previously reported defects. </span><span class="koboSpan" id="kobo.62.2">These regression tests confirm that they have not been re-introduced. </span><span class="koboSpan" id="kobo.62.3">It bears repeating that the regression suite saves on all the manual effort required by non-automated tests </span><em class="italic"><span class="koboSpan" id="kobo.63.1">each and every</span></em><span class="koboSpan" id="kobo.64.1"> time the suite gets executed. </span><span class="koboSpan" id="kobo.64.2">This adds up over the full software life cycle to a </span><span class="No-Break"><span class="koboSpan" id="kobo.65.1">huge reduction.</span></span></p>
<p><span class="koboSpan" id="kobo.66.1">Test automation is</span><a id="_idIndexMarker612"/><span class="koboSpan" id="kobo.67.1"> good, but an automated test is a software machine. </span><span class="koboSpan" id="kobo.67.2">It cannot think for itself. </span><span class="koboSpan" id="kobo.67.3">It cannot visually inspect code. </span><span class="koboSpan" id="kobo.67.4">It cannot assess the appearance of a user interface. </span><span class="koboSpan" id="kobo.67.5">It cannot tell whether the user experience is good or bad. </span><span class="koboSpan" id="kobo.67.6">It cannot determine whether the overall system is fit </span><span class="No-Break"><span class="koboSpan" id="kobo.68.1">for purpose.</span></span></p>
<p><span class="koboSpan" id="kobo.69.1">This is where human-driven manual testing comes in. </span><span class="koboSpan" id="kobo.69.2">The following sections will look at areas where we need human-led testing, starting with an obvious one: finding bugs that our </span><span class="No-Break"><span class="koboSpan" id="kobo.70.1">tests missed.</span></span></p>
<h1 id="_idParaDest-230"><a id="_idTextAnchor239"/><span class="koboSpan" id="kobo.71.1">Manual exploratory – discovering the unexpected</span></h1>
<p><span class="koboSpan" id="kobo.72.1">In this section, we will appreciate the role of manual exploratory testing</span><a id="_idIndexMarker613"/><span class="koboSpan" id="kobo.73.1"> as an important line of defense against defects where TDD </span><span class="No-Break"><span class="koboSpan" id="kobo.74.1">is used.</span></span></p>
<p><span class="koboSpan" id="kobo.75.1">The biggest threat to our success with TDD lies in our ability to think about all the conditions our software needs to handle. </span><span class="koboSpan" id="kobo.75.2">Any reasonably complex piece of software has a huge range of possible input combinations, edge cases, and </span><span class="No-Break"><span class="koboSpan" id="kobo.76.1">configuration options.</span></span></p>
<p><span class="koboSpan" id="kobo.77.1">Consider using TDD to write code to restrict the sales of a product to buyers who are 18 years old and above. </span><span class="koboSpan" id="kobo.77.2">We must first write a happy-path test to check whether the sale is allowed, make it pass, then write a negative test, confirming that the sale can be blocked based on age. </span><span class="koboSpan" id="kobo.77.3">This test has the </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1">following form:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.79.1">
public class RestrictedSalesTest {
    @Test
    void saleRestrictedTo17yearOld() {
        // ... </span><span class="koboSpan" id="kobo.79.2">test code omitted
    }
    @Test
    void salePermittedTo19yearOld() {
        // ... </span><span class="koboSpan" id="kobo.79.3">test code omitted
    }
}</span></pre>
<p><span class="koboSpan" id="kobo.80.1">The error is obvious when we’re looking for it: what happens at the boundary between the ages of 17 and 18? </span><span class="koboSpan" id="kobo.80.2">Can an 18-year-old buy this product or not? </span><span class="koboSpan" id="kobo.80.3">We don’t know, because there is no test for that. </span><span class="koboSpan" id="kobo.80.4">We tested for 17 and 19 years old. </span><span class="koboSpan" id="kobo.80.5">For that matter, what should happen on that boundary? </span><span class="koboSpan" id="kobo.80.6">In general, that’s a </span><span class="No-Break"><span class="koboSpan" id="kobo.81.1">stakeholder decision.</span></span></p>
<p><span class="koboSpan" id="kobo.82.1">Automated tests cannot do </span><span class="No-Break"><span class="koboSpan" id="kobo.83.1">two things:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.84.1">Ask a stakeholder what they want the software </span><span class="No-Break"><span class="koboSpan" id="kobo.85.1">to do</span></span></li>
<li><span class="koboSpan" id="kobo.86.1">Spot a </span><span class="No-Break"><span class="koboSpan" id="kobo.87.1">missing test</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.88.1">This is where</span><a id="_idIndexMarker614"/><span class="koboSpan" id="kobo.89.1"> manual exploratory testing comes in. </span><span class="koboSpan" id="kobo.89.2">This is an approach to testing that makes the most of human</span><a id="_idIndexMarker615"/><span class="koboSpan" id="kobo.90.1"> creativity. </span><span class="koboSpan" id="kobo.90.2">It uses our instincts and intelligence to work out what tests we might be missing. </span><span class="koboSpan" id="kobo.90.3">It then uses scientific experimentation to discover whether our predictions of a missing test were correct. </span><span class="koboSpan" id="kobo.90.4">If proven true, we can provide feedback on these findings and repair the defect. </span><span class="koboSpan" id="kobo.90.5">This can be done either as an informal discussion or using a formal defect tracking tool. </span><span class="koboSpan" id="kobo.90.6">In due course, we can write new automated tests to capture our discoveries and provide regression tests for </span><span class="No-Break"><span class="koboSpan" id="kobo.91.1">the future.</span></span></p>
<p><span class="koboSpan" id="kobo.92.1">This kind of exploratory testing</span><a id="_idIndexMarker616"/><span class="koboSpan" id="kobo.93.1"> is a highly technical job, based on knowledge of what kinds of boundaries exist in software systems. </span><span class="koboSpan" id="kobo.93.2">It also requires extensive knowledge of local deployment and setup of software systems, together with knowing how software is built, and where defects are likely to appear. </span><span class="koboSpan" id="kobo.93.3">To an extent, it relies on knowing how developers think and predicting the kinds of things they </span><span class="No-Break"><span class="koboSpan" id="kobo.94.1">may overlook.</span></span></p>
<p><span class="koboSpan" id="kobo.95.1">Some key differences between</span><a id="_idIndexMarker617"/><span class="koboSpan" id="kobo.96.1"> automated testing and exploratory testing can be summarized </span><span class="No-Break"><span class="koboSpan" id="kobo.97.1">as follows:</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table001-2">
<colgroup>
<col/>
<col/>
</colgroup>
<thead>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.98.1">Automated Testing</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.99.1">Manual </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.100.1">Exploratory Testing</span></strong></span></p>
</td>
</tr>
</thead>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.101.1">Repeatable</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.102.1">Creative</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.103.1">Tests for </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">known outcomes</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.105.1">Finds </span><span class="No-Break"><span class="koboSpan" id="kobo.106.1">unknown outcomes</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.107.1">Possible </span><span class="No-Break"><span class="koboSpan" id="kobo.108.1">by machine</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.109.1">Requires </span><span class="No-Break"><span class="koboSpan" id="kobo.110.1">human creativity</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.111.1">Behavior verification</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.112.1">Behavior investigation</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.113.1">Planned</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.114.1">Opportunistic</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.115.1">Code is in control of </span><span class="No-Break"><span class="koboSpan" id="kobo.116.1">the testing</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.117.1">Human minds control </span><span class="No-Break"><span class="koboSpan" id="kobo.118.1">the testing</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.119.1">Table 11.1 – Automated versus manual exploratory testing</span></p>
<p><span class="koboSpan" id="kobo.120.1">Manual exploratory testing</span><a id="_idIndexMarker618"/><span class="koboSpan" id="kobo.121.1"> will always be needed. </span><span class="koboSpan" id="kobo.121.2">Even the best developers get pressed for time, distracted, or have yet another meeting that should have been an email. </span><span class="koboSpan" id="kobo.121.3">Once concentration is lost, it’s all too easy for mistakes to creep in. </span><span class="koboSpan" id="kobo.121.4">Some missing tests relate to edge cases that we cannot see alone. </span><span class="koboSpan" id="kobo.121.5">Another human perspective often brings a fresh insight we would simply never have unaided. </span><span class="koboSpan" id="kobo.121.6">Manual exploratory testing provides an important extra layer of defense in depth against defects </span><span class="No-Break"><span class="koboSpan" id="kobo.122.1">going unnoticed.</span></span></p>
<p><span class="koboSpan" id="kobo.123.1">Once exploratory testing identifies some unexpected behavior, we can feed this back into development. </span><span class="koboSpan" id="kobo.123.2">At that point, we can use TDD to write a test for the correct behavior, confirm the presence of the defect, then develop the fix. </span><span class="koboSpan" id="kobo.123.3">We now have a fix and a regression test to ensure the bug remains fixed. </span><span class="koboSpan" id="kobo.123.4">We can think of manual exploratory testing as the fastest possible feedback loop for a defect we missed. </span><span class="koboSpan" id="kobo.123.5">An excellent guide to exploratory testing is listed in the </span><em class="italic"><span class="koboSpan" id="kobo.124.1">Further </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.125.1">reading</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.126.1"> section.</span></span></p>
<p><span class="koboSpan" id="kobo.127.1">Seen in this light, automation testing</span><a id="_idIndexMarker619"/><span class="koboSpan" id="kobo.128.1"> and TDD do not make manual efforts less important. </span><span class="koboSpan" id="kobo.128.2">Instead, their value is amplified. </span><span class="koboSpan" id="kobo.128.3">The two approaches work together to build quality into the </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">code base.</span></span></p>
<p><span class="koboSpan" id="kobo.130.1">Manual testing for things we missed isn’t the only development time activity of value that cannot be automated. </span><span class="koboSpan" id="kobo.130.2">We also have the task of checking the quality of our source code, which is the subject of the </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">next section.</span></span></p>
<h1 id="_idParaDest-231"><a id="_idTextAnchor240"/><span class="koboSpan" id="kobo.132.1">Code review and ensemble programming</span></h1>
<p><span class="koboSpan" id="kobo.133.1">This section reviews another area surprisingly resistant to automation: checking </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">code quality.</span></span></p>
<p><span class="koboSpan" id="kobo.135.1">As we’ve seen throughout this book, TDD is primarily concerned with the design of our code. </span><span class="koboSpan" id="kobo.135.2">As</span><a id="_idIndexMarker620"/><span class="koboSpan" id="kobo.136.1"> we build up a unit test, we define how our code will be used by its consumers. </span><span class="koboSpan" id="kobo.136.2">The implementation of that design is of no concern to our test, but it does concern us as software engineers. </span><span class="koboSpan" id="kobo.136.3">We want that implementation to perform well and to be easy for the next reader to understand. </span><span class="koboSpan" id="kobo.136.4">Code is read many more times than it is written over its </span><span class="No-Break"><span class="koboSpan" id="kobo.137.1">life cycle.</span></span></p>
<p><span class="koboSpan" id="kobo.138.1">Some automated tools exist to help with checking code quality. </span><span class="koboSpan" id="kobo.138.2">These are known as static code analysis tools. </span><span class="koboSpan" id="kobo.138.3">The name comes from the fact that they do not run code; instead, they perform an</span><a id="_idIndexMarker621"/><span class="koboSpan" id="kobo.139.1"> automated review of the source code. </span><span class="koboSpan" id="kobo.139.2">One popular tool for Java is Sonarqube (at </span><a href="https://www.sonarqube.org/"><span class="koboSpan" id="kobo.140.1">https://www.sonarqube.org/</span></a><span class="koboSpan" id="kobo.141.1">), which runs a set of rules across a </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">code base.</span></span></p>
<p><span class="koboSpan" id="kobo.143.1">Out of the box, tools like this give warnings about </span><span class="No-Break"><span class="koboSpan" id="kobo.144.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.145.1">Variable name conventions not </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">being followed</span></span></li>
<li><span class="koboSpan" id="kobo.147.1">Uninitialized variables leading to possible </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.148.1">NullPointerException</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.149.1"> problems</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.150.1">Security vulnerabilities</span></span></li>
<li><span class="koboSpan" id="kobo.151.1">Poor or risky use of </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">programming constructs</span></span></li>
<li><span class="koboSpan" id="kobo.153.1">Violations of community-accepted practices </span><span class="No-Break"><span class="koboSpan" id="kobo.154.1">and standards</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.155.1">These rules can be modified and added to, allowing customization to be made to the local project house style </span><span class="No-Break"><span class="koboSpan" id="kobo.156.1">and rules.</span></span></p>
<p><span class="koboSpan" id="kobo.157.1">Of course, such automated assessments have limitations. </span><span class="koboSpan" id="kobo.157.2">As with manual exploratory testing, there are simply some things only a human can do (at least at the time of writing). </span><span class="koboSpan" id="kobo.157.3">In terms of code analysis, this mainly involves bringing context to the decisions. </span><span class="koboSpan" id="kobo.157.4">One simple example here is preferring longer, more descriptive variable names to a primitive such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.158.1">int</span></strong><span class="koboSpan" id="kobo.159.1">, compared to a more detailed type such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.160.1">WordRepository</span></strong><span class="koboSpan" id="kobo.161.1">. </span><span class="koboSpan" id="kobo.161.2">Static tools lack that understanding of the </span><span class="No-Break"><span class="koboSpan" id="kobo.162.1">different contexts.</span></span></p>
<p><span class="koboSpan" id="kobo.163.1">Automated code analysis</span><a id="_idIndexMarker622"/><span class="koboSpan" id="kobo.164.1"> has its benefits and limitations, as </span><a id="_idIndexMarker623"/><span class="No-Break"><span class="koboSpan" id="kobo.165.1">summarized here:</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table002-1">
<colgroup>
<col/>
<col/>
</colgroup>
<thead>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.166.1">Automated Analysis</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.167.1">Human Review</span></strong></span></p>
</td>
</tr>
</thead>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.168.1">Rigid rules (for example, variable </span><span class="No-Break"><span class="koboSpan" id="kobo.169.1">name length)</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.170.1">Relaxes rules based </span><span class="No-Break"><span class="koboSpan" id="kobo.171.1">on context</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.172.1">Applies a fixed set of </span><span class="No-Break"><span class="koboSpan" id="kobo.173.1">assessment criteria</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.174.1">Applies </span><span class="No-Break"><span class="koboSpan" id="kobo.175.1">experiential learning</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.176.1">Reports </span><span class="No-Break"><span class="koboSpan" id="kobo.177.1">pass/fail outcomes</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.178.1">Suggests </span><span class="No-Break"><span class="koboSpan" id="kobo.179.1">alternative improvements</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.180.1">Table 11.2 – Automated analysis versus human review</span></p>
<p><span class="koboSpan" id="kobo.181.1">Google has a very interesting</span><a id="_idIndexMarker624"/><span class="koboSpan" id="kobo.182.1"> system called </span><strong class="bold"><span class="koboSpan" id="kobo.183.1">Google Tricorder</span></strong><span class="koboSpan" id="kobo.184.1">. </span><span class="koboSpan" id="kobo.184.2">This is a set of program analysis tools that combines the creativity of Google engineers in devising rules for good code with the automation to apply them. </span><span class="koboSpan" id="kobo.184.3">For more information, </span><span class="No-Break"><span class="koboSpan" id="kobo.185.1">see </span></span><a href="https://research.google/pubs/pub43322/"><span class="No-Break"><span class="koboSpan" id="kobo.186.1">https://research.google/pubs/pub43322/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.187.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.188.1">Manually reviewing</span><a id="_idIndexMarker625"/><span class="koboSpan" id="kobo.189.1"> code can be done in various ways, with some </span><span class="No-Break"><span class="koboSpan" id="kobo.190.1">common approaches:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.191.1">Code review on </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.192.1">pull requests</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.193.1">:</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.194.1">A pull request, also known as a </span><a id="_idIndexMarker626"/><span class="koboSpan" id="kobo.195.1">merge request, is made by a developer when they wish to integrate their latest code changes into the main code base. </span><span class="koboSpan" id="kobo.195.2">This provides an opportunity for another developer to review that work and suggest improvements. </span><span class="koboSpan" id="kobo.195.3">They may even visually spot defects. </span><span class="koboSpan" id="kobo.195.4">Once the original developer makes agreed changes, the request is approved and the code </span><span class="No-Break"><span class="koboSpan" id="kobo.196.1">is merged.</span></span></p>
<ul>
<li><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.197.1">Pair programming</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.198.1">:</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.199.1">Pair programming</span><a id="_idIndexMarker627"/><span class="koboSpan" id="kobo.200.1"> is a way of working where two developers work on the same task at the same time. </span><span class="koboSpan" id="kobo.200.2">There is a continuous discussion about how to write the code in the best way. </span><span class="koboSpan" id="kobo.200.3">It is a continuous review process. </span><span class="koboSpan" id="kobo.200.4">As soon as either developer spots a problem, or has a suggested improvement, a discussion happens and a decision is made. </span><span class="koboSpan" id="kobo.200.5">The code is continuously corrected and refined as it </span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">is developed.</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.202.1">Ensemble (</span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.203.1">mob) programming</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.204.1">:</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.205.1">Like pair</span><a id="_idIndexMarker628"/><span class="koboSpan" id="kobo.206.1"> programming, only the whole team takes part in writing the code for one task. </span><span class="koboSpan" id="kobo.206.2">The ultimate in collaboration, which continuously brings</span><a id="_idIndexMarker629"/><span class="koboSpan" id="kobo.207.1"> the expertise and opinions of an entire team to bear on every piece of </span><span class="No-Break"><span class="koboSpan" id="kobo.208.1">code written.</span></span></p>
<p><span class="koboSpan" id="kobo.209.1">The dramatic difference here is that a code review happens after the code is written, but pair programming and mobbing happen while the code is being written. </span><span class="koboSpan" id="kobo.209.2">Code reviews performed after the code is written frequently happen too late to allow meaningful changes to be made. </span><span class="koboSpan" id="kobo.209.3">Pairing and mobbing avoid this by reviewing and refining code continuously. </span><span class="koboSpan" id="kobo.209.4">Changes are made the instant they are identified. </span><span class="koboSpan" id="kobo.209.5">This can result in higher quality output delivered sooner compared to the </span><span class="No-Break"><span class="koboSpan" id="kobo.210.1">code-then-review workflow.</span></span></p>
<p><span class="koboSpan" id="kobo.211.1">Different development situations will adopt different practices. </span><span class="koboSpan" id="kobo.211.2">In every case, adding a second pair of human eyes (or more) provides an opportunity for a design-level improvement, not a </span><span class="No-Break"><span class="koboSpan" id="kobo.212.1">syntax-level one.</span></span></p>
<p><span class="koboSpan" id="kobo.213.1">With that, we’ve seen how developers can benefit from adding manual exploratory testing and code review to their TDD work. </span><span class="koboSpan" id="kobo.213.2">Manual techniques benefit our users as well, as we will cover in the </span><span class="No-Break"><span class="koboSpan" id="kobo.214.1">next section.</span></span></p>
<h1 id="_idParaDest-232"><a id="_idTextAnchor241"/><span class="koboSpan" id="kobo.215.1">User interface and user experience testing</span></h1>
<p><span class="koboSpan" id="kobo.216.1">In this section, we will consider how we evaluate the impact of our user interface on users. </span><span class="koboSpan" id="kobo.216.2">This is another area where automation brings benefits but cannot complete the job without humans </span><span class="No-Break"><span class="koboSpan" id="kobo.217.1">being involved.</span></span></p>
<h2 id="_idParaDest-233"><a id="_idTextAnchor242"/><span class="koboSpan" id="kobo.218.1">Testing the user interface</span></h2>
<p><span class="koboSpan" id="kobo.219.1">User interfaces are </span><a id="_idIndexMarker630"/><span class="koboSpan" id="kobo.220.1">the only part of our software system that matters to the most important people of all: our users. </span><span class="koboSpan" id="kobo.220.2">They are – quite literally – their windows into our world. </span><span class="koboSpan" id="kobo.220.3">Whether we have a command-line interface, a mobile web application, or a desktop GUI, our users will be helped or hindered in their tasks by our </span><span class="No-Break"><span class="koboSpan" id="kobo.221.1">user interface.</span></span></p>
<p><span class="koboSpan" id="kobo.222.1">The success of a user interface rests on two things being </span><span class="No-Break"><span class="koboSpan" id="kobo.223.1">done well:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.224.1">It provides all the functionality a user needs (</span><span class="No-Break"><span class="koboSpan" id="kobo.225.1">and wants)</span></span></li>
<li><span class="koboSpan" id="kobo.226.1">It allows a user to accomplish their end goals in an effective and </span><span class="No-Break"><span class="koboSpan" id="kobo.227.1">efficient manner</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.228.1">The first of these, providing</span><a id="_idIndexMarker631"/><span class="koboSpan" id="kobo.229.1"> functionality, is the more programmatic of the two. </span><span class="koboSpan" id="kobo.229.2">In the same way that we use TDD to drive a good design for our server-side code, we can use it in our frontend code as well. </span><span class="koboSpan" id="kobo.229.3">If our Java application generates HTML – called server-side rendering – TDD is trivial to use. </span><span class="koboSpan" id="kobo.229.4">We test the HTML generation adapter and we’re done. </span><span class="koboSpan" id="kobo.229.5">If we are using a JavaScript/Typescript framework running in the browser, we can use TDD there, with a </span><a id="_idIndexMarker632"/><span class="koboSpan" id="kobo.230.1">test framework such as </span><span class="No-Break"><span class="koboSpan" id="kobo.231.1">Jest (</span></span><a href="https://jestjs.io/"><span class="No-Break"><span class="koboSpan" id="kobo.232.1">https://jestjs.io/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.233.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.234.1">Having tested we’re providing the right functions to the user, automation then becomes less useful. </span><span class="koboSpan" id="kobo.234.2">With TDD, we can verify that all the right sorts of graphical elements are present in our user interface. </span><span class="koboSpan" id="kobo.234.3">But we can’t tell whether they are meeting the needs of </span><span class="No-Break"><span class="koboSpan" id="kobo.235.1">the user.</span></span></p>
<p><span class="koboSpan" id="kobo.236.1">Consider this fictional user interface for buying merchandise relating to our </span><span class="No-Break"><span class="koboSpan" id="kobo.237.1">Wordz application:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer083">
<span class="koboSpan" id="kobo.238.1"><img alt="Figure 11.2 – Example user interface" src="image/Figure_11.2_B18384.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.239.1">Figure 11.2 – Example user interface</span></p>
<p><span class="koboSpan" id="kobo.240.1">We can use TDD to test that all</span><a id="_idIndexMarker633"/><span class="koboSpan" id="kobo.241.1"> those interface elements – the boxes and buttons – are present and working. </span><span class="koboSpan" id="kobo.241.2">But will our users care? </span><span class="koboSpan" id="kobo.241.3">Here are the questions we need </span><span class="No-Break"><span class="koboSpan" id="kobo.242.1">to ask:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.243.1">Does it look and </span><span class="No-Break"><span class="koboSpan" id="kobo.244.1">feel good?</span></span></li>
<li><span class="koboSpan" id="kobo.245.1">Does it align with corporate branding and house </span><span class="No-Break"><span class="koboSpan" id="kobo.246.1">style guides?</span></span></li>
<li><span class="koboSpan" id="kobo.247.1">For the task of buying a T-shirt, is it easy </span><span class="No-Break"><span class="koboSpan" id="kobo.248.1">to use?</span></span></li>
<li><span class="koboSpan" id="kobo.249.1">Does it present a logical flow to the user, guiding them through </span><span class="No-Break"><span class="koboSpan" id="kobo.250.1">their task?</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.251.1">Quite deliberately for this example, the answer is no to all these questions. </span><span class="koboSpan" id="kobo.251.2">This is, quite frankly, a terrible user interface layout. </span><span class="koboSpan" id="kobo.251.3">It has no style, no feeling, and no brand identity. </span><span class="koboSpan" id="kobo.251.4">You have to type in the product name in the text field. </span><span class="koboSpan" id="kobo.251.5">There is no product image, no description, and no price! </span><span class="koboSpan" id="kobo.251.6">This user interface is truly the worst imaginable for an e-commerce product sales page. </span><span class="koboSpan" id="kobo.251.7">Yet it would pass all our automated </span><span class="No-Break"><span class="koboSpan" id="kobo.252.1">functionality tests.</span></span></p>
<p><span class="koboSpan" id="kobo.253.1">Designing effective </span><a id="_idIndexMarker634"/><span class="koboSpan" id="kobo.254.1">user interfaces is a very human skill. </span><span class="koboSpan" id="kobo.254.2">It involves a little psychology in knowing how humans behave when presented with a task, mixed with an artistic eye, backed by creativity. </span><span class="koboSpan" id="kobo.254.3">These qualities of a user interface are best assessed by humans, adding another manual step to our </span><span class="No-Break"><span class="koboSpan" id="kobo.255.1">development process.</span></span></p>
<h2 id="_idParaDest-234"><a id="_idTextAnchor243"/><span class="koboSpan" id="kobo.256.1">Evaluating the user experience</span></h2>
<p><span class="koboSpan" id="kobo.257.1">Closely related to user</span><a id="_idIndexMarker635"/><span class="koboSpan" id="kobo.258.1"> interface design is user </span><span class="No-Break"><span class="koboSpan" id="kobo.259.1">experience design.</span></span></p>
<p><span class="koboSpan" id="kobo.260.1">User experience goes beyond any individual element or view on a user interface. </span><span class="koboSpan" id="kobo.260.2">It is the entire experience our users have, end to end. </span><span class="koboSpan" id="kobo.260.3">When we want to order the latest Wordz T-shirt from our e-commerce store, we want the entire process to be easy. </span><span class="koboSpan" id="kobo.260.4">We want the workflow across every screen to be obvious, uncluttered, and easier to get right than to get wrong. </span><span class="koboSpan" id="kobo.260.5">Going further, service design is about optimizing the experience from wanting a T-shirt to </span><span class="No-Break"><span class="koboSpan" id="kobo.261.1">wearing it.</span></span></p>
<p><span class="koboSpan" id="kobo.262.1">Ensuring users have a great experience is the job of a user experience designer. </span><span class="koboSpan" id="kobo.262.2">It is a human activity that combines empathy, psychology, and experimentation. </span><span class="koboSpan" id="kobo.262.3">Automation is limited in how it can help here. </span><span class="koboSpan" id="kobo.262.4">Some mechanical parts of this can be automated. </span><span class="koboSpan" id="kobo.262.5">Obvious candidates are applications such </span><a id="_idIndexMarker636"/><span class="koboSpan" id="kobo.263.1">as Invision (</span><a href="https://www.invisionapp.com/"><span class="koboSpan" id="kobo.264.1">https://www.invisionapp.com/</span></a><span class="koboSpan" id="kobo.265.1">), which allows us to produce a screen mockup that can be interacted with, and Google Forms, which allows us to collect feedback over the web, with no code to set </span><span class="No-Break"><span class="koboSpan" id="kobo.266.1">that up.</span></span></p>
<p><span class="koboSpan" id="kobo.267.1">After creating a candidate user experience, we can craft experiments where potential users are given a task to complete, then asked to provide feedback on how they found </span><span class="No-Break"><span class="koboSpan" id="kobo.268.1">the experience.</span></span></p>
<p><span class="koboSpan" id="kobo.269.1">A simple, manual form is more than adequate to capture </span><span class="No-Break"><span class="koboSpan" id="kobo.270.1">this feedback:</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table003-1">
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<thead>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.271.1">Experience</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.272.1">Rating of 1 (Poor) – </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.273.1">5 (Good)</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.274.1">Comments</span></strong></span></p>
</td>
</tr>
</thead>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.275.1">My task was easy </span><span class="No-Break"><span class="koboSpan" id="kobo.276.1">to complete</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.277.1">4</span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.278.1">I completed the task ok after being prompted by </span><span class="No-Break"><span class="koboSpan" id="kobo.279.1">your researcher.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.280.1">I felt confident completing my task </span><span class="No-Break"><span class="koboSpan" id="kobo.281.1">without instructions</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.282.1">2</span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.283.1">The text entry field about T-shirt size confused me. </span><span class="koboSpan" id="kobo.283.2">Could it be a dropdown of available </span><span class="No-Break"><span class="koboSpan" id="kobo.284.1">options instead?</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.285.1">The interface guided me through </span><span class="No-Break"><span class="koboSpan" id="kobo.286.1">the task</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.287.1">3</span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.288.1">It was ok in the end – but that text field was an annoyance, so I scored this </span><span class="No-Break"><span class="koboSpan" id="kobo.289.1">task lower.</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.290.1">Table 11.3 – User experience feedback form</span></p>
<p><span class="koboSpan" id="kobo.291.1">User </span><a id="_idIndexMarker637"/><span class="koboSpan" id="kobo.292.1">experience design is primarily a human activity. </span><span class="koboSpan" id="kobo.292.2">So is the evaluation of test results. </span><span class="koboSpan" id="kobo.292.3">These tools only go as far as allowing us to create a mockup of our visions and collect experimental results. </span><span class="koboSpan" id="kobo.292.4">We must run sessions with real users, solicit their opinions on how their experience was, then feed back the results in an </span><span class="No-Break"><span class="koboSpan" id="kobo.293.1">improved design.</span></span></p>
<p><span class="koboSpan" id="kobo.294.1">While user experience is important, the next section deals with a mission-critical aspect of our code: security </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">and operations.</span></span></p>
<h1 id="_idParaDest-235"><a id="_idTextAnchor244"/><span class="koboSpan" id="kobo.296.1">Security testing and operations monitoring</span></h1>
<p><span class="koboSpan" id="kobo.297.1">This section reflects on the critical aspects of security and </span><span class="No-Break"><span class="koboSpan" id="kobo.298.1">operations concerns.</span></span></p>
<p><span class="koboSpan" id="kobo.299.1">So far, we have created an application that is well-engineered and has very low defects. </span><span class="koboSpan" id="kobo.299.2">Our user experience feedback has been positive – it is easy to use. </span><span class="koboSpan" id="kobo.299.3">But all that potential can be lost in an instant if we cannot keep the application running. </span><span class="koboSpan" id="kobo.299.4">If hackers target our site and harm users, the situation becomes </span><span class="No-Break"><span class="koboSpan" id="kobo.300.1">even worse.</span></span></p>
<p><span class="koboSpan" id="kobo.301.1">An application that is not running does not exist. </span><span class="koboSpan" id="kobo.301.2">The discipline of operations – often called DevOps</span><a id="_idIndexMarker638"/><span class="koboSpan" id="kobo.302.1"> these days – aims to keep applications running in good health and alert us if that health starts </span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">to fail.</span></span></p>
<p><span class="koboSpan" id="kobo.304.1">Security testing – also called </span><strong class="bold"><span class="koboSpan" id="kobo.305.1">penetration testing</span></strong><span class="koboSpan" id="kobo.306.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.307.1">pentesting</span></strong><span class="koboSpan" id="kobo.308.1">) – is a special case of manual exploratory testing. </span><span class="koboSpan" id="kobo.308.2">By</span><a id="_idIndexMarker639"/><span class="koboSpan" id="kobo.309.1"> its nature, we are looking for new exploits and unknown vulnerabilities in our application. </span><span class="koboSpan" id="kobo.309.2">Such work is not best served by automation. </span><span class="koboSpan" id="kobo.309.3">Automation repeats what is already known; to discover the unknown requires </span><span class="No-Break"><span class="koboSpan" id="kobo.310.1">human ingenuity.</span></span></p>
<p><span class="koboSpan" id="kobo.311.1">Penetration testing </span><a id="_idIndexMarker640"/><span class="koboSpan" id="kobo.312.1">is the discipline that takes a piece of software and attempts to circumvent its security. </span><span class="koboSpan" id="kobo.312.2">Security breaches can be expensive, embarrassing, or business-ending for a company. </span><span class="koboSpan" id="kobo.312.3">The exploits used to create the breach are often </span><span class="No-Break"><span class="koboSpan" id="kobo.313.1">very simple.</span></span></p>
<p><span class="koboSpan" id="kobo.314.1">Security risks</span><a id="_idIndexMarker641"/><span class="koboSpan" id="kobo.315.1"> can be summarized roughly </span><span class="No-Break"><span class="koboSpan" id="kobo.316.1">as follows:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.317.1">Things we </span><span class="No-Break"><span class="koboSpan" id="kobo.318.1">shouldn’t see</span></span></li>
<li><span class="koboSpan" id="kobo.319.1">Things we </span><span class="No-Break"><span class="koboSpan" id="kobo.320.1">shouldn’t change</span></span></li>
<li><span class="koboSpan" id="kobo.321.1">Things we shouldn’t use </span><span class="No-Break"><span class="koboSpan" id="kobo.322.1">as often</span></span></li>
<li><span class="koboSpan" id="kobo.323.1">Things we should not be able to </span><span class="No-Break"><span class="koboSpan" id="kobo.324.1">lie about</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.325.1">This is an oversimplification, of course. </span><span class="koboSpan" id="kobo.325.2">But the fact remains that our application may be vulnerable to these damaging activities – and we need to know whether that is the case or not. </span><span class="koboSpan" id="kobo.325.3">This requires testing. </span><span class="koboSpan" id="kobo.325.4">This kind of testing must be adaptive, creative, devious, and continually updated. </span><span class="koboSpan" id="kobo.325.5">An automated approach is none of those things, meaning security testing must take its place as a manual step in our </span><span class="No-Break"><span class="koboSpan" id="kobo.326.1">development process.</span></span></p>
<p><span class="koboSpan" id="kobo.327.1">A great </span><a id="_idIndexMarker642"/><span class="koboSpan" id="kobo.328.1">starting point is to review the latest </span><strong class="bold"><span class="koboSpan" id="kobo.329.1">OWASP Top 10 Web Application Security Risks</span></strong><span class="koboSpan" id="kobo.330.1"> (</span><a href="https://owasp.org/www-project-top-ten/"><span class="koboSpan" id="kobo.331.1">https://owasp.org/www-project-top-ten/</span></a><span class="koboSpan" id="kobo.332.1">) and begin some manual exploratory testing based on the risks listed. </span><span class="koboSpan" id="kobo.332.2">Further information on threat models such as </span><strong class="bold"><span class="koboSpan" id="kobo.333.1">Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, and Elevation of Privilege</span></strong><span class="koboSpan" id="kobo.334.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.335.1">STRIDE</span></strong><span class="koboSpan" id="kobo.336.1">) can be found at </span><a href="https://www.eccouncil.org/threat-modeling/"><span class="koboSpan" id="kobo.337.1">https://www.eccouncil.org/threat-modeling/</span></a><span class="koboSpan" id="kobo.338.1">. </span><span class="koboSpan" id="kobo.338.2">OWASP also has some</span><a id="_idIndexMarker643"/><span class="koboSpan" id="kobo.339.1"> excellent resources on useful tools at https://owasp.org/www-community/Fuzzing. </span><strong class="bold"><span class="koboSpan" id="kobo.340.1">Fuzzing</span></strong><span class="koboSpan" id="kobo.341.1"> is an automated way of discovering defects, although </span><a id="_idIndexMarker644"/><span class="koboSpan" id="kobo.342.1">it requires a human to interpret the</span><a id="_idIndexMarker645"/><span class="koboSpan" id="kobo.343.1"> results of a </span><span class="No-Break"><span class="koboSpan" id="kobo.344.1">failed test.</span></span></p>
<p><span class="koboSpan" id="kobo.345.1">As with other manual exploratory tests, these ad hoc experiments may lead to some future test automation. </span><span class="koboSpan" id="kobo.345.2">But the real value lies in the creativity applied to investigating </span><span class="No-Break"><span class="koboSpan" id="kobo.346.1">the unknown.</span></span></p>
<p><span class="koboSpan" id="kobo.347.1">The preceding sections have made a case for the importance of manual interventions to complement our test automation efforts. </span><span class="koboSpan" id="kobo.347.2">But </span><a id="_idIndexMarker646"/><span class="koboSpan" id="kobo.348.1">how does that fit in with a </span><strong class="bold"><span class="koboSpan" id="kobo.349.1">continuous integration/continuous delivery</span></strong><span class="koboSpan" id="kobo.350.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.351.1">CI/CD</span></strong><span class="koboSpan" id="kobo.352.1">) approach? </span><span class="koboSpan" id="kobo.352.2">That’s the focus of the </span><span class="No-Break"><span class="koboSpan" id="kobo.353.1">next section.</span></span></p>
<h1 id="_idParaDest-236"><a id="_idTextAnchor245"/><span class="koboSpan" id="kobo.354.1">Incorporating manual elements into CI/CD workflows</span></h1>
<p><span class="koboSpan" id="kobo.355.1">We’ve seen that not only are </span><a id="_idIndexMarker647"/><span class="koboSpan" id="kobo.356.1">manual processes important in our overall workflow but for some things, they are irreplaceable. </span><span class="koboSpan" id="kobo.356.2">But how do manual steps fit into heavily automated workflows? </span><span class="koboSpan" id="kobo.356.3">That’s the challenge we will cover in </span><span class="No-Break"><span class="koboSpan" id="kobo.357.1">this section.</span></span></p>
<p><span class="koboSpan" id="kobo.358.1">Integrating manual processes into an automated CI/CD pipeline can be difficult. </span><span class="koboSpan" id="kobo.358.2">The two approaches are not natural partners in terms of a linear, repeatable sequence of activities. </span><span class="koboSpan" id="kobo.358.3">The approach we take depends on our ultimate goal. </span><span class="koboSpan" id="kobo.358.4">Do we want a fully automated continuous deployment system, or are we happy with some </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">manual interruptions?</span></span></p>
<p><span class="koboSpan" id="kobo.360.1">The simplest approach to incorporating a manual process is to simply stop the automation at a suitable point, begin the manual process, then resume automaton once the manual process completes. </span><span class="koboSpan" id="kobo.360.2">We can think of this as a blocking workflow, as all further automated steps in the pipeline must stop until the manual work is completed. </span><span class="koboSpan" id="kobo.360.3">This is illustrated in the </span><span class="No-Break"><span class="koboSpan" id="kobo.361.1">following diagram:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer084">
<span class="koboSpan" id="kobo.362.1"><img alt="Figure 11.3 – Blocking workflow" src="image/Figure_11.3_B18384.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.363.1">Figure 11.3 – Blocking workflow</span></p>
<p><span class="koboSpan" id="kobo.364.1">By organizing our development process as a series of stages, some being automated and some being manual, we create a simple blocking workflow. </span><span class="koboSpan" id="kobo.364.2">Blocking here means that the flow of value is blocked by each stage. </span><span class="koboSpan" id="kobo.364.3">The automation stages typically run more quickly than the </span><span class="No-Break"><span class="koboSpan" id="kobo.365.1">manual stages.</span></span></p>
<p><span class="koboSpan" id="kobo.366.1">This workflow has some advantages in that it’s simple to understand and operate. </span><span class="koboSpan" id="kobo.366.2">Each iteration of software we deliver will have all automated tests run as well as all the current manual processes. </span><span class="koboSpan" id="kobo.366.3">In one sense, this release is of the highest quality we know how to make at that time. </span><span class="koboSpan" id="kobo.366.4">The disadvantage is that each iteration must wait for all manual processes </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">to complete:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer085">
<span class="koboSpan" id="kobo.368.1"><img alt="Figure 11.4 – Dual track workflow" src="image/Figure_11.4_B18384.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.369.1">Figure 11.4 – Dual track workflow</span></p>
<p><span class="koboSpan" id="kobo.370.1">One</span><a id="_idIndexMarker648"/><span class="koboSpan" id="kobo.371.1"> enabler for very smooth dual-track workflows is to use a single main trunk for the whole code base. </span><span class="koboSpan" id="kobo.371.2">All developers commit to this main trunk. </span><span class="koboSpan" id="kobo.371.3">There are no other branches. </span><span class="koboSpan" id="kobo.371.4">Any features in active development are isolated by </span><strong class="bold"><span class="koboSpan" id="kobo.372.1">feature flags</span></strong><span class="koboSpan" id="kobo.373.1">. </span><span class="koboSpan" id="kobo.373.2">These are Boolean values that can be set to </span><strong class="source-inline"><span class="koboSpan" id="kobo.374.1">true or false</span></strong><span class="koboSpan" id="kobo.375.1"> at runtime. </span><span class="koboSpan" id="kobo.375.2">The code inspects these</span><a id="_idIndexMarker649"/><span class="koboSpan" id="kobo.376.1"> flags and decides whether to run a feature or not. </span><span class="koboSpan" id="kobo.376.2">Manual testing can then happen without having to pause deployments. </span><span class="koboSpan" id="kobo.376.3">During testing, the features in progress are enabled via the relevant feature flags. </span><span class="koboSpan" id="kobo.376.4">For the general end users, features in progress </span><span class="No-Break"><span class="koboSpan" id="kobo.377.1">are disabled.</span></span></p>
<p><span class="koboSpan" id="kobo.378.1">We can select the approach that fits our delivery goals the best. </span><span class="koboSpan" id="kobo.378.2">The blocking workflow trades off less rework for an extended delivery cycle. </span><span class="koboSpan" id="kobo.378.3">The dual-track approach allows for more frequent feature delivery, with a risk of having defects in production before they are discovered by a manual process and, </span><span class="No-Break"><span class="koboSpan" id="kobo.379.1">subsequently, repaired.</span></span></p>
<p><span class="koboSpan" id="kobo.380.1">Selecting the right process to use involves a trade-off between feature release cadence and tolerating defects. </span><span class="koboSpan" id="kobo.380.2">Whatever we choose, the goal is to focus the expertise of the whole team on creating software with a low </span><span class="No-Break"><span class="koboSpan" id="kobo.381.1">defect rate.</span></span></p>
<p><span class="koboSpan" id="kobo.382.1">Balancing </span><a id="_idIndexMarker650"/><span class="koboSpan" id="kobo.383.1">automated workflows with manual, human workflows isn’t easy, but it does result in getting the most human intuition and experience into the product. </span><span class="koboSpan" id="kobo.383.2">That’s good for our development teams and it is good for our users. </span><span class="koboSpan" id="kobo.383.3">They benefit from improved ease of use and robustness in their applications. </span><span class="koboSpan" id="kobo.383.4">Hopefully, this chapter has shown you how we can combine these two worlds and cross that traditional developer-tester divide. </span><span class="koboSpan" id="kobo.383.5">We can make one great team, aiming at one </span><span class="No-Break"><span class="koboSpan" id="kobo.384.1">excellent outcome.</span></span></p>
<h1 id="_idParaDest-237"><a id="_idTextAnchor246"/><span class="koboSpan" id="kobo.385.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.386.1">This chapter discussed the importance of various manual processes </span><span class="No-Break"><span class="koboSpan" id="kobo.387.1">during development.</span></span></p>
<p><span class="koboSpan" id="kobo.388.1">Despite its advantages, we’ve seen how TDD cannot prevent all kinds of defects in software. </span><span class="koboSpan" id="kobo.388.2">First, we covered the benefits of applying human creativity to manual exploratory testing, where we can uncover defects that we missed during TDD. </span><span class="koboSpan" id="kobo.388.3">Then, we highlighted the quality improvements that code reviews and analysis bring. </span><span class="koboSpan" id="kobo.388.4">We also covered the very manual nature of creating and verifying excellent user interfaces with satisfying user experiences. </span><span class="koboSpan" id="kobo.388.5">Next, we emphasized the importance of security testing and operations monitoring in keeping a live system working well. </span><span class="koboSpan" id="kobo.388.6">Finally, we reviewed approaches to integrating manual steps into automation workflows, and the trade-offs we need </span><span class="No-Break"><span class="koboSpan" id="kobo.389.1">to make.</span></span></p>
<p><span class="koboSpan" id="kobo.390.1">In the next chapter, we’ll review some ways of working related to when and where we develop tests, before moving on to </span><em class="italic"><span class="koboSpan" id="kobo.391.1">Part 3</span></em><span class="koboSpan" id="kobo.392.1"> of this book, where we will finish building our </span><span class="No-Break"><span class="koboSpan" id="kobo.393.1">Wordz application.</span></span></p>
<h1 id="_idParaDest-238"><a id="_idTextAnchor247"/><span class="koboSpan" id="kobo.394.1">Questions and answers</span></h1>
<p><span class="koboSpan" id="kobo.395.1">The following are some questions and answers regarding this </span><span class="No-Break"><span class="koboSpan" id="kobo.396.1">chapter’s content:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.397.1">Have TDD and CI/CD pipelines eliminated the need for </span><span class="No-Break"><span class="koboSpan" id="kobo.398.1">manual testing?</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.399.1">No. </span><span class="koboSpan" id="kobo.399.2">They have changed where the value lies. </span><span class="koboSpan" id="kobo.399.3">Some manual processes have become irrelevant, whereas others have increased in importance. </span><span class="koboSpan" id="kobo.399.4">Traditionally, manual steps, such as following test documents for feature testing and regression testing, are no longer required. </span><span class="koboSpan" id="kobo.399.5">Running feature and regression tests has changed from writing test plans in a word processor to writing test code in an IDE. </span><span class="koboSpan" id="kobo.399.6">But for many human-centric tasks, having a human mind in the loop remains vital </span><span class="No-Break"><span class="koboSpan" id="kobo.400.1">to success.</span></span></p>
<ol>
<li value="2"><span class="koboSpan" id="kobo.401.1">Will </span><strong class="bold"><span class="koboSpan" id="kobo.402.1">artificial intelligence</span></strong><span class="koboSpan" id="kobo.403.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.404.1">AI</span></strong><span class="koboSpan" id="kobo.405.1">) automate away the </span><span class="No-Break"><span class="koboSpan" id="kobo.406.1">remaining tasks?</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.407.1">This is unknown. </span><span class="koboSpan" id="kobo.407.2">Advances in AI at this time (the early 2020s) can probably improve visual identification and static code analysis. </span><span class="koboSpan" id="kobo.407.3">It is conceivable that AI image analysis may one day be able to provide a good/bad analysis of usability – but that is pure speculation, based on AI’s abilities to generate artworks today. </span><span class="koboSpan" id="kobo.407.4">Such a thing may remain impossible. </span><span class="koboSpan" id="kobo.407.5">In terms of practical advice now, assume that the recommended manual processes in this chapter will remain manual for </span><span class="No-Break"><span class="koboSpan" id="kobo.408.1">some time.</span></span></p>
<h1 id="_idParaDest-239"><a id="_idTextAnchor248"/><span class="koboSpan" id="kobo.409.1">Further reading</span></h1>
<p><span class="koboSpan" id="kobo.410.1">To learn more about the topics that were covered in this chapter, take a look at the </span><span class="No-Break"><span class="koboSpan" id="kobo.411.1">following resources:</span></span></p>
<ul>
<li><a href="https://dl.acm.org/doi/pdf/10.1145/274567.274574"><span class="No-Break"><span class="koboSpan" id="kobo.412.1">https://dl.acm.org/doi/pdf/10.1145/274567.274574</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.413.1">:</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.414.1">An overview of the modern genesis of TDD by Kent Beck. </span><span class="koboSpan" id="kobo.414.2">While the ideas certainly predate this project, this is the central reference of modern TDD practice. </span><span class="koboSpan" id="kobo.414.3">This paper contains many important insights into software development and teams – including the quote make it run, make it right, make it fast, and the need to not feel like we are working all the time. </span><span class="koboSpan" id="kobo.414.4">Well </span><span class="No-Break"><span class="koboSpan" id="kobo.415.1">worth reading.</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.416.1">Explore It, Elizabeth Hendrickson, </span><span class="No-Break"><span class="koboSpan" id="kobo.417.1">ISBN 978-1937785024.</span></span></li>
<li><a href="https://trunkbaseddevelopment.com/"><span class="No-Break"><span class="koboSpan" id="kobo.418.1">https://trunkbaseddevelopment.com/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.419.1">.</span></span></li>
<li><a href="https://martinfowler.com/articles/feature-toggles.html"><span class="No-Break"><span class="koboSpan" id="kobo.420.1">https://martinfowler.com/articles/feature-toggles.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.421.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.422.1">Inspired: How to create tech products customers love, Marty Cagan, </span><span class="No-Break"><span class="koboSpan" id="kobo.423.1">ISBN 978-1119387503:</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.424.1">An interesting book that talks about product management. </span><span class="koboSpan" id="kobo.424.2">While this may seem strange in a developer book on TDD, a lot of the ideas in this chapter came from developer experience in a dual-track agile project, following this book. </span><span class="koboSpan" id="kobo.424.3">Dual agile means that fast feedback loops on feature discovery feed into fast feedback agile/TDD delivery. </span><span class="koboSpan" id="kobo.424.4">Essentially, manual TDD is done at the product requirements level. </span><span class="koboSpan" id="kobo.424.5">This book is an interesting read regarding modern product management, which has adopted the principles of TDD for rapid validation of assumptions about user features. </span><span class="koboSpan" id="kobo.424.6">Many ideas in this chapter aim to improve the software at the </span><span class="No-Break"><span class="koboSpan" id="kobo.425.1">product level.</span></span></p>
</div>
<div>
<div class="IMG---Figure" id="_idContainer087">
</div>
</div>
</body></html>