<html><head></head><body>
<div id="_idContainer019">
<h1 class="chapter-number" id="_idParaDest-44"><a id="_idTextAnchor052"/><span class="koboSpan" id="kobo.1.1">3</span></h1>
<h1 id="_idParaDest-45"><a id="_idTextAnchor053"/><span class="koboSpan" id="kobo.2.1">Dispelling Common Myths about TDD</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.3.1">Test-driven development</span></strong><span class="koboSpan" id="kobo.4.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.5.1">TDD</span></strong><span class="koboSpan" id="kobo.6.1">) brings many benefits to developers and the business. </span><span class="koboSpan" id="kobo.6.2">However, it is not always</span><a id="_idIndexMarker095"/><span class="koboSpan" id="kobo.7.1"> used in real projects. </span><span class="koboSpan" id="kobo.7.2">This is something I find surprising. </span><span class="koboSpan" id="kobo.7.3">TDD has been demonstrated to improve internal and external code quality in different industrial settings. </span><span class="koboSpan" id="kobo.7.4">It works for frontend and backend code. </span><span class="koboSpan" id="kobo.7.5">It works across verticals. </span><span class="koboSpan" id="kobo.7.6">I have experienced it working in embedded systems, web conferencing products, desktop applications, and </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">microservice fleets.</span></span></p>
<p><span class="koboSpan" id="kobo.9.1">To better understand how perceptions have gone wrong, let’s review the common objections to TDD, then explore how we can overcome them. </span><span class="koboSpan" id="kobo.9.2">By understanding the perceived difficulties, we can equip ourselves to be TDD advocates and help our colleagues reframe their thinking. </span><span class="koboSpan" id="kobo.9.3">We will examine six popular myths that surround TDD and form constructive responses </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">to them.</span></span></p>
<p><span class="koboSpan" id="kobo.11.1">In this chapter, we’re going to cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">following myths:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.13.1">“Writing tests slows </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">me down”</span></span></li>
<li><span class="koboSpan" id="kobo.15.1">“Tests cannot prevent </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">every bug”</span></span></li>
<li><span class="koboSpan" id="kobo.17.1">“How do you know the tests </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">are right”</span></span></li>
<li><span class="koboSpan" id="kobo.19.1">“TDD guarantees </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">good code”</span></span></li>
<li><span class="koboSpan" id="kobo.21.1">“Our code is too complex </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">to test”</span></span></li>
<li><span class="koboSpan" id="kobo.23.1">“I don’t know what to test until I write </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">the cod</span><a id="_idTextAnchor054"/><span class="koboSpan" id="kobo.25.1">e”</span></span></li>
</ul>
<h1 id="_idParaDest-46"><a id="_idTextAnchor055"/><span class="koboSpan" id="kobo.26.1">Writing tests slows me down</span></h1>
<p><span class="koboSpan" id="kobo.27.1">Writing tests </span><a id="_idIndexMarker096"/><span class="koboSpan" id="kobo.28.1">slowing development down is a popular complaint about TDD. </span><span class="koboSpan" id="kobo.28.2">This criticism has some merit. </span><span class="koboSpan" id="kobo.28.3">Personally, I have only ever felt that TDD has made me faster, but academic research disagrees. </span><span class="koboSpan" id="kobo.28.4">A meta-analysis of 18 primary studies by the </span><em class="italic"><span class="koboSpan" id="kobo.29.1">Association for Computing Machinery</span></em><span class="koboSpan" id="kobo.30.1"> showed that TDD did improve productivity in academic settings but added extra time in industrial contexts. </span><span class="koboSpan" id="kobo.30.2">However, that’s not the </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">full story.</span></span></p>
<h2 id="_idParaDest-47"><a id="_idTextAnchor056"/><span class="koboSpan" id="kobo.32.1">Understanding the benefits of slowing down</span></h2>
<p><span class="koboSpan" id="kobo.33.1">The </span><a id="_idIndexMarker097"/><span class="koboSpan" id="kobo.34.1">aforementioned research indicates that the payback for taking extra time with TDD is a reduction in the number of defects that go live in the software. </span><span class="koboSpan" id="kobo.34.2">With TDD, these defects are identified and eliminated far sooner than with</span><a id="_idIndexMarker098"/><span class="koboSpan" id="kobo.35.1"> other approaches. </span><span class="koboSpan" id="kobo.35.2">By resolving issues before manual </span><strong class="bold"><span class="koboSpan" id="kobo.36.1">quality assurance</span></strong><span class="koboSpan" id="kobo.37.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.38.1">QA</span></strong><span class="koboSpan" id="kobo.39.1">), deployment, and release, and before potentially facing a bug report from an end user, TDD allows us to cut out a large chunk of that </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">wasted effort.</span></span></p>
<p><span class="koboSpan" id="kobo.41.1">We can see the difference in the amount of work to be done in </span><span class="No-Break"><span class="koboSpan" id="kobo.42.1">this figure:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer018">
<span class="koboSpan" id="kobo.43.1"><img alt="Figure 3.1 – Not using TDD slows us down due to rework" src="image/Figure_3.1_B18384.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.44.1">Figure 3.1 – Not using TDD slows us down due to rework</span></p>
<p><span class="koboSpan" id="kobo.45.1">The top row represents developing a feature using TDD, where we have sufficient tests to prevent any defects from going into production. </span><span class="koboSpan" id="kobo.45.2">The bottom row represents developing the same feature in </span><a id="_idIndexMarker099"/><span class="koboSpan" id="kobo.46.1">a </span><strong class="bold"><span class="koboSpan" id="kobo.47.1">code-and-fix</span></strong><span class="koboSpan" id="kobo.48.1"> style, without TDD, and finding that a defect has gone live in production. </span><span class="koboSpan" id="kobo.48.2">Without TDD, we discover faults very late, annoy the user, and pay a heavy time penalty in rework. </span><span class="koboSpan" id="kobo.48.3">Note that the code-and-fix solution </span><em class="italic"><span class="koboSpan" id="kobo.49.1">looks</span></em><span class="koboSpan" id="kobo.50.1"> like it gets us into the QA stage faster, until we consider all the rework caused by undiscovered defects. </span><span class="koboSpan" id="kobo.50.2">The rework is what isn’t taken into account in </span><span class="No-Break"><span class="koboSpan" id="kobo.51.1">this myth.</span></span></p>
<p><span class="koboSpan" id="kobo.52.1">Using TDD, we simply make all our design and testing thinking explicit and upfront. </span><span class="koboSpan" id="kobo.52.2">We capture and document it using executable tests. </span><span class="koboSpan" id="kobo.52.3">Whether we write tests or not, we still spend that same thinking time considering what the specifics that our code needs to cover are. </span><span class="koboSpan" id="kobo.52.4">It turns out that the mechanical writing of the test code takes very little time. </span><span class="koboSpan" id="kobo.52.5">You can measure that yourself when we write our first test in </span><a href="B18384_05.xhtml#_idTextAnchor092"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.53.1">Chapter 5</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.54.1">, Writing Our First Test</span></em><span class="koboSpan" id="kobo.55.1">. </span><span class="koboSpan" id="kobo.55.2">The total time spent writing a piece of code is the time to design it, plus the time to write the code, plus the time to test it. </span><span class="koboSpan" id="kobo.55.3">Even without writing automated tests, the design and coding time remain constant and </span><span class="No-Break"><span class="koboSpan" id="kobo.56.1">dominant factors.</span></span></p>
<p><span class="koboSpan" id="kobo.57.1">The other area conveniently ignored through all this is the time taken to manually test. </span><span class="koboSpan" id="kobo.57.2">Without a doubt, our code will be tested. </span><span class="koboSpan" id="kobo.57.3">The only question is when and by who. </span><span class="koboSpan" id="kobo.57.4">If we write a test first, it is by us, the developers. </span><span class="koboSpan" id="kobo.57.5">It happens before any faulty code gets checked into our system. </span><span class="koboSpan" id="kobo.57.6">If we leave testing to a manual testing colleague, then we slow down the whole development process. </span><span class="koboSpan" id="kobo.57.7">We need to spend time helping our colleague understand what the success criteria are for our code. </span><span class="koboSpan" id="kobo.57.8">They must then devise a manual test plan, which often must be written up, reviewed, and accepted </span><span class="No-Break"><span class="koboSpan" id="kobo.58.1">into documentation.</span></span></p>
<p><span class="koboSpan" id="kobo.59.1">Executing manual tests is very time-consuming. </span><span class="koboSpan" id="kobo.59.2">Generally, the whole system must be built and deployed to a test environment. </span><span class="koboSpan" id="kobo.59.3">Databases must be manually set up to contain known data. </span><span class="koboSpan" id="kobo.59.4">The </span><strong class="bold"><span class="koboSpan" id="kobo.60.1">user interface</span></strong><span class="koboSpan" id="kobo.61.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.62.1">UI</span></strong><span class="koboSpan" id="kobo.63.1">) must </span><a id="_idIndexMarker100"/><span class="koboSpan" id="kobo.64.1">be clicked through to get to a suitable screen where our new code might be exercised. </span><span class="koboSpan" id="kobo.64.2">The output must be manually inspected and a decision made on its correctness. </span><span class="koboSpan" id="kobo.64.3">These steps must be manually performed every time we make </span><span class="No-Break"><span class="koboSpan" id="kobo.65.1">a change.</span></span></p>
<p><span class="koboSpan" id="kobo.66.1">Worse still, the later we leave it to test, the greater the chance is that we will have built on top of any faulty code that exists. </span><span class="koboSpan" id="kobo.66.2">We cannot know we are doing that, as we haven’t tested our code yet. </span><span class="koboSpan" id="kobo.66.3">This often becomes difficult to unpick. </span><span class="koboSpan" id="kobo.66.4">In some projects, we get so far out of step with the main code branch that developers start emailing patch files to each other. </span><span class="koboSpan" id="kobo.66.5">This means we start building on top of this faulty code, making it even harder to remove. </span><span class="koboSpan" id="kobo.66.6">These are bad practices but they do occur in </span><span class="No-Break"><span class="koboSpan" id="kobo.67.1">real projects.</span></span></p>
<p><span class="koboSpan" id="kobo.68.1">The contrast to writing a TDD test first could not be greater. </span><span class="koboSpan" id="kobo.68.2">With TDD, the setup is automated, the steps are captured and automated, and the result checking is automated. </span><span class="koboSpan" id="kobo.68.3">We are talking timescale reductions of minutes for a manual test down to milliseconds using a TDD unit test. </span><span class="koboSpan" id="kobo.68.4">This time saving is made every single time we need to run </span><span class="No-Break"><span class="koboSpan" id="kobo.69.1">that test.</span></span></p>
<p><span class="koboSpan" id="kobo.70.1">While manual</span><a id="_idIndexMarker101"/><span class="koboSpan" id="kobo.71.1"> testing is not as efficient as TDD, there is still one far worse option: no testing at all. </span><span class="koboSpan" id="kobo.71.2">Having a defect released to production means that we leave it to our users to test the code. </span><span class="koboSpan" id="kobo.71.3">Here, there may be financial considerations and the risk of reputation damage. </span><span class="koboSpan" id="kobo.71.4">At the very least, this is a very slow way to discover a fault. </span><span class="koboSpan" id="kobo.71.5">Isolating the defective lines of code from production logs and databases is extraordinarily time-consuming. </span><span class="koboSpan" id="kobo.71.6">It is also usually frustrating, in </span><span class="No-Break"><span class="koboSpan" id="kobo.72.1">my experience.</span></span></p>
<p><span class="koboSpan" id="kobo.73.1">It’s funny how a project that can never find time to write unit tests can </span><em class="italic"><span class="koboSpan" id="kobo.74.1">always</span></em><span class="koboSpan" id="kobo.75.1"> find time to trawl production logs, roll back released code, issue marketing communications, and stop all other work to do a </span><strong class="bold"><span class="koboSpan" id="kobo.76.1">Priority 1 (P1)</span></strong><span class="koboSpan" id="kobo.77.1"> fix. </span><span class="koboSpan" id="kobo.77.2">Sometimes, it feels like days are easier to find than minutes for some </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1">management approaches.</span></span></p>
<p><span class="koboSpan" id="kobo.79.1">TDD certainly </span><a id="_idIndexMarker102"/><span class="koboSpan" id="kobo.80.1">places a time cost up front in writing a test, but in return, we gain fewer faults to rectify in production – with a huge saving in overall cost, time, and reputation compared to multiple rework cycles with defects occurring in </span><span class="No-Break"><span class="koboSpan" id="kobo.81.1">live code.</span></span></p>
<h2 id="_idParaDest-48"><a id="_idTextAnchor057"/><span class="koboSpan" id="kobo.82.1">Overcoming objections to tests slowing us down</span></h2>
<p><span class="koboSpan" id="kobo.83.1">Build a </span><a id="_idIndexMarker103"/><span class="koboSpan" id="kobo.84.1">case that tracks the time spent on undiscovered defects in manual QA and failed deployments. </span><span class="koboSpan" id="kobo.84.2">Find some rough figures for the time taken for the most recent live issue to be fixed. </span><span class="koboSpan" id="kobo.84.3">Work out which missing unit test could have prevented it. </span><span class="koboSpan" id="kobo.84.4">Now work out how long that would have taken to write. </span><span class="koboSpan" id="kobo.84.5">Present these figures to stakeholders. </span><span class="koboSpan" id="kobo.84.6">It can be even more effective to work out the cost of all that engineering time and any </span><span class="No-Break"><span class="koboSpan" id="kobo.85.1">lost revenue.</span></span></p>
<p><span class="koboSpan" id="kobo.86.1">Knowing that tests do have an overall benefit in terms of fewer defects, let’s examine another common objection that tests are of no value, as they cannot prevent </span><span class="No-Break"><span class="koboSpan" id="kobo.87.1">every bug.</span></span></p>
<h1 id="_idParaDest-49"><a id="_idTextAnchor058"/><span class="koboSpan" id="kobo.88.1">Tests cannot prevent every bug</span></h1>
<p><span class="koboSpan" id="kobo.89.1">A very</span><a id="_idIndexMarker104"/><span class="koboSpan" id="kobo.90.1"> old objection to testing of any kind is this one: you cannot catch every bug. </span><span class="koboSpan" id="kobo.90.2">While this is certainly true, if anything, it means that we need more and better testing, not less. </span><span class="koboSpan" id="kobo.90.3">Let’s understand the motivations behind this one to prepare an </span><span class="No-Break"><span class="koboSpan" id="kobo.91.1">appropriate response.</span></span></p>
<h2 id="_idParaDest-50"><a id="_idTextAnchor059"/><span class="koboSpan" id="kobo.92.1">Understanding why people say tests cannot catch every bug</span></h2>
<p><span class="koboSpan" id="kobo.93.1">Straight away, we can agree with this statement. </span><span class="koboSpan" id="kobo.93.2">Tests cannot catch every bug. </span><span class="koboSpan" id="kobo.93.3">More precisely, it has been proven that testing in software systems can only reveal the presence of defects. </span><span class="koboSpan" id="kobo.93.4">It can never prove that no defects exist. </span><span class="koboSpan" id="kobo.93.5">We can have many passing tests, and defects can still hide in the places we </span><span class="No-Break"><span class="koboSpan" id="kobo.94.1">haven’t tested.</span></span></p>
<p><span class="koboSpan" id="kobo.95.1">This seems to apply in other fields as well. </span><span class="koboSpan" id="kobo.95.2">Medical scans will not always reveal problems that are too faint to notice. </span><span class="koboSpan" id="kobo.95.3">Wind tunnel tests for aircraft will not always reveal problems under specific flight conditions. </span><span class="koboSpan" id="kobo.95.4">Batch sampling in a chocolate factory will not catch every </span><span class="No-Break"><span class="koboSpan" id="kobo.96.1">substandard sweet.</span></span></p>
<p><span class="koboSpan" id="kobo.97.1">Just because we cannot catch every bug, does not mean this invalidates our testing. </span><span class="koboSpan" id="kobo.97.2">Every test we write that catches one defect results in one less defect running through our workflow. </span><span class="koboSpan" id="kobo.97.3">TDD gives us a process to help us think in terms of testing as we develop, but there are still areas where our tests will not </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">be effective:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.99.1">Tests you have not thought </span><span class="No-Break"><span class="koboSpan" id="kobo.100.1">to write</span></span></li>
<li><span class="koboSpan" id="kobo.101.1">Defects that arise due to </span><span class="No-Break"><span class="koboSpan" id="kobo.102.1">system-level interactions</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.103.1">Tests that we have not written are a real problem. </span><span class="koboSpan" id="kobo.103.2">Even when writing tests first in TDD, we must be disciplined enough to write a test for every scenario that we want to function. </span><span class="koboSpan" id="kobo.103.3">It is easy to write a test and then write the code to make it pass. </span><span class="koboSpan" id="kobo.103.4">The temptation is to then just keep adding code because we are on a roll. </span><span class="koboSpan" id="kobo.103.5">It is easy to miss an edge case and so not write a test for it. </span><span class="koboSpan" id="kobo.103.6">If we have a missing test, we open up the possibility of a defect existing and being </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">found later.</span></span></p>
<p><span class="koboSpan" id="kobo.105.1">The problem with system-level interactions here refers to the behavior that emerges when you take tested units of software and join them. </span><span class="koboSpan" id="kobo.105.2">The interactions between units can sometimes be more complex than anticipated. </span><span class="koboSpan" id="kobo.105.3">Basically, if we join up two well-tested things, the new combination itself is still not yet tested. </span><span class="koboSpan" id="kobo.105.4">Some interactions have faults that only show up in these interactions, even though the units that they are made up of passed </span><span class="No-Break"><span class="koboSpan" id="kobo.106.1">all tests.</span></span></p>
<p><span class="koboSpan" id="kobo.107.1">These two problems are real and valid. </span><span class="koboSpan" id="kobo.107.2">Testing will never cover every possible fault, but this misses the main value of testing. </span><span class="koboSpan" id="kobo.107.3">Every test we </span><em class="italic"><span class="koboSpan" id="kobo.108.1">do</span></em><span class="koboSpan" id="kobo.109.1"> write will reduce </span><span class="No-Break"><span class="koboSpan" id="kobo.110.1">one defect.</span></span></p>
<p><span class="koboSpan" id="kobo.111.1">By not testing anything, we will never spot anything wrong. </span><span class="koboSpan" id="kobo.111.2">We will not prevent any defects. </span><span class="koboSpan" id="kobo.111.3">If we test, no matter how little, then we will improve the quality of our code. </span><span class="koboSpan" id="kobo.111.4">Every defect that these tests can detect will be prevented. </span><span class="koboSpan" id="kobo.111.5">We can see the straw-man nature of this</span><a id="_idIndexMarker105"/><span class="koboSpan" id="kobo.112.1"> argument: just because we cannot cover every eventuality, it does not mean we should not do what </span><span class="No-Break"><span class="koboSpan" id="kobo.113.1">we can.</span></span></p>
<h2 id="_idParaDest-51"><a id="_idTextAnchor060"/><span class="koboSpan" id="kobo.114.1">Overcoming objections to not catching every bug</span></h2>
<p><span class="koboSpan" id="kobo.115.1">The </span><a id="_idIndexMarker106"/><span class="koboSpan" id="kobo.116.1">way to reframe this is for us to have confidence that TDD prevents many classes of errors from happening. </span><span class="koboSpan" id="kobo.116.2">Not all kinds of errors, certainly, but a bank of thousands of tests is going to make a noticeable improvement to the quality of </span><span class="No-Break"><span class="koboSpan" id="kobo.117.1">our applications.</span></span></p>
<p><span class="koboSpan" id="kobo.118.1">To explain this to our colleagues, we can draw on familiar analogies: just because a strong password cannot prevent every hacker, this does not mean we should not use passwords and leave ourselves vulnerable to any and </span><em class="italic"><span class="koboSpan" id="kobo.119.1">every</span></em><span class="koboSpan" id="kobo.120.1"> hacker. </span><span class="koboSpan" id="kobo.120.2">Staying healthy will not prevent every kind of medical problem but it will prevent many kinds of </span><span class="No-Break"><span class="koboSpan" id="kobo.121.1">serious problems.</span></span></p>
<p><span class="koboSpan" id="kobo.122.1">Ultimately, this is a question of balance. </span><span class="koboSpan" id="kobo.122.2">Zero testing is clearly not enough – every single defect will end up going live in this case. </span><span class="koboSpan" id="kobo.122.3">We know that testing can never eliminate defects. </span><span class="koboSpan" id="kobo.122.4">So, where should we stop? </span><span class="koboSpan" id="kobo.122.5">What constitutes </span><em class="italic"><span class="koboSpan" id="kobo.123.1">enough</span></em><span class="koboSpan" id="kobo.124.1">? </span><span class="koboSpan" id="kobo.124.2">We can argue that TDD helps us decide on this balance at the best possible time: while we are thinking about writing code. </span><span class="koboSpan" id="kobo.124.3">The automated TDD tests we create will save us manual QA time. </span><span class="koboSpan" id="kobo.124.4">It’s manual work that no longer needs to be done. </span><span class="koboSpan" id="kobo.124.5">These time and cost savings compound, repaying us in every single iteration </span><span class="No-Break"><span class="koboSpan" id="kobo.125.1">of code.</span></span></p>
<p><span class="koboSpan" id="kobo.126.1">Now that we understand why testing as much as possible always beats not testing at all, we can look into the next common objection: how do we know the tests themselves were </span><span class="No-Break"><span class="koboSpan" id="kobo.127.1">written correctly?</span></span></p>
<h1 id="_idParaDest-52"><a id="_idTextAnchor061"/><span class="koboSpan" id="kobo.128.1">How do you know the tests are right?</span></h1>
<p><span class="koboSpan" id="kobo.129.1">This is an </span><a id="_idIndexMarker107"/><span class="koboSpan" id="kobo.130.1">objection that has merit, so we need to deeply understand the logic behind it. </span><span class="koboSpan" id="kobo.130.2">This is a common objection from people unfamiliar with writing automated tests, as they misunderstand how we avoid incorrect tests. </span><span class="koboSpan" id="kobo.130.3">By helping them see the safeguards we put in place, we can help them reframe </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">their thinking.</span></span></p>
<h2 id="_idParaDest-53"><a id="_idTextAnchor062"/><span class="koboSpan" id="kobo.132.1">Understanding the concerns behind writing broken tests</span></h2>
<p><span class="koboSpan" id="kobo.133.1">One objection you will hear is, “</span><em class="italic"><span class="koboSpan" id="kobo.134.1">How do we know the tests are right if the tests themselves don’t have tests?</span></em><span class="koboSpan" id="kobo.135.1">” This objection was raised the first time I introduced unit tests to a</span><a id="_idIndexMarker108"/><span class="koboSpan" id="kobo.136.1"> team. </span><span class="koboSpan" id="kobo.136.2">It was polarizing. </span><span class="koboSpan" id="kobo.136.3">Some of the team understood the value right away. </span><span class="koboSpan" id="kobo.136.4">Others were indifferent, but some were actively hostile. </span><span class="koboSpan" id="kobo.136.5">They saw this new practice as suggesting they were somehow deficient. </span><span class="koboSpan" id="kobo.136.6">It was perceived as a threat. </span><span class="koboSpan" id="kobo.136.7">Against that background, one developer pointed out a flaw in the logic I </span><span class="No-Break"><span class="koboSpan" id="kobo.137.1">had explained.</span></span></p>
<p><span class="koboSpan" id="kobo.138.1">I told the team that we could not trust our visual reading of production code. </span><span class="koboSpan" id="kobo.138.2">Yes, we are all skilled at reading code, but we are humans, so we miss things. </span><span class="koboSpan" id="kobo.138.3">Unit tests would help us avoid missing things. </span><span class="koboSpan" id="kobo.138.4">One bright developer asked a great question: if visual inspection does not work for production code, why are we saying that it </span><em class="italic"><span class="koboSpan" id="kobo.139.1">does</span></em><span class="koboSpan" id="kobo.140.1"> work for test code? </span><span class="koboSpan" id="kobo.140.2">What’s the difference between </span><span class="No-Break"><span class="koboSpan" id="kobo.141.1">the two?</span></span></p>
<p><span class="koboSpan" id="kobo.142.1">The right illustration for this came after I needed to test some XML output (which was in 2005, I remember). </span><span class="koboSpan" id="kobo.142.2">The code I had written for checking the XML output was truly complex. </span><span class="koboSpan" id="kobo.142.3">The criticism was correct. </span><span class="koboSpan" id="kobo.142.4">There was no way I could visually inspect that test code and honestly say it was </span><span class="No-Break"><span class="koboSpan" id="kobo.143.1">without defects.</span></span></p>
<p><span class="koboSpan" id="kobo.144.1">So, I applied TDD to the problem. </span><span class="koboSpan" id="kobo.144.2">I used TDD to write a utility class that could compare two XML strings and report either that they were the same or what the first difference was. </span><span class="koboSpan" id="kobo.144.3">It could be configured to ignore the order of XML elements. </span><span class="koboSpan" id="kobo.144.4">I extracted this complex code out of my original test and replaced it with a call to this new utility class. </span><span class="koboSpan" id="kobo.144.5">I knew the utility class did not have any defects, as it passed every TDD test that I had written for it. </span><span class="koboSpan" id="kobo.144.6">There were many tests, covering every happy path and every edge case I cared about. </span><span class="koboSpan" id="kobo.144.7">The original test that had been criticized now became very short </span><span class="No-Break"><span class="koboSpan" id="kobo.145.1">and direct.</span></span></p>
<p><span class="koboSpan" id="kobo.146.1">I asked my colleague who had raised the point to review the code. </span><span class="koboSpan" id="kobo.146.2">They agreed that in this new, simpler form, they were happy to agree that the test was correct, visually. </span><span class="koboSpan" id="kobo.146.3">They added the caveat “</span><em class="italic"><span class="koboSpan" id="kobo.147.1">if the utility class works right</span></em><span class="koboSpan" id="kobo.148.1">.” </span><span class="koboSpan" id="kobo.148.2">Of course, we had the confidence that it passed every TDD test we had written it against. </span><span class="koboSpan" id="kobo.148.3">We were certain that it did all the things we specifically wanted it to do, as proven by tests for </span><span class="No-Break"><span class="koboSpan" id="kobo.149.1">these things.</span></span></p>
<h2 id="_idParaDest-54"><a id="_idTextAnchor063"/><span class="koboSpan" id="kobo.150.1">Providing reassurance that we test our tests</span></h2>
<p><span class="koboSpan" id="kobo.151.1">The essence of this argument is that short, simple code can be visually inspected. </span><span class="koboSpan" id="kobo.151.2">To ensure this, we keep most of our unit tests simple and short enough to reason about. </span><span class="koboSpan" id="kobo.151.3">Where tests get too complex, we extract that complexity into its own code unit. </span><span class="koboSpan" id="kobo.151.4">We develop that using TDD and end up making both the original test code simple enough to inspect and the test utility simple enough for its tests to inspect, a classic example of divide </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">and conquer.</span></span></p>
<p><span class="koboSpan" id="kobo.153.1">Practically, we invite our colleagues to point out where they feel our test code is too complex to trust. </span><span class="koboSpan" id="kobo.153.2">We refactor it to use simple utility classes, these themselves written using simple TDD. </span><span class="koboSpan" id="kobo.153.3">This approach helps us build trust, respects the valid concerns of our colleagues, and shows how we can find ways to reduce all TDD tests to simple, reviewable </span><span class="No-Break"><span class="koboSpan" id="kobo.154.1">code blocks.</span></span></p>
<p><span class="koboSpan" id="kobo.155.1">Now that we have addressed knowing our tests are right, another common objection involves having overconfidence in TDD: that simply following the TDD process will therefore guarantee good code. </span><span class="koboSpan" id="kobo.155.2">Can that be true? </span><span class="koboSpan" id="kobo.155.3">Let’s examine </span><span class="No-Break"><span class="koboSpan" id="kobo.156.1">the arguments.</span></span></p>
<h1 id="_idParaDest-55"><a id="_idTextAnchor064"/><span class="koboSpan" id="kobo.157.1">TDD guarantees good code</span></h1>
<p><span class="koboSpan" id="kobo.158.1">Just as there </span><a id="_idIndexMarker109"/><span class="koboSpan" id="kobo.159.1">are often overly pessimistic objections to TDD, here is an opposite view: TDD </span><em class="italic"><span class="koboSpan" id="kobo.160.1">guarantees</span></em><span class="koboSpan" id="kobo.161.1"> good code. </span><span class="koboSpan" id="kobo.161.2">As TDD is a process, and it claims to improve code, it is quite reasonable to assume that using TDD is all you need to guarantee good code. </span><span class="koboSpan" id="kobo.161.3">Unfortunately, that is not at all correct. </span><span class="koboSpan" id="kobo.161.4">TDD helps developers write good code and it helps as feedback to show us where we have made mistakes in design and logic. </span><span class="koboSpan" id="kobo.161.5">It cannot guarantee good </span><span class="No-Break"><span class="koboSpan" id="kobo.162.1">code, however.</span></span></p>
<h2 id="_idParaDest-56"><a id="_idTextAnchor065"/><span class="koboSpan" id="kobo.163.1">Understanding problem-inflated expectations</span></h2>
<p><span class="koboSpan" id="kobo.164.1">The issue here is a </span><a id="_idIndexMarker110"/><span class="koboSpan" id="kobo.165.1">misunderstanding. </span><span class="koboSpan" id="kobo.165.2">TDD is not a set of techniques that directly affect your design decisions. </span><span class="koboSpan" id="kobo.165.3">It is a set of techniques that help you specify what you expect a piece of code to do, when, under what conditions, and given a particular design. </span><span class="koboSpan" id="kobo.165.4">It leaves you free to choose that design, what you expect it to do, and how you are going to implement </span><span class="No-Break"><span class="koboSpan" id="kobo.166.1">that code.</span></span></p>
<p><span class="koboSpan" id="kobo.167.1">TDD has no suggestions regarding choosing a long variable name over a short one. </span><span class="koboSpan" id="kobo.167.2">It does not tell you whether you should choose an interface or an abstract class. </span><span class="koboSpan" id="kobo.167.3">Should you choose to split a feature over two classes or five? </span><span class="koboSpan" id="kobo.167.4">TDD has no advice there. </span><span class="koboSpan" id="kobo.167.5">Should you eliminate duplicated code? </span><span class="koboSpan" id="kobo.167.6">Invert a dependency? </span><span class="koboSpan" id="kobo.167.7">Connect to a database? </span><span class="koboSpan" id="kobo.167.8">Only you can decide. </span><span class="koboSpan" id="kobo.167.9">TDD offers no advice. </span><span class="koboSpan" id="kobo.167.10">It is not intelligent. </span><em class="italic"><span class="koboSpan" id="kobo.168.1">It cannot replace you and your expertise.</span></em><span class="koboSpan" id="kobo.169.1"> It is a simple process, enabling you to validate your assumptions </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">and ideas.</span></span></p>
<h2 id="_idParaDest-57"><a id="_idTextAnchor066"/><span class="koboSpan" id="kobo.171.1">Managing your expectations of TDD</span></h2>
<p><span class="koboSpan" id="kobo.172.1">TDD is hugely beneficial in my</span><a id="_idIndexMarker111"/><span class="koboSpan" id="kobo.173.1"> view but we must regard it in context. </span><span class="koboSpan" id="kobo.173.2">It provides instant feedback on our decisions but leaves every important software design decision </span><span class="No-Break"><span class="koboSpan" id="kobo.174.1">to us.</span></span></p>
<p><span class="koboSpan" id="kobo.175.1">Using TDD, we are free to write code using the </span><strong class="bold"><span class="koboSpan" id="kobo.176.1">SOLID</span></strong><span class="koboSpan" id="kobo.177.1"> principles (which will be covered in </span><a href="B18384_07.xhtml#_idTextAnchor128"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.178.1">Chapter 7</span></em></span></a><span class="koboSpan" id="kobo.179.1">, </span><em class="italic"><span class="koboSpan" id="kobo.180.1">Driving Design  — TDD and SOLID</span></em><span class="koboSpan" id="kobo.181.1">, of this book) or we can use a procedural approach, an object-oriented </span><a id="_idIndexMarker112"/><span class="koboSpan" id="kobo.182.1">approach, or a functional approach. </span><span class="koboSpan" id="kobo.182.2">TDD allows us to choose our algorithm as we see fit. </span><span class="koboSpan" id="kobo.182.3">It enables us to change our minds about how something should be implemented. </span><span class="koboSpan" id="kobo.182.4">TDD works across every programming language. </span><span class="koboSpan" id="kobo.182.5">It works across </span><span class="No-Break"><span class="koboSpan" id="kobo.183.1">every vertical.</span></span></p>
<p><span class="koboSpan" id="kobo.184.1">Helping our colleagues see past this objection helps them realize that TDD is not some magic system that replaces the intelligence and skill of the programmer. </span><span class="koboSpan" id="kobo.184.2">It harnesses this skill by providing instant feedback on our decisions. </span><span class="koboSpan" id="kobo.184.3">While this may disappoint colleagues who hoped it would allow perfect code to come from imperfect thinking, we can point out that TDD gives us time to think. </span><span class="koboSpan" id="kobo.184.4">The advantage is that it puts thinking and design up front and central. </span><span class="koboSpan" id="kobo.184.5">By writing a failing test before writing the production code that makes the test pass, we have ensured that we have thought about what that code should do and how it should be used. </span><span class="koboSpan" id="kobo.184.6">That’s a </span><span class="No-Break"><span class="koboSpan" id="kobo.185.1">great advantage.</span></span></p>
<p><span class="koboSpan" id="kobo.186.1">Given that we understand that TDD does not design our code for us, yet is still a developer’s friend, how can we approach testing </span><span class="No-Break"><span class="koboSpan" id="kobo.187.1">complex code?</span></span></p>
<h1 id="_idParaDest-58"><a id="_idTextAnchor067"/><span class="koboSpan" id="kobo.188.1">Our code is too complex to test</span></h1>
<p><span class="koboSpan" id="kobo.189.1">Professional</span><a id="_idIndexMarker113"/><span class="koboSpan" id="kobo.190.1"> developers routinely deal with highly complex code. </span><span class="koboSpan" id="kobo.190.2">That’s just a fact of life. </span><span class="koboSpan" id="kobo.190.3">It leads to one valid objection: our code is too difficult to write unit tests for. </span><span class="koboSpan" id="kobo.190.4">The code we work on might be highly valuable, trusted legacy code that brings in significant top-line revenue. </span><span class="koboSpan" id="kobo.190.5">This code may be complex. </span><span class="koboSpan" id="kobo.190.6">But is it </span><em class="italic"><span class="koboSpan" id="kobo.191.1">too</span></em><span class="koboSpan" id="kobo.192.1"> complex to test? </span><span class="koboSpan" id="kobo.192.2">Is it true to say that every piece of complex code simply cannot </span><span class="No-Break"><span class="koboSpan" id="kobo.193.1">be tested?</span></span></p>
<h2 id="_idParaDest-59"><a id="_idTextAnchor068"/><span class="koboSpan" id="kobo.194.1">Understanding the causes of untestable code</span></h2>
<p><span class="koboSpan" id="kobo.195.1">The answer lies in the three ways that </span><a id="_idIndexMarker114"/><span class="koboSpan" id="kobo.196.1">code becomes complex and hard </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">to test:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.198.1">Accidental complexity: We chose a hard way over a simpler way </span><span class="No-Break"><span class="koboSpan" id="kobo.199.1">by accident</span></span></li>
<li><span class="koboSpan" id="kobo.200.1">External systems cannot be controlled to set up for </span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">our tests</span></span></li>
<li><span class="koboSpan" id="kobo.202.1">The code is so entangled that we no longer </span><span class="No-Break"><span class="koboSpan" id="kobo.203.1">understand it</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.204.1">Accidental complexity makes code hard to read and hard to test. </span><span class="koboSpan" id="kobo.204.2">The best way to think about this is to know that any given problem has many valid solutions. </span><span class="koboSpan" id="kobo.204.3">Say we want to add a total of five numbers. </span><span class="koboSpan" id="kobo.204.4">We could write a loop. </span><span class="koboSpan" id="kobo.204.5">We could create five concurrent tasks that take each number, then report that number to another concurrent task that computes the total (bear with me, please… I’ve seen this happen). </span><span class="koboSpan" id="kobo.204.6">We could have a complex design pattern-based system that has each number trigger an observer, which places each one in a collection, which triggers an observer to add to the total, which triggers an observer every 10 seconds after the </span><span class="No-Break"><span class="koboSpan" id="kobo.205.1">last input.</span></span></p>
<p><span class="koboSpan" id="kobo.206.1">Yes, I know some of those are silly. </span><span class="koboSpan" id="kobo.206.2">I just made them up. </span><span class="koboSpan" id="kobo.206.3">But let’s be honest – what kinds of silly designs have you worked on before? </span><span class="koboSpan" id="kobo.206.4">I know I have written code that was more complex than it needed </span><span class="No-Break"><span class="koboSpan" id="kobo.207.1">to be.</span></span></p>
<p><span class="koboSpan" id="kobo.208.1">The key point of the addition of five numbers example is that it really should use a simple loop. </span><span class="koboSpan" id="kobo.208.2">Anything else is accidental complexity, neither necessary nor intentional. </span><span class="koboSpan" id="kobo.208.3">Why would we do that? </span><span class="koboSpan" id="kobo.208.4">There are many reasons. </span><span class="koboSpan" id="kobo.208.5">There may be some project constraints, a management directive, or simply a personal preference that steers our decision. </span><span class="koboSpan" id="kobo.208.6">However it happened, a simpler solution was possible, yet we did not </span><span class="No-Break"><span class="koboSpan" id="kobo.209.1">take it.</span></span></p>
<p><span class="koboSpan" id="kobo.210.1">Testing more complex solutions generally requires more complex tests. </span><span class="koboSpan" id="kobo.210.2">Sometimes, our team thinks it is not worth spending time on that. </span><span class="koboSpan" id="kobo.210.3">The code is complex, it will be hard to write tests for, and we think it works already. </span><span class="koboSpan" id="kobo.210.4">We think it is best not to </span><span class="No-Break"><span class="koboSpan" id="kobo.211.1">touch it.</span></span></p>
<p><span class="koboSpan" id="kobo.212.1">External systems cause problems in testing. </span><span class="koboSpan" id="kobo.212.2">Suppose our code talks to a third-party web service. </span><span class="koboSpan" id="kobo.212.3">It is hard to write a repeatable test for that. </span><span class="koboSpan" id="kobo.212.4">Our code consumes the external service and the data it sends to us is different each time. </span><span class="koboSpan" id="kobo.212.5">We cannot write a test and verify what the service sent us, as we do not know what the service should be sending to us. </span><span class="koboSpan" id="kobo.212.6">If we could replace that external service with some dummy service that we could control, then we could fix this problem easily. </span><span class="koboSpan" id="kobo.212.7">But if our code does not permit that, then we </span><span class="No-Break"><span class="koboSpan" id="kobo.213.1">are stuck.</span></span></p>
<p><span class="koboSpan" id="kobo.214.1">Entangled code is a further </span><a id="_idIndexMarker115"/><span class="koboSpan" id="kobo.215.1">development of this. </span><span class="koboSpan" id="kobo.215.2">To write a test, we need to understand what that code does to an input condition: what do we expect the outputs to be? </span><span class="koboSpan" id="kobo.215.3">If we have a body of code that we simply do not understand, then we cannot write a test </span><span class="No-Break"><span class="koboSpan" id="kobo.216.1">for it.</span></span></p>
<p><span class="koboSpan" id="kobo.217.1">While these three problems are real, there is one underlying cause to them all: we allowed our software to get into this state. </span><span class="koboSpan" id="kobo.217.2">We could have arranged it to only use simple algorithms and data structures. </span><span class="koboSpan" id="kobo.217.3">We could have isolated external systems so that we could test the rest of the code without them. </span><span class="koboSpan" id="kobo.217.4">We could have modularized our code so that it was not </span><span class="No-Break"><span class="koboSpan" id="kobo.218.1">overly </span></span><span class="No-Break"><a id="_idIndexMarker116"/></span><span class="No-Break"><span class="koboSpan" id="kobo.219.1">entangled.</span></span></p>
<p><span class="koboSpan" id="kobo.220.1">However, how can we persuade our teams with </span><span class="No-Break"><span class="koboSpan" id="kobo.221.1">these ideas?</span></span></p>
<h2 id="_idParaDest-60"><a id="_idTextAnchor069"/><span class="koboSpan" id="kobo.222.1">Reframing the relationship between good design and simple tests</span></h2>
<p><span class="koboSpan" id="kobo.223.1">All the preceding problems relate to making software that works yet does not follow good design practices. </span><span class="koboSpan" id="kobo.223.2">The most effective way to change this, in my experience, is </span><strong class="bold"><span class="koboSpan" id="kobo.224.1">pair programming</span></strong><span class="koboSpan" id="kobo.225.1"> – working</span><a id="_idIndexMarker117"/><span class="koboSpan" id="kobo.226.1"> together on the same piece of code and helping each other find these better design ideas. </span><span class="koboSpan" id="kobo.226.2">If pair programming is not an option, then code reviews also provide a checkpoint to introduce better designs. </span><span class="koboSpan" id="kobo.226.3">Pairing is better as by the time you get to code review, it can be too late to make major changes. </span><span class="koboSpan" id="kobo.226.4">It’s cheaper, better, and faster to prevent poor design than it is to </span><span class="No-Break"><span class="koboSpan" id="kobo.227.1">correct it.</span></span></p>
<h2 id="_idParaDest-61"><a id="_idTextAnchor070"/><span class="koboSpan" id="kobo.228.1">Managing legacy code without tests</span></h2>
<p><span class="koboSpan" id="kobo.229.1">We will encounter legacy code </span><a id="_idIndexMarker118"/><span class="koboSpan" id="kobo.230.1">without tests that we need to maintain. </span><span class="koboSpan" id="kobo.230.2">Often, this code has grown to be quite unmanageable and ideally needs replacing, except that nobody knows what it does anymore. </span><span class="koboSpan" id="kobo.230.3">There may be no written documentation or specification to help us understand it. </span><span class="koboSpan" id="kobo.230.4">Whatever written material there is may be completely outdated and unhelpful. </span><span class="koboSpan" id="kobo.230.5">The original authors of the code may have moved on to a different team or </span><span class="No-Break"><span class="koboSpan" id="kobo.231.1">different company.</span></span></p>
<p><span class="koboSpan" id="kobo.232.1">The best advice here is to simply leave this code alone if possible. </span><span class="koboSpan" id="kobo.232.2">Sometimes though, we need to add features that require that code to be changed. </span><span class="koboSpan" id="kobo.232.3">Given that we have no existing tests, it is quite likely we will find that adding a new test is all but impossible. </span><span class="koboSpan" id="kobo.232.4">The code simply is not split up in a way that gives us access points to hang a </span><span class="No-Break"><span class="koboSpan" id="kobo.233.1">test off.</span></span></p>
<p><span class="koboSpan" id="kobo.234.1">In this case, we can use</span><a id="_idIndexMarker119"/><span class="koboSpan" id="kobo.235.1"> the </span><strong class="bold"><span class="koboSpan" id="kobo.236.1">Characterization Test</span></strong><span class="koboSpan" id="kobo.237.1"> technique. </span><span class="koboSpan" id="kobo.237.2">We can describe this in </span><span class="No-Break"><span class="koboSpan" id="kobo.238.1">three steps:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.239.1">Run the legacy code, supplying it with every possible combination </span><span class="No-Break"><span class="koboSpan" id="kobo.240.1">of inputs.</span></span></li>
<li><span class="koboSpan" id="kobo.241.1">Record all the outputs that result from each one of these input runs. </span><span class="koboSpan" id="kobo.241.2">This output is traditionally called the </span><span class="No-Break"><span class="koboSpan" id="kobo.242.1">Golden Master.</span></span></li>
<li><span class="koboSpan" id="kobo.243.1">Write a Characterization Test that runs the code with all inputs again. </span><span class="koboSpan" id="kobo.243.2">Compare every output against the captured Golden Master. </span><span class="koboSpan" id="kobo.243.3">The test fails if any </span><span class="No-Break"><span class="koboSpan" id="kobo.244.1">are different.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.245.1">This automated test compares any changes that we have made to the code against what the original code did. </span><span class="koboSpan" id="kobo.245.2">This will guide us as we refactor the legacy code. </span><span class="koboSpan" id="kobo.245.3">We can use standard refactoring techniques combined with TDD. </span><span class="koboSpan" id="kobo.245.4">By preserving the defective outputs in the Golden Master, we ensure that we are purely refactoring in this step. </span><span class="koboSpan" id="kobo.245.5">We avoid the trap of restructuring the code at the same time as fixing the bugs. </span><span class="koboSpan" id="kobo.245.6">When bugs are present in the original code, we work in two distinct phases: first, refactor the code without changing observable behavior. </span><span class="koboSpan" id="kobo.245.7">Afterwards, fix the defects as a separate task. </span><span class="koboSpan" id="kobo.245.8">We never fix bugs and refactor together. </span><span class="koboSpan" id="kobo.245.9">The Characterization Test ensures we do not accidentally conflate the </span><span class="No-Break"><span class="koboSpan" id="kobo.246.1">two tasks.</span></span></p>
<p><span class="koboSpan" id="kobo.247.1">We’ve seen how </span><a id="_idIndexMarker120"/><span class="koboSpan" id="kobo.248.1">TDD helps tackle accidental complexity and the difficulty of changing legacy code. </span><span class="koboSpan" id="kobo.248.2">Surely writing a test before production code means we need to know what the code looks like before we test it though? </span><span class="koboSpan" id="kobo.248.3">Let’s review this common </span><span class="No-Break"><span class="koboSpan" id="kobo.249.1">objection next.</span></span></p>
<h1 id="_idParaDest-62"><a id="_idTextAnchor071"/><span class="koboSpan" id="kobo.250.1">I don’t know what to test until I write the code</span></h1>
<p><span class="koboSpan" id="kobo.251.1">A great </span><a id="_idIndexMarker121"/><span class="koboSpan" id="kobo.252.1">frustration for TDD learners is knowing what to test without having written the production code beforehand. </span><span class="koboSpan" id="kobo.252.2">This is another criticism that has merit. </span><span class="koboSpan" id="kobo.252.3">In this case, once we understand the issue that developers face, we can see that the solution is a technique we can apply to our workflow, not a reframing </span><span class="No-Break"><span class="koboSpan" id="kobo.253.1">of thinking.</span></span></p>
<h2 id="_idParaDest-63"><a id="_idTextAnchor072"/><span class="koboSpan" id="kobo.254.1">Understanding the difficulty of starting with testing</span></h2>
<p><span class="koboSpan" id="kobo.255.1">To an extent, it’s natural to think about how we implement code. </span><span class="koboSpan" id="kobo.255.2">It’s how we learn, after all. </span><span class="koboSpan" id="kobo.255.3">We write </span><strong class="source-inline"><span class="koboSpan" id="kobo.256.1">System.out.println("Hello, World!");</span></strong><span class="koboSpan" id="kobo.257.1"> instead of thinking up some structure to place around the famous line. </span><span class="koboSpan" id="kobo.257.2">Small programs and utilities work just fine when we write them as linear code, similar to a shopping list </span><span class="No-Break"><span class="koboSpan" id="kobo.258.1">of instructions.</span></span></p>
<p><span class="koboSpan" id="kobo.259.1">We begin to face difficulties as programs get larger. </span><span class="koboSpan" id="kobo.259.2">We need help organizing the code into understandable chunks. </span><span class="koboSpan" id="kobo.259.3">These chunks need to be easy to understand. </span><span class="koboSpan" id="kobo.259.4">We want them to be self-documenting and it to be easy for us to know how to call them. </span><span class="koboSpan" id="kobo.259.5">The larger the code gets, the less interesting the insides of these chunks are, and the more important the external structure of these chunks – the </span><em class="italic"><span class="koboSpan" id="kobo.260.1">outsides</span></em><span class="koboSpan" id="kobo.261.1"> – </span><span class="No-Break"><span class="koboSpan" id="kobo.262.1">becomes.</span></span></p>
<p><span class="koboSpan" id="kobo.263.1">As an example, let’s say we are writing a </span><strong class="source-inline"><span class="koboSpan" id="kobo.264.1">TextEditorWidget</span></strong><span class="koboSpan" id="kobo.265.1"> class, and we want to check the spelling on the fly. </span><span class="koboSpan" id="kobo.265.2">We find a library with a </span><strong class="source-inline"><span class="koboSpan" id="kobo.266.1">SpellCheck</span></strong><span class="koboSpan" id="kobo.267.1"> class in it. </span><span class="koboSpan" id="kobo.267.2">We don’t care that much about how the </span><strong class="source-inline"><span class="koboSpan" id="kobo.268.1">SpellCheck</span></strong><span class="koboSpan" id="kobo.269.1"> class works. </span><span class="koboSpan" id="kobo.269.2">We only care about how we can </span><em class="italic"><span class="koboSpan" id="kobo.270.1">use</span></em><span class="koboSpan" id="kobo.271.1"> this class to check the spelling. </span><span class="koboSpan" id="kobo.271.2">We want to know how to create an object of that class, what methods we need to call to get it to do its spellchecking job, and how we can access </span><span class="No-Break"><span class="koboSpan" id="kobo.272.1">the output.</span></span></p>
<p><span class="koboSpan" id="kobo.273.1">This kind of thinking is the definition of software design – how components fit together. </span><span class="koboSpan" id="kobo.273.2">It is critical that we emphasize design as code bases grow if we want to maintain them. </span><span class="koboSpan" id="kobo.273.3">We use encapsulation to hide the details of data structures and algorithms inside our functions and classes. </span><span class="koboSpan" id="kobo.273.4">We provide a simple-to-use </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">programming interface.</span></span></p>
<h2 id="_idParaDest-64"><a id="_idTextAnchor073"/><span class="koboSpan" id="kobo.275.1">Overcoming the need to write production code first</span></h2>
<p><span class="koboSpan" id="kobo.276.1">TDD </span><a id="_idIndexMarker122"/><span class="koboSpan" id="kobo.277.1">scaffolds design decisions. </span><span class="koboSpan" id="kobo.277.2">By writing the test before the production code, we are defining how we want the code under test to be created, called, and used. </span><span class="koboSpan" id="kobo.277.3">This helps us see very quickly how well our decisions are working out. </span><span class="koboSpan" id="kobo.277.4">If the test shows that creating our object is hard, that shows us that our design should simplify the creation step. </span><span class="koboSpan" id="kobo.277.5">The same applies if the object is difficult to use; we should simplify our programming interface as </span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">a result.</span></span></p>
<p><span class="koboSpan" id="kobo.279.1">However, how do we cope with the times when we simply do not yet know what a reasonable design should be? </span><span class="koboSpan" id="kobo.279.2">This situation is common when we either use a new library, integrate with some new code from the rest of our team, or tackle a large </span><span class="No-Break"><span class="koboSpan" id="kobo.280.1">user story.</span></span></p>
<p><span class="koboSpan" id="kobo.281.1">To solve this, we use a </span><strong class="bold"><span class="koboSpan" id="kobo.282.1">spike</span></strong><span class="koboSpan" id="kobo.283.1">, a short</span><a id="_idIndexMarker123"/><span class="koboSpan" id="kobo.284.1"> section of code that is sufficient to prove the shape of a design. </span><span class="koboSpan" id="kobo.284.2">We don’t aim for the cleanest code at this stage. </span><span class="koboSpan" id="kobo.284.3">We do not cover many edge cases or error conditions. </span><span class="koboSpan" id="kobo.284.4">We have the specific and limited goal of exploring a possible arrangement of objects and functions to make a credible design. </span><span class="koboSpan" id="kobo.284.5">As soon as we have that, we sketch out some notes on the design and then delete it. </span><span class="koboSpan" id="kobo.284.6">Now that we know what a reasonable design looks like, we are better placed to know what tests to write. </span><span class="koboSpan" id="kobo.284.7">We can now use normal TDD to drive </span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">our design.</span></span></p>
<p><span class="koboSpan" id="kobo.286.1">Interestingly, when we start over in this way, we often end up driving out a better design than our spike. </span><span class="koboSpan" id="kobo.286.2">The feedback loop of TDD helps us spot new approaches </span><span class="No-Break"><span class="koboSpan" id="kobo.287.1">and improvements.</span></span></p>
<p><span class="koboSpan" id="kobo.288.1">We’ve seen how natural it is to want to start implementing code before tests, and how we can use TDD and spikes to create a better process. </span><span class="koboSpan" id="kobo.288.2">We make decisions at the </span><strong class="bold"><span class="koboSpan" id="kobo.289.1">last responsible moment</span></strong><span class="koboSpan" id="kobo.290.1"> – the latest possible time to decide before we are knowingly making an irreversible, inferior decision. </span><span class="koboSpan" id="kobo.290.2">When in doubt, we can learn more about the solution space by </span><a id="_idIndexMarker124"/><span class="koboSpan" id="kobo.291.1">using a </span><strong class="bold"><span class="koboSpan" id="kobo.292.1">spike</span></strong><span class="koboSpan" id="kobo.293.1"> – a short piece of experimental code designed to learn from and then </span><span class="No-Break"><span class="koboSpan" id="kobo.294.1">throw away.</span></span></p>
<h1 id="_idParaDest-65"><a id="_idTextAnchor074"/><span class="koboSpan" id="kobo.295.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.296.1">In this chapter, we’ve learned six common myths that prevent teams from using TDD and discussed the right approach to reframing those conversations. </span><span class="koboSpan" id="kobo.296.2">TDD really deserves a much wider application in modern software development than it has now. </span><span class="koboSpan" id="kobo.296.3">It’s not that the techniques don’t work. </span><span class="koboSpan" id="kobo.296.4">TDD simply has an image problem, often among people who haven’t experienced its </span><span class="No-Break"><span class="koboSpan" id="kobo.297.1">true power.</span></span></p>
<p><span class="koboSpan" id="kobo.298.1">In the second part of this book, we will start to put the various rhythms and techniques of TDD into practice and build out a small web application. </span><span class="koboSpan" id="kobo.298.2">In the next chapter, we will start our TDD journey with the basics of writing a unit test with the </span><strong class="bold"><span class="koboSpan" id="kobo.299.1">Arrange-Act-Assert</span></strong><span class="koboSpan" id="kobo.300.1"> (</span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.301.1">AAA</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.302.1">) </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.303.1">pattern</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.304.1">.</span></span></p>
<h1 id="_idParaDest-66"><a id="_idTextAnchor075"/><span class="koboSpan" id="kobo.305.1">Questions and answers</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.306.1">Why is it believed that TDD slows </span><span class="No-Break"><span class="koboSpan" id="kobo.307.1">developers down?</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.308.1">When we don’t write a test, we save the time spent writing the test. </span><span class="koboSpan" id="kobo.308.2">What this fails to consider is the extra time costs of finding, reproducing, and fixing a defect </span><span class="No-Break"><span class="koboSpan" id="kobo.309.1">in production.</span></span></p>
<ol>
<li value="2"><span class="koboSpan" id="kobo.310.1">Does TDD eliminate human </span><span class="No-Break"><span class="koboSpan" id="kobo.311.1">design contributions?</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.312.1">No. </span><span class="koboSpan" id="kobo.312.2">Quite the opposite. </span><span class="koboSpan" id="kobo.312.3">We still design our code using every design technique at our disposal. </span><span class="koboSpan" id="kobo.312.4">What TDD gives us is a fast feedback loop on whether our design choices have resulted in easy-to-use, </span><span class="No-Break"><span class="koboSpan" id="kobo.313.1">correct code.</span></span></p>
<ol>
<li value="3"><span class="koboSpan" id="kobo.314.1">Why doesn’t my project team </span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">use TDD?</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.316.1">What a fantastic question to ask them! </span><span class="koboSpan" id="kobo.316.2">Seriously. </span><span class="koboSpan" id="kobo.316.3">See whether any of their objections have been covered by this chapter. </span><span class="koboSpan" id="kobo.316.4">If so, you can gently lead the conversation using the </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">ideas presented.</span></span></p>
<h1 id="_idParaDest-67"><a id="_idTextAnchor076"/><span class="koboSpan" id="kobo.318.1">Further reading</span></h1>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Characterization_test"><span class="No-Break"><span class="koboSpan" id="kobo.319.1">https://en.wikipedia.org/wiki/Characterization_test</span></span></a></li>
</ul>
<p><span class="koboSpan" id="kobo.320.1">More detail on the Characterization Test technique, where we capture the output of an existing software module exactly as-is, with a view to restructuring the code without changing any of its behavior. </span><span class="koboSpan" id="kobo.320.2">This is especially valuable in older code where the original requirements have become unclear, or that has evolved over the years to contain defects that other systems now </span><span class="No-Break"><span class="koboSpan" id="kobo.321.1">rely on.</span></span></p>
<ul>
<li><a href="https://effectivesoftwaredesign.com/2014/03/27/lean-software-development-before-and-after-the-last-responsible-moment/"><span class="No-Break"><span class="koboSpan" id="kobo.322.1">https://effectivesoftwaredesign.com/2014/03/27/lean-software-development-before-and-after-the-last-responsible-moment/</span></span></a></li>
</ul>
<p><span class="koboSpan" id="kobo.323.1">An in-depth look at what deciding at the last responsible moment means for </span><span class="No-Break"><span class="koboSpan" id="kobo.324.1">software design.</span></span></p>
</div>
<div>
<div id="_idContainer020">
</div>
</div>


<div class="Content" id="_idContainer021">
<h1 id="_idParaDest-68"><a id="_idTextAnchor077"/><span class="koboSpan" id="kobo.1.1">Part 2: </span><span lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.2.1">TDD Techniques</span></span></h1>
</div>
<div id="_idContainer022">
<p><em class="italic"><span class="koboSpan" id="kobo.3.1">Part 2</span></em><span class="koboSpan" id="kobo.4.1"> introduces the techniques necessary for effective TDD. </span><span class="koboSpan" id="kobo.4.2">Along the way, we will incrementally build the core logic of a word guessing game, Wordz – writing all our </span><span class="No-Break"><span class="koboSpan" id="kobo.5.1">tests first.</span></span></p>
<p><span class="koboSpan" id="kobo.6.1">By the end of this part, we will have produced high-quality code by writing tests first. </span><span class="koboSpan" id="kobo.6.2">The SOLID principles and hexagonal architecture will help us organize code into well-engineered building blocks that are easy to test. </span><span class="koboSpan" id="kobo.6.3">Test doubles will bring external dependencies under our control. </span><span class="koboSpan" id="kobo.6.4">We will look at the bigger picture of test automation and how the test pyramid, QA engineers, and workflow improve </span><span class="No-Break"><span class="koboSpan" id="kobo.7.1">our work.</span></span></p>
<p><span class="koboSpan" id="kobo.8.1">This part has the </span><span class="No-Break"><span class="koboSpan" id="kobo.9.1">following chapters:</span></span></p>
<ul>
<li><a href="B18384_04.xhtml#_idTextAnchor078"><em class="italic"><span class="koboSpan" id="kobo.10.1">Chapter 4</span></em></a><span class="koboSpan" id="kobo.11.1">, </span><em class="italic"><span class="koboSpan" id="kobo.12.1">Building an Application Using TDD</span></em></li>
<li><a href="B18384_05.xhtml#_idTextAnchor092"><em class="italic"><span class="koboSpan" id="kobo.13.1">Chapter 5</span></em></a><span class="koboSpan" id="kobo.14.1">, </span><em class="italic"><span class="koboSpan" id="kobo.15.1">Writing Our First Test</span></em></li>
<li><a href="B18384_06.xhtml#_idTextAnchor117"><em class="italic"><span class="koboSpan" id="kobo.16.1">Chapter 6</span></em></a><span class="koboSpan" id="kobo.17.1">, </span><em class="italic"><span class="koboSpan" id="kobo.18.1">Following the Rhythms of TDD</span></em></li>
<li><a href="B18384_07.xhtml#_idTextAnchor128"><em class="italic"><span class="koboSpan" id="kobo.19.1">Chapter 7</span></em></a><span class="koboSpan" id="kobo.20.1">, </span><em class="italic"><span class="koboSpan" id="kobo.21.1">Driving Design – TDD and SOLID</span></em></li>
<li><a href="B18384_08.xhtml#_idTextAnchor149"><em class="italic"><span class="koboSpan" id="kobo.22.1">Chapter 8</span></em></a><span class="koboSpan" id="kobo.23.1">, </span><em class="italic"><span class="koboSpan" id="kobo.24.1">Test Doubles – Stubs and Mocks</span></em></li>
<li><a href="B18384_09.xhtml#_idTextAnchor179"><em class="italic"><span class="koboSpan" id="kobo.25.1">Chapter 9</span></em></a><span class="koboSpan" id="kobo.26.1">, </span><em class="italic"><span class="koboSpan" id="kobo.27.1">Hexagonal Architecture – Decoupling External Systems</span></em></li>
<li><a href="B18384_10.xhtml#_idTextAnchor209"><em class="italic"><span class="koboSpan" id="kobo.28.1">Chapter 10</span></em></a><span class="koboSpan" id="kobo.29.1">, </span><em class="italic"><span class="koboSpan" id="kobo.30.1">FIRST Tests and the Test Pyramid</span></em></li>
<li><a href="B18384_11.xhtml#_idTextAnchor234"><em class="italic"><span class="koboSpan" id="kobo.31.1">Chapter 11</span></em></a><span class="koboSpan" id="kobo.32.1">, </span><em class="italic"><span class="koboSpan" id="kobo.33.1">How TDD Fits into Quality Assurance</span></em></li>
<li><a href="B18384_12.xhtml#_idTextAnchor249"><em class="italic"><span class="koboSpan" id="kobo.34.1">Chapter 12</span></em></a><span class="koboSpan" id="kobo.35.1">, </span><em class="italic"><span class="koboSpan" id="kobo.36.1">Test First, Test Later, Test Never</span></em></li>
</ul>
</div>
<div>
<div id="_idContainer023">
</div>
</div>
<div>
<div id="_idContainer024">
</div>
</div>
</body></html>