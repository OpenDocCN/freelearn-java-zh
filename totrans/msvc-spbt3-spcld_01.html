<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer038" class="Basic-Text-Frame">
    <h1 class="chapterNumber">1</h1>
    <h1 id="_idParaDest-14" class="chapterTitle">Introduction to Microservices</h1>
    <p class="normal">This book does not blindly praise microservices. Instead, it’s about how we can use their benefits while being able to handle the challenges of building scalable, resilient, and manageable microservices.</p>
    <p class="normal">As an introduction to this book, the following topics will be covered in this chapter:</p>
    <ul>
      <li class="bulletList">My way into microservices</li>
      <li class="bulletList">What is a microservice-based architecture?</li>
      <li class="bulletList">Challenges with microservices</li>
      <li class="bulletList">Design patterns for handling challenges</li>
      <li class="bulletList">Software enablers that can help us handle these challenges</li>
      <li class="bulletList">Other important considerations that aren’t covered in this book</li>
    </ul>
    <h1 id="_idParaDest-15" class="heading-1">Technical requirements</h1>
    <p class="normal">No installations are required for this chapter. However, you may be interested in taking a look at the C4 model conventions, <a href="https://c4model.com"><span class="url">https://c4model.com</span></a>, since the illustrations in this chapter are inspired by the C4 model.</p>
    <p class="normal">This chapter does not contain any source code.</p>
    <h1 id="_idParaDest-16" class="heading-1">My way into microservices</h1>
    <p class="normal">When I first learned <a id="_idIndexMarker000"/>about the concept of microservices back in 2014, I realized that I had been developing microservices (well, kind of) for a number of years without knowing it was microservices I was dealing with. I was involved in a project that started in 2009 where we developed a platform based on a set of separated features. The platform was delivered to a number of customers that deployed it on-premises. To make it easy for customers to pick and choose what features they wanted to use from the platform, each feature was developed <a id="_idIndexMarker001"/>as an <strong class="keyWord">autonomous software component</strong>; that is, it had its<a id="_idIndexMarker002"/> own persistent data and only communicated with other components using well-defined APIs.</p>
    <p class="normal">Since I can’t discuss specific features in this project’s platform, I have generalized the names of the components, which are labeled from <strong class="keyWord">Component A</strong> to <strong class="keyWord">Component F</strong>. The <strong class="keyWord">composition</strong> of the platform as a set of components is illustrated as follows:</p>
    <figure class="mediaobject"><img src="../Images/B19825_01.png" alt="Diagram  Description automatically generated" width="668" height="241"/></figure>
    <p class="packt_figref">Figure 1.1: The composition of the platform</p>
    <p class="normal">From the illustration, we can also see that each component has its own storage for persistent data, and is not sharing databases with other components.</p>
    <p class="normal">Each component is developed using Java and the Spring Framework, packaged as a WAR file, and deployed as a web app in a Java EE web container, for example, Apache Tomcat. Depending on the customer’s specific requirements, the platform can be deployed on single or multiple servers. A two-node deployment may look as follows:</p>
    <figure class="mediaobject"><img src="../Images/B19825_02.png" alt="Diagram  Description automatically generated" width="848" height="384"/></figure>
    <p class="packt_figref">Figure 1.2: A two-node deployment scenario</p>
    <h2 id="_idParaDest-17" class="heading-2">Benefits of autonomous software components</h2>
    <p class="normal">From this project, I <a id="_idIndexMarker003"/>learned that decomposing the platform’s functionality into a set of autonomous software components provides a number of benefits:</p>
    <ul>
      <li class="bulletList">A customer can deploy parts of the platform in its own system landscape, integrating it with its existing systems using its well-defined APIs.
      <p class="normal">The following is an example where one customer decided to deploy <strong class="keyWord">Component A</strong>, <strong class="keyWord">Component B</strong>, <strong class="keyWord">Component D</strong>, and <strong class="keyWord">Component E</strong> from the platform and integrate them with two existing systems in the customer’s system landscape, <strong class="keyWord">System A</strong> and <strong class="keyWord">System B</strong>:</p>
    </li></ul>
    <figure class="mediaobject"><img src="../Images/B19825_03.png" alt="Diagram  Description automatically generated" width="567" height="610"/></figure>
    <p class="packt_figref">Figure 1.3: Partial deployment of the platform</p>
    <ul>
      <li class="bulletList">Another<a id="_idIndexMarker004"/> customer could choose to replace parts of the platform’s functionality with implementations that already exist in the customer’s system landscape, potentially requiring some adoption of the existing functionality in the platform’s APIs. 
      <p class="bulletList">The following is an example where a customer has replaced <strong class="keyWord">Component C</strong> and <strong class="keyWord">Component F</strong> in the platform with their own implementation:</p>
    </li></ul>
    <figure class="mediaobject"><img src="../Images/B19825_04.png" alt="Diagram  Description automatically generated" width="713" height="497"/></figure>
    <p class="packt_figref">Figure 1.4: Replacing parts of the platform</p>
    <ul>
      <li class="bulletList">Each<a id="_idIndexMarker005"/> component in the platform can be delivered and upgraded separately. Thanks to the use of well-defined APIs, one component can be upgraded to a new version without being dependent on the life cycle of the other components.
      <p class="normal">The following is an example where <strong class="keyWord">Component A</strong> has been upgraded from version <strong class="keyWord">v1.1</strong> to <strong class="keyWord">v1.2</strong>. <strong class="keyWord">Component B</strong>, which calls <strong class="keyWord">Component A</strong>, does not need to be upgraded since it uses a well-defined API; that is, it’s still the same after the upgrade (or it’s at least backward-compatible):</p>
    </li></ul>
    <figure class="mediaobject"><img src="../Images/B19825_05.png" alt="Graphical user interface  Description automatically generated" width="637" height="282"/></figure>
    <p class="packt_figref">Figure 1.5: Upgrading a specific component</p>
    <ul>
      <li class="bulletList">Thanks <a id="_idIndexMarker006"/>to the use of well-defined APIs, each component in the platform can also be scaled out to multiple servers independently of the other components. Scaling can be done either to meet high availability requirements or to handle higher volumes of requests. In this specific project, it was achieved by <em class="italic">manually</em> setting up load balancers in front of a number of servers, each running a Java EE web container. An example where <strong class="keyWord">Component A</strong> has been scaled out to three instances looks as follows:</li>
    </ul>
    <figure class="mediaobject"><img src="../Images/B19825_06.png" alt="" role="presentation" width="744" height="728"/></figure>
    <p class="packt_figref">Figure 1.6: Scaling out the platform</p>
    <h2 id="_idParaDest-18" class="heading-2">Challenges with autonomous software components</h2>
    <p class="normal">My team also <a id="_idIndexMarker007"/>learned that decomposing the platform introduced a number of new challenges that we were not exposed to (at least not to the same degree) when developing more traditional, monolithic applications:</p>
    <ul>
      <li class="bulletList">Adding new instances to a component required manually configuring load balancers and manually setting up new nodes. This work was both time-consuming and error-prone.</li>
      <li class="bulletList">The platform was initially prone to errors caused by the other systems it was communicating with. If a system stopped responding to requests that were sent from the platform in a timely fashion, the platform quickly ran out of crucial resources, for example, OS threads, specifically when exposed to a large number of concurrent requests. This caused components in the platform to hang or even crash. Since most of the communication in the platform is based on synchronous communication, one component crashing can lead to cascading failures; that is, clients of the crashing components could also crash after a while. This is known as<a id="_idIndexMarker008"/> a <strong class="keyWord">chain of failures</strong>.</li>
      <li class="bulletList">Keeping the configuration in all the instances of the components consistent and up to date quickly became a problem, causing a lot of manual and repetitive work. This led to quality problems from time to time.</li>
      <li class="bulletList">Monitoring<a id="_idIndexMarker009"/> the state of the platform in terms of latency issues and hardware usage (for example, usage of CPU, memory, disks, and the network) was more complicated compared to monitoring a single instance of a monolithic application.</li>
      <li class="bulletList">Collecting log files from a number of distributed components and correlating related log events from the components was also difficult, but feasible since the number of components was fixed and known in advance.</li>
    </ul>
    <p class="normal">Over time, we addressed most of the challenges that were mentioned in the preceding list with a mix of in-house-developed tools and well-documented instructions for handling these challenges manually. The scale of the operation was, in general, at a level where manual procedures for releasing new versions of the components and handling runtime issues were acceptable, even though they were not desirable.</p>
    <h2 id="_idParaDest-19" class="heading-2">Enter microservices</h2>
    <p class="normal">Learning <a id="_idIndexMarker010"/>about microservice-based architectures in 2014 made me realize that other projects had also been struggling with similar challenges (partly for other reasons than the ones I described earlier, for example, the large cloud service providers meeting web-scale requirements). Many microservice pioneers had published details of lessons they’d learned. It was very interesting to learn from these lessons.</p>
    <p class="normal">Many of the pioneers initially developed monolithic applications that made them very successful from a business perspective. But over time, these monolithic applications became more and more difficult to maintain and evolve. They also became challenging to scale beyond the capabilities of the largest machines available (also known as <strong class="keyWord">vertical scaling</strong>). Eventually, the pioneers started to find ways to split<a id="_idIndexMarker011"/> monolithic applications into smaller components that could be released and scaled independently of each other. Scaling small components can be done <a id="_idIndexMarker012"/>using <strong class="keyWord">horizontal scaling</strong>, that is, deploying a component on a number of smaller servers and placing a load balancer in front of it. If done in the cloud, the scaling capability is potentially endless – it is just a matter of how many virtual servers you bring in (given that your component can scale out on a huge number of instances, but more on that later on).</p>
    <p class="normal">In 2014, I also <a id="_idIndexMarker013"/>learned about a number of new open source projects that delivered tools and frameworks that simplified the development of microservices and could be used to handle the challenges that come with a microservice-based architecture. </p>
    <p class="normal">Some of these are as follows:</p>
    <ul>
      <li class="bulletList">Pivotal <a id="_idIndexMarker014"/>released <strong class="keyWord">Spring Cloud</strong>, which wraps parts of the <strong class="keyWord">Netflix OSS</strong> in <a id="_idIndexMarker015"/>order to provide capabilities such as dynamic service discovery, configuration management, distributed tracing, circuit breaking, and more.</li>
      <li class="bulletList">I also learned <a id="_idIndexMarker016"/>about <strong class="keyWord">Docker</strong> and the container revolution, which is great for minimizing the gap between development and production. Being able to package a component not only as a deployable runtime artifact (for example, a Java <code class="inlineCode">war</code> or <code class="inlineCode">jar</code> file) but as a complete image, ready to be launched as a container on a server running Docker, was a great step forward for development and testing.</li>
    </ul>
    <div class="packt_tip">
      <p class="normal">For now, think of a container as an isolated process. We will learn more about containers in <em class="chapterRef">Chapter 4</em>, <em class="italic">Deploying Our Microservices Using Docker</em>.</p>
    </div>
    <ul>
      <li class="bulletList">A container engine, such as Docker, is not enough to be able to use containers in a production environment. Something is needed that can ensure that all the containers are up and running and that can scale out containers on a number of servers, thereby providing high availability and increased compute resources.</li>
      <li class="bulletList">These types of products became <a id="_idIndexMarker017"/>known as <strong class="keyWord">container orchestrators</strong>. A number of products have evolved over the last few years, such <a id="_idIndexMarker018"/>as Apache Mesos, Docker <a id="_idIndexMarker019"/>in Swarm mode, Amazon ECS, HashiCorp <a id="_idIndexMarker020"/>Nomad, and <strong class="keyWord">Kubernetes</strong>. Kubernetes<a id="_idIndexMarker021"/> was<a id="_idIndexMarker022"/> initially developed by Google. When Google released v1.0 in 2015, it also<a id="_idIndexMarker023"/> donated Kubernetes to <strong class="keyWord">CNCF</strong> (<a href="https://www.cncf.io/"><span class="url">https://www.cncf.io/</span></a>). During 2018, Kubernetes became kind of a de facto standard, available both pre-packaged for on-premises use and as a service from most of the major cloud providers.</li>
    </ul>
    <div class="note">
      <p class="normal">As explained in <a href="https://kubernetes.io/blog/2015/04/borg-predecessor-to-kubernetes/"><span class="url">https://kubernetes.io/blog/2015/04/borg-predecessor-to-kubernetes/</span></a>, Kubernetes is actually an open source-based rewrite of an internal container orchestrator, named <strong class="keyWord">Borg</strong>, used by Google for more than a decade before the Kubernetes project was founded.</p>
    </div>
    <ul>
      <li class="bulletList">In 2018, I started <a id="_idIndexMarker024"/>to learn about the concept of a <strong class="keyWord">service mesh</strong> and how a service mesh can complement a container orchestrator to further offload microservices from responsibilities to make them manageable and resilient.</li>
    </ul>
    <h2 id="_idParaDest-20" class="heading-2">A sample microservice landscape</h2>
    <p class="normal">Since this<a id="_idIndexMarker025"/> book can’t cover all aspects of <a id="_idIndexMarker026"/>the technologies I just mentioned, I will focus on the parts that have proven to be useful in customer projects I have been involved in since 2014. I will describe how they can be used together to create cooperating microservices that are manageable, scalable, and resilient.</p>
    <p class="normal">Each chapter in this book will address a specific concern. To demonstrate how things fit together, I will use a small set of cooperating microservices that we will evolve throughout this book. The microservice landscape will be described in <em class="chapterRef">Chapter 3</em>, <em class="italic">Creating a Set of Cooperating Microservices</em>; for now, it is sufficient to know that it looks like this:</p>
    <figure class="mediaobject"><img src="../Images/B19825_07.png" alt="Diagram  Description automatically generated" width="751" height="262"/></figure>
    <p class="packt_figref">Figure 1.7: The microservice-based system landscape used in the book</p>
    <div class="note">
      <p class="normal">Note that this is a very small system landscape of cooperating microservices. The surrounding support services that we will add in the coming chapters might look overwhelmingly complex for these few microservices. But keep in mind that the solutions presented in this book aim to support a much larger system landscape.</p>
    </div>
    <p class="normal">Now that we<a id="_idIndexMarker027"/> have<a id="_idIndexMarker028"/> been introduced to the potential benefits and challenges of microservices, let’s start to look into how a microservice can be defined.</p>
    <h1 id="_idParaDest-21" class="heading-1">Defining a microservice</h1>
    <p class="normal">A microservice architecture <a id="_idIndexMarker029"/>is about splitting up monolithic applications into smaller components, which achieves two major goals:</p>
    <ul>
      <li class="bulletList">Faster development, enabling continuous deployments</li>
      <li class="bulletList">Easier to scale, manually or automatically</li>
    </ul>
    <p class="normal">A microservice is essentially an autonomous software component that is independently upgradeable, replaceable, and scalable. To be able to act as an autonomous component, it must fulfill certain criteria, as follows:</p>
    <ul>
      <li class="bulletList">It must conform to a shared-nothing architecture; that is, microservices don’t share data in databases with each other!</li>
      <li class="bulletList">It must only communicate through well-defined interfaces, either using APIs and synchronous services or preferably by sending messages asynchronously. The APIs and message formats used must be stable, well documented, and evolve by following a defined versioning strategy.</li>
      <li class="bulletList">It must be deployed as separate runtime processes. Each instance of a microservice runs in a separate runtime process, for example, a Docker container.</li>
      <li class="bulletList">Microservice instances are stateless so that incoming requests to a microservice can be handled by any of its instances.</li>
    </ul>
    <p class="normal">Using a set of <a id="_idIndexMarker030"/>cooperating microservices, we can deploy to a number of smaller servers instead of being forced to deploy to a single big server, like we have to do when deploying a monolithic application.</p>
    <p class="normal">Given that the preceding criteria have been fulfilled, it is easier to scale up a single microservice into more instances (for example, using more virtual servers) compared to scaling up a big monolithic application.</p>
    <p class="normal">Utilizing autoscaling capabilities that are available in the cloud is also a possibility, but is not typically feasible for a big monolithic application. It’s also easier to upgrade or even replace a single microservice compared to upgrading a big monolithic application.</p>
    <p class="normal">This is illustrated by the following diagram, where a monolithic application has been divided into six microservices, all of which have been deployed into separate servers. Some of the microservices have also been scaled up independently of the others:</p>
    <figure class="mediaobject"><img src="../Images/B19825_08.png" alt="Diagram  Description automatically generated with medium confidence" width="877" height="417"/></figure>
    <p class="packt_figref">Figure 1.8: Dividing a monolith into microservices</p>
    <p class="normal">A very frequent <a id="_idIndexMarker031"/>question I receive from customers is:</p>
    <blockquote class="packt_quote">
      <p class="quote">How big should a microservice be?</p>
    </blockquote>
    <p class="normal">I try to use the following rules of thumb:</p>
    <ul>
      <li class="bulletList">Small enough to fit in the head of a developer</li>
      <li class="bulletList">Big enough to not jeopardize performance (that is, latency) and/or data consistency (SQL foreign keys between data that’s stored in different microservices are no longer something you can take for granted)</li>
    </ul>
    <p class="normal">So, to summarize, microservice architecture is, in essence, an architectural style where we decompose a monolithic application into a group of cooperating autonomous software components. The motivation is to enable faster development and to make it easier to scale the application.</p>
    <p class="normal">With a better understanding of how to define a microservice, we can move on and detail the challenges that come with a system landscape of microservices.</p>
    <h1 id="_idParaDest-22" class="heading-1">Challenges with microservices</h1>
    <p class="normal">In the <em class="italic">Challenges with autonomous software components</em> section, we have already<a id="_idIndexMarker032"/> seen some of the challenges that autonomous software components can bring (and they all apply to microservices as well), as follows:</p>
    <ul>
      <li class="bulletList">Many small components that use synchronous communication can cause <em class="italic">a chain of failure</em> problem, especially under high load</li>
      <li class="bulletList">Keeping the configuration up to date for many small components can be challenging</li>
      <li class="bulletList">It’s hard to track a request that’s being processed and involves many components, for example, when performing root cause analysis, where each component stores log records locally</li>
      <li class="bulletList">Analyzing the usage of hardware resources on a component level can be challenging as well</li>
      <li class="bulletList">Manual configuration and management of many small components can become costly and error-prone</li>
    </ul>
    <p class="normal">Another downside (but not always obvious initially) of decomposing an application into a group of autonomous components is that they form a <strong class="keyWord">distributed system</strong>. Distributed systems are known to be, by their nature, very hard to deal with. This has been known for many years (but in many cases was neglected until proven differently). My favorite quote to establish this fact is from Peter Deutsch who, back in 1994, stated the following:</p>
    <blockquote class="packt_quote">
      <p class="quote"><strong class="keyWord">The 8 fallacies of distributed computing</strong>: Essentially everyone, when they first build a distributed application, makes the following eight assumptions. All prove to be false in the long run and all cause big trouble and painful learning experiences:</p>
      <p class="quote">1. The network is reliable</p>
      <p class="quote">2. Latency is zero</p>
      <p class="quote">3. Bandwidth is infinite</p>
      <p class="quote">4. The network is secure</p>
      <p class="quote">5. The topology doesn’t change</p>
      <p class="quote">6. There is one administrator</p>
      <p class="quote">7. The transport cost is zero</p>
      <p class="quote">8. The network is homogeneous</p>
      <p class="cite">— Peter Deutsch, 1994</p>
    </blockquote>
    <p class="normal">In general, building microservices based on these false assumptions leads to solutions that are prone to both temporary network glitches and problems that occur in other microservice instances. When the number of microservices in a system landscape increases, the likelihood of problems also goes up. A good rule of thumb is to design your microservice architecture based on the assumption that there is always something going wrong in the system landscape. The microservice<a id="_idIndexMarker033"/> architecture needs to be designed to handle this, in terms of detecting problems and restarting failed components. Also, on the client side, ensure that requests are not sent to failed microservice instances. When problems are corrected, requests to the previously failing microservice should be resumed; that is, microservice clients need to be resilient. All of this needs, of course, to be fully automated. With a large number of microservices, it is not feasible for operators to handle this manually!</p>
    <p class="normal">The scope of this is large, but we will limit ourselves for now and move on to learn about design patterns for microservices.</p>
    <h1 id="_idParaDest-23" class="heading-1">Design patterns for microservices</h1>
    <p class="normal">This topic<a id="_idIndexMarker034"/> will cover the use of design patterns to mitigate challenges with microservices, as described in the preceding section. Later <a id="_idIndexMarker035"/>in this book, we will see how we can implement these design patterns using Spring Boot, Spring Cloud, Kubernetes, and Istio.</p>
    <p class="normal">The concept of design patterns is actually quite old; it was invented by Christopher Alexander back in 1977. In essence, a design pattern is about describing a reusable solution to a problem when given a specific context. Using a tried and tested solution from a design pattern can save a lot of time and increase the quality of the implementation compared to spending time inventing the solution ourselves.</p>
    <p class="normal">The design patterns we <a id="_idIndexMarker036"/>will cover are as follows:</p>
    <ul>
      <li class="bulletList">Service discovery</li>
      <li class="bulletList">Edge server</li>
      <li class="bulletList">Reactive microservices</li>
      <li class="bulletList">Central configuration</li>
      <li class="bulletList">Centralized log analysis</li>
      <li class="bulletList">Distributed tracing</li>
      <li class="bulletList">Circuit breaker</li>
      <li class="bulletList">Control loop</li>
      <li class="bulletList">Centralized monitoring and alarms</li>
    </ul>
    <div class="packt_tip">
      <p class="normal">This list is not intended to be comprehensive; instead, it’s a minimal list of design patterns that are required to handle the challenges we described previously.</p>
    </div>
    <p class="normal">We will use a lightweight <a id="_idIndexMarker037"/>approach to describing design patterns, and focus on the following:</p>
    <ul>
      <li class="bulletList">The problem</li>
      <li class="bulletList">A solution</li>
      <li class="bulletList">Requirements for the solution</li>
    </ul>
    <p class="normal">Throughout this book, we will delve more deeply into how to apply these design patterns. The context for these design patterns is a system landscape of cooperating microservices where the microservices communicate with each other using either synchronous requests (for example, using HTTP) or by sending asynchronous messages (for example, using a message broker).</p>
    <h2 id="_idParaDest-24" class="heading-2">Service discovery</h2>
    <p class="normal">The service discovery pattern <a id="_idIndexMarker038"/>has the<a id="_idIndexMarker039"/> following problem, solution, and solution requirements.</p>
    <h3 id="_idParaDest-25" class="heading-3">Problem</h3>
    <p class="normal">How <a id="_idIndexMarker040"/>can clients find microservices and their instances?</p>
    <p class="normal">Microservices instances are typically assigned dynamically allocated IP addresses when they start up, for example, when running in containers. This makes it difficult for a client to make a request to a microservice that, for example, exposes a REST API over HTTP. Consider the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B19825_09.png" alt="Graphical user interface, diagram  Description automatically generated" width="509" height="434"/></figure>
    <p class="packt_figref">Figure 1.9: The service discovery issue</p>
    <h3 id="_idParaDest-26" class="heading-3">Solution</h3>
    <p class="normal">Add a <a id="_idIndexMarker041"/>new component – a <strong class="keyWord">service discovery</strong> service – to the system landscape, which keeps track of currently available microservices and the IP addresses of its instances.</p>
    <h3 id="_idParaDest-27" class="heading-3">Solution requirements</h3>
    <p class="normal">Some <a id="_idIndexMarker042"/>solution requirements are as follows:</p>
    <ul>
      <li class="bulletList">Automatically register/unregister microservices and their instances as they come and go.</li>
      <li class="bulletList">The client must be able to make a request to a logical endpoint for the microservice. The request will be routed to one of the available microservice instances.</li>
      <li class="bulletList">Requests to a microservice must be load-balanced over the available instances.</li>
      <li class="bulletList">We must <a id="_idIndexMarker043"/>be able to detect instances that currently are unhealthy so that requests will not be routed to them.</li>
    </ul>
    <p class="normal"><strong class="keyWord">Implementation notes</strong>: As <a id="_idIndexMarker044"/>we will see in <em class="chapterRef">Chapter 9</em>, <em class="italic">Adding Service Discovery Using Netflix Eureka</em>, <em class="chapterRef">Chapter 15</em>, <em class="italic">Introduction to Kubernetes</em>, and <em class="chapterRef">Chapter 16</em>, <em class="italic">Deploying Our Microservices to Kubernetes</em>, this design pattern can be implemented using two different strategies:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Client-side routing</strong>: The <a id="_idIndexMarker045"/>client uses a library that communicates with the service discovery service to find out the proper instances to send the requests to.</li>
      <li class="bulletList"><strong class="keyWord">Server-side routing</strong>: The <a id="_idIndexMarker046"/>infrastructure of the service discovery service also exposes a reverse proxy that all requests are sent to. The reverse proxy forwards the requests to a proper microservice instance on behalf of the client.</li>
    </ul>
    <h2 id="_idParaDest-28" class="heading-2">Edge server</h2>
    <p class="normal">The<a id="_idIndexMarker047"/> edge server pattern has the following <a id="_idIndexMarker048"/>problem, solution, and solution requirements.</p>
    <h3 id="_idParaDest-29" class="heading-3">Problem</h3>
    <p class="normal">In a<a id="_idIndexMarker049"/> system landscape of microservices, it is in many cases desirable to expose some of the microservices to the outside of the system landscape and hide the remaining microservices from external access. The exposed microservices must be protected against requests from malicious clients.</p>
    <h3 id="_idParaDest-30" class="heading-3">Solution</h3>
    <p class="normal">Add a new<a id="_idIndexMarker050"/> component, an <strong class="keyWord">edge server</strong>, to the system landscape that all incoming requests will go through:</p>
    <figure class="mediaobject"><img src="../Images/B19825_10.png" alt="Diagram  Description automatically generated" width="676" height="466"/></figure>
    <p class="packt_figref">Figure 1.10: The edge server design pattern</p>
    <p class="normal"><strong class="keyWord">Implementation notes</strong>: An <a id="_idIndexMarker051"/>edge server typically behaves like a reverse proxy and can be integrated with a discovery service to provide dynamic load-balancing capabilities.</p>
    <h3 id="_idParaDest-31" class="heading-3">Solution requirements</h3>
    <p class="normal">Some <a id="_idIndexMarker052"/>solution requirements are as follows:</p>
    <ul>
      <li class="bulletList">Hide internal services that should not be exposed outside their context; that is, only route requests to microservices that are configured to allow external requests</li>
      <li class="bulletList">Expose external services and protect them from malicious requests; that is, use standard protocols and best practices such as OAuth, OIDC, JWT tokens, and API keys to ensure that the clients are trustworthy</li>
    </ul>
    <h2 id="_idParaDest-32" class="heading-2">Reactive microservices</h2>
    <p class="normal">The<a id="_idIndexMarker053"/> reactive microservices pattern has the following problem, solution, and solution requirements.</p>
    <h3 id="_idParaDest-33" class="heading-3">Problem</h3>
    <p class="normal">Traditionally, as<a id="_idIndexMarker054"/> Java developers, we are used to implementing synchronous communication using blocking I/O, for example, a RESTful JSON API over HTTP. Using a blocking I/O means that a thread is allocated from the operating system for the length of the request. </p>
    <p class="normal">If the number of concurrent requests goes up, a server might run out of available threads in the operating system, causing problems ranging from longer response times to crashing servers. Using a microservice architecture typically makes this problem even worse, where typically a chain of cooperating microservices is used to serve a request. The more microservices involved in serving a request, the faster the available threads will be drained.</p>
    <h3 id="_idParaDest-34" class="heading-3">Solution</h3>
    <p class="normal">Use <a id="_idIndexMarker055"/>non-blocking I/O to ensure that no threads are allocated while waiting for processing to occur in another service, that is, a database or another microservice.</p>
    <h3 id="_idParaDest-35" class="heading-3">Solution requirements</h3>
    <p class="normal">Some <a id="_idIndexMarker056"/>solution requirements are as follows:</p>
    <ul>
      <li class="bulletList">Whenever feasible, use an asynchronous programming model, sending messages without waiting for the receiver to process them.</li>
      <li class="bulletList">If a synchronous programming model is preferred, use reactive frameworks that can execute synchronous requests using non-blocking I/O, without allocating a thread while waiting for a response. This will make the microservices easier to scale in order to handle an increased workload.</li>
      <li class="bulletList">Microservices <a id="_idIndexMarker057"/>must also be designed to be resilient and self-healing. Resilient meaning being capable of producing a response even if one of the services it depends on fails; self-healing meaning that once the failing service is operational again, the microservice must be able to resume using it.</li>
    </ul>
    <div class="note">
      <p class="normal">In 2013, key principles for <a id="_idIndexMarker058"/>designing reactive systems were established in <strong class="keyWord">The Reactive Manifesto </strong>(<a href="https://www.reactivemanifesto.org/"><span class="url">https://www.reactivemanifesto.org/</span></a>).</p>
      <p class="normal">According to the manifesto, the foundation for reactive systems is that they are message-driven; they use asynchronous communication. This allows them to be elastic, that is, scalable, and resilient, that is, tolerant to failures. Elasticity and resilience together enable a reactive system to always respond in a timely fashion.</p>
    </div>
    <h2 id="_idParaDest-36" class="heading-2">Central configuration</h2>
    <p class="normal">The<a id="_idIndexMarker059"/> central configuration pattern<a id="_idIndexMarker060"/> has the following problem, solution, and solution requirements.</p>
    <h3 id="_idParaDest-37" class="heading-3">Problem</h3>
    <p class="normal">An<a id="_idIndexMarker061"/> application is, traditionally, deployed together with its configuration, for example, a set of environment variables and/or files containing configuration information. Given a system landscape based on a microservice architecture, that is, with a large number of deployed microservice instances, some queries arise:</p>
    <ul>
      <li class="bulletList">How do I get a complete picture of the configuration that is in place for all the running microservice instances?</li>
      <li class="bulletList">How do I update the configuration and make sure that all the affected microservice instances are updated correctly?</li>
    </ul>
    <h3 id="_idParaDest-38" class="heading-3">Solution</h3>
    <p class="normal">Add a new <a id="_idIndexMarker062"/>component, a <strong class="keyWord">configuration server</strong>, to the system landscape to store the configuration of all the microservices, as illustrated by the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B19825_11.png" alt="Diagram  Description automatically generated" width="711" height="383"/></figure>
    <p class="packt_figref">Figure 1.11: The central configuration design pattern</p>
    <h3 id="_idParaDest-39" class="heading-3">Solution requirements</h3>
    <p class="normal">Make it possible <a id="_idIndexMarker063"/>to store configuration information for a group of microservices in one place, with different settings for different environments (for example, <strong class="keyWord">dev</strong>, <strong class="keyWord">test</strong>, <strong class="keyWord">qa</strong>, and <strong class="keyWord">prod</strong>).</p>
    <h2 id="_idParaDest-40" class="heading-2">Centralized log analysis</h2>
    <p class="normal">Centralized log analysis <a id="_idIndexMarker064"/>has the following problem, solution, and solution requirements.</p>
    <h3 id="_idParaDest-41" class="heading-3">Problem</h3>
    <p class="normal">Traditionally, an <a id="_idIndexMarker065"/>application writes log events to log files that are stored in the local filesystem of the server that the application runs on. Given a system landscape based on a microservice architecture, that is, with a large number of deployed microservice instances on a large number of smaller servers, we can ask the following questions:</p>
    <ul>
      <li class="bulletList">How do I get an overview of what is going on in the system landscape when each microservice instance writes to its own local log file?</li>
      <li class="bulletList">How <a id="_idIndexMarker066"/>do I find out if any of the microservice instances get into trouble and start writing error messages to their log files?</li>
      <li class="bulletList">If end users start to report problems, how can I find related log messages; that is, how can I identify which microservice instance is the root cause of the problem? The following diagram illustrates the problem:</li>
    </ul>
    <figure class="mediaobject"><img src="../Images/B19825_12.png" alt="Diagram  Description automatically generated" width="658" height="549"/></figure>
    <p class="packt_figref">Figure 1.12: Microservices write log files to their local file system</p>
    <h3 id="_idParaDest-42" class="heading-3">Solution</h3>
    <p class="normal">Add a<a id="_idIndexMarker067"/> new component that can manage <strong class="keyWord">centralized logging</strong> and is capable of the following:</p>
    <ul>
      <li class="bulletList">Detecting new microservice instances and collecting log events from them</li>
      <li class="bulletList">Interpreting and storing log events in a structured and searchable way in a central database</li>
      <li class="bulletList">Providing APIs and graphical tools for querying and analyzing log events</li>
    </ul>
    <h3 id="_idParaDest-43" class="heading-3">Solution requirements</h3>
    <p class="normal">Some <a id="_idIndexMarker068"/>solution requirements are as follows:</p>
    <ul>
      <li class="bulletList">Microservices stream log events to standard system output, <code class="inlineCode">stdout</code>. This makes it easier for a log collector to find the log events compared to when log events are written to microservice-specific log files.</li>
      <li class="bulletList">Microservices tag the log events with the correlation ID described in the next section regarding the <em class="italic">Distributed tracing</em> design pattern.</li>
      <li class="bulletList">A canonical log format is defined, so that log collectors can transform log events collected from the microservices to a canonical log format before log events are stored in the central database. Storing log events in a canonical log format is required to be able to query and analyze the collected log events.</li>
    </ul>
    <h2 id="_idParaDest-44" class="heading-2">Distributed tracing</h2>
    <p class="normal">Distributed tracing <a id="_idIndexMarker069"/>has the following problem, solution, and solution requirements.</p>
    <h3 id="_idParaDest-45" class="heading-3">Problem</h3>
    <p class="normal">It must<a id="_idIndexMarker070"/> be possible to track requests and messages that flow between microservices while processing an external request to the system landscape.</p>
    <p class="normal">Some examples of fault scenarios are as follows:</p>
    <ul>
      <li class="bulletList">If end users start to file support cases regarding a specific failure, how can we identify the microservice that caused the problem, that is, the root cause?</li>
      <li class="bulletList">If one <a id="_idIndexMarker071"/>support case mentions problems related to a specific entity, for example, a specific order number, how can we find log messages related to processing this specific order – for example, log messages from all microservices that were involved in processing it?</li>
      <li class="bulletList">If end users start to file support cases regarding an unacceptably long response time, how can we identify which microservice in a call chain is causing the delay?</li>
    </ul>
    <p class="normal">The following diagram depicts this:</p>
    <figure class="mediaobject"><img src="../Images/B19825_13.png" alt="Diagram  Description automatically generated" width="738" height="615"/></figure>
    <p class="packt_figref">Figure 1.13: The distributed tracing issue</p>
    <h3 id="_idParaDest-46" class="heading-3">Solution</h3>
    <p class="normal">To<a id="_idIndexMarker072"/> track the processing between cooperating microservices, we need to ensure that all related requests and messages are marked with a common <strong class="keyWord">correlation ID</strong> and that the correlation ID is part of all log events. Based on a correlation ID, we can use the centralized logging service to find all related log events. If one of the log events also includes information about a business-related identifier, for example, the ID of a customer, product, or order, we can find all related log events for that business identifier using the correlation ID.</p>
    <p class="normal">To be able to analyze delays in a call chain of cooperating microservices, we must be able to collect timestamps for when requests, responses, and messages enter and exit each microservice.</p>
    <h3 id="_idParaDest-47" class="heading-3">Solution requirements</h3>
    <p class="normal">The <a id="_idIndexMarker073"/>solution requirements are as follows:</p>
    <ul>
      <li class="bulletList">Assign unique correlation IDs to all incoming or new requests and events in a well-known place, such as a header with a standardized name</li>
      <li class="bulletList">When a microservice makes an outgoing request or sends a message, it must add the correlation ID to the request and message</li>
      <li class="bulletList">All log events must include the correlation ID in a predefined format so that the centralized logging service can extract the correlation ID from the log event and make it searchable</li>
      <li class="bulletList">Trace records must be created for when requests, responses, and messages both enter and exit a microservice instance</li>
    </ul>
    <h2 id="_idParaDest-48" class="heading-2">Circuit breaker</h2>
    <p class="normal">The<a id="_idIndexMarker074"/> circuit breaker pattern has the following problem, solution, and solution requirements.</p>
    <h3 id="_idParaDest-49" class="heading-3">Problem</h3>
    <p class="normal">A system landscape<a id="_idIndexMarker075"/> of microservices that uses synchronous intercommunication can be exposed <a id="_idIndexMarker076"/>to a <strong class="keyWord">chain of failures</strong>. If one microservice stops responding, its clients might get into problems as well and stop responding to requests from their clients. The problem can propagate recursively throughout a system landscape and take out major parts of it.</p>
    <p class="normal">This is <a id="_idIndexMarker077"/>especially common in cases where synchronous requests are executed using blocking I/O, that is, blocking a thread from the underlying operating system while a request is being processed. Combined with a large number of concurrent requests and a service that starts to respond unexpectedly slowly, thread pools can quickly become drained, causing the caller to hang and/or crash. This failure can spread unpleasantly quickly to the caller’s caller, and so on.</p>
    <h3 id="_idParaDest-50" class="heading-3">Solution</h3>
    <p class="normal">Add a <strong class="keyWord">circuit breaker</strong> that <a id="_idIndexMarker078"/>prevents new outgoing requests from a caller if it detects a problem with the service it calls.</p>
    <h3 id="_idParaDest-51" class="heading-3">Solution requirements</h3>
    <p class="normal">The<a id="_idIndexMarker079"/> solution requirements are as follows:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Open</strong> the circuit and fail fast (without waiting for a timeout) if problems with the service are detected.</li>
      <li class="bulletList">Probe for failure<a id="_idIndexMarker080"/> correction (also known as a <strong class="keyWord">half-open</strong> circuit); that is, allow a single request to go through on a regular basis to see whether the service is operating normally again.</li>
      <li class="bulletList"><strong class="keyWord">Close</strong> the circuit if the probe detects that the service is operating normally again. This capability is very important since it makes the system landscape resilient to these kinds of problems; in other words, it self-heals.</li>
    </ul>
    <p class="normal">The following diagram illustrates a scenario where all synchronous communication within the system landscape of microservices goes through circuit breakers. All the circuit breakers are closed; they allow traffic, except for one circuit breaker (for <strong class="keyWord">Microservice E</strong>) that has detected problems in the service the requests go to. Therefore, this circuit breaker is open and utilizes fast-fail logic; that is, it does not call the failing service and waits for a timeout to occur. Instead, <strong class="keyWord">Microservice E</strong> can<a id="_idIndexMarker081"/> immediately return a response, optionally applying some<a id="_idIndexMarker082"/> fallback logic before responding:</p>
    <figure class="mediaobject"><img src="../Images/B19825_14.png" alt="Diagram  Description automatically generated" width="877" height="513"/></figure>
    <p class="packt_figref">Figure 1.14: The circuit breaker design pattern</p>
    <h2 id="_idParaDest-52" class="heading-2">Control loop</h2>
    <p class="normal">The<a id="_idIndexMarker083"/> control loop pattern has<a id="_idIndexMarker084"/> the following problem, solution, and solution requirements.</p>
    <h3 id="_idParaDest-53" class="heading-3">Problem</h3>
    <p class="normal">In a system <a id="_idIndexMarker085"/>landscape with a large number of microservice instances spread out over a number of servers, it is very difficult to manually detect and correct problems such as crashed or hung microservice instances.</p>
    <h3 id="_idParaDest-54" class="heading-3">Solution</h3>
    <p class="normal">Add a <a id="_idIndexMarker086"/>new component, a <strong class="keyWord">control loop</strong>, to the system landscape. This process is illustrated as follows:</p>
    <figure class="mediaobject"><img src="../Images/B19825_15.png" alt="Diagram  Description automatically generated" width="878" height="293"/></figure>
    <p class="packt_figref">Figure 1.15: The control loop design pattern</p>
    <h3 id="_idParaDest-55" class="heading-3">Solution requirements</h3>
    <p class="normal">The control <a id="_idIndexMarker087"/>loop will constantly observe <a id="_idIndexMarker088"/>the <strong class="keyWord">actual state</strong> of the system landscape, comparing it with<a id="_idIndexMarker089"/> a <strong class="keyWord">desired state</strong>, as specified by the operators. If the two states differ, it will take action to make the actual state equal to the desired state.</p>
    <p class="normal"><strong class="keyWord">Implementation notes</strong>: In <a id="_idIndexMarker090"/>the world of containers, a <em class="italic">container orchestrator</em> such as Kubernetes is typically used to implement this pattern. We will learn more about Kubernetes in <em class="chapterRef">Chapter 15</em>, <em class="italic">Introduction to Kubernetes</em>.</p>
    <h2 id="_idParaDest-56" class="heading-2">Centralized monitoring and alarms</h2>
    <p class="normal">For this <a id="_idIndexMarker091"/>pattern, we <a id="_idIndexMarker092"/>have the following problem, solution, and solution requirements.</p>
    <h3 id="_idParaDest-57" class="heading-3">Problem</h3>
    <p class="normal">If <a id="_idIndexMarker093"/>observed response times and/or the usage of hardware resources become unacceptably high, it can be very hard to discover the root cause of the problem. For example, we need to be able to analyze hardware resource consumption per microservice.</p>
    <h3 id="_idParaDest-58" class="heading-3">Solution</h3>
    <p class="normal">To curb<a id="_idIndexMarker094"/> this, we add a new component, a <strong class="keyWord">monitor service</strong>, to<a id="_idIndexMarker095"/> the system landscape, which is capable of collecting metrics about hardware resource usage for each microservice instance level.</p>
    <h3 id="_idParaDest-59" class="heading-3">Solution requirements</h3>
    <p class="normal">The <a id="_idIndexMarker096"/>solution requirements are as follows:</p>
    <ul>
      <li class="bulletList">It must be able to collect metrics from all the servers that are used by the system landscape, which includes autoscaling servers</li>
      <li class="bulletList">It must be able to detect new microservice instances as they are launched on the available servers and start to collect metrics from them</li>
      <li class="bulletList">It must be able to provide APIs and graphical tools for querying and analyzing the collected metrics</li>
      <li class="bulletList">It must be possible to define alerts that are triggered when a specified metric exceeds a specified threshold value</li>
    </ul>
    <p class="normal">The following screenshot shows Grafana, which visualizes metrics from Prometheus, a monitoring tool that we will look at in <em class="chapterRef">Chapter 20</em>, <em class="italic">Monitoring Microservices</em>:</p>
    <figure class="mediaobject"><img src="../Images/B19825_16.png" alt="A screenshot of a computer  Description automatically generated" width="877" height="622"/></figure>
    <p class="packt_figref">Figure 1.16: Monitoring with Grafana</p>
    <p class="normal">That was an <a id="_idIndexMarker097"/>extensive list! I am sure these design patterns helped you to understand the challenges with microservices better. Next, we will move on to learning about software enablers.</p>
    <h1 id="_idParaDest-60" class="heading-1">Software enablers</h1>
    <p class="normal">As we’ve <a id="_idIndexMarker098"/>already mentioned, we have a number of very good open source tools that can help us both meet our expectations of microservices and, most importantly, handle the new challenges that come with them:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Spring Boot</strong>, an application framework</li>
      <li class="bulletList"><strong class="keyWord">Spring Cloud/Netflix OSS</strong>, a mix of application framework and ready-to-use services</li>
      <li class="bulletList"><strong class="keyWord">Docker</strong>, a tool for running containers on a single server</li>
      <li class="bulletList"><strong class="keyWord">Kubernetes</strong>, a container orchestrator that manages a cluster of servers that run containers</li>
      <li class="bulletList"><strong class="keyWord">Istio</strong>, a service mesh implementation</li>
    </ul>
    <p class="normal">The following table maps the design patterns we will need to handle these<a id="_idIndexMarker099"/> challenges, along with the corresponding open source tool that will be used in this book to implement the design patterns:</p>
    <table id="table001" class="table-container">
      <tbody>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Design Pattern</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Spring Boot</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Spring Cloud</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Kubernetes</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Istio</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Service discovery</strong></p>
          </td>
          <td class="table-cell"/>
          <td class="table-cell">
            <p class="normal">Netflix Eureka and Spring Cloud LoadBalancer</p>
          </td>
          <td class="table-cell">
            <p class="normal">Kubernetes <code class="inlineCode">kube-proxy</code> and service resources</p>
          </td>
          <td class="table-cell"/>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Edge server</strong></p>
          </td>
          <td class="table-cell"/>
          <td class="table-cell">
            <p class="normal">Spring Cloud Gateway and Spring Security OAuth</p>
          </td>
          <td class="table-cell">
            <p class="normal">Kubernetes Ingress controller</p>
          </td>
          <td class="table-cell">
            <p class="normal">Istio ingress gateway</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Reactive microservices</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">Project Reactor and Spring WebFlux</p>
          </td>
          <td class="table-cell"/>
          <td class="table-cell"/>
          <td class="table-cell"/>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Central configuration</strong></p>
          </td>
          <td class="table-cell"/>
          <td class="table-cell">
            <p class="normal">Spring Config Server</p>
          </td>
          <td class="table-cell">
            <p class="normal">Kubernetes <code class="inlineCode">ConfigMaps</code> and Secrets</p>
          </td>
          <td class="table-cell"/>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Centralized log analysis</strong></p>
          </td>
          <td class="table-cell"/>
          <td class="table-cell"/>
          <td class="table-cell">
            <p class="normal">Elasticsearch, Fluentd, and Kibana. Note: Actually not part of Kubernetes, but can easily be deployed and configured together with Kubernetes</p>
          </td>
          <td class="table-cell"/>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Distributed tracing</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">Micrometer Tracing and Zipkin</p>
          </td>
          <td class="table-cell"/>
          <td class="table-cell"/>
          <td class="table-cell">
            <p class="normal">Jaeger</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Circuit breaker</strong></p>
          </td>
          <td class="table-cell"/>
          <td class="table-cell">
            <p class="normal">Resilience4j</p>
          </td>
          <td class="table-cell"/>
          <td class="table-cell">
            <p class="normal">Outlier detection</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Control loop</strong></p>
          </td>
          <td class="table-cell"/>
          <td class="table-cell"/>
          <td class="table-cell">
            <p class="normal">Kubernetes controller managers</p>
          </td>
          <td class="table-cell"/>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Centralized monitoring and alarms</strong></p>
          </td>
          <td class="table-cell"/>
          <td class="table-cell"/>
          <td class="table-cell"/>
          <td class="table-cell">
            <p class="normal">Kiali, Grafana, and Prometheus</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Figure 1.17: Mapping design patterns to open source tools </p>
    <p class="normal">Please <a id="_idIndexMarker100"/>note that any of Spring Cloud, Kubernetes, or Istio can be used to implement some design patterns, such as service discovery, edge server, and central configuration. We will discuss the pros and cons of using these alternatives later in this book.</p>
    <p class="normal">With the design patterns and tools that we will use in the book introduced, we will wrap up this chapter by going through some related areas that are also important, but not covered in this text.</p>
    <h1 id="_idParaDest-61" class="heading-1">Other important considerations</h1>
    <p class="normal">To be <a id="_idIndexMarker101"/>successful when it comes to implementing a microservice architecture, there are a number of related areas to consider as well. I will not cover these areas in this book; instead, I’ll just briefly mention them here as follows:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Importance of DevOps</strong>: One of the benefits of a microservice architecture is that it enables shorter delivery times and, in extreme cases, allows <em class="italic">continuous delivery</em> of new versions. To be able to deliver that fast, you need to establish an organization where dev and ops work together under the mantra <em class="italic">you built it, you run it</em>. This means that developers are no longer allowed to simply pass new versions of the software over to the operations team. Instead, the dev and ops organizations need to work much more closely together, organized into teams that have full responsibility for the end-to-end life cycle of one microservice (or a group of related microservices). Besides the organizational part of dev/ops, the teams also need to automate the delivery chain, that is, the steps for building, testing, packaging, and deploying the microservices to the various deployment environments. This is known as setting up a <em class="italic">delivery pipeline</em>.</li>
      <li class="bulletList"><strong class="keyWord">Organizational aspects and Conway’s law</strong>: Another interesting aspect of how a microservice<a id="_idIndexMarker102"/> architecture might affect the organization is <em class="italic">Conway’s law</em>, which states the following:
      <blockquote class="packt_quote">
        <p class="quote">”Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization’s communication structure.”</p>
        <p class="cite">— Melvyn Conway, 1967</p>
      </blockquote>
      <p class="normal">This <a id="_idIndexMarker103"/>means that the traditional approach of organizing IT teams for large applications based on their technology expertise (for example, UX, business logic, and database teams) will lead to a big three-tier application – typically, a big monolithic application with a separately deployable unit for the UI, one for processing the business logic, and one for the big database. </p>
      <p class="normal">To successfully deliver an application based on a microservice architecture, the organization needs to be changed into teams that work with one or a group of related microservices. The team must have the skills that are required for those microservices, for example, languages and frameworks for the business logic and database technologies for persisting its data.</p>
    </li></ul>
    <ul>
      <li class="bulletList"><strong class="keyWord">Decomposing a monolithic application into microservices</strong>: One of the most difficult decisions (and expensive if done wrong) is how to decompose a monolithic application into a set of cooperating microservices. If this is done in the wrong way, you will end up with problems such as the following:<ul>
          <li class="bulletList"><strong class="keyWord">Slow delivery</strong>: Changes in the business requirements will affect too many of the microservices, resulting in extra work.</li>
          <li class="bulletList"><strong class="keyWord">Bad performance</strong>: To be able to perform a specific business function, a lot of requests have to be passed between various microservices, resulting in long response times.</li>
          <li class="bulletList"><strong class="keyWord">Inconsistent data</strong>: Since related data is separated into different microservices, inconsistencies can appear over time in data that’s managed by different microservices.</li>
        </ul>
     
      <p class="normal">A good <a id="_idIndexMarker104"/>approach to finding proper boundaries for microservices is to apply <strong class="keyWord">domain-driven design</strong> and its <a id="_idIndexMarker105"/>concept of <strong class="keyWord">bounded contexts</strong>. According to Eric Evans, a <em class="italic">bounded context</em> is:</p>
      <blockquote class="packt_quote">
        <p class="quote">”A description of a boundary (typically a subsystem, or the work of a particular team) within which a particular model is defined and applicable.”</p>
      </blockquote>
      <p class="normal">This means<a id="_idIndexMarker106"/> that a microservice defined by a bounded context will have a well-defined model of its own data.</p>
     </li></ul>
    <ul>
      <li class="bulletList"><strong class="keyWord">Importance of API design</strong>: If <a id="_idIndexMarker107"/>a group of microservices exposes a common, externally available API, it is important that the API is easy to understand and adheres to the following guidelines:<ul>
          <li class="bulletList">If the same concept is used in multiple APIs, it should have the same description in terms of the naming and data types used.</li>
          <li class="bulletList">It is of great importance that APIs are allowed to evolve in an independent but controlled manner. This typically requires applying a proper versioning schema for the APIs, for example, <a href="https://semver.org/"><span class="url">https://semver.org/</span></a>. This implies supporting multiple major versions of an API over a specific period of time, allowing clients of the API to migrate to new major versions at their own pace.</li>
        </ul>
      </li>
      <li class="bulletList"><strong class="keyWord">Migration paths from on-premises to the cloud</strong>: Many companies today run their workload on-premises, but are searching for ways to move parts of their workload to the cloud. Since most cloud providers today offer <em class="italic">Kubernetes as a Service</em>, an appealing migration approach can be to first move the workload into Kubernetes on-premises (as microservices or not) and then redeploy it on a Kubernetes as a Service offering provided by a preferred cloud provider.</li>
      <li class="bulletList"><strong class="keyWord">Good design principles for microservices, the 12-factor app</strong>: The 12-factor app (<a href="https://12factor.net"><span class="url">https://12factor.net</span></a>) is a<a id="_idIndexMarker108"/> set of design principles <a id="_idIndexMarker109"/>for building software that can be deployed in the cloud. Most of these design principles are applicable to building microservices independently of where and how they will be deployed, that is, in the cloud or on-premises. Some of these principles will be covered in this book, such as config, processes, and logs, but not all.</li>
    </ul>
    <p class="normal">That’s it for the first<a id="_idIndexMarker110"/> chapter! I hope it gave you a good basic idea of microservices and the challenges that come with them, as well as an overview of what we will cover in this book.</p>
    <h1 id="_idParaDest-62" class="heading-1">Summary</h1>
    <p class="normal">In this introductory chapter, I described my own way into microservices and delved into a bit of their history. We defined what a microservice is – a kind of autonomous distributed component with some specific requirements. We also went through both the good and challenging aspects of microservice-based architecture.</p>
    <p class="normal">To handle these challenges, we defined a set of design patterns and briefly mapped the capabilities of open source products such as Spring Boot, Spring Cloud, Kubernetes, and Istio to the design patterns.</p>
    <p class="normal">You’re eager to develop your first microservice now, right? In the next chapter, you will be introduced to Spring Boot and complementary open source tools that we will use to develop our first microservices.</p>
    <h1 id="_idParaDest-63" class="heading-1">Join our community on Discord</h1>
    <p class="normal">Join our community’s Discord space for discussion with the author and other readers:</p>
    <p class="normal"><a href="https://packt.link/SpringBoot3e"><span class="url">https://packt.link/SpringBoot3e</span></a></p>
    <p class="normal"><img src="../Images/QR_Code1849216352344398875.png" alt="" role="presentation" width="177" height="177"/></p>
  </div>
</div>
</div>
</body></html>