- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Concurrency – Virtual Threads and Structured Concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter includes 16 problems that briefly introduce *virtual threads* and
    *structured concurrency*.
  prefs: []
  type: TYPE_NORMAL
- en: If you don’t have a background in concurrency in Java, then I strongly recommend
    postponing this chapter until after you have read some good introductory coverage
    on the topic. For instance, you could try out *Chapters 10* an*d 11* from *Java
    Coding Problems*, *First Edition*.
  prefs: []
  type: TYPE_NORMAL
- en: '*Virtual threads* are one of the most important and astonishing features added
    by Java in the last few years. They have a significant impact on how we will continue
    to write and understand concurrent code from this point forward. In this chapter,
    you’ll learn, step by step, every single detail of this topic and the *structured
    concurrency* paradigm.'
  prefs: []
  type: TYPE_NORMAL
- en: After this chapter, you’ll be quite knowledgeable in working with virtual threads
    and structured concurrency.
  prefs: []
  type: TYPE_NORMAL
- en: Problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Use the following problems to test your programming prowess in virtual threads
    and structured concurrency in Java. I strongly encourage you to give each problem
    a try before you turn to the solutions and download the example programs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Explaining concurrency vs. parallelism**: Provide a brief but meaningful
    explanation of concurrency vs. parallelism.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing structured concurrency**: Write an example highlighting the main
    issues of “unstructured” concurrency. Moreover, provide an introduction to the
    structured concurrency paradigm.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing virtual threads**: Explain and exemplify the main concepts of
    virtual threads.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Using the ExecutorService for virtual threads**: Write several examples that
    highlight the *task-per-thread* model via `ExecutorService` and virtual threads.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Explaining how virtual threads work**: Provide comprehensive coverage of
    how virtual threads work internally.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Hooking virtual threads and sync code**: Explain and exemplify via a meaningful
    snippet of code how virtual threads and sync code work together.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Exemplifying thread context switching**: Write several examples that show
    how *thread context switching* works for virtual threads.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing the ExecutorService invoke all/any for virtual threads – part
    1**: Provide a brief introduction of `ExecutorService` invoke all/any for virtual
    threads.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing the ExecutorServiceinvoke all/any for virtual threads – part
    2**: Re-write the example of “unstructured” concurrency from *Problem 210* via
    `ExecutorService` invoke all/any for virtual threads.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Hooking task state**: Explain and exemplify the new `Future#state()` API.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Combining new VirtualThreadPerTaskExecutor() and streams**: Write several
    examples that introduce how Java stream pipelines can be combined with the `newVirtualThreadPerTaskExecutor()`
    executor.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing a scope object (StructuredTaskScope)**: Provide a brief introduction
    of structured concurrency via the `StructuredTaskScope` API.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing ShutdownOnSuccess**: Exemplify the `ShutdownOnSuccess` flavor
    of `StructuredTaskScope`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing ShutdownOnFailure**: Exemplify the `ShutdownOnFailure` flavor
    of `StructuredTaskScope`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Combining StructuredTaskScope and streams**: Write several examples that
    introduce how Java stream pipelines can be combined with `StructuredTaskScope`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Observing and monitoring virtual threads**: Exemplify how we can use **JFR**
    (**Java Flight Recorder**), **JMX** (**Java Management Extensions**), and any
    other tool that you like, for observing and monitoring virtual threads.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The following sections describe solutions to the preceding problems. Remember
    that there usually isn’t a single correct way to solve a particular problem. Also,
    remember that the explanations shown here include only the most interesting and
    important details needed to solve the problems. Download the example solutions
    to see additional details and to experiment with the programs at [https://github.com/PacktPublishing/Java-Coding-Problems-Second-Edition/tree/main/Chapter10](https://github.com/PacktPublishing/Java-Coding-Problems-Second-Edition/tree/main/Chapter10).
  prefs: []
  type: TYPE_NORMAL
- en: 209\. Explaining concurrency vs. parallelism
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before tackling the main topic of this chapter, *structured concurrency*, let’s
    forget about *structure*, and let’s keep only *concurrency*. Next, let’s put *concurrency*
    against *parallelism*, since these two notions are often a source of confusion.
  prefs: []
  type: TYPE_NORMAL
- en: Both of them, concurrency and parallelism, use *tasks* as the main unit of work.
    However, the way that they handle these tasks makes them very different.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of parallelism, a task is split into subtasks across multiple CPU
    cores. These subtasks are computed in parallel, and each of them represents a
    partial solution for the given task. By joining these partial solutions, we obtain
    the solution. Ideally, solving a task in parallel should result in less wall-clock
    time than in the case of solving the same task sequentially. In a nutshell, in
    parallelism, at least two threads run at the same time, which means that parallelism
    can solve a single task faster.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of concurrency, we try to solve as many tasks as possible via several
    threads that compete with each other, progressing in a time-slicing fashion. This
    means that concurrency can complete multiple tasks faster. This is why concurrency
    is also referred to as virtual parallelism.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure depicts parallelism vs. concurrency:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1.png](img/B19665_10_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.1: Concurrency vs. parallelism'
  prefs: []
  type: TYPE_NORMAL
- en: In parallelism, tasks (subtasks) are part of the implemented solution/algorithm.
    We write the code, set/control the number of tasks, and use them in a context
    that has parallel computational capabilities. On the other hand, in concurrency,
    tasks are part of the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, we measure parallelism efficiency in *latency* (the amount of time
    needed to complete the task), while the efficiency of concurrency is measured
    in *throughput* (the number of tasks that we can solve).
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, in parallelism, tasks control resource allocation (CPU time, I/O operations,
    and so on). On the other hand, in concurrency, multiple threads compete with each
    other to gain as many resources (I/O) as possible. They cannot control resource
    allocation.
  prefs: []
  type: TYPE_NORMAL
- en: In parallelism, threads operate on CPU cores in such a way that every core is
    busy. In concurrency, threads operate on tasks in such a way that, ideally, each
    thread has a separate task.
  prefs: []
  type: TYPE_NORMAL
- en: 'Commonly, when parallelism and concurrency are compared, somebody comes and
    says: *How about asynchronous methods?*'
  prefs: []
  type: TYPE_NORMAL
- en: It is important to understand that *asynchrony* is a separate concept. Asynchrony
    is about the capability to accomplish non-blocking operations. For instance, an
    application sends an HTTP request, but it doesn’t just wait for the response.
    It goes and solves something else (other tasks) while waiting for the response.
    We do asynchronous tasks every day. For instance, we start the washing machine
    and then go to clean other parts of the house. We don’t just wait by the washing
    machine until it is finished.
  prefs: []
  type: TYPE_NORMAL
- en: 210\. Introducing structured concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are as old as I am, then most probably you started programming with a
    language such as BASIC or a similar unstructured programming language. At that
    time, an application was just a sequence of lines that defined a sequential logic/behavior
    via a bunch of GOTO statements, driving the flow by jumping like a kangaroo back
    and forward between the code lines. Well, in Java, the building blocks of a typical
    concurrent code are so primitive that the code looks somewhat like unstructured
    programming because it is hard to follow and understand. Moreover, a thread dump
    of a concurrent task doesn’t provide the needed answers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s follow a snippet of Java concurrent code and stop every time we have
    a question (always check the code below the question). The task is to concurrently
    load three testers by ID and team them up in a testing team. First, let’s list
    the server code (we will use this simple code to serve us in this problem and
    subsequent problems):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, the code that we are especially interested in starts as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*First stop*: As you can see, `buildTestingTeam()` throws an `InterruptedException`.
    So if the thread executing `buildTestingTeam()` gets interrupted, how can we easily
    interrupt the following threads?'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '*Second stop*: Here, we have three `get()` calls. So the current thread waits
    for other threads to complete. Can we easily observe those threads?'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*Third stop:* If an `ExecutionException` is caught, then we know that one of
    these three `Future` instances has failed. Can we easily cancel the remaining
    two, or will they just hang on there? `future1` will probably fail while `future2`
    and `future3` will complete successfully, or maybe `future2` will complete successfully
    while `future3` will just run forever (a so-called *orphan* thread). This can
    lead to serious mismatches in the expected results, memory leaks, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '*Fourth stop*: The next line of code is used to shut down the `executor`, but
    it is so easy to overlook. Is this the proper place to do this?'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '*Fifth stop*: If you didn’t spot the previous line of code, then it is legitimate
    to ask yourself how/where this executor got shut down:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We skip the rest of the code, since you can find it in the bundled code.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we can implement code answers to each of these questions via error
    handling, task abandons and abortions, `ExecutorService`, and so on, but this
    means a lot of work for the developer. Writing failsafe solutions that carefully
    cover all possible scenarios across multiple tasks/subtasks while tracking their
    progress in a concurrent environment is not an easy job. That’s not to mention
    how hard it is to understand and maintain the resulting code by another developer,
    or even the same developer after 1–2 years or even months.
  prefs: []
  type: TYPE_NORMAL
- en: It is time to add some structure to this code, so let’s introduce *structured
    concurrency* (or Project Loom).
  prefs: []
  type: TYPE_NORMAL
- en: '*Structured concurrency* relies on several pillars meant to bring lightweight
    concurrency to Java. The fundamental pillar or principle of structured concurrency
    is highlighted next.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important note**'
  prefs: []
  type: TYPE_NORMAL
- en: The fundamental principle of structured concurrency is that when a task has
    to be solved concurrently, then all the threads needed to solve it are spun and
    rejoined in the same block of code. In other words, all these threads’ lifetimes
    are bound to the block’s lexical scope, so we have clear and explicit entry-exit
    points for each concurrent code block.
  prefs: []
  type: TYPE_NORMAL
- en: Based on this principle, the thread that initiates a concurrent context is the
    *parent-thread* or the *owner-thread*. All threads started by the parent-thread
    are *children-threads* or *forks*, so between them, these threads are siblings.
    Together, the parent-thread and the child-threads define a *parent-child hierarchy*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Putting the structured concurrency principle into a diagram will show us the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2.png](img/B19665_10_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.2: Parent-child hierarchy in structured concurrency'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the context of the parent-child hierarchy, we have support for error/exception
    handling with short-circuiting, cancellation propagation, and monitoring/observability:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Error/exception handling with short-circuiting*: If a child-thread fails,
    then all child-threads are canceled unless they are complete. For instance, if
    `futureTester(1)` fails, then `futureTester(2)` and `futureTester(3)` are automatically
    canceled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Cancellation propagation*: If the parent-thread is interrupted until joining
    the child-threads is over, then these forks (the child-threads/subtasks) are canceled
    automatically. For instance, if the thread executing `buildTestingTeam()` gets
    interrupted, then its three forks are automatically canceled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Monitoring/observability*: A thread dump reveals a crystal-clear image of
    the entire parent-child hierarchy, no matter how many levels have been spawned.
    Moreover, in structured concurrency, we take advantage of scheduling and the memory
    management of threads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While these are purely concepts, writing code that respects and follows these
    concepts requires the proper API and the following awesome callout:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3.png](img/B19665_10_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.3: Don’t reuse virtual threads'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cut this out and stick it somewhere so that you see it every day! So in structured
    concurrency, **don’t reuse virtual threads**. I know what you are thinking: *hey
    dude, threads are expensive and limited, so we have to reuse them*. A quick hint:
    we are talking about *virtual threads* (massive throughput), not *classical threads*,
    but the virtual threads topic is covered in the next problem.'
  prefs: []
  type: TYPE_NORMAL
- en: 211\. Introducing virtual threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Java allows us to write multithreaded applications via the `java.lang.Thread`
    class. These are classical Java threads that are basically just thin wrappers
    of OS (kernel) threads. As you’ll see, these classical Java threads are referred
    to as *platform threads*, and they have been available for quite a long time (since
    JDK 1.1, as the following diagram reveals):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4.png](img/B19665_10_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.4: JDK multithreading evolution'
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s move on to JDK 19 virtual threads.
  prefs: []
  type: TYPE_NORMAL
- en: What’s the problem with platform (OS) threads?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: OS threads are expensive in every single way, or more specifically, they are
    costly in terms of time and space. Creating OS threads is, therefore, a costly
    operation that requires a lot of stack space (around 20 megabytes) to store their
    context, Java call stacks, and additional resources. Moreover, the OS thread scheduler
    is responsible for scheduling Java threads, which is another costly operation
    that requires moving around a significant amount of data. This is referred to
    as *thread context switching.*
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following figure, you can see the one-to-one relationship between a
    Java thread and an OS thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4.png](img/B19665_10_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.5: JVM to OS threads'
  prefs: []
  type: TYPE_NORMAL
- en: For decades, our multithreaded applications have run in this context. All this
    time and experience taught us that we can create a limited number of Java threads
    (because of low throughput) and that we should reuse them wisely. The number of
    Java threads is a limiting factor that is usually exhausted before other resources,
    such as network connections, CPU, and so on. Java doesn’t differentiate between
    threads that perform intensive computational tasks (i.e., threads that really
    exploit the CPU) or those that just wait for data (i.e., they just hang on the
    CPU).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s do a quick exercise. Let’s assume that our machine has 8 GB of memory,
    and a single Java thread needs 20 MB. This means that we have room for around
    400 Java threads (8 GB = 8,000 MB / 20 MB = 400 threads). Next, let’s assume that
    these threads perform I/O operations over a network. Each I/O operation needs
    around 100 ms to complete, while the request preparation and response processing
    needs around 500 ns. So a thread works for 1,000 ns (0.001 ms) and then waits
    for 100 ms (100,000,000 ns) for the I/O operation to complete. This means that
    at 8 GB of memory, the 400 threads will use 0.4% of CPU availability (under 1%),
    which is very low. We can conclude that a thread is idle for 99.99% of the time.
  prefs: []
  type: TYPE_NORMAL
- en: Based on this exercise, it is quite obvious that Java threads become a bottleneck
    in throughput that doesn’t allow us to solicit hardware at full capacity. Of course,
    we can sweeten the situation a little bit by using *thread pools* to minimize
    the costs, but it still does not solve the major issues of dealing with resources.
    You have to go for `CompletableFuture`, reactive programming (for instance, Spring
    `Mono` and `Flux`), and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, how many classical Java threads can we create? We can easily find
    out by running a simple snippet of code, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, if we want to taste from the new concurrent API, we can call
    the new `Thread.ofPlatform()` method, as follows (`OfPlatform` is a `sealed` interface,
    introduced in JDK 19):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: On my machine, I got an `OutOfMemoryError` after around 40,000 Java threads.
    Depending on your OS and hardware, this number may vary.
  prefs: []
  type: TYPE_NORMAL
- en: The `Thread.ofPlatform()` method was added in JDK 19 to easily distinguish between
    Java threads (i.e., classical Java threads as we have known them for decades –
    thin wrappers of OS threads) and the new kids in town, virtual threads.
  prefs: []
  type: TYPE_NORMAL
- en: What are virtual threads?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Virtual threads were introduced in JDK 19 as a preview (JEP 425), and they
    became a final feature in JDK 21 (JEP 444). Virtual threads run on top of platform
    threads in a one-to-many relationship, while the platform threads run on top of
    OS threads in a one-to-one relationship, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5.png](img/B19665_10_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.6: Virtual threads architecture'
  prefs: []
  type: TYPE_NORMAL
- en: If we break this figure down into a few words, then we can say that JDK maps
    a large number of virtual threads to a small number of OS threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before creating a virtual thread, let’s see two important notes that will help
    us to quickly understand the fundamentals of virtual threads. First, let’s have
    a quick note about a virtual thread’s memory footprint:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important note**'
  prefs: []
  type: TYPE_NORMAL
- en: Virtual threads are not wrappers of OS threads. They are lightweight Java entities
    (they have their own stack memory with a small footprint – only a few hundred
    bytes) that are cheap to create, block, and destroy (creating a virtual thread
    is around 1,000 times cheaper than creating a classical Java thread). There can
    be many of them at the same time (millions) so that they sustain a massive throughput.
    Virtual threads should not be reused (they are disposable) or pooled.
  prefs: []
  type: TYPE_NORMAL
- en: When we talk about virtual threads, there are more things that we should unlearn
    than things that we should learn. But where are virtual threads stored, and who’s
    responsible for scheduling them accordingly?
  prefs: []
  type: TYPE_NORMAL
- en: '**Important note**'
  prefs: []
  type: TYPE_NORMAL
- en: Virtual threads are stored in the JVM heap (so they take advantage of Garbage
    Collector) instead of the OS stack. Moreover, virtual threads are scheduled by
    the JVM via a *work-stealing* `ForkJoinPool` scheduler. Practically, JVM schedules
    and orchestrates virtual threads to run on platform threads in such a way that
    a platform thread executes only one virtual thread at a time.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s create a virtual thread.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a virtual thread
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'From the API perspective, a virtual thread is another flavor of `java.lang.Thread`.
    If we dig a little bit via `getClass()`, we can see that a virtual thread class
    is `java.lang.VirtualThread`, which is a `final` non-public class that extends
    the `BaseVirtualThread` class, which, in turn, is a `sealed abstract` class that
    extends `java.lang.Thread`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s consider that we have the following task (`Runnable`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Creating and starting a virtual thread
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We can create and start a virtual thread for our task via the `startVirtualThread(Runnable
    task)` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The returned `vThread` is scheduled for execution by the JVM itself. But we
    can also create and start a virtual thread via `Thread.ofVirtual()`, which returns
    `OfVirtual` (the `sealed` interface introduced in JDK 19), as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Now, `vThread` will solve our `task`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, we have the `Thread.Builder` interface (and `Thread.Builder.OfVirtual`
    subinterface) that can be used to create a virtual thread, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is another example of creating two virtual threads via `Thread.Builder`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: You can check out these examples further in the bundled code.
  prefs: []
  type: TYPE_NORMAL
- en: Waiting for a virtual task to terminate
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The given `task` is executed by a virtual thread, while the main thread is
    not blocked. In order to wait for the virtual thread to terminate, we have to
    call one of the `join()` flavors. We have `join()` without arguments that waits
    indefinitely, and a few flavors that wait for a given time (for instance, `join(Duration
    duration)` and `join(long millis)`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: These methods throw an `InterruptedException`, so you have to catch it and handle
    it (or just throw it). Now, because of `join()`, the main thread cannot terminate
    before the virtual thread. It has to wait until the virtual thread completes.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an unstarted virtual thread
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Creating an unstarted virtual thread can be done via `unstarted(Runnable task)`,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Or via `Thread.Builder` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, the thread is not scheduled for execution. It will be scheduled
    for execution only after we explicitly call the `start()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check if a thread is alive (i.e., it was started but not terminated)
    via the `isAlive()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The `unstarted()` method is available for platform threads as well (there is
    also the `Thread.Builder.OfPlatform` subinterface):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We can start `pThread` by calling the `start()` method.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a ThreadFactory for virtual threads
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'You can create a `ThreadFactory` of virtual threads, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Or, via `Thread.Builder`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'And a `ThreadFactory` for platform threads, as follows (you can use `Thread.Builder`
    as well):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Or a `ThreadFactory` that we can use to switch between virtual/platform threads,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we can use any of these factories via the `ThreadFactory.newThread(Runnable
    task)`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: If the thread factory starts the created thread as well, then there is no need
    to explicitly call the `start()` method.
  prefs: []
  type: TYPE_NORMAL
- en: Checking a virtual thread’s details
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Moreover, we can check if a certain thread is a platform thread or a virtual
    thread via `isVirtual()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Obviously, only `vThread` is a virtual thread.
  prefs: []
  type: TYPE_NORMAL
- en: '*A virtual thread always runs as a daemon thread.* The `isDaemon()` method
    returns `true`, and trying to call `setDaemon(false)` will throw an exception.'
  prefs: []
  type: TYPE_NORMAL
- en: '*The priority of a virtual thread is always* `NORM_PRIORITY` (calling `getPriority()`
    always returns `5` – constant `int` for `NORM_PRIORITY`). Calling `setPriority()`
    with a different value has no effect.'
  prefs: []
  type: TYPE_NORMAL
- en: '*A virtual thread cannot be part of a thread group* because it already belongs
    to the *VirtualThreads* group. Calling `getThreadGroup().getName()` returns *VirtualThreads*.'
  prefs: []
  type: TYPE_NORMAL
- en: A virtual thread has no permission with Security Manager (which is deprecated
    anyway).
  prefs: []
  type: TYPE_NORMAL
- en: Printing a thread (toString())
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If we print a virtual thread (calling the `toString()` method), then the output
    will be something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'In a nutshell, this output can be interpreted as follows: `VirtualThread[#22]`
    indicates that this is a virtual thread that contains the thread identifier (`#22`)
    with no name (in the case of `VirtualThread[#26,vt-0]`, the id is `#26` and the
    name is `vt-0`). Then, we have the `runnable` text, which indicates the state
    of the virtual thread (`runnable` means that the virtual thread is running). Next,
    we have the *carrier thread* of the virtual thread, which is a platform thread;
    `ForkJoinPool-1-worker-1` contains the platform thread name (`worker-1`) of the
    default `ForkJoinPool` (`ForkJoinPool-1`).'
  prefs: []
  type: TYPE_NORMAL
- en: How many virtual threads we can start
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, let’s run code that allows us to see how many virtual threads we can
    create and start:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: On my machine, this code started to slow down after around 14,000,000 virtual
    threads. It continues to run slowly while memory becomes available (Garbage Collector
    is in action), but it didn’t crash. So a massive throughput!
  prefs: []
  type: TYPE_NORMAL
- en: Backward compatibility
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Virtual threads are compatible with:'
  prefs: []
  type: TYPE_NORMAL
- en: Synchronized blocks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread-local variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Thread` and `currentThread()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread interruption (`InterruptedException`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basically, virtual threads work out of the box once you update to at least JDK
    19\. They heavily sustain a clean, readable, and more structured code, being the
    bricks behind the structured concurrency paradigm.
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding fake conclusions (potentially myths)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are a few fake conclusions about virtual threads that we should consider
    as follow:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Virtual threads are faster than platform threads (WRONG!)*: There can be a
    lot of virtual threads, but they are not faster than classical (platform) threads.
    They don’t boost in-memory computational capabilities (for that, we have parallel
    streams). Don’t conclude that virtual threads do some magic that makes them faster
    or more optimal to solve a task. So virtual threads can seriously improve throughput
    (since millions of them can wait for jobs), but they cannot improve latency. However,
    virtual threads can be launched much faster than platform threads (a virtual thread
    has a creation time measured in µs and needs space in the order of kB).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Virtual threads should be pooled (WRONG!)*: Virtual threads should not be
    part of any thread pool and should never be pooled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Virtual threads are expensive (WRONG!)*: Virtual threads are not for free
    (nothing is for free), but they are cheaper to create, block, and destroy than
    platform threads. A virtual thread is 1,000x cheaper than a platform thread.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Virtual threads can release a task (WRONG!)*: This is not true! A virtual
    thread takes a task and will return a result unless it gets interrupted. It cannot
    release the task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Blocking a virtual thread blocks its carrier thread (WRONG!)*: Blocking a
    virtual thread doesn’t block its carrier thread. The carrier thread can serve
    other virtual threads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 212\. Using the ExecutorService for virtual threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Virtual threads allow us to write more expressive and straightforward concurrent
    code. Thanks to the massive throughput obtained via virtual threads, we can easily
    adopt the *task-per-thread* model (for an HTTP server, this means a request per
    thread, for a database, this means a transaction per thread, and so on). In other
    words, we can assign a new virtual thread for each concurrent task.
  prefs: []
  type: TYPE_NORMAL
- en: Trying to use the *task-per-thread* model with platform threads will result
    in a throughput limited by the number of hardware cores – this is explained by
    Little’s law ([https://en.wikipedia.org/wiki/Little%27s_law](https://en.wikipedia.org/wiki/Little%27s_law)),
    L = λW, or throughput equals average concurrency multiplied by latency.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever possible, it is recommended to avoid interacting with threads directly.
    JDK sustains this via the `ExecutorService`/`Executor` API. More precisely, we
    are used to submitting a task (`Runnable`/`Callable`) to an `ExecutorService`/`Executor`
    and working with the returned `Future`. This pattern is valid for virtual threads
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: So we don’t have to write ourselves all the plumbing code to adopt the *task-per-thread
    model* for virtual threads because, starting with JDK 19, this model is available
    via the `Executors` class. More precisely, it’s via the `newVirtualThreadPerTaskExecutor()`
    method, which creates an `ExecutorService` capable of creating an unbounded number
    of virtual threads that follow the *task-per-thread* model. This `ExecutorService`
    exposes methods that allow us to give tasks such as the `submit()` (as you’ll
    see next) and `invokeAll`/`Any()` (as you’ll see later) methods, returning a `Future`
    containing an exception or a result.
  prefs: []
  type: TYPE_NORMAL
- en: '**Important note**'
  prefs: []
  type: TYPE_NORMAL
- en: Starting with JDK 19, the `ExecutorService` extends the `AutoCloseable` interface.
    In other words, we can use `ExecutorService` in a `try-with-resources` pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following simple `Runnable` and `Callable`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Executing the `Runnable`/`Callable` can be done as follows (here, we submit
    15 tasks (`NUMBER_OF_TASKS = 15`)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, in the case of `Runnable`/`Callable`, we can capture a `Future`
    and act accordingly, via the blocking `get()` method or whatever we want to do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'A possible output looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Check out the virtual threads’ IDs. They range between #22 and #37 without
    repetition. Each task is executed by its own virtual thread.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The *task-per-thread* model is also available for classical threads via `newThreadPerTaskExecutor(ThreadFactory
    threadFactory)`. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, `newThreadPerTaskExecutor()` can be used for classic or virtual
    threads. The number of created threads is unbounded. By simply modifying the thread
    factory, we can switch between virtual/classic threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'A possible output looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Check out the threads’ IDs. They range between #75 and #89 without repetition.
    Each task is executed by its own thread.'
  prefs: []
  type: TYPE_NORMAL
- en: 213\. Explaining how virtual threads work
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we know how to create and start a virtual thread, let’s see how they
    actually work.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with a meaningful diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.6.png](img/B19665_10_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.7: How virtual threads work'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, *Figure 10.7* is similar to *Figure 10.6*, except that we have
    added a few more elements.
  prefs: []
  type: TYPE_NORMAL
- en: First of all, notice that the platform threads run under a `ForkJoinPool` umbrella.
    This is a **First-In-First-Out** (**FIFO**) dedicated fork/join pool, dedicated
    to scheduling and orchestrating the relationships between virtual threads and
    platform threads (detailed coverage of Java’s fork/join framework is available
    in *Java Coding Problems*, *First Edition*, *Chapter 11*).
  prefs: []
  type: TYPE_NORMAL
- en: '**Important note**'
  prefs: []
  type: TYPE_NORMAL
- en: 'This dedicated `ForkJoinPool` is controlled by the JVM, and it acts as the
    virtual thread scheduler based on a FIFO queue. Its initial capacity (i.e., the
    number of threads) is equal to the number of available cores, and it can be increased
    to 256\. The default virtual thread scheduler is implemented in the `java.lang.VirtualThread`
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Do not confuse this `ForkJoinPool` with the one used for parallel streams (the
    Common Fork Join Pool - `ForkJoinPool.commonPool()`).
  prefs: []
  type: TYPE_NORMAL
- en: Between the virtual threads and the platform threads, there is a one-to-many
    association. Nevertheless, the JVM schedules virtual threads to run on platform
    threads in such a way that only one virtual thread runs on a platform thread at
    a time. When the JVM assigns a virtual thread to a platform thread, the so-called
    *stack chunk object* of the virtual thread is copied from the heap memory on the
    platform thread.
  prefs: []
  type: TYPE_NORMAL
- en: If the code running on a virtual thread encounters a blocking (I/O) operation
    that should be handled by the JVM, then the virtual thread is released by copying
    its *stack chunk object* back into the heap (this operation of copying the *stack
    chunk* between the heap memory and platform thread is the cost of blocking a virtual
    thread - this is much cheaper than blocking a platform thread). Meanwhile, the
    platform thread can run other virtual threads. When the blocking (I/O) of the
    released virtual thread is done, JVM reschedules the virtual thread for execution
    on a platform thread. This can be the same platform thread or another one.
  prefs: []
  type: TYPE_NORMAL
- en: '**Important note**'
  prefs: []
  type: TYPE_NORMAL
- en: The operation of assigning a virtual thread to a platform thread is called *mounting*.
    The operation of unassigning a virtual thread from the platform thread is called
    *unmounting*. The platform thread running the assigned virtual thread is called
    a *carrier thread*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see an example that reveals how the virtual threads are mounted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'However, we can configure the `ForkJoinPool` via three system properties, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`jdk.virtualThreadScheduler.parallelism` – the number of CPU cores'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`jdk.virtualThreadScheduler.maxPoolSize` – the maximum pool size (256)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`jdk.virtualThreadScheduler.minRunnable` – the minimum number of running threads
    (half the pool size)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a subsequent problem, we will use these properties to better shape *virtual
    thread context switching* (mounting/unmounting) details.
  prefs: []
  type: TYPE_NORMAL
- en: Capturing virtual threads
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have learned that a virtual thread is mounted by the JVM to a platform
    thread, which becomes its carrier thread. Moreover, the carrier thread runs the
    virtual thread until it hits a blocking (I/O) operation. At that point, the virtual
    thread is unmounted from the carrier thread, and it will be rescheduled after
    the blocking (I/O) operation is done.
  prefs: []
  type: TYPE_NORMAL
- en: 'While this scenario is true for most of the blocking operations, resulting
    in unmounting the virtual threads and freeing the platform thread (and the underlying
    OS thread), there are a few exceptional cases when the virtual threads are not
    unmounted. There are two main causes for this behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: Limitations on the OS (for instance, a significant number of filesystem operations)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations on the JDK (for instance, `Object.wait()`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the virtual thread cannot be unmounted from its carrier thread, it means
    that the carrier thread and the underlying OS thread are blocked. This may affect
    the scalability of the application, so if the platform threads pool allows it,
    the JVM can decide to add one more platform thread. So for a period of time, the
    number of platform threads may exceed the number of available cores.
  prefs: []
  type: TYPE_NORMAL
- en: Pinning virtual threads
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are also two other use cases when a virtual thread cannot be unmounted:'
  prefs: []
  type: TYPE_NORMAL
- en: When the virtual thread runs code inside a `synchronized` method/block
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the virtual thread invokes a foreign function or native method (a topic
    covered in *Chapter 7*)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this scenario, we say that the virtual thread is *pinned* to the carrier
    thread. This may affect the scalability of the application, but the JVM will not
    increase the number of platform threads. Instead of this, we should take action
    and refactor the `synchronized` blocks to ensure that the locking code is simple,
    clear, and short. Whenever possible, we should prefer `java.util.concurrent` locks
    instead of `synchronized` blocks. If we manage to avoid long and frequent locking
    periods, then we will not face any significant scalability issues. In future releases,
    the JDK team aims to eliminate the pinning inside `synchronized` blocks.
  prefs: []
  type: TYPE_NORMAL
- en: 214\. Hooking virtual threads and sync code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of this problem is to highlight how virtual threads interact with synchronous
    code. For this, we use the built-in `java.util.concurrent.SynchronousQueue`. This
    is a built-in blocking queue that allows only one thread to operate at a time.
    More precisely, a thread that wants to insert an element in this queue is blocked
    until another thread attempts to remove an element from it, and vice versa. Basically,
    a thread cannot insert an element unless another thread attempts to remove an
    element.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s assume that a virtual thread attempts to insert an element into a `SynchronousQueue`,
    while a platform thread attempts to remove an element from this queue. In code
    lines, we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'So the virtual thread (`vThread`) waits for 5 seconds before attempting to
    insert an element into the queue. However, it will not successfully insert an
    element until another thread attempts to remove an element from this queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the `Thread.currentThread()` refers to the main thread of the application,
    which is a platform thread not blocked by `vThread`. This thread successfully
    removes from the queue only if another thread attempts to insert (here, `vThread`):'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of this code looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The virtual thread started its execution (it is in a *runnable* state), but
    the main thread cannot remove an element from the queue until the virtual thread
    inserts an element, so it is blocked by the `queue.take()` operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Meanwhile, the virtual thread sleeps for 5 seconds (currently, the main thread
    has nothing to do), and afterward, it inserts an element:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The virtual thread has inserted an element into the queue, so the main thread
    can remove this element from it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The virtual thread is also terminated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: So virtual threads, platform threads, and synchronous code work as expected.
    In the bundled code, you can find an example where the virtual and platform threads
    switch places. So the platform thread attempts to insert elements, and the virtual
    thread attempts to remove them.
  prefs: []
  type: TYPE_NORMAL
- en: 215\. Exemplifying thread context switching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Remember that a virtual thread is mounted on a platform thread, and it is executed
    by that platform thread until a blocking operation occurs. At that point, the
    virtual thread is unmounted from the platform thread, and it will be rescheduled
    for execution by the JVM later on after the blocking operation is done. This means
    that, during its lifetime, a virtual thread can be mounted multiple times on a
    different or the same platform thread.
  prefs: []
  type: TYPE_NORMAL
- en: In this problem, let’s write several snippets of code meant to capture and exemplify
    this behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Example 1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the first example, let’s consider the following thread factory that we can
    use to easily switch between the platform and virtual threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we try to execute the following task via 10 platform threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Between the two logging lines, we have a blocking operation (`sleep()`). Next,
    we rely on `newThreadPerTaskExecutor()` to submit 10 tasks that should log their
    details, sleep for 3 seconds, and log again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this code with platform threads reveals the following side-to-side
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.7.png](img/B19665_10_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.8: Using platform threads'
  prefs: []
  type: TYPE_NORMAL
- en: By carefully inspecting this figure, we can see that there is a fixed association
    between these numbers. For instance, the task with ID 5 is executed by `Thread-5`,
    the task with ID 3 by `Thread-3`, and so on. After sleeping (i.e., a blocking
    operation), these numbers are unchanged. This means that while the tasks sleep,
    the threads just hang and wait there. They have no work to do.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s switch from platform threads to virtual threads and then run the code
    again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the output is resumed, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.8.png](img/B19665_10_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.9: Using virtual threads'
  prefs: []
  type: TYPE_NORMAL
- en: This time, we can see that things are more dynamic. For instance, the task with
    ID 5 is started by a virtual thread executed by `worker-6`, but it is finished
    by `worker-4`. The task with ID 3 is started by a virtual thread executed by `worker-4`,
    but it is finished by `worker-6`. This means that, while a task sleeps (a blocking
    operation), the corresponding virtual thread is unmounted, and its worker can
    serve other virtual threads. When the sleeping is over, the JVM schedules the
    virtual thread for execution and is mounted on another (it could also be the same)
    worker. This is also referred to as *thread context switching*.
  prefs: []
  type: TYPE_NORMAL
- en: Example 2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this example, let’s start by limiting the parallelism to 1 (which is like
    having a single core and a single virtual thread):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let’s consider that we have a slow task (we call it slow because it sleeps
    for 5 seconds):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'And then, a fast task (similar to the slow task, but it sleeps for only 1 second):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define two virtual threads to execute these two tasks, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run this code, then the output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'If we analyze this output, we can see that the execution starts the slow task.
    The fast task cannot be executed, since `worker-1` (the only available worker)
    is busy executing the slow task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '`Worker-1` executes the slow task until this task hits the sleeping operation.
    Since this is a blocking operation, the corresponding virtual thread (#22) is
    unmounted from `worker-1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The JVM takes advantage of the fact that `worker-1` is available and pushes
    for the execution of the fast task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The fast task also hits a sleeping operation, and its virtual thread (#24)
    is unmounted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'However, the fast task sleeps for only 1 second, so its blocking operation
    is over before the slow task blocking operation, which is still sleeping. So the
    JVM can schedule the fast task for execution again, and `worker-1` is ready to
    accept it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: At this moment, the fast task is done, and `worker-1` is free. But the slow
    task is still sleeping. After these 5 seconds, the JVM schedules the slow task
    for execution, and `worker-1` is there to take it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Done!
  prefs: []
  type: TYPE_NORMAL
- en: Example 3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This example is just a slight modification of Example 2\. This time, let’s
    consider that the slow task contains a non-blocking operation that runs forever.
    In this case, this operation is simulated via an infinite loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'We have a single worker (`worker-1`), and the fast task is the same as in Example
    2\. If we run this code, the execution hangs on, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: The execution hangs on because the infinite loop is not seen as a blocking operation.
    In other words, the virtual thread of the slow task (#22) is never unmounted.
    Since there is a single worker, the JVM cannot push for the execution of the fast
    task.
  prefs: []
  type: TYPE_NORMAL
- en: If we increase the parallelism from 1 to 2, then the fast task will be successfully
    executed by `worker-2`, while `worker-1` (executing the slow task) will simply
    hang on to a partial execution. We can avoid such situations by relying on a timeout
    join, such as `join(Duration duration)`. This way, after the given timeout, the
    slow task will be automatically interrupted. So pay attention to such scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 216\. Introducing the ExecutorService invoke all/any for virtual threads – part
    1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this problem, we won’t spend time on the basics and, instead, jump right
    into how to use `invokeAll()` and `invokeAny()`. If you need a primer on the `ExecutorService`
    API’s `invokeAll()`/`invokeAny()` functions, then you could consider *Java Coding
    Problems*, *First Edition*, *Chapter 10*, *Problem 207*.
  prefs: []
  type: TYPE_NORMAL
- en: Working with invokeAll()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In a nutshell, `invokeAll()` executes a collection of tasks (`Callable`) and
    returns a `List<Future>` that holds the results/status of each task. The tasks
    can finish naturally or be forced by a given timeout. Each task can finish successfully
    or exceptionally. Upon return, all the tasks that have not been completed yet
    are automatically canceled. We can check out the status of each task via `Future.isDone()`
    and `Future.isCancelled()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Using `invokeAll()` with virtual threads via `newVirtualThreadPerTaskExecutor()`
    (or with `newThreadPerTaskExecutor()`) is straightforward. For instance, here
    we have a simple example of executing three `Callable` instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Have you spotted the `f.state()` call? This API was introduced in JDK 19, and
    it computes the state of a future based on the well-known `get()`, `isDone()`,
    and `isCancelled()`. While we will detail this in a subsequent problem, currently,
    the output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: The three tasks have successfully completed.
  prefs: []
  type: TYPE_NORMAL
- en: Working with invokeAny()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In a nutshell, `invokeAny()` executes a collection of tasks (`Callable`) and
    strives to return a result corresponding to a task that has successfully terminated
    (before the given timeout, if any). All the tasks that have not been completed
    are automatically canceled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Using `invokeAny()` with virtual threads via `newVirtualThreadPerTaskExecutor()`
    is also straightforward (or with `newThreadPerTaskExecutor()`). For instance,
    here we have a simple example of executing three `Callable` instances when we
    are interested in a single result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'A possible output might be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: This output corresponds to the second `Callable`.
  prefs: []
  type: TYPE_NORMAL
- en: In the next problem, we will come up with a more realistic example.
  prefs: []
  type: TYPE_NORMAL
- en: 217\. Introducing the ExecutorService invoke all/any for virtual threads – part
    2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Earlier, in *Problem 210*, we wrote a piece of “unstructured” concurrency code
    to build a testing team of three testers, served by an external server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s try to rewrite the `buildTestingTeam()` method via `invokeAll()`/`Any()`
    and `newVirtualThreadPerTaskExecutor()`. If we rely on `invokeAll()`, then the
    application will attempt to load three testers by ID, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'We have three testers with IDs 1, 2, and 3\. So the output will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: In the next problem, we will see how we can make decisions based on task state.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we can handle the testing phase even with a single tester, then we can rely
    on `invokeAny()`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: This code will return a single result representing one of these three testers.
    If none of them is available, then we will get a `UserNotFoundException`.
  prefs: []
  type: TYPE_NORMAL
- en: 218\. Hooking task state
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Starting with JDK 19, we can rely on `Future.state()`. This method computes
    the state of a `Future` based on the well-known `get()`, `isDone()`, and `isCancelled()`,
    returning a `Future.State` enum entry, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`CANCELLED` – the task was canceled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FAILED` – the task was completed exceptionally (with an exception).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RUNNING` – the task is still running (has not been completed).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SUCCESS` – the task was completed normally with a result (no exception).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following snippet of code, we analyze the state of loading the testing
    team members and act accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: We know that when the execution reaches the `switch` block, the `Future` objects
    should be completely normal or exceptional. So if the current `Future` state is
    `RUNNING`, then this is a really weird situation (possibly a bug), and we throw
    an `IllegalStateException`. Next, if the `Future` state is `SUCCESS` (`fetchTester(2)`),
    then we have a result that can be obtained via `resultNow()`. This method was
    added in JDK 19, and it is useful when we know that we have a result. The `resultNow()`
    method returns immediately without waiting (as `get()`). If the state is `FAILED`
    (`fetchTester(Integer.MAX_VALUE)`), then we log the exception via `exceptionNow()`.
    This method was also added in JDK 19, and it returns immediately the underlying
    exception of a failed `Future`. Finally, if the `Future` was canceled, then there
    is nothing to do. We just report it in the log.
  prefs: []
  type: TYPE_NORMAL
- en: 219\. Combining newVirtualThreadPerTaskExecutor() and streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Streams and `newVirtualThreadPerTaskExecutor()` is a handy combination. Here
    is an example that relies on `IntStream` to submit 10 simple tasks and collect
    the returned `List` of `Future` instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we wait for each `Future` to complete by calling the `get()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Moreover, using stream pipelines is quite useful in combination with `invokeAll()`.
    For instance, the following stream pipeline returns a `List` of results (it filters
    all `Future` instances that haven’t completed successfully):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we can write the following solution (without `mapMulti()`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, if `List<Object>` is all you need, then you can go straight ahead
    via `Future::resultNow`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, you may need to collect all the `Future` that has been completed
    exceptionally. This can be achieved via `exceptionNow()`, as follows (we intentionally
    sneaked into the given `List<Callable>` a `Callable` that will generate an `StringIndexOutOfBoundsException`,
    `() -> "pass02".substring(50)`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'If you don’t prefer `mapMulti()`, then rely on the classical approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: You can find all these examples in the bundled code.
  prefs: []
  type: TYPE_NORMAL
- en: 220\. Introducing a scope object (StructuredTaskScope)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have covered a bunch of problems that use virtual threads directly
    or indirectly via an `ExecutorService`. We already know that virtual threads are
    cheap to create and block and that an application can run millions of them. We
    don’t need to reuse them, pool them, or do any fancy stuff. *Use and throw* is
    the proper and recommended way to deal with virtual threads. This means that virtual
    threads are very useful for expressing and writing asynchronous code, which is
    commonly based on a lot of threads that are capable of blocking/unblocking several
    times in a short period. On the other hand, we know that OS threads are expensive
    to create, very expensive to block, and are not easy to put into an asynchronous
    context.
  prefs: []
  type: TYPE_NORMAL
- en: Before virtual threads (so for many, many years), we had to manage the life
    cycle of OS threads via an `ExecutorService`/`Executor`, and we could write asynchronous
    (or reactive) code via *callbacks* (you can find detailed coverage of asynchronous
    programming in *Java Coding Problems*, *First Edition*, *Chapter 11*).
  prefs: []
  type: TYPE_NORMAL
- en: However, asynchronous/reactive code is hard to write/read, very hard to debug
    and profile, and almost deadly hard to unit-test. Nobody wants to read and fix
    your asynchronous code! Moreover, once we start to write an application via asynchronous
    callback, we tend to use this model for all tasks, even for those that shouldn’t
    be asynchronous. We can easily fall into this trap when we need to somehow link
    asynchronous code/results to non-asynchronous code. And the easiest way to do
    it is to go only for asynchronous code.
  prefs: []
  type: TYPE_NORMAL
- en: So is there a better way? Yes, there is! Structured concurrency is the answer.
    Structured concurrency started as an *incubator* project and reached the *preview*
    stage in JDK 21 (JEP 453).
  prefs: []
  type: TYPE_NORMAL
- en: 'And, in this context, we should introduce `StructuredTaskScope`. A `StructuredTaskScope`
    is a virtual thread launcher for `Callable` tasks that returns a `Subtask`. A
    subtask is an extension of the well-known `Supplier<T>` functional interface represented
    by the `StructuredTaskScope.Subtask<T>` interface and forked with `StructuredTaskScope.fork(Callable
    task)`. It follows and works based on the fundamental principle of structured
    concurrency (see *Problem 210*): “*When a task has to be solved concurrently,
    then all the threads needed to solve it are spun and rejoined in the same block
    of code. In other words, all these threads’ lifetimes are bound to the block’s
    scope, so we have clear and explicit entry-exit points for each concurrent code
    block*.” These threads are responsible for running subtasks (`Subtask`) of the
    given task as a single unit of work.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at an example of fetching a single tester (with ID 1) from our web
    server via `StructuredTaskScope`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we create a `StructuredTaskScope` in a `try-with-resources` pattern.
    `StructuredTaskScope` implements `AutoCloseable`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'The `scope` is a wrapper for the virtual threads’ lifetimes. We use the `scope`
    to fork as many virtual threads (subtasks) as needed via the `fork(Callable task)`
    method. Here, we fork only one virtual thread and get back a `Subtask` (forking
    is a non-blocking operation):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: Next, we have to call the `join()` method (or `joinUntil(Instant deadline)`).
    This method waits for all threads (all `Subtask` instances) forked from this `scope`
    (or all threads that have been submitted to this `scope`) to complete, so it is
    a blocking operation. A scope should block only while it waits for its subtasks
    to complete, and this happens via `join()` or `joinUntil()`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'When the execution passes this line, we know that all threads (all forked `Subtask`)
    forked from this `scope` are complete, with a result or an exception (each subtask
    runs independently, so each of them can complete with a result or an exception).
    Here, we call the non-blocking `get()` method to get the result, but pay attention
    – calling `get()` for a task that did not complete will raise an exception as
    `IllegalStateException(`*"Owner did not join after forking subtask"*`)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: On the other hand, we can obtain the exception of a failed task via `exception()`.
    However, if we call `exception()` for a subtask (`Subtask`) that is completed
    with a result, then we will get back an exception as `IllegalStateException(`*"Subtask
    not completed or did not complete with exception"*`)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'So if you are not sure whether your task(s) completed with a result or an exception,
    it is better to call `get()` or `exception()` only after you test the state of
    the corresponding `Subtask`. A state of `SUCCESS` will safely allow you to call
    `get()`, while a state of `FAILED` will safely allow you to call `exception()`.
    So in our case, we may prefer it this way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: Besides `Subtask.State.SUCCESS` and `Subtask.State.FAILED`, we also have `Subtask.State.UNAVAILABLE`,
    which means that the subtask is not available (for instance, if the subtask is
    still running, then its state is `UNAVAILABLE`, but there could be another cause
    as well).
  prefs: []
  type: TYPE_NORMAL
- en: ExecutorService vs. StructuredTaskScope
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The previous code looks like the code that we would write via a classical `ExecutorService`,
    but there are two big differences between these solutions. First of all, an `ExecutorService`
    holds the precious platform threads and allows us to pool them. On the other hand,
    a `StructuredTaskScope` is just a thin launcher for virtual threads that are cheap
    and shouldn’t be pooled. So once we’ve done our job, a `StructuredTaskScope` can
    be destroyed and garbage-collected. Second, an `ExecutorService` holds a single
    queue for all the tasks, and the threads take from this queue whenever they have
    the chance to do so. A `StructuredTaskScope` relies on a fork/join pool, and each
    virtual thread has its own wait queue. However, a virtual thread can steal a task
    from another queue as well. This is known as the *work-stealing* pattern, and
    if you want to read more about it, we covered it in depth in *Java Coding Problem*,
    *First Edition*, *Chapter 11*.
  prefs: []
  type: TYPE_NORMAL
- en: 221\. Introducing ShutdownOnSuccess
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous problem, we introduced `StructuredTaskScope` and used it to
    solve a task via a single virtual thread (a single `Subtask`). Basically, we fetched
    the tester with ID 1 from our server (we had to wait until this one was available).
    Next, let’s assume that we still need a single tester, but not mandatorily the
    one with ID 1\. This time, it could be any of IDs 1, 2, or 3\. We simply take
    the first one that is available from these three, and we cancel the other two
    requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Especially for such scenarios, we have an extension of `StructuredTaskScope`
    called `StructuredTaskScope.ShutdownOnSuccess`. This scope is capable of returning
    the result of the first task that completes successfully and interrupts the rest
    of the threads. It follows the “invoke any” model and can be used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: Here, we fork three subtasks (threads) that will compete with each other to
    complete. The first subtask (thread) that completes successfully wins and returns.
    The `result()` method returns this result (if none of the subtasks (threads) complete
    successfully, then it throws an `ExecutionException`).
  prefs: []
  type: TYPE_NORMAL
- en: 'If we check the state of these three `Subtask`, we can see that one succeeds
    while the other two are unavailable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, you don’t need the code that checks/prints the state of each `Subtask`.
    It was added here just to highlight how `ShutdownOnSuccess` works. You don’t even
    need the explicit `Subtask` objects, since we don’t call `get()` or anything else
    from this API. Basically, we can reduce the code to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: Done! You just create the scope, fork your subtasks, call `join()`, and collect
    the result. So the scope is really business-focused.
  prefs: []
  type: TYPE_NORMAL
- en: A task that completes exceptionally under the `ShutdownOnSuccess` umbrella will
    never be chosen to produce a result. However, if all tasks complete exceptionally,
    then we will get an `ExecutionException` that wraps the exception (i.e., the cause)
    of the first completed task.
  prefs: []
  type: TYPE_NORMAL
- en: 222\. Introducing ShutdownOnFailure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As its name suggests, `StructuredTaskScope.ShutdownOnFailure` is capable of
    returning the exception of the first subtask that completes exceptionally and
    interrupts the rest of the subtasks (threads). For instance, we may want to fetch
    the testers with IDs 1, 2, and 3\. Since we need exactly these three testers,
    we want to be informed if any of them are not available and, if so, cancel everything
    (i.e., the remaining threads). The code looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we intentionally replaced ID 3 with `Integer.MAX_VALUE`. Since
    there is no tester with this ID, the server will throw `UserNotFoundException`.
    This means that the states of the subtasks will reveal that the third subtask
    has failed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'Moreover, when we call the `exception()` method, we will get back an `Optional<Throwable>`
    containing this exception (if you’re interested in reading more about this subject,
    in-depth coverage of the `Optional` feature is available in *Java Coding Problems*,
    *First Edition*, *Chapter 12*). If we decide to throw it, then we simply call
    the `throwIfFailed()` method, which wraps the original exception (the cause) in
    an `ExecutionException` and throws it. The message of the exception in our case
    will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'If we remove the guideline code, then we can compact the previous code, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: If no exception occurs, then `throwIfFailed()` doesn’t do anything, and those
    three testers are available. The result of each `Subtask` is available via the
    non-blocking `Subtask.get()`.
  prefs: []
  type: TYPE_NORMAL
- en: A subtask that completes exceptionally under the `ShutdownOnFailure` umbrella
    will be chosen to produce an exception. However, if all subtasks complete normally,
    then we will not get any exceptions. On the other hand, if no subtasks were completed
    exceptionally but were canceled, then `ShutdownOnFailure` will throw `CancellationException`.
  prefs: []
  type: TYPE_NORMAL
- en: 223\. Combining StructuredTaskScope and streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you prefer functional programming, then you’ll be happy to see that streams
    can be used with `StructuredTaskScope` as well. For instance, here we rewrite
    the application from *Problem 221*, using a stream pipeline to fork our tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'Moreover, we can use stream pipelines to collect results and exceptions, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: You can find these examples in the bundled code.
  prefs: []
  type: TYPE_NORMAL
- en: 224\. Observing and monitoring virtual threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Observing and monitoring virtual threads can be done in several ways. First,
    we can use **Java Flight Recorder** (**JFR**) – we introduced this tool in *Chapter
    6*, *Problem 143*.
  prefs: []
  type: TYPE_NORMAL
- en: Using JFR
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Among its reach list of events, JFR can monitor and record the following events
    related to virtual threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '`jdk.VirtualThreadStart` – this event is recorded when a virtual thread starts
    (by default, it is disabled)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`jdk.VirtualThreadEnd` – this event is recorded when a virtual thread ends
    (by default, it is disabled)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`jdk.VirtualThreadPinned` – this event is recorded when a virtual thread is
    parked while pinned (by default, it is enabled with a threshold of 20 ms)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`jdk.VirtualThreadSubmitFailed` – this event is recorded if a virtual thread
    cannot be started or unparked (by default, it is enabled)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can find all the JFR events at [https://sap.github.io/SapMachine/jfrevents/](https://sap.github.io/SapMachine/jfrevents/).
  prefs: []
  type: TYPE_NORMAL
- en: 'We start configuring JFR to monitor the virtual threads, by adding to the root
    folder of the application the following `vtEvent.jfc` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let’s consider the following code (basically, this is the application
    from Problem 216):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: Next, we use `-XX:StartFlightRecording=filename=recording.jfr` to instruct JFR
    to record output in a file named `recording.jfr`, and we continue with `settings=vtEvent.jfc`
    to highlight the configuration file listed previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'So the final command is the one from this figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.10.png](img/B19665_10_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.10: Running JFR'
  prefs: []
  type: TYPE_NORMAL
- en: 'JFR has produced a file named `recording.jfr`. We can easily view the content
    of this file via the JFR CLI. The command (`jfr print recording.jfr`) will display
    the content of `recording.jfr`. The content is too large to be listed here (it
    contains three entries for `jdk.VirtualThreadStart` and three for `jdk.VirtualThreadEnd`),
    but here is the event specific to starting a virtual thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.11.png](img/B19665_10_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.11: JFR event to start a virtual thread'
  prefs: []
  type: TYPE_NORMAL
- en: 'And, in the next figure, you can see the event recorded to end this virtual
    thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.12.png](img/B19665_10_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.12: JFR event to end a virtual thread'
  prefs: []
  type: TYPE_NORMAL
- en: Besides the JFR CLI, you can use more powerful tools to consume the virtual
    thread events, such as JDK Mission Control ([https://www.oracle.com/java/technologies/jdk-mission-control.html](https://www.oracle.com/java/technologies/jdk-mission-control.html))
    and the well-known Advanced Management Console ([https://www.oracle.com/java/technologies/advancedmanagementconsole.html](https://www.oracle.com/java/technologies/advancedmanagementconsole.html)).
  prefs: []
  type: TYPE_NORMAL
- en: To get a stack trace for threads that block while pinned, we can set the system
    property, `jdk.tracePinnedThreads`. A complete (verbose) stack trace is available
    via `-Djdk.tracePinnedThreads=full`, or if all you need is a brief/short stack
    trace, then rely on `-Djdk.tracePinnedThreads=short`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, we can easily get a pinned virtual thread by marking the `fetchTester()`
    method as `synchronized` (remember that a virtual thread cannot be unmounted if
    it runs code inside a `synchronized` method/block):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'In this context, JFR will record a pinned virtual thread, as shown in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.12.png](img/B19665_10_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.13: JFR event for a pinned virtual thread'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we run the application with `-Djdk.tracePinnedThreads=full`, then your IDE
    will print a detailed stack trace that starts as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see the complete output by executing the bundled code. Of course, you
    can get a thread dump and analyze it via several other tools. You may prefer any
    of `jstack`, **Java Mission Control** (**JMC**), `jvisualvm`, or `jcmd`. For instance,
    we can obtain a thread dump in plain text or the JSON format via `jcmd`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: Next, let’s play with `jconsole` (JMX) to quickly analyze the performance of
    virtual threads.
  prefs: []
  type: TYPE_NORMAL
- en: Using Java Management Extensions (JMX)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Until JDK 20 (inclusive), JMX provided support for monitoring only the platform
    and threads. However, we can still use JMX to observe the performance brought
    by virtual threads in comparison with platform threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, we can use JMX to monitor platform threads at 500 ms each, via
    the following snippet of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: We rely on this code in the following three scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Running 10,000 tasks via the cached thread pool executor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'On my machine, it took 8,147 ms (8 seconds) to run these 10,000 tasks, using
    at peak 7,729 platform threads. The following screenshot from `jconsole` (JMX)
    reveals this information:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.12.png](img/B19665_10_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.14: Running 10,000 tasks via the cached thread pool executor'
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s repeat this test via a fixed thread pool.
  prefs: []
  type: TYPE_NORMAL
- en: Running 10,000 tasks via the fixed thread pool executor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Depending on your machine, the previous test may finish successfully, or it
    may result in an `OutOfMemoryError`. We can avoid this unpleasant scenario by
    using a fixed thread pool. For instance, let’s limit the number of platform threads
    to 200 via the following snippet of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'On my machine, it took 50,190 ms (50 seconds) to run these 10,000 tasks, using
    at peak 216 platform threads. The following screenshot from JMX reveals this information:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.13.png](img/B19665_10_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.15: Running 10,000 tasks via the fixed thread pool executor'
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, a smaller number of platform threads is reflected in performance.
    If we put 216 workers to do the job of 7,729 workers, of course, it will take
    longer. Next, let’s see how virtual threads will handle this challenge.
  prefs: []
  type: TYPE_NORMAL
- en: Running 10,000 tasks via the virtual thread per task executor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This time, let’s see how the `newVirtualThreadPerTaskExecutor()` can handle
    these 10,000 tasks. The code is straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'On my machine, it took 3,519 ms (3.5 seconds) to run these 10,000 tasks, using
    at peak 25 platform threads. The following screenshot from JMX reveals this information:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.14.png](img/B19665_10_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.16: Running 10000 tasks via the virtual thread per task executor'
  prefs: []
  type: TYPE_NORMAL
- en: Wow! How cool is this?! The resulting time is far and away the best in comparison
    with the previous tests, and it uses fewer resources (only 25 platform threads).
    So virtual threads really rock!
  prefs: []
  type: TYPE_NORMAL
- en: 'I also strongly recommend you check out the following benchmark: [https://github.com/colincachia/loom-benchmark/tree/main](https://github.com/colincachia/loom-benchmark/tree/main).'
  prefs: []
  type: TYPE_NORMAL
- en: Starting with JDK 21, JMX’s `HotSpotDiagnosticMXBean` was enriched with the
    `dumpThreads(String outputFile, ThreadDumpFormat format)` method. This method
    outputs a thread dump to the given file (`outputFile`) in the given format (`format`).
    The thread dump will contain all platform threads, but it may also contain some
    or all virtual threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we attempt to obtain a thread dump for all subtasks
    (threads) of a `StructuredTaskScope`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'The output file is named `threadDump.json`, and you can find it in the root
    folder of the application. The part of the output that we are interested in is
    partially listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, we have three virtual threads (#22, #24, and #25) that run
    subtasks of our scope. In the bundled code, you can find the complete output.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covered 16 introductory problems about virtual threads and structured
    concurrency. You can see this chapter as preparation for the next one, which will
    cover more detailed aspects of these two topics.
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://discord.gg/8mgytp5DGQ](https://discord.gg/8mgytp5DGQ )'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code1139613064111216156.png)'
  prefs: []
  type: TYPE_IMG
