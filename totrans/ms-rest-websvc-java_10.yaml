- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing Strategies for Robust APIs
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While researching and drafting this chapter, we had a completely different vision
    in mind. The original plan was to write a traditional piece on testing APIs, a
    structured, methodical exploration of established practices. The focus was going
    to be on the tools and techniques that have been staples of **API testing** for
    years, such as Postman, Bruno, and various mocking frameworks. These tools have
    been essential in helping engineers ensure API reliability and are still widely
    used, particularly in projects with legacy systems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: However, the more we thought about the topic, it became clear that the landscape
    of software testing has undergone a significant shift. The rise of **generative
    AI** and **large language models** ( **LLMs** )—such as ChatGPT, Gemini, and similar
    tools—has fundamentally transformed how we approach software development, including
    testing. What was once a slow and often repetitive process has now evolved into
    a dynamic, AI-enhanced workflow. Generative AI doesn’t just make writing tests
    faster; it makes the entire process more engaging, efficient, and effective.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: This transformation isn’t just about convenience. The integration of generative
    AI into API testing has far-reaching benefits for everyone involved in the software
    development lifecycle. Engineers can now focus on higher-level problem solving
    rather than being bogged down by tedious test creation. Product managers and owners
    gain greater confidence in the quality of their APIs, knowing that testing has
    become more thorough and adaptive. The results are more meaningful, ensuring that
    APIs meet real-world needs while maintaining the highest quality standards.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: This chapter, therefore, is not the one originally set out to be written. We
    have shifted focus entirely to reflect this new reality. Here, we’ll explore how
    generative AI can revolutionize the way we write tests for APIs, providing insights
    and techniques to help you leverage this game-changing technology. By embracing
    these advancements, we can create better APIs, foster collaboration, and deliver
    software that exceeds expectations.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Types of tests
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test format and tooling
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prompt engineering for testing
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing a development environment
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running and evolving the code
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the advantages of focusing on these new ideas for integration and regression
    tests is in tools and installations. If you can run a JavaJUnit test on your local
    machine, you already have everything needed to run a test.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: We will also utilize Docker to deploy our applications and dependencies locally.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: You will also need access to an LLM. Any of the freely available LLMs should
    work well (ChatGPT, Gemini, Claude, …).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Types of tests
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With a few minutes of online search, one can identify 19 different types of
    tests commonly referenced in the industry, and I’m sure there are a few more:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '**Functional testing** : Validates that the API functions as expected by checking
    its behavior against specified requirements'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**功能测试**：通过检查其行为是否符合特定要求来验证API按预期工作'
- en: '**Integration testing** : Ensures the API interacts correctly with other software
    components, systems, or APIs'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成测试**：确保API与其他软件组件、系统或API正确交互'
- en: '**Unit testing** : Tests individual units or components of the API in isolation'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单元测试**：在隔离状态下测试API的各个单元或组件'
- en: '**Performance testing** : Evaluates the API’s responsiveness, scalability,
    and stability under different conditions'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能测试**：评估API在不同条件下的响应性、可扩展性和稳定性'
- en: '**Load testing** : Checks how the API handles expected user traffic'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负载测试**：检查API如何处理预期的用户流量'
- en: '**Stress testing** : Pushes the API beyond its limits to find breaking points'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**压力测试**：将API推向极限以找到破坏点'
- en: '**Spike testing** : Assesses the API’s reaction to sudden traffic spikes'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**峰值测试**：评估API对突然流量激增的反应'
- en: '**Soak testing** : Monitors the API’s performance over an extended period under
    sustained load'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '** soak测试**：在持续负载下监控API的长时间性能'
- en: '**Security testing** : Ensures the API is secure from vulnerabilities and unauthorized
    access'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全测试**：确保API免受漏洞和未经授权的访问'
- en: '**Validation testing** : Verifies the API meets the expected system and business
    requirements as a whole'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证测试**：验证API作为一个整体满足预期的系统和企业需求'
- en: '**Usability testing** : Ensures the API is easy to understand and use by developers'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可用性测试**：确保API易于开发者理解和使用'
- en: '**Regression testing** : Ensures new changes or updates to the API do not break
    existing functionality'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归测试**：确保API的新更改或更新不会破坏现有功能'
- en: '**Compliance testing** : Verifies the API meets specific legal, regulatory,
    or industry standards'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合规性测试**：验证API符合特定的法律、法规或行业标准'
- en: '**Exploratory testing** : Performs unscripted interactions with the API to
    uncover unexpected issues'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**探索性测试**：通过与非脚本化的API交互来发现意外问题'
- en: '**Interoperability testing** : Verifies the API works correctly with different
    platforms, languages, and environments'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**互操作性测试**：验证API与不同平台、语言和环境正确工作'
- en: '**Fuzz testing** : Identifies vulnerabilities by sending random, malformed,
    or unexpected data to the API'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模糊测试**：通过向API发送随机、格式错误或意外的数据来识别漏洞'
- en: '**End-to-end testing** : Validates entire workflows or user scenarios involving
    the API'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端到端测试**：验证涉及API的整个工作流程或用户场景'
- en: '**Data testing** : Ensures the integrity and correctness of the data processed
    or stored by the API'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据测试**：确保API处理或存储的数据的完整性和正确性'
- en: '**Mock and sandbox testing** : Tests API functionality in isolation or simulates
    environments without impacting live systems'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模拟和沙箱测试**：在隔离状态下测试API功能或模拟不影响实时系统的环境'
- en: 'Clearly, a comprehensive discussion on all these types of testing would require
    an entire book or more. Therefore, in this chapter, we will focus on a few specific
    types of testing: functional, regression, and validation tests.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，对所有这些测试类型的全面讨论需要一本书或更多。因此，在本章中，我们将重点关注几种特定的测试类型：功能测试、回归测试和验证测试。
- en: Why these specific types of tests? Well, as stated earlier, the main goal is
    to help software engineers create better APIs. Among the various types of tests,
    functional, regression, and validation provide the most value in achieving this
    goal. Their primary benefit is the confidence they instill when making changes.
    One of the biggest challenges software engineers face is the unpredictable consequences
    of modifying code. Changes needed to address one problem might inadvertently break
    something else. This problem is both common and paralyzing. How can we ensure
    that our changes won’t disrupt existing functionality? By prioritizing functional
    and regression testing, we can tackle this concern head-on, ensuring the API continues
    to meet its requirements while safeguarding against unintended consequences introduced
    by new changes. This is the essence of the **test-driven development** ( **TDD**
    ) methodology that started in the early 2000s.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么选择这些特定的测试类型？正如之前所述，主要目标是帮助软件工程师创建更好的API。在各种类型的测试中，功能测试、回归测试和验证测试在实现这一目标方面提供了最大的价值。它们的主要好处是它们在做出更改时提供的信心。软件工程师面临的最大挑战之一是修改代码可能带来的不可预测的后果。为了解决一个问题而需要的更改可能会无意中破坏其他东西。这个问题既普遍又令人瘫痪。我们如何确保我们的更改不会破坏现有的功能？通过优先考虑功能测试和回归测试，我们可以直接应对这一担忧，确保API继续满足其要求，同时保护不受新更改引入的不预期的后果。这正是始于2000年代初的**测试驱动开发**（**TDD**）方法的核心。
- en: However, creating and maintaining comprehensive test sets is a resource-intensive
    process, both in terms of time and cost. Writing effective tests requires a deep
    understanding of the system, careful planning, and meticulous implementation.
    Once written, these tests must be regularly updated and adapted to reflect changes
    in the system, which adds to the ongoing maintenance effort. This level of investment
    can be difficult for organizations to justify, especially in fast-paced environments
    where tight deadlines and budget constraints are common. As a result, many projects
    have historically deprioritized testing, often preventing development teams from
    dedicating the time and resources needed to build robust test suites. This short-sighted
    approach may save effort in the short term but often leads to higher costs later
    when defects surface, affecting system reliability and customer satisfaction.
    Also, let’s be honest—writing tests can be boring, and it’s a sentiment shared
    by many in the industry.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，创建和维护全面的测试集是一个资源密集型的过程，无论是从时间还是成本上讲。编写有效的测试需要深入理解系统、周密的规划和细致的实施。一旦编写完成，这些测试必须定期更新和调整，以反映系统中的变化，这增加了持续维护的工作量。这种程度的投资可能对组织来说很难证明其合理性，尤其是在快节奏的环境中，那里通常有严格的截止日期和预算限制。因此，许多项目历史上都降低了测试的优先级，这往往阻碍了开发团队投入所需的时间和资源来构建健壮的测试套件。这种短视的方法可能在短期内节省了精力，但往往会导致后期出现缺陷时成本更高，影响系统的可靠性和客户满意度。坦白说——编写测试可能很无聊，这在业界是许多人的共同感受。
- en: Then, in November of 2022, the introduction of generative AI completely transformed
    the creation of software tests. Generative AI has become an incredible asset in
    writing tests. While there’s an ongoing debate about its impact on developing
    actual business logic—a discussion for another time—for testing purposes, it’s
    a phenomenal tool. We will leverage generative AI extensively to write our tests
    and assist in their development. This innovation not only enhances the value of
    functional and regression testing for software engineers but also makes these
    tests much easier and cheaper to write.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在2022年11月，生成式AI的引入彻底改变了软件测试的创建。生成式AI在编写测试方面已成为一个难以置信的宝贵资产。虽然关于其对开发实际业务逻辑的影响的争论仍在进行中——这是一个留待以后讨论的话题——但对于测试目的而言，它是一个非凡的工具。我们将广泛利用生成式AI来编写我们的测试并协助其开发。这一创新不仅增强了功能测试和回归测试对软件工程师的价值，而且使这些测试的编写变得更加容易和便宜。
- en: Test format and tooling
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试格式和工具
- en: When it comes to testing APIs, we have access to a variety of tools and formats,
    each serving different needs and levels of expertise. Tools such as Postman and
    Bruno provide user-friendly interfaces for building, managing, and running API
    tests. These tools are especially useful for quick exploratory testing or for
    creating manual test workflows. They excel in environments where visual representation
    and non-technical collaboration are essential. However, when we shift our focus
    to automated, scalable, and pipeline-ready testing, tools such as JUnit, which
    are integrated directly into the development ecosystem, offer significant advantages.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Tools such as Postman allow users to design API tests with minimal coding, making
    them accessible to a broader audience. These tools often include features such
    as sharing test collections, generating test documentation, and providing real-time
    visual results. Despite these strengths, they fall short when integrated into
    sophisticated CI/CD pipelines. Exporting and running tests from Postman or Bruno
    often require additional tooling or manual steps, and they lack the seamless compatibility
    with source control systems such as Git that code-based testing frameworks offer.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast, JUnit, a widely used testing framework for Java, provides a code-first
    approach to testing APIs. By writing API tests directly in Java using JUnit, developers
    can ensure their tests are treated as part of the source code. This approach brings
    several advantages:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '**Integration into deployment pipelines** : JUnit tests are inherently compatible
    with CI/CD tools such as Jenkins, GitHub Actions, and GitLab CI. This allows API
    tests to run automatically during builds or deployments, ensuring that no changes
    go live without thorough testing.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Leverage of source code infrastructure** : Because JUnit tests are written
    in pure code, they benefit from the same tools and workflows used for the application
    code itself—version control, peer reviews, static analysis, and more. This consistency
    reduces complexity and ensures tests are always in sync with the application.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability and maintainability** : Code-based tests are easier to maintain
    as they evolve alongside the application. Refactoring tools, IDE features, and
    linters help developers quickly adapt tests when APIs change, minimizing the risk
    of outdated or broken tests.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reusability and customization** : JUnit enables developers to write reusable
    test helpers and utilities, providing greater flexibility for complex testing
    scenarios. It also supports advanced features such as parameterized tests, mock
    environments, and dependency injections.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, JUnit’s ability to directly call real APIs—whether deployed locally
    or in a test environment—ensures that tests mimic real-world usage. This helps
    catch issues such as incorrect request formatting, unexpected responses, or performance
    bottlenecks, which can be missed in abstracted environments such as Postman or
    Bruno.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: While Postman and Bruno are excellent for quick, one-off testing or for collaborating
    with non-developers, JUnit (and similar code-first tools) is the superior option
    for teams aiming to achieve robust, automated, and pipeline-integrated testing.
    By treating API tests as first-class citizens within the code base, developers
    can maximize efficiency, scalability, and confidence in their APIs.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Postman 和 Bruno 适用于快速的单次测试或与非开发者协作，但对于旨在实现稳健、自动化和管道集成测试的团队来说，JUnit（以及类似的代码优先工具）是更优的选择。通过将
    API 测试视为代码库中的第一类公民，开发者可以最大化效率、可扩展性和对 API 的信心。
- en: Leveraging the strengths of automated testing is essential, yet AI is beginning
    to redefine testing entirely and a new approach to testing has appeared.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 充分利用自动化测试的优势至关重要，然而人工智能正在开始完全重新定义测试，并出现了一种新的测试方法。
- en: The evolution of software development practices has always revolved around improving
    efficiency, quality, and collaboration. One such recent advancement is the integration
    of generative AI into Agile software development, particularly within the SCRUM
    framework (see [https://www.scrum.org/resources/what-scrum-module](https://www.scrum.org/resources/what-scrum-module)
    ). Some teams are already experimenting with a new practice where prompts for
    AI-driven testing become an integral part of the development process, transforming
    how teams define, implement, and validate new features.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 软件开发实践的演变始终围绕着提高效率、质量和协作。最近的一项进步是将生成式人工智能集成到敏捷软件开发中，特别是在 SCRUM 框架内（见 [https://www.scrum.org/resources/what-scrum-module](https://www.scrum.org/resources/what-scrum-module)）。一些团队已经在尝试一种新的实践，即
    AI 驱动测试的提示成为开发过程的一个组成部分，从而改变团队定义、实施和验证新功能的方式。
- en: In this updated workflow, the Technical Lead, in collaboration with the Product
    Owner, plays a pivotal role in shaping the development and testing lifecycle.
    When a new story is defined, a feature or enhancement to an API is introduced,
    and the Technical Lead crafts detailed prompts designed for generative AI tools.
    These prompts serve as the blueprint for testing the story’s acceptance criteria.
    By leveraging the domain expertise of both the Technical Lead and the Product
    Owner, the prompts encapsulate not only the technical requirements but also the
    business context and expected outcomes of the feature.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个更新的工作流程中，技术负责人与产品负责人合作，在塑造开发和测试生命周期中扮演关键角色。当定义一个新的故事，引入 API 的功能或增强时，技术负责人会为生成式人工智能工具制定详细的提示。这些提示作为测试故事验收标准的蓝图。通过利用技术负责人和产品负责人的领域专业知识，这些提示不仅封装了技术要求，还包括了业务背景和功能的预期结果。
- en: '![Figure 8.1 – Incorporating AI-driven prompts into Agile SCRUM workflows](img/B21843_08_1.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.1 – 将人工智能驱动的提示集成到敏捷 SCRUM 工作流程中](img/B21843_08_1.jpg)'
- en: Figure 8.1 – Incorporating AI-driven prompts into Agile SCRUM workflows
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1 – 将人工智能驱动的提示集成到敏捷 SCRUM 工作流程中
- en: For example, if a new API endpoint is being added to return a customer’s transaction
    history, the prompt might specify the exact input parameters, the expected structure
    of the JSON response, and edge cases to test, such as handling invalid input or
    empty datasets. These prompts are more than just instructions—they’re a shared
    artifact that bridges technical and business perspectives, ensuring alignment
    and clarity.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果正在添加一个新的 API 端点以返回客户的交易历史，提示可能指定确切的输入参数、预期的 JSON 响应结构以及测试边缘情况，例如处理无效输入或空数据集。这些提示不仅仅是指令——它们是连接技术和业务视角的共享工件，确保了对齐和清晰。
- en: 'This integration of generative AI into Agile workflows offers several significant
    advantages:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 将生成式人工智能集成到敏捷工作流程中提供了几个显著的优势：
- en: '**Consistency** : Standardized prompts ensure a consistent approach to testing
    across stories, reducing variability and improving reliability'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性**：标准化的提示确保了在故事之间测试方法的一致性，减少了可变性并提高了可靠性'
- en: '**Efficiency** : By automating the generation of test cases, developers can
    focus on coding the feature itself, reducing repetitive tasks and freeing up time
    for innovation'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率**：通过自动化测试用例的生成，开发者可以专注于编写功能本身的代码，减少重复性任务，并为创新腾出时间'
- en: '**Collaboration** : The joint creation of prompts by Technical Leads and Product
    Owners fosters better communication and alignment between technical and business
    teams'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协作**：技术负责人和产品负责人共同创建提示，促进了技术团队和业务团队之间更好的沟通和对齐'
- en: '**Quality assurance** : Prompts encourage the team to think critically about
    edge cases, error handling, and expected outcomes from the start, reducing bugs
    and rework down the line'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storing prompts in the code base
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To solidify the importance of these prompts, they are stored in the project’s
    Git repository alongside the source code. This integration elevates prompts to
    a first-class citizen within the development lifecycle, treating them with the
    same rigor as the code itself. Storing prompts in Git provides several key benefits:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '**Version control** : Prompts evolve as features mature or requirements change.
    Storing them in Git ensures a complete history of modifications, enabling teams
    to trace changes over time.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Collaboration** : Developers can review and refine prompts during code reviews,
    ensuring their accuracy and relevance before implementation begins.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Traceability** : Linking prompts to specific stories, commits, and branches
    creates a transparent and auditable process that ties testing directly to development
    efforts.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reusability** : Over time, prompts for similar features or scenarios can
    be repurposed, reducing redundancy and accelerating future development cycles.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI-generated code as acceptance criteria
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the prompts are finalized and stored, they become an integral part of the
    story’s acceptance criteria. The assigned software engineer uses the prompt to
    generate test cases or other relevant code through generative AI tools. This generated
    code acts as a baseline for validating the new feature. The key requirement is
    that the generated code must pass successfully—be *green* —before the story is
    marked as complete.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: This approach introduces a new layer of rigor to the definition of *done* in
    SCRUM. It ensures that testing is not an afterthought but a parallel process that
    evolves alongside the feature’s development. Additionally, by automating large
    portions of the testing process through AI, teams can deliver high-quality software
    faster, with fewer manual testing bottlenecks.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Integrating AI-driven testing into Agile practices demands more than tools—it
    requires a cultural shift.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Adopting a new Agile mindset
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This practice represents a shift in mindset for Agile teams. The act of defining
    prompts moves testing considerations to earlier in the development process, aligning
    with the principles of TDD. It emphasizes the importance of testing not just as
    a verification step but as a collaborative, iterative process that enhances the
    overall quality of the software.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: 'By embedding AI-driven testing prompts into the Agile workflow, teams not only
    embrace the power of generative AI but also elevate their development practices
    to a new level of precision and efficiency. This approach aligns perfectly with
    the goals of Agile: to deliver value faster, adapt to change effectively, and
    maintain a high standard of quality throughout the development lifecycle.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: The structure of an API test environment
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The goal of an API testing environment is to replicate all critical components
    of your application locally, facilitating comprehensive and realistic tests of
    your code. The following figure illustrates a typical setup for such an environment,
    emphasizing a self-contained system suitable for development and testing purposes.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Typical structure of a local API testing environment using Docker
    and cloud networks](img/B21843_08_2.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 – Typical structure of a local API testing environment using Docker
    and cloud networks
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: In this diagram, **API App** represents the primary application whose APIs you
    are testing. This app connects directly to essential backend components such as
    databases, caching services, or messaging queues, all deployed within a containerized
    (Docker) or cloud-based, non-production network environment. The **API Tests**
    component directly interacts with **API App** , simulating real-world scenarios
    and ensuring thorough coverage and validation of API functionality.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: 'The term “local” here is flexible: it can refer to an individual software engineer’s
    machine, typically using Docker containers, or any non-production cloud-based
    environment provisioned for development purposes. Ensuring every team member has
    access to such standardized, isolated environments is crucial, allowing consistent
    and repeatable tests across different workstations and reducing variability in
    test outcomes.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: There is an upfront effort involved in creating this local or development environment.
    However, making this investment early in the development lifecycle significantly
    enhances efficiency, reducing the risk of integration issues and accelerating
    overall development.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: “Prompting” the LLMs
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Prompt engineering** is the practice of designing and refining prompts given
    to generative AI models to produce precise, accurate, and relevant outputs. It
    involves careful phrasing and iterative tuning to achieve desired responses efficiently.
    And now let’s look at some mechanisms needed to create effective prompts for test
    generation.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: As was said before, the use of generative AI for software testing is a perfect
    application of this technology. Specifically, tests are generally less sensitive
    in terms of intellectual property and ownership concerns. Tests are primarily
    tools for validation, ensuring that your main code behaves as expected. Since
    the focus of tests is on functionality, edge cases, and coverage, generative AI
    can quickly generate a wide variety of test cases, saving developers time and
    effort. Moreover, tests are often repetitive and detail-oriented—tasks that AI
    excels at. The use of generative AI here can allow developers to focus on more
    creative or complex aspects of their work, while the AI takes care of the grunt
    work. This means better productivity, faster iteration, and higher test coverage
    with minimal manual effort.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, when it comes to using generative AI to write the main production
    code, the situation becomes a little more complex. A major concern is ownership
    of the generated code. Depending on the terms of the AI service, the code you
    use might still be partially owned or influenced by the AI provider. This can
    create legal or compliance issues, especially in industries where intellectual
    property is a critical asset. Additionally, there’s the concern that your code—or
    patterns from it—could be used to train future AI models. This could inadvertently
    expose proprietary algorithms, business logic, or sensitive methodologies to external
    entities. While this may not be a major issue for tests (which are often more
    generic and less confidential), it can be a significant risk for production code,
    where the intellectual property and security of the organization are at stake.
    At the time of writing, there are several legal decisions establishing that AI-generated
    content cannot be copyrighted *[3][4]* . Now, we will create the actual prompts
    for our test.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Testing the Products API
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Products API that we have been using in this book is a very good use case
    for this new testing strategy. Let’s look at a test-generating prompt for that
    API.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by creating a test to validate the creation of new products with
    the `PUT` method:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let’s look at each part of this prompt in more detail:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we define the LLM perspective. This is relevant to establish the role
    the LLM should play, and it does influence the answers. Sometimes it is clear
    in the resulting code when you tell the LLM to act as a senior or junior professional:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, give a clear request:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The LLM’s output is heavily influenced by what you want as a result.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, explain the API behavior as clearly as possible. This is important because
    if the underlying behavior is not clear then the LLM will try to fill in the blanks,
    sometimes with invalid assumptions. The more details you add, the better the test
    cases created:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Part of these details is the code that defines the data being tested. Either
    present the data structures used or the expected HTTP responses, but some form
    of unambiguous definition must be present.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, add any specific assertions we want the test to validate:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The result of this prompt is the following code and `pom.xml` dependency elements:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This code is not in itself complex or hard to write, but it is time-consuming,
    and most software engineers don’t particularly enjoy writing it. Also, using an
    LLM to create the tests adds a lot of flexibility to the process. For example,
    if you want this test to be created in a different language—for example, in Go—we
    only need to change the expected results to have a new version.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Go ahead and play around with the code generation options.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: In some projects, there is even the requirement that automated tests be written
    in a different language than the original code. There may not be a real technical
    reason for such a requirement, as an HTTP client is exactly like another, but
    it offers some extra psychological comfort to non-technical people in the project
    to have this extra layer of separation.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: A more complex API to test
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous exercise, we looked at testing an API in which we had complete
    access to the source code, and we were developing that API from scratch. Also,
    the example API was intentionally simple. But, there is another common situation
    that many software engineers face: An API that is already in production, with
    not many automated tests available, that is more complex and returns sophisticated
    responses. Let’s look at one such scenario.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: For this section, we are going to use the HAPI FHIR APIs and write some tests
    for them.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: HAPI FHIR is a complete Java implementation of the HL7 FHIR standard for healthcare
    interoperability. We chose this example because the API is complex, there is a
    public test implementation available, and it is used extensively in the healthcare
    market. This implementation is used by many organizations worldwide, including
    large hospital complexes, healthcare organizations, and governmental health agencies.
    But what is interesting to us from a testing perspective is how complex these
    APIs are. It is not uncommon to receive a few thousand lines of JSON in the response
    to a search, which allows us to create more nuanced prompts and corresponding
    tests.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '![img](img/Information_Box_Icon.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
- en: 'To know more about HAPI FHIR and HL7 FHIR, please refer to the following links:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[https://hapifhir.io/](https://hapifhir.io/)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[https://hl7.org/fhir/](https://hl7.org/fhir/)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Because healthcare requirements are usually unique to each organization and
    dependent on many local regulations, there is a high level of customization required
    for any HAPI FHIR implementation. It is not uncommon to find several thousand
    lines of custom code in a specific implementation. A strong set of tests is crucial
    when customizing such a complex API. You don’t want to break any of the HAPI FHIR
    contracts.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, one great advantage of HAPI FHIR as a test example for us is the availability
    of a public test server: [https://hapi.fhir.org/baseR4](https://hapi.fhir.org/baseR4)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: 'Having prior knowledge of the HAPI FHIR APIs is not necessary to follow this
    section. We are interested only in looking at the API’s behavior and preparing
    tests to validate that such behavior does not change. Here are a couple of HAPI
    FHIR concepts we will use:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '**PATIENT** : HAPI FHIR is a healthcare system; therefore, PATIENT is a first-class
    element in it. We will write some tests to validate that searching for a patient
    returns the elements we want.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RESOURCE TYPE – BUNDLE** : In HAPI FHIR, all results of a search are bundles.
    This is just the name used to define a set of data, but we will validate this
    behavior as part of our tests.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With that in mind, let’s assume you are a software engineer in the HAPI FHIR
    support team in a large hospital, and you just received the task of customizing
    the HAPI FHIR API to add a new element to a `Patient` record. This new element
    is used only in this hospital’s system. Assume that there are no test cases for
    the Patient API. What can you do?
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Well, you could start by looking at the source code and try to find all the
    relevant classes and all, but this is a time-consuming task and will delay the
    generation of the tests. Maybe a more pragmatic approach is needed.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: So, start by looking at the API responses and prepare tests so your changes
    will not break the current contract.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a `GET` request that returns all the patients in the system, one at
    a time. All the data is synthetic and not related to any real individual:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let’s examine in detail the response we received (you will not get the same
    data when running this example, but the format and structure will be the same):'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This result is already 70+ lines long and is a good start for our API analysis
    and to design our tests.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the results. We can see that the result of a `GET` function has
    a `resourceType` , which in this case is `Bundle` . `Type` is a `searchset` .
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: There is an array of links (“link”) and an array of entries (“entry”) with the
    actual patient’s data.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Good, this is a start.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Preparing your test prompt
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Remember that your goal is to make changes to the code, without breaking the
    current state, so start by defining clearly what you want to validate with your
    test—for example, “Test that all `GET` searches will return a valid pagination
    JSON.” Now, let’s write a prompt to generate our first test. The results are from
    ChatGPT 4:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Paste the whole JSON sample with the prompt.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 'The results are the following tests and `pom.xml` changes:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This code runs immediately without any modifications. This was not the case
    with the previous generation of LLMs. If you are using an older model, such as
    ChatGPT 3.5 for example, you may have to manually adjust the code.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: This whole test was completed in less than a minute by the LLM and it is actually
    fun to write and see the results so quickly—a very different experience from having
    to manually write tests by hand. The test can be improved, of course. For example,
    it could be changed to get the URL to be tested from a list or even a property
    file for added flexibility, but the core of the code is there and ready to be
    used.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s move on to a more complex type of test and see how far we can go
    with our validations.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Validating more complex behavior
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Looking at the API’s response, we can see that the “link” array has two entries
    on this first page: “ `self"` and “ `next"` .'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: A good test would be to validate that a response always has the `self` link.
    Let’s expand the prompt to include this.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the new prompt:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This will add the following code to our test:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Again, the code is not very complex, but it is already showing signs of increasing
    difficulty. Writing this by hand would not be hard, but would take some time and
    attention. LLMs can create it in 30 seconds or less.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s add even more complexity. This is a pagination exercise, so let’s
    ask the code to follow the `next` link for a few pages and validate that page.
    Then, validate if every entry in the result is unique, using `fullUrl` inside
    the `entry` array as a candidate key.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The result is starting to look more sophisticated and interesting.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The test is now a lot more complex. Look at how some helping functions are created
    ( `isValidUUID()` , `createConnection()` ). This test would take longer to write
    and be costlier to maintain. But with the use of LLMs, the whole test is ready
    to run in just a few minutes.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: I hope you are seeing the pattern at this point. As the API gets more complex,
    the tests also evolve. The LLM prompt itself is now stored in the Git repository
    and is an integral part of the code base, to the point that it can be seen as
    part of the software documentation.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The introduction of generative AI holds immense potential to reshape the landscape
    of software development, especially in the realm of testing. By automating test
    creation, streamlining complex processes, and enhancing adaptability, generative
    AI offers the promise of transforming testing into a more efficient, accessible,
    and cost-effective part of the development lifecycle.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Through the strategies and examples discussed in this chapter, we hope you have
    acquired the skills and inspiration to explore and extend the testing of your
    APIs.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Testing is a tool for validating behavior during the development and maintenance
    of our APIs, but for a truly robust service, we need to monitor these behaviors
    in production. That is what we will be looking at in the next chapter.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Test driven development* : [https://en.wikipedia.org/wiki/Test-driven_development](https://en.wikipedia.org/wiki/Test-driven_development
    )'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Prompt Engineering* : [https://en.wikipedia.org/wiki/Prompt_engineering](https://en.wikipedia.org/wiki/Prompt_engineering
    )'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Legal Ruling: AI-Generated Art and Copyright* : [https://www.reuters.com/legal/ai-generated-art-cannot-receive-copyrights-us-court-says-2023-08-21/](https://www.reuters.com/legal/ai-generated-art-cannot-receive-copyrights-us-court-says-2023-08-21/
    )'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*U.S. Copyright Office’s View on AI Prompts* : [https://www.theverge.com/news/602096/copyright-office-says-ai-prompting-doesnt-deserve-copyright-protection](https://www.theverge.com/news/602096/copyright-office-says-ai-prompting-doesnt-deserve-copyright-protection
    )'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*HAPI FHIR: Open-Source Implementation of HL7 FHIR* : [https://hapifhir.io/](https://hapifhir.io/
    )'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*HL7 FHIR Official Specification* [https://hl7.org/fhir/](https://hl7.org/fhir/)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
