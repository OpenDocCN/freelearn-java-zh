- en: Implementing Concurrency Patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 11](313a6506-6bc8-4785-a51b-1637f219bd00.xhtml), *Implementing Reactive
    Design Patterns*, we discussed the Reactive Design Pattern and how it fulfills
    the requirements of today's applications. Spring 5 Framework has introduced the
    Reactive Web Application Modules for the web application. In this chapter, we
    will explore some of the Concurrency Design Patterns and how these patterns solve
    the common problems of the multithreaded application. Spring 5 Framework's reactive
    modules also provide the solution for the multithreaded application.
  prefs: []
  type: TYPE_NORMAL
- en: If you are a software engineer or are in the process of becoming one, you must
    be aware of the term *concurrency*. In geometric properties, concurrent circles
    or shapes are those shapes that have a common center point. These shapes can differ
    in dimensions but have a common center or midpoint.
  prefs: []
  type: TYPE_NORMAL
- en: The concept is similar in terms of software programming as well. The term *concurrent
    programming* in the technical or programming means the ability of a program to
    carry out multiple computations in parallel and also the capability of a program
    to handle multiple external activities taking place in a single time interval.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we are talking in terms of software engineering and programming, concurrency
    patterns are those design patterns that help in dealing with multi-threaded programming
    models. Some of the concurrency patterns are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Handling concurrency with concurrency patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Active object pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitor object pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Half-Sync/Half-Async patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leader/followers pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread-specific storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reactor pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Best practices for concurrency module
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's now explore each of these five concurrency design patterns in depth.
  prefs: []
  type: TYPE_NORMAL
- en: Active object pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The active object type of concurrency design pattern differentiates/distinguishes
    the method execution from the method invocation. The job of this pattern is the
    enhancement of concurrency along with simplification in the synchronized access
    to objects that reside in separate and distinguishable threads of control. It
    is used for dealing with the multiple client requests that arrive all at once,
    and also for improving the quality of the service. Let''s see the following diagrams,
    which illustrates the active object design pattern in the concurrency and multithread-based
    application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/57d27554-470b-4014-8f1f-3aac617b382f.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see in the preceding diagram, the following components of this concurrency
    design pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Proxy**: This is the active object that is visible to the client. The proxy
    advertises its interface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Servant**: There is a method that is defined in the interface of the proxy.
    The servant is the provider of its implementation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Activation list**: This is a serialized list that contains method request
    objects that the proxy inserts. This list allows the servant to run concurrently.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, how does this design pattern work? Well, the answer to this is that every
    concurrent object belongs to or resides in a separate thread of control. This
    is also independent of the thread of control of the client. This invokes one of
    its methods, which means that both the method execution and method invocation
    take place in separate threads of control. However, the client sees this process
    as an ordinary method. In order for the proxy to pass the requests of the client
    to the servant at runtime, both must be run in separate threads.
  prefs: []
  type: TYPE_NORMAL
- en: In this design pattern, what the proxy does after receiving a request is that
    it sets up a method request object and inserts it in an activation list. This
    method carries out two jobs; holds the method request objects and keeps track
    of on which method request it can execute. Request parameters and any other information
    are contained in the method request object for executing the desired method later.
    This activation list in return helps the proxy and the servant to run concurrently.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see another concurrency design pattern in the upcoming section, which
    is the monitor object pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Monitor object pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The monitor object pattern is another concurrency design pattern that helps
    in the execution of multi-threaded programs. It is a design pattern implemented
    to make sure that at a single time interval, only one method runs in a single
    object, and for this purpose, it synchronizes concurrent method execution.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike the active object design pattern, the monitor object pattern does not
    have a separate thread of control. Every request received is executed in the thread
    of control of the client itself, and until the time the method returns, the access
    is blocked. At a single time interval, a single synchronized method can be executed
    in one monitor.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following solutions are offered by the monitor object pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: The synchronization boundaries are defined by the interface of the object, and
    it also makes sure that a single method is active in a single object.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It must be ensured that all the objects keep a check on every method that needs
    synchronization and serialize them transparently without letting the client know.
    Operations, on the other hand, are mutually exclusive, but they are invoked like
    ordinary method calls. Wait and signal primitives are used for the realization
    of condition synchronization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To prevent the deadlock and use the concurrency mechanisms available, other
    clients must be allowed to access the object when the method of the object blocks
    during execution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The invariants must always hold when the thread of control is interrupted voluntarily
    by the method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s see the following diagram, which illustrates more about the monitor
    object design pattern in the concurrency application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ad5ee399-9e8f-4e4b-b51b-373ad439dbe3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this preceding diagram, the client object calls the monitor object that
    has several synchronized methods and the monitor object associated with the monitor
    conditions and monitor locks. Let''s explore each component of this concurrency
    design pattern as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Monitor object**: This component exposes the methods that are synchronized
    to the clients'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Synchronized methods**: The thread-safe functions that are exported by the
    interface of the object are implemented by these methods'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitor conditions**: This component along with the monitor lock decides
    whether the synchronized method should resume its processing or suspend it'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The active object and the monitor object patterns are the branches of design
    patterns of concurrency.
  prefs: []
  type: TYPE_NORMAL
- en: Now, the other type of concurrency patterns that we will discuss are the branches
    of architectural patterns for concurrency.
  prefs: []
  type: TYPE_NORMAL
- en: Half-Sync/Half-Async patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The job of Half-Sync and Half-Async is to distinguish between the two types
    of processing called asynchronous and synchronous, for the simplification of the
    program without hindering its performance.
  prefs: []
  type: TYPE_NORMAL
- en: The two layers intercommunicating are introduced for both asynchronous and synchronous
    services for the purpose of processing with a queuing layer in between.
  prefs: []
  type: TYPE_NORMAL
- en: Every concurrent system contains both asynchronous and synchronous services.
    To enable these services to communicate with each other, the Half-Sync/Half-Async
    pattern decomposes the services in the system into layers. Using the queuing layer,
    both these services pass messages to each other for intercommunication.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see the following diagram that illustrates these design patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3ac500d9-772d-4adc-b337-c409fd5c7b19.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see in the preceding diagram, there are three layers--**Synchronous
    Service Layer**, **Queuing Layer**, and **Asynchronous Service Layer**. Synchronous
    layer contains the services that are working synchronously to the queue at the
    **Queuing Layer**, and this query performs asynchronously using Asynchronous services
    at the **Asynchronous Service Layer**. These Asynchronous Services at this layer
    are using the external event-based resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see in the preceding diagram, there are three layers included here.
    Let''s look at these layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Synchronous Task Layer**: The tasks in this layer are active objects. High-level
    input and output operations are carried by these tasks, which transfer the data
    synchronously towards the queuing layer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Queuing Layer**: This layer provides the synchronization and buffering required
    between the synchronous and asynchronous task layers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Asynchronous Task Layer**: The events from the external sources are handled
    by the tasks present in this layer. These tasks do not contain a separate thread
    of control.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have discussed the Half-Sync and Half-Async design patterns of the concurrency
    pattern. Let's move to another concurrency pattern, that is, the leader/follower
    Pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Leader/follower pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Detection, demultiplexing, dispatching, and processing of service requests
    in the event sources is carried out in an efficient way in a concurrency model,
    in which many multiple threads process one by one to use the set on event sources.
    Another replacement for the Half-Sync/Half-Async is the leader/follower pattern.
    This pattern can be used instead of the Half-Sync/Half-Async and active object
    patterns for improvement in the performance. The condition of using this is that
    there must be neither ordering nor synchronization constraints while processing
    multiple threads of requests:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4a208fe3-b0fc-44b4-92f7-39a0d103bfd5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The focused job of this pattern is to process multiple events concurrently or
    simultaneously. Due to concurrency-related overheads, it might not be possible
    to connect a separate thread with each single socket handle. The highlighted feature
    of this design is that by using this pattern, demultiplexing the associations
    between threads and event source becomes possible. When the events arrive on the
    event sources, this pattern builds up a pool of threads. This is done to share
    a set of event sources efficiently. These event sources demultiplex the arriving
    events turn by turn. Also, the events are synchronously dispatched to application
    services for processing. Out of the pool of threads structured by the leader/follower
    pattern, only a single thread waits for the occurrence of the event; other threads
    queue up waiting. A follower is promoted as the leader when a thread detects an
    event. It then processes the thread and dispatches the event to the application
    handler.
  prefs: []
  type: TYPE_NORMAL
- en: In this type of pattern, processing threads can be run concurrently, but only
    one thread is allowed to wait for the upcoming new events.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see another concurrency-based design pattern in the upcoming section.
  prefs: []
  type: TYPE_NORMAL
- en: Reactor pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The reactor pattern is used to handle service requests that are received concurrently
    by a service handler from a single or multiple input sources. The received service
    requests are then demultiplexed by the service handler and dispatched to the associated
    request handlers. All the reactor systems are commonly found in single threads,
    but they are also said to exist in a multi-threaded environment.
  prefs: []
  type: TYPE_NORMAL
- en: The key benefit of using this pattern is that the application components can
    be divided into multiple parts such as modular or reusable. Furthermore, this
    allows simple coarse-grain concurrency without the additional complexity of multiple
    threads to the system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see the following diagram about the reactor design pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/134addef-7c54-433a-9106-abe5fd104dd4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see in the preceding diagram, the dispatcher uses the demultiplexer
    to notify handler and the handler performs the actual work to be done with an
    I/O event. A reactor responds to I/O events by dispatching the appropriate handler.
    Handlers perform non-blocking actions. The preceding diagram has the following
    components of this design pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources:** These are the resources through which input is provided or output
    is consumed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Synchronous event demultiplexer:** This blocks all resources via an event
    loop. When there is a possibility that a synchronous operation will start, the
    resource is sent to the dispatcher through the demultiplexer without blocking.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dispatcher:** The registering or unregistering of request handler is handled
    by this component. Resources are dispatched to the respective request handler
    through the dispatcher.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Request Handler:** This handles the request dispatched by the dispatcher.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, we are moving on to our next and the last concurrency pattern that is the
    thread-specific storage pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Thread-specific storage pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A single logical global access point can be used to retrieve an object local
    to the thread. This concurrency design pattern allows multiple threads to carry
    this function out. This is done without incurring locking overhead on each access
    to the object. Sometimes, this particular pattern can be viewed as an antithesis
    among all the concurrency design patterns. This is due to the fact that several
    complexities are addressed by the thread-specific storage by prevention of sharing
    of the available resources among the threads.
  prefs: []
  type: TYPE_NORMAL
- en: The method appears to be invoked on an ordinary object by the application thread.
    Actually, it is invoked on a thread-specific object. A single thread-specific
    object proxy can be used by multiple application threads for accessing the unique
    thread-specific objects associated to each of them. The proxy to distinguish between
    the thread-specific object it encapsulates uses the application thread identifier.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices for concurrency module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here is a list of considerations that a programmer must look into when carrying
    out concurrency. Let's look at the following best practices to consider when you
    to get a chance to work with the concurrent application module.
  prefs: []
  type: TYPE_NORMAL
- en: '**Obtaining an executor**: The Executor Framework for obtaining an executor
    supplies the executors utility class. Various types of executors offer specific
    thread executions policies. Here are three examples:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ExecutorService newCachedThreadPool()**: This creates a thread pool using
    the previously constructed threads if available. The performance of the programs
    that make use of the short-lived asynchronous tasks is enhanced using this type
    of thread pool.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ExecutorService newSingleThreadExecutor()**: A worker thread that is operating
    in an unbounded queue is used here to create an executor. In this type, the tasks
    are added to the queue that is then executed one by one. In case, this thread
    fails during the execution, a new thread will be created and replace the failed
    thread so that the tasks can be executed without interruption.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ExecutorService newFixedThreadPool(int nThreads)**: A fixed number of threads
    that are operating in a shared unbounded queue are reused in this case for the
    creation of a thread pool. At threads, the tasks are being actively processed.
    While all the threads in the pool are active and new tasks are submitted, the
    tasks will be added in the queue until a thread becomes available for the processing
    of the new task. If before the shutdown of the executor, the thread fails, a new
    thread will be created for carrying out the execution of the task. Note that these
    thread pools exist only when the executor is active or on.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use of cooperative synchronized constructs**: It is recommended to use cooperative
    synchronized constructs when possible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**No unnecessary lengthy tasks and oversubscription**: Lengthy tasks are known
    to cause deadlock, starvation, and even prevent other tasks from functioning properly.
    Larger tasks can be broken down into smaller tasks for proper performance. Oversubscription
    is also a way to avoid the deadlock, starvation, and so on. Using this, more threads
    than the available number of threads can be created. This is highly efficient
    when a lengthy task contains a lot of latency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use of concurrent memory-management functions**: If in a situation, ensuing
    concurrent memory management functions can be used, it is highly recommended to
    use it. These can be used when objects with a short lifetime are used. The functions
    such as `Allot` and `Free` are used to free memory and allocate, without memory
    barriers or using locks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use of RAII to manage the lifetime of concurrency objects**: RAII is the
    abbreviation for **Resource Acquisition Is Initialization**. This is an efficient
    way to manage the lifetime of a concurrency object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This was all about the concurrency and it's design patterns that can be used
    to handle and implement concurrency. These are the most common five design patterns
    for concurrency programs. Also, some of the best practices for carrying out concurrency
    modules were discussed. Hope this was an informative a piece and helped you understand
    how concurrency patterns work!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned several concurrency design patterns and also saw
    the use cases of these patterns. In this book, I have covered only the basic of
    the concurrency design patterns. We have included the active object, monitor object,
    Half-Sync/Half-Async, leader/followers, thread-specific storage, and reactor patterns.
    These all are the part of the concurrency design patterns in the multithreaded
    environment of the application. We also discussed some best practices consideration
    to use the concurrency design pattern in the application.
  prefs: []
  type: TYPE_NORMAL
