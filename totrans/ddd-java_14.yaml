- en: '*Chapter 11*: Decomposing into Finer-Grained Components'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we decomposed the *LC Application Processing* functionality
    out of the monolith. In this chapter, we will further decompose these components
    into even more fine-grained components. In addition, we will examine if and when
    such a decomposition is justified.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Continuing our design journey
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even more fine-grained decomposition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decomposing the frontend
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where to draw the line
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the end of this chapter, you will be able to appreciate both technical and
    non-technical factors that play toward where we should draw the line on decomposing
    these components.
  prefs: []
  type: TYPE_NORMAL
- en: Continuing our design journey
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Currently, our application resembles the diagram depicted here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – Independent data persistence'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_11.1.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.1 – Independent data persistence
  prefs: []
  type: TYPE_NORMAL
- en: The *LC Application Processing* functionality lives as its own independent component
    from the rest of the application. It communicates with the monolith through the
    exchange of domain events using the event bus. It makes use of its own persistence
    store and exposes HTTP-based APIs that the frontend consumes. Let’s examine whether
    it is possible to further decompose the application into finer-grained components.
    The `AutoApprovalSaga` component currently lives within the confines of the monolith,
    but this is mostly an artifact of our previous design as opposed to an intentional
    design choice. Let’s look at how we can extract this into its own component next.
  prefs: []
  type: TYPE_NORMAL
- en: Saga as a standalone component
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Currently, the `AutoApprovalSaga` component (discussed in detail in [*Chapter
    8*](B16716_08_Final_NM_ePub.xhtml#_idTextAnchor129), Implementing *Long-Running
    Workflows*) works by listening to domain events, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2 – The AutoApprovalSaga functionality dissected'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_11.2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.2 – The AutoApprovalSaga functionality dissected
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that these events are published by different bounded contexts onto the
    event bus, there is no need for `AutoApprovalSaga` to be embedded within the monolith.
    This means that it can be safely pulled out into its own deployable unit along
    with its private data store. This means that our system now looks like the diagram
    depicted here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3 – AutoApprovalSaga extracted into an independent component'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_11.3.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.3 – AutoApprovalSaga extracted into an independent component
  prefs: []
  type: TYPE_NORMAL
- en: Saga components can be characterized as a collection of stateful event listeners
    listening to events from more than one aggregate that can issue commands to more
    than aggregate. We saw earlier that we form bounded contexts along aggregate boundaries.
    Given that sagas tend to require interaction with more than one aggregate, they
    may not fall within the confines of those bounded contexts. In a lot of ways,
    sagas are components that can be viewed as their own bounded contexts. This makes
    it natural to have sagas work as standalone components that exist distinctly (both
    from a logical and physical perspective) from other parts of a solution.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, commands and queries within the *LC Application Processing*
    component continue to use a common data store. Let’s look at what is involved
    in segregating them into their own data store.
  prefs: []
  type: TYPE_NORMAL
- en: Commands and queries as standalone components
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we saw in the *CQRS pattern* section in [*Chapter 2*](B16716_02_Final_NM_ePub.xhtml#_idTextAnchor037),
    *Where and How Does DDD Fit?*, the primary benefit that we derive is the ability
    to evolve and scale these components independently of each other. This is important
    because commands and queries have completely different usage patterns and thus
    require the use of distinct domain models. This makes it fairly natural to further
    split our bounded contexts along these boundaries. Thus far, the segregation is
    logical. A physical separation will enable us to truly scale these components
    independently, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4 – Commands and queries as independent components'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_11.4.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.4 – Commands and queries as independent components
  prefs: []
  type: TYPE_NORMAL
- en: 'It is pertinent to note that the command processing component is now shown
    to have access to two distinct data stores:'
  prefs: []
  type: TYPE_NORMAL
- en: The **aggregate store**, which stores either an event-sourced or state-stored
    representation of an aggregate state.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **lookup store**, which can be used to store lookup data when performing
    business validations when processing commands. This is applicable when we need
    to access data that is/cannot be stored as part of the aggregate state.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The reason we bring this up is that we may have to continue making lookups for
    data that still remains in the monolith. To achieve full independence, this lookup
    data must also be migrated using techniques such as a historic event replay (as
    discussed in [*Chapter 7*](B16716_07_Final_NM_ePub.xhtml#_idTextAnchor112), *Implementing
    Queries*) or other conventional data migration techniques (as discussed in [*Chapter
    10*](B16716_10_Final_NM_ePub.xhtml#_idTextAnchor150), *Beginning the Decomposition
    Journey*).
  prefs: []
  type: TYPE_NORMAL
- en: Distributing individual query components
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At this point, we have achieved segregation along command and query boundaries.
    But we do not need to stop here. Each of the queries we service need not necessarily
    remain a single component. Let’s consider an example where we need to implement
    a fuzzy LC search feature for the UI and a view of LC facts for analytical use
    cases. It is conceivable that these requirements may be implemented by a different
    set of teams, thereby necessitating the need for distinct components. Even if
    these are not distinct teams, the disparity in usage patterns may warrant the
    use of different persistence stores and APIs, again requiring us to look at implementing
    at least a subset of these as distinct components, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.5 – Queries split into individual components'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_11.5.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.5 – Queries split into individual components
  prefs: []
  type: TYPE_NORMAL
- en: 'Owning domains should strive to create query APIs that exhibit the characteristics
    of a good domain data product. Some of these characteristics include being discoverable,
    trustworthy, valuable in their own right, and self-describing. For more information,
    please refer to this article on moving from a monolithic data lake to a distributed
    data mesh. Specifically, the section on domain data as a product is relevant in
    this context: [https://martinfowler.com/articles/data-monolith-to-mesh.html#DomainDataAsAProduct](https://martinfowler.com/articles/data-monolith-to-mesh.html#DomainDataAsAProduct).'
  prefs: []
  type: TYPE_NORMAL
- en: Even more fine-grained decomposition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this stage, is there any further decomposition that is required and feasible?
    These days, whether rightfully or otherwise, serverless architecture (specifically,
    *functions as a service*) is arguably becoming all the rage. As we pointed out
    in [*Chapter 2*](B16716_02_Final_NM_ePub.xhtml#_idTextAnchor037), *Where and How
    Does DDD Fit?*, this means that we may be able to decompose our command side in
    a manner that each command becomes its own independently deployable unit (hence
    a bounded context). In other words, `LCApplicationSubmitCommand` and the `LCApplicationCancelCommand`
    can be deployed independently.
  prefs: []
  type: TYPE_NORMAL
- en: 'But just because this is technically possible, should we do it? While it is
    easy to dismiss this as a passing fad, there may be good reasons to split applications
    along command boundaries:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Risk profile**: Certain pieces of functionality present a higher risk when
    changes are made. For example, submitting an LC application may be deemed a lot
    more critical than the ability to cancel it. However, that is not to say that
    *canceling* is unimportant. Being decoupled from *submit* allows *cancel* changes
    to be made with a lot less scrutiny. This may make it easier to innovate quickly
    with more experimental features, with minimal fear of causing large disruptions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability needs**: Scaling needs can differ wildly for various commands
    in a system. For example, *submit* may need to scale a lot more than *cancel*.
    However, being coupled will force us to treat them as equals, which can be inefficient.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost attribution**: Having fine-grained components allows us to more accurately
    measure the amount of effort and the resulting ROI dedicated to each individual
    command. This can make it easier to focus our efforts on the most critical functionality
    (the “core” of the core) and minimize waste.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Effects on the domain model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'These finer grainer components are leading us to a point where it may appear
    that the deployment model is starting to have a big influence on the design. The
    fact that it is now feasible to deploy individual “tasks” independently requires
    us to reexamine how we arrive at bounded contexts. For example, we started by
    working on the *LC Application Processing* bounded context, and our aggregate
    design was based on all functionality included in the scope of application processing.
    Now, our aggregate design can be a lot more fine-grained. This means that we can
    have an aggregate specifically for *start* functionality and another for *cancel*,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.6 – A fine-grained bounded contexts example'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_11.6.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.6 – A fine-grained bounded contexts example
  prefs: []
  type: TYPE_NORMAL
- en: 'The most fine-grained decomposition may lead us to a bounded context per command,
    but that does not necessarily mean that we have to decompose the system this way.
    In the preceding example, we have chosen to create a single bounded context for
    the *submit* and *approve* commands. However, *start* and *cancel* have their
    own bounded contexts. The actual decision that you make in your own ecosystems
    will depend on maintaining a balance among reuse, coupling, transactional consistency,
    and other considerations that we discussed earlier. It is important to note that
    the aggregate labeled as `LCApplication`, although named identically, is distinct
    from a domain model perspective in its respective bounded context. The only attribute
    they will need to share is a **common identifier**. If we choose to decompose
    the system into a bounded context per command, our overall solution will look
    like the diagram shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.7 – Decomposition per command'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_11.7.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.7 – Decomposition per command
  prefs: []
  type: TYPE_NORMAL
- en: 'It is pertinent to note that the *command* functions continue to share a single
    event store, although they may make use of their own individual lookup stores.
    We understand that this decomposition likely feels unnecessary and forced. However,
    this does allow us to focus our energies on the *core of the core*. For example,
    LC application processing may be our business differentiator. However, an even
    more careful examination may reveal that it is our ability to *decision* LCs near
    real time that is our real business differentiator. This means that it may be
    prudent to isolate that functionality from the rest of the system. In fact, doing
    so may enable us to optimize our business process without adding risk to the overall
    solution. While it is not strictly necessary to decompose the system in this way
    to arrive at such insights, a fine-grained decomposition may enable us to refine
    the idea of what is most important to our business. Having to share a persistent
    store can be a wrinkle to achieve complete independence. Therefore, a final decomposition
    may look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.8 – Command components with individual event stores'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_11.8.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.8 – Command components with individual event stores
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, there is no free lunch! This fine-grained decomposition may require
    additional coordination and duplication of data among these components – to a
    point where it may not be attractive anymore. However, we feel that it is important
    to illustrate the art of the possible.
  prefs: []
  type: TYPE_NORMAL
- en: Decomposing the frontend
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Thus far, we have focused on decomposing and distributing the backend components
    while keeping the frontend untouched as part of the existing monolithic system.
    It is worth considering breaking down the frontend to align it more closely along
    functional boundaries. Patterns such as micro-frontends ([https://micro-frontends.org/](https://micro-frontends.org/),
    [https://martinfowler.com/articles/micro-frontends.html](https://martinfowler.com/articles/micro-frontends.html))
    extend the concepts of microservices to the frontend. Micro-frontends promote
    team structures to support end-to-end ownership of a set of features. It is conceivable
    that a cross-functional, polyglot team owns both the experience (frontend) and
    the business logic (backend) functions, eliminating communication overheads drastically
    (along the lines of the vertical slice architecture conversation, as discussed
    in [*Chapter 2*](B16716_02_Final_NM_ePub.xhtml#_idTextAnchor037), *Where and How
    Does DDD Fit?*). Even if such a team organization where the frontend and backend
    are one team is not feasible in your current ecosystem, this approach still has
    many merits, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Increased end-to-end collaboration**: Creating solutions that work end to
    end is what ultimately provides value. Having a set of backend services isolated
    from their respective customer experiences will only cause us to accumulate unused
    inventory. To reduce the possibility of failure, the closer the collaboration
    between the backend capability and frontend experience teams, the greater our
    chance of reducing waste due to misaligned requirements. Including the customer
    experiences as part of the vertical slice allows us to apply the ubiquitous language
    through the entire stack.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Uniform omnichannel experiences**: These days, it is very common to surface
    the same functionality across more than one experience channel. Having an inconsistent
    experience across channels can lead to customer dissatisfaction and/or adverse
    business consequences. Aligning teams closely along functional boundaries (within
    the same *swim lane*) can promote high levels of collaboration and consistency
    when exposing business functionality. Consider the example shown here. Within
    a vertical slice, the allegiance is to the functionality being developed, although
    there may be a need to use disparate technologies to build each channel (iOS,
    Android, web, and so on). Within a vertical slice, each box depicted in the diagram
    may operate as a team of its own, while maintaining strong cohesion with the functional
    team within the same swim lane, as shown here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 11.9 – Teams aligned along functional boundaries'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_11.9_NEW.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.9 – Teams aligned along functional boundaries
  prefs: []
  type: TYPE_NORMAL
- en: 'While there are many advantages in employing this approach, as with everything
    else, it does come with a few gotchas that you may need to be mindful of:'
  prefs: []
  type: TYPE_NORMAL
- en: '**End-to-end testing complexity**: While this is true for a lot of distributed
    architectures, this problem is exacerbated in the case of user experiences because
    of it being a visual medium. Especially if real components come together close
    to the end of the cycle, it may become harder to visualize the end-to-end flow
    until almost all the visual elements are in place. This may also be in conflict
    with how end users interact with a system as a whole. This may make end-to-end
    testing complex because it needs components from multiple teams to come together,
    possibly close to the end of the cycle.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment complexity**: In the preceding example, we have split the application
    along functional boundaries. However, they have to come together as a single artifact
    at the time of deployment (this is especially true in the case of mobile applications).
    This can add quite a bit of deployment complexity when the complete application
    is assembled. It is important to be cognizant of the relationship patterns between
    teams (as covered in [*Chapter 9*](B16716_09_Final_NM_ePub.xhtml#_idTextAnchor138),
    *Integrating with External Systems*) to work through kinks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dependency management**: Given that teams may need to ultimately deploy the
    application as a unit, managing dependencies between individual modules may become
    cumbersome. This may manifest itself in the form of conflicting dependency versions,
    leading to unpredictable and inefficient runtime behavior and performance. For
    example, two teams may use different versions of the same frontend library, which
    may add to the overall payload that gets downloaded to the browser. In addition
    to being wasteful, this may also result in unpredictable, hard-to-diagnose errors,
    and eventually, poor customer experience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inconsistent user experiences**: Although we may have split the application
    in a seemingly logical manner, if we don’t do it in a manner that is transparent
    to the end users, it may result in a confusing and likely frustrating experience.
    To mitigate this, there may be a need to build common assets, widgets, and so
    on. which may further add to the overall complexity and coordination required
    when shipping out the end product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we proceed to continue decomposing our application as suggested previously,
    our application will end up looking like the diagram shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.10 – Commands and query frontends decomposed into individual functions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_11.10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.10 – Commands and query frontends decomposed into individual functions
  prefs: []
  type: TYPE_NORMAL
- en: As we saw, there are multiple ways to approach decomposing an application into
    finer-grained components. Just because it is possible to do it, it doesn’t mean
    that we should. Let’s look at when decomposition starts to become too expensive
    to sustain productivity.
  prefs: []
  type: TYPE_NORMAL
- en: Where to draw the line
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In general, the smaller the size of our bounded contexts, the easier it becomes
    to manage complexity. Does that mean we should decompose our systems into as fine-grained
    a granularity as possible? On the other hand, having extremely fine-grained components
    can increase coupling among them to the extent where it becomes very hard to manage
    operational complexity. Hence, decomposing a system into well-factored, collaborating
    components can be a bit tricky, seeming to work more like an art rather than an
    exact science. There is no right or wrong answer here. In general, if things feel
    and become painful, you most likely got it more wrong than right. Here are some
    non-technical heuristics that might help guide this process:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Existing organization boundaries**: Look to align along with current organizational
    structures. Identify which applications your business unit/department/team already
    owns and assign responsibilities in a manner that causes minimal disruption.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**End-user roles and responsibilities**: What work do your end users carry
    out? What enables them to do their work with the least friction possible? If too
    many people need to get involved to get a piece of work done, that may be a sign
    that the current decomposition may be suboptimal. On the other hand, if it is
    hard to assign a task to a specific user, it may again be a sign of incorrect
    decomposition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Change in vernacular**: Look for subtle changes in the usage of common terms
    (the *ubiquitous language*). Does someone call something that is/feels the same
    in the physical world by different names? For example, a credit card can be called
    “plastic,” “payment instrument,” and “account” by different people or the same
    people in a different context. The point at which the vernacular changes may be
    the time to split functionality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Existing (modular/monolithic/distributed) applications**: How are your current
    applications segregated logically? How are they segregated physically? This might
    provide some inspiration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Team organization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All of the preceding techniques draw inspiration from existing constructs. However,
    what if one or more of the preceding are wrong/cumbersome/suboptimal? In such
    a case, our work as developers/architects is a bit more involved.
  prefs: []
  type: TYPE_NORMAL
- en: It is also pertinent to note that it is not uncommon to get domain boundaries
    wrong. Coming up with an initial breakdown that seems to make more sense and applying
    a series of *what if* questions to assess suitability can help. If the reasoning
    is able to stand up to scrutiny by domain experts, architects, and other stakeholders,
    you might be in a good place. If you do choose to go down this route, it may be
    prudent to adjust existing organizational structures to match your proposed architecture.
    This will help reduce friction (in other words, apply what is called the *inverse
    Conway maneuver* ([https://www.thoughtworks.com/en-us/radar/techniques/inverse-conway-maneuver](https://www.thoughtworks.com/en-us/radar/techniques/inverse-conway-maneuver)).
  prefs: []
  type: TYPE_NORMAL
- en: 'This style of team organization can be quite complex. The people at Spotify
    popularized the idea of a multidisciplinary, mostly autonomous team structure
    aligning closely along functional boundaries (called *squads*), as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.11 – The Spotify model of team organization'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_11.11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.11 – The Spotify model of team organization
  prefs: []
  type: TYPE_NORMAL
- en: 'The team structure has other components such as chapters, tribes, and guilds,
    which enable a better flow of change, clarify team responsibilities, promote better
    intra- and inter-team collaboration, and so on. You can find out more about it
    in this post: [https://blog.crisp.se/wp-content/uploads/2012/11/SpotifyScaling.pdf](https://blog.crisp.se/wp-content/uploads/2012/11/SpotifyScaling.pdf).
    However, there is no one-size-fits-all approach, and you will need to account
    for your own organizational structures and realities before looking to adopt this
    style. To find out more about the *limitations of the Spotify model* ([https://www.youtube.com/watch?v=4GK1NDTWbkY](https://www.youtube.com/watch?v=4GK1NDTWbkY))
    and how you can arrive at a team organization that better suits your own requirements,
    you may want to take a look at the work done by Matthew Skelton and Manuel Pais
    in their popular book *Team Topologies* ([https://teamtopologies.com/book](https://teamtopologies.com/book)).
    On a related note, it may also be helpful to look at the chapter on team design
    from the book *Agile IT Organization Design* ([https://www.amazon.com/Agile-Organization-Design-Transformation-Continuous/dp/0133903354](https://www.amazon.com/Agile-Organization-Design-Transformation-Continuous/dp/0133903354))
    by Sriram Narayan, where he talks about outcome-oriented versus activity-oriented
    teams.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite all our due diligence and noble intentions, it is still possible to
    get these boundaries wrong, or a change in business priorities or competitor offerings
    may render decisions that appeared perfectly valid at the time to become incorrect.
    Instead of looking to arrive at the perfect decomposition, it might be prudent
    to embrace change and invest in building designs that are flexible while being
    prepared to evolve and refactor the architecture iteratively. This book on building
    evolutionary architectures has some great advice on how to do precisely that:
    [https://evolutionaryarchitecture.com/](https://evolutionaryarchitecture.com/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to attain a reasonable level of success, there will be a need to maintain
    a fine balance between how domains are modeled, what the team organizations are,
    and how applications are architected. When all of these are in agreement, it is
    likely that you get pretty close to achieving high levels of success, as depicted
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.12 – Forces influencing component decomposition'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_11.12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.12 – Forces influencing component decomposition
  prefs: []
  type: TYPE_NORMAL
- en: As a general guideline, it helps to start with a coarse-grained decomposition
    at the outset when requirements and/or our understanding are likely still unclear,
    leaving finer-grained decomposition to a time when our understanding improves.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how an already fine-grained application can be further
    decomposed to the level of individual functions, each of which may be deployed
    as its own independent unit. We looked at how we stand to benefit from keeping
    end-to-end functionality (a thin vertical slice) as a cohesive unit, which includes
    components from the frontend experience all the way to the backend.
  prefs: []
  type: TYPE_NORMAL
- en: Further, we looked at how Conway’s law can play an important role in the evolution
    of our architecture. We also looked at how we may be able to course correct cumbersome
    organizational structures by applying the inverse Conway maneuver. Finally, we
    briefly touched on popular methods of team organization that you can take inspiration
    from when designing your own organizational structures.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at a variety of non-functional characteristics
    that play a significant role in how we can decompose and distribute applications.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](img/B16716_11_Table_01.jpg)'
  prefs: []
  type: TYPE_IMG
