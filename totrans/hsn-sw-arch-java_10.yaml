- en: 'Chapter 8: Designing Application Integration and Business Automation'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章：设计应用程序集成和业务自动化
- en: 'In the previous chapter, we explored the concept of middleware in an application
    server. That''s probably the most traditional meaning of middleware: you are using
    a layer providing some features to your code in order to standardize and avoid
    *reinventing the wheel*.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们探讨了在应用程序服务器中中间件的概念。这可能是中间件最传统的含义：你正在使用一个层为你的代码提供一些功能，以便标准化并避免*重新发明轮子*。
- en: 'That''s, of course, a concept inherent to the *middleware* term: something
    in between your code and the rest of the world (whether it''s a database, the
    operating system resources, and so on). But middleware has a broader meaning in
    the enterprise world. One such meaning is related to the concept of **application
    integration**. In this sense, the middleware sits in between your application
    and the rest of the world, meaning other applications, legacy systems, and more.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这是一个与**中间件**术语固有的概念：介于你的代码和世界其他部分（无论是数据库、操作系统资源等）之间。但在企业世界中，中间件有更广泛的意义。其中一个意义与**应用程序集成**的概念相关。在这种情况下，中间件位于你的应用程序与世界其他部分（即其他应用程序、遗留系统等）之间。
- en: 'In this chapter, we will look at some typical topics related to application
    integration. We will then have a look at another important related middleware
    aspect, which is **business automation**, more related to workflows and business
    rules. We will discuss the following topics in detail:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨一些与应用程序集成相关的典型主题。然后，我们将查看另一个重要的相关中间件方面，即**业务自动化**，这更多与工作流和业务规则相关。我们将详细讨论以下主题：
- en: Integration – point-to-point versus centralized
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成——点对点与集中式
- en: Digging into enterprise integration patterns
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入探讨企业集成模式
- en: Exploring communication protocols and formats
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索通信协议和格式
- en: Introducing data integration
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍数据集成
- en: Messaging
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消息传递
- en: Completing the picture with business automation
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过业务自动化完善图景
- en: Integration versus automation – where to draw the line
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成与自动化——在哪里划清界限
- en: Case studies and examples
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 案例研究和示例
- en: After reading this chapter, you will be able to design and implement the most
    common integration, messaging, and business automation patterns, to be used in
    wider solution architecture design for your applications.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读本章后，你将能够设计和实现最常用的集成、消息传递和业务自动化模式，用于更广泛的应用程序解决方案架构设计。
- en: So, let's start with some reasoning about different integration approaches.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们从对不同集成方法的推理开始。
- en: Integration – point-to-point versus centralized
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成——点对点与集中式
- en: 'Before digging into patterns and implementation techniques for application
    architecture, it''s important to define that integration capabilities, as in making
    one application talk to another one, including different protocols and data formats,
    can be roughly split into two approaches:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究应用程序架构的模式和实现技术之前，定义集成能力非常重要，即在使一个应用程序与另一个应用程序通信时，包括不同的协议和数据格式，可以大致分为两种方法：
- en: '**Point-to-point**, where the integration capabilities are provided within
    each application component and components directly talk to each other'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**点对点**，在这里，集成能力在每个应用程序组件内部提供，组件直接相互通信'
- en: '**Centralized**, where a central integration layer plays a mediation role,
    hiding (partially or completely) the technological details of every component,
    hence facilitating the communication of components with each other'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集中式**，在这里，一个中央集成层扮演调解角色，隐藏（部分或全部）每个组件的技术细节，从而促进组件之间的通信'
- en: It's worth noticing that there is an important comparison to be made. We've
    already discussed, in [*Chapter 7*](B16354_07_Final_JM_ePUB.xhtml#_idTextAnchor164),
    *Exploring Middleware and Frameworks*, that Java Enterprise Edition evolved into
    componentization with the goal of breaking monolithic approaches. This kind of
    architectural evolution is independent of software layers. This also means that
    other than the applications per se, the other architectural components (such as
    the integration layers) are impacted by such considerations, and so you may have
    a monolithic approach (as in centralized integration) and a modular approach (as
    in point-to-point).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，有一个重要的比较需要做出。我们已经在[*第7章*](B16354_07_Final_JM_ePUB.xhtml#_idTextAnchor164)，*探索中间件和框架*中讨论过，Java企业版通过组件化发展，目的是打破单体方法。这种架构演变与软件层无关。这也意味着，除了应用程序本身之外，其他架构组件（如集成层）也会受到这种考虑的影响，因此你可能会遇到单体方法（如集中式集成）和模块化方法（如点对点）。
- en: The goal of this section is to give an overview of different integration approaches,
    starting from centralized, then modularized (point-to-point or cloud-native),
    touching on emerging topics (such as citizen integration), and in general providing
    a number of different architectural points of view on how to implement application
    integration.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目标是概述不同的集成方法，从集中式开始，然后是模块化（点对点或云原生），涉及新兴主题（如公民集成），并在一般情况下提供多种不同的架构观点，以展示如何实现应用集成。
- en: 'To start, let''s talk about a traditional, centralized integration approach:
    **Service-Oriented Architecture** (**SOA**).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们谈谈一种传统的、集中式的集成方法：**面向服务的架构**（**SOA**）。
- en: Understanding service-oriented architecture
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解面向服务的架构
- en: SOA is a broad term. It is more of an industry trend than a standard per se.
    It basically defines an architectural standard, somewhat similar to microservices
    (and different as well—more on this in [*Chapter 9*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230),
    *Designing Cloud-Native Architectures*).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: SOA是一个广泛的概念。它更多的是一个行业趋势，而不是一个真正的标准。它基本上定义了一个架构标准，与微服务（以及不同之处——更多内容请见[*第9章*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230)，*设计云原生架构*）相似。
- en: This whole concept is about creating reusable services. To do that, SOA relies
    on a number of different technologies, such as SOAP web services, an **Enterprise
    Service Bus** (**ESB**), and sometimes other components, such as a service registry
    (**Universal Description Discovery and Integration** (**UDDI**), which used to
    be a standard for this area), security, governance, and repositories.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 整个概念是关于创建可重用服务。为此，SOA依赖于多种不同的技术，例如SOAP网络服务、**企业服务总线**（**ESB**），有时还有其他组件，如服务注册（**通用描述、发现与集成**（**UDDI**），曾经是该领域的标准），安全、治理和存储库。
- en: The ESB is the relevant component for this chapter. Very often, SOA has been
    loosely adopted and ultimately abandoned in enterprise contexts (for reasons such
    as scalability and complexity), while the ESB has survived such architectures.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ESB是本章的相关组件。在许多企业环境中，SOA通常被松散采用，最终被放弃（原因如可扩展性和复杂性），而ESB则在这种架构中幸存下来。
- en: Enterprise service bus – what and why?
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 企业服务总线——是什么以及为什么？
- en: The ESB technology is commonly considered to have been born together with SOA,
    even though some of its concepts predate SOA technology.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ESB技术通常被认为与SOA同时诞生，尽管其中一些概念在SOA技术之前就已经存在。
- en: 'Some commonly used ESB products include the following:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常用的ESB产品包括以下：
- en: '**Red Hat Fuse** ([https://www.redhat.com/it/technologies/jboss-middleware/fuse](https://www.redhat.com/it/technologies/jboss-middleware/fuse)),
    distributed by Red Hat, and made using Apache Camel, which is the framework that
    we are going to see in this chapter.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**红帽Fuse** ([https://www.redhat.com/it/technologies/jboss-middleware/fuse](https://www.redhat.com/it/technologies/jboss-middleware/fuse))，由红帽公司发行，使用Apache
    Camel构建，这是我们将在本章中看到的框架。'
- en: '**Tibco BusinessWorks** ([https://www.tibco.com/](https://www.tibco.com/)),
    distributed by Tibco. This is a widespread solution among many enterprise customers.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tibco BusinessWorks** ([https://www.tibco.com/](https://www.tibco.com/))，由Tibco发行。这是许多企业客户中广泛采用的一种解决方案。'
- en: '**MuleSoft** ([https://www.mulesoft.com](https://www.mulesoft.com)), distributed
    by Salesforce, particularly suited to integrating SaaS applications.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MuleSoft** ([https://www.mulesoft.com](https://www.mulesoft.com))，由Salesforce发行，特别适合集成SaaS应用程序。'
- en: While SOA focuses on supporting the construction of composable services and
    modular architecture (by stressing standard protocol usage, common security and
    governance policies, and a machine-readable registry of exposed services), ESB
    does some heavy lifting behind the scenes. An ESB provides all the glue needed
    for making the communication between different technologies transparent. The idea
    is we want to standardize services (such as SOAP) to make ESB interoperable and
    ultimately reusable to create new applications. We can integrate existing applications
    and services by using an ESB. An ESB revolves around the concept of a message,
    being the basic unit of information managed in each integration.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然SOA侧重于支持可组合服务的构建和模块化架构（通过强调标准协议的使用、常见的安全和治理策略以及可机器读取的服务暴露注册），但ESB在幕后承担了大量工作。ESB提供了使不同技术之间的通信透明所需的全部粘合剂。我们的想法是标准化服务（如SOAP），以便使ESB具有互操作性，并最终可重用以创建新的应用程序。我们可以通过使用ESB来集成现有应用程序和服务。ESB围绕消息的概念展开，它是每个集成中管理的基本信息单元。
- en: 'There are a number of ways to represent a message, but they normally include
    the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 表示消息的方式有很多种，但通常包括以下几种：
- en: A **header**, including a variable amount of metadata (usually in the form of
    key-value pairs), which may include information such as a unique ID, the message
    creation timestamp, and the original sender identifier (which is the system that
    generated the message).
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个**报头**，包括一定量的元数据（通常以键值对的形式），可能包括诸如唯一ID、消息创建时间戳和原始发送者标识符（即生成消息的系统）等信息。
- en: A `.xsd` for `.xml` files).
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`.xsd`文件用于`.xml`文件）。
- en: 'Given that the message represents the information flowing into our integration
    system, an ESB is then further composed of the following kinds of logical building
    blocks, dealing with such information:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由于消息代表流入我们集成系统的信息，因此ESB进一步由以下类型的逻辑构建块组成，处理此类信息：
- en: '**Connectors**, providing interoperability (sending and receiving messages)
    with different technologies, such as databases, filesystems, and SaaS components.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**连接器**，提供与不同技术（如数据库、文件系统和服务软件组件）的互操作性（发送和接收消息）。'
- en: '`.json`, `.xml`, and `.csv`. These are used to validate messages (to ensure
    the format is correct) or to convert a message between formats (to make the integration
    between different systems possible). We will see some widespread message formats
    in detail in the upcoming sections.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.json`、`.xml`和`.csv`。这些用于验证消息（以确保格式正确）或在不同格式之间转换消息（以使不同系统之间的集成成为可能）。我们将在接下来的章节中详细介绍一些广泛使用的消息格式。'
- en: '**Patterns**, providing well-known integration behaviors, solving common integration
    problems such as content-based routing, splitting, and aggregating.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模式**，提供众所周知的集成行为，解决诸如基于内容的路由、拆分和聚合等常见集成问题。'
- en: 'In this book, we will refer to integrations defined as routes. A **route**,
    in the context of integration, is composed of the following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将把定义为路由的集成。在集成的上下文中，一个**路由**由以下组成：
- en: One or more **sources** (or endpoints), which are basically systems generating
    messages. This is usually a connector implementing a specific technology (such
    as receiving REST calls, reading files, or getting data from a database).
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个或多个**源**（或端点），它们基本上是生成消息的系统。这通常是一个实现特定技术（如接收REST调用、读取文件或从数据库获取数据）的连接器。
- en: One or more **destinations** (or endpoints), which are the systems that receive
    the messages. Also, in this case, this is commonly a connector for a specific
    technology (such as inserting data into a SaaS system, writing files, or calling
    a web service).
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个或多个**目的地**（或端点），它们是接收消息的系统。在这种情况下，这通常是一个针对特定技术（如将数据插入SaaS系统、写入文件或调用Web服务）的连接器。
- en: One or more **integration steps**, which are the business logic of the integration
    itself. Integration steps can imply changing the data format by calling a third-party
    system (using a connector) in order to retrieve (or send) data or even to implement
    a specific pattern (as per the previous section, so content-based routing, splitting,
    and so on).
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个或多个**集成步骤**，它们是集成本身的业务逻辑。集成步骤可能意味着通过调用第三方系统（使用连接器）来更改数据格式，以检索（或发送）数据，甚至实现特定的模式（如前述章节中的内容路由、拆分等）。
- en: 'This is what an integration route schematically looks like: a source, a destination,
    and a number of steps in between. The messages flow in such a way, following the
    required steps:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是集成路由的示意图：一个源，一个目的地，以及其中间的一系列步骤。消息以这种方式流动，遵循所需的步骤：
- en: '![Figure 8.1 – Integration route'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.1 – 集成路由'
- en: '](img/Figure_8.01_B16354.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.01 – 集成路由](img/Figure_8.01_B16354.jpg)'
- en: Figure 8.1 – Integration route
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1 – 集成路由
- en: Please note that, usually, the steps are executed sequentially (straight through
    integration routes). However, according to specific patterns, it may be possible
    to have optional steps (skipped in some cases) or steps executed in parallel (for
    performance purposes). Now, when hearing about messages, you may get fooled into
    thinking that the concept of integration is inherently asynchronous. But in this
    context, this is not necessarily true. Conversely, integration may be (and usually
    is) a synchronous interaction, meaning that the initiator of such an integration
    process waits for the execution to complete.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，通常，步骤是顺序执行的（直接通过集成路由）。然而，根据特定的模式，可能存在可选步骤（在某些情况下被跳过）或并行执行的步骤（为了性能目的）。现在，当听到关于消息的内容时，你可能会被误导，认为集成概念本质上就是异步的。但在这个上下文中，这并不一定正确。相反，集成可能是（并且通常是）同步交互，意味着此类集成过程的发起者等待执行完成。
- en: Asynchronous integrations are behaviorally different. The initiator of such
    a process sends the message to the integration route and doesn't wait for the
    completion. It's usually enough to get an *acknowledgment* from the integration
    infrastructure, meaning that the system has taken charge of the message.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 异步集成在行为上有所不同。此类过程的发起者将消息发送到集成路由，并不等待其完成。通常，从集成基础设施获得一个*确认*就足够了，这意味着系统已经接管了该消息。
- en: To implement such logic, usually, it's enough to use a message broker. In this
    way, you can publish the messages into a dedicated *parking space* (which is the
    broker) and have one or more consumers take it and execute the integration logic
    against it. Then, the integration logic may or may not signal the result of integration
    in some way (by using another message or synchronously calling an endpoint, such
    as a REST service). With this approach, you will have producers and consumers
    decoupled. We will see more about message brokers in the upcoming sections.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这种逻辑，通常，使用消息代理就足够了。这样，你可以将消息发布到一个专门的*停车场*（即代理），让一个或多个消费者取走并对其执行集成逻辑。然后，集成逻辑可能会或可能不会以某种方式（通过使用另一个消息或同步调用一个端点，如REST服务）发出集成结果的信号。采用这种方法，你将拥有解耦的生产者和消费者。我们将在接下来的章节中了解更多关于消息代理的内容。
- en: However, while most (if not all) of the principles of integration still hold
    valid today, ESBs have evolved and play a different role (and with different names)
    in the modern, cloud-native world.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管大多数（如果不是所有）的集成原则至今仍然有效，ESB（企业服务总线）已经发展并在这个现代、云原生世界中扮演着不同的角色（以及不同的名称）。
- en: Integration in the cloud-native world
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 云原生世界的集成
- en: With microservices and cloud-native architectures becoming popular, many started
    to question the role of ESBs and **integration**. The most common reason behind
    this is the lack of scalability. The microservices architectural approach heavily
    relies on the concept of product teams, each developing and having responsibility
    for a well-defined piece of software (implementing a subset of use cases).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 随着微服务和云原生架构的流行，许多人开始质疑ESB和**集成**的作用。最常见的原因是缺乏可扩展性。微服务架构方法严重依赖于产品团队的概念，每个团队开发和负责一个定义良好的软件部分（实现用例的子集）。
- en: 'A central ESB is simply against such an idea: in order to have service A talk
    to service B, you will need an integration route in the ESB, which means that
    both service A and service B are coupled to the system, both from a technical
    and an organizational point of view. You will have to pay attention to changes
    in your service that may break the compatibility with the central ESB (and the
    services dependent on it). Also, as a further side effect, you will introduce
    a single point of failure in the platform. Moreover, in the worst case, you''ll
    have to raise a ticket to a specific team, which you''ll need to implement yourself.
    This kind of complex synchronization and tight coupling between different projects
    is not the best in a fast-moving, self-service-oriented, cloud-native world.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 中心ESB根本反对这种想法：为了使服务A能够与服务B通信，你需要在ESB中实现一个集成路由，这意味着服务A和服务B从技术和组织角度来看都与系统耦合。你必须注意你服务的任何变化，这些变化可能会破坏与中心ESB（及其依赖的服务）的兼容性。此外，作为一个进一步的副作用，你将在平台上引入一个单点故障。更糟糕的是，你可能需要向一个特定的团队提交工单，而这个团队需要你自己来实现。这种在不同项目之间的复杂同步和紧密耦合在快速移动、以自助服务为导向的云原生世界中并不是最好的。
- en: '*But what happens if you remove the concept of the ESB from your architecture
    altogether?*'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*但是，如果你完全从你的架构中移除ESB的概念会发生什么？*'
- en: 'Well, the problems that an ESB tries to solve will still exist, so you will
    need to solve them anyway. In order to integrate service A with service B (especially
    if service A and B use different technologies and protocols to communicate with
    each other), you will need to implement some glue. So, commonly, integration ends
    up buried in your services. While this is a somewhat widespread practice (more
    on this in [*Chapter 9*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230), *Designing
    Cloud-Native Architectures*), I still think this has some downsides to be considered:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，ESB试图解决的问题仍然存在，所以你无论如何都需要解决它们。为了将服务A与服务B集成（尤其是如果服务A和B使用不同的技术和协议进行通信），你需要实现一些粘合剂。所以，通常情况下，集成最终会隐藏在你的服务中。虽然这是一种相当普遍的做法（更多内容请参阅[*第9章*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230)，*设计云原生架构*），但我仍然认为这有一些需要考虑的缺点：
- en: You end up polluting your business logic with technological glue that needs
    to be encapsulated and isolated from your domain model (as per the patterns seen
    in [*Chapter 6*](B16354_06_Final_JM_ePUB.xhtml#_idTextAnchor141), *Exploring Essential
    Java Architectural Patterns*).
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你最终会在你的业务逻辑中引入需要封装和从你的领域模型中隔离的技术粘合剂（正如在[*第6章*](B16354_06_Final_JM_ePUB.xhtml#_idTextAnchor141)，*探索Java关键架构模式*中看到的模式）。
- en: You will likely have many different implementations for the same use case (think
    about SOAP to REST or XML to JSON). This is inherently inefficient and may increase
    the occurrence of bugs.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可能会有很多针对相同用例的不同实现（想想SOAP到REST或XML到JSON）。这本质上是不高效的，可能会增加错误发生的频率。
- en: You will hardly reach the complete decentralization of integration capabilities.
    Supporting infrastructures for things such as service discovery, observability,
    and security will likely be needed, and are more difficult to distribute (and
    decentralizing such capabilities may be just wrong).
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你几乎无法达到集成能力的完全去中心化。支持服务发现、可观察性和安全等基础设施可能仍然需要，而且更难以分布（并且去中心化这些能力可能本身就是错误的）。
- en: 'As usual, when we look at these kinds of considerations, there is not a complete
    answer that''s good for everybody. Of course, relying on a complex and extensive
    centralized ESB may be a bottleneck (both technical and organizational), while
    trying to decentralize such capabilities may lead to repetition and a lack of
    governance. A common approach to resolving this kind of dilemma is basically to
    still rely on centralization but make it lighter and smarter. Some approaches
    to reduce coupling and implement more flexible integration include the following:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当我们考虑这些类型的考虑因素时，并没有一个适合所有人的完整答案。当然，依赖于复杂且广泛的集中式ESB可能是一个瓶颈（技术和组织上的），而试图去中心化这些能力可能会导致重复和缺乏治理。解决这类困境的常见方法基本上是仍然依赖集中化，但使其更轻便和智能。以下是一些减少耦合和实现更灵活集成的方案：
- en: It may be that your ESB becomes a set of reusable integration components (organized
    around capabilities) that you basically re-instantiate (and maybe modify) in your
    project context (hence, depending on the team providing such components, in a
    way).
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能你的ESB会变成一组可重用的集成组件（围绕能力组织），你基本上可以在你的项目环境中重新实例化（也许还会修改）它们（因此，根据提供这些组件的团队，可能以某种方式）。
- en: Such components may also not even technically be artifacts. It may be that you
    simply share the best practices and code samples (or even the complete code) with
    the project teams working with related projects. In this way, you still have some
    (light) control over what's going on, but each team has more freedom in understanding
    the component, building it, evolving it (if needed), and maybe reverting changes
    into the main collection via a pull request. Hence, this creates an open community
    behind integration capabilities across different projects.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些组件甚至可能不是技术上的工件。可能的情况是，你只是与相关项目的项目团队分享最佳实践和代码示例（甚至完整的代码）。这样，你仍然对正在发生的事情有一些（轻微）的控制权，但每个团队在理解组件、构建它、（如果需要）发展它以及通过拉取请求将更改回主集合方面有更多的自由。因此，这就在不同项目之间的集成能力背后创造了一个开放的社区。
- en: 'Another approach is to still use an ESB but limit it to one small boundary.
    So, instead of having a single, huge integration bus for the whole company, we
    can have smaller ones by department or project. They could be logical tenants
    of the same ESB (hence, reusing skills and best practices) or even completely
    different ones, based on different technologies. Once again, this is kind of a
    trade-off: you may still end up having repetition and/or bottlenecks, so the downsides
    may outweigh the benefits if you don''t manage it properly.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一种方法是仍然使用ESB，但限制它只在一个小边界内。因此，我们不必有一个为整个公司服务的单一、庞大的集成总线，我们可以通过部门或项目来拥有更小的总线。它们可以是同一ESB的逻辑租户（因此，重用技能和最佳实践）或者基于不同技术的完全不同的总线。再次强调，这是一种权衡：如果你没有妥善管理，你可能会遇到重复和/或瓶颈，因此，如果管理不当，缺点可能会超过优点。
- en: So, even though ESBs are often viewed badly in modern architectures, the need
    for integration is still there, and it's important to properly study your environment
    in order to make good choices and evolve it correctly.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，尽管ESB在现代架构中通常被看作是负面的，但集成的需求仍然存在，正确研究你的环境以做出良好的选择并正确地发展它是非常重要的。
- en: Citizen integration
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 市民集成
- en: One last trend that is worth highlighting is **citizen integration**. This is
    a trend highly studied by consulting firms and considered to be a game-changer
    in some scenarios. Basically, citizen integration is about having non-technical
    users (such as business analysts, managers, and other similar roles) being able
    to create integrations on their own, without having to rely on developers and
    other technical teams. To do so, our citizen integrators rely on highly expressive
    and user-friendly interfaces, usually simply accessible from the browser, and
    provide integration capabilities with wizards and drag and drop. Such interfaces
    are part of what's commonly called an **Integration Platform as a Service** (**IPaaS**).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个值得强调的趋势是**市民集成**。这是咨询公司高度研究的一种趋势，在某些情况下被认为是一个颠覆者。基本上，市民集成是关于让非技术用户（如业务分析师、经理和其他类似角色）能够自己创建集成，而不必依赖开发人员和其他技术团队。为此，我们的市民集成器依赖于高度表达性和用户友好的界面，通常只需从浏览器中简单访问，并提供带有向导和拖放功能的集成能力。这些界面是通常被称为**集成平台即服务**（**IPaaS**）的一部分。
- en: 'As you can imagine, this is too good to be true: IPaaS and citizen integration
    is, of course, not a silver bullet. It''s hard to solve every possible use case
    with such tools that commonly work very well on a specified subset of the infinite
    integration problems. There are technical implications too. IPaaS is a platform
    that needs to be configured and connected to backend systems, which can be a challenge
    (also from the security point of view), especially if you consider that such platforms
    are commonly hosted on the cloud.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所想，这太好了，以至于不可能是真的：IPaaS和市民集成当然不是万能的银弹。使用这些工具很难解决无限集成问题中的每一个可能用例，这些工具通常在特定的集成问题子集上工作得非常好。也存在技术影响。IPaaS是一个需要配置并连接到后端系统的平台，这可能是一个挑战（从安全角度考虑也是如此），特别是如果你考虑这些平台通常托管在云上。
- en: So, I think that the whole concept of citizen integration is still relevant
    and deserves to be thoroughly considered in your integration strategy but usually
    does not solve all the integration needs a complex enterprise may have and should
    be targeted at a well-defined subset of them.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我认为公民整合的整个概念仍然相关，值得在您的整合策略中彻底考虑，但通常并不能解决复杂企业可能拥有的所有整合需求，而应该针对其中定义明确的子集。
- en: In this section, we explored the basic components and characteristics of integration,
    including the concept of an integration route, steps, and messages. We also discussed
    what an ESB is and how such a concept is evolving, starting from centralized SOA
    and going toward more modern, decentralized, self-service approaches.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了整合的基本组件和特征，包括整合路线的概念、步骤和消息。我们还讨论了ESB是什么，以及这一概念是如何从集中的SOA发展到更现代、去中心化、自助服务的方法。
- en: Beyond the semantic difference and historical evolution of the integration technologies,
    there is a common sharing of knowledge about the integration patterns used. We
    will look at them in the next section.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 超越整合技术的语义差异和历史演变，关于整合模式的知识共享是共同的。我们将在下一节中探讨它们。
- en: Digging into enterprise integration patterns
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入企业整合模式
- en: 'The most complete and widely used collection of integration patterns is enterprise
    integration patterns. **Enterprise integration patterns** are a list of recipes
    for implementing well-known solutions to well-known problems in integration. Indeed,
    very often, the issues that occur when implementing an integration solution fall
    into some recognizable categories. According to common groupings, such categories
    include the following:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最完整和最广泛使用的整合模式集合是企业整合模式。**企业整合模式**是一系列针对整合中常见问题的已知解决方案的食谱。实际上，在实施整合解决方案时出现的问题往往落入一些可识别的类别。根据常见的分组，这些类别包括以下内容：
- en: '**Message routing**, which includes all the issues and solutions about message
    dispatching, with topics such as filtering, routing, and aggregating messages'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消息路由**，包括所有关于消息派发的问题和解决方案，包括过滤、路由和聚合消息'
- en: '**Message transformation**, which is more focused on the message content, including
    all kinds of message manipulation techniques, such as enriching, filtering, and
    *uniforming* the message content'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消息转换**，这更侧重于消息内容，包括所有类型的消息操作技术，如丰富、过滤和*统一*消息内容'
- en: '**System management**, which is a category including known techniques for managing
    and operating the integration system as a whole, including wiretaps, message archiving,
    and tracing'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系统管理**，这是一个包括管理和操作整个整合系统的已知技术的类别，包括窃听、消息归档和跟踪'
- en: In this section, we will see a curated list of these patterns.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到这些模式的精选列表。
- en: Message routing
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 消息路由
- en: 'The **message routing** family of integration patterns is a set of integration
    techniques aimed at programmatically defining the destination of an integration
    message. In this way, you can sort messages or define complex integration logic
    by chaining different integration steps designed for different types of messages.
    The most commonly used routing patterns are the following:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**消息路由**整合模式家族是一组旨在程序化定义整合消息目的地的整合技术。通过这种方式，您可以通过链式不同的整合步骤（这些步骤是为不同类型的消息设计的）来对消息进行排序或定义复杂的整合逻辑。最常用的路由模式如下：'
- en: '**Message filter**: This is probably the easiest routing pattern. Here, a message
    filter simply discards the messages that don''t comply with a specified policy.
    Such a policy can be a rule as complex as needed, which takes the message as input
    and outputs a Boolean value. The message is discarded according to that value.
    Common implementations of such a pattern include the comparison of some message
    attributes against a defined set of values. An example of a message filter is
    shown here:'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消息过滤器**：这可能是最简单的路由模式。在这里，消息过滤器简单地丢弃不符合指定策略的消息。这样的策略可以是一个复杂的规则，它将消息作为输入并输出一个布尔值。根据该值丢弃消息。这种模式的常见实现包括将某些消息属性与定义的值集进行比较。这里展示了一个消息过滤器的示例：'
- en: '![Figure 8.2 – Message filter'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.2 – 消息过滤器'
- en: '](img/Figure_8.02_B16354.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.02_B16354.jpg)'
- en: Figure 8.2 – Message filter
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 – 消息过滤器
- en: As you can see in the diagram, the message filter applies a policy to input
    messages and discards the messages that are not compliant with such a policy.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如图中所示，消息过滤器对输入消息应用策略，并丢弃不符合该策略的消息。
- en: '**Content-based router**: This is slightly more complex than the filter pattern.
    Content-based router dispatch uses logic similar to the message filter. As a result,
    the message can be delivered to two or more different destinations (including
    other integration steps, queues, or other kinds of endpoints). Of course, unlike
    the message filter use case, the criteria here don''t output a Boolean value,
    but two or more different results mapping to the destination endpoint:'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于内容的路由器**：这比过滤器模式稍微复杂一些。基于内容的路由器调度使用与消息过滤器类似的逻辑。因此，消息可以被发送到两个或更多不同的目的地（包括其他集成步骤、队列或其他类型的端点）。当然，与消息过滤器用例不同，这里的标准不会输出布尔值，而是映射到目的地端点的两个或更多不同结果：'
- en: '![Figure 8.3 – Content-based router'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.3 – 基于内容的路由器'
- en: '](img/Figure_8.03_B16354.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_8.03_B16354.jpg)'
- en: Figure 8.3 – Content-based router
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 – 基于内容的路由器
- en: We will further discuss the content-based router approach in [*Chapter 9*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230),
    *Designing Cloud-Native Architectures*, as it will conceptually support some interesting
    cloud-native behaviors in the area of release management.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第 9 章*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230)中进一步讨论基于内容的路由器方法，*设计云原生架构*，因为它在发布管理领域将概念性地支持一些有趣的云原生行为。
- en: '**Aggregator**: The aggregator is an interesting pattern because, unlike the
    others described in this list, it is a stateful one. In the aggregator pattern,
    the incoming messages are collected (according to some defined policy) and composed
    as a more complex message. Being stateful is relevant here because you may want
    to understand what happens if such components crash when some messages are currently
    in flight, and how to react to such situations:'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚合器**：聚合器是一个有趣的模式，因为它与列表中描述的其他模式不同，它是一个有状态的。在聚合器模式中，传入的消息根据某些定义的策略进行收集并组合成一个更复杂的消息。有状态在这里是相关的，因为你可能想了解如果某些消息正在传输时这些组件崩溃会发生什么，以及如何应对这种情况：'
- en: '![Figure 8.4 – Aggregator'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.4 – 聚合器'
- en: '](img/Figure_8.04_B16354.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_8.04_B16354.jpg)'
- en: Figure 8.4 – Aggregator
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – 聚合器
- en: '**Splitter**: This complements the aggregator pattern. A complex message is
    taken as an input and is divided into two or more different messages. Then, it
    may be followed by a content-based router to help dispatch each message to a different
    path to implement different business logic:'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分裂器**：这补充了聚合器模式。将复杂消息作为输入，并将其分成两个或更多不同的消息。然后，它可能随后跟一个基于内容的路由器，以帮助将每条消息发送到不同的路径以实现不同的业务逻辑：'
- en: '![Figure 8.5 – Splitter'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.5 – 分裂器'
- en: '](img/Figure_8.05_B16354.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_8.05_B16354.jpg)'
- en: Figure 8.5 – Splitter
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 – 分裂器
- en: '**Routing slip**: This is a slightly different pattern, useful to model complex
    integration logic, unpredictable beforehand. With this pattern, you basically
    attach metadata to each of your messages and identify the next integration step
    (if any) that needs to be applied against such a message. This metadata can be
    calculated using any policy relevant to your use case. You will then need to have
    a component (similar to a registry) that associates the key present in this metadata
    with a defined destination (being another component or other endpoints):'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**路由条**：这是一个略有不同的模式，用于模拟复杂且事先不可预测的集成逻辑。使用此模式，你基本上将元数据附加到每条消息上，并标识需要应用于此类消息的下一个集成步骤（如果有的话）。这些元数据可以使用与你的用例相关的任何策略进行计算。然后，你需要有一个组件（类似于注册表）将此元数据中存在的键与定义的目的地（另一个组件或其他端点）关联起来：'
- en: '![Figure 8.6 – Routing slip'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.6 – 路由条'
- en: '](img/Figure_8.06_B16354.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_8.06_B16354.jpg)'
- en: Figure 8.6 – Routing slip
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.6 – 路由条'
- en: In the previous diagram, the objects with a shape (a cross, star, or triangle)
    represent the available integration steps. By implementing the **routing slip**
    integration pattern, each message obtains a list of integration steps, which is
    attached as metadata to the message itself and calculated starting from the message
    content. In this particular case, our message will then go through the steps represented
    by the *triangle* and the *cross mark*, while skipping the step represented by
    the *star*.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的图中，形状（一个十字、星号或三角形）表示可用的集成步骤。通过实现**路由条**集成模式，每个消息都会获得一个集成步骤列表，这个列表作为元数据附加到消息本身，并从消息内容开始计算。在这种情况下，我们的消息将通过代表三角形的步骤和代表交叉标记的步骤，而跳过代表星号的步骤。
- en: Now let's move on to another family of patterns, focused on message transformation.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续讨论另一组模式，专注于消息转换。
- en: Message transformation
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 消息转换
- en: 'As it''s easy to imagine, message transformation patterns focus on changing
    the data format of the message body. This is useful when connecting systems based
    on different data models or formats (think about connecting a database to a REST
    service or a legacy application to a SaaS solution). The pattern used for message
    transformation is generically referred to as message translator and simply operates
    on the message body, manipulating it to change the format. Apart from this generic
    description, there are some specific, recognizable types of message translators.
    Some examples are the following:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如想象中一样，消息转换模式侧重于改变消息体的数据格式。当连接基于不同数据模型或格式的系统时很有用（想想将数据库连接到REST服务或将遗留应用程序连接到SaaS解决方案）。用于消息转换的模式通常称为消息翻译器，它简单地操作消息体，对其进行操作以改变格式。除了这个通用描述之外，还有一些具体的、可识别的消息翻译器类型。以下是一些例子：
- en: '**Content filter**: A content filter is somewhat analogous to the message filter.
    But instead of dropping the message as a whole when the content doesn''t comply
    with a set of rules, it operates within the message data, discards part of the
    content, and only keeps the part of the message that is relevant (by checking
    it against a set of conditions):'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容过滤器**：内容过滤器在某种程度上类似于消息过滤器。但是，当内容不符合一组规则时，它不是整个丢弃消息，而是在消息数据内部操作，丢弃部分内容，并且只保留与一组条件相关的消息部分：'
- en: '![Figure 8.7 – Content filter'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.7 – 内容过滤器'
- en: '](img/Figure_8.07_B16354.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_8.07_B16354.jpg)'
- en: Figure 8.7 – Content filter
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7 – 内容过滤器
- en: '**Content enricher**: This complements the content filter. A content enricher
    adds some new data to the message content. To do that, it relies on an external
    repository (such as a database). The enrichment algorithm may use a replacement
    (each value corresponds to another one, like when changing a ZIP code for a city
    name), a fixed value (adds the same value to each message), or more complex logic.
    Here is a diagram of it:'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容增强器**：这补充了内容过滤器。内容增强器向消息内容添加一些新数据。为此，它依赖于外部存储库（如数据库）。增强算法可能使用替换（每个值对应另一个值，例如将ZIP代码更改为城市名称时），固定值（将相同的值添加到每个消息），或更复杂的逻辑。以下是它的示意图：'
- en: '![Figure 8.8 – Content enricher'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.8 – 内容增强器'
- en: '](img/Figure_8.08_B16354.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_8.08_B16354.jpg)'
- en: Figure 8.8 – Content enricher
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8 – 内容增强器
- en: '**Canonical data model**: This is a common approach in ESBs. Basically, in
    order to decouple the message format of all the participants of the system, a
    *neutral* format is defined to be used in the ESB. This is usually a superset
    of all the messages, or simply a different format. In order to implement this
    approach, each system is plugged into the ESB with a special **Message Translator**
    component, which translates the native format of each system to the canonical
    data model, and vice versa:'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准数据模型**：这是ESB中常用的一种方法。基本上，为了解耦系统所有参与者的消息格式，定义了一个*中性*格式用于ESB。这通常是所有消息的超集，或者简单地是不同的格式。为了实现这种方法，每个系统都通过一个特殊的**消息翻译器**组件连接到ESB，该组件将每个系统的本地格式转换为标准数据模型，反之亦然：'
- en: '![Figure 8.9 – Canonical data model'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.9 – 标准数据模型'
- en: '](img/Figure_8.09_B16354.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_8.09_B16354.jpg)'
- en: Figure 8.9 – Canonical data model
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.9 – 标准数据模型
- en: '**Normalizer**: This is a special case of the canonical data model approach.
    In order to maintain the common data format inside the ESB, but use a single endpoint
    for each external system, you can use the router component (as per the *Message
    routing* section). The only purpose of such a component will be to look into the
    messages, recognize the message format (by looking into the body or header), and
    route it to a specific message translator, which must be able to translate the
    message format to the common data format:'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正规化器**：这是规范数据模型方法的一个特例。为了在ESB内部保持常见的数据格式，但为每个外部系统使用单个端点，你可以使用路由组件（如“消息路由”部分所述）。此类组件的唯一目的将是检查消息，识别消息格式（通过查看正文或标题），并将其路由到特定的消息翻译器，该翻译器必须能够将消息格式转换为常见的数据格式：'
- en: '![Figure 8.10 – Normalizer'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.10 – 正规化器'
- en: '](img/Figure_8.10_B16354.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.10_B16354.jpg)'
- en: Figure 8.10 – Normalizer
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.10 – 正规化器
- en: These are just some well-known examples, but the message translators are usually
    something very specific to the business logic, including custom approaches, such
    as the merging of different fields, string formatting, and calculations. In the
    next section, we will talk about system management patterns.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是一些众所周知的例子，但消息翻译器通常是与业务逻辑非常具体的某些东西，包括自定义方法，例如不同字段的合并、字符串格式化和计算。在下一节中，我们将讨论系统管理模式。
- en: System management
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 系统管理
- en: '**System management patterns** are essentially positioned as a way to monitor
    and manage integration routes in production. So, in this sense, they are useful
    for the operation of the platform and ensuring the service level for the customer.
    However, there are several patterns that could also be useful for implementing
    logic that solves specific use cases (besides being useful for monitoring and
    management). Such patterns include the following:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**系统管理模式**基本上定位为一种监控和管理生产中集成路由的方式。因此，从这个意义上说，它们对平台操作和确保客户服务水平是有用的。然而，还有一些模式也可能对实现解决特定用例的逻辑（除了监控和管理之外）很有用。这些模式包括以下内容：'
- en: '**Detour**: A detour is a practical technique for ensuring a particular treatment
    for some messages. In practice, you will have a content-based router triggering
    a specific path when some condition happens. The content-based router may be triggered
    by certain content in the incoming messages (as usual) or may be based on specific
    external conditions (such as special messages coming in, and maybe even on specific
    channels different from the one on which the rest of the traffic comes). When
    activated, the detour will route the messages to a different path that may be
    used for debugging, testing, or validating such messages.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**旁路**：旁路是一种确保某些消息特定处理的实用技术。在实践中，当某些条件发生时，你将有一个基于内容的路由器触发特定的路径。基于内容的路由器可能由传入消息中的某些内容（如通常情况）触发，或者可能基于特定的外部条件（例如，特殊消息的传入，甚至可能基于与其余流量不同的特定通道）。当激活时，旁路将消息路由到不同的路径，这可能用于调试、测试或验证此类消息。'
- en: 'The detour opens a lot of interesting (and modern) use cases, such as the concept
    of the circuit breaker and other cloud-native patterns (we''ll see more about
    this in [*Chapter 9*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230), *Designing
    Cloud-Native Architectures*). In the following diagram, there''s an example of
    a detour: each message is inspected and, depending on the content (using the content-based
    routing pattern), it is routed to the normal path or a special path (if some conditions
    are met). In this way, you can activate special handling for some specific messages:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 旁路打开了许多有趣（且现代）的使用案例，例如断路器概念和其他云原生模式（我们将在[*第9章*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230)，*设计云原生架构*）中了解更多。在以下图中，有一个旁路的例子：每个消息都会被检查，根据内容（使用基于内容的路由模式），它会被路由到正常路径或特殊路径（如果满足某些条件）。这样，你可以为某些特定消息激活特殊处理：
- en: '![Figure 8.11 – Detour'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.11 – 旁路'
- en: '](img/Figure_8.11_B16354.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.11_B16354.jpg)'
- en: Figure 8.11 – Detour
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.11 – 旁路
- en: '**Wiretap**: Wiretap is a pretty simple pattern. You basically add a step to
    the integration route that duplicates all the incoming messages and sends a copy
    to an alternative channel (while a copy continues to travel on the usual integration
    route). In this way, you can monitor the incoming messages (such as counting them
    or inspecting them) and analyze the system behavior with real data:'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**窃听**：窃听是一个相当简单的模式。您基本上在集成路由中添加一个步骤，该步骤复制所有传入的消息并将副本发送到另一个通道（同时副本继续在常规集成路由上传输）。这样，您可以监控传入的消息（例如计数或检查它们），并使用真实数据分析系统行为：'
- en: '![Figure 8.12 – Wiretap'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 8.12 – Wiretap](img/Figure_8.12_B16354.jpg)'
- en: '](img/Figure_8.12_B16354.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 8.12 – Wiretap](img/Figure_8.12_B16354.jpg)'
- en: Figure 8.12 – Wiretap
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.12 – 窃听
- en: '**Message history**: Message history is a simple and structured way to understand
    the path that each message flows through. Think about an integration route with
    multiple paths (such as conditional ones, which are diverted by content-based
    routers and similar patterns). It may be useful for debugging purposes or even
    mandated for regulation purposes (such as audit logging) to have a registry of
    every step spanned by the message. Message history suggests doing so by attaching
    some data at each step. This is commonly done by adding a unique key for each
    system in a specific message header. At the end of the integration route, you
    will have a list of keys identifying each integration step. Even in this case,
    this is not so different from tracking a cloud-native pattern needed for heavily
    distributed architectures (such as microservices). Here is a diagram for visualizing
    message history:'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消息历史**：消息历史是一种简单且结构化的方式来理解每条消息流经的路径。考虑一个具有多个路径的集成路由（例如基于内容的路由器等类似模式）。对于调试目的或甚至出于监管目的（如审计日志），可能需要记录消息跨越的每个步骤。消息历史建议通过在每个步骤附加一些数据来实现这一点。这通常是通过在特定消息头中为每个系统添加一个唯一键来完成。在集成路由的末尾，您将有一个标识每个集成步骤的键列表。即使在这种情况下，这也不太不同于跟踪适用于高度分布式架构（如微服务）的云原生模式。以下是可视化消息历史的图表：'
- en: '![Figure 8.13 – Message history'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 8.13 – 消息历史](img/Figure_8.13_B16354.jpg)'
- en: '](img/Figure_8.13_B16354.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 8.13 – Message history](img/Figure_8.13_B16354.jpg)'
- en: Figure 8.13 – Message history
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.13 – 消息历史
- en: In this diagram, we see the integration steps are represented by a symbol (a
    *cross mark* and a *triangle*). Each time a message passes into an integration
    step, the message is marked with an identifier corresponding to it. So, at the
    end of the integration route, you know exactly the path that each message has
    followed (if it skipped any step, went through optional paths, and so on).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在此图表中，我们可以看到集成步骤由一个符号（一个*交叉标记*和一个*三角形*）表示。每次消息进入集成步骤时，都会用相应的标识符标记该消息。因此，在集成路由的末尾，您可以确切知道每条消息所经过的路径（如果它跳过了任何步骤，通过了可选路径等）。
- en: '**Message store**: There are use cases in which you want to know exactly the
    content of each message, including intermediate transformation. This can be required
    for a subset of messages (such as for troubleshooting purposes) or all messages
    (as we saw in the message history pattern, that may be for audit logging requirements).
    The message store pattern suggests implementing this case by attaching a wiretap
    to each integration and diverting every message (or some messages, conditionally)
    to a shared message store (such as a database).'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消息存储**：在某些用例中，您可能需要确切知道每条消息的内容，包括中间转换。这可能适用于消息的子集（例如，用于故障排除目的）或所有消息（正如我们在消息历史模式中看到的，可能出于审计日志要求）。消息存储模式建议通过在每个集成中附加窃听器并将每条消息（或某些消息，条件性地）重定向到共享消息存储（如数据库）来实现这种情况。'
- en: 'It may be necessary to add some complementary metadata, such as a timestamp,
    an identifier for each step, and maybe a signature (for checking the data integrity).
    In some cases, the message store may need to implement specific technologies for
    non-repudiation, such as **Write Once, Read Many** (**WORM**), in terms of special
    anti-tampering hardware. The following diagram visualizes the workings of the
    message store:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 可能需要添加一些补充元数据，例如时间戳、每个步骤的标识符，以及可能的一个签名（用于检查数据完整性）。在某些情况下，消息存储可能需要实现特定的技术以实现不可否认性，例如在特殊防篡改硬件方面的**一次写入，多次读取**（**WORM**）。以下图表展示了消息存储的工作原理：
- en: '![Figure 8.14 – Message store'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 8.14 – Message store](img/Figure_8.14_B16354.jpg)'
- en: '](img/Figure_8.14_B16354.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 8.14 – Message store](img/Figure_8.14_B16354.jpg)'
- en: Figure 8.14 – Message store
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.14 – 消息存储
- en: '**Test message**: This is a simple health check for integration routes. Basically,
    in order to understand the message flow (such as whether there is any intermediate
    component losing messages or taking too long to process them), you inject some
    special test messages into the integration route. You will then need a content-based
    router at the end of the integration route in order to identify such special messages
    (such as looking for a particular pattern in the data or a special key in a header).
    Then, you''ll need to route it to a monitoring system, which can then check whether
    every message is returned (so that there is no message dropping) or calculate
    the elapsed time, and so on.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试消息**：这是对集成路由的简单健康检查。基本上，为了理解消息流（例如，是否有任何中间组件丢失消息或处理消息时间过长），你需要在集成路由中注入一些特殊的测试消息。然后，你需要在集成路由的末尾放置一个基于内容的路由器，以便识别这类特殊消息（例如，在数据中查找特定的模式或在标题中查找特殊键）。然后，你需要将其路由到监控系统，该系统可以检查是否每条消息都被返回（这样就不会丢失消息），或者计算经过的时间等。'
- en: 'Bear in mind that every intermediate step may need to be aware of or at least
    resistant to this kind of test message. This means that if you are calling external
    systems or writing data to a database, you may want to instruct a specific step
    to skip in the case of test messages. In the next diagram, we can see a graphical
    representation of this pattern, that is, a content-based router that identifies
    a special test message and routes it to a monitoring system, instead of the standard
    integration flow:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，每个中间步骤可能都需要意识到或至少能够抵抗这种测试消息。这意味着如果你正在调用外部系统或将数据写入数据库，你可能希望指示特定的步骤在测试消息的情况下跳过。在下一张图中，我们可以看到这种模式的图形表示，即一个基于内容的路由器，它识别特殊的测试消息并将其路由到监控系统，而不是标准的集成流程：
- en: '![Figure 8.15 – Test message'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.15 – 测试消息'
- en: '](img/Figure_8.15_B16354.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_8.15_B16354.jpg)'
- en: Figure 8.15 – Test message
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.15 – 测试消息
- en: The group of system management patterns is different from what we have seen
    so far. They are less focused on application logic and data and more on the monitoring,
    maintenance, and operation of the integration infrastructure. This does not mean
    that you cannot use them to implement some use cases (think about the Wiretap
    pattern, which can be a way to implement multiple different behaviors on the same
    message), but that's for sure not the main usage.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 系统管理模式的集合与我们之前所看到的不同。它们不太关注应用逻辑和数据，而更多地关注集成基础设施的监控、维护和操作。这并不意味着你不能使用它们来实现某些用例（想想
    Wiretap 模式，它可以作为在相同消息上实现多种不同行为的一种方式），但肯定不是主要用途。
- en: As we said, all the patterns that we have seen so far are useful both for synchronous
    and asynchronous integration. However, when it comes to async use cases, a whole
    new set of considerations arises in terms of messaging brokers and integration
    with them. This is partially related to enterprise integration patterns and partially
    implicit in the technology itself (which may be referred to as **message-oriented
    middleware**, or more commonly, **queue managers**). In the next section, we will
    have a look at those cases.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所说，到目前为止我们所看到的所有模式都对同步和异步集成都很有用。然而，当涉及到异步用例时，在消息代理及其集成方面会出现一系列全新的考虑因素。这部分与企业集成模式有关，部分则隐含在技术本身中（可能被称为**面向消息的中间件**，或者更常见的是，**队列管理器**）。在下一节中，我们将探讨这些案例。
- en: The Camel integration framework
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Camel 集成框架
- en: '**Apache Camel** is likely the most famous open source integration framework.
    It was created in the years after 2000 and it has been evolving constantly since
    then, mostly because of the very active community behind it. At the time of writing,
    Camel has hundreds of contributors and thousands of stars on GitHub.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**Apache Camel** 可能是最著名的开源集成框架。它是在2000年之后创建的，并且从那时起一直在不断进化，这主要归功于其背后非常活跃的社区。在撰写本文时，Camel
    拥有数百位贡献者和数千颗 GitHub 星标。'
- en: Camel isn't exactly an ESB but can be used as one. It is more like a core engine
    containing integration capabilities. Indeed, Camel implements the enterprise integration
    patterns by design (and other patterns, including some techniques for cloud-native
    applications). Moreover, Camel includes hundreds of connectors for specific technologies
    (such as queues, databases, and applications) and data formats (such as JSON and
    XML). Camel can be run standalone or on top of a selection of runtimes (including
    Quarkus, which we saw in the previous chapter). It can be deployed as an ESB (centralizing
    all the integration capabilities at one point) or embedded in your applications
    (distributing such capabilities where it's needed).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: Camel 并非一个真正的 ESB，但可以用作 ESB。它更像是一个包含集成能力的核心引擎。实际上，Camel 通过设计实现了企业集成模式（以及其他模式，包括一些云原生应用的技巧）。此外，Camel
    包含了数百个针对特定技术（如队列、数据库和应用程序）和数据格式（如 JSON 和 XML）的连接器。Camel 可以独立运行或在一系列运行时之上运行（包括我们在上一章中看到的
    Quarkus）。它可以作为 ESB 部署（在一点集中所有集成能力）或嵌入到您的应用程序中（将这种能力分布到需要的地方）。
- en: The Camel DSL
  id: totrans-152
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Camel DSL
- en: Camel exactly implements the concept of routes as we have seen it so far, as
    a sequence of specific steps to run against each message (intended as a piece
    of data). In order to specify each route with Camel, you can use a `.xml` file
    or the Java **Domain-Specific Language** (**DSL**), which is basically a dialect
    of Java made for the purpose of expressing concepts specific to the Camel world.
    For the purpose of this section, we will use the Java DSL, which allows the definition
    of routes using a Java-fluent API.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Camel 完全实现了我们迄今为止所看到的路由概念，即将一系列特定的步骤应用于每条消息（被视为数据的一个片段）。为了使用 Camel 指定每条路由，你可以使用一个
    `.xml` 文件或 Java **领域特定语言**（**DSL**），这基本上是为了表达 Camel 世界中特定概念而制作的 Java 方言。在本节中，我们将使用
    Java DSL，它允许使用 Java 流畅 API 定义路由。
- en: 'This is what a simple integration route that converts JSON to XML looks like:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个将 JSON 转换为 XML 的简单集成路由的示例：
- en: '[PRE0]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you will see, there is `from`, which is the endpoint starting the integration
    route (in our case, by exposing an HTTP REST endpoint, by using a component called
    `platformHttp`), and `to`, which writes the final result to a file (by using the
    `file` component). In between, you can see an example of data transformation,
    including the mapping (`unmarshal`) of a JSON object to a Java object, and then
    mapping back (`marshal`) of such a **Plain Old Java Object** (**POJO**) to XML.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您将看到的，有 `from`，它是启动集成路由的端点（在我们的案例中，通过暴露一个 HTTP REST 端点，使用名为 `platformHttp`
    的组件），以及 `to`，它将最终结果写入文件（使用 `file` 组件）。在两者之间，您可以看到一个数据转换的示例，包括将 JSON 对象映射到 Java
    对象的映射（`unmarshal`），然后将这样的 **普通 Java 对象**（**POJO**）映射回 XML。
- en: We will see a more complete example in the *Case studies and examples* section.
    Now, let's have an overview of the messaging concepts.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 *案例研究和示例* 部分看到一个更完整的示例。现在，让我们概述一下消息概念。
- en: Messaging
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 消息传递
- en: '**Messaging** is a core concept in the integration world. In the previous section,
    we discussed messages as the basic unit of data flowing inside each integration
    step. Let''s now focus a bit more on the concepts specific to messaging, such
    as message brokers, asynchronous interactions, producers, and consumers. First,
    we will start with the broker concept.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '**消息传递** 是集成世界中的核心概念。在前一节中，我们讨论了消息作为每个集成步骤内部流动的基本数据单元。现在，让我们更深入地关注消息特有的概念，例如消息代理、异步交互、生产者和消费者。首先，我们将从代理概念开始。'
- en: Defining the broker concept
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义代理概念
- en: A **broker** is a common, elementary concept in IT. It can be intended as an
    architectural solution as well as a technology.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**代理** 是 IT 领域的一个常见、基本概念。它可以被视为一种架构解决方案，也可以被视为一种技术。'
- en: From an architectural standpoint, a broker allows producers to push messages
    into an intermediate system (a broker itself), which dispatches it to one or more
    consumers. The message broker concept is described in the homonymous enterprise
    integration pattern.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 从架构角度来看，代理允许生产者将消息推送到一个中间系统（一个代理本身），该系统将其分发给一个或多个消费者。消息代理概念在同名企业集成模式中进行了描述。
- en: Beyond this simple description, a huge number of variants and other concepts
    can be elaborated on, influenced by the underlying technology and the use case
    we are trying to model. Examples of broker technology include Apache ActiveMQ,
    Kafka, and RabbitMQ.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这个简单的描述之外，还有大量的变体和其他概念可以详细阐述，受底层技术和我们试图建模的使用案例的影响。代理技术的例子包括 Apache ActiveMQ、Kafka
    和 RabbitMQ。
- en: Now, let's dig into some basic messaging concepts.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入探讨一些基本的消息概念。
- en: Queues versus topics
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 队列与主题
- en: The first categorization that is common in a Java programmer's mind is queues
    versus topics. This differentiation has been made famous by the **Java Message
    Service** (**JMS**), which is the API defining messaging practices under the Java
    Enterprise standard.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在Java程序员心中常见的第一个分类是队列与主题。这种区分是由**Java消息服务**（**JMS**）所著名，它是定义Java企业标准下消息实践的API。
- en: In the JMS world, a **queue** is defined in the message broker, which takes
    care of messages sent by producers and dispatches them to a consumer. If there
    are no consumers available, the queue stores them until one connects, trying to
    avoid the loss of messages. This is referred to as the **store and forward** approach.
    The queue can also be used for point-to-point connections (one producer and one
    consumer) as the **point-to-point channel enterprise integration pattern**.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在JMS世界中，**队列**是在消息代理中定义的，它负责处理生产者发送的消息并将它们分发给消费者。如果没有消费者可用，队列将存储这些消息，直到有消费者连接，以尝试避免消息丢失。这被称为**存储转发**方法。队列还可以用于点对点连接（一个生产者和一个消费者），作为**点对点通道企业集成模式**。
- en: A common usage of queues is to have one or more producers and a number of consumers
    that may also vary with time, depending on the number of messages to work effectively
    (an example of horizontal scaling). In this case, each consumer takes a message
    in an exclusive way, usually with some sort of transactional semantic. This pattern
    is named **Competing Consumer** in the enterprise integration patterns world.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 队列的常见用法是有一个或多个生产者和一些消费者，这些消费者的数量可能随时间变化，取决于要有效处理的消息数量（水平扩展的一个例子）。在这种情况下，每个消费者以独占的方式获取一条消息，通常带有某种事务性语义。这种模式在企业集成模式世界中被称为**竞争消费者**。
- en: A **topic** has a slightly different semantic. In a topic, the messages sent
    by producers are propagated to all the consumers connected in that particular
    moment. This is similar to the concept of a broadcast, commonly used in networking.
    Consumers usually lose all the messages sent before they were connected with that
    particular topic.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '**主题**有一个稍微不同的语义。在主题中，生产者发送的消息会传播给在那个特定时刻连接的所有消费者。这类似于网络中常用的广播概念。消费者通常会在与特定主题连接之前丢失所有发送的消息。'
- en: Queues and topics are two high-level concepts that encompass, in recognizable
    names, a number of different characteristics of the messages, producers, and consumers
    involved (and may include different variants). In the enterprise integration pattern
    world, a queue is defined as a point-to-point channel including the Competing
    Consumer pattern. The topic is instead defined by the concept of the **publish-subscribe
    channel**, in which you have one or more producers, and not every consumer is
    competing, but instead receives a copy of each message, in a broadcast fashion,
    where everybody receives every message.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 队列和主题是两个高级概念，以可识别的名称涵盖了涉及消息、生产者和消费者的一些不同特征（可能包括不同的变体）。在企业集成模式世界中，队列被定义为包括竞争消费者模式在内的点对点通道。而主题则由**发布-订阅通道**的概念定义，其中有一个或多个生产者，并不是每个消费者都在竞争，而是接收每条消息的副本，以广播的方式，每个人都能收到每条消息。
- en: Message quality of service
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 消息服务质量
- en: 'An important concept, often related to the underlying messaging technology,
    is the **quality of service** (also known as **QoS**). QoS, in the context of
    messages, refers to the *commitment* that the broker takes on when it comes to
    delivering our message to consumers. This refers to what happens after the producer
    puts a message into the system and gets an acknowledgment from the broker. Then,
    based on the configuration of the system, three delivery scenarios are possible:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的概念，通常与底层消息技术相关，是**服务质量**（也称为**QoS**）。在消息的上下文中，QoS指的是代理在将我们的消息传递给消费者时所做出的*承诺*。这指的是生产者在将消息放入系统并获得代理的确认之后会发生什么。然后，根据系统的配置，可能出现三种交付场景：
- en: '**At most once**, which means that the message may not be delivered at all,
    but if it''s indeed delivered, it will not be delivered more than once. Here,
    the use case is about *best-effort* messages (so, we can lose some), where duplication
    is to be avoided (because it *pollutes* our downstream systems). A real-world
    example of this is currency exchange rates. These are values that change very
    often, and in some scenarios (such as high-frequency trading), you would rather
    lose one value (which is valid for a very short period of time and overridden
    by a new one) than just having a *ghost* value caused by a message duplicate.
    Here is a diagram to illustrate this:'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**至多一次**，这意味着消息可能根本不会被交付，但如果确实被交付，则不会重复交付。在这里，用例是关于**尽力而为**的消息（因此，我们可以丢失一些），其中要避免重复（因为这会*污染*我们的下游系统）。现实世界中的例子是货币汇率。这些值变化非常频繁，在某些场景（如高频交易）中，你宁愿丢失一个值（这个值在非常短的时间内有效，并被新的一个覆盖），也不愿有一个由消息重复引起的*幽灵值*。以下图表说明了这一点：'
- en: '![Figure 8.16 – At most once message delivery'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.16 – 至多一次消息交付'
- en: '](img/Figure_8.16_B16354.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.16_B16354.jpg)'
- en: Figure 8.16 – At most once message delivery
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.16 – 至多一次消息交付
- en: '**At least once**, which implies that messages will never get lost, but may
    be sent more than once to consumers. Here, the use case is, of course, the opposite
    to the previous one. In particular, it''s more important to not lose any messages.
    In the real world, this could be an **Internet of Things** (**IoT**) scenario:
    imagine collecting field data from an industrial machine. You may prefer to have
    all messages (which, for example, may highlight an imminent failure), even if
    this means that you may have duplicates (which could be discarded in downstream
    systems or simply be considered as harmless). The following diagram exemplifies
    this:'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**至少一次**，这意味着消息永远不会丢失，但可能会被发送多次给消费者。在这里，用例当然是与之前相反的。特别是，不丢失任何消息更为重要。在现实世界中，这可能是一个**物联网**（**IoT**）场景：想象从工业机器收集现场数据。你可能更希望拥有所有消息（例如，可能突出即将发生的故障），即使这意味着你可能会有重复（这些重复可以在下游系统中丢弃，或者简单地被认为是无害的）。以下图表举例说明了这一点：'
- en: '![Figure 8.17 – At least once message delivery'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.17 – 至少一次消息交付'
- en: '](img/Figure_8.17_B16354.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.17_B16354.jpg)'
- en: Figure 8.17 – At least once message delivery
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.17 – 至少一次消息交付
- en: '**Exactly once**, which is the ideal scenario that you can imagine when approaching
    a messaging system. Needless to say, here the broker guarantees that your message
    will be delivered and no duplicates will exist. This, of course, may be a mandatory
    requirement in some kinds of use cases. Typically, in the real world, this is
    related to financial services: once you have entered a payment transaction, you
    cannot afford to lose it, nor execute it twice. The following diagram demonstrates
    this:'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**恰好一次**，这是当你接近消息系统时可以想象的最理想场景。不用说，在这里，代理保证你的消息将被交付，且不会有重复。当然，在某些用例中，这可能是一个强制性的要求。通常，在现实世界中，这与金融服务相关：一旦你完成了一次支付交易，你就无法承受丢失它，也不能执行两次。以下图表演示了这一点：'
- en: '![Figure 8.18 – Exactly once message delivery'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.18 – 恰好一次消息交付'
- en: '](img/Figure_8.18_B16354.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.18_B16354.jpg)'
- en: Figure 8.18 – Exactly once message delivery
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.18 – 恰好一次消息交付
- en: '*Now, you might be wondering, why don''t we simply stick with the exactly once
    delivery scenario every time, and simplify our lives?* The answer is simple and
    expected: exactly once is the most expensive of the three. Since the system will
    need to lock at some point (to check for duplicates), providing there are the
    same number of messages and the same hardware, exactly once would probably be
    the worst choice in terms of performance. This may not be noticeable with low
    traffic, but it may be crucial if you are designing with high-traffic peaks in
    mind.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '*现在，你可能想知道，为什么我们每次都不简单坚持使用“恰好一次”的交付场景，简化我们的生活呢？* 答案简单且预期：恰好一次是三种中成本最高的。由于系统需要在某个时刻锁定（以检查重复项），假设消息数量和硬件相同，从性能的角度来看，恰好一次可能是最差的选择。在低流量情况下，这可能不明显，但如果考虑到高流量峰值，这可能是至关重要的。'
- en: Zero message loss
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 零消息丢失
- en: 'In messaging, it''s a common requirement to guarantee the zero loss of messages
    (and as we have seen, this is a combination of at least once and exactly once
    QoS). In order to provide such requirements, messaging systems usually use two
    kinds of solutions:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '**Message persistence**, which is usually on a filesystem or database. This
    means that a producer will get an acknowledgment for putting a message in a queue
    only after the message is serialized on the persistent storage. In this way, in
    the event of a system crash, it is guaranteed that the situation can be recovered
    by reading from the journal. Here is a diagram for demonstration:'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.19 – Message persistence'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.19_B16354.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.19 – Message persistence
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '**Message copies**, which are sent to different instances of the message broker.
    The producer gets the acknowledgment for putting a message in the queue after
    a copy of the message is propagated (over the network) to one or more (usually
    configurable) backup instances of the messaging system. This guarantees that,
    in the case of our messaging system crashing, the backup instances can take over
    and deliver the message. Of course, in this scenario, you are reducing but not
    eliminating risks. You may still end up with all the instances down in the case
    of catastrophic failures, and you should plan accordingly (such as using different
    physical locations, where possible), as shown in the following diagram:'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.20 – Message copies'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.20_B16354.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.20 – Message copies
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Zero message loss scenarios almost always have performance impacts.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: Other messaging concepts
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As has been said, depending on the underlying implementation technology, there
    are a number of use cases that can be implemented in the messaging world. Here
    is a list of the most useful ones:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '**Dead Letter Queue** (**DLQ**): This is pretty common in any messaging system.
    A DLQ is basically a special location, as shown in the following diagram, to redirect
    messages when certain conditions happen (such as no consumers are available after
    a certain amount of time, as we will see in the next point about time to live)
    or simply when the broker doesn''t know what to do with a message (for example,
    for runtimes or configuration errors). It''s a common behavior to persist and
    monitor the DLQ as an indicator if something goes wrong and if the messages contain
    any recoverable data.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.21 – Dead letter queue'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.21_B16354.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.21 – Dead letter queue
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '**Time to live**: When used, time to live is an attribute associated with each
    message when it is inserted into the queue. It will define the expiry of the message:
    if a message is still in the queue after the expiration has occurred (because
    there are no consumers or they aren''t fast enough), it could be discarded or
    moved to a special queue (such as the DLQ).'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It''s an elegant way to model some use cases: there are some kinds of data
    that are just useless after a certain amount of time has passed (maybe because
    some more recent information has become available by that time). In this way,
    you avoid putting overhead on the consumers. However, if you have too many messages
    expiring, there is probably a need for something else to be tuned (such as the
    availability and performance of the consumers).'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '**Duplicate checks**: Some broker implementations can check messages against
    duplicates. This is usually a delicate matter to handle. There are different possible
    implementations, but the most common one involves the presence of a unique identifier
    for the message (which can be provided externally, such as a database key, or
    calculated by the broker, such as a hash) and storing such messages in a proper
    data structure (such as a database or a key-value store). Each message is then
    checked against such a structure, and if a duplicate is found, the message is
    discarded. The message store commonly has a fixed maximum size or an expiration
    to avoid indefinite growth.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Priority**: This is a common requirement for some use cases. Basically, it
    is the possibility to identify some messages as having a higher priority than
    others (usually setting a specific header), to inform the broker to have it delivered
    before the other messages in the queue (if present).'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bridge**: This is an infrastructure for multiple queue management that basically
    passes messages from one broker to another, as shown in the following diagram.
    It can copy the messages or just move them to another queue and broker. It''s
    useful to interface with different technologies and existing systems, or even
    to provide reliability (such as a multi-site messaging system):'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.22 – Bridge infrastructure'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.22_B16354.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.22 – Bridge infrastructure
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '**Filters**: This is a common functionality of brokers, which mimics the content-based
    router pattern that we have already seen. It''s basically a configuration instructing
    the broker to move messages between different queues when some conditions happen
    (such as if a special header is present or a condition is met in the message payload).'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Chunking**: It may happen that a queue is used to transfer data of a consistent
    size. In order to avoid hogging the broker and handle very big messages, a broker
    can implement chunking. As it''s easy to imagine, a big message is then chunked
    into smaller parts before being delivered, as shown in the following diagram.
    However, some mechanism is needed to reconstruct the message on the consumer''s
    side. A common one is to tag each chunk with an identifier and a sequence number:'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.23 – Message chunking'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.23_B16354.jpg)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.23 – Message chunking
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '**Schema**: It''s sometimes useful to perform some validation on the messages
    inserted into the broker. A smart way to do that is to define a data schema (such
    as an XSD). The messages that are not compliant with such a schema are then discarded
    or moved to special queues (such as the DLQ), as follows:'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.24 – Data schema in messaging'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.24_B16354.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.24 – Data schema in messaging
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: This list completes our considerations about messaging. In this section, we
    have seen many constructs (such as brokers, queues, and topics) and configurations
    (such as QoS and zero message loss) that can be used to model a lot of different
    use cases. In the next section, we will focus on the protocols and formats of
    data.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: Exploring formats
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have seen in the previous sections, integration works with flows (synchronous
    or asynchronous) of small information bites (in the form of messages) to be acted
    upon. Such messages are usually formatted into well-known shapes. Let's have a
    quick overview of the most common ones.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: XML
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ostracized for being verbose and cumbersome, and often considered old and past
    it, **eXtensible Markup Language** (**XML**) is simply here to stay. And for good
    reason, since, as we will see, it has a number of powerful and useful features.
    To start, XML files are expressive and structured, and there is a lot of tooling
    supporting them.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what a simple XML file looks like:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'I''m sure everybody is familiar with XML; however, just to set common ground,
    the characteristics of a proper `.xml` file are as follows:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: It is text-based.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a special tag at the beginning, called a `<?xml version="1.0" encoding="UTF-8"?>`).
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a root tag including all the other tags in the document (excluding
    the prolog, which is considered to be a special element of the document).
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each tag of the document can include text content (`<myTag>my content</myTag>`)
    or other tags (`<myTag> <mySubTag>...</mySubTag> </myTag>`). This is called an
    **element**.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each tag may include one or more key-value pairs, called `<myTag myKey="myValue"
    ...>...</myTag>`).
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each tag must be opened and closed properly (such as `<myTag>...</myTag>`).
    The shorthand form is allowed if the tag is empty (`<myTag/>`). Tags must be properly
    nested: if you open a tag, you can open other tags inside it, but you need to
    close the parent tag before closing the child tags (`<myTag><myOtherTag></myOtherTag></myTag>`
    is allowed, while `<myTag><myOtherTag></myTag></myOtherTag>` is not).'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Special characters, such as `<`, `>`, and `"`, must be replaced with special
    entity references, such as `&lt;`, `&gt;`, and `&quot;`, which are commonly called
    **escape sequences** and are basically one-to-one mappings between each special
    character and the related entity reference.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Most likely, such rules are just taken for granted: after all, you have probably
    already edited a `.html` file (which is a sibling of the `.xml` file) or a configuration
    file in the XML format.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned, detractors of XML say that it is long and hardly human-readable,
    not to mention the frustration of parsing errors when you try to manually edit
    it: one single character off will often corrupt the whole file.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: 'However, due to this simple but powerful syntax, XML provides some interesting
    features:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '`.xml` file is considered to be the instance. An XSD can be applied to a given
    `.xml` file to ensure it is compliant with such a specification. That''s crucial
    in machine-to-machine interactions and may reduce the number of runtime errors.
    By defining an XSD, you are basically creating an XML dialect suitable for your
    own problem.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.xml` document. That''s particularly interesting in the context of integration
    (think about the content filter or content-based router patterns that we have
    seen), so most of the available ESB technology provides support for this kind
    of feature.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.xml` files. In this way, you can set rules allowing a processor to change
    a `.xml` file from one definition to another, mapping and transforming tags in
    the source files to something different in the target files. Also, in this case,
    it''s an interesting feature in the integration world that can basically cover
    most of the message transformation patterns.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Talking about XML is like talking about Java: there is plenty of criticism
    around calling it an old and outmoded standard. However, while more modern approaches
    have, of course, come along and deserve attention, XML, like Java, provides proper
    support for a wide range of use cases to date, due to a structured set of rules
    and the extensive availability of supporting tools and technology.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: Working with XML in Java
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The translation of `.xml` files from and to Java objects is a pretty common
    task. There are basically two ways to do so:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: The first (and now less common) way to parse XML is to use `.xml` document upfront
    that you are going to parse. So, you rely on a streaming approach, in which XML
    is traversed from the beginning to the end, and each element triggers events,
    such as the start element and the end element.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each event contains the data for the particular elements (contents and attributes).
    While it is not particularly widespread today and has some practical disadvantages
    (the creation of Java objects is cumbersome and random access to elements is not
    allowed), this kind of parsing has the advantage of usually being very efficient,
    especially in terms of memory usage. The most famous implementation of XML streaming
    in Java is **SAX** ([www.saxproject.org](http://www.saxproject.org)).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: The most common way to implement XML serialization and deserialization is to
    use **direct mapping**. With this approach, there is a direct link between elements
    (and attributes) of the XML content and fields of the POJO. Such linking is defined
    by a proper mapping, which could be defined in configuration files or, more conveniently,
    by using annotations. Part of the mapping can also be implicit (such as fields
    mapped to homonymous XML elements and vice versa).
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nested elements are commonly mapped using collections or other complex subobjects.
    This approach is heavily used in integration (but not only that), as XML content
    is mapped to Java objects that are then used for business logic, checks, and other
    interactions. The most common implementation of XML mapping in Java is provided
    by `Jackson`, a JSON library that we saw in [*Chapter 7*](B16354_07_Final_JM_ePUB.xhtml#_idTextAnchor164),
    *Exploring Middleware and Frameworks*, in the *JPA and REST (and more) with Quarkus*
    section, can also be used as a framework for REST serialization for XML mapping
    (and supporting other data formats too).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: Whatever the approach is for parsing, mapping XML to Java is a pretty common
    use case in the enterprise world, as XML is a widely used format for data interchange
    (used in many different industries, including banking and healthcare).
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next section, we are going to see a challenger of XML in the field of
    web services: JSON notation.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: JSON
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have already seen and used JSON, in [*Chapter 7*](B16354_07_Final_JM_ePUB.xhtml#_idTextAnchor164),
    *Exploring Middleware and Frameworks*, in the *Jakarta RESTful web services* section.
    Now, it's time for a bit of theory about it.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '**JSON** is the acronym for **JavaScript Object Notation**. It is a text representation
    for representing data. The technology was born in the context of web development
    when the AJAX application became widespread. We will see more about AJAX and web
    development in [*Chapter 10*](B16354_10_Final_JM_ePUB.xhtml#_idTextAnchor250),
    *Implementing User Interaction*, but for now, it''s enough to know that it''s
    now a common technology that started to be used around 1999 and is about web pages
    dynamically requesting data from the backend after the page is downloaded by the
    browser. To do so, the JavaScript language is used on the client side for both
    requesting and parsing such data.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: 'While it is possible to use XML to serialize such data, JSON emerged as an
    effective and simpler alternative. JSON is indeed native to JavaScript, and the
    serialization/deserialization of JavaScript objects to JSON is done without the
    need for external libraries. This is what a simple JSON file looks like:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: JSON is basically made of primitive types (such as strings, Booleans, and numbers),
    objects, which have one or more key-value pairs enclosed in curly brackets, and
    arrays, which are collections of other objects, arrays, or primitive types, enclosed
    in square brackets. The thing that made JSON popular, other than being native
    to JavaScript, is that it is less verbose and more human-readable than XML.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: The major criticism of JSON is that it's less *structured* than XML, which has
    produced a number of other concepts and technologies in terms of validation (XSD,
    as we saw in the previous section), web services (SOAP), querying (the aforementioned
    XPath and XQuery), and more (such as security and other features associated with
    the SOAP standard).
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: However, JSON nowadays covers some (if not all) of those features, both natively
    and via third-party implementation. It's worth mentioning that JSON Schema is
    a technology available for syntactic validation, and other implementations, such
    as JSONPath, are used for querying JSON documents. Moreover, JSON is commonly
    used as a base technology in NoSQL document databases (we'll see more on this
    in [*Chapter 11*](B16354_11_Final_JM_ePUB.xhtml#_idTextAnchor271), *Dealing with
    Data*). In the next couple of sections, we are going to see the interactions between
    JSON and YAML (which is a widely used data format nowadays), and, of course, JSON
    and Java.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: JSON and YAML
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**YAML Ain''t Markup Language** (**YAML**) is an alternative data serialization
    language created in 2001 that became widespread with the popularity of Kubernetes
    because it''s used as a format to encode resources and configurations (we''ll
    see more on Kubernetes in [*Chapter 9*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230),
    *Designing Cloud-Native Architectures*). YAML is also widely used in frameworks
    such as Quarkus and Spring Boot for managing configurations of microservices.
    YAML is designed to be easily human-readable and is heavily based on key-value-like
    structures (and more complex objects), which are organized using a syntax similar
    to the Python language, which relies on spaces to define hierarchies.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what a simple YAML file looks like:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: It's interesting to note that, since YAML can (but does not enforce doing so)
    use a syntax based on curly brackets, it is indeed a proper superset of JSON.
    This means that YAML provides some additional features that are not present in
    JSON (such as comments and richer data type management).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: A YAML parser, in other words, can parse JSON documents. Moreover, if the additional
    features are not used, a YAML document can be directly translated to JSON (and
    vice versa) without losing any data. Indeed, the example for YAML that we have
    seen is the exact representation of the example for JSON that we saw in the section
    before.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: Working with JSON in Java
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we already know, the parsing of JSON files is native in JavaScript, while
    in Java the already mentioned `Jackson` library is a common way to work with JSON.
    The mapping, as we saw in [*Chapter 7*](B16354_07_Final_JM_ePUB.xhtml#_idTextAnchor164),
    *Exploring Middleware and Frameworks*, is made by associating (explicitly by using
    an annotation, or implicitly by relying on the name) each field of the POJO to
    each key of the `.json` file, similar to the approach of JAXB for XML mapping.
    This kind of mapping is particularly useful when dealing with REST web services.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: Protobuf
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Protocol Buffers** (**Protobuf**) is a slightly different way to store data.
    It was created by Google as an internal tool (widely used within their infrastructure)
    and then was open sourced. The most notable difference from the other technologies
    seen so far is that Protobuf is a binary protocol. As per the other technologies
    seen so far, it is language-independent, so you can use it as a way to communicate
    from Java to other technologies.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: Google (and the other organizations and contributors involved in the open source
    community) provides tools for serializing, deserializing, and in general working
    with Protobuf, including an SDK for Java. The SDK contains a compiler (protoc)
    that acts as a source code generator. Basically, when given a specific configuration
    (in a `.proto` file), it creates all the needed scaffolding for serializing and
    deserializing POJOs to and from byte arrays (and they then can be sent over the
    network, persisted to a file, or used as a message). Since the output is in a
    binary format, it is very efficient and optimized.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: 'The configuration is basically a declaration of all the fields contained in
    the POJO you want to serialize, plus some metadata:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here are some details about the preceding block of code:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '`syntax` refers to the version of Protobuf used. **Proto3** is the current
    version at the time of writing.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The two `option` keywords are specific to Java. They will configure the name
    of the class and the package containing all the autogenerated facilities.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`message` is the description of each field. Other than the name of the object
    (`MyPojo`), it defines the name of each field and the primitive type (`string`,
    `int32`, and so on). The field can be prefixed by the `repeated` keyword, meaning
    that a specific field can be present multiple times in a valid message. If that
    keyword is not present, it can be present zero or one times (not more than once).
    Last but not least, each field is attached to a numerical index (`1`, `2`, `3`,
    and so on), which Protobuf uses as a unique identifier for the fields in a message.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running the protoc compiler against the `.proto` file will generate a class
    (in our case, named `MyPojoProto`). This file will contain an inner class that
    will be used to represent our POJO (a message, in Protobuf jargon, which in our
    case is named `MyPojo`). In the class, there will also be a number of utility
    methods, including a builder to create such messages, and methods to serialize
    and deserialize to and from byte arrays.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have seen a number of widely used data formats, such as
    XML, which is a traditional, old, and widely used technology; JSON, which has
    become more and more popular also, thanks to JavaScript and web technologies;
    and Protobuf, a less-used alternative with a different approach and aiming to
    reach cases where a binary format is needed.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: Exploring communication protocols
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous sections, we focused on the data formats used for storing and
    exchanging information in a standard way. The next step is identifying the ways
    to exchange such information, in other words, the most commonly used communication
    protocols.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: SOAP and REST
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**SOAP** and **REST** are two widely used communication protocols. Even if
    they have been mentioned many times in previous chapters (and in this chapter
    too), I think it''s still relevant to provide a quick summary of them, as this
    can be the key to understanding the role of communication protocols in integration
    systems:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '`envelope`, containing a header and a body. Being regulated by a lot of substandards,
    SOAP is used to define the methods, the exchanged data, and optionally other specifications,
    such as the security, to be used. Last but not least, SOAP provides a well-structured
    way for defining method signatures and performing validations, called **WSDL**.
    SOAP is less popular currently for the same reasons as the XML technology: it
    is verbose and less flexible than most modern alternatives.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GET`, `PUT`, `POST`, and `DELETE`). Such operations are performed against
    resources, which are identified by the URIs. The threatened resources can be formatted
    in many different ways, but JSON is a widely used way to do so. REST is way more
    lightweight than SOAP. For this reason, some of the features embedded in SOAP
    (such as security, session handling, and validation) are not natively part of
    REST and are usually implemented by using external tools, libraries, and extensions.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, that's just a very high-level introduction to SOAP and REST, but
    since they are widely used, well-defined protocols, there is a lot of relevant
    material available that can be used for getting more information. Having said
    that, it should be clear by now that SOAP and REST are ways to allow different
    systems (across different languages and technologies) to communicate with each
    other, and basically implement APIs for both querying data and invoking remote
    operations. Now, let's see a couple of more modern, alternative approaches commonly
    used today for achieving similar goals.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: gRPC
  id: totrans-284
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**gRPC Remote Procedure Call** (**gRPC**) is a modern, open source framework
    developed originally by Google, and then released in open source as part of the
    CNCF projects umbrella. It defines a complete way for implementing interoperability
    between different systems. In order to do so, it provides a number of client libraries
    for all major languages, including Java, PHP, and Python.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: gRPC natively implements a lot of useful mechanisms that are often missing or
    implemented externally in SOAP and REST. Such mechanisms include bidirectional
    streaming and notifications (full-duplex communication), security, synchronous
    and asynchronous patterns, and flow control. Another key characteristic is that
    gRPC natively uses Protobuf as a serialization technique, hence providing more
    stability and fewer issues with cross-language communication. For all of those
    reasons, gRPC is now considered to be a good alternative to REST and SOAP for
    the communication between microservices and has proven to be most useful, in production
    and in many well-known contexts (such as Netflix, Spotify, and Dropbox), in providing
    low-footprint, high-performance communications.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: From a practical standpoint, in order to use gRPC communication, it is of course
    necessary to retrieve the relevant library for the language that we are going
    to use. As said, Java is a great choice. Once the dependency is provided, you
    have a component acting as a server and another component acting as a client.
    Once the server has been started, the client can connect to it and from that point,
    fully bidirectional communication is established.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see a practical example of a server and a client implementation, using
    the official Java gRPC library. Here is a basic server implementation:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this simple example, you can see a Java class launching and an embedded gRPC
    server. The `main` method creates the server using the `ServerBuilder` class provided
    by the library. In order to build the server, a port is passed (`9783`, in this
    case), then a `static` class is passed, which defines the implementation of the
    server method defined by the RPC (in this case, a `send` method, answering to
    a simple request by passing a string). The server is then built and started in
    the same chain of method calls in the `ServerBuilder` utility. Lastly, the `awaitTermination`
    method is called, and basically blocks the execution while waiting for connections
    and handling them.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now see how a simple gRPC client can be implemented to contact this
    server:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As you can see, in the previous simple example, `ManagedChannel` is built, passing
    some parameters (the host and port to contact the server, in this case, locally).
    Then, a stub is instantiated. A `request` object is built, and a message is set
    inside (in this case, the `Ciao` string). The `send` method is then invocated
    against this stub, passing the `request` object. The response is then collected
    and logged.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned before, gRPC relies on Protobuf by default for defining serialization.
    That''s where the request and reply objects are defined, and the signature for
    the `send` method is declared. Here is a sample `.proto` definition for our example:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'That''s all for our primer about gRPC. Of course, in the real world, more things
    need to be taken into account, such as correctly shutting down the server, handling
    exceptions, and any other features (such as retries, flow control, or load balancing)
    that you may want to use. In the next section, we are going to see another protocol
    that is commonly compared and used alongside REST: GraphQL.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: GraphQL
  id: totrans-297
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**GraphQL** is a technology for defining complete API systems in order to query
    and manipulate data. It has some similarities with the REST and SQL technologies,
    but it''s really a unique idea, as it defines APIs that are structured while providing
    freedom to the clients, who can specify what kind of data they are requesting.
    GraphQL was originally implemented by Facebook, which then released the governance
    of the project to an open source community under the Linux Foundation.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned previously, an aspect that is really interesting (and unique)
    of GraphQL is that the client is controlling the kind of data that is sending
    requests to the server, thus making this technology well suited for mobile applications
    and, in general, optimizing the communication, because only the data needed is
    transferred. In order to do so, GraphQL defines a special way to make queries
    that explicitly define the kind of data we are requesting to the server. As an
    example, take a look at the following query:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This is a simple definition asking for payments and three specific fields of
    each payment. Of course, some conditions for querying can be passed, such as the
    following:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Of course, there are a lot of other options that can be explored. GraphQL supports
    complex, nested types. You can specify queries with multiple conditions. It is
    possible to use other interesting features, such as pagination, sorting, and caching.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to implement and expose GraphQL APIs in your projects, there are at
    least two different options:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: You can implement a server, embedded in your backend code. In this case, it
    can be useful to use a framework such as the Domain Graph Service framework built
    by Netflix ([github.com/netflix/dgs-framework](http://github.com/netflix/dgs-framework)).
    Other options include GraphQL Spring Boot ([github.com/graphql-java-kickstart/graphql-spring-boot](http://github.com/graphql-java-kickstart/graphql-spring-boot))
    and graphql-java ([github.com/graphql-java/graphql-java](http://github.com/graphql-java/graphql-java)).
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another option is to use a standalone server. In this case, instead of embedding
    the GraphQL functionalities in your code, you will configure an external application
    that provides data through GraphQL APIs and retrieves it from a data store (such
    as a SQL database). A couple of popular implementations of such an approach are
    Apollo ([apollographql.com](http://apollographql.com)) and Hasura ([hasura.io](http://hasura.io)).
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In order to consume and query GraphQL APIs, your best bet is to use a client
    for your language. There are a number of semi-official implementations for a lot
    of languages. Due to the protocol being heavily used for web and mobile applications,
    JavaScript, Android, and iPhone clients are very common. Of course, there are
    also a couple of libraries for Java, such as graphql-java (seen before for its
    server capabilities), which can be used as a client too.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have seen a number of different technologies in the scope
    of APIs. We glanced at API technologies, briefly looking at SOAP and REST, and
    then some modern alternatives, such as gRPC and GraphQL. In the next section,
    we are going to dig a bit more into the world of data and integration in such
    a layer.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: Introducing data integration
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Data integration** is a very widespread technique, or rather, consists of
    a range of techniques.'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: Under this umbrella terminology, there are a lot of different approaches aiming
    to consolidate, enrich, filter, and in general work on data, potentially in a
    range of different formats, to generate different results. Basically, while the
    integration techniques seen in the *Digging into enterprise integration patterns*
    section are about transient data (being part of a method call, as a web service,
    or an asynchronous interaction, such as a message), data integration focuses on
    data at rest, so when it's persisted on a data store, such as a database or a
    file. Better again, data integration starts and ends with data persisted (at rest),
    usually with a big amount of data (such as databases and `.csv` files).
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: I have to admit that this is not my favorite approach, and I advise against
    indiscriminate use, especially in greenfield applications. Indeed, data integration
    can generate a lot of side effects, including stale data (if something goes wrong
    in the process), an unpredictable amount of time taken to complete the processes,
    and scalability issues. Moreover, you may end up having less *trust* in the data
    you deal with, as you may not know who the master is and which data is the most
    recent or reliable.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: 'Given this warning, I also have to say that, in a more or less structured way,
    data integration is very widespread in enterprise contexts, especially in the
    context of data warehouses and batch processing. The more common data integration
    techniques include the following:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: '**Extract, Transform, and Load** (**ETL**): This is a generic term indicating
    the process of reading data from one or more sources, transforming it (enriching,
    joining, filtering, and other techniques, more or less similar to what we saw
    in the *Message transformation* section), and loading it to one or more target
    storage systems (as a database). This can be done by using specialized software
    (proprietary or open source) or custom developments (such as SQL queries or custom-written
    software).'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data virtualization**: This is an approach that tries to minimize the downsides
    of ETL. It basically involves the same steps as ETL but without replicating the
    data. To do so, the last step (load) is replaced by the virtualization of a target
    system (usually a database). This means that, instead of loading the data in a
    target database, there is a *fake* database simulated by the data virtualization
    technology of choice (which can be an open source or proprietary product). This
    translates the requests into queries or other ways to collect data from the source
    systems.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If it sounds complicated and cumbersome, it's because it is complicated and
    cumbersome. There can be caching in between (to enhance performance), as the generated
    queries (or whatever will be needed for collecting data from source systems, which
    can also be files or other data stores) are usually not so optimized. In general,
    an approach that can work very well in some scenarios could go awfully in other
    cases (depending on the source data and the transformations needed).
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '**Change data capture**: This is an alternative technique for aligning different
    data sources. There is a process of listening for changes in a data source and
    propagating such changes to the systems that are interested in them. The listening
    for changes is usually specific to each source technology but is commonly done
    by polling the system (such as with a scheduled query running repeatedly) or by
    parsing the system metadata (usually the so-called **transaction log**). It is
    indeed a log maintained by some databases keeping a track of changes. The events
    detected in this way are then usually propagated in queues (Kafka is particularly
    widespread as a technology for such use cases). Last but not least, one or more
    consumers will then listen for some or all the events generated and use them to
    create a target data store with the desired format.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we had an overview of data virtualization techniques. In the
    next section, we will talk about another important piece of enterprise middleware
    systems, business automation, which includes rules and workflow engines.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: Completing the picture with business automation
  id: totrans-319
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section is focused on another big use case of enterprise middleware. While
    the previous section was about integrating applications with each other by translating
    data formats and protocols, in this section, we are going to see how to decouple
    the business logic from the application code.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: '*What do we mean by that?* Basically, in each application, there is a part
    of the behavior that may be subjected to a change periodically. We are not talking
    about the business logic *as a whole*, but about the specific subsections that
    are likely known in advance as being required to change due to some specific conditions,
    such as new business requirements. This kind of logic is usually grouped into
    two categories:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '**Rules**, which include all kinds of calculations and algorithms that are
    specific to the business domain and can be isolated, changed, and fine-tuned in
    the application life cycle. We already introduced the concept of business rules,
    in [*Chapter 3*](B16354_03_Final_JM_ePUB.xhtml#_idTextAnchor065), *Common Architecture
    Design Techniques*, in the *Decision model and notation* section, which is standard
    notation for business rules.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Workflows**, which are modeled around the concept of business processes by
    mapping a use case as a set of sequential steps. We already introduced the concept
    of business workflows, in [*Chapter 3*](B16354_03_Final_JM_ePUB.xhtml#_idTextAnchor065),
    *Common Architecture Design Techniques*, in the *Business process model and notation*
    section, which is standard notation for business processes.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Why should you use such separation of logic and implementation in your applications?*
    Well, there are at least two important reasons, which are as follows:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: Having the business logic encapsulated in a rule or workflow will make it quicker,
    cheaper, and safer to change the business logic itself, in order to fix bugs or
    adhere to changing external conditions. Depending on the technology you are going
    to use, it may be supported for a hot reload of the logic, meaning that you can
    change the behavior of the application with minimal or no downtime. Even if hot
    reload is not supported, changes in the business logic will still have a very
    limited impact (such as changing a text file or a database), with minimal consequences
    on the rest of the application. This means that you can run a smaller set of tests,
    and the risk of introducing bugs and regressions elsewhere is limited.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on the language used for the business logic, it can be validated or
    even directly edited by the business owners (or by a non-technical person anyway).
    Some technologies for business rules and workflows, such as the aforementioned
    **Decision Model and Notation** (**DMN**) and **Business Process Model and Notation**
    (**BPMN**), indeed are basically human-readable as there are tools available to
    provide a graphical representation of the logic included. Also, the concepts used
    (such as the task, the item, or the decision table) require no technical knowledge
    and are intended to have a direct mapping to business concepts.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Business rules, as well as workflows, can be basically deployed in a centralized
    or embedded way. The considerations about it are similar to the ones that we saw
    in the integration area:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: When deployed in a centralized way, all your rules or workflows sit on a server
    (or a cluster of servers), and you interact with them remotely (such as via a
    REST service call or a message). In this way, everything is organized, and you
    have a central view and management of all the business artifacts. The downside
    is, as usual, that this may become a bottleneck and a single point of failure.
    As the performance slows down, a crash or a maintenance window will impact all
    the applications dependent on this central component.
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If deployed in an embedded mode, you include the business engine powering workflows
    and rules in each component that needs such functionalities. Of course, the rules
    and workflows per se will still be deployed separately (usually being loaded from
    external text files or artifacts). The embedded mode will allow better scalability
    as each component will have full control over the decision capabilities. On the
    other hand, you will lack central administration and governance capabilities.
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's now have a look at those two technologies in detail and learn when you
    should use them in your application.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: Business rules
  id: totrans-331
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Business rules** are a way to express and isolate logic from the implementation,
    or better, the algorithm that ultimately leads to a decision from the technical
    details behind it. The examples here are very different scenarios. A common one
    is the concept of promotions in an e-commerce environment: the products, the price,
    and the rest of the behavior stay the same, but you may change the amount of discount
    calculated based on the time of year, the number of items in stock, or simply
    new requirements coming from the business.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: Another widespread use of business rules is regarding anti-fraud. Basically,
    before accepting a payment request, you make several checks to ensure that said
    payment is not a fraudulent one. The number and type of checks you perform may
    vary with time, as you may discover more fraudulent cases and add other controls
    in order to detect them. In the next section, we will extend the concept of business
    rules by introducing the temporal dimension. This concept is called **Complex
    Event Processing** (**CEP**).
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: Complex event processing
  id: totrans-334
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CEP is a concept related to business rules. The most widely accepted distinction
    between business rule processing and CEP is that in CEP, the concept of time and
    event flow is the core of the computation.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: With CEP, each decision can be influenced by previous events that occurred,
    both in a time window (such as in the last hour) or an event window (such as in
    the last 10 events).
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: Let's get back to our anti-fraud example. A business rule checking for fraud
    will make a decision based on the data related to the specific incoming payment,
    such as the amount or the profile of the sender. CEP-based checking for fraud
    will add the temporal dimension to it, so the evaluated information will include
    past payment transactions. You may want to check whether any of the last 10 transactions
    have been suspected of fraud, or you may want to check whether, in the last hour,
    other payment transactions have occurred in a very distant location (such as a
    different country).
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have cleared the basics of business rules and CEP, let's have a
    look at the Drools project, which is a very widespread implementation of such
    concepts.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: The Drools project
  id: totrans-339
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Drools** is a widespread open source business rules engine, created in the
    early 2000s. It is part of a broader community called **Knowledge Is Everything**
    (**KIE**), which included related features, such as a workflow manager implementation
    (**jBPM**—more about that in a few sections) and the related tooling (such as
    rules modeling and graphical interfaces). Drools ships a lot of interesting capabilities,
    such as great performance, a small footprint, and compatibility with different
    rule languages, including DRL and the already mentioned DMN. Moreover, Drools
    can be deployed in various configurations, including embedded and server mode
    (supporting a number of different runtimes, including Quarkus).'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: The decision model and notation
  id: totrans-341
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As already mentioned in [*Chapter 3*](B16354_03_Final_JM_ePUB.xhtml#_idTextAnchor065),
    *Common Architecture Design Techniques*, DMN is a language for modeling business
    decisions in a way that's understandable to both technical and non-technical people.
    The language is based on XML, so while it is text-based (hence easily versionable
    in a source code repository), it's hardly human-readable because it contains all
    the properties and coordinates for visualizing the components onscreen. However,
    there are plenty of free and commercial tools to edit and visualize such files.
    You can download some from the Kogito tooling page ([github.com/kiegroup/kogito-tooling](http://github.com/kiegroup/kogito-tooling)),
    or you can have the same experience online for free (at the [dmn.new](http://dmn.new)
    page).
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what a simple `hello world` rule looks like in the editor:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.25 – A simple DMN rule'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.25_B16354.jpg)'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.25 – A simple DMN rule
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: This rule will check whether a number in input is even, returning `Yes` or `No`.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: 'The rounded component is a `DMN Input Data` element, which contains the `NumberToTest`
    input variable, while the `Is Even ?` rectangle component is a `DMN Decision`
    containing the algorithm. In this case, if we look in the panel on the left, the
    component contains a so-called **literal expression**. By editing the component,
    we can see this expression:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.26 – A simple DMN rule'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.26_B16354.jpg)'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.26 – A simple DMN rule
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: Of course, this is a very simple example expression. In a real-world application,
    you could have much more complex logic, such as a combination of different expressions,
    a function, and a decision table. The decision would likely have other components,
    such as different input, complex types, and reusable decisions.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: Let's now extend our reasoning with business workflows.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: Business workflows
  id: totrans-354
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Business workflows** can be seen, conceptually, as an extension of the concept
    of business rules. By using workflows, indeed, you aim to logically separate the
    business logic from the implementation and application logic.'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: While with rules you isolate a decision (which may be simple or complex at will),
    with workflows you model an entire process. You will still start from a set of
    information and arrive at a final outcome, but the process will involve a number
    of different steps and it will usually be *passivated* every now and then (usually
    on a database) while waiting for each step to complete.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: The steps can be fully automated (such as when calling a REST service or sending
    a message to a queue or similar things), or simply represent a human task happening
    outside of our application (such as the signature on a paper document or other
    manual tasks) and need an explicit confirmation (which may be via email or completing
    a web form) in order to signal the completion (and let the process continue).
    So, to keep it simple, while a business rules model represents a single calculation,
    a business process involves a set of different steps and each decision may go
    through a set of different paths.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, one core function of workflows, other than modeling and isolating business
    processes, is to give insights into the process performance and statistics from
    both a business and a technical point of view.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: Let's suppose that we implement a business process to represent a loan request.
    You will have a first step for getting the data for the request, including the
    amount of money requested, the name of the requestor, and their age. You will
    then most likely have a set of validation, such as a background check of the requestor,
    verification of their salary, and the history of the payments made by the requestor.
    Each of these steps can be modeled as an item in a workflow, which can be completed
    automatically (such as calling an external system asking for information) or by
    asking an operator (such as sending an email and waiting for the reply). It's
    a common practice to model some of those steps as business rules, according to
    what we have seen so far in this chapter.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: Let's suppose you have such a system in production. You can then extract the
    historical data from the past process instances and understand how well your workflow
    is performing. *How many loan requests get approved at the end? How much time
    do you spend on each task? What's the average age of each requestor?*
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: From this valuable data, the business can get insights to change the process
    (such as simplifying, changing, or removing some steps), to create different promos
    (such as a special loan with different interest rates for a specific audience),
    and so on. This is basically the reason why you want to isolate decisions (whether
    rules or processes). You now can easily know what's happening in your application
    and fine-tune such behavior while having a limited impact on the other functionalities.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: The most widespread approach to technically model such business processes is
    to rely on the BPMN notation, which is a standard. Also, as DMN is based on XML,
    it is human-readable and editable by using graphical tools. For more information
    on BPMN, please refer to [*Chapter 3*](B16354_03_Final_JM_ePUB.xhtml#_idTextAnchor065),
    *Common Architecture Design Techniques*.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: The jBPM project
  id: totrans-363
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**jBPM** is another project under the KIE umbrella, providing a lightweight
    and extensible engine for running BPMN workflows. Similar to Drools, jBPM can
    be deployed in many different ways, including embedded in your applications and
    standalone, and it can rely on many different runtimes (such as **JBoss WildFly**
    and Quarkus), implementing both traditional and cloud-native scenarios.'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: As per the Drools project, jBPM provides some free tools to visualize and edit
    BPMN files at [github.com/kiegroup/kogito-tooling](http://github.com/kiegroup/kogito-tooling)
    and you can use the online editor on the [bpmn.new](http://bpmn.new) page.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what a simple workflow looks like:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.27 – A simple BPMN process'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.27_B16354.jpg)'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.27 – A simple BPMN process
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: 'In this simple process, we check the divisibility of a number by 5\. There
    is a start, then a couple of checks (whether the number ends with zero or five),
    and a logic gateway that leads to an end in both cases: is or is not divisible.'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: This section completes our overview of business automation. In the next section,
    we will compare the architectural roles of integration and automation.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: Integration versus automation – where to draw the line
  id: totrans-372
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A common discussion when designing complex software architectures is where to
    define the boundary between integration and automation.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: 'After all, there is a bit of overlap: both a business workflow and an integration
    route can call a number of external systems sequentially or while going through
    conditions (which may be represented, in both cases, as business rules).'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, there is not a fixed answer for every behavior. I personally prefer
    to avoid polluting the business automation with too many technical integrations
    (such as connectors for specific uncommon technologies, everything that is not
    a call to a web service or a message in a queue) and the integration routes with
    conditions that are dependent on specific business requirements (such as modeling
    a business process as an integration route). But other than this high-level, common-sense
    advice, there are a few considerations that can help in understanding whether
    a particular feature should stay in the automation or integration layer:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: If the flow that represents our use case involves a significant number of human
    tasks (such as when human interaction is needed), it will likely be a business
    workflow.
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have to deal with technologically driven behavior, such as retries in
    the case of errors in service calls or other details about the protocols used
    by the external system, it is most likely something to encapsulate in an integration
    route.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the process has business relevance, so every step is something significant
    to a business person, who could be interested in the performance of the process
    (meaning how many processes are stuck in a step, or how much time is needed for
    a particular path), it is likely to be a business workflow.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no passivation is needed, meaning that the majority of instances are straight-through
    processes, or in other words, a set of steps performed one after the other without
    needing to be persisted in a data store (waiting for a signal or other events
    to restart), it is likely an integration route.
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'That is my personal advice on how to consider whether a particular feature
    should be in an integration or business automation layer. Indeed, in many cases,
    you will need a combination of both layers:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: An integration layer is used to encapsulate technical details into interactions
    with third-party and other external systems (such as databases) and expose such
    functionalities as a higher-level, composite API (such as a REST service).
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A workflow layer orchestrates the calls to those high-level APIs, adds human
    tasks (if needed) and processes instance persistence, and in general models business
    processes and gets metrics and insights on such process execution.
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This completes our overview of business automation. In the next section, we
    will have a look at examples of integration and automation using the aforementioned
    technologies.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: Case studies and examples
  id: totrans-384
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to go on with our payment use case, to see some
    examples of integration and business automation.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: For example purposes, we will use Camel, jBPM, and Drools. Our target runtime
    will be Quarkus, which we already saw in the previous chapter.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: But many of the concepts and implementations are applicable to other runtimes,
    such as embedded ones (as in using the runtime as a dependency of your Java application),
    deployed on JBoss WildFly, and deployed on Spring Boot.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: Integrating payment capabilities
  id: totrans-388
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our first use case to implement integration is the connection of payment capabilities
    with a legacy backend. Let's suppose that we have developed our microservices
    payment application and it is working correctly. A new business requirement is
    to integrate a legacy platform for settlement purposes (which is a kind of accounting
    operation done after payments).
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s fairly easy for our core application to call a REST service for this
    purpose, but the legacy system used for settlement works with `.xml` files placed
    in a shared folder. That''s a perfect fit for integration: there is no business
    logic apart from some plumbing to make the two systems talk to each other, and
    it will be fairly easy to implement with a rich and expressive framework such
    as Camel.'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of ways to create a Camel project on top of Quarkus. As we
    saw in the previous chapter, we can create it with the `mvn` command, or go to
    the Quarkus website and use a web wizard to download an empty project scaffold.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: 'The dependencies that we are going to use are in the `camel-quarkus` family.
    Here are the details:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: '`camel-quarkus-platform-http` is basically a bridge to make the existing HTTP
    server of the runtime (Quarkus, in our case) usable from Camel.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`camel-quarkus-jackson` is the component to marshal POJO to JSON and vice versa.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`camel-quarkus-jacksonxml` works on the same concept, but for XML serialization.
    As we have seen, `Jackson` is a library that can be used for JSON, XML, and other
    formats.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`camel-quarkus-file` is the default component for reading and writing files.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We have already created a `Payment` Java class for holding our payment data,
    in the previous chapter. You can see the fields used in the following code (*the
    rest of the class is getters and setters plus some more boilerplate code*):'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In order to define a Camel integration route using Java DSL, it''s enough to
    create a class extending `EndpointRouteBuilder`, as follows (*imports are omitted
    here*):'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This simple Java code models an integration route that starts by exposing an
    HTTP endpoint, unmarshals the requests coming as JSON objects (using the `Jackson`
    framework), mapping it to a Java object of the `Payment` class, sets a header,
    then marshals the Java object to XML (using `Jackson` again), and finally writes
    the XML to a file.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: 'To call the Camel route, we have to post a request to `/camel/settlement` (`http://127.0.0.1:8080/camel/settlement`,
    if we are running locally), which is a JSON representation of the `Payment` object
    (as seen in the previous chapter). Here''s an example:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Regarding the Camel route, we already saw a similar flow a couple of sections
    ago, in the *The Camel DSL* section, following our first look at the Camel framework,
    in the *The Camel integration framework* section. However, there are a couple
    of things worth noticing:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: There is a `setHeader` method, which locates the `id` field from the body of
    the current message flowing through the Camel route (which is the ID of the payment
    transaction) and sets it into the `PaymentId` header so it can be reused later
    as a name for the `.xml` file that we are generating. Note that the `simple` expression
    language is used, which can be used for navigating the payload (using the dot
    notation) and express conditions.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Quarkus properties (defined according to what we saw in the previous chapter,
    using the system properties defined in `application.properties` or in many other
    ways) are directly accessed and used with double curly brackets. In this case,
    the file component accesses the `{{settlement.path}}` variable to set the destination
    path of the settlement file.
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*But what if we want to avoid the generation of settlement for an amount of
    less than 10 €?* That''s easy. It is enough to implement the filter EIP and basically
    drop the messages that do not respect the relevant condition:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As you can see, the Camel component is indeed called `filter`.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: '*And what if we want to add a different behavior for the two conditions (less
    than 10 € or more than 10 €)?* The EIP here is a content-based router, which can
    be implemented in Camel using the `choice` component, like this:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this case, we are simply logging in the `otherwise` case, but in the real
    world, you may consider doing something more (such as writing a different file
    format or in different storage) and you can also add a number of different `when`
    conditions.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: More generally, this is just a taste of what Camel can do. In the real world,
    there are a lot of technology connectors, formats, and patterns, and the routes
    can be modularized to call each other. On the official Camel website, you can
    even find a page about mapping between EIP and Camel components. This completes
    our integration example. Let's now have a look at automation.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: Automating customer onboarding
  id: totrans-414
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our payment platform will for sure need a process to onboard customers. It's
    pretty common to have some actions supporting the creation of profiles for new
    customers, including validations and the provisioning of customers on many different
    systems. This is a task that is a perfect fit for business automation.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, customer onboarding is commonly driven by (changing) business requirements
    (such as the number of steps for registering a user and facilitating the onboarding
    of some categories for promotional purposes). Moreover, these kinds of processes
    may be regulated by laws, and so it may happen that you have different workflows
    in different geolocations (such as some countries requiring wet signatures on
    paper needing to be modeled as human tasks) and changing steps with changing regulations
    over time.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: 'Last but not least, the process of provisioning a user is typically stateful:
    you will want to have it persisted on a data store for auditing, reporting, and
    customer experience purposes. It may happen that a customer starts the registration
    process on a mobile app, then the user continues doing other steps on a computer,
    then lastly, finalizing it by going to a bank branch.'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: 'A workflow will allow this kind of experience (also known as *omnichannel*)
    by persisting each step (where needed) and providing a stateful process. Let''s
    start with modeling one single step of the workflow: a business rule modeling
    the age check of a customer. That''s quite easy with DMN and the visual editor
    provided by the **Kogito** project (maybe the online one, or a standalone version,
    as a plugin for an IDE, such as **VSCode**):'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.28 – A simple DMN validation rule'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.28_B16354.jpg)'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.28 – A simple DMN validation rule
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a very simple rule: using the **customer** data structure and providing
    a **CheckAge** DMN decision. Here is what''s inside such a decision:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.29 – The rule expression'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.29_B16354.jpg)'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.29 – The rule expression
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we are using a very simple `age` field of the `customer` structure.
    Here is what the structure looks like in the **Data Types** editor:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.30 – The customer data type'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.30_B16354.jpg)'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.30 – The customer data type
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: 'In the sources of this example, you can also find the POJO representing the
    same structure (and it is interoperable with it). In order to invoke this rule,
    we need to post this REST request in JSON:'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Here, the Kogito engine will reply with `VALID` or `INVALID`. This is, of course,
    pretty useful: you can easily create decision services providing business rules
    (usually more complex than the one seen in this example) and use them in your
    project. But there is more: this rule can become one step in a more complex workflow.'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s imagine a very simple prototype of a customer onboarding process: you
    have the start of the process, a preparation step (which may include sending a
    request to a CRM or other systems), and the evaluation of the age of the customer
    (by using the DMN rule that we have just seen). If the age is `INVALID`, you may
    want to have some special handling (such as asking for the permission of a parent).
    We did exactly that in this simple BPMN workflow:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.31 – The customer data type'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.31_B16354.jpg)'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.31 – The customer data type
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, the `System.out` call). Of course, you may want to have different
    kinds of tasks here, such as REST calls to external services, sending messages,
    or human tasks. Whatever your implementation is, you can trigger the workflow
    with a REST request, such as the following:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Take into account that in this simple example, we have not configured a persistence
    layer, nor defined tasks requiring passivation of the process instance. If this
    is needed, you can easily do it by adding some configurations (such as in the
    `application.properties` file). Once you have a process requiring and using persistence,
    you can then query the Kogito engine, asking for the status of encapsulated (or
    even completed) process instances, the list of pending tasks, and so on (like
    you could do in a typical BPMN workflow engine). This completes our examples for
    this chapter.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-440
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have looked at a lot of technologies, completing the middleware
    overview that we started in the last chapter. You have also learned what an ESB
    is (including connectors, patterns, and data formats).
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: We have looked at the enterprise integration patterns and the Camel library,
    which is an implementation of enterprise integration patterns. We have also looked
    at messaging systems to support the concept of integration in asynchronous scenarios.
    We then shifted our view of process automation by digging into business rules
    and business workflows and having a glimpse at Kogito, which is a complete business
    automation engine running on Quarkus.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: After this chapter, you should be able to understand the basics of enterprise
    integration, including messaging capabilities. We have also seen what business
    automation is, including workflows and rules, and how to differentiate what should
    stay in an integration layer from what should stay in a business automation layer.
    By using some open source libraries, we have gone through a couple of examples
    of implementing these concepts in Java.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see how to design and implement a modern distributed
    application by applying cloud-native architecture recommended practices.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-445
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The arc42 official website: [https://arc42.org/](https://arc42.org/)'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gregor Hohpe, Bobby Woolf, Enterprise Integration Patterns ([www.enterpriseintegrationpatterns.com](http://www.enterpriseintegrationpatterns.com))
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Enterprise Integration Patterns*, by Gregor Hohpe and Bobby Woolf, published
    by Pearson Education (2012)'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Apache Software Foundation: The Apache Camel project ([camel.apache.org](http://camel.apache.org))'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Apache Software Foundation: The Apache Camel project – mapping to EIP ([camel.apache.org/components/latest/eips/enterprise-integration-patterns.html](http://camel.apache.org/components/latest/eips/enterprise-integration-patterns.html))'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The official XML website ([XML.org](http://XML.org))
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The official JSON website ([JSON.org](http://JSON.org))
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Google Protobuf Java tutorial ([developers.google.com/protocol-buffers/docs/javatutorial](http://developers.google.com/protocol-buffers/docs/javatutorial))
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The official gRPC website ([grpc.io](http://grpc.io))
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The KIE project, including Drools, jBPM, and more ([www.kiegroup.org](http://www.kiegroup.org))
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Kogito project, providing business automation on Quarkus ([kogito.kie.org](http://kogito.kie.org))
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
