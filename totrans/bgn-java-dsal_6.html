<html><head></head><body><div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Graphs, Prime Numbers, and Complexity Classes</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root">Graph problems are very common in computer science, and their applications pervade many real-life applications. Everything that can be represented by entities and their relationships can ultimately be modeled by a graph. How we connect with friends on social media, how route-planning applications are able to find the shortest route, and how e-commerce websites are able to provide us with recommendations are all examples of problems modeled by graphs.</p>
<p class="mce-root">A graph is a structure composed of a set of objects in which some pairs of objects are related. The objects are modeled by the mathematical abstraction of vertices (sometimes also called nodes), and the pairwise relationships are modeled by the mathematical abstraction of edges (sometimes also called arcs).</p>
<p class="mce-root">Edges can be directed or undirected. A directed edge is an edge which has a direction associated with it. A graph that is composed of directed edges is called a directed graph. A graph that is composed of undirected edges is called an undirected graph. In a directed edge, it is common to call the start of the edge the head and the end of the edge the tail. In a directed graph, the out-degree of a vertex is the number of edges whose head is adjacent to it. The in-degree of a vertex is the number of edges whose tail is adjacent to it.</p>
<p class="mce-root"><em class="calibre19">Figure 6.1</em> gives an example of a directed graph with six nodes and eight edges, as follows:</p>
<p class="cdpaligncenter"><img src="Images/bc8a9fae-e427-4835-a3d5-69a984df089b.png" width="390" height="380" class="calibre85"/></p>
<div class="packt_figref"><span class="calibre10">Figure 6.1: A directed graph</span></div>
<p class="mce-root"><em class="calibre19"><span class="calibre14">Figure 6.2</span></em> <span class="calibre14">gives an example of an undirected graph with</span> <span class="calibre14">five</span> <span class="calibre14">nodes and</span> <span class="calibre14">seven</span> <span class="calibre14">edges, as follows:</span></p>
<p class="cdpaligncenter"><img src="Images/298ca250-bda8-4e99-972c-3fa860ae7598.png" width="330" height="205" class="calibre86"/></p>
<div class="packt_figref"><span class="calibre10">Figure 6.2: An undirected graph</span></div>
<p class="mce-root">Before we dive into how to represent a graph in a computer program, it is important to describe how the runtime of graph algorithms is usually characterized. As previously stated, a graph, <em class="calibre19">G</em>, can be seen as a set of vertices and edges, that is, <em class="calibre19">G = (V, E)</em>. As such, the size of the input is usually measured in terms of the number of vertices (<em class="calibre19">|V|</em>) and the number of edges (<em class="calibre19">|E|</em>). So, instead of relying solely on a single input size, <em class="calibre19">N</em>, the runtime of graph algorithms usually refers to both <em class="calibre19">|V|</em> and <em class="calibre19">|E|</em>. In big O notation, it is common to use <em class="calibre19">V</em> to denote <em class="calibre19">|V|</em> and <em class="calibre19">E</em> to denote <em class="calibre19">|E|</em>. For example, an algorithm that runs in time proportional to the number of vertices multiplied by the number of edges is said to run in time <em class="calibre19">O(VE)</em>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Representing Graphs</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root"><span class="calibre14">There are usually two standard ways to represent a graph</span> <em class="calibre19"><span class="calibre14">G = (V, E)</span></em> <span class="calibre14">in a computer program:</span></p>
<ul class="calibre12">
<li class="calibre13"><span class="calibre10">As a collection of adjacency lists</span></li>
<li class="calibre13"><span class="calibre10">As an adjacency matrix</span></li>
</ul>
<p class="mce-root"><span class="calibre14">You can use either way to represent both directed and undirected graphs. We'll start by looking at the adjacency list representation.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Adjacency List Representation</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root"><span class="calibre14">The adjacency list representation of a graph consists of an array of</span> <em class="calibre19"><span class="calibre14">|V|</span></em> <span class="calibre14">lists, one for each vertex in</span> <em class="calibre19"><span class="calibre14">V</span></em><span class="calibre14">. For each vertex</span> <em class="calibre19"><span class="calibre14">u</span></em> <span class="calibre14">in</span> <em class="calibre19"><span class="calibre14">V</span></em><span class="calibre14">, there's a list containing all vertices</span> <span class="calibre14"><em class="calibre19">v</em> </span><span class="calibre14">so that there is an edge connecting</span> <em class="calibre19"><span class="calibre14">u</span></em> <span class="calibre14">and</span> <em class="calibre19"><span class="calibre14">v</span></em> <span class="calibre14">in</span> <em class="calibre19"><span class="calibre14">E</span></em><span class="calibre14">.</span> <em class="calibre19"><span class="calibre14">Figure 6.3</span></em> <span class="calibre14">shows the adjacency list representation of the directed graph in</span> <span class="calibre14"><em class="calibre19">Figure 6.1</em>:</span></p>
<p class="cdpaligncenter"><img src="Images/c6f058c4-8d1a-4696-89bc-6eca0d572fd3.png" width="374" height="401" class="calibre87"/></p>
<div class="packt_figref"><span class="calibre10">Figure 6.3: Adjacency list representation of the directed graph in Figure 6.1</span></div>
<p class="mce-root"><span class="calibre14">For undirected graphs, we follow a similar strategy and build the adjacency list as if it were a directed graph with two edges between each pair of vertices</span> <em class="calibre19"><span class="calibre14">u</span></em> <span class="calibre14">and</span> <em class="calibre19"><span class="calibre14">v</span></em><span class="calibre14">, which are</span> <em class="calibre19"><span class="calibre14">(u, v)</span></em> <span class="calibre14">and</span> <em class="calibre19"><span class="calibre14">(v, u)</span></em><span class="calibre14">.</span></p>
<p class="mce-root"><em class="calibre19"><span class="calibre14">Figure 6.4</span></em> <span class="calibre14">shows the adjacency list representation of the undirected graph in</span> <span class="calibre14"><em class="calibre19">Figure 6.2</em>:</span></p>
<p class="cdpaligncenter"><img src="Images/cce9c0c2-0290-4236-b3ec-ec499b019aae.png" width="636" height="334" class="calibre88"/></p>
<div class="packt_figref"><span class="calibre10">Figure 6.4: Adjacency list representation of the undirected graph in Figure 6.2</span></div>
<p class="mce-root">If <em class="calibre19">G</em> is a directed graph, the sum of the lengths of all the adjacency lists is <em class="calibre19">|E|</em>, as each edge constitutes a single node in one of the adjacency lists.</p>
<p class="mce-root">If <em class="calibre19">G</em> is an undirected graph, the sum of the lengths of all the adjacency lists is <em class="calibre19">2*|E|</em>, since each edge <em class="calibre19">(u, v)</em> appears twice, that is, once in <em class="calibre19">u</em>'s and once in <em class="calibre19">v</em>'s adjacency list.</p>
<p class="mce-root">For both types of graphs, the adjacency list representation has the property of requiring an amount of memory equal to <em class="calibre19">O(V + E)</em>.</p>
<p class="mce-root">The following code snippet shows how to create a graph using the adjacency list representation in Java:</p>
<pre class="calibre20"><span class="calibre10">public class AdjacencyListGraph {<br class="calibre2"/>  ArrayList&lt;Integer&gt;[] adj;<br class="calibre2"/>  public AdjacencyListGraph(int nodes) {<br class="calibre2"/>    this.adj = new ArrayList[nodes];<br class="calibre2"/>    for (int i = 0; i &lt; nodes; i++)<br class="calibre2"/>    this.adj[i] = new ArrayList&lt;&gt;();<br class="calibre2"/>  }<br class="calibre2"/>  public void addEdge(int u, int v) {<br class="calibre2"/>    adj[u].add(v);<br class="calibre2"/>  }<br class="calibre2"/>}</span>  </pre>
<div class="packt_figref"><span class="calibre10">Snippet 6.1: Implementation of an adjacency list representation of a graph. Source class name: </span><span class="calibre10">Adjacencylistgraph</span></div>
<div class="packt_infobox"><br class="calibre2"/>
<span class="calibre10">Go to</span> <a href="https://goo.gl/Jrb2jH" class="pcalibre pcalibre3 calibre28 pcalibre1 pcalibre2"><span class="calibre10">https://goo.gl/Jrb2jH</span></a> <span class="calibre10">to access this code.</span></div>
<p class="mce-root"><span class="calibre14">It is common for one to have weighted graphs, that is, graphs in which each edge has an associated weight. The adjacency list representation is robust enough to support different graph variants, since we can store different edge representations in the adjacency lists.</span></p>
<div class="packt_infobox"><br class="calibre2"/>
<span class="calibre10">We can store different edge representations in adjacency lists because we store the edges themselves, thereby allowing customizable representations.</span></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Writing a Java Code to Add Weights to the Directed Graph</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root"><span class="calibre14">The aim is to adapt the implementation of the</span> <span class="calibre14"><kbd class="calibre15">AdjacencyListGraph</kbd></span> <span class="calibre14">class to support weights on edges.</span></p>
<p class="mce-root"><span class="calibre14">The steps should be the following:</span></p>
<ol class="calibre17">
<li class="chapter"><span class="calibre10">Understand</span> <em class="calibre21"><span class="calibre10">Snippet 6.1</span></em> <span class="calibre10">showing how we can implement the adjacency list representation</span></li>
<li class="chapter"><span class="calibre10">Adapt the implementation so that the array list can store the weights</span></li>
</ol>
<pre class="calibre30"><span class="calibre10">ArrayList&lt;Edge&gt;[] adj;<br class="calibre2"/>public AdjacencyListWeightedGraph(int nodes) {</span>  <br class="calibre2"/>  <span class="calibre10">this.adj = new ArrayList[nodes];<br class="calibre2"/>  for (int i = 0; i &lt; nodes; i++)<br class="calibre2"/>  this.adj[i] = new ArrayList&lt;&gt;();<br class="calibre2"/>}<br class="calibre2"/>public void addEdge(int u, int v, int weight) {<br class="calibre2"/>  this.adj[u].add(new Edge(u, v, weight));<br class="calibre2"/>}</span>  </pre>
<div class="packt_figref"><span class="calibre10">Snippet 6.2: Implementation of an adjacency list representation of a weighted graph. Source class name:</span> <span class="calibre10">Adjacencylistweightedgraph</span></div>
<div class="packt_infobox"><br class="calibre2"/>
<span class="calibre10">Go to</span> <a href="https://goo.gl/uoazxy" class="pcalibre pcalibre3 calibre28 pcalibre1 pcalibre2"><span class="calibre10">https://goo.gl/uoazxy</span></a> <span class="calibre10">to access this code.</span></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Adjacency Matrix Representation</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root">The adjacency list representation of a graph provides a compact way to represent sparse graphs, for example, those for which <em class="calibre19">|E|</em> is much less than <em class="calibre19">|V|<sup class="calibre32">2</sup></em>. Even though it is a representation that is useful for a lot of algorithms (which we will visit later), it does not support some features. For example, one cannot quickly tell whether there is an edge connecting two given vertices. In order to determine if <em class="calibre19">u</em> and <em class="calibre19">v</em> are connected, one has to go through the adjacency list of <em class="calibre19">u</em> to find an edge connecting it to <em class="calibre19">v</em>. Since the adjacency list of <em class="calibre19">u</em> can have at most <em class="calibre19">E</em> edges, this procedure runs in <em class="calibre19">O(E)</em> time. One alternative representation that remedies this disadvantage at the cost of using asymptotically more memory is the adjacency matrix representation.</p>
<div class="packt_infobox"><br class="calibre2"/>
The main disadvantage of adjacency list representation of a weighted graph representation is that we can't quickly determine if a given edge <em class="calibre21">(u, v)</em> is present in the graph.<span class="calibre10"><br class="calibre2"/></span></div>
<p class="mce-root">In this representation, a graph <em class="calibre19">G = (V, E)</em> is represented by a <em class="calibre19">|V| x |V|</em> matrix <em class="calibre19">A = (a<sub class="calibre40">ij</sub>)</em>, where <em class="calibre19">a<sub class="calibre40">ij</sub></em> equals <em class="calibre19">1</em> if there's an edge <em class="calibre19">(i, j)</em> and <em class="calibre19">0</em> otherwise. The following table shows the adjacency matrix representation of the directed graph of <em class="calibre19">Figure 6.1</em>:</p>
<p class="cdpaligncenter"><img class="fm-editor-equation10" src="Images/190d01d6-1224-455b-b4e8-b88fdaaec6bb.png" width="979" height="343"/></p>
<div class="packt_figref"><span class="calibre10">Table 6.1: Adjacency matrix representation of the directed graph of Figure 6.1</span></div>
<p class="mce-root"><span class="calibre14">The following table shows the adjacency matrix representation of the undirected graph of</span> <span class="calibre14"><em class="calibre19">Figure 6.2</em>:</span></p>
<p class="cdpaligncenter"><img class="fm-editor-equation11" src="Images/52459e9a-347f-43b9-98b6-fd7b932b3f5c.png" width="985" height="305"/></p>
<div class="packt_figref"><span class="calibre10">Table 6.2: Adjacency matrix representation of the undirected graph of Figure 6.2</span></div>
<p class="mce-root">The adjacency matrix representation of a graph requires <em class="calibre19">O(V<sup class="calibre32">2</sup>)</em> memory, independent of the number of edges in the graph. One thing to note on the adjacency matrix representation of undirected graphs is that the matrix is symmetrical along the main diagonal, since <em class="calibre19">(u, v)</em> and <em class="calibre19">(v, u)</em> represent the same edge. As such, the adjacency matrix of an undirected graph is its own transpose <em class="calibre19">(A = A<sup class="calibre32">T</sup>)</em>. Taking advantage of this symmetry, one can cut on the memory needed to store the graph almost in half, as you don't need the array of each vertex to have size <em class="calibre19">V</em>. If <em class="calibre19">i</em> tracks the index of vertices in <em class="calibre19">V</em>, the size of <em class="calibre19">array[i]</em> can decrease by one as <em class="calibre19">i</em> increases by one.</p>
<p class="mce-root"><span class="calibre14">The following code shows how to create a graph using the adjacency matrix representation in Java:</span></p>
<pre class="calibre20"><span class="calibre10">public class AdjacencyMatrixGraph {<br class="calibre2"/>  int[][] adj;<br class="calibre2"/>  public AdjacencyMatrixGraph(int nodes) {<br class="calibre2"/>    this.adj = new int[nodes][nodes];<br class="calibre2"/>  }<br class="calibre2"/>  public void addEdge(int u, int v) {<br class="calibre2"/>    this.adj[u][v] = 1;<br class="calibre2"/>  }<br class="calibre2"/>}</span>  </pre>
<div class="packt_figref"><span class="calibre10">Snippet 6.3: Implementation of an adjacency matrix representation of a directed graph. Source class name:</span> <span class="calibre10">AdjacencyMatrixGraph</span></div>
<div class="packt_infobox"><br class="calibre2"/>
<span class="calibre10">Go to</span> <a href="https://goo.gl/EGyZJj" class="pcalibre pcalibre3 calibre28 pcalibre1 pcalibre2"><span class="calibre10">https://goo.gl/EGyZJj</span></a> <span class="calibre10">to access this code.</span></div>
<p class="mce-root">The adjacency matrix representation is also robust enough to support different graph variants. In order to support weighted graphs, for example, one can store the weight of the edge in <em class="calibre19">a<sub class="calibre40">ij</sub></em>, instead of just one. The adjacency list representation is asymptotically at least as space-efficient as the adjacency matrix representation, but adjacency matrices are simpler, so they might be preferable when the graphs are reasonably small or dense. As previously stated, a sparse graph is one in which <em class="calibre19">|E|</em> is much less than <em class="calibre19">|V|<sup class="calibre32">2</sup></em>, whereas a dense graph is one in which <em class="calibre19">|E|</em> is closer to <em class="calibre19">|V|<sup class="calibre32">2</sup></em>. The adjacency list representation is more memory-efficient for sparse graphs. For dense graphs, an adjacency matrix representation is better suited, as it possibly takes less memory due to list pointers.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Activity: Building the Adjacency Matrix Representation of a Weighted Undirected Graph</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root"><span class="calibre14"><strong class="calibre6">Scenario</strong><br class="calibre7"/></span></p>
<p class="mce-root"><span class="calibre14">Creating an adjacency matrix for a weighted undirected graph to be used for social networking website.<br class="calibre7"/></span></p>
<p class="mce-root"><span class="calibre14"><strong class="calibre6">Aim</strong><br class="calibre7"/></span></p>
<p class="mce-root"><span class="calibre14">To write a code in Java for implementing the adjacency matrix representation of a weighted undirected graph.</span></p>
<p class="mce-root"><strong class="calibre6"><span class="calibre14">Prerequisites</span><br class="calibre7"/></strong></p>
<p class="mce-root"><span class="calibre14">For this activity, you have to implement methods</span> <kbd class="calibre15"><span class="calibre10">addEdge()</span></kbd> <span class="calibre14">and</span> <kbd class="calibre15"><span class="calibre10">edgeWeight()</span></kbd> of<span class="calibre14"> class</span> <span class="calibre14"><kbd class="calibre15">AdjacencyMatrixWeightedUndirected</kbd></span> <span class="calibre14">available at the following URL: </span></p>
<p class="mce-root"><a href="https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson6/activity/weightedundirected/AdjacencyMatrixWeightedUndirected.java" class="pcalibre pcalibre3 calibre11 pcalibre1 pcalibre2"><span class="calibre10">https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson6/activity/weightedundirected/AdjacencyMatrixWeightedUndirected.java</span></a></p>
<p class="mce-root"><span class="calibre14">The methods should add an edge and return the edge weight between two vertices, respectively.</span></p>
<p class="mce-root"><strong class="calibre6"><span class="calibre14">Steps for Completion</span></strong></p>
<ol class="calibre17">
<li class="chapter">Start storing the weights of edges in each cell of the matrix. Since we're dealing with undirected graphs, both <em class="calibre21">(u, v)</em> and <em class="calibre21">(v, u)</em> refer to the same edge, so we need to update both accordingly.</li>
</ol>
<ol start="2" class="calibre17">
<li class="chapter">It is also possible to not repeat the weight assignment. We just have to be careful and always choose one of <em class="calibre21">(u, v)</em> or <em class="calibre21">(v, u)</em> when referring to that edge. One possible strategy is to always use <em class="calibre21">(min(u, v), max(u, v))</em>. Using that strategy, we also don't need to store the full matrix, thereby saving some space.</li>
</ol>
<p class="mce-root">In this first section, we learned two different ways of representing a graph in a computer program. We briefly examined the pros and cons of each representation, and we will take a look at their usefulness when implementing graph algorithms in the following sections.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Traversing a Graph</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root"><span class="calibre14">A common activity on a graph is visiting each vertex of it in a given order. We will start by introducing the breadth-first search, and then follow with depth-first search. Both of these techniques form the archetype for many important graph algorithms, as we will see later with the cycle detection and Dijkstra's algorithm for single-source shortest paths.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Breadth-First Search</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root"><span class="calibre14">Given a graph</span> <em class="calibre19"><span class="calibre14">G = (V, E)</span></em> <span class="calibre14">and a source vertex</span> <span class="calibre14">s</span><span class="calibre14">, breadth-first search explores the edges of</span> <em class="calibre19"><span class="calibre14">G</span></em> <span class="calibre14">systematically to discover every vertex that is reachable from</span> <em class="calibre19"><span class="calibre14">s</span></em><span class="calibre14">. While doing so, it computes the smallest number of edges from</span> <em class="calibre19"><span class="calibre14">s</span></em> <span class="calibre14">to each reachable vertex, making it suitable to solve the single-source shortest path problem on unweighted graphs, or graphs whose edges all have the same weight.<br class="calibre7"/></span></p>
<p class="mce-root"><span class="calibre14"><strong class="calibre6">Breadth-First Search</strong> (<strong class="calibre6">BFS</strong>)</span> <span class="calibre14">is named so because it expands the frontier between discovered and undiscovered vertices uniformly across the breadth of the frontier. In that sense, the algorithm first explores vertices at distance</span> <em class="calibre19"><span class="calibre14">k</span></em> <span class="calibre14">from</span> <em class="calibre19"><span class="calibre14">s</span></em> <span class="calibre14">before discovering vertices at distance</span> <em class="calibre19"><span class="calibre14">k + 1</span></em><span class="calibre14">. To keep track of progress, breadth-first search identifies each vertex as undiscovered, discovered, or expanded. All vertices start out undiscovered. A vertex is discovered the first time it is encountered during search, and is expanded when all the vertices adjacent to it have been discovered.<br class="calibre7"/></span></p>
<p class="mce-root"><span class="calibre14">BFS constructs a breadth-first tree, rooted at source vertex <em class="calibre19">s</em>. Whenever the search discovers an undiscovered vertex <em class="calibre19">v</em> when scanning the outward edges of already discovered vertex</span> <em class="calibre19"><span class="calibre14">u</span></em><span class="calibre14">, the vertex</span> <em class="calibre19"><span class="calibre14">v</span></em> <span class="calibre14">and the edge <em class="calibre19">(</em></span><em class="calibre19"><span class="calibre14">u</span><span class="calibre14">,</span> <span class="calibre14">v</span></em><span class="calibre14"><em class="calibre19">)</em> are added to the tree. Therefore, </span><em class="calibre19"><span class="calibre14">u</span></em> <span class="calibre14">becomes the parent of</span> <em class="calibre19"><span class="calibre14">v</span></em> <span class="calibre14">in the breadth-first tree. Since a vertex is discovered at most once, it has at most one parent.</span></p>
<p class="mce-root"><span class="calibre14">In order to illustrate this, let's look at a run of breadth-first searches for the directed graph of</span> <em class="calibre19"><span class="calibre14">Figure 6.1</span></em><span class="calibre14">, starting at node</span> <span class="calibre14">2</span><span class="calibre14">, in the following table:</span></p>
<p class="cdpaligncenter"><img class="fm-editor-equation12" src="Images/bacec7ef-7200-40aa-b815-4b0fd60114cb.png"/></p>
<div class="packt_figref"><span class="calibre10">Table 6.3: A Run of BFS on the directed graph of Figure 6.1, starting at node 2</span></div>
<p class="mce-root">There are a lot of insights to take from the breadth-first tree. For instance, the path from the root to a given node in the tree is the shortest path (in terms of edges) from those two vertices. Another thing to note is that vertices that are not in the breadth-first tree (as is the case of 0) are unreachable from the root vertex.</p>
<p class="mce-root"/>
<p class="mce-root">We previously saw how to perform the breadth-first search on trees. BFS on graphs is similar, but we need to keep track of explored nodes so that we don't get stuck in cycles. In order to implement breadth-first search, we will assume that our graph is represented using adjacency lists.</p>
<p class="mce-root">We will attach certain attributes to each vertex in the graph that will allow us to guide our search and later construct the breadth-first tree. We will also use a first-in, first-out queue (covered in <a href="ab7975d0-4b38-437d-9ff5-8f6c20199874.xhtml" class="pcalibre pcalibre3 calibre11 pcalibre1 pcalibre2">Chapter 2</a>, <em class="calibre19">Sorting Algorithms and Fundamental Data Structures</em>) to manage the set of discovered vertices. The following code snippet illustrates the implementation of breadth-first search:</p>
<pre class="calibre20"><span class="calibre10">Queue&lt;Integer&gt; q = new LinkedList&lt;&gt;();<br class="calibre2"/>q.add(start);<br class="calibre2"/>while (!q.isEmpty()) {<br class="calibre2"/>  int current = q.remove();<br class="calibre2"/>  for (int i = 0; i &lt; this.adj[current].size(); i++) {<br class="calibre2"/>    int next = this.adj[current].get(i);<br class="calibre2"/>    if (!visited[next]) {<br class="calibre2"/>      visited[next] = true;<br class="calibre2"/>      parent[next] = current;<br class="calibre2"/>      q.add(next);<br class="calibre2"/>    }<br class="calibre2"/>  }<br class="calibre2"/>}</span>  </pre>
<div class="packt_figref"><span class="calibre10">Snippet 6.4: Implementation of breadth-first search. Source class name:</span> <span class="calibre10">BFS</span><span class="calibre10">.</span><span class="calibre10">Graph</span></div>
<div class="packt_infobox"><br class="calibre2"/>
<span class="calibre10">Go to</span> <a href="https://goo.gl/VqrQWM" class="pcalibre pcalibre3 calibre28 pcalibre1 pcalibre2"><span class="calibre10">https://goo.gl/VqrQWM</span></a> <span class="calibre10">to access this code.</span></div>
<p class="mce-root">Let's focus on the implementation of the BFS function. We will start by initializing a couple of auxiliary arrays: <kbd class="calibre15">parent</kbd> and <kbd class="calibre15">visited</kbd>. The first one will hold, at <kbd class="calibre15">parent[i]</kbd>, the parent of node <kbd class="calibre15">i</kbd> in the breadth-first tree. The second one will tell us, at <kbd class="calibre15">visited[i]</kbd>, whether or not vertex <kbd class="calibre15">i</kbd> has been discovered. We start by discovering the starting node and adding it to a queue. The queue will keep those vertices that have been discovered but not yet expanded. As such, while there are still elements in the queue, we will take its first element, go through its adjacent vertices, and discover those that haven't already been discovered, adding them to the queue.</p>
<p class="mce-root">When the queue becomes empty, we're sure of having expanded all vertices that are reachable from the starting vertex.</p>
<p class="mce-root">In the previous implementation, we've returned the array of parent nodes of the breadth-first tree in the <kbd class="calibre15">bfs()</kbd> function, allowing us to reconstruct the paths. If not necessary, you could just return the size of paths, or any other information we might be interested in extracting from the breadth-first search traversal.</p>
<p class="mce-root">In the <kbd class="calibre15">bfs()</kbd> method, we're sure of enqueuing, and hence dequeuing, each vertex at most once. As such, the total time dedicated to queue operations is <em class="calibre19">O(V)</em>. After dequeuing each vertex, we scan its adjacency list. Since we dequeue each vertex at most once, we scan each adjacency list at most once. As the sum of lengths of all the adjacency lists is <em class="calibre19">O(E)</em>, the total time spent in scanning adjacency lists is <em class="calibre19">O(E)</em>. Therefore, the BFS procedure has an initialization time of <em class="calibre19">O(V)</em> and a total running time of <em class="calibre19">O(V + E)</em>, running in linear time to the size of the adjacency list representation of <em class="calibre19">G</em>.</p>
<p class="mce-root">As we will see in later sections, the BFS procedure is the archetype for many important graph algorithms.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Depth-First Search</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root">Given a graph <em class="calibre19">G = (V, E)</em> and a source vertex s, depth-first search explores the edges of the graph by going "deeper" in the graph whenever possible. <strong class="calibre6">Depth-First Search</strong> (<strong class="calibre6">DFS</strong>) explores edges adjacent to the most recently discovered vertex <em class="calibre19">v</em> that still has unexplored edges whose head is adjacent to it. Once all of <em class="calibre19">v</em>'s edges have been explored, the search "backtracks" to explore edges, leaving the vertex from which <em class="calibre19">v</em> was discovered. The process continues until all vertices that are reachable from the original source vertex have been discovered.</p>
<p class="mce-root">If any undiscovered vertices remain, then DFS selects one of them as a new source, and it repeats the search from that source. While it may seem odd that BFS limits itself to vertices reachable from a single source whereas DFS considers multiple sources, the reason behind it is related to the applications of these searches.</p>
<p class="mce-root">BFS is usually used to find shortest-path distances while DFS is often used as a subroutine in another algorithm, which we shall see when we explore the cycle detection problem.</p>
<p class="mce-root">Similar to BFS, when we discover a vertex <em class="calibre19">v</em> during the scan of the adjacency list of an already discovered vertex, we record its parent attribute. Since we mentioned that we explore different sources, the parent subgraph produced by DFS is, unlike the breadth-first tree, a forest (that is, a set of trees).</p>
<p class="mce-root">In order to illustrate this, let's look  <span class="calibre14">at a run of DFS for the directed</span> <span class="calibre14">graph of</span> <em class="calibre19"><span class="calibre14">Figure 6.1</span></em><span class="calibre14">, starting at</span> <em class="calibre19"><span class="calibre14">node 2</span></em><span class="calibre14">, in the following table:</span></p>
<div class="title-page-name"><img class="fm-editor-equation13" src="Images/cf3f6f30-0e1b-496c-98fd-d08a5d877fac.png"/></div>
<div class="title-page-name"><img class="fm-editor-equation14" src="Images/c4409456-7b0c-43ac-b420-25981eed3d0f.png"/></div>
<div class="packt_figref"><span class="calibre10">Table 6.4: A run of DFS on the directed graph of Figure 6.1, starting at node 2</span></div>
<p class="mce-root"><span class="calibre14">Note that the results of DFS may depend on the order in which the vertices are examined. In the previous case, we started with</span> <span class="calibre14">2</span> <span class="calibre14">and always went for the lowest-numbered vertex in the adjacency list of a vertex first. If we had started with</span> <span class="calibre14">vertex 0</span><span class="calibre14">, we would have a different forest. In practice, we can usually use any DFS result with equivalent results.<br class="calibre7"/></span></p>
<p class="mce-root"><span class="calibre14">We previously saw how to perform DFS on trees. DFS on graphs is similar, but we need to keep track of explored nodes so that we don't get stuck in cycles.</span></p>
<p class="mce-root">In order to implement DFS, we will assume that our graph is represented using adjacency lists. We will attach certain attributes to each vertex in the graph, which will allow us to guide our search and later construct the depth-first forest. The following code snippet illustrates the implementation of depth-first search:</p>
<p class="mce-root"/>
<pre class="calibre20"><span class="calibre10">public void dfsVisit(int u, boolean[] visited, int[] parent) {<br class="calibre2"/>  visited[u] = true;<br class="calibre2"/>  for (int i = 0; i &lt; adj[u].size(); i++) {<br class="calibre2"/>    int next = adj[u].get(i);<br class="calibre2"/>    if (!visited[next]) {<br class="calibre2"/>      parent[next] = u;<br class="calibre2"/>      dfsVisit(next, visited, parent);<br class="calibre2"/>    }<br class="calibre2"/>  }<br class="calibre2"/>}</span> </pre>
<div class="packt_figref"><span class="calibre10">Snippet 6.5: Implementation of depth-first search. Source class name:</span><span class="calibre10">dfs.Graph</span><span class="calibre10">.</span></div>
<div class="packt_infobox"><br class="calibre2"/>
<span class="calibre10">Go to</span> <a href="https://goo.gl/saZYQp" class="pcalibre pcalibre3 calibre28 pcalibre1 pcalibre2"><span class="calibre10">https://goo.gl/saZYQp</span></a> <span class="calibre10">to access this code.</span></div>
<p class="mce-root">The DFS procedure works by initializing all vertices as not visited, and setting their parents to <em class="calibre19">-1</em> (meaning that they have no parent). Then, we find the first undiscovered vertex and visit it. In each visit, we start by recording the vertex as visited and then going through its adjacency list. There, we are looking for vertices not yet discovered. Once we find one, we visit it. Looking at the previous implementation, we see that the loops inside DFS take time <em class="calibre19">O(V)</em>, as they run for each vertex in the graph. We can also see that the <kbd class="calibre15">dfsVisit()</kbd> method is called exactly once for each vertex. During the execution of <kbd class="calibre15">dfsVisit()</kbd>, the loop scanning the adjacency list executes in time proportional to the size of the vertex's adjacency list. Since we said before that <kbd class="calibre15">dfsVisit()</kbd> is called exactly once for each vertex, the total time spent in the loop is proportional to the sum of the sizes of all adjacency lists, that is, <em class="calibre19">O(E)</em>. Therefore, the total running time of DFS is <em class="calibre19">O(V + E)</em>.</p>
<p class="mce-root">In the DFS method, we're returning the parent array, but the return type of this routine is usually adapted depending on the larger task that a more general algorithm that uses DFS is trying to achieve. We'll see DFS adapted to our specific needs in the next section.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Cycle Detection</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root"><span class="calibre14">A useful application of DFS is determining whether or not a graph is acyclic (that is, it does not contain cycles). In order to do so, it's important to define four types of edges in terms of the depth-first forest produced by DFS. They are as follows:</span></p>
<ul class="calibre12">
<li class="calibre13"><strong class="calibre3"><span class="calibre10">Tree edges</span></strong><span class="calibre10">: They are edges in the depth-first forest. An edge can only be a tree edge if it was the one explored when first discovering a vertex.</span></li>
<li class="calibre13"><strong class="calibre3"><span class="calibre10">Back edges</span></strong><span class="calibre10">: They are edges connecting a vertex to an ancestor in a depth-first tree. Self-loops (which may occur in directed graphs) are back edges.<br class="calibre2"/></span></li>
<li class="calibre13"><strong class="calibre3"><span class="calibre10">Forward edges</span></strong><span class="calibre10">: They are edges that do not belong to a depth-first tree but connect a vertex to one of its descendants in a depth-first tree. Forward edges are therefore edges that weren't used when performing the DFS, but connect vertices</span> <em class="calibre21"><span class="calibre10">u</span></em> <span class="calibre10">and</span> <em class="calibre21"><span class="calibre10">v</span></em> <span class="calibre10">in a depth-first tree provided that</span> <em class="calibre21"><span class="calibre10">v</span></em> <span class="calibre10">is a descendant of</span> <em class="calibre21"><span class="calibre10">u</span></em> <span class="calibre10"><span class="calibre10">in the tree.</span></span></li>
<li class="calibre13"><strong class="calibre3"><span class="calibre10">Cross edges</span></strong><span class="calibre10">: They are all other edges. They can go between vertices in the same depth-first tree or they can go between vertices in different depth-first trees. They are therefore edges that weren't used when performing the depth-first search, but connect vertices that don't share an ancestor relationship in the same tree or vertices in different trees.</span></li>
</ul>
<p class="mce-root">Having classified edges, it is possible to show that a directed graph is acyclic if and only if a DFS does not produce back edges. If a depth-first search produces a back edge <em class="calibre19">(u, v)</em>, then vertex <em class="calibre19">v</em> is an ancestor of vertex <em class="calibre19">u</em> in the depth-first forest. Therefore, <em class="calibre19">G</em> contains a path from <em class="calibre19">v</em> to <em class="calibre19">u</em>, and <em class="calibre19">(u, v)</em> completes a cycle. This algorithm is generalizable for undirected graphs. In undirected graphs, if we find a back edge <em class="calibre19">(u, v)</em> and <em class="calibre19">v</em> is not the parent of u in the depth-first forest, then we are in the presence of a cycle.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Activity: Using BFS to Find the Shortest Path Out of a Maze</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root"><strong class="calibre6"><span class="calibre14">Scenario</span></strong></p>
<p class="mce-root"><span class="calibre14">Our maze is an</span> <em class="calibre19"><span class="calibre14">H</span></em> <span class="calibre14">by</span> <em class="calibre19"><span class="calibre14">W</span></em> <span class="calibre14">rectangle, represented by an array of size</span> <em class="calibre19"><span class="calibre14">H</span></em> <span class="calibre14">of</span> <em class="calibre19"><span class="calibre14">W</span></em><span class="calibre14">-sized strings. Each character in a string can either be '<strong class="calibre6">#</strong>' or '<strong class="calibre6">.</strong>'. '<strong class="calibre6">#</strong>' represents a wall, which we cannot cross, and '.' represents a free space, which we can cross. The border of the maze is always filled with '<strong class="calibre6">#</strong>' except for one square, which represents the exit. For example, the following is a valid maze:</span></p>
<div class="cdpaligncenter1"><img src="Images/e1acfab2-ecc2-454a-b528-150e46593c6b.png" width="93" height="193" class="calibre89"/></div>
<p class="mce-root"><span class="calibre14">Find the total number of steps to exit the maze, when supplied with a starting point</span> <em class="calibre19"><span class="calibre14">(i, j)</span></em> <span class="calibre14">(with</span> <em class="calibre19"><span class="calibre14">(0, 0)</span></em> <span class="calibre14">being the upper-left point and</span> <em class="calibre19"><span class="calibre14">(H, W)</span></em> <span class="calibre14">being the lower-right point).</span></p>
<p class="mce-root"><strong class="calibre6">Aim</strong></p>
<p class="mce-root"><span class="calibre14">To use BFS to find the shortest path out of a given maze.</span></p>
<p class="mce-root"><strong class="calibre6"><span class="calibre14">Prerequisites</span></strong></p>
<ul class="calibre12">
<li class="calibre13"><span class="calibre10">Implement the</span> <kbd class="calibre15"><span class="calibre10">distToExit()</span></kbd> <span class="calibre10">method of the</span> <span class="calibre10"><kbd class="calibre15">Maze</kbd></span> <span class="calibre10">class in the source code, which returns the integer distance from that point to the exit of the maze. It is available at the following URL:<br class="calibre2"/></span><span class="calibre10"><a href="https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson6/activity/maze/Maze.java" class="pcalibre pcalibre3 calibre11 pcalibre1 pcalibre2">https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson6/activity/maze/Maze.java</a></span></li>
<li class="calibre13"><span class="calibre10">Assume that the points supplied to</span> <kbd class="calibre15"><span class="calibre10">distToExit()</span></kbd> <span class="calibre10">are valid (that is, they're not inside walls)<br class="calibre2"/></span></li>
<li class="calibre13"><span class="calibre10">Remember that we can only move in the cardinal directions (North, South,<br class="calibre2"/>
East, and West)</span></li>
</ul>
<p class="mce-root"><strong class="calibre6"><span class="calibre14">Steps for Completion</span></strong></p>
<ol class="calibre17">
<li class="chapter"><span class="calibre10">Encode the maze representation to a graph representation</span></li>
<li class="chapter"><span class="calibre10">Apply the BFS implementation shown in the preceding section (with a small modification to account for distances), or you can build the graph as you go</span></li>
<li class="chapter"><span class="calibre10">Since you know that there are at most four outward edges for a given vertex, compute their positions as you go</span></li>
</ol>
<p class="mce-root"><span class="calibre14">In this section, we've introduced two different ways to traverse a graph—<strong class="calibre6">breadth-first search</strong> (<strong class="calibre6">BFS</strong>) and <strong class="calibre6">depth-first search</strong> (<strong class="calibre6">DFS</strong>). We've seen how to use BFS to find the single-source shortest path in unweighted graphs and how to use DFS to find cycles in a graph. In the next section, we will be looking at two different algorithms to find shortest paths in a graph.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Calculating Shortest Paths</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root">The shortest path is a path between two vertices so that the sum of the weights of the edges that constitute the path is minimized. The shortest path problem has many applications in the real world, from finding directions on mapping applications to minimizing the moves to solve a puzzle.</p>
<p class="mce-root">In this section, we shall look at two different strategies for computing shortest paths: one that finds the shortest paths from a single source to every other vertex in the graph, and another that finds shortest paths between all pairs of vertices in a graph.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Single Source Shortest Path: Dijkstra's Algorithm</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root">When we explored BFS, we saw that it was able to solve the shortest path problem for unweighted graphs, or graphs whose edges have the same (positive) weight. What if we are dealing with weighted graphs? Can we do better? We shall see that Dijkstra's algorithm provides an improvement over the ideas presented in BFS and that it is an efficient algorithm for solving the single-source shortest path problem. One restriction for working with Dijkstra's algorithm is that edges' weights have to be positive. This is usually not a big issue since most graphs represent entities modeled by edges with positive weights. Nonetheless, there are algorithms capable of solving the problem for negative weights. Since the use case for negative edges is less common, those algorithms are outside the scope of this book.</p>
<p class="mce-root">Dijkstra's algorithm, conceived by Edsger W. Dijkstra in 1956, maintains a set <em class="calibre19">S</em> of vertices whose final shortest-path weights from the source <em class="calibre19">s</em> have already been determined. The algorithm repeatedly selects the vertex <em class="calibre19">u</em> with the minimum shortest-path estimate, adds it to set <em class="calibre19">S</em>, and uses the outward edges from that vertex to update the estimates from vertices not yet in set <em class="calibre19">S</em>. In order to see this in action, let's consider the directed graph of <em class="calibre19">Figure 6.5</em>:</p>
<p class="mce-root"> </p>
<div class="cdpaligncenter1"><img src="Images/49a7ece1-feb6-4021-82f2-b3215990b169.png" width="411" height="336" class="calibre90"/></div>
<div class="packt_figref"><span class="calibre10">Figure 6.5: A sample weighted directed graph</span></div>
<p class="mce-root">The graph is composed of five vertices (<em class="calibre19">A</em>, <em class="calibre19">B</em>, <em class="calibre19">C</em>, <em class="calibre19">D</em>, and <em class="calibre19">E</em>) and 10 edges. We're interested in finding the shortest paths, starting at vertex <em class="calibre19">A</em>. Note that A is already marked as <em class="calibre19">0</em>, meaning that the current distance from <em class="calibre19">A</em> to <em class="calibre19">A</em> is zero. The other vertices don't have distances associated with them yet. It is common to use an estimate of infinity as the starting estimate for the distance of nodes not yet seen. The following table shows a run of Dijkstra's algorithm for the graph of <em class="calibre19">Figure 6.5</em>, identifying the current vertex being selected and how it updates the estimates for vertices not yet seen:</p>
<table border="1" class="calibre22">
<tbody class="calibre23">
<tr class="calibre24">
<td class="calibre25"><strong class="calibre3">Step</strong></td>
<td class="calibre25"><strong class="calibre3">Explanation</strong></td>
</tr>
<tr class="calibre26">
<td class="calibre25"><img src="Images/be27917f-9d33-4854-862c-e55345bfa5f3.png" class="calibre91"/></td>
<td class="calibre25">Vertex <em class="calibre21">A</em> is the vertex with the lowest estimate weight, so it is selected as the next vertex whose edges are to be considered to improve our current estimates.</td>
</tr>
<tr class="calibre24">
<td class="calibre25"><img src="Images/f281522a-9f4a-4233-88de-ae382eea15d9.png" class="calibre91"/></td>
<td class="calibre25">We use the outward edges from vertex <em class="calibre21">A</em> to update our estimates for vertices <em class="calibre21">B</em> and <em class="calibre21">D</em>. Afterwards, we add <em class="calibre21">A</em> to set <em class="calibre21">S</em>, avoiding a repeated visit to it. From the edges not yet visited, the one with the lowest estimate is now <em class="calibre21">D</em>, which shall be selected to visit next. Note that we also mark those edges that belong to our estimate shortest path in bold.</td>
</tr>
<tr class="calibre26">
<td class="calibre25"><img src="Images/2cf9e89a-77d0-4d16-8268-421869d67694.png" class="calibre91"/></td>
<td class="calibre25">By exploring the outward edges from vertex <em class="calibre21">D</em>, we were able to improve our estimate for vertex <em class="calibre21">B</em>, so we update it accordingly and now consider a different edge for the shortest path. We were also able to discover vertices <em class="calibre21">C</em> and <em class="calibre21">E</em>, which become potential<br class="calibre2"/>
candidates to visit next. Since <em class="calibre21">E</em> is the one with the shorter estimate weight, we visit it next.</td>
</tr>
<tr class="calibre24">
<td class="calibre25"><img src="Images/b9a16349-a972-458e-bae1-cb32d60615b2.png" class="calibre91"/></td>
<td class="calibre25">Using an outward edge from vertex <em class="calibre21">E</em>, we were able to improve our estimate for vertex <em class="calibre21">C</em>, and now look at vertex <em class="calibre21">B</em> as our next vertex to visit. Note that those vertices that belong to set <em class="calibre21">S</em> (shown in black in the figure) already have their shortest path computed. The value inside them is the weight of the shortest path from <em class="calibre21">A</em> to them, and you can follow the edges in bold to build the shortest path.</td>
</tr>
<tr class="calibre26">
<td class="calibre25"><img src="Images/b93ca2a6-5f6e-48d5-ac55-275628ef8363.png" class="calibre91"/></td>
<td class="calibre25">From vertex <em class="calibre21">B</em>, we were able to once again improve our estimate for the shortest path to vertex <em class="calibre21">C</em>. Since vertex <em class="calibre21">C</em> is the only vertex not yet in set <em class="calibre21">S</em>, it is the one visited next.</td>
</tr>
<tr class="calibre27">
<td class="calibre25"><img src="Images/81e5d6e5-6186-454c-8908-a5c5ff1342f3.png" class="calibre91"/></td>
<td class="calibre25">Since vertex <em class="calibre21">C</em> has no outward edges to vertices not yet in <em class="calibre21">S</em>, we conclude the run of our algorithm, and have successfully computed the shortest paths from <em class="calibre21">A</em> to every other vertex in the graph.</td>
</tr>
</tbody>
</table>
<div class="packt_figref"><span class="calibre10">Table 6.5: A run of Dijkstra's algorithm for the weighted directed graph of Figure 6.5</span></div>
<p class="mce-root">Now that we've seen a run of Dijkstra's algorithm, let's try to put it in code and analyze its runtime performance. We will use an adjacency list representation for our graph, as it helps us when trying to explore the outward edges of a given vertex. The following code snippet shows a possible implementation of Dijkstra's algorithm as previously described:</p>
<pre class="calibre20"><span class="calibre10">while (!notVisited.isEmpty()) {<br class="calibre2"/>  Vertex v = getBestEstimate(notVisited);<br class="calibre2"/>  notVisited.remove(v);<br class="calibre2"/>  visited.add(v);<br class="calibre2"/>  for (Edge e : adj[v.u]) {<br class="calibre2"/>    if (!visited.contains(e.v)) {<br class="calibre2"/>      Vertex next = vertices[e.v];<br class="calibre2"/>      if (v.distance + e.weight &lt; next.distance) {<br class="calibre2"/>        next.distance = v.distance + e.weight;<br class="calibre2"/>        parent[next.u] = v.u;<br class="calibre2"/>      } <br class="calibre2"/>    }<br class="calibre2"/>  } <br class="calibre2"/>}</span>  </pre>
<div class="packt_figref"><span class="calibre10">Snippet 6.6: Implementation of Dijkstra's algorithm. Source class name:</span> <span class="calibre10">Dijkstra</span></div>
<div class="packt_infobox"><br class="calibre2"/>
<span class="calibre10">Go to</span> <a href="https://goo.gl/P7p5Ce" class="pcalibre pcalibre3 calibre28 pcalibre1 pcalibre2"><span class="calibre10">https://goo.gl/P7p5Ce</span></a> <span class="calibre10">to access this code.</span></div>
<p class="mce-root"><span class="calibre14">The</span> <span class="calibre14">Dijkstra</span> <span class="calibre14">method starts by initializing two sets:</span></p>
<ul class="calibre12">
<li class="calibre13"><span class="calibre10">One for visited vertices<br class="calibre2"/></span></li>
<li class="calibre13"><span class="calibre10">One for unvisited vertices</span></li>
</ul>
<p class="mce-root">The set of visited vertices corresponds to the set we previously named as <em class="calibre19">S</em>, and we use the one of not visited vertices to keep track of vertices to explore.</p>
<p class="mce-root">We then initialize each vertex with an estimated distance equal to <kbd class="calibre15">Integer.MAX_VALUE</kbd>, representing a value of "infinity" for our use case. We also use a parent array to keep track of parent vertices in the shortest path, so that we can later recreate the path from the source to each vertex.</p>
<p class="mce-root">The main loop runs for each vertex, while we still have vertices not yet visited. For each run, it selects the "best" vertex to explore. In this case, the "best" vertex is the one with the smallest distance of the vertices not visited so far (the <kbd class="calibre15">getBestEstimate()</kbd> function simply scans all vertices in the <kbd class="calibre15">notVisited()</kbd> set for the one satisfying the requirement).</p>
<p class="mce-root">Then, it adds the vertex to the set of visited vertices and updates the estimate distances for not visited vertices. When we run out of vertices to visit, we build our paths by recursively visiting the parent array.</p>
<p class="mce-root">Analyzing the runtime of the previous implementation, we can see that we have an initialization step that's proportional to the number of vertices in the graph, hence running in <em class="calibre19">O(V)</em>.</p>
<p class="mce-root">The main loop of the algorithm runs once for each vertex, so it is bounded by at least <em class="calibre19">O(V)</em>. Inside the main loop, we determine the next vertex to visit and then scan its adjacency list to update the estimate distances. Updating the distances takes time proportional to <em class="calibre19">O(1)</em>, and since we scan each vertex's adjacency list only once, we take time proportional to <em class="calibre19">O(E)</em>, updating estimate distances. We're left with the time spent selecting the next vertex to visit. Unfortunately, the <kbd class="calibre15">getBestEstimate()</kbd> method needs to scan through all the unvisited vertices, and is therefore bounded by <em class="calibre19">O(V)</em>. The total running time of our implementation of Dijkstra's algorithm is therefore <em class="calibre19">O(V<sup class="calibre32">2</sup>+E)</em>.</p>
<p class="mce-root">Even though some parts of our implementation seem difficult to optimize, it looks like we can do better when selecting the next vertex to visit. If we could have access to a data structure that was capable of storing our vertices sorted by lower estimated distance and provided efficient insert and remove operations, then we could reduce the <em class="calibre19">O(V)</em> time spent inside the <kbd class="calibre15">getBestEstimate</kbd> method.</p>
<p class="mce-root">In <a href="da07fa18-a8ce-4d4c-91eb-9dc893de7273.xhtml" class="pcalibre pcalibre3 calibre11 pcalibre1 pcalibre2">Chapter 4</a>, <em class="calibre19">Algorithm Design Paradigms</em>, we briefly discussed a data structure used in Huffman coding named the  <span class="calibre14">priority queue, which is just what we need for this job. The following code snippet implements a more efficient version of Dijkstra's algorithm, using a priority queue:</span></p>
<pre class="calibre20"><span class="calibre10">PriorityQueue&lt;Node&gt; pq = new PriorityQueue&lt;&gt;();<br class="calibre2"/>pq.add(new Node(source, 0));<br class="calibre2"/>while (!pq.isEmpty()) {<br class="calibre2"/>  Node v = pq.remove();<br class="calibre2"/>  if (!vertices[v.u].visited) {<br class="calibre2"/>    vertices[v.u].visited = true;<br class="calibre2"/>    for (Edge e : adj[v.u]) {<br class="calibre2"/>      Vertex next = vertices[e.v];<br class="calibre2"/>      if (v.distance + e.weight &lt; next.distance) {<br class="calibre2"/>        next.distance = v.distance + e.weight;<br class="calibre2"/>        parent[next.u] = v.u;<br class="calibre2"/>        pq.add(new Node(next.u, next.distance));<br class="calibre2"/>      }<br class="calibre2"/>    }<br class="calibre2"/>  } <br class="calibre2"/>}</span> </pre>
<div class="packt_figref"><span class="calibre10">Snippet 6.7: Implementation of Dijkstra's algorithm using a priority queue. Source class name: </span><span class="calibre10">DijkstraWithPQ</span></div>
<div class="packt_infobox"><br class="calibre2"/>
<span class="calibre10">Go to</span> <a href="https://goo.gl/3rtZCQ" class="pcalibre pcalibre3 calibre28 pcalibre1 pcalibre2"><span class="calibre10">https://goo.gl/3rtZCQ</span></a> <span class="calibre10">to access this code.</span></div>
<p class="mce-root">In this second implementation, we no longer keep sets for visited and not visited vertices. Instead, we rely on a priority queue that will be storing our distance estimates while we run the algorithm.</p>
<p class="mce-root">When we are exploring the outward edges from a given vertex, we therefore add a new entry to the priority queue in case we are able to improve our distance estimate.</p>
<p class="mce-root">Adding and removing an element from our priority queue takes <em class="calibre19">O(logN)</em> time, <em class="calibre19">N</em> being the number of elements in the queue. Do note that we can have the same vertex inserted more than once in the priority queue. That's why we check if we've visited it before expanding its edges.</p>
<p class="mce-root">Since we will visit the instance for that vertex with shorter estimate distance, it's safe to ignore the ones that come after it. However, that means that operations on our priority queue are not bounded by <em class="calibre19">O(logV)</em>, but <em class="calibre19">O(log E)</em> instead (assuming that there's a connected graph).</p>
<p class="mce-root">Therefore, the total runtime of this implementation is <em class="calibre19">O((V + E)logE)</em>. It's still possible to improve this running time by using a priority queue implementation with better asymptotic bounds (such as a Fibonacci heap), but its implementation is out of the scope of this book.</p>
<p class="mce-root">One last thing to note about Dijkstra's algorithm is how it borrows ideas from BFS (the algorithm structure is very similar to Dijkstra's, but we end up using a priority queue instead of a normal queue) and that it is a very good example of a greedy algorithm: Dijkstra's algorithm makes the locally optimum choice (for example, it chooses the vertex with the minimum estimated distance) in order to arrive at a global optimum.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">All Pairs Shortest Paths: Floyd-Warshall Algorithm</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root">Sometimes, it might be necessary to compute the shortest paths between all pairs of vertices. For example, we might be interested in building a table of distances. One way to do that is to perform a single source shortest path for every vertex of the graph. If you use Dijkstra's algorithm for that, we end up with a runtime of <em class="calibre19">O(V*(V + E)logE)</em>.</p>
<p class="mce-root">In this subsection, we shall explore an algorithm capable of solving the all pairs shortest paths problem in <em class="calibre19">O(V<sup class="calibre32">3</sup>)</em> time, with a remarkably simple and elegant implementation.</p>
<div class="packt_infobox"><br class="calibre2"/>
The algorithm we are about to study, more commonly referred to as the Floyd-Warshall algorithm, was published in its current form by Robert Floyd in 1962. However, in its essence, it follows the same ideas published by Bernard Roy in 1959 and Stephen Warshall in 1962.</div>
<p class="mce-root">The algorithm uses the adjacency matrix representation and follows a dynamic programming approach. The basic idea behind it is that, when we're trying to compute the shortest-path distance between vertex <em class="calibre19">i</em> and vertex <em class="calibre19">j</em>, we try to use an intermediate vertex, <em class="calibre19">k</em>. We want to use an intermediate vertex so that doing the path from <em class="calibre19">i</em> to <em class="calibre19">k</em> and then from <em class="calibre19">k</em> to <em class="calibre19">j</em> shortens the currently computed shortest path between <em class="calibre19">i</em> and <em class="calibre19">j</em>. If we find such a vertex, then the best path we're able to compute so far between <em class="calibre19">i</em> and <em class="calibre19">j</em> must go through <em class="calibre19">k</em>. All that we need to do is, for each <em class="calibre19">k</em>, see if using it improves the shortest path between <em class="calibre19">i</em> and <em class="calibre19">j</em>, for all possible <em class="calibre19">i</em> and <em class="calibre19">j</em>.</p>
<p class="mce-root">In order to see that in practice, let's use the directed graph of <em class="calibre19">Figure 6.5</em> that we used to illustrate Dijkstra's algorithm. The graph of <em class="calibre19">Figure 6.5</em> has the adjacency matrix representation of the following table:</p>
<table border="1" class="calibre22">
<tbody class="calibre23">
<tr class="calibre24">
<td class="calibre25"/>
<td class="calibre25"><strong class="calibre3">A</strong></td>
<td class="calibre25"><strong class="calibre3">B</strong></td>
<td class="calibre25"><strong class="calibre3">C</strong></td>
<td class="calibre25"><strong class="calibre3">D</strong></td>
<td class="calibre25"><strong class="calibre3">E</strong></td>
</tr>
<tr class="calibre26">
<td class="calibre25"><strong class="calibre3">A</strong></td>
<td class="calibre25">0</td>
<td class="calibre25">10</td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">5</td>
<td class="calibre25"><span class="calibre10">∞</span></td>
</tr>
<tr class="calibre24">
<td class="calibre25"><strong class="calibre3">B</strong></td>
<td class="calibre25">∞</td>
<td class="calibre25">0</td>
<td class="calibre25">1</td>
<td class="calibre25">2</td>
<td class="calibre25"><span class="calibre10">∞</span></td>
</tr>
<tr class="calibre26">
<td class="calibre25"><strong class="calibre3">C</strong></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">0</td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">4</td>
</tr>
<tr class="calibre24">
<td class="calibre25"><strong class="calibre3">D</strong></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">3</td>
<td class="calibre25">9</td>
<td class="calibre25">0</td>
<td class="calibre25">2</td>
</tr>
<tr class="calibre38">
<td class="calibre25"><strong class="calibre3">E</strong></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">6</td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">0</td>
</tr>
</tbody>
</table>
<div class="packt_figref"><span class="calibre10">Table 6.6: Adjacency matrix representation of the directed graph of Figure 6.5</span></div>
<p class="mce-root">The adjacency matrix representation serves as the starting point for the Floyd-Warshall algorithm, and we iterate through it until we're left with a matrix of the weights of the shortest paths between each pair of vertices. In order to do so, let's start with vertex <em class="calibre19">A</em>, considering it as an intermediate vertex for shortest paths. Unfortunately, vertex <em class="calibre19">A</em> doesn't have inward edges, meaning that it can't be used as an intermediate vertex for shortest paths. Using vertex <em class="calibre19">B</em>, we can improve the distance from <em class="calibre19">A</em> to <em class="calibre19">C (10 + 1 &lt; ∞)</em>, and we can use it to go from <em class="calibre19">A</em> to <em class="calibre19">D</em>, but not improve the overall distance. We can also use it to improve the distance from <em class="calibre19">D</em> to <em class="calibre19">C (3 + 1 &lt; 9)</em>. Therefore, after considering <em class="calibre19">B</em> as an intermediate vertex, we're left with the distance matrix of the following table:</p>
<table border="1" class="calibre22">
<tbody class="calibre23">
<tr class="calibre24">
<td class="calibre25"/>
<td class="calibre25"><strong class="calibre3">A</strong></td>
<td class="calibre25"><strong class="calibre3">B</strong></td>
<td class="calibre25"><strong class="calibre3">C</strong></td>
<td class="calibre25"><strong class="calibre3">D</strong></td>
<td class="calibre25"><strong class="calibre3">E</strong></td>
</tr>
<tr class="calibre26">
<td class="calibre25"><strong class="calibre3">A</strong></td>
<td class="calibre25">0</td>
<td class="calibre25">10</td>
<td class="calibre25">11</td>
<td class="calibre25">5</td>
<td class="calibre25"><span class="calibre10">∞</span></td>
</tr>
<tr class="calibre24">
<td class="calibre25"><strong class="calibre3">B</strong></td>
<td class="calibre25">∞</td>
<td class="calibre25">0</td>
<td class="calibre25">1</td>
<td class="calibre25">2</td>
<td class="calibre25"><span class="calibre10">∞</span></td>
</tr>
<tr class="calibre26">
<td class="calibre25"><strong class="calibre3">C</strong></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">0</td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">4</td>
</tr>
<tr class="calibre24">
<td class="calibre25"><strong class="calibre3">D</strong></td>
<td class="calibre25"><strong class="calibre3"><span class="calibre10">∞</span></strong></td>
<td class="calibre25">3</td>
<td class="calibre25">4</td>
<td class="calibre25">0</td>
<td class="calibre25">2</td>
</tr>
<tr class="calibre38">
<td class="calibre25"><strong class="calibre3">E</strong></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">6</td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">0</td>
</tr>
</tbody>
</table>
<div class="packt_figref"><span class="calibre10">Table 6.7: Distance matrix after considering B as an intermediate vertex</span></div>
<p class="mce-root"><span class="calibre14">Now, we are going to look at vertex</span> <em class="calibre19"><span class="calibre14">C</span></em><span class="calibre14">. Using vertex</span> <em class="calibre19"><span class="calibre14">C</span></em><span class="calibre14">, we can improve the distance from</span> <em class="calibre19"><span class="calibre14">A</span></em> <span class="calibre14">to</span> <em class="calibre19"><span class="calibre14">E (11 + 4 &lt; ∞)</span></em> <span class="calibre14">and</span> <em class="calibre19"><span class="calibre14">B</span></em> <span class="calibre14">to</span> <span class="calibre14"><em class="calibre19">E (1 + 4 &lt; ∞)</em>:</span></p>
<table border="1" class="calibre22">
<tbody class="calibre23">
<tr class="calibre24">
<td class="calibre25"/>
<td class="calibre25"><strong class="calibre3">A</strong></td>
<td class="calibre25"><strong class="calibre3">B</strong></td>
<td class="calibre25"><strong class="calibre3">C</strong></td>
<td class="calibre25"><strong class="calibre3">D</strong></td>
<td class="calibre25"><strong class="calibre3">E</strong></td>
</tr>
<tr class="calibre26">
<td class="calibre25"><strong class="calibre3">A</strong></td>
<td class="calibre25">0</td>
<td class="calibre25">10</td>
<td class="calibre25">11</td>
<td class="calibre25">5</td>
<td class="calibre25">15</td>
</tr>
<tr class="calibre24">
<td class="calibre25"><strong class="calibre3">B</strong></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">0</td>
<td class="calibre25">1</td>
<td class="calibre25">2</td>
<td class="calibre25">5</td>
</tr>
<tr class="calibre26">
<td class="calibre25"><strong class="calibre3">C</strong></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">0</td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">4</td>
</tr>
<tr class="calibre24">
<td class="calibre25"><strong class="calibre3">D</strong></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">3</td>
<td class="calibre25">4</td>
<td class="calibre25">0</td>
<td class="calibre25">2</td>
</tr>
<tr class="calibre38">
<td class="calibre25"><strong class="calibre3">E</strong></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">6</td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">0</td>
</tr>
</tbody>
</table>
<div class="packt_figref"><span class="calibre10">Table 6.8: Distance matrix after considering C as an intermediate vertex</span></div>
<p class="mce-root"><span class="calibre14">Using vertex</span> <em class="calibre19"><span class="calibre14">D</span></em><span class="calibre14">, we can improve the distance from</span> <em class="calibre19"><span class="calibre14">A</span></em> <span class="calibre14">to</span> <em class="calibre19"><span class="calibre14">B (5 + 3 &lt; 10)</span></em><span class="calibre14">,</span> <em class="calibre19"><span class="calibre14">A</span></em> <span class="calibre14">to</span> <em class="calibre19"><span class="calibre14">C (5 + 4 &lt; 11)</span></em><span class="calibre14">,</span> <span class="calibre14"><em class="calibre19">A </em></span><span class="calibre14">to</span> <span class="calibre14"><em class="calibre19">E (5 + 2 &lt; 15)</em>,</span> <span class="calibre14">and</span> <em class="calibre19"><span class="calibre14">B</span></em> <span class="calibre14">to</span> <em class="calibre19"><span class="calibre14">E (2 + 2 &lt; 5)</span></em>:</p>
<table border="1" class="calibre22">
<tbody class="calibre23">
<tr class="calibre24">
<td class="calibre25"/>
<td class="calibre25"><strong class="calibre3">A</strong></td>
<td class="calibre25"><strong class="calibre3">B</strong></td>
<td class="calibre25"><strong class="calibre3">C</strong></td>
<td class="calibre25"><strong class="calibre3">D</strong></td>
<td class="calibre25"><strong class="calibre3">E</strong></td>
</tr>
<tr class="calibre26">
<td class="calibre25"><strong class="calibre3">A</strong></td>
<td class="calibre25">0</td>
<td class="calibre25">8</td>
<td class="calibre25">9</td>
<td class="calibre25">5</td>
<td class="calibre25">7</td>
</tr>
<tr class="calibre24">
<td class="calibre25"><strong class="calibre3">B</strong></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">0</td>
<td class="calibre25">1</td>
<td class="calibre25">2</td>
<td class="calibre25">4</td>
</tr>
<tr class="calibre26">
<td class="calibre25"><strong class="calibre3">C</strong></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">0</td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">4</td>
</tr>
<tr class="calibre24">
<td class="calibre25"><strong class="calibre3">D</strong></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">3</td>
<td class="calibre25">4</td>
<td class="calibre25">0</td>
<td class="calibre25">2</td>
</tr>
<tr class="calibre38">
<td class="calibre25"><strong class="calibre3">E</strong></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">6</td>
<td class="calibre25"><span class="calibre10">∞</span></td>
<td class="calibre25">0</td>
</tr>
</tbody>
</table>
<div class="packt_figref"><span class="calibre10">Table 6.9: Distance matrix after considering D as an intermediate vertex</span></div>
<p class="mce-root"><span class="calibre14">Using vertex</span> <em class="calibre19"><span class="calibre14">E</span></em><span class="calibre14">, we cannot improve any distance, so</span> <em class="calibre19"><span class="calibre14">Table 6.9</span></em> <span class="calibre14">already has the weights for the shortest paths between all pairs of vertices. </span><span class="calibre14">Implementing the Floyd-Warshall algorithm is very simple, as the following code snippet demonstrates:</span></p>
<pre class="calibre20"><span class="calibre10">public void run() {<br class="calibre2"/>  for (int k = 0; k &lt; adj.length; k++) {<br class="calibre2"/>    for (int i = 0; i &lt; adj.length; i++) {<br class="calibre2"/>      if (adj[i][k] &gt;= Integer.MAX_VALUE)<br class="calibre2"/>        continue;<br class="calibre2"/>      for (int j = 0; j &lt; adj.length; j++) {<br class="calibre2"/>        if (adj[k][j] &gt;= Integer.MAX_VALUE)<br class="calibre2"/>          continue;<br class="calibre2"/>        adj[i][j] = Math.min(adj[i][j], adj[i][k] + adj[k][j]);<br class="calibre2"/>      }<br class="calibre2"/>    }<br class="calibre2"/>  }<br class="calibre2"/>}</span>  </pre>
<div class="packt_figref"><span class="calibre10">Snippet 6.8: Implementation of Floyd Warshall's algorithm. Source class name: </span><span class="calibre10">FloydWarshall</span></div>
<div class="packt_infobox"><br class="calibre2"/>
<span class="calibre10">Go to</span> <a href="https://goo.gl/SQxdL2" class="pcalibre pcalibre3 calibre28 pcalibre1 pcalibre2"><span class="calibre10">https://goo.gl/SQxdL2</span></a> <span class="calibre10">to access this code.</span></div>
<p class="mce-root">Looking at the implementation, the runtime of <em class="calibre19">O(V<sup class="calibre32">3</sup>)</em> becomes obvious. One alternative to the Floyd-Warshall algorithm is running Dijkstra's algorithm for each vertex in the graph (so that we end up with all pairwise shortest paths). Given that its complexity is closer to multiple applications of Dijkstra's algorithm for dense graphs, the Floyd-Warshall algorithm is frequently used in practice.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Activity: Improving Floyd-Warshall's Algorithm to Reconstruct the Shortest Path</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root"><strong class="calibre6"><span class="calibre14">Scenario</span></strong></p>
<p class="mce-root"><span class="calibre14">Improve Floyd-Warshall's algorithm so that we're able to reconstruct the shortest path between two given nodes after running the algorithm, using the predecessor matrix.</span></p>
<p class="mce-root"><strong class="calibre6">Aim</strong></p>
<p class="mce-root"><span class="calibre14">To construct a shortest path between the two vertices using the predecessor matrix.</span></p>
<p class="mce-root"><strong class="calibre6"><span class="calibre14">Prerequisite</span></strong></p>
<div class="packt_infobox"><span class="calibre10">The predecessor matrix is used to compute the shortest path between two given vertices. Each cell of the predecessor matrix</span> <em class="calibre21"><span class="calibre10">P</span><sub class="calibre92"><span class="calibre14">ij</span></sub></em> <span class="calibre10">should be either empty (meaning that there is no path between</span> <em class="calibre21"><span class="calibre10">i</span></em> <span class="calibre10">and</span> <em class="calibre21"><span class="calibre10">j</span></em><span class="calibre10">), or equal to some index</span> <em class="calibre21"><span class="calibre10">k</span></em> <span class="calibre10">(meaning that vertex</span> <em class="calibre21"><span class="calibre10">k</span></em> <span class="calibre10">is the one that precedes</span> <em class="calibre21"><span class="calibre10">j</span></em> <span class="calibre10">in the shortest path between</span> <em class="calibre21"><span class="calibre10">i</span></em> <span class="calibre10">and</span> <em class="calibre21"><span class="calibre10">j</span></em><span class="calibre10">). As such, we need to update our predecessor matrix whenever we use an intermediate vertex.</span></div>
<p class="mce-root"><span class="calibre14">Implement the</span> <kbd class="calibre15"><span class="calibre10">run()</span></kbd> <span class="calibre14">method of the</span> <span class="calibre14">Floyd-Warshall</span> <span class="calibre14">class that shall compute the shortest paths for the current graph and populate the path matrix, used later in the</span> <kbd class="calibre15"><span class="calibre10">path()</span></kbd> <span class="calibre14">method to return the path between two given vertices. The method is available at the following URL:</span></p>
<p class="mce-root"><a href="https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson6/activity/floydwarshall/FloydWarshall.java" class="pcalibre pcalibre3 calibre11 pcalibre1 pcalibre2">https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson6/activity/floydwarshall/FloydWarshall.java</a></p>
<p class="mce-root"><strong class="calibre6"><span class="calibre14">Steps for Completion</span></strong></p>
<ol class="calibre17">
<li class="chapter"><span class="calibre10">Adapt the implementation shown in</span> <em class="calibre21"><span class="calibre10">Snippet 6.8</span></em> <span class="calibre10">of the Floyd-Warshall algorithm to update the path matrix</span></li>
<li class="chapter"><span class="calibre10">Use it to reconstruct the paths similarly to what we have previously shown in the implementation of Dijkstra's algorithm</span></li>
</ol>
<p class="mce-root">In this section, we've introduced the shortest paths problem and visited two different algorithms to solve it: one for single source shortest paths (Dijkstra's algorithm), and another for all pairs shortest paths (Floyd-Warshall). We've shown how different implementations of Dijkstra's algorithm can affect its running time. For both algorithms, we've also shown how to reconstruct shortest paths using a parent array and a predecessor matrix, respectively.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Prime Numbers in Algorithms</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root">A prime number is a natural number greater than one whose only divisors are one and the number itself.</p>
<p class="mce-root">Prime numbers play a very important role in the fundamental theorem of arithmetic: every natural number greater than one is either a prime or a product of primes. Nowadays, number-theoretic algorithms are widely used, mainly due to cryptographic schemes based on large prime numbers. Most of those cryptographic schemes are based on the fact that we can efficiently find large primes, but we cannot factor the product of those large primes efficiently. As seen before, prime numbers play an important role in the implementation of hash tables.<span class="calibre14"><br class="calibre7"/></span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Sieve of Eratosthenes</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root">The sieve of Eratosthenes is a simple and ancient algorithm to find all prime numbers up to a given limit. If we want to find all prime numbers up to <em class="calibre19">N</em>, we start by creating a list of consecutive integers from <em class="calibre19">2</em> to <em class="calibre19">N (2, 3, 4, 5… N)</em>, initially unmarked. Let's use <em class="calibre19">p</em> to denote the smallest unmarked number. Then, we select the smallest unmarked number <em class="calibre19">p</em> that is larger than the last <em class="calibre19">p</em>. In the first iteration, <em class="calibre19">p</em> will be two. Afterwards, by increments of <em class="calibre19">p</em>, we mark elements in the list from <em class="calibre19">2p</em> until <em class="calibre19">Mp</em> so that <em class="calibre19">Mp &lt;= N.</em></p>
<p class="mce-root">We repeat this strategy until it is impossible to mark more numbers in the list. At the end of the run, all the unmarked numbers are prime numbers. It is easy to see that all unmarked numbers will be the ones for which we couldn't find a divisor other than the number itself and 1, and are therefore prime numbers.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Prime Factorization</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root">Prime factorization is determining the prime factors of a given number. It is very difficult to build a general-purpose algorithm for this computationally hard problem. A general purpose algorithm that is commonly used to factorize primes was introduced in <a href="52b469c2-7203-4188-9e37-6ab0bf659ca7.xhtml" class="pcalibre pcalibre3 calibre11 pcalibre1 pcalibre2">Chapter 1</a>, <em class="calibre19">Algorithms and Complexities</em>. Its basic idea is to iterate through possible factors attempting to divide the number.</p>
<p class="mce-root">Start with 2; while the number is divisible by 2, keep dividing it, and add 2 to the list of factors. Afterwards, the number must be odd, so start a loop that checks for possible factors from 3 to the square root of the number.</p>
<p class="mce-root">Since we've already covered even numbers, you can do increments of 2 in this loop (there's no need to check 4, 6, 8, and so on once you've already checked 2). Once you find a suitable divisor, add the number to the list of factors and divide it until it is possible. At the end of this step, if we are left with a number greater than 2, then it is a prime number and therefore a prime factor of itself.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Activity: Implementing the Sieve of Eratosthenes</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root"><strong class="calibre6">Scenario</strong></p>
<p class="mce-root"><span class="calibre14">Implementing the sieve of Eratosthenes algorithm to find all prime numbers up to a given limit.</span></p>
<p class="mce-root"><strong class="calibre6">Aim</strong></p>
<p class="mce-root"><span class="calibre14">To develop a code in Java for implementing the sieve of Eratosthenes.</span></p>
<p class="mce-root"><strong class="calibre6"><span class="calibre14">Prerequisites</span></strong></p>
<ul class="calibre12">
<li class="calibre13"><span class="calibre10">Implement the</span> <kbd class="calibre15"><span class="calibre10">isPrime()</span></kbd> <span class="calibre10">method of the</span> <span class="calibre10"><kbd class="calibre15">SieveOfEratosthenes</kbd> class </span><span class="calibre10">that should return <kbd class="calibre15">true</kbd> if the number is prime, and <kbd class="calibre15">false</kbd> otherwise. It is available at the following URL:</span> <br class="calibre2"/>
<a href="https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson7/activity/sieve/SieveOfEratosthenes.java" class="pcalibre pcalibre3 calibre11 pcalibre1 pcalibre2">https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson7/activity/sieve/SieveOfEratosthenes.java</a></li>
<li class="calibre13"><span class="calibre10">Consider building the sieve in the class constructor</span></li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Other Concepts in Graphs</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root"><span class="calibre14">In this chapter, we covered ways of representing and traversing a graph and looked at shortest path algorithms. Graphs are also an optimal data structure for some problems we haven't mentioned yet. This section aims to introduce some of them.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Minimum Spanning Trees</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root">A minimum spanning tree of a graph is a subset of the set of edges <em class="calibre19">E</em> of a connected graph that connects all vertices together, without any cycles and with the minimum total edge weight. It is a tree because every two vertices in it are connected by exactly one path.</p>
<p class="mce-root">In order to understand the applicability of minimum spanning trees, consider the problem of a telecommunications company that is moving into a new neighborhood. The company wants to connect all the houses, but also wants to minimize the length of cable that it uses in order to cut costs. One way to solve the problem is by computing the minimum spanning tree of a graph whose vertices are the houses of the neighborhood, and the edges between houses are weighted according to the distance between them.</p>
<p class="mce-root">There are many algorithms to solve the minimum spanning tree problem. Two of the most famous are Prim's and Kruskal's.</p>
<p class="mce-root">Prim's algorithm is a greedy algorithm that repeatedly selects the edge of smaller weights that connect some edge not yet in the spanning tree with some edge already in the spanning tree. Its runtime depends on the implementation, but it's possible to achieve a runtime of <em class="calibre19">O(VlogE)</em>. It can be implemented similarly to Dijkstra's algorithm. We start with one vertex chosen arbitrarily to be part of the tree. All edges that connect to this "starting" vertex are added to a set of candidate edges that are sorted according to the edges' weights. While we still have vertices to add to the tree, we repeatedly select the edge with the smaller weight from the list of candidate edges that connects to a vertex not yet in the tree, and repeat the process for the new vertex.</p>
<p class="mce-root">Kruskal's algorithm is also a greedy algorithm that uses a disjoint-set data structure. A disjoint-set data structure, or union-find data structure, is a data structure that tracks elements that are partitioned into a number of non-overlapping subsets. It provides an efficient way to merge two sets and check whether two elements belong to the same set.</p>
<p class="mce-root">The idea of Kruskal's algorithm is to reduce a forest (for example, a set of trees) to a single tree, using a disjoint-set data structure to keep track of trees. We start with one tree for each vertex, including only one vertex. While we have more than one tree, we select the edge of the smallest weight that connects two different trees (we don't want to produce a cycle), and join the two trees together. At the end, the resultant tree will be the one whose total edge weight is minimized. The running time of Kruskal's algorithm is also <em class="calibre19">O(VlogE)</em>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">A* Search</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root">The <em class="calibre19">A*</em> search algorithm is a very common algorithm when solving path-finding problems. It also solves the shortest path problem, enhancing Dijkstra's algorithm with the introduction of a heuristic to guide the search. A heuristic is a practical estimate of a given cost, not guaranteed to be optimal or perfect, but sufficient for the immediate goals, or to guide a search. Its basic idea is that, when adding this heuristic to the estimated distance already computed for a node, one can guide the search towards the goal and avoid visiting certain vertices.</p>
<p class="mce-root">For example, if we use the Euclidean distance (for example, the straight line distance between two points) from our location to the exit of a given maze, we can guide the search towards that and avoid visiting certain unnecessary positions.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Maximum Flow</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root">Some directed weighted graphs can be seen as flow networks. In a flow network, edge weights represent capacities and each edge receives a flow that can't exceed the edge's capacity. <span class="calibre14">The labels on the edges represent the used and total capacity of the edge. </span>The maximum flow attempts to find a feasible flow through the network that is maximum, considering a single source (where the initial flow starts) and single sink (where the flow ends). The maximum flow problem allows one to solve related problems like pair wise assignment. There are various algorithms to solve the maximum flow problem. Three of the most famous ones are the FordFulkerson algorithm, the Edmonds-Karp algorithm, and Dinic's algorithm.</p>
<p class="mce-root"><span class="calibre14">The idea behind the Ford-Fulkerson algorithm is to</span> repeatedly <span class="calibre14">find augmenting paths in the flow network. An augmenting path is a path that still has an available capacity. While it is possible to find augmenting paths, one can add a flow through the path equal to its capacity and repeat the process. Ford-Fulkerson algorithm runs in</span> <em class="calibre19">O(Ef)</em><span class="calibre14">,</span> <em class="calibre19">f</em> <span class="calibre14">being the maximum flow of the graph. The Edmonds-Karp algorithm improves on the Ford-Fulkerson algorithm by always selecting the augmenting path that is shortest. The runtime complexity of the Edmonds-Karp algorithm is</span> <em class="calibre19">O(VE<sup class="calibre32">2</sup>)</em><span class="calibre14">, independent of the maximum flow value. Dinic's algorithm runs in</span> <em class="calibre19">O(V<sup class="calibre32">2</sup>E)</em> <span class="calibre14">time, also building on shortest augmenting paths, but uses some concepts that make it more suitable for sparse graphs.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Understanding Complexity Classes of Problems</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root">Nearly all of the algorithms introduced so far run in polynomial time (for instance, on inputs of size <em class="calibre19">n</em>, their worst-case running time is <em class="calibre19">O(n<sup class="calibre32">k</sup>)</em> for constant <em class="calibre19">k</em>). However, there are problems that simply cannot be solved or for which a polynomial-time algorithm hasn't been found yet.</p>
<p class="mce-root">An example of a problem that cannot be solved is the halting problem. The halting problem is the problem of determining, from the description of a computer program and an input, whether the program will finish running or continue to run forever. Alan Turing proved that a general algorithm to solve the halting problem for all pairs of (program, input) cannot exist.</p>
<p class="mce-root">It is common to call problems solvable by polynomial-time algorithms (for instance, those whose worst-case running time is <em class="calibre19">O(n<sup class="calibre32">k</sup>)</em> for constant <em class="calibre19">k</em>) as "tractable", or "easy", and problems that require a super-polynomial-time algorithm (for instance, those whose running time is not bounded above by any polynomial) as "intractable", or "hard".</p>
<p class="mce-root">There is a class of problems, called <strong class="calibre6">NP-Complete</strong> (<strong class="calibre6">NPC</strong>) problems, and no one has yet found a polynomial-time algorithm to solve them. However, no one has yet been able to prove that no polynomial-time algorithm can exist for any of them.</p>
<p class="mce-root">There is another class of problems, called <strong class="calibre6">NP</strong> problems, whose solutions are verifiable in polynomial time. This means that, given a problem, and a possible solution to it, one can verify if the solution is correct in polynomial time.</p>
<p class="mce-root">All problems in P are also in NP. NPC consists of problems that belong to the NP class and to the NP-hard class. A problem is NP-hard if an algorithm for solving it can be translated into one for solving a NP problem.</p>
<p class="mce-root">One of the deepest open research problems in theoretical computer science is whether <em class="calibre19">P</em> is really different from NP (for instance, <em class="calibre19">P != NP</em>).</p>
<p class="mce-root">Examples of NPC problems are as follows:</p>
<ul class="calibre12">
<li class="calibre13"><span class="calibre10">Finding the longest path in the graph</span></li>
<li class="calibre13"><span class="calibre10">Finding a path in a graph that visits all vertices exactly once (known as a Hamiltonian path)</span></li>
</ul>
<p class="mce-root"><span class="calibre14">A common example of an NP-hard problem is finding the shortest path in a graph that visits all vertices exactly once and returns to the starting point. The problem consists of finding the Hamiltonian cycle of the smallest weight, and is often described as the traveling salesman problem as it models the problem of a salesman that needs to visit all cities and return to his hometown.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article class="calibre2">
                
<p class="mce-root">In this chapter, we have introduced graphs, formalized what they are and shown two different ways to represent them in computer programs. Afterwards, we took a look at ways of traversing graphs, using them as building blocks for building more complex algorithms on top. Then, we looked at two different algorithms for finding shortest paths in a graph.</p>
<p class="mce-root">At the end of this book, we provide pointers for curious students to study on their own. The world of data structures and algorithms is vast and requires a type of mathematical reasoning for which some study and practice is required. However, one of the most rewarding feelings in the life of a software engineer is coming up with a clever algorithms to solve a complex problems.</p>


            </article>

            
        </section>
    </div>



  </body></html>