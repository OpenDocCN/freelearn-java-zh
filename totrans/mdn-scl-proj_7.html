<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Building a Recommendation Engine</h1>
                </header>
            
            <article>
                
<p><span>Millions of people order items from Amazon, where they save money and time. Recommendation algorithms are learned from customers, ordering preferences and bring them tailored you may also like recommendations, which are suggestions that help the customer update their cart or add interesting items to a wishlist for later. </span></p>
<p><span>Building our own recommendations engine is a learning journey, where we hit several objectives along the way. At the problem formulation stage, we learn that recommendations are a collaborative filtering machine learning problem. We will take advantage of the Spark ML collaborative filtering algorithm to implement a recommendations engine that will generate ratings-based recommendations.</span></p>
<p>Netflix is famous for its movies where you might enjoy the recommendation feature. Back in 2006, Netflix announced a prize of $1 million for the best enhancement over their aging <strong>CineMatch</strong> movie recommendation algorithm. This <span>trendsetting </span>competition <span>spawned some </span><span>of the best advances in machine learning. </span><span>Working on a </span><span>treasure trove of Netflix-released movie ratings, s</span>everal crack teams of coders across the world battled for the top prize. Their goal—to build an algorithm that <span>would predict user ratings (and hence better recommendations) up to 10% better than CineMatch. </span></p>
<p>Since then, algorithms that make recommendations about <strong>items</strong> to users have come a long way. In this chapter, we set out to build a recommendation system with Scala and Apache Spark. What problem is this recommendation system going to solve? This and other questions are going to be answered shortly.</p>
<p>The overarching learning objective of this chapter is to implement a recommendations engine. <span>The following list is a comprehensive breakdown of individual learning objectives:</span></p>
<ul>
<li>Learning the ropes of recommendations; r<span>ecommendation systems are also known as <strong>recommender systems</strong></span>.</li>
<li>Learning by example—understand (with screenshots) that Amazon's <span>on-site recommendations are double-edged; they enhance </span>customer satisfaction and ramp up sales revenue for Amazon.</li>
<li><span>Given the plethora of product choices on offer on an online store, customers need all the help they can get. In this chapter, we will learn that recommendations can help people make these choices better and faster. This is good for customers and good for an online retailer that wants to convert prospects to clients.</span></li>
<li>The next tangible learning objective is understanding which types of recommendations are implicit and which ones are not. </li>
<li>Learning about the different kinds of recommendations and what they can do is good. We want to go further by learning what kinds of data do not need many details. Why? We want to set up datasets to model a recommendation system and match this dataset with a suitable algorithm that only needs a relationship between users and products. Nothing more, nothing less. Such an algorithm that fits the bill is the collaborative filtering algorithm.</li>
<li><span>What collaborative filtering can achieve is a work in progress. We will only learn more about the algorithm if we create custom datasets, build a collaborative filtering algorithm trained on the data, and see what the outcome is.</span></li>
</ul>
<p>We will learn how to leverage the <span>model-based collaborative filtering algorithm provided by </span>Spark ML to build a r<span>ecommendation system. </span>We will learn that our implemented recommendation system, like others in its class, helps recommend products based on other customers preferences.</p>
<p>We will start with the <em>Problem overviews</em> section. </p>
<p>In this chapter we will cover the following topics:</p>
<ul>
<li class="h1">Problem overviews</li>
<li class="h1">Detailed overview</li>
<li class="h1">Implementation and deployment</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Problem overviews</h1>
                </header>
            
            <article>
                
<p>We will organize this section into overviews on select topics in a sequential order. Here are the topics we are going to cover:</p>
<ul>
<li>Recommendations on Amazon </li>
<li>Recommendation systems, also known as recommender systems or recommendation engines</li>
<li>Categorizing recommendations, such as:</li>
<li style="padding-left: 30px">Implicit recommendations </li>
<li style="padding-left: 30px">Explicit recommendations </li>
</ul>
<ul>
<li>Recommendations for machine learning</li>
<li>Problem formulation for explicit recommendations—the details</li>
<li><span>Weapon sales leads and past sales data—the details</span></li>
</ul>
<p><span> Each topic will be reviewed with an explanation. We will start with the first topic—<em>Recommendations on Amazon</em></span>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Recommendations on Amazon</h1>
                </header>
            
            <article>
                
<p>This topic is presented in two parts—a <em>Brief overview</em> and a <em>Detailed overview</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Brief overview</h1>
                </header>
            
            <article>
                
<p>This topic <span>(details are laid out in the <em>Detailed overview</em> section) will lay out a roadmap, starting with a generalized understanding of recommendations from a non-machine learning perspective. We will show you what recommendations on Amazon look like with supporting illustrations. Not only that, we will highlight the fact that powerful machine learning algorithms power Amazon's recommendation systems to help users make products choices more easily. </span></p>
<p><span>The brief overview of this topic is behind us now. Its detailed overview follows. </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Detailed overview</h1>
                </header>
            
            <article>
                
<p>To build a recommendation system, the approach we must take focuses on understanding recommendations at a conceptual level. Examples of questions providing insights into recommendations are as follows:</p>
<ul>
<li>What are the recommendations?</li>
<li>What are two important recommendation types?</li>
</ul>
<p class="mce-root"/>
<p>Whether you are an online retailer looking to make a recommendation engine work for you in profitable ways, or someone exploring Spark ML's powerful recommendation algorithms from up close, this section will get you started.</p>
<p><span>We will then zero in on suitable machine learning techniques that we can leverage to build a recommendation system.</span></p>
<p>Jeff Bezos, multi-billion dollar business, <a href="http://Amazon.com">Amazon.com</a>, continues to report healthy sales numbers. Recommendation systems have always facilitated increasing streams of revenue for Amazon. These systems are backed by<span> </span><span>machine learning recommendation algorithms that help deliver customer-specific recommendations in real time. Without question, recommendations are an </span>integral part of the Amazon landscape, playing a part in every aspect of a customer's purchase process.<span> </span></p>
<p>There are two categories of Amazon recommendations:</p>
<ul>
<li>On-site recommendations</li>
<li>Off-site recommendations</li>
</ul>
<p>We will only focus on on-site recommendations. Both on-site and off-site recommendations are big revenue earners for Amazon. Off-site recommendations are not covered in this chapter, however, the reader is encouraged to probe this side of Amazon's recommendations landscape. We have a question or two regarding off-site recommendations in the very last section of this chapter. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">On-site recommendations</h1>
                </header>
            
            <article>
                
<p>Two main flavors of on-site recommendations are readily available by simply clicking on the link <span class="packt_screen">XYZ's Amazon.com</span>. These are:</p>
<ul>
<li><strong><span>Recommended for you, XYZ</span></strong>:</li>
</ul>
<p style="padding-left: 60px">The <span class="packt_screen">Recommended for you</span><strong><span class="packt_screen">,</span></strong> <strong>XYZ</strong> link looks like this:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/3a9f5769-066b-4049-9138-054da4120fef.jpg"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Observe the Recommended for you, XYZ link</div>
<p style="padding-left: 60px"><span>It contains Amazon's recommendations of products that it thinks you are likely to click on and buy. How did these recommendations come to you? This question has a two-part answer. First, recommendation algorithms tracked your browsing history. Secondly, this will take you to a page showing a list of products from various categories. </span></p>
<ul>
<li><strong>Your recently viewed items and featured recommendations</strong>:</li>
</ul>
<p style="padding-left: 60px">Another related example of recommendations is shown as follows. These recommendations, according to Amazon's machine learning recommendations system, are in several categories, such as:</p>
<ul>
<li><strong>Inspired by your browsing history</strong>:</li>
</ul>
<p style="padding-left: 60px">The following page is reflective of the <span class="packt_screen">Inspired by your browsing history</span> type of recommendations. We can see the power of Amazon's recommendation systems at work:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/e0ca6623-ec07-4e2c-a427-7a3681c16b36.jpg"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Observe the items under Inspired by your browsing history link</div>
<ul>
<li><strong>Inspired by your purchases</strong>:</li>
</ul>
<p style="padding-left: 60px">Once again, the goal is simple—place a palette of products in front of the customer. This makes it easy for the customer to buy a different product, in this case, a book that is closely related to books falling under a category of interest. How did Amazon come up with the palette of books under the <span class="packt_screen">Inspired by your browsing history</span> category? The recommendation system brings you products that you showed an interest in, at some point in time:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/61bce2f3-3e11-49ae-bfb1-1f8bc7a561f8.jpg"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Observe the items under </span><span>Inspired by your purchases link</span></div>
<ul>
<li><strong>Frequently bought together</strong>:</li>
</ul>
<p style="padding-left: 60px"><span>This type of recommendation is even more interesting. Say you click on the </span><em>Lego Mindstorms</em><span> book, the one featured in the following screenshot. We are taken to a new page that has <strong>Frequently bought together</strong> recommendation.</span></p>
<p style="padding-left: 60px">The following screenshot displays the <span class="packt_screen">Frequently bought together</span> recommendation:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c5ee1f36-d976-49cd-a41b-a9ec8311184c.jpg"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Observe the Frequently bought together link</div>
<ul>
<li><strong>Customers who also bought this item</strong>:</li>
</ul>
<p style="padding-left: 60px">This type of recommendation is Amazon's up-sell and cross-sell recommendation feature at work. The recommendation system is offering products that other customers bought together when they clicked on the <em>Lego Mindstorm</em> book you just clicked:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/6172b4f2-1ddf-4167-8ff5-5250c21d16ce.jpg"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Observe the items under Customer who bought this item also bought link</div>
<p class="mce-root"/>
<p>The next <em>Problem overviews</em> section that follows is <em>Recommendations with machine learning</em>. Recommendations on Amazon are tied to powerful machine learning-based recommendation systems. The topic that follows is an attempt at describing a recommendation system from a high-level, non-machine learning perspective. Therefore, we want to know what a recommendations system looks like at a high-level and the different types of recommendations that such a system may or may not handle. </p>
<p>Attaining this level of understanding of recommendations, and recommendation systems will pave the way for a further exploration into the realm of recommendations as a problem in some subset of the machine learning space.</p>
<p>All the flavors of recommendation share the following goals:</p>
<ul>
<li>Customer satisfaction</li>
<li>Increasing sales revenue for Amazon</li>
</ul>
<p><span>We will take up each recommendation flavor in turn. We will take up the most important on-site recommendation first, which is the</span> <strong>Recommended for you, XYZ</strong> page.</p>
<p>That said, we will step into the next topic, <em>Recommendation systems</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Recommendation systems</h1>
                </header>
            
            <article>
                
<p>In the previous overview topic, we explored the salient aspects of recommendation and recommendation systems at Amazon. Let's attempt to bring some of that together and put together a definition of recommendation systems.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Definition</h1>
                </header>
            
            <article>
                
<p>Recommendation systems can be defined as software applications that draw out and learn from data like such as preferences, their actions (clicks, for example), browsing history, and generated recommendations, which are products that the system determines are appealing to the user in the immediate future.</p>
<p>The following diagram is representative of a typical recommendation system:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/e61fff20-b59d-49d3-9a25-0980d2c2d1de.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Recommendation system</div>
<p>In the preceding diagram, can be thought of as a recommendation ecosystem, where the recommendation system is at the heart of it. This system needs three entities:</p>
<ul>
<li><strong>Users</strong></li>
<li><strong>Products</strong></li>
<li><strong>Transactions between users and products where transactions contain feedback from users about products</strong></li>
</ul>
<p>A transaction can be thought of in terms of the following action—a user provides a rating for a product. That is not all, though. The nature of the transaction implies that the user is providing feedback about the product(s). This explains the solid arrow starting from the <strong>Users</strong> box and extending into the <strong>Products</strong> box. As is evident from the diagram, the <strong>Recommendations system</strong> generates a recommendation after collecting all of the user-product interactions, that is, feedback data. </p>
<p>There are different types of transactions, which brings us to look at the different types of recommendations. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Categorizing recommendations</h1>
                </header>
            
            <article>
                
<p><span>This topic </span><span>will draw on from the previous topic. In particular, we made more than a mention of user-product interactions or feedback data. Indeed, there can be two types of such interactions. User feedback is a better term.</span></p>
<p>Based on the types of user feedback, we can identify two types of recommendations, as follows:</p>
<ul>
<li>Implicit</li>
<li>Explicit</li>
</ul>
<p>Each type of recommendation follows. We will first explain recommendations using feedback of the implicit kind. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implicit recommendations</h1>
                </header>
            
            <article>
                
<p><span>A good example of such data is implicit information, such as </span><span>user preferences, their clicks, browsing history, purchase history, search terms, and so on.</span></p>
<p>This scenario represents an example of an implicit feedback-based recommendation system at work. The key characteristic of such a system is this—what did the user do? Some examples of implicit user feedback, in reference to a user on Amazon, is—what did the user buy? What book did they click on? What was their search phrase? All of these questions bear answers that reflect on a user's<span> </span><strong>behavior</strong>. That said, we will get right down to a problem formulation phase, where we will document what is needed to build a recommendation problem with collaborative filtering. Whether this recommendation system is implicit or explicit will be decided when we get to that point.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Explicit recommendations</h1>
                </header>
            
            <article>
                
<p>This is a collaborative filtering problem that requires explicit data to model the relationship between each user (customer) and product (item). A good example of such data is an explicit rating.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Recommendations for machine learning</h1>
                </header>
            
            <article>
                
<p><span>We discussed the role played by recommendations at Amazon. This gives us a good idea of what recommendations are, and what recommendation systems are, from a layperson's point of view. We provided examples for each flavor of recommendations. Machine learning algorithms generated these Amazon recommendations, and that is the common denominator here.</span></p>
<p><span>With that said, this topic is presented with the clear purpose of explaining the role played by machine learning in the context of recommendations. As always, this topic is approached in two parts: a brief overview part giving a summarized view of what to expect from the topic, and a detailed overview part. Here is the brief overview.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Collaborative filtering algorithms</h1>
                </header>
            
            <article>
                
<p>Recommendations are a collaborative filtering problem in the machine learning space. Two underlying principles define how collaborative filtering algorithms work:</p>
<ul>
<li>Filtering</li>
<li>Collaborative</li>
</ul>
<p>The filtering part is associated with the act of recommending. The algorithm makes recommendations happen by ingesting preferences information from many users.<span> </span><span>A simple example will go a long way in illustrating how c</span><span>ollaborative filtering algorithms work. </span>Imagine that our algorithm is working off of a pool of three users (countries) <em>U1</em>, <em>U2</em>, and <em>U3</em>. However trivial this case may be, it will explain how collaborative filtering algorithms work. Say, at a recent global air show, countries looking for new fighter aircraft were asked to provide ratings for three front-line fighter aircraft. The <strong>Rafaele</strong> is a French fighter. The <strong>SU-35</strong> is Russian and the <strong>F-35</strong> is American, and arguably the world's foremost air-superiority fighter.</p>
<p>The aircraft-countries tables are listed as follows, which is a recommendation algorithm based on collaborative filtering and a u<span>ser-product matrix:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/20ebd7bd-1129-40ff-8920-e4a5da7230ca.jpg" style="width:40.58em;height:21.92em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">User-product matrix</div>
<p>Looking at the preceding table, each country rated a certain aircraft in slightly different ways. India gave all three fighter aircraft reasonably good ratings, with the Flanker receiving the highest rating. The second country, Turkey, assigned good ratings only to the Rafaele and the F-35, and no rating at all for the SU-35. It is assumed that when no rating is provided that that country received a negative rating of –1. Lastly, Saudi Arabia liked the Rafaele and F-35, whereas they did not have anything to say about the SU-35. There are empty squares in the matrix. They are left empty for a reason. </p>
<p><span>Let's say we have a collaborative algorithm called <strong>CF</strong>. We want CF to work on this matrix with a plan. The first part of the plan is to tell the algorithm to find out which users like the same products. The algorithm will get to work and make the following observations:</span></p>
<ul>
<li>User U1 (India) liked the following:</li>
<li style="padding-left: 30px">Product 1 (Rafaele)</li>
<li style="padding-left: 30px">Product 2 (Flanker)</li>
<li style="padding-left: 30px">Product 3 (F-35)</li>
</ul>
<ul>
<li>User U2 (Turkey) liked the following:</li>
<li style="padding-left: 30px">Product 1 (Rafaele)</li>
<li style="padding-left: 30px">Product 3 (F-35)</li>
</ul>
<ul>
<li>User U3 (Saudi Arabia) liked the following:</li>
<li style="padding-left: 60px">Product 1 (Rafaele)</li>
</ul>
<p>The algorithm has a greater mandate. It needs to look closer at the matrix and make a recommendation for Saudi Arabia regarding an aircraft.</p>
<p>The collaborative filtering algorithm comes up with a recommendation for Saudi Arabia with the following reasoning:</p>
<p>India likes all three aircraft (the Rafaele, the Flanker, and the F-35) while Turkey like two (the Rafaele and the F-35). Countries that liked the Rafaele <strong>ALSO</strong> liked the F-35. Note the capitalized word ALSO. Based on India and Turkey having similar likes, the algorithm decides that Saudi Arabia will like what India and Turkey liked—<span>in this case,</span> the F-35. To make sense of the final recommendation, we will draw a Venn diagram-like structure:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/69c584e6-1765-45d2-92e8-6c6881abf1e0.png" style="width:28.67em;height:26.75em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Venn diagram</div>
<p>We just demonstrated what recommendations can do for us. What we have done so far is a step in the right direction regarding implementation. </p>
<p>We have not said yet what kind of data that's available in these datasets would either qualify them as explicit or implicit. Data in these datasets describe interactions between users and products. We have seen evidence of those interactions from the preceding discussion. We also went so far as to make a recommendation for Saudi Arabia. We predicted what weapons system Saudi Arabia is likely to buy in the future. The user-product matrix was our go-to resource for arriving at this recommendation for Saudi Arabia. This matrix boasted of one feature—a user-product interaction. This is a hard number, and a rating, which makes this data explicit. </p>
<p><span>This is a collaborative filtering problem that requires implicit data to model the relationship between each user (customer) and product (item). </span></p>
<p><span>It's time to move on to the next topic, which happens to be a brief overview of the formulation of an explicit recommendations problem.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Recommendations problem formulation</h1>
                </header>
            
            <article>
                
<p>This topic<span>, as its title suggests, will provide a (recommendation) problem formulation. In other words, it would build the contours of a recommendation system based on </span>explicit (user) feedback.</p>
<p><span>The problem formulation topic represents a critical stage in the implementation of one type of recommendation system. Coming up next is a topic that deals with weapons sales lead data and past weapons sales data, respectively.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding datasets</h1>
                </header>
            
            <article>
                
<p><span>Taking off from where the previous topic left us, this important talk proposes two datasets, a weapon sales leads dataset and a past sales data dataset, respectively.</span></p>
<p>At this point, we are done with the brief overview of topics we want to cover, which we decided are relevant toward the implementation of a recommendation system.</p>
<p class="mce-root"/>
<p><span>Thus far, we have given overviews of topics that are essential to the implementation of a recommendations system. These topics were as follows:</span></p>
<ul>
<li><span>Recommendations</span></li>
<li><span>I</span><span>mplicit recommendations</span></li>
<li><span>E</span><span>xplicit recommendations</span></li>
<li><span>Recommendation p</span><span>roblem formulation </span></li>
<li><span>Weapon sales leads and past sales data</span></li>
<li><span>Recommendations and ML</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Detailed overview</h1>
                </header>
            
            <article>
                
<p>The detailed overview section for this topic is the most important section of this chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Recommendations regarding problem formulation</h1>
                </header>
            
            <article>
                
<p>In the detailed version of this topic, we will build a narrative (or story), in which the following features dominate:</p>
<ul>
<li>Users</li>
<li>Products</li>
<li>Understanding of sales leads and past sales</li>
<li>Backing up data that's been built with an understanding of sales leads and past sales</li>
</ul>
<p><span>Where </span>data is concerned, we will compile custom sales leads data and past sales data that is related to weapons systems. In this phase, we will take up the formal formulation and support descriptions of a <span>recommendation system based on explicit feedback from users. Such a formulation is broken down into two tasks:</span></p>
<ul>
<li><span>Defining what explicit feedback is</span></li>
<li><span>Building a narrative (a story) around the recommendation problem involving explicit feedback</span></li>
</ul>
<p><span>What kinds of data constitutes explicit feedback? We set out to answer this question right away.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Defining explicit feedback</h1>
                </header>
            
            <article>
                
<p>Explicit feedback, like its implicit counterpart, depends on user preferences. The machine learning model we will be building later is based on such explicit feedback. The datasets we are about to describe contains explicit feedback. Such explicit feedback data is a compilation of user/customer/client preferences concerning their choice of some weapon system (the product/item). It turns out that we are building a recommendation system that will predict what ratings users might leave for products they loved (or not). Indeed, ratings are a great example of feedback. We are all familiar with what star ratings look like. We generated the following start rating graphic using a little CSS and HTML. This is similar to a <strong>Star Rating</strong> seen on restaurant portal <a href="https://www.yelp.com/">yelp.com</a>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/8637f5a4-a8e1-4a96-898c-ee8920e9532f.jpg" style="width:12.33em;height:5.33em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Restaurant ratings</div>
<p>We will not actually generate a star rating graphic for the impending explicit feedback-based recommendation system. However, the point here is that ratings have a central place in this chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a narrative</h1>
                </header>
            
            <article>
                
<p><span>Weapons maker X is a weapons manufacturer that caters to the defense needs of client nations across the globe. To us, this weapons maker is simply</span> <strong>WMX</strong><span>. Government customer IEX is a typical WMX customer, identified simply as IEX. I</span><span>EX wants to phase out its aging fighter aircraft with modern fifth-generation replacements</span><span>. </span><span>IEX figures are prominently on WMX's past sales data records. Therefore, WMX views IEX as more than just a prospective client. In this scenario, two kinds of actors are evident:</span></p>
<ul>
<li><span>WMX—supplier of weapons systems p</span>roducts</li>
<li>Customers like IEX—these are <span>countries that buy X's weapons systems and</span> allocate ratings to them</li>
</ul>
<p class="mce-root"/>
<p><span>We now have the contours of an interesting use case. Actors 1 and 2 are useless without data. We plan on making two datasets available:</span></p>
<ul>
<li><span>Weapon sales leads—data from a leads campaign</span></li>
<li><span>Past weapon sales data—data from the past describing which customer purchased what weapons system (the item or product) </span></li>
</ul>
<p>Before proceeding further with a deeper discussion on the later use case, we will take a necessary detour. We want to explain the sales leads part in weapon sales leads. What are leads, anyway? What is the role of past sales data? Both questions are answered in the next phase.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sales leads and past sales</h1>
                </header>
            
            <article>
                
<p>A business needs a product or products (or services) to sell and make money, of course. A familiar business strategy is a practice of generating sales leads. What is a sales lead? A <strong>lead</strong> is like a clue or a break that investigators stumble upon in a criminal investigation case. This lead is identifying the helpful information that may lead investigators to pursue a certain line of investigation. Such a lead, in the hands of a skilled, seasoned investigator might help potentially crack the case, nailing the culprit, or getting a fix on a potential suspect.</p>
<p>Applying the criminal investigation analogy back to our sales use case, a sales lead is a sort of identifier in the sense that it represents identifying data early on in the sales process. Naturally, a lead generates the anticipation that a certain person or company will be a potential client down the road. A sales lead does not necessarily have to nail down a potential customer. However, a well-planned sales lead generation campaign can take advantage of “past sales data” to help the business identify a person or other business as a near or long-term prospect. A paying customer that shows up in past sales data <span>may point to a future prospective client, which may be a repeat paying customer. Therefore, the </span>business is not shooting in the dark, as it can use this information to figure out which customer to reach out to. </p>
<p><span>Our detour ends here. Moving into the next phase, we will apply our recently acquired knowledge of sales leads and past sales data to actual weapon sales leads and past sales data datasets.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Weapon sales leads and past sales data</h1>
                </header>
            
            <article>
                
<p>To get started, download the following files <span>from the <kbd>ModernScalaProjects</kbd> folder.</span></p>
<ul>
<li><kbd>PastWeaponSalesOrders.csv</kbd>, compiled from scratch, requiring no citation</li>
<li><kbd>WeaponSalesLeads.csv</kbd>, <span>compiled from scratch, requiring no citation</span></li>
</ul>
<p><kbd>PastWeaponSalesOrders.csv</kbd> is representative of WMX's past weapons sales data, while <kbd>WeaponSalesLeads.csv</kbd> of WMX weapons sales leads data. Both datasets are designed to build a recommendation engine.</p>
<p>Let's assume that our weapons corporation WMX stores its past sales data records in <span><kbd>PastWeaponSalesOrders.csv</kbd>. </span>This dataset's records are depicted as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/2de5d1a3-22c4-4e97-ad0e-a0c1e4abf794.jpg" style="width:47.33em;height:26.92em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Past sales data records</div>
<p>Before we get into a description of data in the fields, we need a schema that is representative of the fields in this dataset:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/2b88397e-494c-4eb3-b2e0-4f855bae3a1c.jpg" style="width:29.83em;height:11.25em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Representation of the field in dataset</div>
<p><span>Seven columns exist, of which the first two columns represent customer data.</span> <span>Eight</span> customers are listed in alphabetical order, as follows:</p>
<ol>
<li><strong>Australia</strong>—Customer #1</li>
<li><strong>Seychelles</strong>—Customer #2</li>
<li><strong>Fiji</strong>—Customer #3</li>
<li><strong>Turkey</strong>—Customer #4</li>
<li><strong>Jordan</strong>—Customer #5</li>
<li><strong>South Korea</strong>—Customer #6</li>
<li><strong>Djibouti</strong>—Customer #7</li>
<li><strong>India</strong>—Customer #8</li>
</ol>
<p><span>The next two columns,</span> <strong>ItemId</strong><span>, followed by</span> <strong>ItemName</strong><span>, represent a weapons system. The fifth column stores the price in millions of dollars per weapons system unit. Each cell of data in the sixth <strong>OrderSize</strong> column represents the number of units of a certain weapons system ordered by a certain customer. For example, Australia had, sometime in the past, ordered 25 units of</span> <strong>WeaponsSystem217</strong> <span>at a price of 2 million dollars per unit.</span></p>
<p><span>While both datasets are by no means comprehensive, they are a representative sampling, which is enough to create our recommendation system.</span></p>
<p>In our case, we are building a sample sales lead prediction model based on past sales orders.</p>
<p>Here are few sample records from both datasets:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/2f7a3730-cbfe-4cc5-bd0d-3e97b8fd0ce6.jpg" style="width:24.75em;height:26.33em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Sample datasets</div>
<p>Both datasets are ready. We want to know what to make of this data and where to go from here. We set about putting together the data with one immediate goal—creating a model that would somehow help us make predictions. That goal wasn't so clear-cut then. Now that we have two datasets, we want a clear goal. The key lies in the weapons sales leads dataset. What if we want to build a weapons sales lead model drawing on data from purchase history? Our past weapons sales dataset represents that purchase history. That then brings us to a sharper goal implementing a weapons sales prediction rating model. In other words, we want our model to do the following:</p>
<ul>
<li>Predict what recommendation to make for each customer. There are 8 customers, ranging from Australia to India. We want our model to only recommend a weapons system that is right for a certain customer. The right weapons system for a customer is based on what they ordered in the past. </li>
<li>In making a recommendation to each customer, the model is also producing a rating that it believes the customer would give a certain product he/she did not purchase before a new product or products.</li>
</ul>
<p class="mce-root"/>
<p>Let's reiterate what both datasets have in common. The first is simple—there's a customer, which in this case is a nation. Then, there is a product an (item), which in this case is a weapons system. The first dataset has this much to say:</p>
<ul>
<li>There is a nation that ordered a certain number of weapons systems, each such system costing a certain unit price in millions of dollars.</li>
<li>The second dataset doesn't reveal much beyond its stated brief, which is to provide a listing of potential prospects. The company manufacturing these systems decides that some of these prospects are more than prospects. </li>
</ul>
<p>The point we are trying to make here is that even though it is not that apparent, it is clear now that the data did not have to reveal many details. The customer is a nation that purchased a certain weapons system at a certain price. That's it, but that's enough. On the other hand, the weapons sales lead data tells a different kind of story, a likely scenario of a future scenario, where a certain company, in the company's estimates, is said to be likely to show interest in a certain type of weapons system.</p>
<p>We have data about users and products. Not detailed information, but apparently enough. This kind of data requires an algorithm that only needs to extract the relationship between users and products. It simply needs to see evidence of an interaction between the two. Both datasets at hand appear to be a fit for a collaborative filtering algorithm. That is why we can, in the next section, initiate a discussion on the basic mechanism driving the workings of a collaborative filtering algorithm.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation and deployment </h1>
                </header>
            
            <article>
                
<p class="mce-root">The following are implementation objectives that are required to implement the recommendations system:</p>
<ol>
<li class="mce-root">Download the past weapons sales order and weapon lead sales datasets from the <kbd>ModernScalaProjects</kbd> data folder.</li>
<li class="mce-root">You may develop the pipeline in three ways:
<ul>
<li class="mce-root">Incrementally in your local Spark Shell.</li>
<li class="mce-root">Recommended: <span>Flesh out your code in IntelliJ and wire up all necessary dependencies in the <kbd>build.sbt</kbd> file. Set SBT up to generate a fat JAR by wiring in an assembly plugin. The resultant </span>self-contained SBT application is then deployed to your local spark cluster using <kbd>spark-submit</kbd>.</li>
<li class="mce-root">Run the application and interpret the results.</li>
</ul>
</li>
</ol>
<ol start="3">
<li class="mce-root">In the next section, <em>Implementation</em>, we will document step-by-step instructions for implementing the project. </li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation</h1>
                </header>
            
            <article>
                
<p>Implementation is documented in the following subsections. All code is developed in an Intellij code editor. The very first step is to create an empty Scala project called <kbd>Chapter7</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 1 – creating the Scala project</h1>
                </header>
            
            <article>
                
<p>Let's create a Scala project called <kbd>Chapter7</kbd> with the following artifacts:</p>
<ul>
<li class="mce-root"><kbd>RecommendationSystem.scala</kbd></li>
<li class="mce-root"><kbd>RecommendationWrapper.scala</kbd></li>
</ul>
<p>Let's break down the project's structure:</p>
<ul>
<li class="mce-root"><kbd>.idea</kbd>: Generated IntelliJ configuration files.</li>
<li class="mce-root"><kbd>project</kbd>: Contains <kbd>build.properties</kbd> and <kbd>plugins.sbt</kbd>.</li>
<li class="mce-root"><kbd>project</kbd>/<kbd>assembly.sbt</kbd>: This file specifies the <kbd>sbt-assembly</kbd> plugin needed to build a fat JAR for deployment.</li>
<li class="mce-root"><kbd>src/main/scala</kbd>: This is a folder that houses Scala source files in the <kbd>com.packt.modern.chapter7</kbd> package.</li>
<li class="mce-root"><kbd>target</kbd>: This is where artifacts of the compile process are stored. The generated assembly JAR file goes here.</li>
<li class="mce-root"><kbd>build.sbt</kbd>: This is the main SBT configuration file. Spark and its dependencies are specified here.</li>
</ul>
<p>At this point, we will start developing code in the IntelliJ code editor. We will start with the <kbd>AirlineWrapper</kbd> Scala file and end with the deployment of the final application JAR into Spark with <kbd>spark-submit</kbd>. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 2 – creating the AirlineWrapper definition</h1>
                </header>
            
            <article>
                
<p>Let's create the <kbd>trait</kbd> definition. The trait will hold the <kbd>SparkSession</kbd> variable, schema definitions for the datasets, and methods to build a dataframe:</p>
<pre><span>trait </span>RecWrapper {  }</pre>
<p>Next, let's create a schema for past weapon sales orders.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 3 – creating a weapon sales orders schema</h1>
                </header>
            
            <article>
                
<p>Let's create a schema for the past sales order dataset:</p>
<pre><span>val </span><span>salesOrderSchema</span>: StructType = StructType(<span>Array</span>(<br/>  <span>StructField</span>(<span>"sCustomerId"</span>, IntegerType,<span>false</span>),<br/>  <span>StructField</span>(<span>"sCustomerName"</span>, StringType,<span>false</span>),<br/>  <span>StructField</span>(<span>"sItemId"</span>, IntegerType,<span>true</span>),<br/>  <span>StructField</span>(<span>"sItemName"</span>,  StringType,<span>true</span>),<br/>  <span>StructField</span>(<span>"sItemUnitPrice"</span>,DoubleType,<span>true</span>),<br/>  <span>StructField</span>(<span>"sOrderSize"</span>, DoubleType,<span>true</span>),<br/>  <span>StructField</span>(<span>"sAmountPaid"</span>,  DoubleType,<span>true</span>)<br/>))</pre>
<p>Next, let's create a schema for weapon sales leads.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 4 – creating a weapon sales leads schema</h1>
                </header>
            
            <article>
                
<p>Here is a schema definition for the weapon sales lead dataset:</p>
<pre><span>val </span><span>salesLeadSchema</span>: StructType = StructType(<span>Array</span>(<br/>  <span>StructField</span>(<span>"sCustomerId"</span>, IntegerType,<span>false</span>),<br/>  <span>StructField</span>(<span>"sCustomerName"</span>, StringType,<span>false</span>),<br/>  <span>StructField</span>(<span>"sItemId"</span>, IntegerType,<span>true</span>),<br/>  <span>StructField</span>(<span>"sItemName"</span>,  StringType,<span>true</span>)<br/>))</pre>
<p>Next, let's build a weapon sales order dataframe.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 5 – building a weapon sales order dataframe</h1>
                </header>
            
            <article>
                
<p>Let's invoke the <kbd>read</kbd> method on our <kbd>SparkSession</kbd> instance and <kbd>cache</kbd> it. We will call this method later from the <kbd>RecSystem</kbd> object: </p>
<pre><span>def </span>buildSalesOrders(dataSet: <span>String</span>): <span>DataFrame </span>= {<br/>  <span>session</span>.read<br/>    .format(<span>"com.databricks.spark.csv"</span>)<br/>    .option(<span>"header"</span>, <span>true</span>).schema(<span>salesOrderSchema</span>).option(<span>"nullValue"</span>, <span>""</span>)<br/>    .option(<span>"treatEmptyValuesAsNulls"</span>, <span>"true"</span>)<br/>    .load(dataSet).cache()<br/>}</pre>
<p><span>Next up, let's build a sales leads dataframe:</span></p>
<pre><span>def </span>buildSalesLeads(dataSet: <span>String</span>): <span>DataFrame </span>= {<br/>  <span>session</span>.read<br/>    .format(<span>"com.databricks.spark.csv"</span>)<br/>    .option(<span>"header"</span>, <span>true</span>).schema(<span>salesLeadSchema</span>).option(<span>"nullValue"</span>, <span>""</span>)<br/>    .option(<span>"treatEmptyValuesAsNulls"</span>, <span>"true"</span>)<br/>    .load(dataSet).cache()<br/>}</pre>
<p>This completes the <kbd>trait</kbd>. Overall, it looks like this:</p>
<pre><span>trait </span>RecWrapper {<br/><br/>   1) Create a lazy SparkSession instance and call it session.<br/>   2) Create a schema for the past sales orders dataset<br/>   3) Create a schema for sales lead dataset<br/>   4) Write a method to create a dataframe that holds past sales order            <br/>      data. This method takes in sales order dataset and <br/>      returns a dataframe<br/>   5) Write a method to create a dataframe that holds lead sales data<br/><br/>}</pre>
<p>Bring in the following imports:</p>
<pre class="mce-root">import org.apache.spark.mllib.recommendation.{ALS, Rating}<br/>import org.apache.spark.rdd.RDD<br/>import org.apache.spark.sql.{DataFrame, Dataset, SparkSession}</pre>
<p class="mce-root">Create a Scala object called <kbd>RecSystem</kbd>:</p>
<pre class="mce-root">object RecSystem extends App with RecWrapper {   }</pre>
<p class="mce-root"/>
<p>Before going any further, bring in the following imports:</p>
<pre>import org.apache.spark.rdd.RDD<br/>import org.apache.spark.sql.DataFrame</pre>
<p class="mce-root">Inside this object, start by loading the past sales order data. This will be our training data. Load the sales order dataset, as follows:</p>
<pre class="mce-root"><span>val salesOrdersDf = buildSalesOrders("sales\\PastWeaponSalesOrders.csv")</span></pre>
<p class="mce-root">Verify the schema. This is what<span> the schema looks like:</span></p>
<pre class="mce-root">salesOrdersDf.printSchema()<br/><strong>root</strong><br/><strong> |-- sCustomerId: integer (nullable = true)</strong><br/><strong> |-- sCustomerName: string (nullable = true)</strong><br/><strong> |-- sItemId: integer (nullable = true)</strong><br/><strong> |-- sItemName: string (nullable = true)</strong><br/><strong> |-- sItemUnitPrice: double (nullable = true)</strong><br/><strong> |-- sOrderSize: double (nullable = true)</strong><br/><strong> |-- sAmountPaid: double (nullable = true)</strong></pre>
<p class="mce-root">Here is a partial view of a dataframe displaying past weapon sales order data:</p>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref"><img src="assets/7c435ac9-2ac8-49fc-9eae-a6f8a24af57f.jpg"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Partial view of dataframe displaying past weapon sales order data</div>
<p class="mce-root">Now, we have what we need to create a dataframe of ratings:</p>
<pre class="mce-root"> val ratingsDf: DataFrame = salesOrdersDf.map( salesOrder =&gt;<br/> Rating( salesOrder.getInt(0),<br/> salesOrder.getInt(2),<br/> salesOrder.getDouble(6)<br/> ) ).toDF("user", "item", "rating")</pre>
<p>Save all and compile the project at the command line:</p>
<pre><strong>C:\Path\To\Your\Project\Chapter7&gt;sbt compile</strong></pre>
<p class="mce-root"/>
<p>You are likely to run into the following error:</p>
<pre><strong>[error] C:\Path\To\Your\Project\Chapter7\src\main\scala\com\packt\modern\chapter7\RecSystem.scala:50:50: Unable to find encoder for type stored in a Dataset. Primitive types (Int, String, etc) and Product types (case classes) are supported by importing spark.implicits._ Support for serializing other types will be added in future releases.</strong><br/><strong>[error] val ratingsDf: DataFrame = salesOrdersDf.map( salesOrder =&gt;</strong><br/><strong>[error] ^</strong><br/><strong>[error] two errors found</strong><br/><strong>[error] (compile:compileIncremental) Compilation failed</strong></pre>
<p>To fix this, place the following statement at the top of the declarations of the rating dataframe. It should look like this:</p>
<pre><span>import </span><span>session</span>.implicits._<br/> <span>val </span><span>ratingsDf</span>: <span>DataFrame </span>= <span>salesOrdersDf</span>.map( salesOrder =&gt; <span>UserRating</span>( salesOrder.getInt(<span>0</span>), salesOrder.getInt(<span>2</span>), salesOrder.getDouble(<span>6</span>) ) ).toDF(<span>"user"</span>, <span>"item"</span>, <span>"rating"</span>)</pre>
<p>Save and recompile the project. This time, it compiles just fine. Next, import the <kbd>Rating</kbd> class from the <kbd>org.apache.spark.mllib.recommendation</kbd> package. This transforms the rating dataframe that we obtained previously to its RDD equivalent:</p>
<pre>val ratings: RDD[Rating] = ratingsDf.rdd.map( row =&gt; Rating( row.getInt(0), row.getInt(1), row.getDouble(2) ) )<br/> println("Ratings RDD is: " + ratings.take(10).mkString(" ") )</pre>
<p>The following few lines of code are very important. We will be using the ALS algorithm from Spark MLlib to create and train a <kbd>MatrixFactorizationModel</kbd>, which takes an <kbd>RDD[Rating]</kbd> object as input. The ALS train method may require a combination of the following training hyperparameters:</p>
<ul>
<li><kbd>numBlocks</kbd>: Preset to <kbd>-1</kbd> in an auto-configuration setting. This parameter is meant to parallelize computation. </li>
<li class="mce-root"><kbd>custRank</kbd>: The number of features, otherwise known as latent factors.</li>
<li class="mce-root"><kbd>iterations</kbd>: This parameter represents the number of iterations for ALS to execute. For a reasonable solution to converge on, this algorithm needs roughly 20 iterations or less.</li>
<li class="mce-root"><kbd>regParam</kbd>: The regularization parameter.</li>
<li class="mce-root"><kbd>implicitPrefs</kbd>: <span>T</span>his hyperparameter is a specifier. It lets us use either of the following:
<ul>
<li class="mce-root">Explicit feedback</li>
<li class="mce-root">Implicit feedback</li>
</ul>
</li>
<li class="mce-root"><kbd>alpha</kbd>: This is a hyperparameter connected to an implicit feedback variant of the ALS algorithm. Its role is to govern the baseline confidence in preference observations.</li>
</ul>
<p><span>We just explained the role played by each parameter needed by the ALS algorithm's train method.</span></p>
<p>Let's get started by bringing in the following imports:</p>
<pre class="mce-root">import org.apache.spark.mllib.recommendation.MatrixFactorizationModel</pre>
<p class="mce-root"><span>Now, let's get down to training the matrix factorization model using the ALS algorithm.  </span><br/>
Let's train a matrix factorization model given an RDD of ratings by customers (users) for certain items (products). Our train method on the ALS algorithm will take the following four parameters:</p>
<ul>
<li>Ratings.</li>
<li>A rank.</li>
<li>A number of iterations.</li>
<li>A Lambda value or regularization parameter:</li>
</ul>
<pre style="padding-left: 60px">val ratingsModel: MatrixFactorizationModel = ALS.train(ratings, <br/>   6, /* THE RANK */ <br/>  10, /* Number of iterations */<br/>  15.0 /* Lambda, or regularization parameter */<br/> )</pre>
<p>Next, we load the sales lead file and convert it into a tuple format:</p>
<pre class="mce-root"> val weaponSalesLeadDf = buildSalesLeads("sales\\ItemSalesLeads.csv") </pre>
<p>In the next section, we will display the new weapon sales lead dataframe.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 6 – displaying the weapons sales dataframe</h1>
                </header>
            
            <article>
                
<p>First, we must invoke the <kbd>show</kbd> method: </p>
<pre class="mce-root">println("Weapons Sales Lead dataframe is: ")<br/>weaponSalesLeadDf.show </pre>
<p>Here is a view of the weapon sales lead dataframe:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/45ba3943-ccd9-4196-8a5d-9227c6e27df6.jpg" style="width:32.83em;height:29.75em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">View of weapon sales lead dataframe</div>
<p class="mce-root">Next, create a version of the sales lead dataframe structured as (customer, item) tuples:</p>
<pre class="mce-root">val customerWeaponsSystemPairDf: DataFrame = weaponSalesLeadDf.map(salesLead =&gt; ( salesLead.getInt(0), salesLead.getInt(2) )).toDF("user","item")</pre>
<p>In the next section, let's display the dataframe that we just created.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 7 – displaying the customer-weapons-system dataframe</h1>
                </header>
            
            <article>
                
<p>Let's the <kbd>show</kbd> method, as follows:</p>
<pre class="mce-root">println("The Customer-Weapons System dataframe as tuple pairs looks like: ")<br/>customerWeaponsSystemPairDf.show </pre>
<p class="mce-root"/>
<p>Here is a screenshot of the new customer-weapons-system dataframe as tuple pairs:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/4567169f-8231-466d-aaea-bbb2932e1f14.jpg" style="width:35.92em;height:25.83em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>New customer-weapons-system dataframe as tuple pairs</span></div>
<p class="mce-root">Next, we will convert the preceding dataframe into an RDD:</p>
<pre class="mce-root"><span>val customerWeaponsSystemPairRDD: RDD[(Int, Int)] = customerWeaponsSystemDf.rdd.map(row =&gt; <br/>                                                               (row.getInt(0),          <br/>                                                                row.getInt(1)) <br/>                                                       )<br/>/*<br/>Notes: As far as the algorithm is concerned, customer corresponds to "user" and "product" or item corresponds to a "weapons system"<br/>*/</span></pre>
<p class="mce-root">We previously created a <kbd>MatrixFactorization</kbd> model that we trained with the weapons system sales orders dataset. We are in a position to predict how each customer country may rate a weapon system in the future. In the next section, we will generate predictions.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 8 – generating predictions</h1>
                </header>
            
            <article>
                
<p class="mce-root">Here is how we will generate predictions. The <kbd>predict</kbd> method of our model is designed to do just that. It will generate a predictions RDD that we call <kbd>weaponRecs</kbd>. It represents the ratings of weapons systems that were not rated by customer nations (listed in the past sales order data) previously:</p>
<pre class="mce-root"><span>val weaponRecs: RDD[Rating] = ratingsModel.predict(customerWeaponsSystemPairRDD).distinct()</span> </pre>
<p>Next up, we will display the final predictions. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 9 – displaying predictions</h1>
                </header>
            
            <article>
                
<p>Here is how to display the predictions, lined up in tabular format:</p>
<pre><span>println</span>(<span>"Future ratings are: " </span>+ <span>weaponRecs</span>.foreach(rating =&gt; { <span>println</span>( <span>"Customer: " </span>+ rating.user + <span>" Product:  " </span>+ rating.product + <span>" Rating: " </span>+ rating.rating ) } ) )</pre>
<p>The following table displays how each nation is expected to rate a certain system in the future, that is, a weapon system that they did not rate earlier:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/4ed1bc7d-c253-47dd-a12a-40468b258f5c.jpg" style="width:40.33em;height:22.83em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">System rating by each nation</div>
<p class="mce-root"/>
<p>Our recommendation system proved itself capable of generating future predictions.</p>
<p><span>Up until now, we did not say how all of the preceding code is compiled and deployed. We will look at this in the next section.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Compilation and deployment</h1>
                </header>
            
            <article>
                
<p>The steps regarding compilation and deployment are as follows:</p>
<ol>
<li>Compile</li>
<li>Build an assembly JAR file of the recommendation system application</li>
<li>Use the <kbd>spark-submit</kbd> command to deploy the recommendation system application</li>
</ol>
<p>We will compile the project first.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Compiling the project</h1>
                </header>
            
            <article>
                
<p>Invoke the <kbd>sbt compile</kbd> project at the root folder of your <kbd>Chapter7</kbd> project. You should get the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/35dfd742-8525-49cd-84c6-f70d67fa88d6.jpg"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Output on compiling the project</div>
<p>Besides loading <kbd>build.sbt</kbd>, the compile task is also loading settings from <kbd>assembly.sbt</kbd>, a file we have not talked about yet, but which we will create soon.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What is an assembly.sbt file?</h1>
                </header>
            
            <article>
                
<p>We have not yet talked <span>about the <kbd>assembly.sbt</kbd> file. </span>Our scala-based Spark application is a Spark job that will be submitted to a (local) Spark cluster as a JAR file. This file, apart from Spark libraries, also needs other dependencies in it for our recommendation system job to successfully complete. The name fat JAR is from all dependencies bundled in one JAR. To build such a fat JAR, we need an <kbd>sbt-assembly</kbd> plugin. This explains the need for creating a new <kbd>assembly.sbt</kbd> and the assembly plugin. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating assembly.sbt</h1>
                </header>
            
            <article>
                
<p><span>Create a new <kbd>assembly.sbt</kbd> in your IntelliJ project view and save it under your <kbd>project</kbd> folder, as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/411d8fd6-ef46-4460-b503-b51a66651f70.jpg" style="width:30.75em;height:12.75em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Creating assembly.sbt</div>
<p>What will <kbd>assembly.sbt</kbd> contain? We will explore this next.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Contents of assembly.sbt</h1>
                </header>
            
            <article>
                
<p>Paste the following contents into the <span>newly created </span><kbd>assembly.sbt</kbd> (under the project folder). The output should look like this:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/28902218-14be-4b75-aebf-e2b0879a9ff7.jpg" style="width:42.92em;height:2.42em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Output on placing contents of assembly.sbt</div>
<p>The <kbd>sbt-assembly</kbd> plugin, version 0.14.7, gives us the ability to run an <kbd>sbt-assembly</kbd> task. With that, we are one step closer to building a fat or Uber JAR. This action is documented in the next step.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the sbt assembly task</h1>
                </header>
            
            <article>
                
<p>Issue the <kbd>sbt assembly</kbd> command, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/746b947a-ac7a-4ee5-b873-6a5d21190903.jpg" style="width:43.00em;height:11.33em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Running the sbt assembly command</div>
<p><span>This time, the assembly task loads the assembly-plugin in <kbd>assembly.sbt</kbd>. However, further assembly halts because of a common duplicate error. This error arises due to several duplicates, multiple copies of dependency files that need removal before the assembly task can successfully complete. To address this situation, <kbd>build.sbt</kbd> needs an upgrade. </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Upgrading the build.sbt file</h1>
                </header>
            
            <article>
                
<p><span>The following lines of code need to be added in, as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/ee6e63fc-fa9c-45a7-bf8a-d1f84a1da6e5.jpg" style="width:43.25em;height:21.17em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Code lines for upgrading the build.sbt file</div>
<p>To test the effect of your changes, save this and go to the command line to reissue the <kbd>sbt assembly</kbd> task.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Rerunning the assembly command</h1>
                </header>
            
            <article>
                
<p>Run the assembly task, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/640a521c-e81b-4395-b123-7f583084f6ee.jpg" style="width:44.17em;height:11.25em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Rer<span>unning the </span>assembly<span> task</span></div>
<p><span>This time, the settings in the </span><span><kbd>assembly.sbt</kbd> file are loaded. The task completes successfully. To verify, drill down to the <kbd>target</kbd> folder. If everything went well, you should see a fat JAR, as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/790792c9-1c8a-4e73-a453-9dbd891f1461.jpg" style="width:20.50em;height:22.17em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Output as a JAR file</div>
<p>Our JAR file under the <kbd>target</kbd> folder is the recommendation system application's JAR file that needs to be deployed into Spark. This is documented in the next step.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deploying the recommendation application</h1>
                </header>
            
            <article>
                
<p>The <kbd>spark-submit</kbd> command is how we will deploy the application into Spark. Here are two formats for the <kbd>spark-submit</kbd> command. The first one is a long one which sets more parameters than the second one:</p>
<pre><strong>spark-submit --class "com.packt.modern.chapter7.RecSystem" --master local[2] --deploy-mode client --driver-memory 16g -num-executors 2 --executor-memory 2g --executor-cores 2  &lt;path-to-jar&gt;</strong></pre>
<p>Leaning on the preceding format, let's submit our Spark job, supplying various parameters to it:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/add330e9-f59e-4921-be71-832b45c3edc4.jpg"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Parameters for Spark  </div>
<p>The different parameters are explained as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/98043e56-0ea3-462b-9d98-be3567914ec3.jpg" style="width:27.08em;height:23.58em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">   Tabular explanation of parameters for Spark Job </div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>We learned how to build an explicit feedback type<span> recommendation system. We implemented a predictions model with the Spark MLlib collaborative filtering algorithm that learns from past sales data and makes ratings-based recommendations about products to customers. The algorithm, as we have come to know, made its tailored product predictions on unknown customer-product interactions. </span></p>
<p>We used Spark's support for recommendations to build a prediction model that generated recommendations for unknown customer-product interactions in terms of sales leads and past weapons sales data. We leveraged Spark's alternating least squares algorithm to implement our collaborative filtering recommendation system.</p>


            </article>

            
        </section>
    </body></html>