- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Beyond Code – Mastering Software Architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, everything should be crystal clear about why and how to constantly
    refactor your code; in general, why it’s important to have a clean, readable,
    and easily maintainable code base. But in today’s development world, it’s highly
    unlikely that we’ll have just one application, one component; it’s much more realistic
    to have various components interacting with each other. If it’s true, as it is,
    that according to Conway’s Law, a company is structured and organized in a way
    that mirrors its software systems, it’s crucial to have a cohesive yet scalable
    ecosystem – not just robust but resilient and, frequently mentioned, clean. Because
    even clean code can lead to epic disasters if interactions between various services
    are poorly managed.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll tackle the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is an architecture?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Architectural patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monolith to microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bad smells in the microservices architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is an architecture?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Having come this far, we’ve realized that writing code is just a small part
    of our job. We need to focus on writing code that not only works but is also easy
    to read and maintain. We’ve learned that there are many small adjustments we can
    make to make our work simpler and smoother. Now, let’s take a step back and think
    further: Is our job really only about code? Is writing good code (whatever that
    means) the only thing, even though it’s broad and complex, that we need to do
    well? If we’re asking this question, you can guess that the answer is: not at
    all! Just like in the movie *Ratatouille* where Chef Gusteau says, “*Anyone can
    cook*,” here, we can paraphrase his words and say that *anyone can code*. It takes
    a little, in fact, to learn to write some lines of Java code or maybe even in
    some other simpler language. In recent months, technologies related to **artificial
    intelligence** (**AI**) have exploded, which can literally write code for us.
    But what is really challenging is not just writing code or even pieces of software
    that work together but doing it well. As Robert C. Martin says, “*Getting software
    right* *is hard.*”'
  prefs: []
  type: TYPE_NORMAL
- en: Software architecture is like the blueprint for a software system. It’s the
    plan that outlines how different parts of the software work together. This involves
    making decisions about how to design things to meet specific goals. It includes
    elements such as the different pieces of software, how they connect to each other,
    and the rules for organizing them. So, software architecture is basically the
    high-level design that guides the creation of a software system.
  prefs: []
  type: TYPE_NORMAL
- en: 'The architecture of a software system is like the design or structure created
    by the people building it. It’s determined by how the system is divided into parts
    (components), how these parts are organized, and how they talk to each other.
    In simpler terms, it’s how the different pieces of the software are put together
    and work together. This is only one definition of architecture, shaped by the
    *Clean Architecture* book by Robert C. Martin. Reading Martin Fowler’s works,
    instead, gives us another (funnier) definition of what architecture is: the collective
    knowledge that experienced developers have about the design of a system and the
    set of decisions you hope to make correctly at the beginning of a project.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We hope it’s a bit clearer what we mean by software architecture, but maybe
    it will be even clearer when we’ve explained its goals. On goals, the ideas seem
    quite clear in literature: good architecture makes things work better. The reason
    for creating a good architecture is to make it easier to develop, deploy, operate,
    and maintain the software system it holds.'
  prefs: []
  type: TYPE_NORMAL
- en: Development
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As long as there’s a small, single team handling the entire project, people
    may think that architecture isn’t that important; in fact, it’s seen as almost
    an obstacle. This is why many projects, especially in the startup phase, often
    don’t have a proper architecture. However, as the project expands, rush to the
    rescue as soon as possible! In fact, it’s challenging to work with different teams
    on the same project, on the same module; it becomes necessary to divide the module
    itself into well-defined parts (“how” is a whole different story). Simply dividing
    the initial component into multiple components is not enough, though. It needs
    to be done carefully, understanding how these components will interact with each
    other. Otherwise, there’s a risk that from a single component, different ones
    may simply develop independently, each doing its own thing. And if everyone goes
    their own way, it’s difficult to work on new features or fix existing problems.
    If a software system is difficult to develop, it’s unlikely to have a long and
    healthy lifespan. Therefore, the system’s architecture should be designed to make
    development easy for the team or teams working on it.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Deployability** means how easily and reliably software can be set up and
    run in a reasonable amount of time (ideally, with a single click). If there’s
    a problem with the new setup, it should be possible to go back to the previous
    one without too much trouble. With the rise of virtualization and cloud systems,
    and as software systems get bigger, it’s the architect’s job to make sure setting
    up the software is done efficiently and predictably, reducing the overall risk
    for the system.'
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, many times, people don’t think about how to set up a system when
    they’re first building it. This can result in designs that make the system easy
    to create but really hard to get up and running.
  prefs: []
  type: TYPE_NORMAL
- en: For example, when starting to build a system, developers might opt for an architecture
    that includes a certain number of services and components. It might seem like
    a good idea for various reasons, such as smoother development and each piece working
    independently. However, during deployment, the team realizes that some of these
    services are interconnected and rely on each other to function properly. Deployment
    then becomes challenging, as you may need to deploy not only one service but also
    interconnected ones. If architects had considered the system setup from the beginning,
    they might have chosen fewer services, a combination of services and in-house
    components, and a more integrated approach to managing connections.
  prefs: []
  type: TYPE_NORMAL
- en: System operation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**System operation** involves the day-to-day management and execution of a
    computer system or software application. It includes tasks such as running the
    software, keeping an eye on its performance, applying updates and fixes, ensuring
    security, handling backups, assisting users, and addressing issues as they arise.
    Essentially, it’s the ongoing effort to keep the system running smoothly and meeting
    user needs.'
  prefs: []
  type: TYPE_NORMAL
- en: The influence of architecture on system operation is generally considered not
    as significant as its impact on development, deployment, and maintenance. Most
    operational challenges can be addressed by increasing the system’s hardware resources
    without causing major changes to the software architecture; this scenario is quite
    common. Inefficient software architectures can often be made to function effectively
    by merely adding more storage and servers. The affordability of hardware compared
    to the cost of human resources means that architectures causing obstacles in operation
    are not as expensive as those hindering development, deployment, and maintenance.
  prefs: []
  type: TYPE_NORMAL
- en: Just because the impact of bad architecture on operations is easily fixable
    doesn’t mean it’s not an important aspect. Even though the so-called “hardware”
    (which often translates to buying cloud computing services from companies such
    as **Amazon Web Services** (**AWS**), Google, or Microsoft) costs less than people
    and time, it doesn’t mean it’s inexpensive or an insignificant cost. An inefficient
    architecture that requires a disproportionate number of resources compared to
    the value it brings (whether economic or otherwise) should be a concern.
  prefs: []
  type: TYPE_NORMAL
- en: Maintenance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Software maintenance** refers to the ongoing process of managing and updating
    software to ensure it continues to meet the needs of users and remains effective
    over time. It involves making modifications, fixing bugs, improving performance,
    and adapting the software to changes in the environment or user requirements.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, we could make a direct comparison with the architecture of buildings
    to understand how it impacts the manageability of a project. Imagine two buildings,
    two residences: one very complicated and sophisticated, unique in its kind; it
    has special aesthetic and technological features created specifically for the
    occasion, refined materials, and unique solutions. The other building is a classic
    European apartment complex, with straight facades and identical windows, common
    and sturdy materials, very similar to others encountered before. In the case that
    I have to make a change or solve a problem, in which building do you think it
    would be easier to operate?'
  prefs: []
  type: TYPE_NORMAL
- en: Out of all the parts of a computer program, keeping it up and running is the
    most expensive. The constant need for new features and fixing mistakes takes a
    lot of time and effort from people. The main cost of keeping a program going comes
    from searching through the existing code and dealing with risks. Searching through
    the code, called **spelunking** by Robert C. Martin in his book *Clean Architecture*,
    takes time and money to figure out the best way to add something new or fix a
    mistake. When making these changes, there’s always a chance of accidentally causing
    new problems, which adds to the risk and cost.
  prefs: []
  type: TYPE_NORMAL
- en: Having a well-thought-out plan for how the program is set up can really help
    cut down on these costs. If the program is split into different parts and each
    part is kept separate through stable connections, it makes it much easier to add
    new things without accidentally causing problems. This kind of planning reduces
    the risk of unintended issues and makes maintenance less costly.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen what architecture is and why it’s important, let’s discover
    the main types of architecture we can have.
  prefs: []
  type: TYPE_NORMAL
- en: Architectural patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In software, we can organize things in different ways, and these organized structures
    are called **software architecture patterns**. Many of them have been tried and
    proven to work well for solving different problems. Each pattern arranges things
    in a specific way to fix particular issues in software.
  prefs: []
  type: TYPE_NORMAL
- en: But let’s keep it interesting and not dive into a super long list of these patterns.
    Instead, we’ll look at a few of the most important and commonly used ones. This
    way, we can understand the main ideas without getting overwhelmed by all the possibilities.
  prefs: []
  type: TYPE_NORMAL
- en: Layered architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **layered architecture pattern** (also called the **n-tier architecture
    pattern**) is probably the most widely used design approach. It’s the go-to standard
    for many Java **Enterprise Edition** (**EE**) applications, and it’s well-known
    among architects, designers, and developers. This pattern closely aligns with
    typical communication and organizational setups in most companies, making it a
    logical and common choice for developing business applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the layered architecture pattern, components are organized into horizontal
    layers, each with a specific role in the application (such as presentation or
    business logic). While the pattern doesn’t prescribe a fixed number of layers,
    common setups have four: **presentation**, **business**, **persistence**, and
    **database**. Sometimes, the business and persistence layers are combined for
    simplicity. Smaller apps might have three layers, while larger ones could have
    five or more.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Each layer has a distinct responsibility. For instance, the presentation layer
    handles user interfaces and communication, while the business layer executes business
    rules. Layers create abstractions, simplifying tasks. The presentation layer focuses
    on displaying information, not retrieving it. Similarly, the business layer concentrates
    on business logic, leaving data retrieval to the persistence layer, which then
    passes data to the business layer for processing and onward to the presentation
    layer for display:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – Layered architecture](img/B20912_09_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – Layered architecture
  prefs: []
  type: TYPE_NORMAL
- en: The layered architecture pattern excels in separating concerns among components.
    Each layer focuses solely on its relevant logic—presentation in the presentation
    layer, business in the business layer, and so forth. This classification simplifies
    role and responsibility models, making development, testing, governance, and maintenance
    straightforward. Defined component interfaces and limited scope contribute to
    this ease.
  prefs: []
  type: TYPE_NORMAL
- en: Notably, every layer in the architecture is marked as closed, a crucial concept
    in this pattern. A **closed layer** means a request must pass through the immediate
    layer below it before reaching the next one beneath. For instance, a request from
    the presentation layer travels through the business layer, then to the persistence
    layer, and finally reaches the database layer.
  prefs: []
  type: TYPE_NORMAL
- en: Monolithic application architectures
  prefs: []
  type: TYPE_NORMAL
- en: 'In a layered architecture, as we said, the concept involves organizing different
    components or functionalities of a system into distinct layers. But these layers
    can be interpreted in two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Different applications/deployments**: In this interpretation, each layer
    is considered a separate application or deployment. Each layer represents a self-contained
    unit with specific responsibilities. For example, you might have a presentation
    layer, business logic layer, and data access layer deployed as separate applications.
    This approach promotes modularity and facilitates scalability and maintenance.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Components inside the same application (monolith or N-tier)**: Alternatively,
    the layers can be viewed as components within the same application. In a monolithic
    architecture or an N-tier architecture, different layers exist within a single
    application’s codebase. For instance, you could have a presentation layer handling
    user interfaces, a business logic layer managing application rules, and a data
    access layer interacting with the database—all within the confines of a single
    application.'
  prefs: []
  type: TYPE_NORMAL
- en: Both interpretations are valid, and the choice between them depends on the specific
    architectural design goals and requirements of the system.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many lengthy books about **microservices**, and it would be impossible
    to tell you everything here and now. However, we should at least give you a general
    overview of the topic because for years – and perhaps still today – they have
    been one of the main trends in our industry.
  prefs: []
  type: TYPE_NORMAL
- en: '**Microservices architecture**, commonly abbreviated as microservices, is a
    specific way of structuring applications. In this architectural style, a large
    application is broken down into smaller, independent parts, each with its distinct
    set of responsibilities. This approach enables the creation of more modular and
    manageable components within the overall system. To represent this, we could put
    an example of a very common application, having a microservice dedicated to searching
    for items, another one handling the order, another one dealing with accounting
    issues, and a last one dealing with notifying users via email, push, and so on.
    Here is an example of microservices architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2 – An example of microservices architecture](img/B20912_09_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – An example of microservices architecture
  prefs: []
  type: TYPE_NORMAL
- en: In the context of microservices, an application can consist of numerous internal
    microservices, each handling a specific function. When a user makes a request,
    the microservices work together to compose and fulfill that request. This decentralized
    and modular nature of microservices offers flexibility, scalability, and easier
    maintenance compared to monolithic architectures where all functionalities are
    tightly integrated into a single, large application.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the concept of a service component is crucial within this pattern.
    Instead of viewing services in a microservices architecture, it’s more beneficial
    to consider service components. These components can vary in size, ranging from
    a single module to a substantial part of the application. Service components house
    one or more modules (that is, Java classes) representing either a specialized
    function (such as providing traffic information for a specific location) or an
    autonomous section of a comprehensive business application. Determining the appropriate
    level of granularity for service components stands as a significant challenge
    in the context of microservices architecture. Nobody I know is completely satisfied
    with that!
  prefs: []
  type: TYPE_NORMAL
- en: Another essential idea in the microservices architecture pattern is its distributed
    nature. In this framework, all components within the architecture are completely
    independent of each other and are accessed through various remote access protocols
    (such as **Java Message Service** (**JMS**), **Advanced Message Queuing Protocol**
    (**AMQP**), **Representational State Transfer** (**REST**), **Simple Object Access
    Protocol** (**SOAP**), **Remote Method Invocation** (**RMI**), and so on). The
    distributed aspect of this architecture pattern is instrumental in achieving remarkable
    scalability and deployment characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: In a microservices architecture, finding the right granularity for service components
    is a significant challenge. If they are too coarse-grained, you might miss out
    on the benefits of this pattern (deployment, scalability, testability, and loose
    coupling). On the other hand, overly fine-grained components can lead to service
    orchestration demands, turning your lean microservices architecture into a complex
    **service-oriented architecture** (**SOA**) with added complexity, confusion,
    and cost.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting the granularity challenge is possible by looking for signs such as
    orchestrating service components from the user interface or **application programming
    interface** (**API**) layer, indicating components may be too fine-grained. Inter-service
    communication for a single request may also suggest incorrect granularity or improper
    partitioning based on business functionality.
  prefs: []
  type: TYPE_NORMAL
- en: If service-component orchestration persists regardless of granularity, it might
    signal that a microservices architecture may not be the ideal choice. The distributed
    nature of this pattern makes maintaining a single transactional unit across components
    challenging, requiring complex transaction compensation frameworks for rollback,
    adding unnecessary complexity to this otherwise simple and elegant architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'The microservices architecture offers a myriad of advantages that significantly
    impact the development and operation of large, complex applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Continuous delivery and deployment**: One of the key strengths of the microservices
    architecture is its facilitation of continuous delivery and deployment. This means
    that updates, enhancements, or new features can be seamlessly integrated into
    the application without disrupting its overall functionality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Modular and easily maintained**: Microservices are designed to be small and
    modular, allowing for easy maintenance. Each service is focused on a specific
    business capability, making it more straightforward to understand, update, and
    troubleshoot.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Independent deployability**: A notable feature is the ability to independently
    deploy services. This ensures that changes or updates to a particular service
    do not require a comprehensive redeployment of the entire application, leading
    to more efficient development processes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability on a service level**: Microservices empower teams to independently
    scale services based on their specific demands. This granular scalability optimizes
    resource utilization and responsiveness, enhancing the overall performance of
    the application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Autonomous teams**: The microservices architecture fosters team autonomy,
    enabling different teams to work independently on specific services. This autonomy
    streamlines development cycles, allowing teams to innovate and iterate at their
    own pace.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Experimentation with new technologies**: Embracing microservices allows for
    easy experimentation and adoption of new technologies. Since services can be built
    and deployed independently, teams can explore and implement cutting-edge tools
    or frameworks without overhauling the entire system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enhanced fault isolation**: In the microservices model, faults are isolated
    to individual services, preventing a failure in one service from cascading and
    affecting the entire application. This improves the overall resilience and robustness
    of the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Of course, no technology is perfect, and the microservices system has some
    problems and challenges. Let’s delve into significant challenges and issues associated
    with the microservices architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Service identification**: Determining the optimal set of services can be
    a demanding task. Selecting the right services that effectively represent distinct
    business capabilities requires careful consideration and planning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Complexity of distributed systems**: Microservices involve the creation of
    distributed systems, adding a layer of complexity. This complexity extends to
    the development, testing, and deployment phases, posing challenges in ensuring
    seamless integration and operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Coordination for feature deployment**: Deploying features that span multiple
    services necessitates meticulous coordination. Ensuring that various services
    work harmoniously to deliver a unified functionality demands careful planning
    and execution to avoid disruptions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decision-timing dilemma**: Determining the opportune moment to adopt the
    microservices architecture is a challenging decision. Knowing when the benefits
    outweigh the drawbacks and aligning the transition with organizational needs requires
    thoughtful evaluation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Addressing these challenges is crucial for successfully implementing the microservices
    architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Event-driven architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is another common type of architectural pattern that can also be seen
    as a nuance of microservices. To put it simply, it involves designing a structure
    that recognizes events happening in the system—something that occurs—and making
    it react by producing some kind of result. The examples of “things that can happen”
    are potentially endless: a user signs up for the platform, a third-party system
    calls one of our webhooks, and an error occurs during some kind of process. For
    each of these events, one or more components will be listening and responding
    to the event itself. But let’s try to be a bit more formal in our definition.'
  prefs: []
  type: TYPE_NORMAL
- en: An **event** refers to a change in state or, more expansively, any observable
    occurrence that can be detected and documented by an application or device. These
    events can then be communicated and exchanged with other applications and devices.
    Within your enterprise, every incident—be it customer requests, updates in inventory,
    sensor readings, and the like—constitutes an event.
  prefs: []
  type: TYPE_NORMAL
- en: An **event-driven architecture** is a way for decoupled services to talk to
    each other using events, which are like little messages about changes or updates.
    This is a pretty common approach in modern apps with microservices.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this setup, there are three main parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Event producers**: These are the creators of events and publish them to the
    router; for example, “a purchase is completed.”'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Event routers or event brokers**: These are the organizers who decide where
    each event should go. For example, you can imagine something like “a completed
    purchase should result in sending an email to the customer.”'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Event consumers**: These are the parts of the system that want to know about
    certain events; for example, a component that receives some data about a completed
    purchase and reacts by sending an email to the customer.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The cool thing is these different parts don’t have to know too much about each
    other. They just send out these little event messages, and the other parts can
    choose to listen and react or not. In our examples, the component that completes
    the purchase doesn’t know a thing about what will happen next; it just publishes
    an event. The consumer, who is in charge of sending an email, doesn’t have to
    know anything about the purchase completion process. This makes things flexible
    because, for instance, you can update how the payment system works without messing
    up how the mailing system works. They are like separate teams that can do their
    own thing without always checking with each other. This can often translate into
    two actually different teams working more or less separately.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, an event can also be referred to as a message; the terms are often
    interchangeable. A bit more specific is the concept of a command: unlike an event
    that defines a change of state in some data or entity within the domain, a command
    explicitly requires something to be done. The implicit aspect is that in this
    case, the one carrying out the action and publishing the event is aware of something
    that is supposed to happen afterward. Technologically, however, almost nothing
    changes. Here is a diagram of event-driven architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Event-driven architecture](img/B20912_09_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – Event-driven architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several advantages to embracing an event-driven architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first is probably **independent scaling and fault isolation**: by adopting
    an event-driven architecture, the ability to scale and manage failures independently
    becomes a key benefit. As already mentioned, these are also benefits of microservices.
    Through the decoupling of services, each service interacts solely with the event
    router, rendering them agnostic to the existence of other services. Consequently,
    in the event of a failure in one service, the rest can continue to function seamlessly.
    The event router serves as an elastic buffer, adept at handling surges in workloads
    and ensuring overall system stability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **development is more agile** because the event-driven model eliminates
    the need for custom code to poll, filter, and route events. Instead, the event
    router autonomously manages these tasks, automatically filtering and pushing events
    to consumers. This streamlined process significantly accelerates development cycles
    by minimizing the heavy coordination traditionally required between producer and
    consumer services. Developers can focus more on implementing business logic rather
    than dealing with intricate event-handling intricacies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you have an event router acting as a centralized hub for auditing applications
    and establishing policies, you get **effortless auditing**. These policies can
    dictate access controls, limiting who can publish and subscribe to the router
    and specifying permissions for users and resources to access data. Additionally,
    the event router facilitates the encryption of events both during transit and
    while at rest, enhancing data security measures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You usually also have some **cost reductions**: event-driven architectures
    operate on a push-based model, triggering actions only when an event is present
    in the router. This contrasts with continuous polling, leading to reduced network
    bandwidth consumption, lower CPU utilization, decreased idle fleet capacity, and
    fewer SSL/TLS handshakes. The result is a more cost-effective system that maximizes
    resource efficiency by minimizing unnecessary operations, providing both economic
    and operational benefits.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the world of event-driven setups, there are two main ways things work: the
    pub/sub model and the event streaming model.'
  prefs: []
  type: TYPE_NORMAL
- en: Pub/sub model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Pub/sub** stands for **publish/subscribe** or **publisher/subscriber**. This
    system functions using a messaging framework built on event stream subscriptions.
    Once an event takes place or is published, it is sent to subscribers who have
    expressed interest in that particular information. This method guarantees timely
    notification of relevant parties regarding unfolding events.'
  prefs: []
  type: TYPE_NORMAL
- en: Event streaming
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unlike the pub/sub model, the event streaming model involves the recording of
    events in a log. Here, event consumers do not subscribe to an event stream; instead,
    they have the flexibility to read from any segment of the stream and can join
    the stream at their convenience.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some different types of event streaming, the main ones being:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Event stream processing**: Leverages a data streaming platform such as Apache
    Kafka to intake events and handle the processing or transformation of the event
    stream'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Simple event processing**: An action is promptly triggered in the event consumer
    as soon as an event occurs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Kafka
  prefs: []
  type: TYPE_NORMAL
- en: The most widely tool used for event streaming is Apache Kafka. Apache Kafka
    stands out as a powerful distributed data streaming platform, widely recognized
    as a top-tier solution for event processing. Renowned for its versatility, this
    platform excels in managing the seamless flow of event streams in real-time, encompassing
    tasks such as publishing, subscribing, storing, and processing data. Designed
    to meet the demands of diverse use cases, Apache Kafka particularly shines in
    scenarios where high throughput and scalability are paramount.
  prefs: []
  type: TYPE_NORMAL
- en: One of the distinctive features of Apache Kafka is its ability to efficiently
    handle a spectrum of data-sharing tasks without the need for intricate point-to-point
    integrations. This characteristic not only streamlines the overall architecture
    but also plays a pivotal role in reducing latency to an impressive millisecond
    scale. By offering a robust foundation for real-time data processing, Apache Kafka
    empowers organizations to harness the potential of timely insights and responsive
    analytics.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, Apache Kafka emerges as an indispensable tool for industries and
    applications where the rapid exchange of information is critical. Its architecture
    not only supports the simultaneous handling of numerous events but also ensures
    that the system can effortlessly scale to accommodate growing demands. This combination
    of flexibility, scalability, and low-latency processing positions Apache Kafka
    as a preferred choice for businesses seeking a reliable and efficient solution
    for their data streaming and event processing needs.
  prefs: []
  type: TYPE_NORMAL
- en: The natural evolution of an event-driven architecture, especially one that adopts
    the event streaming pattern, is reactive architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Reactive architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In recent years, a new way of doing things in the Java world has become popular,
    and it is called the **reactive paradigm**. Let us try to understand the basic
    ideas. As usual, we don’t expect you to fully grasp the reactive paradigm in just
    one part of a book. The *Further reading* section is there for you, so you can
    explore more about it!
  prefs: []
  type: TYPE_NORMAL
- en: 'The term *reactive* is employed in the realm of reactive systems (not only
    in Java), and it was coined in the 2014 Reactive Manifesto, a collaborative effort
    by the community to develop responsive and distributed systems. The manifesto
    emphasizes the creation of systems that must be:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Responsive**: The system promptly responds with minimal and predictable delays
    to inputs to enhance user experience. For example, in a web application following
    reactive principles, user interface components are designed to update quickly
    in response to user interactions. For instance, when a user clicks a button, the
    system responds immediately, providing feedback without noticeable delays.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resilient**: In the face of a component failure, the system gracefully handles
    it, minimizing the impact on overall system availability and responsiveness. For
    example, consider a microservices architecture where one service fails due to
    a temporary issue. A resilient system would handle this failure gracefully, perhaps
    by rerouting requests to an alternative instance of the service, ensuring that
    the overall system remains operational (**Circuit** **Breaker pattern**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Circuit Breaker pattern
  prefs: []
  type: TYPE_NORMAL
- en: Connecting to the concept of resilience, it’s worth talking about the **Circuit
    Breaker** pattern; it is a design pattern to improve the resilience of a system.
    It is used to handle faults and failures in a distributed or remote service by
    detecting and preventing repeated failures. The pattern is inspired by the electrical
    circuit breaker, which automatically interrupts the flow of electricity when a
    fault is detected to prevent damage to the electrical system.
  prefs: []
  type: TYPE_NORMAL
- en: A circuit breaker operates by wrapping a function call (such as a remote service
    call) and monitoring for failures. When a certain threshold of failures is reached,
    the circuit breaker “trips” and stops allowing calls to that function for a specified
    period. During this time, the system can take alternative actions, such as returning
    a fallback response or retrying the operation after a delay. This prevents the
    system from repeatedly trying to call a failing service, which could lead to degraded
    performance or complete system failure.
  prefs: []
  type: TYPE_NORMAL
- en: If you’d like to implement a circuit breaker in your Java application, the most
    used libraries are probably **Hystrix** and **Resilience4j**. Developed by Netflix,
    Hystrix is a widely used library for implementing the Circuit Breaker pattern
    in Java. It provides **fault tolerance** (**FT**) and **latency tolerance** (**LT**)
    features for distributed systems. Resilience4j is a lightweight, modular library
    for handling failures in Java 8+ and functional programming styles. It provides
    several resilience patterns, including Circuit Breaker, Rate Limiter, Retry, and
    Bulkhead. If you’re using Spring Boot, **Spring Cloud Circuit Breaker** offers
    a unified abstraction layer for various circuit breaker implementations. This
    framework presents a uniform API that developers can use within their applications,
    granting the flexibility to select the circuit breaker implementation that aligns
    most effectively with their specific application requirements. The supported implementations
    at the moment of writing are Resilience4j and Spring Retry.
  prefs: []
  type: TYPE_NORMAL
- en: '**Elastic**: The system can adapt to varying workloads, maintaining consistent
    response times. For example, an elastic system could automatically scale its resources
    up or down based on demand. During peak usage, additional server instances might
    be provisioned to handle the increased load, and they can be scaled down during
    periods of lower demand.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Message-driven**: Systems aligned with the manifesto employ a message-driven
    communication model. For example, in a distributed application, components communicate
    through messages rather than direct method calls: instead of invoking a remote
    service synchronously, a system following the message-driven approach might send
    a message asynchronously and continue processing other tasks while awaiting a
    response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A reactive architecture follows all these indications, emphasizing the propagation
    of changes and the declarative specification of the system’s behavior in response
    to those changes. In reactive systems, an often-used paradigm is the Actor Model.
  prefs: []
  type: TYPE_NORMAL
- en: The Actor Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'I think it’s worth mentioning the **Actor Model** because it’s truly interesting,
    serving as the foundation for reactive systems. The Actor Model is nothing new:
    it was introduced by Carl Eddie Hewitt in 1973 as a theoretical model for managing
    concurrent computation. Its practical relevance became evident as the software
    industry recognized the challenges associated with implementing concurrent and
    distributed applications. In other words: managing threads is not suitable anymore
    and we do not have faster CPUs; we only have CPUs with more cores!'
  prefs: []
  type: TYPE_NORMAL
- en: 'An actor is a *self-contained computational unit*, embodying several crucial
    characteristics that distinguish it within the Actor Model:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Encapsulation of state and logic**: An actor encapsulates both its state
    and a portion of the application logic. This encapsulation ensures that an actor’s
    internal workings are shielded from direct external access, promoting modular
    and maintainable code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Asynchronous message interaction**: Actors communicate exclusively through
    asynchronous messages, avoiding direct method calls. This design choice enhances
    the responsiveness of the system, as actors can continue processing messages independently
    without waiting for immediate responses.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Unique address and mailbox**: Each actor possesses a unique address and maintains
    a mailbox for incoming messages. The address serves as a distinct identifier in
    the system, while the mailbox provides a mechanism for other actors to deliver
    messages asynchronously.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Sequential message processing**: Messages in an actor’s mailbox are processed
    sequentially in the order of their arrival. The default implementation of the
    mailbox often adopts a **First-In-First-Out** (**FIFO**) queue, ensuring predictable
    and ordered execution of messages.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tree-like hierarchy**: The actor system is organized in a hierarchical, tree-like
    structure. This hierarchy facilitates the organization of actors, with each actor
    having a specific place and role within the larger system.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Dynamic actor operations**: Actors can dynamically create other actors, send
    messages to any actor within the system, and initiate their own termination or
    that of actors they have spawned. This dynamic behavior allows for flexible and
    adaptive system architectures.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Making programs that do many things at the same time is tricky because we have
    to make sure different parts of the program don’t interfere with each other. The
    Actor Model makes it easier by letting us write code that can run independently
    without getting tangled up in these issues.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of directly asking another part of the program to do something and waiting
    for it to finish, we can send a message and keep going. This means the part sending
    the message doesn’t have to wait around for a reply. A system using this feature
    is usually referred to as a **non-blocking system**.
  prefs: []
  type: TYPE_NORMAL
- en: Using messages also helps prevent problems that can happen when many parts of
    the program are working at the same time. Messages are like notes passed between
    different parts, and they get dealt with one after the other, so there’s no confusion.
  prefs: []
  type: TYPE_NORMAL
- en: Another good thing about the Actor Model is that if something goes wrong, such
    as a part of the program not doing what it’s supposed to, the actors can tell
    their “boss” about it. The boss can then decide whether to fix the problem or
    just start over with a fresh attempt. This way, the whole program can keep running
    smoothly even if there are hiccups along the way.
  prefs: []
  type: TYPE_NORMAL
- en: In Java, you can leverage the Actor Model by using **Akka**, a toolkit and runtime
    for building highly concurrent, distributed, and fault-tolerant systems. It provides
    abstractions for managing concurrency, making it easier to develop scalable and
    resilient applications. In the *Further reading* section, there’s a simple tutorial
    about it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have quickly covered several broad and somewhat complex concepts; much of
    it relies on modern, non-monolithic architecture. Let’s now say a few words about
    one of the main trends of recent years: breaking the monolith!'
  prefs: []
  type: TYPE_NORMAL
- en: Monolith to microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **monolithic architecture** refers to a traditional approach in software design
    where an entire application is built as a single, unified code base. In a monolithic
    architecture, all components and modules of the application are interconnected
    and interdependent. This means that the code for the user interface, business
    logic, and data access layers, among others, is tightly integrated into a single
    executable or deployment unit.
  prefs: []
  type: TYPE_NORMAL
- en: In a monolithic architecture, the entire application is developed and maintained
    within a single code base, making it a cohesive unit. All modules and components
    within the application are closely connected and share the same resources, such
    as databases and servers; therefore, the entire application is deployed as a single
    unit, making updates and releases a coordinated process. One advantage of the
    monolithic architecture is that it often uses a uniform technology stack throughout
    the entire system; the main disadvantage is that scaling a monolithic application
    typically involves replicating the entire application, which can be less efficient
    than scaling individual components independently.
  prefs: []
  type: TYPE_NORMAL
- en: While monolithic architectures have been the standard for many years and have
    certain advantages, such as simplicity in development and deployment, they also
    pose challenges, especially as applications grow in size and complexity. The move
    away from monolithic architecture has led to the adoption of alternative architectural
    patterns, the most common being microservices. This has been quite a mantra for
    the last few years, and there are lots of books and articles about that. We’ll
    just say a few words so that you don’t feel completely unprepared!
  prefs: []
  type: TYPE_NORMAL
- en: 'Our first piece of advice is: don’t treat a monolith like it was necessarily
    evil because, well, it depends. In some cases, the monolith is OK. For example,
    if you have a small-scale application with limited complexity and traffic, the
    overhead of managing a microservices architecture might outweigh the potential
    benefits, especially if requirements don’t change that much. A monolith can be
    simpler to develop and maintain in such cases. Also, you could have limited resources:
    microservices often require specialized knowledge and additional infrastructure,
    which might not be feasible for smaller teams. Transitioning from a monolith to
    microservices requires time, effort, and potentially additional resources. If
    your organization is constrained in terms of time, budget, or expertise, maintaining
    the monolith might be a pragmatic decision. But the main reason could be that
    your monolith *just works*: if your monolithic application is stable, performs
    well, and meets the current and foreseeable future needs of the business, there
    might not be a compelling reason to undergo the complexity of transitioning to
    microservices.'
  prefs: []
  type: TYPE_NORMAL
- en: 'While the benefits of microservices are evident, the transition from monolith
    to microservices comes with its own set of challenges. Entire books have been
    written on the argument, so we’ll just give you a couple of hints:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data management**: The transition to microservices introduces a paradigm
    shift in data management. In a monolith, data is often stored and accessed within
    a unified database. However, in a microservices architecture, data is distributed
    across multiple services. This decentralization of data can lead to challenges
    in ensuring consistency and maintaining transactional integrity. Organizations
    must grapple with issues such as data synchronization, versioning, and cross-service
    transactions to avoid data inconsistencies and ensure the reliability of their
    applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service communication**: Efficient communication between microservices is
    paramount for the success of the architecture. Unlike monolithic applications,
    where function calls can be internal, microservices communicate over a network.
    Choosing appropriate communication protocols and mechanisms becomes crucial to
    facilitate seamless interactions between services. Decisions regarding synchronous
    or asynchronous communication, API design, and message formats require careful
    consideration to optimize the performance and reliability of the entire system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Operational complexity**: The move to microservices introduces a new level
    of operational complexity. Managing a distributed system involves orchestrating
    the deployment and scaling of multiple services. Monitoring the health and performance
    of each service, logging relevant information for debugging purposes, and ensuring
    the overall reliability of the system become intricate tasks. Organizations need
    robust tools and practices for distributed tracing, logging aggregation, and monitoring
    to effectively navigate the operational challenges posed by microservices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cultural shift**: Beyond technical considerations, transitioning to microservices
    often necessitates a cultural shift within development teams. Embracing a DevOps
    mindset, where development and operations teams collaborate closely throughout
    the **software development life cycle** (**SDLC**), becomes essential. **Continuous
    integration** and **continuous deployment** (**CI/CD**) practices need to be adopted
    to enable rapid and reliable releases. This cultural transformation requires a
    commitment to automation, collaboration, and a shared sense of responsibility
    among team members.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of the previous points hides a world of challenges behind them. These challenges,
    while surmountable, underscore the need for a thoughtful and well-executed transition.
  prefs: []
  type: TYPE_NORMAL
- en: 'It would be really difficult, naive, and maybe even arrogant to try to guide
    you in just a few words through the transition to adopting a microservices architecture.
    I have been involved several times in projects where this transition took years
    and sometimes wasn’t even fully completed. It’s a lengthy process that requires
    great attention, especially in deciding how big a microservice should be. However,
    we can offer you some insights to understand what to pay attention to if you find
    yourself involved in such a transition (and it’s quite likely!):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Incremental adoption**: One of the best practices for a successful transition
    to microservices involves adopting a strategy of incremental changes rather than
    a sudden, big-bang overhaul. Organizations often find it prudent to start the
    migration process by identifying and transitioning non-critical services first.
    This phased approach allows teams to gain experience with microservices while
    minimizing the impact on the overall system. It also facilitates the identification
    and resolution of challenges on a smaller scale before tackling more critical
    components.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Effective communication**: In a microservices architecture, where services
    communicate over a network, establishing clear and effective communication channels
    is paramount. Organizations should define and adhere to well-defined APIs to ensure
    seamless interaction between services. This not only enhances the reliability
    of the system but also facilitates the independence of services, enabling teams
    to evolve and update services without disrupting the entire application. Effective
    communication is foundational to achieving the modularity and flexibility that
    microservices promise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automated testing**: Comprehensive automated testing is a linchpin of successful
    microservices adoption. Given the distributed nature of microservices, thorough
    testing is essential to catch issues early in the development and deployment process.
    Test suites should cover unit testing, integration testing, and **end-to-end**
    testing for each microservice. Automation not only accelerates the testing process
    but also provides a safety net for frequent deployments, ensuring that changes
    to one service do not inadvertently break the functionality of others. Consider
    adopting contract testing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring and logging**: Operational complexities introduced by microservices
    necessitate robust monitoring and logging solutions. Organizations should invest
    in tools that enable real-time monitoring of service health, performance metrics,
    and potential issues. Centralized logging allows for efficient debugging and troubleshooting
    across distributed services. Proactive monitoring and logging not only aid in
    maintaining system reliability but also contribute to a proactive approach to
    system optimization and performance enhancement.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cultural alignment**: Transitioning to a microservices architecture is not
    only a technological shift but also a cultural one. Fostering a culture of collaboration,
    shared responsibility, and continuous learning is crucial for the success of the
    transition. Teams should embrace a DevOps mindset, where development and operations
    collaborate closely, and there is a shared sense of ownership for the entire system.
    Continuous learning and knowledge sharing ensure that teams are equipped to adapt
    to the evolving landscape of microservices and embrace the agility it brings to
    software development.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These best practices try to provide a roadmap for teams and organizations navigating
    the complex terrain of transitioning from monolithic architectures to microservices.
  prefs: []
  type: TYPE_NORMAL
- en: When you have some kind of microservice architecture in place or, better, while
    designing it, you’ll want to be aware of some bad smells you could spot quite
    easily.
  prefs: []
  type: TYPE_NORMAL
- en: Bad smells in the microservices architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just as there are **bad smells** in code – issues that hide between methods
    and classes – there are also problems related to how software components work
    together in a software architecture. These are recurring patterns or, rather,
    anti-patterns, and when we see them, we should be suspicious and take action if
    needed. Let’s take a look at some of the most common ones.
  prefs: []
  type: TYPE_NORMAL
- en: Shared persistence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: “*Don’t cross the streams*,” as the *Ghostbusters* used to say. It’s a bit like
    what happens with shared persistence. We talk about shared persistence when two
    or more microservices share the same persistent data, such as a database, a **Redis**
    instance, or a cache. This can cause a few problems. First, if services *A* and
    *B* try to read and write to the same data layer at the same time, synchronization
    problems can occur. What one service reads might have been written by another,
    and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the most significant issue, in my opinion, is the interdependence
    that arises when you need to make changes to the data structure itself. For example,
    simply changing, adding, or removing a column from a database table could become
    a big problem and might require modifying both microservices, even if one of them
    isn’t affected by the change. If we wanted to represent this situation in a very
    simple yet effective way, we would have a diagram like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – Two (micro) services rely on the same data storage](img/B20912_09_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – Two (micro) services rely on the same data storage
  prefs: []
  type: TYPE_NORMAL
- en: The most obvious solution is to maintain a separate data storage layer for each
    microservice. This means that each microservice owns its data, and it’s responsible
    for providing functions to access that data. When someone needs to use that data,
    they’ll use the microservice as a kind of **data abstraction**. They won’t need
    to know where or how the data is stored. Data owned by a specific microservice
    should not be duplicated elsewhere.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, it’s essential to note that having a non-shared data storage layer
    doesn’t necessarily mean having a separate database for each microservice. It
    depends on the granularity of the service. For example, if you have a microservice
    that handles customers and their shipping addresses (such as in an e-commerce
    platform), you might have a database specific to this service. Customers and addresses
    are likely interconnected, so you might have relational tables linked; for example,
    by a foreign key. If you want to make your microservices more granular, say, a
    customer service and an address service, you can’t have completely separate and
    unrelated databases. However, you can ensure that the customer service writes
    to the `CUSTOMER` table and the address service writes to the `ADDRESS` table.
    These tables will be related by a foreign key but will remain distinct. Data integrity
    will be guaranteed (also) by the properties of the relational database (**ACID
    properties**):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5 – Two services use different tables of the same database, which
    are related by the id-customer_id foreign key relationship](img/B20912_09_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 – Two services use different tables of the same database, which are
    related by the id-customer_id foreign key relationship
  prefs: []
  type: TYPE_NORMAL
- en: Now, we’ve told you how it should be, but we also need to tell you that this
    doesn’t always happen, especially during the transition from a monolithic system
    to microservices. You may have to share the data storage layer for a while. However,
    our advice is to avoid this situation as much as possible and resolve this issue
    as soon as you can.
  prefs: []
  type: TYPE_NORMAL
- en: Shared libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Sharing persistence** (data storage) leads to coupling problems, and the
    same goes for sharing libraries. One of the first things we discussed in this
    book, and generally emphasized in studies and work, is the principle of **Don’t
    Repeat Yourself** (**DRY**). Do things once, do them well, and reuse your code
    as much as possible. This is certainly a mantra to follow, but in the case of
    architecture (especially a microservices architecture), one must be very cautious.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s imagine having two services – two components that use the same shared
    library, always written and managed by us. If we need to make a change to this
    library, we will not only have to handle the change in the library itself but
    also update the dependency in the microservices, and perhaps even change the code
    if needed (this depends on whether we change the method signatures or not).
  prefs: []
  type: TYPE_NORMAL
- en: 'The example we are discussing involves only two microservices and one library.
    However, within an architecture, there can be many interrelated components: component
    *A* is connected to component *B*, which is connected to component *C*, and so
    on. Modifying a library can potentially lead to a difficult-to-control ripple
    effect, triggering a chain of retesting, rebuilding, and redeploying that can
    be quite costly.'
  prefs: []
  type: TYPE_NORMAL
- en: I’m not saying here not to use shared libraries. Shared libraries are crucial
    for avoiding code duplication among software components. Take logging, for instance.
    Custom logic, such as formatting or concealing sensitive data such as customer
    details, is often required. Now, picture each component with its unique implementation.
    Consider the wasted developer hours if it’s not identical across components. Aggregating
    logs becomes challenging, and slight implementation differences can lead to inconsistent
    labeling.
  prefs: []
  type: TYPE_NORMAL
- en: Something such as the recent `log4j` vulnerability poses a significant challenge
    if this implementation is spread all around the code base. Fixing it per microservice
    or component demands substantial effort. Conversely, with a custom logging library
    using `log4j` internally, addressing the vulnerability only would require action
    at a single point. **Logging** is a universal feature in microservices, making
    it an excellent candidate for a shared library. Other examples include security,
    monitoring, async communication, and handling exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: Also, adding a middle layer between the code and external tools is really helpful.
    It protects the main part of the program from changes in those tools. This makes
    it easier to put new features in or fix problems. It also makes the code easier
    to read and work on with a team. After a year of doing this, it’s clear that it
    makes our software stronger and more flexible.
  prefs: []
  type: TYPE_NORMAL
- en: I’m trying to say here that while good architecture implies decoupling the different
    parts of the application, shared libraries do exactly the opposite. On the other
    hand, they reduce repetition, and that’s good! We have to find a balance. There’s
    no one-size-fits-all rule for every situation. You need to consider each case
    individually. In general, it could be said that it’s worth creating a shared library
    whenever you need to write code that doesn’t depend on the specific subject of
    the module you’re working on. The examples mentioned earlier (logging, security,
    monitoring, and so on) are things that can be used in different situations, no
    matter what specific area you’re working in.
  prefs: []
  type: TYPE_NORMAL
- en: There are different ways to handle your shared libraries. You could either set
    up a distinct repository for each needed library or use a single repository (referred
    to as a **monorepo**; more on this in the *Further reading* section) that houses
    multiple libraries. The crucial point is to have some form of separation. For
    instance, you could have a single repository covering monitoring, security, and
    logging projects. Each project would be self-contained, except for any necessary
    dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s really important to keep the user’s decisions and logic inside a kind
    of protective bubble; this is crucial in programming and when making shared libraries.
    **Encapsulation** is like a shield that stops unwanted access and keeps data safe
    from being leaked. That’s why it’s a must when you’re building shared libraries.
    Let’s imagine you’re making a library with code specific to a certain company,
    such as a tool to put files into storage. The parts that the user works with need
    to be designed in a general way, avoiding names such as *S3FileUploader* (because
    S3 is Amazon’s storage service). But why avoid these names? Well, think about
    this: what if in the future you want to switch to Azure Blob (which is like Microsoft’s
    version of Amazon S3)? If you had named things specifically to Amazon, all your
    users would have to change their ways of doing things. So, it’s better to use
    more general names, such as *FileUploader*. Believe me, it’ll save you a bunch
    of time and work in the long haul.'
  prefs: []
  type: TYPE_NORMAL
- en: Keep your library code clean. Even though many people may contribute to the
    shared library, avoid turning it into a big, complicated thing! Before adding
    a new library, think about it a lot. When you do add one, think about how it might
    change and who will use it. Don’t just make it for your own needs; that makes
    it hard for others to use or add to.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t put domain-specific code in there! Even shared business code probably
    doesn’t belong there. Even if it means each component that uses it has to copy
    it, a user model that starts the same for all components is still business-related
    logic that shouldn’t be in the library. That’s because different services might
    need to change later to fit their specific business needs. It’s not good if they
    all use the same model because it might have things that don’t relate to other
    microservices or even break them if they want to rename or change some of the
    logic. So, when working with a single repository, it’s a great idea to use conventional
    commits to talk about changes in the code. Follow some commit conventions you’ll
    find among the team, such as starting each commit with *fix* when you’re fixing
    something. This is helpful when someone else is trying to understand the history
    of the repository, what was done, and where things are in the code.
  prefs: []
  type: TYPE_NORMAL
- en: Last but not least, when you’re dealing with a shared library that is a client
    library to another service, you could think about generating it. Rather than writing
    a shared library to interact with APIs in a system, it’s more effective to create
    an API specification. This specification can then be used to automatically generate
    API clients for various languages and services. Something really cool we did once
    was to include and use a library called **Feign**, a Java-based declarative web
    service client developed by Netflix. It simplifies the creation of HTTP clients
    for RESTful services by allowing developers to define requests using annotations
    and interface methods. Feign integrates with Netflix Ribbon for load balancing,
    supports various data formats, and provides fallback mechanisms for enhanced application
    robustness. It’s commonly used in microservices architectures for efficient communication
    between services.
  prefs: []
  type: TYPE_NORMAL
- en: Direct communication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the primary motivations behind designing good architecture is the desire
    for improved flexibility and easier maintenance of the overall system. This flexibility
    is crucial for accommodating changes within the application, including modifications
    to the API of individual services or adjustments to the communication protocols
    between services.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, a challenge arises when clients communicate directly with different
    services. This direct communication model diminishes some of the benefits of a
    good architectural design, particularly regarding flexibility. When clients are
    tightly coupled to the specific addresses of other services, the ability to relocate
    or split these services becomes problematic. In essence, the address of a service
    becomes a fixed point, making it difficult to make structural changes to the system
    without impacting its clients. Additionally, when a service is publicly exposed,
    there is a constant need to maintain backward compatibility in its API to avoid
    disrupting existing clients. This is usually considered an anti-pattern, and we’re
    going to represent it with the following diagram, where you can see different
    types of devices connecting directly to the exposed services:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.6 – Different clients for different devices directly call the services](img/B20912_09_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 – Different clients for different devices directly call the services
  prefs: []
  type: TYPE_NORMAL
- en: There are many possible solutions to avoid this anti-pattern. Let’s see a couple
    of them.
  prefs: []
  type: TYPE_NORMAL
- en: API gateway
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'An **API gateway** is a server or service that acts as an entry point for a
    collection of services. Its primary role is to provide a centralized and unified
    point of entry for clients (such as mobile apps, web applications, or other services)
    to interact with various components. It basically sits between the client and
    server, providing other essential functions. Here is a diagram of an API gateway:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.7 – All of the clients of the different devices pass through the
    same API gateway](img/B20912_09_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 – All of the clients of the different devices pass through the same
    API gateway
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, API gateways usually provide **request routing**: an API gateway
    routes incoming requests from clients to the appropriate service(s). It acts as
    a traffic cop, directing requests to the relevant service based on factors such
    as the endpoint, version, or other criteria.'
  prefs: []
  type: TYPE_NORMAL
- en: The API gateway can **aggregate multiple requests** from clients into a single
    request to reduce the number of round trips between the client and the services.
    This is beneficial for optimizing performance and reducing latency. Similarly,
    the API gateway can **aggregate responses** from multiple services before sending
    them back to the client. This can reduce the number of requests needed from the
    client and enhance overall system efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: '**Load balancing** distributes incoming requests across multiple instances
    of a service to ensure optimal resource utilization and prevent overload on any
    single instance. The API gateway can handle this load balancing to enhance the
    system’s scalability and reliability.'
  prefs: []
  type: TYPE_NORMAL
- en: The API gateway usually centralizes **authentication and authorization** processes.
    It can enforce security measures such as validating API keys, handling user authentication,
    and ensuring that only authorized clients can access specific services.
  prefs: []
  type: TYPE_NORMAL
- en: To improve performance, the API gateway can implement **caching** strategies.
    It can store and retrieve responses from services in a cache, reducing the need
    to recompute or fetch the same data repeatedly.
  prefs: []
  type: TYPE_NORMAL
- en: The API gateway often includes **monitoring and analytics** tools to track the
    performance and usage of microservices. This information can be valuable for identifying
    bottlenecks, optimizing resource allocation, and ensuring the overall health of
    the system.
  prefs: []
  type: TYPE_NORMAL
- en: An API gateway can enforce **rate limits** on incoming API requests to prevent
    abuse or overuse of resources. This involves setting a maximum number of requests
    a user or client can make within a specified time frame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Throttling can also be implemented through **quotas**, where clients are allocated
    a certain number of resources or requests over a defined period. Somehow related
    to quotas is the concept of **monetization**: API gateways can track the usage
    of APIs by clients and implement usage-based billing. This involves charging clients
    based on the number of requests, data transferred, or other relevant metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: An alternative to the API gateway pattern is the **Backend for Frontend** (**BFF**)
    pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Backend For Frontend (BFF)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The term *BFF* refers to a design pattern in software development where a separate
    backend is created for each frontend application or user interface. This approach
    is particularly common in the context of microservices architectures and is aimed
    at optimizing the interaction between frontend and backend components.
  prefs: []
  type: TYPE_NORMAL
- en: In a traditional web application, there is usually a single backend that serves
    data and functionality to various frontend clients. However, as applications become
    more complex and diverse, with different platforms (web, mobile, and so on) and
    user experiences, managing all these requirements within a single backend can
    become challenging.
  prefs: []
  type: TYPE_NORMAL
- en: 'The BFF pattern addresses this challenge by creating specialized backend services
    for each frontend or client type. Each BFF is tailored to the specific needs of
    the corresponding frontend, providing a more efficient and targeted interface
    between the two layers. This allows frontend developers to have more control over
    the data and services they need, without being constrained by a monolithic backend
    that serves multiple purposes. Please be mindful that the BFF functions as a “proxy,”
    filtering and adjusting requests from a shared set of backend (BE) services to
    a particular frontend (FE) client. It is essential that the BFF does not duplicate
    backend business functionalities in theory, as doing so would compromise the integrity
    of the application. Here is a diagram of the BFF pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.8 – In BFF, we have a gateway for each type of client](img/B20912_09_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.8 – In BFF, we have a gateway for each type of client
  prefs: []
  type: TYPE_NORMAL
- en: In contrast to the earlier diagram, in this setup, each device type links to
    its dedicated API gateway tailored to its requirements. These gateways act as
    a kind of cover, hiding the services in the background and decoupling the devices
    from direct connections to these services.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several advantages to using the BFF pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Specialization**: Each BFF can be optimized for the specific requirements
    of its associated frontend, leading to better performance and user experience'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Autonomy**: Frontend and backend teams can work more independently, as changes
    to one do not necessarily affect the other, provided the API contracts are maintained'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability**: Different frontends may have varying scalability needs, and
    BFFs allow for more fine-grained scalability planning based on individual requirements'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flexibility**: BFFs can adapt to the technology stack and architectural choices
    that are most suitable for the specific frontend they serve'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s important to note that while the BFF pattern offers advantages, it also
    introduces some complexities, such as the need to manage multiple backend services.
    Proper communication and coordination between frontend and backend teams, as well
    as adherence to well-defined API contracts, are crucial for the success of this
    pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ve dived into the meaning of the term *architecture* and
    checked out its main variations. We’ve seen why having a clean, maintainable,
    and scalable architecture is important, and we’ve got some hints on how to achieve
    it (make sure to dig deeper in the *Further reading* section). We’ve looked at
    the main architectural patterns, from the (relatively) simpler ones to the slightly
    more complex ones designed for larger systems. We’ve also discussed what to watch
    out for when trying to break the monolith – moving from a monolithic architecture
    to a microservices one. Speaking of the latter, we’ve taken a quick look at some
    of the most common bad smells you might encounter. Remember – always keep your
    spider senses active!
  prefs: []
  type: TYPE_NORMAL
- en: As you close this book, remember that writing good code is not a one-time effort
    but a continuous commitment to excellence. Act like a craftsman, constantly refining
    your code to reflect your evolving understanding of best practices and industry
    trends.
  prefs: []
  type: TYPE_NORMAL
- en: The concepts you’ve acquired here will not only result in more readable and
    efficient Java code but will also empower you to collaborate seamlessly with fellow
    developers, ultimately contributing to the success of your projects. As you start
    your coding journey, let the principles of clean code and the art of refactoring
    be your guiding lights, illuminating a path toward software excellence.
  prefs: []
  type: TYPE_NORMAL
- en: May your code always be clean, your designs elegant, and your ride in the world
    of Java programming be both fulfilling and rewarding.
  prefs: []
  type: TYPE_NORMAL
- en: Happy coding!
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Giuseppe Bonocore, *Hands-On Software Architecture with Java*, Packt Publishing
    Ltd.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Robert C. Martin, *Clean Architecture*, Prentice Hall
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mark Richards, *Software Architecture* *Patterns*, O’Reilly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Martin Fowler’s work on architecture: [https://martinfowler.com/architecture/](https://martinfowler.com/architecture/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Monorepo* *Explained*: [https://monorepo.tools/](https://monorepo.tools/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Intro to* *Feign*: [https://www.baeldung.com/intro-to-feign](https://www.baeldung.com/intro-to-feign)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Intro to Apache* *Kafka*: [https://www.baeldung.com/apache-kafka](https://www.baeldung.com/apache-kafka)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Akka: [https://www.baeldung.com/akka-actors-java](https://www.baeldung.com/akka-actors-java)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sam Newman, *Monolith to* *Microservices*, O’Reilly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
