<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Build a Breast Cancer Prognosis Pipeline with the Power of Spark and Scala</h1>
                </header>
            
            <article>
                
<p class="mce-root">Breast <span>cancer is the leading cause of death among women each year,</span><span> leaving others in various stages of the disease. </span><span>Lately,</span> <strong>machine learning</strong> <span>(</span><strong>ML</strong><span>) has shown great promise for physicians and researchers working towards better outcomes and lowering the cost of treatment. With that in mind, the</span> <strong>Wisconsin Breast Cancer</strong><span> </span><strong>Da</strong><span><strong>ta Set</strong> represents a combination of suitable features that are useful enough to</span> <span>generate ML models, models that are able to predict a future diagnostic outcome by learning from predetermined or historical breast mass tissue sample data.</span><br/></p>
<p>Here is  the dataset we refer to:</p>
<ul>
<li>UCI Machine Learning Repository: Breast Cancer Wisconsin (Original) Data Set</li>
<li>UCI Machine Learning Repository: Breast Cancer Wisconsin (Diagnostic) Data Set</li>
<li>Accessed July 13, 2018</li>
<li>Website URL: <a href="https://archive.ics.uci.edu/ml/datasets/Breast%20Cancer%20Wisconsin%20(Original)">https://archive.ics.uci.edu/ml/datasets/Breast Cancer Wisconsin (Original)</a></li>
</ul>
<p>In this chapter, we will be focusing on implementing and training a logistic regression multiclass classifier for making a prediction on whether a breast cancer mass is malignant or not. T<span>he Wisconsin Breast Cancer Data Set is a classification task.</span></p>
<p>The overarching learning objective of this chapter is to be able to implement a Scala solution that will predict cancer outcomes. Starting from the <strong>UCI Machine Learning Repository</strong> b<span>reast cancer dataset, we will lean on the Spark ML library's ML APIs and its supporting libraries to build a breast cancer prediction pipeline.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The following list is a section-wise breakdown of individual learning outcomes for this chapter:</p>
<ul>
<li>Breast cancer classification problem</li>
<li>Getting started</li>
<li>Random Forest breast cancer pipeline</li>
<li>LR breast cancer pipeline</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Breast cancer classification problem</h1>
                </header>
            
            <article>
                
<p><span>At the moment supervised learning is the most common class of ML problems in the business domain. In <a href="4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml">Chapter 1</a>, <em>Predict the Class of a Flower from the Iris Dataset</em>, we approached the Iris classification task by employing a powerful supervised learning classification algorithm called <strong>Random Forests</strong>, which at its core depends on a categorical response variable.</span> In this chapter, besides the Random Forest approach, we also turn to yet another intriguing yet popular classification technique, called <strong>logistic regression</strong>. Both approaches present a unique solution to the prediction problem of breast cancer prognosis, while an <span>iterative learning process is a </span>common denominator. The logistic regression technique occupies center stage in this chapter, taking precedence over Random Forests. However, both <span>learn from a test dataset containing samples with </span>predetermined measurements and compute<span> a prediction on new, unseen data.</span></p>
<p><span>Before we proceed further, a quick note on ML terminology. The literature in this rapidly expanding field is sometimes seen to be replete with terms from other overlapping fields, leading to differing perceptions, even though two apparently different terms refer to the same thing or are mostly equivalent in regard to semantics. Sometimes, two terms that are often used interchangeably in the literature might actually be quite different; for example, the terms <strong>multivariate</strong> and <strong>multivariable</strong> are two such terms. We will avoid using multivariable in this chapter. </span><span>That said, let's take up the Wisconsin Breast Cancer Data Set and understand the terms around it, prior to problem formulation and implementation.</span></p>
<p>First, we must download the dataset from the UCI Machine Learning Repository. It is available in the <kbd>ModernScalaProjects_Code</kbd> folder.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Breast cancer dataset at a glance</h1>
                </header>
            
            <article>
                
<p> </p>
<p><span>The Wisconsin Breast Cancer Data Set contains 699 rows of data. Each row corresponds to a single sample (the term <strong>example</strong> is sometimes used interchangeably with a <strong>sample</strong> in the ML literature) containing nine feature measurements of digitized images of a fine needle aspirate of a breast mass.</span></p>
<p>Before we dive into the details, here is a table listing the key characteristics of the <span>699 rows (instances) of the </span><span>Wisconsin Breast Cancer Data Set:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ddc04472-19c3-40fa-a0f1-1f2111bf31e7.jpg" style="width:30.08em;height:28.25em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Breast cancer dataset characteristics</span></div>
<p>The preceding table lists nine cell nuclei attributes of the b<span>reast cancer dataset, where each attribute bears a single value. All of the nine cell nuclei attribute values are measurements that have been captured from digitized images of a certain sample.</span> 699 of these breast cancer tissue samples, then, should constitute our ML experimental unit of 699 input vectors.</p>
<p class="mce-root"/>
<p>To reflect on what input vectors are, we invite readers to draw upon their previous <span>experience with the Iris dataset supervised learning problem; this was a classification task characterized by two fundamental aspects:</span></p>
<ul>
<li>An input vector</li>
<li>A response variable value <kbd>Y</kbd> with two <span>possible outcomes for its input vector:</span>
<ul>
<li><kbd>Y</kbd> is represented by the class column and is sometimes known as <span>a supervisory signal.</span></li>
<li>Two outcomes (for example, either heads or tails) implies more than one class label. An outcome represents a <em>classification</em>, as in a classification task.</li>
</ul>
</li>
</ul>
<p><span>The preceding two aspects are also shared by our breast cancer supervised learning problem—the task at hand. The following points describe the task at hand by offering more insight:</span></p>
<ul>
<li>It is a <span>699-input vector</span> multiclass classification task. <span>This task is characterized by historical (predetermined) categorical data and more than one </span><span>dependent or outcome variable (or label).</span></li>
<li><span>This task is performed on a dataset that has 699 observations/measurements (instances), where each observation row may be described further as follows:</span>
<ul>
<li>Each row is composed of 10 attributes; each of these attributes is a predictor variable (inputs, <kbd>X</kbd>), which are also known as input variables (<kbd>X</kbd>)</li>
<li><span>Each of the 699 observations is historical or predetermined (with the exception of certain incomplete observations/rows), and represent (breast mass cell nuclei) characteristics of cell nuclei from a breast cancer tissue sample from a needle aspirate</span></li>
</ul>
<ul>
<li>There are 10 characteristics of the aforementioned breast mass cell nuclei; these are just the breast's mass cell nuclei measurements</li>
</ul>
</li>
<li><span>The classification task is also multidimensional, owing to the fact that </span><span>10 (input) attribute values exist as feature parameters that are passed into <kbd>Model</kbd> to carry out a </span><span>diagnosis classification on the so-called target class.</span></li>
<li>Each instance (row) in the breast cancer dataset represents measurements (from digitized images) made on breast mass tissue samples.</li>
<li>The goal of the classification task is as follows:</li>
<li style="padding-left: 30px">To identify (or classify) the diagnosis on a new breast cancer sample as belonging to either of two diagnoses: malignant <span>(cancerous) </span>or benign <span><span>(non-cancerous).</span></span></li>
<li style="padding-left: 30px"><span>To derive a predicted value for the response from the predictors by a process of learning (or fitting) a discrete number of targets or category labels (<kbd>Y</kbd>). </span><span>The predicted value is a categorical response (outcome) variable (output <kbd>Y</kbd>), also known as a response or outcome variable (<kbd>Y</kbd>).</span>
<ul>
<li style="padding-left: 30px">To learn a predictive function also known as a model; <span>this </span>computes a predictor function that predetermines the feature measurements on 10 attributes that will be able to classify or identify, the type of diagnosis (benign or malignant).</li>
</ul>
</li>
</ul>
<p>In <a href="4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml">Chapter 1</a>, <em>Predict the Class of a Flower from the Iris Dataset</em>, we used a supervised learning classification algorithm called Random Forests. In this chapter, we will employ what is known as the l<span>ogistic regression classification technique (a Spark ML algorithm). This will be the heart of our predictive analysis classification pipeline. </span>To sum this up, a high-level view of the breast cancer classification task can be compartmentalized as follows:</p>
<ul>
<li><strong>The classifier algorithm</strong>: This i<span>nvolves the creation of a discriminant function or model function that </span><span>discovers patterns, relationships, or interactions between several independent variables and one dependent variable (indexed by the model to a binary dummy variable) that is either a nominal or ordinal variable</span></li>
<li><strong>Predetermined features</strong>: M<span>easurements or </span><span>observations that have been labeled malignant or otherwise</span></li>
<li><strong> Predicted labels</strong>: L<span>abeling unseen data before arriving at a </span><span>prediction on new, unseen data after a learning process</span></li>
</ul>
<p>The end goal of logistical regression is to produce a model that is as well fitted (trained) as possible and one that emits a prediction. A prediction, of course, is a variable of interest.</p>
<p>The next section is a prelude to a broader discussion on the application of the logistic regression statistical technique.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logistic regression algorithm</h1>
                </header>
            
            <article>
                
<p>The <strong>logistic regression</strong> (<strong>LR</strong>) algorithm, which is employed when building a data pipeline in this chapter, is a fresh approach to making a prediction on whether a breast cancer mass is malignant or not.</p>
<p>At the outset, the key to understanding the LR algorithm boils down to this:</p>
<ul>
<li>"if (categorical) feature x = …”, then it treats the label as an output that is something like this: “label =..”.</li>
</ul>
<p class="mce-root"/>
<ul>
<li>Speaking of categorical features, we may want to understand the relationship between two or more of them in the breast cancer dataset. In addition, we are also interested in building LR ML models as an efficient data <span>inference to derive the concurrent effects of </span><span>multiple categorical variables.</span></li>
</ul>
<p><span><span>In the next section, we will present you with a high-level overview of the LR technique.</span></span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Salient characteristics of LR</h1>
                </header>
            
            <article>
                
<p><span>The following table lists the salient characteristics of LR:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/bf9cb42f-114d-4898-a245-e45c8ae6e1cf.png" style="width:30.17em;height:29.58em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>LR at a glance</span></div>
<div class="packt_infobox"><span>The regression or classification model that we implement for the pipeline in this chapter is a specialized type of a generalized linear regression model called <strong>binary logistic regression</strong></span>.</div>
<p>Before we talk about binary logistic regression, we will take a step back, refer back to <a href="4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml">Chapter 1</a>, <em>Predict the Class of a Flower from the Iris Dataset</em>, and remind ourselves of the different types of variables. One such variable type is that of a response variable, a variable whose changes are explained by a so-called explanatory variable. An explanatory variable is plotted on the <em>x </em>axis of a scatter plot, whereas the response variable plotted on the <em>y</em> axis is dependent on the former. The following diagram is an example of a scatter plot that, though not directly relevant to this chapter, has some significance:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/9ba8a82f-d08d-44a3-9cdd-1e93c471ebd2.jpg" style="width:34.08em;height:34.25em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">A scatter plot example</div>
<p class="mce-root"/>
<p>Going one step further, we get into the topic of linear regression. This type of prediction model takes a bunch of explanatory categorical values as hyperparameters that play a direct role in predicting expected response variable values. What are the odds of our response variable taking on a certain value? Those odds are represented in mathematical terms, which is a probability model that translates to a predictor function. A function like this does two things:</p>
<ul>
<li>Accepts more than one explanatory (or input) variable feature measurement</li>
<li>Models the probabilities of response variables</li>
</ul>
<p>Before we apply all of this to our breast cancer dataset, we will cite a (fictitious) example of a mathematics program admission process from the Case Western Reserve University. This process can be described in terms of the following points:</p>
<ul>
<li>It is supposed to be a fair, nondiscriminatory process, one that admits students coming from various categories or groups to academic programs.</li>
<li>An admission process predictor model would predict the probability of the successful (or not) admission of a student, given that they belong to a certain gender, race, or economic background.</li>
<li>An important question to pose is what are the odds of student A being successfully admitted into this program? In other words, how do we come up with a <kbd>StudentAdmission</kbd> predictor function (model) that will predict the odds of the <kbd>admission status</kbd> response variable taking a specific value?</li>
<li>The <kbd>StudentAdmission</kbd> model receives a group of explanatory variables. This group consists of independent variables representing some characteristics of the individual. These are multiple feature measurements. Some features can include gender, race, income group, and many more.</li>
</ul>
<p>All that being said, we want to know how binary logistic regression finds its niche as an extension of the linear regression model approach. Two examples of usage are described as follows:</p>
<ul>
<li>Consider, for example, that a binary logistic regression model simply predicts whether an incident (an event) took place or not. A researcher with earthquake data is interested in analyzing whether an earthquake is bound to happen sometime in the future. This kind of response variable is <strong>discrete</strong>. In other words, it is noncontinuous, static, or a one-time limited occurrence.</li>
</ul>
<ul>
<li>The university admission process could be modeled as a binary logistic regression model, one that involves more than one explanatory variable or course. This model will predict the odds (or probability) of the response variable (<kbd>admission status</kbd>) taking a certain value. Taking this a step further, the predicted discrete value in the student admission process is a value of either <kbd>0</kbd> or <kbd>1</kbd>. </li>
</ul>
<p>Next, we will list assumptions that will help us formulate a logistical regression task. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Binary logistic regression assumptions</h1>
                </header>
            
            <article>
                
<p>Here are some assumptions that are made for a binary logistic regression classification task:</p>
<ul>
<li>The dependent variable should be<span> </span><span>dichotomous, representing mutually exclusive states. </span>There is more than one independent predictor variable.</li>
<li>Correlations<span> </span>between predictor <span>variables are </span>represented by the elements of a<span> </span><span>correlation matrix.</span> <span>They can be no higher than </span>0.9.</li>
<li>Outliers must be absent. Outlier presence or absence can be determined by transforming predictors into standardized statistical scores.</li>
</ul>
<p>The only dataset that is relevant to us in this chapter is the breast cancer dataset. This is a classification task whose analysis solution will be a binary logistic regression. Before we get to that, we will present this as a much simpler dataset to illustrate the following:</p>
<ul>
<li>Independent variables</li>
<li>Dependent variables</li>
<li>Correlation matrix</li>
</ul>
<p>In the next section, we will illustrate the bottom line of linear regression with a fictitious example from a survey on males and their luck with snagging the next date.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">A fictitious dataset and LR</h1>
                </header>
            
            <article>
                
<p>Here, we are going to present you with a fictitious dataset to merely present our case on LR so that it can be a candidate for our breast cancer dataset classification task.</p>
<p>The following example lists data that has been created by a dating website about male singles. Listed in the table is a dependent variable that represents whether the guy was lucky, which means they were able to work up to a second date with the same person within a week after the first date.</p>
<p>There are two independent variables, and they are as follows:</p>
<ul>
<li>Did the guy attend a dating workshop to firm up his dating skills?</li>
<li>The second variable measures the guy's desperation on a desperation scale. The higher the score, the more desperate the guy is, with 100 being the most desperate.</li>
</ul>
<p>The following dating survey table tabulates data pertaining to the dating logistical regression problem:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/7cf47e02-461d-4b78-9e7a-5711946ce0c3.jpg" style="width:30.75em;height:39.83em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Logistical regression example</div>
<p class="mce-root"/>
<p>An inspection of the dataset tells us that a little more than half of all single guys have had a second date in less than a week. This is assuming that the dating survey company does not possess any other background data on these singles and is applying the best techniques in this (fictitious) dating help industry. </p>
<p>Now, we want to know whether those in the <strong>Workshop</strong> group are more likely to have another date. Looking at the fourth column, <strong>Cool</strong>, greater coolness translates to a better chance of a second date:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/bf651e9a-b4df-4e18-bd02-f488fe9126b4.jpg" style="width:33.75em;height:18.75em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Correlation coefficient table</div>
<p>Looking at the table for  <strong>Correlation Coefficients</strong>, those men not in the <strong>Workshop</strong> were less likely to have another date and those with a higher <strong>Cool</strong> factor were more likely to have a second date.</p>
<p>A logistical regression applied on this dataset would have the following:</p>
<ul>
<li>Response (dependent) variable: <strong>Date</strong></li>
<li>Levels of measurement: <strong>Mean</strong> and <strong>standard deviation</strong></li>
<li>Regression function: <strong>Logistic</strong> or <strong>logit</strong></li>
<li>Total number of feature rows: <strong>20</strong></li>
</ul>
<p class="mce-root"/>
<p>At this point, we have given you a better understanding of LR. We will wade deeper into this topic in the next section. We talked about response variables and correlation coefficients, otherwise known as dichotomous variables, and got a good handle on all of these. However, we have not yet formulated the LR model in mathematical terms. We want to know if using linear regression for building a model is appropriate for the breast cancer classification task. As it turns out, we will not be able to apply linear regression models to the task at hand. Why we turned to LR and not linear regression is one of the points of discussion in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">LR as opposed to linear regression</h1>
                </header>
            
            <article>
                
<p>Before choosing between logistic and linear regression methods, here are a few pointers that reiterate or restate what we talked about in this chapter and <a href="4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml">Chapter 1</a>, <em>Predict the Class of a Flower from the Iris Dataset</em>:</p>
<ul>
<li>A data scientist working on their experimental data unit is seeking to build a model. Naturally, the follow-up question might be why are they interested in building an (ML) model?</li>
<li>One answer to the previous question might be that the model helps discover patterns or the underlying relationship between the predictor (explanatory or independent) variables and their response counterparts.</li>
</ul>
<p>Speaking of response variables, <span>response variables in a</span> breast cancer dataset are categorical, as opposed to other ML classification tasks where the response variables are as follows:</p>
<ul>
<li>Continuous</li>
<li>Unbounded</li>
</ul>
<p>This brings us clarity, and with it the following working hypotheses:</p>
<p>The linear regression approach for our breast cancer classification task models may not work. After all, the response variable <kbd>Y</kbd> is neither continuous unbounded, or normally distributed. Before writing off the linear regression approach for our purposes, we will attempt such a formulation anyway, and in the process, shed more light on why LR is what we really want.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Formulation of a linear regression classification model</h1>
                </header>
            
            <article>
                
<p><span>The basis for a mathematical formulation of a linear regression model may be broken down as follows:</span></p>
<ul>
<li>Left-hand side: The predicted variable.</li>
<li>Right-hand side represented by <kbd>y</kbd>: A linear construct that is made up of coefficients, a predictor (independent variable), and the arithmetic operators <kbd>+</kbd> for addition and <kbd>*</kbd> for multiplication.</li>
<li>Assuming there are four predictor variables, <kbd>PX1</kbd>, <kbd>PX2</kbd>, <kbd>PX3</kbd>, and <kbd>PX4</kbd>, each of these variables represents the so-called <kbd>X</kbd>.</li>
</ul>
<p>At the outset, we could write an equation <span>representing a linear regression model, as follows: </span></p>
<pre>//y on the Left-Hand is the predicted variable, and PX1, PX2, PX3... are predictor varibles (X)<br/>y = LR0 + (LR1 * PX1) + (LR2 * PX2) + (LR3 * PX3) + (LR4 * PX4) + ......</pre>
<p class="mce-root">There is a catch! Our new linear regression model is characterized by response variables that are actually <strong>non-dichotomous</strong>. Well, we could put up a stand and say that it is still possible to come up with an improved version of this equation, which will represent a linear regression model with dichotomous response variables. It turns out that such an improved linear model will not work in actuality, for two reasons:</p>
<ul>
<li><span>Our (dichotomous) response variables need to be arbitrarily assigned <kbd>0</kbd> and <kbd>1</kbd>. </span><span>This is because we want to represent two mutually exclusive categorical states. Those states can be either benign or malignant, respectively.</span></li>
<li>The second reason has to do with the fact that because the response variable value <kbd>Y</kbd> is categorical, the predicted value is really the probability that this variable accepts a certain value, and not the value itself.</li>
</ul>
<p>At this point, our thought process appears to be decidedly in favor of at least a regression model with dichotomous response variables, as opposed to a linear regression model. How so?</p>
<p>It may be that the model we are looking to build is a function of probabilities, an <span>LR equation, distinguished by a</span><span> left-hand-side representation of a logit of <kbd>Y</kbd> rather than <kbd>Y</kbd> itself. </span>The next section will weave the ideas presented here and build a mathematical formulation of the LR as an equation.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logit function as a mathematical equation</h1>
                </header>
            
            <article>
                
<p><span> Continuing on from where we left off in the previous section, this section is an attempt at translating those ideas and conclusions into a newer narrative. The goal of this section is to have a high-level mathematical formulation for LR.</span></p>
<p><span>However, with LR being a much more complicated case, we will formulate a simpler equation for what is known as a logit function, logit model, or logit odds.</span></p>
<p><span>Without further ado, the logit function at a high level is expressed as <kbd>Logit(p)</kbd> and can be expanded to the mean logit of the odds of</span> <kbd>Y</kbd><span>, rather than</span> <kbd>Y</kbd> <span>itself.</span></p>
<p><span>That said, here are a few mathematical concepts to help us understand and write a logit function:</span></p>
<ul>
<li><span><strong>Euler number</strong></span>:<span> </span><span>Euler number (<em>e</em>) = 2.718228183</span></li>
<li><span><strong>Natural logarithm</strong></span>: <span>I</span>f <em>e</em> can be raised to the power <em>y</em>, as in <em>e</em><em> <sup>y</sup></em><span> = <em>x</em>, then </span>the logarithm of <em>x</em> to the base <em>e</em> is <em>log<sub>e</sub></em><span>(<em>x</em>) = <em>y</em></span></li>
</ul>
<p>At this point, a formulation of the logit function becomes something like the following equation:</p>
<pre class="main">//Natural Logarithm of the probability that Y equals one of two values, perhaps 0 and 1, each taken to //represent one of two mutually exclusive states<br/>Ln[p/(1-p)] = LR0 + (LR1 * PX1) + (LR2 * PX2) + (LR3 * PX3) + (LR4 * PX4)</pre>
<p><span>Our newly-minted logit function is an equation based on the natural logarithm of the ratio of odds or probabilities. The logit function is a model, which is characterized by the following features:</span></p>
<ul>
<li>In this logit function, <kbd>Ln[p/(1-p)]</kbd>, <kbd>p/(1-p)</kbd> is called the odds of our sample being labeled as benign. For example, <kbd>Ln[p/(1-p)]</kbd> is the natural logarithm or log-odds, or simply the logit as <kbd>Ln[p/(1-p)]</kbd> varying between drop down -∞ to +<span>∞.</span></li>
<li>The logit function can be written as <kbd>fnLogistic(p) = ln(p/1-p)</kbd>, where <kbd>p</kbd> is between <kbd>0</kbd> and <kbd>1</kbd>, and where <kbd>0</kbd> and <kbd>1</kbd> are the maximum and minimum values plotted on the <em>x</em> axis, for example, <kbd>fnLogistic(0.9) = <span>2.197224577336</span></kbd>.</li>
<li><kbd>LR0</kbd>, <kbd>LR1</kbd>, <kbd>LR2</kbd>, and so on are known as m<span>odel coefficients or correlation coefficients. </span><span>These model coefficients relate to the predictor (explanatory) variable of the predicted (response) variable.</span></li>
</ul>
<ul>
<li><kbd>PX1</kbd>, <kbd>PX2</kbd>, and <kbd>PX3</kbd> are predictor variables.</li>
<li>The logit function is also a <strong>link function</strong>. It is a link function because it links the natural log of the probabilities on the left of the logit function to the linear equation made up of predictor variables and their respective coefficients.</li>
<li><kbd>p</kbd> is said to be bounded between 0 and 1, which is the case here. </li>
</ul>
<p>A typical logit function curve looks like this:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/b835b690-a0ca-4189-9417-826d70661550.jpg" style="width:27.75em;height:24.50em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Logit model graph</div>
<div class="packt_infobox">At this point, we haven't discussed LR, which is a little more complicated than the logit model.</div>
<p>An interpretation of the graph is as follows:</p>
<ul>
<li>The nonlinear graph will depict the following:</li>
<li style="padding-left: 30px"><em>x</em> axis: Logit values</li>
<li style="padding-left: 30px"><em>y</em> axis: Probabilities (or odds)</li>
<li style="padding-left: 30px">Looking at the graph, for a probability of <strong>0</strong>, the logit value is <strong>0.5</strong></li>
</ul>
<p><span>To recap, we started with linear regression and then progressed to a discussion on the logit model. Understanding what the logit function is sets the stage for LR in the context of the breast cancer classification task.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">LR function</h1>
                </header>
            
            <article>
                
<p>We said before that LR is harder than the logit function. However, the LR formulation, as we shall see, is a good fit for this problem. We want to make a prediction on the fate of a sample being either benign or malignant. In other words, a prediction on a particular breast cancer tissue sample can only take one of two mutually exclusive values, based on feature measurements such as clump thickness, uniformity of cell size, and many more. Each of these feature measurements can be <kbd>X1</kbd>, <kbd>X2</kbd>, and <kbd>X3</kbd>, respectively.</p>
<p>This brings us to the beginning of a formulation of the LR function.</p>
<p>The core concept behind the LR function is the so-called inverse function, which is written down as:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/ca1342bb-fb83-4473-8ba0-5a38a02994ba.png" style="width:5.58em;height:2.33em;"/></div>
<p>Here is a brief interpretation of the preceding equation:</p>
<p><strong>p</strong> in the preceding equation is simply a function of feature measurements of breast cancer samples represented by <kbd>X1</kbd>, <kbd>X2</kbd>, <kbd>X3</kbd>, and many more.</p>
<p>Rewriting <strong>p</strong> as <kbd>fLogistic(X1,X2,..)</kbd>, we have a complete function definition as follows:</p>
<pre>fLogistic(X1,X2,X3,..) = LR0 + (LR1 * PX1) + (LR2 * PX2) + (LR3 * PX3) +  ...</pre>
<p>It turns out that the logit function we discussed earlier and our logistic regression function are inverses of each other.</p>
<p>Important points to remember about logistic regression are as follows:</p>
<ul>
<li>There is a dichotomous response variable representing the odds of an outcome occurring or not</li>
<li>A non-linear relationship between:</li>
<li style="padding-left: 30px">The categorical input (independent feature measurements) values plotted on the <em>x</em> axis. These are also known as predictor variables.</li>
<li style="padding-left: 30px">The probabilities on the <em>y</em>-axis. These are predicted values.</li>
<li style="padding-left: 30px">Very important: The coefficients <kbd>LR0</kbd>, <kbd>LR1</kbd>, and <kbd>LR2</kbd> are computed from our training dataset. Our training dataset has known or predetermined input measurements and output labels.</li>
</ul>
<p><span>At this point, we have what we need to switch focus to the Spark ML API for an implementation of the LR mathematical model that we just discussed.</span></p>
<p>In the next section, we will build two data pipelines:</p>
<ul>
<li>A pipeline using the Random Forests algorithm</li>
<li> A pipeline using the LR method</li>
</ul>
<p>We are familiar with Random Forests from <a href="4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml">Chapter 1, </a><em>Predict the Class of a Flower from the Iris Dataset</em>. LR is a proven method that is backed by established statistical techniques that ML has found very handy for solving binary classification problems.</p>
<p><span>The following <em>Getting started</em> section will get you started with the implementation process.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting started</h1>
                </header>
            
            <article>
                
<p>The best way to get started is by understanding the bigger picture—gauging the magnitude of the work ahead of us. In this sense, we have identified two broad tasks:</p>
<ul>
<li>Setting up the prerequisite software.</li>
<li>Developing two pipelines, starting with data collection and building a workflow sequence that could end with predictions. Those pipelines are as follows:</li>
<li style="padding-left: 30px">A Random Forests pipeline</li>
<li style="padding-left: 30px">A logistical regression pipeline</li>
</ul>
<p>We will talk about setting up the prerequisite software in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setting up prerequisite software</h1>
                </header>
            
            <article>
                
<p>First, please refer back to the <em>Setting up the prerequisite software</em> section in <a href="4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml">Chapter 1</a>, <em>Predict the Class of a Flower from the Iris Dataset</em>, to review your existing infrastructure. If need be, you might want to install everything again. The chances of you having to substantively change anything are slim.</p>
<p class="mce-root"/>
<p>However, here are the upgrades I recommend:</p>
<ul>
<li>JDK upgrade to 1.8.0_172, if you have not already done so</li>
<li>Scala from 2.11.12 to an early stable version of 2.12</li>
<li>Spark 2.2 to 2.3 where 2.3, is a major release with numerous bug fixes, which is why hence it is recommended</li>
</ul>
<p>At the time of writing this book, Java 9 and 10 don't appear to work with Spark. That might change. For the purposes of this chapter, your local Spark shell will be the development environment of choice.</p>
<p>With the prerequisites out of the way, we are ready to jump right into developing pipelines. This journey starts in the <em>Implementation objectives</em> section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation objectives</h1>
                </header>
            
            <article>
                
<p>We fulfilled our implementation objectives for <a href="4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml">Chapter 1</a>, <em>Predict the Class of a Flower from the Iris Dataset</em>. In that chapter, early on, we developed the beginnings of a workflow process. This is depicted in the following diagram, which will help us frame the implementation objectives for this chapter as well:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/1ae72d8d-a9ba-4d16-88f5-cebbd65d6a66.png" style="width:36.75em;height:17.50em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Stages in a preliminary workflow</div>
<p class="mce-root"/>
<p>Since the current chapter also deals with a multiclass classification task like the one before it, the four boxes that are shown in the preceding diagram are our guide to setting up implementation objectives for this chapter. The broad high-level objectives are: </p>
<ul>
<li>A <strong>Data Collection</strong> step followed by an <strong>Exploratory Data Analysis</strong> (<strong>EDA</strong>) step</li>
<li>A <strong>Data Cleaning</strong>/<strong>Preprocessing</strong> step</li>
<li>Handing off data to an algorithm; there are models to be trained (fitted) and predictions to be generated</li>
</ul>
<p>This paves the way for a more complete list of implementation objectives, and they are:</p>
<ul>
<li>Getting the breast cancer dataset from the UCI Machine Learning Repository.</li>
<li>Deriving a dataframe for EDA.</li>
<li>Carrying out preliminary EDA i<span>n the Sandbox Zeppelin Notebook environment</span> (or Spark shell), and running a statistical analysis.</li>
<li>Developing the pipeline incrementally in Zeppelin and porting the code into IntelliJ. What this means is the following:</li>
<li style="padding-left: 30px">Creating a new Scala project in IntelliJ, or importing an existing empty project into IntelliJ, and <span>creating Scala artifacts from c</span>ode that was incrementally developed in the Notebook</li>
<li style="padding-left: 30px">Do not forget to wire up all the necessary dependencies in the <kbd>build</kbd> file</li>
</ul>
<ul>
<li>Interpreting the results of the pipeline:</li>
<li style="padding-left: 30px">How well did the classifier perform?</li>
<li style="padding-left: 30px">How close are the predicted values to those in the original dataset?</li>
</ul>
<p>Now, we will start working on these implementations one by one, starting with getting the Wisconsin Breast Cancer Data Set from the UCI Machine Learning Repository.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation objective 1 – getting the breast cancer dataset</h1>
                </header>
            
            <article>
                
<p>Head over to the UCI Machine Learning Repository website at <a href="https://archive.ics.uci.edu/ml/datasets/bcw">https://archive.ics.uci.edu/ml/datasets/bcw</a> and download the <kbd>Data</kbd> folder by clicking on <span class="packt_screen">Data Folder</span>. Extract this folder someplace convenient and copy <kbd>bcw.csv</kbd> into the root of your project folder, which we will call <kbd>Chapter2</kbd>. At this point, <kbd>Chapter2</kbd> will be empty.</p>
<p class="mce-root"/>
<p class="mce-root">You may refer back to the project overview for an in-depth description of the breast cancer dataset. We depict the contents of the <kbd>bcw.data</kbd> file here as follows:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/6fc9f404-d847-4dfe-94a9-049f4b0af745.jpg" style="font-size: 1em;width:15.08em;height:44.00em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>A snapshot of the breast cancer dataset with 699 rows</span></div>
<p><span>The breast cancer dataset that we just downloaded is multivariate, meaning it includes a set of more than one independent variable.</span> Before performing any <span>EDA on it, we need to create an abstraction over the dataset, which we call a d</span>ataframe<span>. </span>How we create a dataframe as a prelude to EDA is the goal of the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation objective 2 – deriving a dataframe for EDA</h1>
                </header>
            
            <article>
                
<p>We downloaded the Wisconsin Breast Cancer data file into the <kbd>Chapter2</kbd> folder and renamed it <kbd>bcw.csv</kbd>. The process of <kbd>DataFrame</kbd> creation starts with loading the data.</p>
<p>We will invoke the <kbd>read</kbd> method on <kbd>SparkSession</kbd> as follows:</p>
<pre><strong>scala&gt; val dfReader1 = spark.read </strong><br/><strong>dfReader1: org.apache.spark.sql.DataFrameReader = org.apache.spark.sql.DataFrameReader@3d9dc84d</strong></pre>
<p>The <kbd>read</kbd> method that has been returned <span>produces <kbd>DataFrameReader</kbd>. </span>Because our dataset is a CSV file, we want to tell Spark about it by invoking the <kbd>format</kbd> method on <kbd>DataFrameReader</kbd> by passing in the <kbd>com.databricks.spark.csv</kbd> format specifier string:</p>
<pre><strong>scala&gt; val dfReader2 = dfReader1.format("com.databricks.spark.csv")</strong><br/><strong>dfReader2: org.apache.spark.sql.DataFrameReader = org.apache.spark.sql.DataFrameReader@3d9dc84d</strong></pre>
<p>At this point, <kbd>DataFrameReader</kbd> needs an input data source option in the form of a key-value pair. Invoke the <kbd>option</kbd> method with two arguments, a key <kbd>"header"</kbd> of type string and its value <kbd>true</kbd> of type Boolean:</p>
<pre><strong>scala&gt; val dfReader3 = dfReader2.option("header", true)</strong><br/><strong>dfReader3: org.apache.spark.sql.DataFrameReader = org.apache.spark.sql.DataFrameReader@3d9dc84d</strong></pre>
<p>Next, the code is invoking the <kbd>option</kbd> method again (on the <kbd>DataFrameReader)</kbd> with an argument called <kbd>inferSchema</kbd> and a <kbd>true</kbd> value. With the <kbd>inferSchema</kbd> method call, we want Spark to figure out the schema of our input data source and return our <kbd>DataFrameReader</kbd>:</p>
<pre class="mce-root"><strong>scala&gt; val dfReader4 = dfReader3.option("inferSchema", true)</strong><br/><strong>dfReader4: org.apache.spark.sql.DataFrameReader = org.apache.spark.sql.DataFrameReader@3d9dc84d</strong></pre>
<p><span>Next, load <kbd>bcw.csv</kbd> by invoking the <kbd>load</kbd> method and passing it to the path to the dataset file. External data sources such as our dataset require a path for Spark to be able to load the data so that <kbd>DataFrameReader</kbd> can process the file and return the <kbd>DataFrame</kbd>, as follows:</span></p>
<pre><strong>scala&gt; val dataFrame = dfReader4.load("\\bcw.csv")</strong><br/><strong>dataFrame: org.apache.spark.sql.DataFrame = [id: int, clump_thickness: int ... 9 more fields]</strong></pre>
<p class="mce-root"/>
<p>We now have a breast cancer dataframe! This completes the <em>Implementation objective 2 – deriving a dataframe for EDA</em> section. Our next step is to run a preliminary statistical analysis. </p>
<p>Finally, before we move on to the next step, here is a view of the dataframe:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/cd772ab5-cd71-410d-8bd1-748be5055d54.jpg" style="width:58.33em;height:19.75em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Dataframe with raw data</div>
<p><span>It looks like we have data in our <kbd>DataFrame</kbd></span>, which is now <span>ready for EDA.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 1 – conducting preliminary EDA </h1>
                </header>
            
            <article>
                
<p><span>At this point, we will perform a fairly simple statistical analysis on our dataset. This will provide us with useful, though preliminary, statistical insights such as m</span>ean, median<span>, r</span><span>ange, and s</span><span>tandard deviation, to name a few.</span></p>
<p><span>To proceed with the preliminary EDA, let's invoke the <kbd>describe</kbd> method with the required column names as parameters. This will give us a new <kbd>DataFrame</kbd> called <kbd>stats</kbd>. Invoking a <kbd>show</kbd> method on <kbd>stats</kbd> will produce a table of statistical results as follows:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/f92ee6f5-15cb-4485-b4d3-ac9030619620.jpg" style="width:59.08em;height:12.08em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Statistical analysis</div>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Although the output is ugly to look at and is mangled, we see statistical numbers such as the <kbd>count</kbd>, <kbd>mean</kbd>, standard deviation, minimum, and maximum. Yes, the dataset has 699 rows of continuous, discrete (or categorical) values.</p>
<p>Now that the preliminary exploratory data analysis is complete, we proceed to the next step, where we will load the dataset into Spark.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 2 – loading data and converting it to an RDD[String]</h1>
                </header>
            
            <article>
                
<p>In this step, we will load the data again, but in a slightly different manner. The goal of this phase of the data analysis is to produce a <kbd>DataFrame</kbd> where the data has been read into an <kbd>RDD[String]</kbd>. First, we will need a path to the dataset:</p>
<pre><strong>scala&gt; val dataSetPath = "C:\\Users\\Ilango\\Documents\\Packt\\DevProjects\\Chapter2\\"</strong><br/><strong>dataSetPath: String = C:\Users\Ilango\Documents\Packt\DevProjects\Chapter2\</strong></pre>
<p><span>We have just created <kbd>dataSetpath</kbd>. In the following code, we will pass the path to the dataset into the <kbd>textFile</kbd> method:</span></p>
<pre><strong>scala&gt; val firstRDD = spark.sparkContext.textFile(dataSetPath + "\\bcw.csv")</strong><br/><strong>firstRDD: org.apache.spark.rdd.RDD[String] = C:\&lt;&lt;path to your dataset file&gt;&gt;</strong><br/><strong> MapPartitionsRDD[1] at textFile at &lt;console&gt;:25</strong></pre>
<p>The <kbd>textFile</kbd> method returned an <kbd>RDD[String]</kbd>. To check if data was loaded into the RDD, we need to invoke the <kbd>first</kbd> method on <kbd>firstRDD</kbd> to give us the <kbd>header</kbd> content. We will leave this as an exercise for the reader.</p>
<p><span>Next, we want to know the number of partitions in our RDD:</span></p>
<pre><strong>scala&gt; firstRDD.getNumPartitions</strong><br/><strong>res7: Int = 2</strong></pre>
<p> The <kbd>getNumPartitions</kbd> method returned the number of partitions in <kbd>firstRDD</kbd>.  Since an RDD allows us to work with data at a low level, we will continue to reorganize and massage this data as required.</p>
<p>In the next step, we want to inspect the RDD. We want to reorganize and repackage data into arrays. </p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 3 – splitting the resilient distributed dataset and reorganizing individual rows into an array</h1>
                </header>
            
            <article>
                
<p>To split the dataset, we will start with the RDD partitions. It is helpful to think of an RDD partition in the following manner.</p>
<p>Each partition can be visualized as one long string <span>consisting of rows of data separated by <kbd>"\n"</kbd>. </span>We want to break down this long string into its constituent string, by splitting them along the <kbd>"\n"</kbd> separator. Shortly, we will try a <kbd>flatMap</kbd> operation on our RDD, <kbd>firstRDD</kbd>. Each constituent string is a <kbd>Row</kbd> that represents a row in the original dataset.</p>
<p>We will do <kbd>flatMap</kbd> and pass to it an anonymous function, which will be invoked on rows separated by a <kbd>"\n"</kbd> character, as follows:</p>
<pre class="mce-root"><strong>scala&gt; val secondRDD = firstRDD.flatMap{ row =&gt; row.split("\n").toList }</strong><br/><strong>secondRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[33] at flatMap at &lt;console&gt;:27</strong></pre>
<p><span> The preceding code does a <kbd>flatMap</kbd> flattening operation, resulting in the creation of a new <kbd>RDD[String]</kbd> that will hold all of these strings (each string is a row in our dataset). </span>At this point, we will <kbd>split</kbd> (along the comma between individual characters of that row) a <kbd>String</kbd> producing an <kbd>RDD[Array[String]]</kbd>:</p>
<pre class="mce-root"><strong>scala&gt; val rddArrayString = secondRDD.map(_.split(","))</strong><br/><strong>rddArrayString: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[34] at map at &lt;console&gt;:29</strong></pre>
<p>The <kbd>RDD[Array[String]]</kbd> naturally implies that the RDD contains more than one <kbd>Array[String]</kbd>. How many of these arrays are in this RDD? </p>
<pre><strong>scala&gt; rddArrayString.count</strong><br/><strong>res9: Long = 700</strong></pre>
<p>Invoking <kbd>count</kbd> on our RDD returns an array count of <kbd>700</kbd>, which is what it should be.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 4 – purging the dataset of rows containing question mark characters</h1>
                </header>
            
            <article>
                
<p>Before we go any further, let's eyeball the raw dataset again. If you looked closely, you will notice that the dataset contains a <kbd>?</kbd> character in some places. Actually, this character starts appearing in some rows in the seventh column, starting on the 25<sup>th</sup> row. The 25<sup>th</sup> row, with the <kbd>?</kbd> character, is displayed in the following diagram. That them is a problem,<span> which needs a solution.</span></p>
<div class="packt_infobox">Sometimes, a visual inspection of the dataset can reveal the presence of extraneous characters.</div>
<p>The following is a snapshot of the Wisconsin Breast Cancer Data Set with the <kbd>?</kbd> character in the 25<sup>th</sup> row and the sixth column:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/fb958bd9-a451-4a2e-a353-2116ffe8bb41.jpg" style="width:16.50em;height:27.67em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Dataset showing ? characters</div>
<p><span> </span></p>
<p><span>Obviously, it is not just</span> row 25<sup>th</sup> that has a <kbd>?</kbd> character. There are likely other rows with the <span>extraneous <kbd>?</kbd></span><span> character that needs to be purged.</span> One solution appears to be to <span>invoke a <kbd>filter</kbd> operation on our <kbd>rddArrayString</kbd></span>:</p>
<pre class="mce-root"><strong>scala&gt; val purgedRDD = rddArrayString.filter(_(6) != "?")</strong><br/><strong>purgedRDD: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[35] at filter at &lt;console&gt;:31</strong></pre>
<p><span>As evident from the preceding code, we just ran the <kbd>filter</kbd> operation, which returned a new <kbd>RDD[Array[String]</kbd> that we called <kbd>purgedRDD</kbd></span>. <span>Naturally, we may want to count the number of rows left in the dataset that we believe are relevant for data analysis. That is the goal of the next section.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 5 – running a count after purging the dataset of rows with questionable characters</h1>
                </header>
            
            <article>
                
<p>We will now run <kbd>count</kbd> on our new <kbd>purgedRDD</kbd>: </p>
<pre><strong>scala&gt; purgedRDD.count</strong><br/><strong>res12: Long = 684</strong></pre>
<p>So, in the preceding code, we invoked the <kbd>count</kbd> method on <kbd>purgedRDD</kbd>. Spark returned a value of <kbd>684</kbd>. Apparently, 16 rows contained <kbd>?</kbd> characters. After all, many datasets like this one need a preprocessing step or two. For now, we will proceed with the next steps in data analysis, secure in the knowledge that Spark will probably not report an error, especially at the point where we want a new two-column <kbd>DataFrame</kbd> containing a consolidated feature vector.</p>
<p><span><span>In the next section, we are going to get rid of <kbd>header</kbd></span></span>. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 6 – getting rid of header</h1>
                </header>
            
            <article>
                
<p><span>Each of the inner arrays shown earlier holds rows that represent feature measurements, and a row representing the dataset <kbd>header</kbd>. The following line of code converts our RDD into an <kbd>Array</kbd></span>, <span>containing arrays that themselves contain rows as strings: </span></p>
<pre class="mce-root"><strong>//Drop the Array with the headers in it</strong><br/><strong>scala&gt; val headerRemoved = <span>cleanedRDD.collect</span>.drop(1)</strong><br/><strong>headerRemoved: Array[Array[String]] </strong></pre>
<p><span>The <kbd>drop</kbd> method got rid of <kbd>header</kbd></span>. <span>Next, we will move on and create a new <kbd>DataFrame</kbd></span>.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 7 – creating a two-column DataFrame</h1>
                </header>
            
            <article>
                
<p>We are close. In this section, the goal is to create an input feature vector, and the steps are listed as follows:</p>
<ol>
<li>Import the <kbd>Vectors</kbd> class.</li>
<li>Inside the <kbd>map</kbd> operation on the <kbd>Array</kbd>, we will iterate over each row of our header-free dataset. Then, we transform each row in turn, operating on every single column containing predetermined cell nuclei measurements. These columns are converted to doubles by using the <kbd>dense</kbd> method.</li>
<li>The <kbd>map</kbd> operation processes the entire dataset and produces <kbd>featureVectorArray,</kbd> a structure of type <kbd>Array[(Input Feature Vector, String representing the Class)]</kbd>:</li>
</ol>
<pre class="mce-root" style="padding-left: 90px"><strong>//Step 1</strong><br/><strong>scala&gt; import org.apache.spark.ml.linalg.Vectors</strong><br/><strong>import org.apache.spark.ml.linalg.Vectors</strong><br/><br/><strong>//Step 2</strong><br/><strong>scala&gt; val featureVectorArray = headerRemoved.map(row =&gt; (Vectors.dense(row(1).toDouble,..,row(10)))</strong><br/><strong>featureVectorArray: Array[(org.apache.spark.ml.linalg.Vector, String)]</strong> </pre>
<p><span>Okay, we created <kbd>featureVectorArray</kbd>, an <kbd>Array</kbd> consisting of a set of <kbd>(Vector, String)</kbd> tuples. This <kbd>Array</kbd> is now </span>ready to be converted into <kbd>DataFrame</kbd>. That is the goal of the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 8 – creating the final DataFrame</h1>
                </header>
            
            <article>
                
<p><span><span>The goal of this section is to create a final version of our analysis-ready <kbd>DataFrame</kbd></span></span>. <span><span>The</span></span> <kbd>createDataFrame</kbd> method available on <kbd>SparkSession</kbd> is suitable, and is shown as follows:</p>
<pre class="mce-root"><strong>scala&gt; val dataFrame = spark.createDataFrame(featureVectorArray)</strong><br/><strong>dataFrame: org.apache.spark.sql.DataFrame = [_1: vector, _2: string]</strong><br/><br/><strong>//display the first 20 rows of the new DataFrame 'dataFrame'</strong><br/><strong>//Readers are requested to run the show command and see what the contents are, as an exercise</strong><br/><strong>scala&gt; dataFrame.show</strong><br/><strong>+--------------------+---+</strong><br/><strong>| _1| _2|</strong><br/><strong>+--------------------+---+</strong><br/><strong>|------------------------</strong><br/><strong>|-----------------------</strong><br/><strong>|----------------------</strong><br/><strong>|-----------------------</strong><br/><strong>Displaying 20 rows..</strong></pre>
<p><span> As seen earlier, the new <kbd>DataFrame</kbd> has two columns, which are not very readable named <kbd>_1</kbd> and <kbd>_2</kbd>. </span></p>
<p>What we want is a renamed <kbd>DataFrame</kbd> with two readable columns as follows:</p>
<ul>
<li> A feature vector column that is named <kbd>bc-diagnosis-label-column</kbd> and a target variable label column named <kbd>bc-indexed-category-column</kbd>.</li>
<li>By the way, a target variable in ML terminology denotes what is being predicted. For example, it could be a <kbd>0</kbd> for benign or <kbd>1</kbd> for malignant. Since a target variable is associated with the output, it can also be termed an outcome or output variable. Defining a target variable is an integral part of the binary classification model creation step; a target variable in statistics terminology is the same as a response variable.</li>
</ul>
<p> To get a renamed <kbd>DataFrame</kbd>, we will transform it a little, and we will do this by creating two methods as follows:</p>
<pre class="mce-root"><strong>//Features column</strong><br/><strong>scala&gt; def bcFeatures = "bc-diagnosis-label-column"</strong><br/><strong>bcFeatures: String</strong><br/><br/><strong>//unindexed label column</strong><br/><strong>scala&gt; def bcDiagCategory = "bc-indexed-category-column"</strong><br/><strong>bcDiagCategory: String</strong></pre>
<p>In the following line of code, invoke the <kbd>toDF</kbd> method:</p>
<pre class="mce-root"><strong>;scala&gt; val dataFrame2 = dataFrame.toDF(bcFeatures, bcDiagCategory)</strong><br/><strong>dataFrame2: org.apache.spark.sql.DataFrame = [bc-diagnosis-label-column: vector, bc-indexed-category-column: string]</strong></pre>
<p class="mce-root"/>
<p><span>Invoking the <kbd>toDF</kbd> method creates a <kbd>DataFrame</kbd> with the desired column names. Invoking <kbd>show</kbd> on <kbd>dataFrame2</kbd> will result in the following display:</span></p>
<pre class="mce-root"><strong>scala&gt; dataFrame2.show</strong><br/><strong>+-------------------------+--------------------------+</strong><br/><strong>|bc-diagnosis-label-column|bc-indexed-category-column|</strong><br/><strong>+-------------------------+--------------------------+</strong><br/><strong>| --------------------| 2|</strong><br/><strong>| --------------------| 2|</strong><br/><strong>| --------------------| 2|</strong><br/><strong>| --------------------| 2|</strong><br/><strong>| --------------------| 2|</strong><br/><strong>| --------------------| 4|</strong><br/><strong>| --------------------| 2|</strong><br/><strong>| --------------------| 2|</strong><br/><strong>| --------------------| 2|</strong><br/><strong>| --------------------| 2|</strong><br/><strong>| -----------------------</strong><br/><strong>| ------------------------</strong><br/><strong>| ------------------------</strong><br/><strong>| ------------------------</strong><br/><strong>| ------------------------</strong><br/><strong>| ------------------------</strong><br/><strong>| ------------------------</strong><br/><strong>| ------------------------</strong><br/><strong>| ------------------------</strong><br/><strong>| -----------------------</strong><br/><strong>+-------------------------+--------------------------+</strong><br/><strong>only showing top 20 rows</strong></pre>
<p><span>The preceding listing confirms that the <kbd>DataFrame</kbd> you wanted is what you got. In the next section, we will use this <kbd>DataFrame</kbd> to build a data pipeline with two algorithms:</span></p>
<ul>
<li>The Random Forest algorithm</li>
<li>LR</li>
</ul>
<p>We will build a Random Forest pipeline first. </p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Random Forest breast cancer pipeline</h1>
                </header>
            
            <article>
                
<p>A good way to start this section off is to download the <kbd>Skeleton</kbd> SBT project archive file from the <kbd>ModernScalaProjects_Code</kbd> folder. Here is the structure of the <kbd>Skeleton</kbd> project:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/1d7e9856-8def-4c5a-b296-ce02f3458bec.jpg" style="width:34.42em;height:18.83em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Project structure</span></div>
<p><span>Instructions to readers: </span><span>Copy and paste the file into a folder of your choice before extracting it. Import this project into IntelliJ, drill down to the package <kbd>"com.packt.modern.chapter"</kbd>, and rename it <kbd>"com.packt.modern.chapter2"</kbd>. If you would rather choose a different name, choose something appropriate. The breast cancer pipeline project is already set up with <kbd>build.sbt</kbd>, <kbd>plugins.sbt</kbd>, and <kbd>build.properties</kbd>. You only need to make appropriate changes to the organization element in <kbd>build.sbt</kbd>. Once these changes are done, you are all set for development. For an explanation of dependency entries in <kbd>build.sbt</kbd>, please refer back to <a href="4d645e21-43b1-49dd-99ad-4059360bfc15.xhtml">Chapter 1</a>, <em>Predict the Class of a Flower from the Iris Dataset</em>. Unless we introduce new dependencies for this project, we will stick with the <kbd>build.sbt</kbd> that came bundled in the <kbd>Skeleton</kbd> project.</span></p>
<p>All that being said, we will now start the implementation. The first step will be to create Scala code files in IntelliJ. Note that the complete code is available in your downloaded folder, <kbd>ModernScalaProjects_Code</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 1 – creating an RDD and preprocessing the data</h1>
                </header>
            
            <article>
                
<p class="mce-root">Create a Scala file called <kbd>BreastCancerRfPipeline.scala</kbd> in the <kbd>com.packt.modern.chapter2</kbd> package. Up until now, we relied on <kbd>SparkSession</kbd> and <kbd>SparkContext</kbd>, which are what <kbd>spark-shell</kbd> gave us. We need to create our <kbd>SparkSession</kbd> now, which will give us <kbd>SparkContext</kbd>.<br/>
In <kbd>BreastCancerRfPipeline.scala</kbd>, after the package statement, place the following import statements:</p>
<pre class="mce-root">import org.apache.spark.sql.SparkSession</pre>
<p> Create a <kbd>SparkSession</kbd> inside a trait, which we shall call <kbd>WisconsinWrapper</kbd>:</p>
<pre class="mce-root"><span>lazy val session: SparkSession = { SparkSession .builder() .master("local") .appName("breast-cancer-pipeline") .getOrCreate()</span></pre>
<p class="mce-root">Just one <kbd>SparkSession</kbd> is made available to all classes extending from <kbd>WisconsinWrapper</kbd>. Create <kbd>val</kbd> to hold the <kbd>bcw.csv</kbd> file path:</p>
<pre class="mce-root">val dataSetPath = "&lt;&lt;path to folder containing your Breast Cancer Dataset file&gt;&gt;\\bcw.csv"</pre>
<p class="mce-root">Create a method to build the <kbd>DataFrame</kbd>. This method takes in the complete path to the breast cancer dataset as a <kbd>String</kbd> and returns <kbd>DataFrame</kbd>:</p>
<pre class="mce-root">def buildDataFrame(dataSet: String): DataFrame</pre>
<p class="mce-root">Import the <kbd>DataFrame</kbd> class by updating the previous <kbd>import</kbd> statement for <kbd>SparkSession</kbd>:</p>
<pre class="mce-root">import org.apache.spark.sql.{DataFrame, SparkSession}</pre>
<p class="mce-root">Create a nested function inside <kbd>buildDataFrame</kbd> to process the raw dataset. Name this function <kbd>getRows</kbd>. The <kbd>getRows</kbd> function takes no parameters but returns <kbd>Array[(Vector, String)]</kbd>. The <kbd>textFile</kbd> method on the <kbd>SparkContext</kbd> variable processes <kbd>bcw.csv</kbd> into <kbd>RDD[String]</kbd>:</p>
<pre class="mce-root">val result1: Array[String] = session.sparkContext.textFile(&lt;&lt;path to bcw.csv represented by the dataSetPath variable&gt;&gt;)</pre>
<p class="mce-root">The resulting RDD contains two partitions. Each partition, in turn, contains rows of strings separated by a newline character, <kbd>"\n"</kbd>. Each row in the RDD represents its original counterpart in the raw data.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mce-root">In the next step, we will preprocess this RDD; this entails creating a single consolidated input <kbd>features</kbd> column out of the original four feature columns. We start this process by invoking <kbd>flatMap</kbd> and passing a function block to it. After successive transformations, which are listed in the following code, we should be able to create an array of type <kbd>Array[(org.apache.spark.ml.linalg.Vector, String)]</kbd>. </p>
<p class="mce-root"><kbd>Vector</kbd>, in this case, represents a row of feature measurements. The Scala code to give us <kbd>Array[(org.apache.spark.ml.linalg.Vector, String)]</kbd> is as follows:</p>
<pre class="mce-root">val result2: RDD[String] = result1.flatMap { partition =&gt; partition.split("\n").toList }<br/>val result3: RDD[Array[String]] = result2.map(_.split(","))</pre>
<p class="mce-root">Next, drop the <kbd>header</kbd> column, but not before performing a <kbd>collect</kbd> that returns an <kbd>Array[Array[String]]</kbd>:</p>
<pre class="mce-root">val result4: Array[Array[String]] = result3.collect.drop(1)</pre>
<p class="mce-root">The <kbd>header</kbd> column is now eliminated. We will now import the <kbd>Vectors</kbd> class:</p>
<pre class="mce-root">import org.apache.spark.ml.linalg.Vectors</pre>
<p class="mce-root">Now, transform the <kbd>Array[Array[String]]</kbd> into <kbd>Array[(Vector, String)]</kbd>:</p>
<pre class="mce-root">val result5 = result4.map(row =&gt; (Vectors.dense(row(1).toDouble,..toDouble),row(5)))</pre>
<p class="mce-root">Now, we will invoke the <kbd>createDataFrame</kbd> method with a parameter called <kbd>getRows</kbd>. This returns a <kbd>DataFrame</kbd> with <kbd>featureVector</kbd> and <kbd>speciesLabel</kbd> (for example, <kbd>bcw-Setos</kbd>):</p>
<pre class="mce-root">val dataFrame = spark.createDataFrame(result5).toDF(featureVector, speciesLabel)</pre>
<p>The new <kbd>DataFrame</kbd> contains two rows:</p>
<ul>
<li>A column named <kbd>bcw-features-column</kbd></li>
<li>A column named <kbd>bcw-species-label-column</kbd></li>
</ul>
<p class="mce-root"><span>We need to index <kbd>species-label-column</kbd> by converting the <kbd>"bcw-Setosa"</kbd>, <kbd>"bcw-Virginica"</kbd>, and <kbd>"bcw-Versicolor"</kbd> strings into doubles. We will use a <kbd>StringIndexer</kbd> to do that.</span></p>
<p class="mce-root"/>
<p class="mce-root">Now, create a file called <kbd>bcwPipeline.scala</kbd>.</p>
<p class="mce-root">Create an object called <kbd>bcwPipeline</kbd> that extends our <kbd>bcwWrapper</kbd> trait:</p>
<pre class="mce-root">object BreastCancerRfPipeline extends WisconsinWrapper { }</pre>
<p class="mce-root">Import the <kbd>StringIndexer</kbd> algorithm class:</p>
<pre class="mce-root">import org.apache.spark.ml.feature.StringIndexer</pre>
<p class="mce-root">Now, create a <kbd>StringIndexer</kbd> algorithm instance. <kbd>StringIndexer</kbd> will map <kbd>species-label-column</kbd> to an indexed learned column:</p>
<pre class="mce-root">val indexer = new StringIndexer().setInputCol(bcwCategory).setOutputCol("indexedSpeciesLabel")</pre>
<p>The indexer transforms the <kbd>bcw</kbd> type column into a column of type double. This is an example where a categorical variable is disguised as a quantitative variable. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 2 – creating training and test data</h1>
                </header>
            
            <article>
                
<p>Now, let's split our dataset in two by providing a random seed:</p>
<pre class="mce-root"><span>val splitDataSet: Array[org.apache.spark.sql.<br/>Dataset[org.apache.spark.sql.Row]] = indexedDataFrame.randomSplit(Array(0.75, 0.25), 98765L)</span></pre>
<p class="mce-root">The new <kbd>splitDataset</kbd> contains two datasets:</p>
<ul>
<li class="mce-root">The training <kbd>Dataset</kbd> is a dataset containing <kbd>Array[(Vector, bcw-species-label-column: String)]</kbd></li>
<li class="mce-root">The test <kbd>Dataset</kbd> is a dataset containing <kbd>Array[(Vector, bcw-species-label-column: String)]</kbd></li>
</ul>
<p class="mce-root">Confirm that the new <kbd>Dataset</kbd> is of size <kbd>2</kbd>:</p>
<pre class="mce-root">splitDataset.size<br/><strong>res48: Int = 2</strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mce-root">Assign the training <kbd>Dataset</kbd> to the <kbd>trainSet</kbd> variable:</p>
<pre class="mce-root"><span>val trainDataSet = splitDataSet(0)</span><br/><strong>trainSet:</strong> <strong>org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [bcw-features-column: vector, bcw-species-label-column: string]</strong></pre>
<p class="mce-root">Assign the testing <kbd>Dataset</kbd> to the <kbd>testSet</kbd> variable:</p>
<pre class="mce-root">val testDataSet = splitDataSet(1)<br/><strong>testSet: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [bcw-features-column: vector, bcw-species-label-column: string]</strong></pre>
<p class="mce-root"/>
<p class="mce-root">Now, we will see how to create a Random Forest classifier.</p>
<p>Create a classifier and pass into it hyperparameters. We will set the following parameters first:</p>
<ul>
<li>A <kbd>"features"</kbd> column name</li>
<li>An indexed <kbd>"label"</kbd> column name</li>
<li>The number of features to be considered per split (we have 150 observations and four features) that will make our <kbd>max_features 2</kbd></li>
</ul>
<p class="mce-root">Since <kbd>bcw</kbd> is a classification problem, the <kbd>'sqrt'</kbd> setting for <kbd>featureSubsetStrategy</kbd> is what we need. In addition, we will pass in other parameters such as impurity, the number of trees to train, and many more, as follows:</p>
<ul>
<li class="mce-root">Impurity settings—values can be gini and entropy</li>
<li class="mce-root">Number of trees to train (since the number of trees is greater than 1, we set the tree maximum depth, which is a number equal to the number of nodes)</li>
<li class="mce-root">The required minimum number of feature measurements (sampled observations), also known as the minimum instances per node</li>
</ul>
<p class="mce-root"/>
<p class="mce-root">This time, we will employ an exhaustive grid search-based model selection process, based on combinations of parameters, where parameter value ranges are specified.<br/>
Create a <kbd>randomForestClassifier</kbd> instance. Set the features and <kbd>featureSubsetStrategy</kbd>:</p>
<pre class="mce-root">val randomForestClassifier = new RandomForestClassifier()<br/> .setFeaturesCol(bcwFeatures_CategoryOrSpecies_IndexedLabel._1)<br/> .setFeatureSubsetStrategy("sqrt")</pre>
<p>Start building a <kbd>Pipeline</kbd> that has two stages, an <kbd>indexer</kbd> and a <kbd>Classifier</kbd>:</p>
<pre class="mce-root"><span>val irisPipeline = new Pipeline().setStages(Array[PipelineStage](indexer) ++ Array[PipelineStage](randomForestClassifier)</span></pre>
<p class="mce-root">Next, set the hyperparameter <kbd>num_trees</kbd> (number of trees) on the classifier to <kbd>15</kbd>, a <kbd>Max_Depth</kbd> parameter, and an impurity with two possible values of gini and entropy. Then, build a parameter grid with all three hyperparameters.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 3 – training the Random Forest classifier</h1>
                </header>
            
            <article>
                
<p>Next, we will split our existing training set (the one used to train the model) into two:</p>
<ul>
<li><strong>Validation set</strong>: This is a subset of the training dataset which is used to get a preliminary estimate of the effectiveness of the level of skillfulness attained by the model.</li>
<li><strong>Training set</strong>: A training set is that percentage of dataset that the model learns from. This learning process is called training the model. Also because the model learns from this data, the data is said fit the model.</li>
</ul>
<p>We can accomplish a split by creating an instance of the <kbd>TrainValidationSplit</kbd> algorithm:</p>
<div>
<pre><span>val validatedTestResults: DataFrame = new TrainValidationSplit() .setSeed(1234567L) .setEstimatorParamMaps(finalParamGrid) .setEstimator(irisPipeline)</span></pre></div>
<p>On this variable, set a seed, set <kbd>EstimatorParamMaps,</kbd> set the <kbd>Estimator</kbd> with <kbd>bcwPipeline,</kbd> and finally set the training ratio to <kbd>0.8</kbd>.</p>
<div>
<p><span>Finally, do a fit and transform with our training <kbd>Dataset</kbd> and testing <kbd>Dataset</kbd></span>.</p>
</div>
<p>Great! Now, the classifier is trained. In the next step, we will apply this classifier to the testing data.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 4 – applying the classifier to the test data</h1>
                </header>
            
            <article>
                
<p>The purpose of our validation set is to be able to make a choice between models. We want an evaluation metric as well as hyperparameter tuning. Now, we will create an instance of a validation estimator called <kbd>TrainValidationSplit</kbd>, which will split the training set into a validation set and a training set as follows:</p>
<pre>validatedTestResults.setEvaluator(new MulticlassClassificationEvaluator())</pre>
<p>Next, we will fit this estimator over the training dataset to produce a model and a transformer that we will use to transform our testing dataset. Finally, we will perform validation for hyperparameter tuning by applying an evaluator for a metric.</p>
<p class="mce-root">The new <kbd>ValidatedTestResults DataFrame</kbd> should contain the following columns, including three newly generated columns—<kbd>rawPrediction</kbd>, <kbd>probability</kbd>, and <kbd>prediction</kbd>, and some additional ones:</p>
<ul>
<li><kbd>bcw-features-column</kbd></li>
<li><kbd>bcw-species-column</kbd></li>
<li><kbd>label</kbd></li>
<li><kbd>rawPrediction</kbd></li>
<li><kbd>probability</kbd></li>
<li><kbd>prediction</kbd></li>
</ul>
<p class="mce-root">Next, let's generate a new dataset. Invoke the <kbd>select</kbd> method on the <kbd>validatedTestResults</kbd> dataset and pass the column expressions for <kbd>prediction</kbd> and <kbd>label</kbd> into it:</p>
<pre class="mce-root">val validatedTestResultsDataset:DataFrame = validatedTestResults.select("prediction", "label")</pre>
<p>We will revisit these test results towards the close of this chapter, where we will be evaluating the classifier. At that point, we will explain how to interpret these results and how they tie into the main goal of this chapter predicting the class of a breast cancer mass diagnosis.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 5 – evaluating the classifier</h1>
                </header>
            
            <article>
                
<p>In this section, we will evaluate the accuracy of the mode output results on the test result. Evaluation starts by creating an instance of <kbd>MulticlassEvaluator</kbd>:</p>
<pre>val modelOutputAccuracy: Double = new MulticlassClassificationEvaluator()</pre>
<p>Now, on <kbd>MulticlassEvaluationEvaluator</kbd>, we set the following:</p>
<ul>
<li>The <kbd>"label"</kbd> column</li>
<li>A metric name</li>
<li>The prediction column <kbd>label</kbd></li>
</ul>
<p>Next, we invoke the <kbd>evaluate</kbd> method with the <kbd>validatedTestResults</kbd> dataset. Note the accuracy of the model output results for the testing dataset from the <kbd>modelOutputAccuracy</kbd> variable. The other metric of note to evaluate is how close the predicted label value in the <kbd>predicted</kbd> column is to the actual label value in the (indexed) <kbd>"label"</kbd> column.</p>
<p>Next, we want to extract the metrics:</p>
<pre class="mce-root"><span>val multiClassMetrics = new MulticlassMetrics(validatedRDD2</span>)</pre>
<p class="mce-root"><kbd>MulticlassMetrics</kbd> includes two computed metrics that we extract by giving a reading of the <kbd>accuracy</kbd> and <kbd>weightedMetrics</kbd> variables.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 6 – running the pipeline as an SBT application</h1>
                </header>
            
            <article>
                
<p class="mce-root">At the root of your project folder, issue the <kbd>sbt console</kbd> command, and in the Scala shell, import the <kbd>bcwPipeline</kbd> object and then invoke the <kbd>main</kbd> method of <kbd>bcwPipeline</kbd> with the <kbd>bcw</kbd> argument:</p>
<pre class="mce-root"><strong>sbt console</strong><br/><strong>scala&gt;</strong><br/><strong>import com.packt.modern.chapter2.BreastCancerRfPipeline<br/>BreastCancerRfPipeline.main("bcw")</strong><br/><strong>Accuracy (precision) is 0.9285714285714286 Weighted Precision is: 0.9428571428571428</strong></pre>
<p>The classifier reported on two metrics:</p>
<ul>
<li>Accuracy</li>
<li>Weighted precision</li>
</ul>
<p class="mce-root">In the next section, we will package the application.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 7 – packaging the application</h1>
                </header>
            
            <article>
                
<p>In the root folder of your SBT application, we want to generate an Uber JAR. We will run the following command:</p>
<pre><strong>sbt package</strong></pre>
<p><span><span>This command generates an U</span></span>ber JAR file, which can then be easily deployed into <span><kbd>[local]</kbd> in standalone deploy mode:</span></p>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/d350f370-8839-476f-8510-b638736fe56f.jpg" style="width:47.08em;height:10.33em;"/></div>
<div class="mce-root CDPAlignCenter packt_figref CDPAlign">The application JAR file</div>
<p class="mce-root">The pipeline JAR file is available under the target folder. In the next section, we will deploy the application into Spark.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 8 – deploying the pipeline app into Spark local</h1>
                </header>
            
            <article>
                
<p>At the root of the application folder, issue the <kbd>spark-submit</kbd> command with the class and JAR file path arguments, respectively. If everything went well, the application will do the following:</p>
<ol>
<li>Load up the data.</li>
<li>Performs EDA.</li>
</ol>
<ol start="3">
<li>Create training, test, and validation datasets.</li>
<li>Create a Random Forest classifier model.</li>
<li>Train the model.</li>
<li>Test the accuracy of the model, which is the most important part of the ML classification task.</li>
<li>To accomplish step 6, we apply our trained Random Forest classifier model to the test dataset, which is data that has not been seen by the model yet:</li>
</ol>
<ul>
<li style="padding-left: 30px">Unseen data could be likened to new data that the classifier needs to predict on</li>
<li style="padding-left: 30px">Our goal at the beginning of this was to classify the diagnosis of a breast cancer mass that is exemplified by specific features in the test dataset</li>
</ul>
<ol start="8">
<li>Applying the model to the test dataset results in a prediction of the diagnosis.</li>
<li>The pipeline runs an evaluation process, which is all about checking the model reports the correct diagnosis. </li>
<li>Lastly, pipeline reports back on how important a certain feature of the breast cancer dataset turned out to be in relation to the others. As a matter of fact, it turns out that a certain feature is more important than others in carrying out the classification task.</li>
</ol>
<p>The preceding summary listing concludes the Random Forests section and brings us to the beginning of a brand new section on the topic of creating a logistic regression pipeline.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">LR breast cancer pipeline</h1>
                </header>
            
            <article>
                
<p>Before getting down to the implementation of a logistic regression pipeline, refer back to the earlier table in section <em>Breast cancer dataset at a glance </em>where nine b<span>reast cancer tissue sample characteristics (features) are listed, along with one class column. To recap, those characteristics or features are listed as follows for context:</span></p>
<ul>
<li><span><strong>c</strong></span><strong><span>lump_thickness</span></strong></li>
<li><strong><span>size_uniformity</span></strong></li>
<li><strong><span>shape_uniformity</span></strong></li>
<li><strong><span>marginal_adhesion</span></strong></li>
<li><strong><span>epithelial_size</span></strong></li>
<li><strong><span>bare_nucleoli</span></strong></li>
</ul>
<ul>
<li><strong><span>bland_chromatin</span></strong></li>
<li><strong><span>normal_nucleoli</span></strong></li>
<li><strong><span>mitoses</span></strong></li>
</ul>
<p>Now, let's get down to <span>a </span>high-level formulation of the logistic regression approach in terms of what it is meant to achieve. The following diagram represents the elements of such a formulation at a high level:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ba37e64b-0234-427d-bfa4-589093753c8a.png" style="width:21.83em;height:23.83em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Breast cancer classification formulation</div>
<p>The preceding diagram represents a high-level formulation of a logistic classifier pipeline that we are aware needs to be translated into an implementation in Spark and Scala. Here are a few helpful points to get you started:</p>
<ul>
<li>What are some interesting attributes that we can choose to come up with predictions? Attributes or features are like <kbd>if</kbd> statements and the predicted label is the answer. For example, if it looks like a fish, is 100 feet long, and is a mammal, it must be a whale. We must identify those <kbd>if</kbd> statements or attributes with the express purpose of making predictions. Of course, a prediction must classify a tissue sample as either malignant or benign.</li>
</ul>
<ul>
<li>Create a classifier model with LR.</li>
<li><span>There is our class column in the breast cancer dataset, which represents the label. </span><span>This column holds known (or predetermined) label values that <kbd>"label"</kbd> each feature measurement row with either malignant or benign. </span></li>
<li><span>Thus, the entire dataset, an experimental unit of known labels for known measurements, is said to be labeled either malignant or benign.</span></li>
</ul>
<p>In the next section, we will lay out our implementation objectives, what our implementation goals will be, and how we plan on implementing them.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation objectives</h1>
                </header>
            
            <article>
                
<p>We will kickstart this section by listing the following implementation objectives:</p>
<ul>
<li><span><strong>Implementation objective 1</strong>: </span>Depicting what we believe are fundamental pipeline building blocks, rough workflow stages in the actual pipeline, and where each block is visualized as being connected to the next, implying flow of data and the transformation of data. A state of connection implies a set of workflow stages placed in a sequence.</li>
<li><span><strong>Implementation objective 2</strong>: </span>Core building blocks of the pipeline.</li>
<li><span><strong>Implementation objective 3</strong>: </span><span>Spark ML Workflow for the breast cancer classification task.</span></li>
<li><span><strong>Implementation objective 4</strong>: </span>Developing <span>two pipeline stages and assigning an indexer and logit model to each of these stages.</span></li>
<li><strong>Implementation objective 5</strong>: Evaluating the binary classifier's performance.</li>
</ul>
<p>Next, we get on with implementation objectives 1 and 2.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation objectives 1 and 2</h1>
                </header>
            
            <article>
                
<p>The following diagram depicts a <strong>DataFrame</strong> block that <span>progresses through a transformation process into the <strong>FeatureVector creation</strong> block. A <strong>Feature Vector</strong> and an unindexed label (not shown in the following diagram for simplicity) make up a new (transformed) <strong>DataFrame</strong>. The <strong>FeatureVector creation</strong> block (or stage) is a precursor to <strong>Classifier Model </strong>creation. The last block is a <strong>Prediction</strong> stage where predictions are generated.</span></p>
<p><span>This is a succinct description of what is to be implemented in the code later: </span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c1d596f3-8a93-4aed-8902-3a1aae9420db.png" style="width:18.17em;height:16.75em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Core building blocks of the pipeline</div>
<p><span>The preceding diagram makes no mention of splitting the <kbd>DataFrame[Feature Vector and Label]</kbd> into two parts:</span></p>
<ul>
<li><span>A training dataset</span></li>
<li><span>A testing dataset, which is </span><span>input data on which the model is fitted (trained) </span></li>
</ul>
<p><span>These two datasets are represented by a <strong>training</strong> block and a <strong>testing</strong> block in the diagram in the next section instead. </span>Implementation objectives 1 and 2 were laid out in this section. Implementation objective 3 is laid out in the topic that follows.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation objective 3 – Spark ML workflow for the breast cancer classification task</h1>
                </header>
            
            <article>
                
<p><span>We will start working on implementation objective 3. This forms the basis for our logistic regression pipeline. This pipeline is divided into two functional areas—a training block depicted in the diagram as</span> training, a<span>nd a testing block depicted</span> as testing.</p>
<p><span><span>We filled out the </span></span><strong>training</strong> block with four pipeline stages, which are as follows:</p>
<ul>
<li><strong>Loading Data</strong></li>
<li><strong>Feature Extraction</strong></li>
<li><strong>Model Fitting (Training)</strong></li>
<li><strong>Evaluation</strong></li>
</ul>
<p class="mce-root"/>
<p><span>Likewise, th</span>e testing b<span>lock has four stages of its own:</span></p>
<ul>
<li><strong>Loading Data</strong></li>
<li><strong>Feature Extraction</strong></li>
<li><strong>Prediction</strong></li>
<li><strong>Evaluation</strong></li>
</ul>
<p><span>The two blocks don't appear to be all that different. However, there is more to it than meets the eye. We will now lay out a new ML workflow diagram in terms of the training, testing, and Spark ML components, as follows:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/b05ece70-273c-4948-b0be-4dc9a9f6dcad.png" style="width:30.17em;height:29.08em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Spark ML workflow for the breast cancer classification task</span></div>
<p><span>An arrow from t</span>he training bloc<span>k to the</span> testing block indic<span>ates a d</span><span>ata transformation workflow starting in the</span> training blo<span>ck and proceeding into the</span> testing block<span>. </span></p>
<p>Our preceding ML workflow diagram is a step forward. It is a precursor of sorts to the actual pipeline, whose implementation details will be laid out in <em>Implementation objective 4—coding steps for building the indexer and logit machine learning model </em>section.</p>
<p>At this point, we must note that the implementation critically depends on leveraging the following Spark ML API components:</p>
<ul>
<li><strong>DataFrame</strong></li>
<li><strong>Transformer</strong></li>
<li><strong>Estimator</strong></li>
<li><strong>Metrics Evaluator</strong></li>
</ul>
<p>Now, we have enough information to get to the next level that is <em>Implementation</em> <em>objective 4—coding steps for building the indexer and logit machine learning model</em> section where we will go through all the motions of building a two-stage pipeline.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation objective 4 – coding steps for building the indexer and logit machine learning model</h1>
                </header>
            
            <article>
                
<p>At the outset, fulfilling implementation objective 5 requires that we import the following. Create an empty Scala file in the following package and add the following imports in.</p>
<p>After all the imports are in, create a new Scala object called <kbd>BreastCancerLrPipeline</kbd> and have this class extend from the <kbd>WisconsinWrapper</kbd> trait:</p>
<pre>package com.packt.modern.chapter2<br/><br/><span>import </span>com.packt.modern.chapter2.WisconsinWrapper<br/><span>import </span>org.apache.spark.ml.classification.LogisticRegression<br/><span>import </span>org.apache.spark.ml.evaluation.{BinaryClassificationEvaluator, MulticlassClassificationEvaluator}<br/><span>import </span>org.apache.spark.ml.{Pipeline, PipelineStage}<br/><span>import </span>org.apache.spark.mllib.evaluation.BinaryClassificationMetrics<br/><span>import </span>org.apache.spark.rdd.RDD<br/><span>import </span>org.apache.spark.sql.{<span>DataFrame</span>, Row}</pre>
<p>The <kbd>WisconsinWrapper</kbd> trait contains code that creates a <kbd>SparkSession</kbd> for us. It also contains a method that takes in the dataset and creates a <kbd>DataFrame</kbd> from it. The imports also bring in the following, which is important for implementation tasks. For example, you will note that they are necessary for importing the Spark ML API for <kbd>LogisticRegression</kbd>, which is one of the algorithms used in binary classification. We needed APIs to compute binary classification metrics. That said, we will move on to the next task, where we talk more about our trait, <kbd>WisconsinWrapper</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Extending our pipeline object with the WisconsinWrapper trait</h1>
                </header>
            
            <article>
                
<p><kbd>WisconsionWrapper</kbd> contains a trait called <kbd>WisconsinWrapper</kbd>, which contains the following code components:</p>
<ul>
<li>A <kbd>SparkSession</kbd> called <kbd>lazy val</kbd></li>
<li>A <kbd>val</kbd> representing the path to the breast cancer dataset, <kbd>bcw.csv</kbd> (this file is available in the root of the project folder)</li>
<li>A tuple holding string representations of columns for <kbd>"features"</kbd> and <kbd>"label"</kbd> in <kbd>DataFrame</kbd>, which we will create shortly</li>
<li>A method to build <kbd>DataFrame</kbd>. It takes in the fully qualified path to the dataset path with a method named <kbd>buildDataFrame()</kbd></li>
</ul>
<p>The <kbd>Wrapper</kbd> trait is depicted as follows, and includes all four code components:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c98695e5-286d-43b8-8f5e-ee0be9ad2af2.jpg" style="width:50.25em;height:28.83em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">WisconsinWrapper</div>
<div class="packt_infobox">Readers may grab a copy of the <kbd>WisconsinWrapper</kbd> trait and paste this file into their SBT project. The SBT project is available under the <kbd>ModernScalaProjects_Code</kbd> folder.</div>
<p>Now, create a declaration for <kbd>object BreastCancerLrPipeline</kbd> as follows:</p>
<pre><span>object </span>BreastCancerLrPipeline <span>extends </span>WisconsinWrapper { }</pre>
<p>We now have an empty <kbd>object</kbd> body, so we will add in an <kbd>import</kbd> for the <kbd>StringIndexer</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing the StringIndexer algorithm and using it</h1>
                </header>
            
            <article>
                
<p>We need the <kbd>StringIndexer</kbd> algorithm to index values in the <kbd>"label"</kbd> column. That is why <kbd>StringIndexer</kbd> is imported:</p>
<pre>import org.apache.spark.ml.feature.StringIndexer</pre>
<p><kbd>StringIndexer</kbd> is an algorithm that can take a list of hyperparameters. Two such parameters are set as follows:</p>
<pre><span>val </span>indexer = <span>new S</span>tringIndexer().setInputCol(<span>bcwFeatures_IndexedLabel</span>._2).setOutputCol(<span>bcwFeatures_IndexedLabel</span>._3)</pre>
<p>We have created an <kbd>indexer StringIndexer</kbd> algorithm instance. The next step will be to fit the model on a new generic <kbd>DataFrame</kbd> that we will build using the <kbd>buildDataFrame</kbd> method:</p>
<pre><span>val </span>indexerModel = indexer.fit(dataSet)<br/><span>val </span>indexedDataFrame = indexerModel.transform(dataSet)<br/><br/></pre>
<p>The resulting <kbd>StringIndexerModel</kbd> is transformed:</p>
<pre>indexedDataFrame.show</pre>
<p>The <kbd>show</kbd> method now displays the first <kbd>20</kbd> rows of the <kbd>DataFrame</kbd>:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/171ec8a6-1b46-42f3-8b6a-71398790669a.jpg" style="width:24.00em;height:19.17em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Result of the fit and transform of StringIndexer</div>
<p>There is a reason for the <kbd>"features"</kbd> column to coexist with <kbd>"bcw-diagnoses-column"</kbd>. The <kbd>"features"</kbd> that are present in the feature vector are attributes that are closely tied to the diagnosis of a certain tissue sample. <span><kbd>"bcw-diagnoses-column"</kbd> represents the class column in the original dataset. This is a binary classification problem where the category cannot have a numerical measure, so we must artificially assign a value of either <kbd>0</kbd> or <kbd>1</kbd>. In this case, <kbd>2</kbd> and <kbd>4</kbd> are standing in for benign and malignant, respectively. The <kbd>"label"</kbd> column beside the <kbd>"features"</kbd> column bears two kinds of values:</span></p>
<ul>
<li><kbd>0.0</kbd></li>
<li><kbd>1.0</kbd></li>
</ul>
<p>The <kbd>StringIndexer</kbd> indexed values in the <kbd>"bcw-diagnoses-column"</kbd> from the original <kbd>DataFrame</kbd> are produced by the <kbd>buildDataFrame</kbd> method and are assigned values of <kbd>0.0</kbd> to <kbd>2.0</kbd> and <kbd>1.0</kbd> to <kbd>4.0</kbd>, respectively.</p>
<p>Next, we will venture deeper into ML territory. As with any ML exercise, it is common to split a dataset into a training set and testing set. That is exactly what we will do in the next coding step.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Splitting the DataFrame into training and test datasets</h1>
                </header>
            
            <article>
                
<p>We will split our <kbd>DataFrame</kbd> in two:</p>
<ul>
<li>Training set—75%</li>
<li>Testing set—25%</li>
</ul>
<p>The training set is used to train (fit) the model, and the remaining 25% will be put to use for testing:</p>
<pre><span>val </span>splitDataSet: Array[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]] = indexedDataFrame.randomSplit(<span>Array</span>(<span>0.75</span>, <span>0.25</span>), <span>98765L</span>)<br/><br/>//create two vals to hold TrainingData and TestingData respectively<br/><span>val </span>trainDataFrame = splitDataSet(<span>0</span>)<br/><span>val </span>testDataFrame = splitDataSet(<span>1</span>)</pre>
<p>To verify that our split went well, we will run the <kbd>count</kbd> method on both the <kbd>trainDataFrame</kbd> and <kbd>testDataFrame</kbd> dataframes. <br/>
We will leave this as an exercise to the reader. Next, we will move on to creating a <kbd>LogisticRegression</kbd> classifier model and passing parameters into it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a LogisticRegression classifier and setting hyperparameters on it</h1>
                </header>
            
            <article>
                
<p>The <kbd>LogisticRegression</kbd> classifier can take hyperparameters, which we will set by using the appropriate setter methods from the <kbd>LogisticRegression</kbd> API. Since Spark ML has support for elastic net regularization, we will pass this as a parameter first. We also want two additional parameters:</p>
<ul>
<li>The <kbd>"features"</kbd> column</li>
<li>An indexed <kbd>"label"</kbd> column</li>
</ul>
<pre><span>val logitModel = new LogisticRegression() .setElasticNetParam(0.75) .setFamily("auto") .setFeaturesCol(bcwFeatures_IndexedLabel._1) .setLabelCol(bcwFeatures_IndexedLabel._3).fit(trainDataSet</span>)</pre>
<p><span>What we just did was start the training process by creating an LR classifier model. We are now in a position to train our LR model on the training dataset by making an association between input </span><span>feature measurements and their l</span><span>abeled output. To recap, we passed in a <kbd>"features"</kbd> column, a <kbd>"label"</kbd> column, and an elastic net coefficient.</span></p>
<p>Next, we will execute our model with a transformation operation and testing dataset data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the LR model on the test dataset</h1>
                </header>
            
            <article>
                
<p>We will now invoke the <kbd>transform</kbd> method on our <kbd>LogisticRegression</kbd> model:</p>
<pre><span>//Next run the model on the test dataset and obtain predictions<br/></span><span>val </span>testDataPredictions = logitModel.transform(testDataSet)</pre>
<p>The <kbd>transform</kbd> method invocation returns a new <kbd>DataFrame</kbd>. <span>Not only that, that model transformation step resulted in three new columns:</span></p>
<ul>
<li><kbd>rawPrediction</kbd></li>
<li><kbd>probability</kbd></li>
<li><kbd>predictions</kbd></li>
</ul>
<p><span>Next, we will display the first <kbd>25</kbd> rows of this <kbd>DataFrame</kbd></span>:<span> </span></p>
<pre>testDataPredictions.show(<span>25</span>)</pre>
<p><span>See the following table to look at the displayed predictions, which were made by running our LR models on the test dataset:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/6fe43848-6883-416c-88bc-75e88bf3558f.jpg" style="width:51.50em;height:22.92em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Three new columns resulting from model transformation</span></div>
<div class="packt_infobox">Spark's pipeline API provides us with the necessary tools to help us build a pipeline. A pipeline is a workflow and consists of a sequence of stages that we call pipeline stages. As we shall see later, each of these stages is executed in order.</div>
<p>That being said, we will now get on with the next order of business—creating a data pipeline with the following stages:</p>
<ul>
<li>A logit model</li>
<li>An indexer</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a breast cancer pipeline with two stages</h1>
                </header>
            
            <article>
                
<p>Create the pipeline and add two stages to it as follows:</p>
<pre><span>//Start building a Pipeline that has 2 stages, an Indexer and a Classifier<br/></span><span>val </span>wbcPipeline = <span>new </span>Pipeline().setStages( <br/><span>                                  Array</span>[PipelineStage](indexer) ++ <span>Array</span>[PipelineStage](logitModel)<br/>                                 )</pre>
<p> Next, let's do something with our pipeline. We can do the following things right away:</p>
<ul>
<li>Train the pipeline with the training dataset</li>
<li>Run a <kbd>transform</kbd> operation with the test set data on our derived <kbd>pipelineModel</kbd>:</li>
</ul>
<pre style="padding-left: 60px"><span>val </span>pipelineModel = wbcPipeline.fit(trainDataSet)</pre>
<p>Next, we will make predictions by running a <kbd>transform</kbd> operation<span> on the <kbd>pipelineModel</kbd> with the testing dataset:</span></p>
<pre style="padding-left: 30px"><span>val </span>predictions = pipelineModel.transform(testDataSet)</pre>
<p>The next step focuses on obtaining quantifiable measures. These are k<span>ey performance indicators, metrics that with facts and figures </span>assess how each one of our algorithms fared. How do they stack up with respect to one another? <span>What graphical evaluation tools are available that help us assess the performance of a certain algorithm contributing to a particular binary </span>classification? To understand what it takes to perform this evaluation, we might want to ask the following question first: how close is the predicted value of a certain breast cancer sample to a predetermined label?</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation objective 5 – evaluating the binary classifier's performance</h1>
                </header>
            
            <article>
                
<p>This section is all about obtaining evaluations, metrics, and supporting Spark ML APIs. In this section, we will go into depth on the importance of the evaluation step regarding <span>quantifiable measures of effectiveness, as follows:</span></p>
<ul>
<li>Our breast cancer classification task is a supervised learning classification problem. In such a problem, there's a so-called <strong>true output</strong>, and a classifier or ML model generated prediction output for each individual feature measurement or data point in our breast cancer dataset.</li>
<li>We have now turned our attention to evaluating the performance of our binary classification algorithm by deriving certain metrics. That said, the question is this: is pure accuracy enough to gauge the correctness of our classifier's evaluation effort? Here, pure accuracy is trying to simply tell whether the prediction was correct or not. Okay, what is a better method? We can employ a binary classification evaluator to evaluate the correctness and hence have a measure of the performance regarding this kind of accuracy. </li>
<li>Circling back to the same topic of pure accuracy, the question to ask again is this: is this a good enough metric? It turns out that pure accuracy is not a great metric, because it does not take into account the type of error.</li>
<li>For the aforementioned reason, we will derive better metrics, such as the <strong>area under ROC curve</strong> (<strong>AUC</strong>) and the <strong>area under the precision recall curve</strong> (<strong>AUPCR</strong>). We will employ Spark's <kbd>BinaryClassificationMetrics</kbd> to compute such metrics for us.</li>
</ul>
<p><span>Next, we will get on with the implementation part of the metric derivation process. First, we will create a <kbd>BinaryClassificationEvaluator</kbd></span>. <span>We will reiterate this evaluator and </span>evaluate predictions with a kind of metric or score that we will call pure accuracy:</p>
<pre><span>val modelOutputAccuracy: Double = new BinaryClassificationEvaluator() .setLabelCol("label") .setMetricName("areaUnderROC") //Area under Receiver Operating Characteristic Curve .setRawPredictionCol("prediction") .setRawPredictionCol("rawPrediction")<br/>.evaluate(testDataPredictions)</span></pre>
<p>We just computed a so-called pure accuracy score that we called <kbd>modelOutputAccuracy</kbd> in the preceding line of code. As an exercise, readers are invited to determine their pure accuracy score. The question they could pose is this: is this score useful? Is it a naive score?</p>
<p class="mce-root"/>
<p>With that accomplished, we will now turn our attention to the next task at hand, deriving a new dataframe by running a <kbd>select</kbd> operation on our predictions <kbd>DataFrame</kbd>:</p>
<pre><span>val predAndLabelsDFrame</span>:DataFrame = predictions.select(<span>"prediction"</span>, <span>"label"</span>)<br/>println(<span>"Validated TestSet Results Dataset is:  " </span>+ validatedTestResultsDataset.take(<span>10</span>))</pre>
<p>We are not done yet. We will convert our <kbd>"predictions"</kbd> and <kbd>"label" DataFrame</kbd> that we derived in the preceding code to an <kbd>RDD[Double, Double]</kbd>:</p>
<pre><span>val validatedRDD2: RDD[(Double, Double)] = predictionAndLabels.rdd.collect { case Row(predictionValue: Double, labelValue: Double) =&gt; (predictionValue,labelValue</span>)<br/>}</pre>
<p><span>The RDD is now at hand. But why are we doing this? The answer is this: we talked about deriving better, meaningful, and not naive metric scores. We will now create a <kbd>BinaryClassificationMetrics</kbd> instance that we will call <kbd>classifierMetrics</kbd></span>:</p>
<pre><span>val classifierM</span>etrics = <span>new </span>BinaryClassificationMetrics(validatedRDD2)</pre>
<p><kbd>BinaryClassificationMetrics</kbd> provides us with tools to derive meaningful evaluation metrics for our breast cancer binary classification task. At its core, binary classification is an ML approach to classifying new, unclassified, incoming data under either of two mutually exclusive categories. For example, our classifier classified a breast cancer sample as either benign or malignant, but not both, of course. More specifically, the breast cancer binary classifier pipeline predicted the probability of a target breast cancer sample belonging to one of two outcomes, either benign or malignant. This looks like a straightforward yes or no-type prediction.</p>
<p>Sure, our model performed and did the heavy lifting. However, we want to put its performance to the test. To do that, we need numeric metrics that, if properly thought through and computed, will tell us the model's performance story in ways that are meaningful<span>. </span></p>
<p class="mce-root"/>
<p><span>What are those measures and when do they assume relevance? When an experimental analysis unit is balanced—the number of breast cancer samples like our breast cancer dataset—the following measures assume relevance:</span></p>
<ul>
<li><strong>True Positive Rate</strong> (<strong>TPR</strong>): This is a ratio of the <strong>true positives</strong> (<span>abbreviated as </span><strong>TPs</strong>) in the predicted output to the <strong>false negatives</strong> (<span>abbreviated as</span> <strong>FNs</strong>). Mathematically, it is represented as follows: <em>TPR</em> = <em>TPs</em> / (<em>TPs</em> + <em>FNs</em>). TPR is known by the terms <strong>Hit Rate</strong>, <strong>Recall</strong>, or <strong>Sensitivity</strong>.</li>
<li><strong>False Positive Rate</strong> (<strong>FPR</strong>): Mathematically, it is represented as <em>FPR</em> = <em>1</em> - (<em>TNs </em>/ (<em>TNs </em>+ <em>FPs</em>), where <strong>TNs</strong> is a stand-in for <strong>true negatives</strong> and <strong>FPs</strong>, which is a stand-in for <strong>false positives</strong>.</li>
<li>Before we proceed any further, some explanations are in order for TPs, TNs, FNs, and FPs: </li>
<li style="padding-left: 30px">True positives point to those predictions that turn out to be truly malignant</li>
<li style="padding-left: 30px">True negatives point to those predictions that turn out to be truly benign</li>
<li style="padding-left: 30px">False negatives point to those breast cancer samples that were wrongly labeled benign</li>
<li style="padding-left: 30px">False positives point to those <span>breast cancer samples</span> that were wrongly labeled malignant</li>
</ul>
<ul>
<li><span><strong>Receiver Operating Characteristic</strong> (<strong>ROC</strong>) <strong>curve</strong></span>:<span><strong> </strong>The area under this curve is a measure of binary classification performance. This curve is a graphical plot of FPR on the <em>x</em> axis and TPR on the <em>y</em> axis. A typical plot is shown later.</span></li>
<li><strong>The area under the </strong><span><strong>Precision-Recall (PR) curve</strong>: This is a graphical plot of precision on the <em>y</em> axis and accuracy on the <em>x</em> axis. To plot the curve, we need computed (precision value, accuracy value) pairs. </span><span>To compute these values, the following mathematical equations for accuracy and</span> precision are applied as follows: Precision = <em>TPs</em> / (<em>TPs</em> + <em>FPs</em>); Accuracy = <em>TPs</em> / (<em>TPs</em> +<em>FNs</em>). The ROC curve is shown later, followed by the PR curve.</li>
</ul>
<p class="mce-root"/>
<p>Both the ROC and PR curves represent binary classifier performance. How so? The area under the ROC curve becomes a measure of the binary classifier's performance. If a curve plotted for a particular algorithm snakes higher up to the top-right reading from left to right (the greater area under it), it has a lower <strong>false positive rate</strong>, making it a better classifier than a curve for a different algorithm that has a higher <strong>false positive rate</strong>. This is useful, though not necessarily the best metric. A typical ROC curve is shown as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/12467032-121d-4dad-a2ae-233d01346a05.png" style="width:37.92em;height:30.67em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">A typical <span>ROC curve</span></div>
<p>The next metric that is worth mentioning is the so-called precision-recall curve or PR curve for short. This curve involves the computation of two separate metrics, precision and recall.</p>
<p>A PR curve is plotted with a<span>ccuracy on the <em>x</em> axis and p</span><span>recision on the <em>y</em> axis. In this case, a particular algorithm fared better than others in its binary classification task if its curve snaked higher up towards the top-right. There are more TPs and considerably fewer FNs. This indicates a better classification. </span></p>
<p><span>This completes our discussion on binary classifier metrics, and their computation marks an important milestone regarding the b</span><span>reast cancer data analysis initiative. </span></p>
<p class="mce-root"/>
<p><span>Indeed, if the logit model we built performed well, the area under the ROC d</span><span>iscriminant curve should represent a meaningful measure of prediction performance:</span></p>
<pre><span>val </span>accuracyMetrics = (classifierMetrics.areaUnderROC(), classifierMetrics.areaUnderPR())<br/><br/><span>//Area under ROC<br/></span><span>val </span>aUROC = accuracyMetrics._1<br/><span>println</span>(<span>s"Area under Receiver Operating Characteristic (ROC) curve: </span><span>$</span>{aUROC} <span>"</span>)<br/><span>val </span>aPR = accuracyMetrics._2<br/><span>println</span>(<span>s"Area under Precision Recall (PR) curve: </span><span>$</span>{aPR} <span>"</span>)</pre>
<p>The metrics are ready. Here are the results. Running the pipeline should generate the following metrics:</p>
<pre><strong>Area under Receiver Operating Characteristic (ROC) curve: 0.958521384053299</strong><br/><strong>Area under Precision Recall (PR) curve: 0.9447563927932</strong></pre>
<p>That concludes our breast cancer classification task. In the previous section, on a Random Forests breast cancer pipeline, we showed you how to deploy your pipeline application into Spark. Likewise, in a similar fashion, we can deploy our logistic regression pipeline.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we learned how to implement a binary classification task using two approaches such as, an ML pipeline using the Random Forest algorithm and a<span>n secondly </span>using the logistic regression method. </p>
<p>Both pipelines combined several stages of data analysis into one workflow. In both pipelines, we calculated metrics to give us an estimate of how well our classifier performed. Early on in our data analysis task, we introduced a data preprocessing step to get rid of rows that were missing attribute values that were filled in by a placeholder, <kbd>?</kbd>. With 16 rows of unavailable attribute values eliminated and 683 rows with attribute values still available, we constructed a new <kbd>DataFrame</kbd>.</p>
<p class="mce-root"/>
<p>In each pipeline, we also created training, training, and validation datasets, followed by a training phase where we fit the models on training data. As with every ML task, the classifier may learn by rotating the training set details, a preponderant phenomenon called overfitting. We got around this problem by arriving at a reduced but optimal number of attributes. We did this by fitting our classifier models with various combinations of attributes.</p>
<p><span>In the next chapter, we will move our development efforts away from a local <kbd>spark-shell</kbd>. This time, we will take advantage of a Zeppelin Notebook running inside a <strong>Hortonworks Development Platform</strong> (<strong>HDP</strong>) Sandbox Virtual Machine.</span></p>
<p>To conclude this chapter, we will move on to the last section where we pose a set of questions to the reader.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<p><span>We will now list a set of questions to test your knowledge of what you have learned so far:</span></p>
<ul>
<li>What do you understand by logistical regression? Why is it important?</li>
<li>How does logistical regression differ from linear regression?</li>
<li>Name one powerful feature of <kbd>BinaryClassifier</kbd>.</li>
<li>What are the feature variables in relation to the breast cancer dataset?</li>
</ul>
<p>The breast cancer dataset problem is a classification task that can be approached with other machine learning algorithms as well. Prominent among other techniques are <strong>Support Vector Machine</strong> (<strong>SVM</strong>), <strong>k-nearest neighbor</strong>, and <strong>decision trees</strong>. When you run the pipelines developed in this chapter, compare the time it took to build a model in each case and how many of the input rows of the dataset were classified correctly by each algorithm.</p>
<p>This concludes this chapter. The next chapter implements a new kind of pipeline, which is a stock prediction task pipeline. We shall see how we can use Spark to work on larger datasets. Stock price prediction is not an easy problem to solve. How we shall tackle this is the subject of the next chapter.</p>


            </article>

            
        </section>
    </body></html>