- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Garbage Collectors and Dynamic CDS Archives
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter includes 15 problems covering garbage collectors and **Application
    Class Data Sharing** (**AppCDS**).
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you’ll have a profound understanding of how a **garbage
    collector** (**GC**) works and how you can tune it for maximum performance. Moreover,
    you’ll have a good understanding of how AppCDS can boost your application startup.
  prefs: []
  type: TYPE_NORMAL
- en: Problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Use the following problems to test your advanced programming prowess in garbage
    collectors and application class data sharing in Java. I strongly encourage you
    to give each problem a try before you turn to the solutions and download the example
    programs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hooking the garbage collector goal**: Introduce Java garbage collectors quickly.
    Highlight the main objectives (advantages) and disadvantages of a garbage collector.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Handling the garbage collector stages**: List and briefly describe the most
    common stages of a garbage collector.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Covering some garbage collector terminology**: A garbage collector has specific
    terminology. Provide here the main terms used in conjunction with garbage collectors.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tracing the generational GC process**: Exemplify and explain a hypothetical
    scenario containing several consecutive runs of a generational garbage collector.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Choosing the correct garbage collector**: List and explain the three main
    factors that should be considered for choosing the correct garbage collector.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Categorizing garbage collectors**: Highlight the main categories of garbage
    collector across JDK’s evolution.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing G1**: Provide a brief introduction to the G1 GC, including its
    design principles.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tackling G1 throughput improvements**: List the main improvements of G1 GC
    throughput across JDK versions.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tackling G1 latency improvements**: List the main improvements of G1 GC latency
    across JDK versions.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tackling G1 footprint improvements**: List the main improvements of the G1
    GC footprint across JDK versions.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing ZGC**: Provide a brief introduction to the Z Garbage Collector.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Monitoring garbage collectors**: Explain and exemplify at least one tool
    for monitoring garbage collectors.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Logging garbage collectors**: Provide the steps needed to log the garbage
    collector activity. Moreover, highlight some tools capable of analyzing and plotting
    the logged data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tuning garbage collectors**: Explain how to tune garbage collectors, including
    G1 and ZGC.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing Application Class Data Sharing (AppCDS, or Java’s Startup Booster)**:
    Give a quick and practical guide to using CDS and AppCDS in JDK 10/11, 13, and
    19.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The following sections describe solutions to the preceding problems. Remember
    that there usually isn’t a single correct way to solve a particular problem. Also,
    remember that the explanations shown here include only the most interesting and
    important details needed to solve the problems. Download the example solutions
    to see additional details and experiment with the programs at [https://github.com/PacktPublishing/Java-Coding-Problems-Second-Edition/tree/main/Chapter12](https://github.com/PacktPublishing/Java-Coding-Problems-Second-Edition/tree/main/Chapter12).
  prefs: []
  type: TYPE_NORMAL
- en: 243\. Hooking the garbage collector goal
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every programming language has to manage memory usage. Some programming languages
    delegate this task to programmers, while others leverage different mechanisms
    to partially control how memory is used. Java programmers can focus 100% on the
    functionalities of the application and let the *garbage collector* manage how
    memory is used.
  prefs: []
  type: TYPE_NORMAL
- en: 'The name *garbage collector* suggests an entity capable of finding and collecting
    garbage from memory. Actually, a garbage collector is a very complex process representing
    the climax of Java memory management that is capable of tracking every object
    from the heap and identifying and removing the ones that are not used/referenced
    by the application. The main advantages of a garbage collector include:'
  prefs: []
  type: TYPE_NORMAL
- en: The Java programmer doesn’t need to manually handle the allocation/deallocation
    of memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Java programmer doesn’t need to deal with *dangling* and *wild pointers*
    ([https://en.wikipedia.org/wiki/Dangling_pointer](https://en.wikipedia.org/wiki/Dangling_pointer)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a wide range of scenarios, a garbage collector prevents *memory leaks* ([https://en.wikipedia.org/wiki/Memory_leak](https://en.wikipedia.org/wiki/Memory_leak)).
    However, this issue is not 100% covered.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While these advantages are major, there are a few disadvantages as well:'
  prefs: []
  type: TYPE_NORMAL
- en: A garbage collector itself is a resource that needs CPU power to work. We’re
    talking about CPU power that is in addition to the CPU power needed by the application.
    More garbage collector activity requires more CPU power.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The programmer cannot control the garbage collector scheduler. This may cause
    performance issues at peaks or when the application deals with intensive computations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some garbage collectors cause long and unpredictable pauses of the application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning and tuning the correct garbage collector can be really cumbersome.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next problems, we’ll go deeper into this topic.
  prefs: []
  type: TYPE_NORMAL
- en: 244\. Handling the garbage collector stages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'During its work, GC passes through different stages or steps. It can pass through
    one or more of the following stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Mark* – In this stage, the GC identifies and marks (or paints) all pieces
    of memory (blocks) that are used (have references) and not used (have no references).
    The marked (painted) blocks are called *live objects*, while the rest are called
    *non-live objects*. *Imagine that you go to the pantry and identify all the fresh
    fruits and vegetables and separate them from the spoiled ones*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Sweep* – In this stage, the GC removes all *non-live objects* from memory.
    *Next, you take all the spoiled fruits and vegetables out of the pantry and throw
    them away*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Compact* – In this stage, the GC attempts to group the *live objects* closer
    together – in other words, it arranges the live objects at the start of the heap
    in a continuous sequence of memory blocks. So, compacting involves *defragmentation*
    and *relocation* of the *live objects*. The goal of compaction is to obtain large
    memory blocks that are free and ready to serve other objects. *Next, we go to
    the pantry and stack all the fruits and vegetables in crates so that we get as
    much free space as possible. We will use this space for other fruits and vegetables
    that we are going to buy*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Copy* – This is another stage dedicated to organizing memory. It is an alternative
    to the *mark* stage. In this stage, the GC moves the *live objects* into a so-called
    *ToSpace*. The rest of the objects are considered *non-live* and remain in the
    so-called *FromSpace*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Typically, a GC follows one of these three scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: Mark -> Sweep -> Compact
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Copy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mark -> Compact
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, let’s cover some GC terminology.
  prefs: []
  type: TYPE_NORMAL
- en: 245\. Covering some garbage collector terminology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Garbage collection has its own terminology that it is essential to know in order
    to better understand how it works. Some of these terms are presented here; we
    start with *epoch*, *single pass*, and *multiple passes*.
  prefs: []
  type: TYPE_NORMAL
- en: Epoch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A GC works in cycles. A complete cycle of a GC is known as an *epoch*.
  prefs: []
  type: TYPE_NORMAL
- en: Single and multiple passes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A GC can handle its internal steps in a single pass (*single-pass*) or multiple
    passes (*multi-pass*). In the case of *single-pass*, the GC groups multiple steps
    and handles them in a single run. On the other hand, in the case of *multi-pass*,
    the GC handles multiple steps in a sequence of several passes.
  prefs: []
  type: TYPE_NORMAL
- en: Serial and parallel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A GC is considered *serial* if it uses a single thread. On the other hand, a
    GC is considered *parallel* if it uses multiple threads.
  prefs: []
  type: TYPE_NORMAL
- en: Stop-the-World (STW) and concurrent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A GC is of the type *Stop-the-World* (STW) if it has to stop (temporarily suspend)
    the application execution in order to carry out its cycle. On the other hand,
    a GC is *concurrent* if it is capable of running at the same time as the application
    without affecting its execution.
  prefs: []
  type: TYPE_NORMAL
- en: Live set
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A GC *live set* represents all the *live objects* of the current application.
    If there is no memory leak (or other issues), then the *live set* should have
    a constant load factor and a relatively constant size. During application execution,
    objects are added/removed from the heap and from the *live set* respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Allocation rate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Java allows us to set the size of the heap memory via the `–Xmx` options. This
    size should not exceed the memory available on your machine (server) and should
    be big enough to serve the *live set*. This can be achieved by taking into account
    the *allocation rate*, which is expressed as the amount of memory (for instance,
    MB) allocated per unit of time (for instance, seconds).
  prefs: []
  type: TYPE_NORMAL
- en: '**Important note**'
  prefs: []
  type: TYPE_NORMAL
- en: As a rule of thumb, try to set the heap size as 2.5 to 5 times the average size
    of the *live set*.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, when many objects are created, there will be many cleanups as
    well. This means that the GC will run at a high frequency and will need a higher
    *allocation rate*.
  prefs: []
  type: TYPE_NORMAL
- en: NUMA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: NUMA is the acronym for non-uniform memory access. A processor has its own memory
    (called local memory) but it can also access the memory of other processors. Access
    to its local memory is faster than access to non-local memory. Basically, NUMA
    is a memory architecture that attempts to optimize access to local memory.
  prefs: []
  type: TYPE_NORMAL
- en: Region-based
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A *region-based* GC divides the heap into smaller (eventually equal) regions/chunks
    of memory (for instance, G1 and ZGC are *region-based* GCs). Each such region
    can be allocated for different purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Generational garbage collection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Generational garbage collection* is an algorithm that excels in handling short-living
    objects. A GC that implements this algorithm is called a *generational GC*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This algorithm distinguishes between *young* and *old* objects and keeps them
    separate. The *young* objects are kept in an area called the *Young* generation
    or *Nursery* space, while the *old* objects are kept in an area called the *Old*
    generation or *Tenured* space. The following figure highlights the transitions
    of objects through the *Young* and *Old* generations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.1.png](img/B19665_12_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.1: The transitions of objects through Young and Old generations'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the *Young* generation is divided into two regions/spaces, named
    the *Eden* region or *Eden* space and the *Survivor* region or *Survivor* space.
    Initially, the *Young* generation is empty.
  prefs: []
  type: TYPE_NORMAL
- en: 'Objects that are newly created are placed in the *Eden* space by default. However,
    there is an exception for extremely large objects, called *humongous objects*,
    that exceed 50% of the region’s size. These objects are placed directly into the
    *Old* generation area, which may cause performance issues due to the increased
    occurrence of *major*/*full* GC events. It is important to note that GCs can trigger
    different types of events:'
  prefs: []
  type: TYPE_NORMAL
- en: '*MinorGC* – This event occurs in the *Young* generation when the *Eden* space
    becomes full. Its purpose is to collect *non-live* objects and promote the remaining
    ones into the *Survivor* space. This event is the most commonly triggered by a
    GC.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*MajorGC* – This event occurs in the *Old* generation and is responsible for
    collecting garbage from this area.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*MixedGC* – This is a *MinorGC* event followed by reclaiming the *Old* generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*FullGC* – Clean up the *Young* and *Old* generations and perform compacting
    of the *Old* generation (we can programmatically force a *FullGC* via `System.gc()`
    or `Runtime.getRunTime().gc()`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, let’s return to the topic of the *Young* generation. During the *epoch*
    (a GC complete cycle), the objects that survive (have not been garbage collected)
    are promoted into the *Survivor* space (the GC algorithm chooses between *Survivor
    space 0* (known as *S0* or *FromSpace*) or *1* (known as *S1* or *ToSpace*)).
    The objects that don’t fit into the *Survivor* space (if any) will be moved into
    the *Tenured* space – this is known as *premature promotion*. Usually, the GC
    handles the *Eden* space pretty quickly via the *MinorGC* events. Using local
    variables with short-living methods encourages the usage of *Eden* space and sustains
    the GC’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: Objects that are considered old enough (they have survived during multiple epochs)
    are eventually promoted into the *Old* generation. This is an area typically (but
    not mandatorily) larger than the *Young* generation. Some GCs use a fixed delimitation
    between these areas (for instance, the **Concurrent Mark Sweep** (**CMS**) GC)
    while others use an elastic boundary between these areas (for instance, the G1
    GC). The *Old* generation area takes a relatively long time to be garbage collected
    and has a lower frequency than the *Young* generation.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in *Figure 12.1*, the heap also contains an area named the *Metadata*
    space. Before JDK 8, this area was named *PermGenSpace* or *Permanent* generation.
    This area is used to store classes and methods. This area is specially designed
    to grow beyond the heap size into the native memory (if the size of this area
    goes beyond the physical memory, the operating system will use virtual memory
    – but be aware that moving data between physical and virtual memory is a costly
    operation that will affect the application performance). Via *Metadata* space,
    JVM avoids out-of-memory errors. However, this area can be garbage collected in
    order to remove unused classes/methods. In this context, there are a few flags
    that can help us to tune it, but we will cover these flags in *Problem 256*.
  prefs: []
  type: TYPE_NORMAL
- en: 246\. Tracing the generational GC process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this problem, let’s start from an arbitrary initial state of a generational
    GC and follow a few hypothetical epochs (generally, all generational GC works
    more or less as you’ll see in this problem). We start with the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.2.png](img/B19665_12_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.2: GC initial state'
  prefs: []
  type: TYPE_NORMAL
- en: 'At its initial state, the GC has an almost full *Eden* space (it stores objects
    1, 4, 5, 2, 6, and 3, and some free space – represented by those white gaps between
    objects) and empty *Survivor* and *Tenured* spaces. Moreover, object 7 should
    be added in the *Eden* space but there is not enough memory for it. When the *Eden*
    space cannot accommodate more objects, the GC triggers a *MinorGC* event. First,
    the *non-live objects* are identified. Here (as you can see in the following diagram),
    we have three objects (5, 2, and 3) that should be collected as garbage:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3.png](img/B19665_12_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.3: Identify the non-live objects from the Eden space'
  prefs: []
  type: TYPE_NORMAL
- en: 'These three objects are collected as garbage, so they are removed from the
    heap. Next, the *live objects* (1, 4, and 6) are moved into *Survivor space 0*.
    Finally, the new object (7) is added into the *Eden* space, as in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.4.png](img/B19665_12_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.4: Removing objects from memory (5, 2, and 3), moving objects to
    Survivor space 0 (1, 4, and 6), and adding object 7 into the Eden space'
  prefs: []
  type: TYPE_NORMAL
- en: Here, an *epoch* (complete GC cycle) has ended.
  prefs: []
  type: TYPE_NORMAL
- en: 'Later on, more objects are added into the *Eden* space until it is almost full
    again:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.5.png](img/B19665_12_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.5: The Eden space is almost full again'
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding the new object (12) requires a *Minor GC* event. Again, the *non-living
    objects* are identified as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.6.png](img/B19665_12_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.6: There are non-live objects in the Eden and Survivor 0 spaces'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are four objects that should be collected as garbage. In the *Eden* space,
    there are three objects (11, 10, and 9), and in *Survivor space 0*, there is one
    object (4). All four of these objects are removed from the heap. The *live objects*
    from *Survivor space 0* (1 and 6) are moved to *Survivor space 1*. The *live objects*
    from the *Eden* space (7 and 8) are also moved into *Survivor space 1*. At any
    moment in time, one of the *Survivor* spaces is empty. Finally, the new object
    (12) is added to *Eden* space, as in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.7.png](img/B19665_12_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.7: At the end of another epoch'
  prefs: []
  type: TYPE_NORMAL
- en: Here, another epoch has ended.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, objects 13, 14, 15, and 16 are added to the *Eden* space, which is almost
    full again:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.8.png](img/B19665_12_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.8: There is no memory available for object 17'
  prefs: []
  type: TYPE_NORMAL
- en: 'Being almost full, the *Eden* space cannot accommodate the new object, 17\.
    A new *Minor GC* event is triggered and objects 12, 15, 16, 13, 6, and 8 are identified
    as *non-live objects*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.9.png](img/B19665_12_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.9: There are several non-live objects in different spaces'
  prefs: []
  type: TYPE_NORMAL
- en: 'These objects (12, 15, 16, 13, 6, and 8) are removed from the heap. Next, object
    14 is moved from the *Eden* space to *Survivor space 0*. Afterward, objects 1
    and 7 (from *Survivor space 1*) are moved into *Survivor space 0*. Finally, the
    new object 17 is moved into the *Eden* space, as in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.10.png](img/B19665_12_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.10: The new object (17) is added to the Eden space'
  prefs: []
  type: TYPE_NORMAL
- en: Here, another *epoch* has ended.
  prefs: []
  type: TYPE_NORMAL
- en: 'We repeat the scenario and fill up the *Eden* space again. We stop when object
    22 should be added into the *Eden* space:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.11.png](img/B19665_12_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.11: Trying to add in Eden space object 22'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we already know, the GC marks all the *non-live objects* (here, 17, 21,
    18, and 7):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.12.png](img/B19665_12_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.12: Marking the non-live objects'
  prefs: []
  type: TYPE_NORMAL
- en: 'This time, the GC promotes object 1 (when it is considered old enough) from
    the *Young* generation to the *Old* generation. Next, the objects from the *Eden*
    space (19 and 20) and the objects from *Survivor space 0* (14) are moved into
    *Survivor space 1*. The result is sketched in the next figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.13.png](img/B19665_12_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.13: We have the first object promoted to Old generation'
  prefs: []
  type: TYPE_NORMAL
- en: At the end of this *epoch*, we finally have an object (1) in *Tenured* space.
    Continuing to run *epoch* after *epoch* will eventually fill up the *Tenured*
    space, which will not be able to accommodate more objects. In other words, the
    *Minor GC* events (which are *stop-the-world* events) will reclaim the memory
    of the *Young* generation until the *Old* generation is full. When that happens,
    a *Mixed GC* or even *Full GC* event will be triggered (the *Full GC* is also
    an STW event and will handle the *Metadata* space as well).
  prefs: []
  type: TYPE_NORMAL
- en: In a nutshell, this is how a GC works. Of course, there are many other internal/external
    factors that may influence the GC’s decisions.
  prefs: []
  type: TYPE_NORMAL
- en: 247\. Choosing the correct garbage collector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you’ll see in the next problem, Java allows us to choose between several
    garbage collectors. There is no silver bullet, so choosing the correct garbage
    collector for your particular application is an important decision that should
    be made based on three factors: *throughput*, *latency*, and *footprint*.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.14.png](img/B19665_12_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.14: The factors that affect the choice of GC'
  prefs: []
  type: TYPE_NORMAL
- en: '*Throughput* represents the total time spent running the application code vs.
    running the GC. For instance, your application may run 97% of the total time,
    so you have a throughput of 97%. The remaining 3% is the time spent running the
    GC.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Latency* measures how much the execution of the application is delayed by
    pauses caused by the GC. This is important because latency can affect the application’s
    responsiveness. These pauses may lead, at the interactivity level, to an unpleasant
    experience for the end users.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Footprint* represents the extra memory needed by the GC to run its algorithms.
    This is the memory needed in addition to the memory used by the application itself.'
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the proper GC based on these three factors is a very subjective decision.
    You may need a massive throughput while you can bear latencies, or you may not
    be able to afford latencies because you have high interactivity with the end users,
    or your scalability is in direct correlation with limited physical memory, so
    you are really interested in the footprint factor. As you’ll see in the next problem,
    each GC type has its own advantages and disadvantages in the context of these
    three factors.
  prefs: []
  type: TYPE_NORMAL
- en: 248\. Categorizing garbage collectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Garbage collectors have evolved exactly as Java itself has evolved. Today (JDK
    21), we distinguish between several GC types, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Serial garbage collector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallel garbage collector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Garbage-First (G1) collector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Z Garbage Collector (ZGC)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shenandoah Garbage Collector (not generational)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concurrent Mark Sweep (CMS) collector (deprecated)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s tackle the main aspects of each GC type.
  prefs: []
  type: TYPE_NORMAL
- en: Serial garbage collector
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The serial garbage collector is an STW single-threaded generational collector.
    Before running its own algorithms, this GC freezes/pauses all the application
    threads. This means that this GC is not suitable for multi-threaded applications
    such as server-side components. However, being focused on a very small footprint
    (useful for small heaps), this collector is a good fit for single-threaded applications
    (and single-processor machines) that can easily accommodate and tolerate a significant
    latency (for instance, batch jobs or bulk processing).
  prefs: []
  type: TYPE_NORMAL
- en: Parallel garbage collector
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The parallel garbage collector is an STW multi-threaded generational collector.
    Before running its own algorithms, this GC freezes/pauses all the application
    threads, but it speeds up the garbage collection by using multiple threads. In
    other words, this GC can take advantage of multi-processor machines and can be
    a good fit for multi-threaded applications that use medium/large datasets. This
    GC is focused on throughput rather than latency and comes with pauses of 1 second
    or more. So, if you are in a multi-threaded context that can afford pauses of
    1 second or more, then this GC is the right choice.
  prefs: []
  type: TYPE_NORMAL
- en: Garbage-First (G1) collector
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Garbage-First (G1) collector is an STW multi-threaded, region-based, generational
    collector focused on balanced performance. This GC was introduced in JDK 7 update
    4 as a default (since JDK 9) solution that sustains high throughput and low latency
    (a few hundred milliseconds). The price to pay for this performance is a more
    frequent rate of epochs. The GC will run more often, so be prepared to provide
    a CPU ready to accommodate more cycles than other GCs. This GC was designed for
    server-style applications that are executed on multi-processor machines with massive
    memory (large heap size). Also known as a *mostly concurrent* collector, G1 performs
    heavily next to the application using equally sized spaces/regions (from 1 to
    32 MB). So, if you can afford a large heap size and need low latency, then G1
    is the proper choice. We will talk in detail about G1 in subsequent problems.
  prefs: []
  type: TYPE_NORMAL
- en: Z Garbage Collector (ZGC)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Z Garbage Collector (ZGC) was introduced for production starting with JDK 15
    as a low-latency GC that can handle large heap sizes (terabytes). Like G1, ZGC
    works concurrently but it guarantees to not stop the application threads for more
    than a few milliseconds (the documentation even states that ZGC can perform with
    sub-millisecond max pause times). We will cover it in detail in subsequent problems.
  prefs: []
  type: TYPE_NORMAL
- en: Shenandoah Garbage Collector
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Shenandoah Garbage Collector was introduced in JDK 12 (and became more reliable
    in JDK 17) as a very low-latency, highly responsive GC (sub-millisecond pauses).
    It performs its job (including compaction) concurrently with the application.
    Shenandoah pauses are extremely short and independent of the heap size. Garbage
    collecting a 1 GB heap or a 300 GB heap should produce similar pauses.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrent Mark Sweep (CMS) collector (deprecated)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CMS is a *mostly concurrent* collector deprecated by G1\. Since it is deprecated,
    I will not talk about it further.
  prefs: []
  type: TYPE_NORMAL
- en: 249\. Introducing G1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The G1 Garbage Collector is probably the most mature, maintained, and improved
    GC in Java. It was introduced in JDK 7 update 4, and from JDK 9, it became the
    default GC. This GC sustains high throughput and low latency (a few hundred milliseconds),
    being known for its balanced performance.
  prefs: []
  type: TYPE_NORMAL
- en: Internally, G1 splits the heap into equally small chunks (max size of 32 MB),
    which are independent of each other and can be allocated dynamically to *Eden*,
    *Survivor*, or *Tenured* spaces. Each such chunk is called the G1 *heap region*.
    So, G1 is a region-based GC.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.15.png](img/B19665_12_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.15: G1 splits the memory heap into equal small chunks'
  prefs: []
  type: TYPE_NORMAL
- en: This architecture has a significant number of advantages. Probably, the most
    important one is represented by the fact that the *Old* generation can be cleaned
    up efficiently by cleaning it up in parts that sustain low latency.
  prefs: []
  type: TYPE_NORMAL
- en: For a heap size smaller than 4 GB, G1 will create regions of 1 MB. For heaps
    between 4 and 8 GB, G1 will create regions of 2 MB, and so on, up to 32 MB for
    a heap of 64 GB or larger. Basically, the JVM sets a number of regions that have
    a power of 2 and between 1 and 32 MB (typically, during the application start,
    the JVM sets up around 2,000+ regions).
  prefs: []
  type: TYPE_NORMAL
- en: Design principles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'G1 was designed on a set of principles, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Balanced performance – Designed to balance throughput and low latency to sustain
    performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generational – Dynamically split the heap into the *Young* and *Old* generations
    and focus on the *Young* generation, since in this region there is more garbage
    (most objects die in the *Young* generation region). The idea that most objects
    are short-lived is also known as the *generational hypothesis*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incremental collecting of *Old* generation – G1 eventually moves objects from
    the *Young* to the *Old* generation and leaves them there to die slowly and collects
    them incrementally.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mostly concurrent – G1 strives to perform heavy tasks next to the application
    (concurrently) with low and predictable pauses.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thanks to these design principles, G1 has deprecated the CMS collector.
  prefs: []
  type: TYPE_NORMAL
- en: 250\. Tackling G1 throughput improvements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: G1 has made major progress from JDK 8 to JDK 20\. Some of these improvements
    have been reflected in throughput. Of course, this throughput improvement is dependent
    on a lot of factors (application, machine, tuning, and so on) but you may expect
    at least 10% higher throughput in JDK 18/20 than in JDK 8.
  prefs: []
  type: TYPE_NORMAL
- en: In order to increase throughput, G1 has passed through several changes, as follows.
  prefs: []
  type: TYPE_NORMAL
- en: Delaying the start of the Old generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Starting with JDK 9, G1 is heavily focused on collecting garbage from the *Young*
    generation while delaying the start (initialization, resource allocation, and
    so on) of the *Old* generation to the last moment (it anticipates when the *Old*
    generation should be started).
  prefs: []
  type: TYPE_NORMAL
- en: Focusing on easy pickings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By easy pickings, we mean objects that are short-lived (for instance, temporary
    buffers), occupy a significant amount of heap, and can be collected easily at
    low cost with important benefits. Starting with JDK 9, G1 is highly focused on
    easy pickings.
  prefs: []
  type: TYPE_NORMAL
- en: Improving NUMA-aware memory allocation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: NUMA stands for non-uniform memory access and it was described in *Problem 245*.
    G1 takes advantage of NUMA from JDK 14 and it is continuously improved. If NUMA
    is enabled, then JVM requires the OS to place G1 heap regions on NUMA nodes. At
    the end of this process, the whole heap should be located evenly across the NUMA
    nodes that are active.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.16.png](img/B19665_12_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.16: Heap memory without and with NUMA'
  prefs: []
  type: TYPE_NORMAL
- en: 'The relationship between G1 heap regions and memory pages (operating system
    pages – [https://en.wikipedia.org/wiki/Page_(computer_memory)](https://en.wikipedia.org/wiki/Page_(computer_memory))
    falls into one of these two cases:'
  prefs: []
  type: TYPE_NORMAL
- en: If the size of a G1 heap region is greater than or equal to the size of a memory
    page, then a G1 heap region will consist of multiple memory pages (*Figure 12.17*,
    left-hand side).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the size of a G1 heap region is smaller than or equal to the size of a memory
    page, then a memory page will consist of multiple G1 heap regions (*Figure 12.17*,
    right-hand side).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 12.17.png](img/B19665_12_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.17: G1 heap region and memory page relationship'
  prefs: []
  type: TYPE_NORMAL
- en: Without NUMA, the G1 GC allocates memory to threads from a single common memory
    allocator. With NUMA, there is a memory allocator per NUMA node, and memory is
    allocated to threads based on these NUMA nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Improving NUMA allocation awareness is a continuous goal of G1.
  prefs: []
  type: TYPE_NORMAL
- en: Parallelized full-heap collections
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Among other not-so-common optimizations, we have the parallelization of full-heap
    collection. This was added in JDK 10 as a solution to make full-heap collections
    as fast as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Other improvements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tons of small improvements have been added to JVM itself, and their effects
    are reflected in GC performance as well. This means that by simply updating to
    the latest JDK, our GC will perform better. You’ll notice an improvement of at
    least 10% between JDK 8 and JDK 20.
  prefs: []
  type: TYPE_NORMAL
- en: 251\. Tackling G1 latency improvements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: G1 GC latency has also recorded some improvements from JDK 8 to JDK 20 (which
    are obviously reflected in G1 GC throughput as well).
  prefs: []
  type: TYPE_NORMAL
- en: In order to decrease latency, G1 has passed through several changes, as follows.
  prefs: []
  type: TYPE_NORMAL
- en: Merge parallel phases into a larger one
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Starting with JDK 8, many aspects of G1 have been parallelized. In other words,
    at any moment in time, we may have in execution multiple parallel phases. Starting
    with JDK 9, these parallel phases can be merged into a single larger one. In practice,
    this means less synchronization and less time spent creating/destroying threads.
    As a result, this improvement speeds up the parallelization processing, leading
    to less latency.
  prefs: []
  type: TYPE_NORMAL
- en: Reduction of metadata
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Reduction of metadata was added in JDK 11\. Practically, G1 attempts to manage
    less metadata by reducing its amount as much as possible. Less data to manage
    means better latency. Of course, this means a smaller footprint as well.
  prefs: []
  type: TYPE_NORMAL
- en: Better work balancing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Work balancing was improved starting with JDK 11\. In a nutshell, this means
    that threads that have finished their current work can steal work from other threads.
    In practice, this means that the tasks are done faster since all threads are working
    (on their own work or on stolen work) and none of them are just hanging on. So,
    smarter algorithms have been developed to orchestrate and keep threads busy in
    order to finish the tasks faster and decrease latency. However, reducing the overhead
    of stealing work is still a subject of improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Better parallelization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Better parallelization is available starting with JDK 14\. In practice, G1 removes
    all duplicates from potential areas with references. Afterward, it applies parallelization
    instead of brute force.
  prefs: []
  type: TYPE_NORMAL
- en: Better reference scanning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to sustain better parallelization, JDK 15 has also improved the reference
    scanning in the collected areas. JDK 14 knows how to remove duplicates and parallelize
    the data processing, while JDK 15 knows how to scan references more optimally.
    Their effects are combined into decreasing latency.
  prefs: []
  type: TYPE_NORMAL
- en: Other improvements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A lot of time has been spent improving so-called uncommon situations. For instance,
    special attention has been focused on *evacuation failures* (the attempt of moving
    the *live objects* between two memory areas and compacting them is known as *evacuation
    fashion*, and when moving objects around leads to out-of-memory issues, then we
    have an *evacuation failure*). This corner case has been seriously improved in
    order to handle such scenarios faster than before (before JDK 17).
  prefs: []
  type: TYPE_NORMAL
- en: 252\. Tackling G1 footprint improvements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Between JDK 8 and JDK 20, the G1 footprint has been improved by focusing on
    efficient metadata and freeing the memory as quickly as possible.
  prefs: []
  type: TYPE_NORMAL
- en: In order to optimize its footprint, G1 has passed through several changes, as
    follows.
  prefs: []
  type: TYPE_NORMAL
- en: Maintain only the needed metadata
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to maintain only the needed metadata, JDK 11 is capable of concurrently
    (re)creating the needed data and freeing it as fast as possible. In JDK 17, the
    focus on the needed metadata has been reiterated and only the absolutely required
    data is kept around. Moreover, JDK 18 comes up with a denser representation of
    data. All these improvements are reflected in a smaller footprint.
  prefs: []
  type: TYPE_NORMAL
- en: Release memory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Starting with JDK 17, the G1 GC is capable of concurrently releasing memory
    (giving it back to the OS). This means that memory can be optimally reused and
    is available to serve other tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 253\. Introducing ZGC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Z Garbage Collector (ZGC) was introduced for the first time (as an experimental
    feature) in JDK 11\. It was promoted to the production stage (production ready)
    in JDK 15 under JEP 377\. It continues to be improved as we speak – in JDK 21,
    ZGC sustains application performance by maintaining separate generations for young
    and old objects. Basically, this minimizes allocation stalls and heap memory overhead.
    Moreover, JDK 21 (JEP 439) has promoted ZGC’s status from Targeted to Completed.
  prefs: []
  type: TYPE_NORMAL
- en: ZGC is concurrent (works at the same time as the application based on low-level
    concurrency primitives such as *load barriers* and *colored pointers*), tracing
    (traversing the object graph to identify *live* and *non-live* objects), and compacting
    (fight against fragmentation). It is also NUMA-aware and region-based.
  prefs: []
  type: TYPE_NORMAL
- en: ZGC was specially designed as a low-latency, highly scalable GC capable of handling
    from small (a few megabytes; the documentation states 8 MB) to massive heaps (terabytes;
    the documentation states 16 TB) with pauses (pulse times) of a maximum of a few
    milliseconds (the documentation states sub-millisecond max pause times).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.18.png](img/B19665_12_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.18: ZGC is focused on low latency'
  prefs: []
  type: TYPE_NORMAL
- en: It is very important to say that pauses don’t increase with the heap size (pulse
    times are O(1), so they execute in constant time).
  prefs: []
  type: TYPE_NORMAL
- en: The shortcoming (trade-off) of ZGC relies on throughput. In other words, ZGC
    throughput is slightly reduced (a few percent, for instance from 0% to 10% in
    some cases) in comparison with G1 throughput.
  prefs: []
  type: TYPE_NORMAL
- en: Starting with JDK 16, ZGC takes advantage of a concurrent thread stack, and
    starting with JDK 18, it supports string de-duplication. These are just two of
    the major improvements next to many other improvements.
  prefs: []
  type: TYPE_NORMAL
- en: ZGC is auto-tuned. In other words, as you’ll see in *Problem 256*, ZGC has just
    a few options that we can tune while most of the tuning is automatic.
  prefs: []
  type: TYPE_NORMAL
- en: ZGC is concurrent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'G1 and ZGC are both concurrent, but they don’t follow the same path. ZGC strives
    to collect as much garbage as possible in a concurrent fashion. For this, ZGC
    relies on three main lightweight (very short, sub-millisecond) pauses and three
    concurrent phases, as in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.19.png](img/B19665_12_19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.19: ZGC concurrency'
  prefs: []
  type: TYPE_NORMAL
- en: 'Each of the three phases is signaled by a synchronization point (pause):'
  prefs: []
  type: TYPE_NORMAL
- en: '*Pause Mark Start –* This pause signals that the *Concurrent Mark* phase follows.
    During this synchronization point, ZGC prepares the current state for executing
    the *Concurrent Mark* phase. This is a lightweight pause that performs some settings
    on *colored pointers* and resets a few flags and counters. Next, the *Concurrent
    Mark* phase runs concurrently and marks the objects from the heap.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Pause Mark End –* This pause signals the end of the *Concurrent Mark* phase.
    It also pauses before executing the *Concurrent Prepare for Relocation* phase.
    This phase is responsible for locating all the *live* objects from sparsely populated
    regions and marks them as candidates to be moved/evacuated to other regions. Moreover,
    during this phase, ZGC deallocates regions that don’t contain *live* objects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Pause Relocate Start* – This pause signals that the *Concurrent Relocate*
    phase follows. During this phase, the objects marked as evacuation candidates
    in the previous phase are effectively moved (copied) from the current region to
    the new region. Their references are also restored, being deallocated from the
    current region and reallocated to the new region.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ZGC and colored pointers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ZGC runs next to the application and manipulates (moves around) the objects
    used by that application. This may lead to unexpected errors (for instance, the
    application may attempt to use out-of-date references) that cause the application
    to act weirdly or even crash. In order to prevent such scenarios, ZGC relies on
    two low-level concurrency primitives known as *colored pointer* and *load barriers*.
  prefs: []
  type: TYPE_NORMAL
- en: A *colored pointer* is a 64-bit pointer. This pointer is used by ZGC with a
    44-bit object address capable of handling up to 16 terabytes.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.20.png](img/B19665_12_20.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.20: Colored pointer'
  prefs: []
  type: TYPE_NORMAL
- en: 'A *colored pointer* reserves 20 bits for storing metadata about this pointer.
    The most important metadata is:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Finalizable* – 1 bit that indicates if an object is reachable (*live* object)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Remapped* – 1 bit that indicates if an object doesn’t point into a relocation
    set'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Marked0*/*Marked1* – 2 bits that indicate if an object is or is not marked'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As well as colored pointers, ZGC needs load barriers.
  prefs: []
  type: TYPE_NORMAL
- en: ZGC and load barriers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Load barriers* are portions of code injected by the compiler to handle *colored
    pointers*. While the application is not aware of *colored pointers*, ZGC needs
    to interpret and work with them, and this is exactly the job of *load barriers*.
    For instance, let’s assume that we have, in the application, the following snippet
    of code (I’ve intentionally added the line numbers manually):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The compiler analyzes the code to decide where to inject a *load barrier*.
    The conclusion is that the only place where a *load barrier* should be injected
    is between lines 1 and 2 because that is the only place where an object is loaded
    from the heap. In line 2, there is no need for a *load barrier* since there is
    a copy of the memory reference. In line 3, there is also no need for a *load barrier*
    since there is a method reference. Finally, in line 4, there is no need for a
    *load barrier* since there is no object reference. So, ZGC sees this code as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The purpose of the *load barrier* is to ensure that the pointers are valid (shown
    by having a good color). If a bad color is encountered, then the *load barrier*
    tries to heal it (update the pointer, relocate the object reference, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: ZGC is region-based
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'ZGC is a *region-based* GC, so it divides the heap into smaller regions/chunks
    that are allocated to the *Young* or *Old* generation, as in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.21.png](img/B19665_12_21.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.21: ZGC heap regions'
  prefs: []
  type: TYPE_NORMAL
- en: 'Exactly like G1, ZGC is a *region-based* GC. Nevertheless, ZGC is more powerful
    than G1 and has the capability to dynamically increase/decrease the number of
    active regions during runtime. Moreover, ZGC can rely on regions of three sizes,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Small region – These regions are 2 MB.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Medium region – These regions can be from 4 MB to 32 MB. They are dynamically
    sized.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Large region – These are regions reserved for *humongous* objects. These are
    tightly fitted regions that can be smaller or larger than a medium region.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, at a glance, ZGC is a concurrent GC with constant pause times (sub-millisecond),
    working in parallel mode, and capable of fighting against fragmentation via compacting.
    Moreover, it is region-based, NUMA-aware, capable of auto-tuning, and relies on
    *colored pointers* and *load barriers*.
  prefs: []
  type: TYPE_NORMAL
- en: 254\. Monitoring garbage collectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Monitoring the activity and evolution in the timeline of your GC is a major
    aspect in order to identify potential performance issues. For instance, you may
    be interested in monitoring pause times, identifying the frequency and types of
    GC events, what spaces are filled up by the triggered GC events, and so on. The
    main goal is to collect as much information as possible that can be helpful in
    troubleshooting performance issues related to heap memory and GC evolution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Any modern IDE provides profilers that contain (among other related things)
    information and real-time graphs about the GC *epochs*/cycles. For instance, the
    following figure is from the NetBeans IDE, which displays the GC evolution (heap
    status) as an item of the toolbar (by simply clicking on that area, you can force
    the GC to perform garbage collection):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.22.png](img/B19665_12_22.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.22: NetBeans display GC evolution on the toolbar'
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, a more detailed view is available via the NetBeans profiler:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.23.png](img/B19665_12_23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.23: NetBeans profiler for GC'
  prefs: []
  type: TYPE_NORMAL
- en: Among other tools that can be used to monitor your GC are the *jstat* command-line
    utility (`jstat -gc $JAVA_PID`) and *JConsole* (Java Monitoring and Management
    Console).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure is a screenshot from *JConsole*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.24.png](img/B19665_12_24.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.24: Monitoring the GC via JConsole'
  prefs: []
  type: TYPE_NORMAL
- en: You may also be interested in **visualgc** (**Visual Garbage Collection Monitoring
    Tool**) from Oracle, **JDK VisualGC** (IntelliJ IDE plugin), and **Memory Analyzer**
    (**MAT**) from Eclipse.
  prefs: []
  type: TYPE_NORMAL
- en: 255\. Logging garbage collectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Analyzing the GC logs is another approach that can be useful for finding memory
    issues. Since GC logs don’t add a significant overhead, they can be enabled in
    production for debugging purposes. Really, GC logs have an insignificant overhead,
    so you should definitely use them!
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider some simple Java code that adds and removes from `List<String>`.
    Adding and removing the code requires a full GC via `System.gc()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Next, we want to run this simple application and log the GC activity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before JDK 9, we can obtain a quick and verbose log of GC via the `-verbose:gc`
    option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'A possible output will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the simplest GC log. For more details, we can add the `-XX:+PrintGCDetails`
    option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Moreover, we can attach a few options for obtaining information about tenuring
    distribution (`-XX:+PrintTenuringDistribution`), garbage collector time stamps
    (`-XX:+PrintGCTimeStamps`), the class histogram (`-XX:+PrintClassHistogram`),
    and the application stopped time (`-XX:+PrintGCApplicationStoppedTime`).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this context, GC logs are available on the console (stdout) using the info
    level. You can easily redirect the GC logs to a file via the `-Xloggc` option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Actually, `-Xloggc` is deprecated and you should use it only if you are using
    a JDK earlier than version 9\. Starting with JDK 9 (JEP 158 – [https://openjdk.org/jeps/158](https://openjdk.org/jeps/158)),
    we have a *unified logging system* for all JVM components.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, starting with JDK 9, we have a unified logging system via the `–Xlog` option.
    The equivalent of `-XX:+PrintGCDetails -verbose:gc` is `-Xlog:gc*`. If we want
    to redirect GC logs to a file using the debug level, then we can do it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `gclog.txt` will be saved in the application root folder. If you remove
    the `*` character, then you’ll get a less verbose GC log.
  prefs: []
  type: TYPE_NORMAL
- en: Logging only NUMA logs is available via `-Xlog:numa*={log level}`.
  prefs: []
  type: TYPE_NORMAL
- en: Having the GC log is half of the problem. The other half consists of interpreting
    this log. As you can see, this is not that easy. Fortunately, you don’t have to
    bother reading the log files because we have tools capable of parsing, analyzing,
    and providing detailed reports from GC logs.
  prefs: []
  type: TYPE_NORMAL
- en: One of these tools is Universal GC Log Analyzer ([https://gceasy.io/](https://gceasy.io/)).
    Using the free version, we can upload our `gclog.txt` file and get a detailed
    report. For instance, in the following figure, we can see how memory was allocated
    for our application.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.25.png](img/B19665_12_25.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.25: A screenshot from Universal GC Log Analyzer (GCEasy) report'
  prefs: []
  type: TYPE_NORMAL
- en: This figure is just a very small part of the report. Try it yourself to see
    the full report. Other similar tools that you may like to try are GCViewer, GCPlot,
    IBM Garbage Collection and Memory Visualizer, garbagecat, SolarWinds Loggly, Sematext
    Logs, **Java Flight Recorder** (**JFR**), jvm-gc-logs-analyzer, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 256\. Tuning garbage collectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Garbage collectors are complex machinery whose performances are highly related
    to their settings (startup parameters) in the context of the current JVM, current
    application, and hardware. Since the GC consumes and shares resources (memory,
    CPU time, and so on) with our application, it is essential to tune it to work
    as efficiently as possible. If the GC is not efficient, then we may face significant
    pause times that will negatively impact the application run.
  prefs: []
  type: TYPE_NORMAL
- en: In this problem, we will cover the main tuning options available for the serial
    GC, parallel GC, G1 GC, and ZGC.
  prefs: []
  type: TYPE_NORMAL
- en: How to tune
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before attempting to tune the GC, ensure that it is really causing trouble.
    By inspecting and correlating the charts and logs, you can identify such troubles
    and decide where you should act (what parameters should be tuned). Check out the
    usage of the heap memory and how objects fill up the *Eden*, *Survivor*, and *Tenured*
    spaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Typically, a healthy GC produces a heap usage graph known as *shark teeth*,
    as in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.26.png](img/B19665_12_26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.26: Healthy heap usage'
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, check out the 90^(th) and 99^(th) percentiles along with the average
    GC time. This information can give you a hint about whether more memory is needed
    or if it is cleared properly.
  prefs: []
  type: TYPE_NORMAL
- en: Once you identify the GC troubles, try to tackle them one by one. Don’t rush
    to change several parameters at once because it will be hard to manage and analyze
    their combined effect. Try to modify one of them and experiment to see what’s
    happening and what the results are. If you see some benefits, then go for the
    next one and experiment again. Observe if the combined effect has been improved
    or not. Otherwise, maybe it is better to restore this one to its default value
    before going for the next one.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning the serial garbage collector
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The serial garbage collector can be enabled via `-XX:+UseSerialGC`.
  prefs: []
  type: TYPE_NORMAL
- en: Since this is a single-threaded GC, there is not much to tune. However, you
    may adjust the heap size via `–Xmx` and `–Xms` (for instance, a heap size of 3
    GB can be set via `–Xmx3g` and `–Xms3g`) and the *Young* generation size via the
    `–Xmn` option. Nevertheless, these options work with all types of GC for setting
    the heap size.
  prefs: []
  type: TYPE_NORMAL
- en: Tunning the parallel garbage collector
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The parallel garbage collector can be enabled via `-XX:+UseParallelGC`.
  prefs: []
  type: TYPE_NORMAL
- en: This GC is multi-threaded and we can control the number of threads used for
    cleaning tasks via the `-XX:ParallelGCThreads` option (for instance, setting six
    threads can be done with `-XX:ParallelGCThreads=6`).
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that a higher number of threads results in a higher fragmentation
    of the heap reserved for the *Tenured* space. Each thread that participates in
    a *Minor* GC event will reserve some space in the *Tenured* space for its promotions
    goals. This will lead to serious fragmentation of the *Tenured* space. Fixing
    this issue requires reducing the number of threads and increasing the size of
    the *Old* generation.
  prefs: []
  type: TYPE_NORMAL
- en: The maximum pause time can be controlled via the `-XX:MaxGCPauseMillis` option
    (for instance, `-XX:MaxGCPauseMillis=150`, which will ensure maximum pause times
    of 150 milliseconds between two consecutive runs/events of GC). However, be aware
    that bigger pause times will allow more garbage to hit the heap. This means that
    the next run of the GC will be more expensive. On the other hand, a small pause
    time will instruct the GC to run more frequently, and this may cause the application
    to spend too much time on garbage collection.
  prefs: []
  type: TYPE_NORMAL
- en: Next, the maximum throughput that we want to achieve can be set via the `-XX:GCTimeRatio`
    option. This option is evaluated as the ratio between the time spent inside vs.
    outside the GC. It is a percentage computed as 1/(1 + n). In other words, `-XX:GCTimeRatio`
    specifies the amount of time dedicated to garbage collection in a 1/(1+n) ratio.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, if we set this option as `-XX:GCTimeRatio=14`, then we target
    a goal of 1/15\. This means that 6% of the total time should be spent in garbage
    collection (by default, this option is set to 99, or 1% of time is spent on garbage
    collection).
  prefs: []
  type: TYPE_NORMAL
- en: If you get an `OutOfMemoryError`, then most probably, this is caused by too
    much time spent on garbage collection. For instance, if more than 98% of the time
    is spent recovering less than 2% of the heap, then you’ll see such an error. In
    other words, GC has spent a lot of time cleaning a small part of the heap. This
    may indicate memory leaks or a heap that is too small. Nevertheless, if you can
    live with this error, then you can suppress it via the `-XX:-UseGCOverheadLimit`
    option.
  prefs: []
  type: TYPE_NORMAL
- en: We can also control the size of the *Young*/*Old* generation. You can control
    the growth of the *Young* generation via `-XX:YoungGenerationSizeIncrement`, and
    the growth of the *Old* generation via `-XX:TenuredGenerationSizeIncrement`. The
    values of these options are percentages (by default, the growth percentage is
    20% and the shrinking percentage is 5%). Moreover, you can control the shrinking
    percentage by simply setting the `-XX:AdaptiveSizeDecrementScaleFactor` option.
    The shrinking of the *Young* generation is automatically computed via `-XX:YoungGenerationSizeIncrement`/`-XX:AdaptiveSizeDecrementScaleFactor`.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning the G1 garbage collector
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The G1 garbage collector can be enabled via `-XX:+UseG1GC`.
  prefs: []
  type: TYPE_NORMAL
- en: By default, G1 takes care of the *Young* generation. Basically, it cleans the
    *Young* generation and promotes the reachable objects to the *Old* generation
    until it hits a threshold of 45%. This default value can be altered via `-XX:InitiatingHeapOccupancyPercent`.
  prefs: []
  type: TYPE_NORMAL
- en: When tuning the G1 collector, we can target throughput, latency, or footprint.
    When tuning for latency, we have to focus on low pause times. This can be achieved
    by setting the `–Xmx` and `–Xms` options at the same value (to avoid heap resizing).
    Moreover, we can rely on the `-XX:+AlwaysPreTouch` and `-XX:+UseLargePages` flag
    options to load the (large) memory pages at the start of the application.
  prefs: []
  type: TYPE_NORMAL
- en: If latency is affected by the *Young* generation size, then it is a good idea
    to decrease its size via `-XX:G1NewSizePercent` and `-XX:G1MaxNewSizePercent`.
    On the other hand, if the *Mixed* GC events affect latency, then we should focus
    on spreading the *Tenured* space across more collections via the `-XX:G1MixedGCCountTarget`
    flag option. In addition, we may want to focus on `-XX:G1HeapWastePercent` (stop
    earlier the *Tenured* space cleanup) and `-XX:G1MixedGCLiveThresholdPercent` (the
    *Tenured* space becomes part of a mixed collection only when this threshold is
    exceeded (defaults to 65)). You may also be interested in `-XX:G1RSetUpdatingPauseTimePercent`,
    `-XX:-ReduceInitialCardMarks`, and `-XX:G1RSetRegionEntries` (for details, see
    the G1 documentation).
  prefs: []
  type: TYPE_NORMAL
- en: When tuning for throughput (applications that manipulate a lot of data need
    a GC capable of cleaning as much garbage as possible), we have to focus on the
    `-XX:MaxGCPauseMillis` option. When this option has a low effect, then you should
    focus on `-XX:G1NewSizePercent` and `-XX:G1MaxNewSizePercent`. Basically, G1 strives
    to bound the *Young* generation size between the values of `-XX:G1NewSizePercent`
    (default is 5) and `-XX:G1MaxNewSizePercent` (default is 60). By juggling these
    three options, we can relax the GC and give it more time and space to process
    a lot of garbage. In addition, throughput can be sustained via the `-XX:G1RSetUpdatingPauseTimePercent`
    option.
  prefs: []
  type: TYPE_NORMAL
- en: By increasing the value of this option, we decrease the time spent in concurrent
    parts while performing more work when pausing the application’s threads. In addition,
    as in the case of tuning for latency, we may want to avoid heap resizing (set
    `–Xmx` and `–Xms` at the same value) and turn on the `-XX:+AlwaysPreTouch` and
    `-XX:+UseLargePages` flag options.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning for footprint may be influenced by setting the `-XX:GCTimeRatio`. This
    defaults to 12 (8%) but we can increase it to force the GC to spend more time
    in garbage collection. As a result, more heap memory will be free, but this is
    not a general rule. It is recommended to experiment and see how it really works.
    Moreover, since JDK 8 (update 20), we can set up the `-XX:+UseStringDeduplication`
    flag option. Practically, if this option is enabled, then G1 locates duplicate
    strings and holds a single reference to one string while cleaning up the duplicates.
    This should result in a more efficient and optimal usage of the heap memory. You
    also may want to consult the documentation for `-XX:+PrintStringDeduplicationStatistics`
    and `-XX:StringDeduplicationAgeThreshold=n`.
  prefs: []
  type: TYPE_NORMAL
- en: As you already know, G1 splits the heap into small regions up to 32 MB. In practice,
    this may lead to performance degradation, especially for large objects on very
    large heaps. But, starting with JDK 18, the maximum region size was set up to
    512 MB. Whenever you need, you can control the maximum region size via the `-XX:G1HeapRegionSize`.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning Z Garbage Collector
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Z Garbage Collector can be enabled via `-XX:+UseZGC` (before JDK 15, you may
    also need `-XX:+UnlockExperimentalVMOptions`).
  prefs: []
  type: TYPE_NORMAL
- en: One of the most important settings of this GC is `–Xmx` to set up the maximum
    heap size. Next to this one, we have `-XX:ConcGCThreads=n`, where `n` is the number
    of threads used by ZGC. However, ZGC is fully capable of dynamically determining
    the optimal value for this option, so think twice before modifying it.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning Metaspace (Metadata space)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If your focus is on tuning Metaspace, then you’ll be interested in the following
    options:'
  prefs: []
  type: TYPE_NORMAL
- en: '`-XX:MetaspaceSize` – Set the initial size of Metaspace'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-XX:MaxMetaspaceSize` – Set the maximum size of Metaspace'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-XX:MinMetaspaceFreeRatio` – Set the class metadata capacity that should be
    free after running the GC (this is the minimum value as a percentage)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-XX:MaxMetaspaceFreeRatio` – Set the class metadata capacity that should be
    free after running the GC (this is the maximum value as a percentage)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controlling the size and behavior of the Metaspace can also be part of tuning
    your GC. Again, experimenting and comparing the results is the main rule of thumb
    that can lead you to a successful and optimal GC.
  prefs: []
  type: TYPE_NORMAL
- en: 257\. Introducing Application Class Data Sharing (AppCDS, or Java’s Startup
    Booster)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Launching a Java application is a multi-step process. Before executing the
    bytecode of a class, the JVM has to perform at least the following steps for a
    given class name:'
  prefs: []
  type: TYPE_NORMAL
- en: Look up the class on disk (JVM has to scan the disk and find the given class
    name).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Load the class (JVM opens the file and loads its content).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check the bytecode (JVM verifies the integrity of the content).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pull the bytecode internally (JVM transfers the code into an internal data structure).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Obviously, these steps are not cost-free. Loading hundreds/thousands of classes
    will have a significant overhead on launching time and memory footprint. Typically,
    an application’s JAR remains unchanged for a long time, but JVM performs the previous
    steps and obtains the same result every time we launch the application.
  prefs: []
  type: TYPE_NORMAL
- en: Improving/accelerating the startup performance and even reducing the memory
    footprint are the main goals of Application Class Data Sharing (AppCDS). In a
    nutshell, AppCDS was initially popularized in JDK 10 (2018), and it was simplified
    in JDK 13 and JDK 19\. The idea of AppCDS is to perform the previous steps once
    and dump the result into an archive. This archive can be reused for subsequent
    launches and even shared across multiple JVM instances running on the same host.
    The bigger the application is, the bigger the startup benefits are.
  prefs: []
  type: TYPE_NORMAL
- en: 'Putting these ideas into practice requires the following three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create the list of classes that should be shared between the application instances.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Archive this list of classes in an archive suitable for memory mapping.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Give the resulting archive to every application startup (every application instance).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Depending on the JDK used, you may have to manually follow these steps or only
    a part of them. The AppCDS algorithm is constantly improved, so its use depends
    on your JDK, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: In JDK 10/11, you have to follow the previous three steps. However, if you want
    to share only the JDK classes (not the application classes), then you can skip
    step 1\. JDK has already prepared the list of classes that should be shared in
    `$JAVA_HOME\lib\classlist` (there are around 1,200 classes).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In JDK 12+, you can skip steps 1 and 2 because an archive of JDK classes is
    already available. However, if you want to share the application classes as well,
    then you need to follow all three steps.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In JDK 13+, we can take advantage of dynamic CDS archives. Practically, JVM
    collects the classes to be added into the archive at application runtime. Steps
    1 and 2 are merged automatically.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In JDK 19+, we can take advantage of the autogenerated shared archive. The CDS
    archive is built and used in a single command.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tackling a JDK class data archive
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tackling a JDK class data archive means that we will create a reusable archive
    containing only JDK classes, not the classes of our application.
  prefs: []
  type: TYPE_NORMAL
- en: JDK 10/JDK 11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In JDK 10/11, we can use the already existent `$JAVA_HOME/lib/classlist`. This
    is a file that contains the list of JDK classes, and you can easily inspect it
    with a text editor. Having the class list, we can create the proper CDS archive
    via the `–Xshare:dump` option, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The resulting archive will be stored in `$JAVA_HOME\bin\server\classes.jsa`
    (this is the default location and you may need to run this command as an administrator
    to avoid a permission denied restriction).
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can use this archive via `–Xshare:on`, as follows (if you run under
    JDK 11, then `--enable-preview` is also needed, but I’ll skip it here):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use the unified logging system to track CDS work via `–Xlog`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In the output, we can see that a shared object is marked with a significant
    message, as follows (objects that are not shared don’t contain the “*shared objects
    file*” text):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'By default, JVM scans for archives in the default location. But, if we move
    the archive to another location (for instance, in the application root folder),
    then we have to indicate this location via `-XX:SharedArchiveFile`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Actually, the default value of `–Xshare` is `auto`. This means that if an archive
    is found, then it is used automatically. So, if you omit `–Xshare:on`, then JVM
    relies on `–Xshare:auto`, which has the same effect. If you want to shut down
    CDS support, then use `–Xshare:off`.
  prefs: []
  type: TYPE_NORMAL
- en: JDK 12+
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'JDK 12+ comes with an already prepared archive for JDK classes, so there is
    no need to create one (no need to use `–Xshare:dump`). JVM will use it automatically
    thanks to `–Xshare:auto` or via the explicit `–Xshare:on`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Of course, if you have a different location than the default one (`$JAVA_HOME\bin\server\classes.jsa`),
    then use `-XX:SharedArchiveFile`.
  prefs: []
  type: TYPE_NORMAL
- en: Tackling application class data archive
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Besides the JDK classes, we may want to share our application classes as well.
    This can be done in several steps depending on the JDK.
  prefs: []
  type: TYPE_NORMAL
- en: Before JDK 13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before JDK 13, we need to create the list of classes that we want to share.
    We can do it manually or via the `-XX:DumpLoadedClassList` option, as follows
    (I’ll skip it here, but you’ll need `--enable-preview` as well):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The generated `classes.lst` contains all classes (classes used by the JDK +
    your application classes) that will be shared. Next, we can obtain the archive,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Consider the following important note.
  prefs: []
  type: TYPE_NORMAL
- en: '**Important note**'
  prefs: []
  type: TYPE_NORMAL
- en: Notice that CDS (AppCDS) can archive classes from JAR files only. Don’t use
    classpaths with wildcards or exploded paths such as `target/classes`. Replace
    `app.jar` with your JAR.
  prefs: []
  type: TYPE_NORMAL
- en: The archive (`appcds.jsa`) is stored in the application root folder, not in
    `$JAVA_HOME`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can share the archive and get some logs, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Done!
  prefs: []
  type: TYPE_NORMAL
- en: JDK 13+
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Starting with JDK 13, we can take advantage of *dynamic application class-data
    sharing*. In other words, we can obtain the archive when JVM exits via the `-XX:ArchiveClassesAtExit`
    option, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Replace `app.jar` with your JAR. Use the generated archive as usual via `-Xshare:on`
    and `-XX:SharedArchiveFile`.
  prefs: []
  type: TYPE_NORMAL
- en: JDK 19+
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Starting with JDK 19, we can rely on autogenerated archives. This is possible
    in a single command, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This time, JVM checks if an archive exists at the path given via `-XX:SharedArchiveFile`.
    If such an archive exists, then JVM loads and uses it; otherwise, at exit, JVM
    will generate an archive at that location. Moreover, JVM checks the JDK version
    used for creating the archive. If the current JDK version (the JVM JDK version)
    and the archive JDK are not the same, then JVM will overwrite the existing archive.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may also be interested in the following article: [https://spring.io/blog/2023/12/04/cds-with-spring-framework-6-1](https://spring.io/blog/2023/12/04/cds-with-spring-framework-6-1).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covered 15 problems with garbage collectors and AppCDS. Even if
    these problems have been mostly theoretical, they still represent major topics
    that can boost your application performance at runtime (in the GC case) and startup
    (in the AppCDS case).
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://discord.gg/8mgytp5DGQ](https://discord.gg/8mgytp5DGQ )'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code1139613064111216156.png)'
  prefs: []
  type: TYPE_IMG
