- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Data Storage and Databases
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据存储和数据库
- en: In the previous chapter, we understood the foundations of modern data engineering
    and what architects are supposed to do. We also covered how data is growing at
    an exponential rate. However, to make use of that data, we need to understand
    how to store it efficiently and effectively.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们了解了现代数据工程的基础以及架构师应该做什么。我们还介绍了数据是如何以指数速度增长的。然而，为了利用这些数据，我们需要了解如何高效有效地存储它们。
- en: In this chapter, we will focus on learning how to store data. We will start
    by learning about various types of data and the various formats of the available
    data. We will briefly discuss encoding and compression and how well they work
    with various data types. Then, we will learn about file and object storage and
    compare these data storage techniques. After that, we will cover the various kinds
    of databases that are available in modern data engineering. We will briefly discuss
    the techniques and tricks to choose the correct database for a particular use
    case. However, choosing the correct database doesn’t guarantee a well-built solution.
    As a data architect, it is important to know how to best design a solution around
    the database so that we can make the most of the technology we have chosen and
    have an effective, robust, and scalable data engineering solution in place.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将专注于学习如何存储数据。我们将从了解各种数据类型和可用数据的各种格式开始。我们将简要讨论编码和压缩以及它们与各种数据类型的配合程度。然后，我们将学习关于文件和对象存储的知识，并比较这些数据存储技术。之后，我们将介绍现代数据工程中可用的各种数据库。我们将简要讨论选择特定用例的正确数据库的技术和技巧。然而，选择正确的数据库并不能保证构建出良好的解决方案。作为一名数据架构师，了解如何围绕数据库最佳设计解决方案非常重要，这样我们才能充分利用我们所选择的技术，并实施一个有效、健壮和可扩展的数据工程解决方案。
- en: We will end this chapter by discussing how to design data models for different
    kinds of databases. To help you understand these critical concepts, we will provide
    hands-on real-world scenarios wherever possible.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将本章的结尾讨论如何为不同类型的数据库设计数据模型。为了帮助您理解这些关键概念，我们将尽可能提供实际场景。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Understanding data types, formats, and encodings
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解数据类型、格式和编码
- en: Understanding file, block, and object storage
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解文件、块和对象存储
- en: The data lake, data warehouse, and data mart
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据湖、数据仓库和数据集市
- en: Databases and their types
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库及其类型
- en: Data model design considerations
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据模型设计考虑因素
- en: Understanding data types, formats, and encodings
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解数据类型、格式和编码
- en: In this section, you will learn about the various data types and data formats.
    We will also cover compression and how compression and formats go together. After
    that, we will briefly discuss data encodings. This section will prepare you to
    understand these basic features of data, which will be of use when we discuss
    data storage and databases in the upcoming sections.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将了解各种数据类型和数据格式。我们还将介绍压缩以及压缩和格式如何结合在一起。之后，我们将简要讨论数据编码。本节将为您理解这些数据的基本特征做好准备，这些特征将在我们讨论即将到来的数据存储和数据库部分时有用。
- en: Data types
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据类型
- en: 'All datasets that are used in modern-day data engineering can be broadly classified
    into one of three categories, as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所有在现代数据工程中使用的数据集可以大致分为以下三个类别：
- en: '**Structured data**: This is a type of dataset that can easily be mapped to
    a predefined structure or schema. It usually refers to the relational data model,
    where each data element can be mapped to a predefined field. In a structured dataset,
    usually, the number of fields, their data type, and the order of the fields are
    well defined. The most common example of this is a relational data structure where
    we model the data structure in terms of an *entity* and a *relationship*. Such
    a relational data structure can be denoted by crows-foot notation. If you are
    interested in learning the basics of crows-foot notation, please refer to [https://vertabelo.com/blog/crow-s-foot-notation](https://vertabelo.com/blog/crow-s-foot-notation).The
    following diagram shows an example of structured data in crows-feet notation:'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结构化数据**：这是一种可以轻松映射到预定义结构或模式的类型的数据集。它通常指的是关系数据模型，其中每个数据元素都可以映射到预定义的字段。在结构化数据集中，通常字段的数量、数据类型以及字段的顺序都是明确定义的。最常见的例子是关系数据结构，我们用实体和关系来描述数据结构。这种关系数据结构可以用脚注形符号表示。如果您想了解脚注形符号的基础知识，请参阅[https://vertabelo.com/blog/crow-s-foot-notation](https://vertabelo.com/blog/crow-s-foot-notation)。以下图表展示了结构化数据在脚注形符号中的示例：'
- en: '![Figure 2.1 – Structured data representation ](img/B17084_02_001.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图2.1 – 结构化数据表示](img/B17084_02_001.jpg)'
- en: Figure 2.1 – Structured data representation
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1 – 结构化数据表示
- en: In the preceding diagram, we can see a system consisting of three structured
    datasets called `Customer`, `Order`, and `Product`. Each of these datasets has
    a fixed number of fields and their corresponding data types. We can also see the
    relationship between the datasets. For example, here, `Order` is related to `Customer`
    via `customer_id` and `Order` is related to `Product` via `product_id`. Since
    structured datasets have relationships between them, they are also called relational
    data models.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图表中，我们可以看到一个由三个结构化数据集组成的系统，称为“客户”、“订单”和“产品”。这些数据集每个都有固定数量的字段和相应的数据类型。我们还可以看到数据集之间的关系。例如，在这里，“订单”通过“customer_id”与“客户”相关联，“订单”通过“product_id”与“产品”相关联。由于结构化数据集之间存在关系，它们也被称为关系数据模型。
- en: '**Unstructured data**: This is a type of data or a dataset that doesn’t conform
    to any predefined data model. Due to the lack of any internal structure, they
    cannot be stored by any relational data stores such as **Relational Database Management
    Systems** (**RDBMSs**). Also, since there is no schema attached to it, querying
    and searching is not as easy as in a structured data model.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不结构化数据**：这是一种不符合任何预定义数据模型的数据或数据集。由于缺乏任何内部结构，它们不能被任何关系数据存储，如**关系数据库管理系统**（**RDBMSs**）存储。此外，由于没有与之关联的模式，查询和搜索不像在结构化数据模型中那样容易。'
- en: 'Around 70% of the data that’s generated by systems is unstructured. They can
    either be generated by humans or by machines:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 大约70%的系统生成数据是不结构化的。它们可以由人类或机器生成：
- en: '**Human-generated unstructured data**: A few examples of human-generated unstructured
    datasets are media files such as audio and video files, chat, instant messaging,
    phone call transcriptions, and text messages'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人类生成的不结构化数据**：一些人类生成的不结构化数据集的例子包括媒体文件，如音频和视频文件、聊天、即时消息、电话录音和短信'
- en: '**Machine-generated unstructured data**: A few examples of machine-generated
    unstructured data are scientific data such as seismic imagery, digital surveillance,
    and satellite imagery'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器生成的不结构化数据**：一些机器生成的不结构化数据的例子包括科学数据，如地震图像、数字监控和卫星图像'
- en: '**Semi-structured data**: This is a type of dataset that, unlike a relational
    data model, doesn’t contain a tabular structure, but still contains markers or
    tags to define the hierarchy and field names of the data model. Semi-structured
    data is hierarchical. Semi-structured data is especially useful for platforms
    and programming language-agnostic communication between different systems. Before
    we discuss a few types of semi-structured data, let’s look at a real-world example.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**半结构化数据**：这是一种类型的数据集，与关系数据模型不同，它不包含表格结构，但仍然包含标记或标签来定义数据模型的层次结构和字段名称。半结构化数据是分层的。半结构化数据对于不同系统之间的平台和编程语言无关的通信特别有用。在我们讨论几种半结构化数据类型之前，让我们看看一个现实世界的例子。'
- en: Mastercard, Visa, and **American Express** (**Amex**) are card networks that
    connect payment processors with issuers. Usually, there are a lot of **business-to-business**
    (**B2B**) sales on card networks, where a merchant buys subscription plans to
    accept a card network, thus increasing the card networks’ revenue stream. For
    example, my dentist accepts only Mastercard and Amex, while Costco stores now
    only accept Visa all over the US. Each of these huge card networks has many Salesforce
    orgs or business units such as accounting, sales, and marketing.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 万事达卡、维萨和 **美国运通**（**Amex**）是连接支付处理器和发行人的卡网络。通常，在卡网络上有很多 **商业对商业**（**B2B**）的销售，其中商家购买订阅计划以接受卡网络，从而增加卡网络的收入流。例如，我的牙医只接受万事达卡和美国运通，而美国仓储式会员商店现在在美国各地只接受维萨卡。每个这些庞大的卡网络都有许多
    Salesforce org 或业务单元，如会计、销售和营销。
- en: Suppose Visa wants to generate a saleability score and the best time to reach
    a B2B customer. Information gathered from marketing and accounting via Salesforce
    will be used by a real-time **machine learning** (**ML**)-based application, which
    will generate and attach the saleability score and best time to reach the customer.
    The enriched record, along with this extra information, must flow to the Salesforce
    org for sales. Salesforce usually uses APEX as a language on the Salesforce cloud
    (which may be hosted in a different OS), while the AI application that generates
    the score and best call time is written in Java and Python and sits over an on-premises
    Kubernetes cluster. For messages to communicate easily between these disparate
    systems (with different OSs and different languages), we would use a form of semi-structured
    data (JSON) that is independent of the OS or the language of the different applications
    involved in this use case.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 假设维萨想要生成一个销售评分和最佳接触 B2B 客户的时间。通过 Salesforce 从营销和会计收集的信息将被一个基于实时 **机器学习**（**ML**）的应用程序使用，该应用程序将生成并附加销售评分和最佳接触客户的时间。这个增强的记录，连同这些额外信息，必须流向
    Salesforce org 以进行销售。Salesforce 通常在 Salesforce 云上使用 APEX 作为语言（该云可能托管在不同的操作系统上），而生成评分和最佳通话时间的
    AI 应用程序是用 Java 和 Python 编写的，并位于本地 Kubernetes 集群之上。为了使这些异构系统（具有不同的操作系统和不同的语言）之间的消息能够轻松通信，我们将使用一种半结构化数据（JSON）的形式，这种数据与操作系统或涉及此用例的不同应用程序的语言无关。
- en: 'Now, let’s look at a few of the most popular types of semi-structured data:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看几种最流行的半结构化数据类型：
- en: '**JSON** is the short form of **JavaScript Object Notation**. According to
    Wikipedia, it is “*an open standard format that uses human-readable text to transmit
    data objects consisting of attribute-value pairs*.” The following example consists
    of key-value pairs, where the value can be another JSON as well. This JSON has
    at least one key-value pair and is a value; this is known as a nested JSON. An
    array of JSON objects is called a **JSON array**.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**JSON** 是 **JavaScript 对象表示法**的缩写。根据维基百科，它是一种“*使用人类可读的文本来传输由属性-值对组成的数据对象的开放标准格式*。”以下示例由键值对组成，其中值可以是另一个
    JSON。这个 JSON 至少有一个键值对，是一个值；这被称为嵌套 JSON。JSON 对象的数组称为 **JSON 数组**。'
- en: 'The following is an example of a JSON:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个 JSON 的示例：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you can see, there are tags denoting field names such as `‘customerId’`.
    The `‘bills’` tag’s value is an array of JSON objects, so, its value is a JSON
    array. Also, since `‘bills’` is not a primitive data type but instead another
    JSON, the preceding JSON is a nested JSON object that shows how JSON has a hierarchical
    structure.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，有一些表示字段名称的标签，例如 `‘customerId’`。`‘bills’` 标签的值是一个 JSON 对象的数组，因此其值是一个 JSON
    数组。此外，由于 `‘bills’` 不是一个基本数据类型，而是另一个 JSON，因此前面的 JSON 是一个嵌套的 JSON 对象，显示了 JSON 的层次结构。
- en: '**XML** denotes **Extensible Markup Language**. As is evident from the name,
    it is an open data format that is both human and machine-readable, in which each
    data value is tagged or marked by a tag that denotes the name of the field. XML
    is very similar to JSON in passing information between disparate systems in a
    platform and language-agnostic way. Like JSON, XML is also a hierarchical data
    structure. XML is the de facto standard for wsdl SOAP APIs. The following is the
    XML structure for the JSON described earlier:'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**XML** 表示 **可扩展标记语言**。从其名称可以看出，它是一种开放的数据格式，既适合人类阅读也适合机器阅读，其中每个数据值都通过一个标签进行标记或标记，该标签表示字段的名称。XML
    在以平台和语言无关的方式在异构系统之间传递信息方面与 JSON 非常相似。像 JSON 一样，XML 也是一种层次化的数据结构。XML 是 wsdl SOAP
    API 的既定标准。以下是为之前描述的 JSON 描述的 XML 结构：'
- en: '[PRE1]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The full source code for the preceding code snippet is available on GitHub at
    [https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/blob/main/Chapter02/sample.xml](https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/blob/main/Chapter02/sample.xml).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个代码片段的完整源代码可在GitHub上找到：[https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/blob/main/Chapter02/sample.xml](https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/blob/main/Chapter02/sample.xml)。
- en: As you can see, each XML starts with a `root` tag, and each value is encapsulated
    by the tag names. We explored various data types in this section, but we need
    to understand how these types of data are formatted. So, in the next section,
    we will discuss various data formats.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，每个XML都以一个`root`标签开始，每个值都被标签名称封装。在本节中，我们探讨了各种数据类型，但我们需要了解这些类型的数据是如何格式化的。因此，在下一节中，我们将讨论各种数据格式。
- en: Data formats
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据格式
- en: In data engineering, a dataset can be stored in different kinds of file formats.
    Each format has its pros and cons. However, it is important to know which data
    format is more suitable for certain types of use cases over others. In this section,
    we will discuss the various characteristics of data formats, a few popular data
    formats, and their suitable use cases.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据工程中，数据集可以存储在不同的文件格式中。每种格式都有其优缺点。然而，了解哪种数据格式比其他数据格式更适合某些类型的用例是很重要的。在本节中，我们将讨论数据格式的各种特点、一些流行的数据格式以及它们适用的用例。
- en: Characteristics of data formats
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据格式的特点
- en: 'First, let’s review the various characteristics of the data format that makes
    them different. These characteristics also determine when a particular data type
    should be selected over others to solve a business problem. The main characteristics
    of data formats are as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们回顾一下数据格式的各种特点，这些特点使它们彼此不同。这些特点还决定了在解决业务问题时，何时应该选择特定数据类型而不是其他数据类型。数据格式的主要特点如下：
- en: '`.jpg` file can only be opened by applications such as Photos. Text files,
    on the other hand, can only contain characters, can be opened in any text editor,
    and are human-readable. For example, any `.txt` file that can be opened by text
    editors such as Notepad is a text file.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.jpg`文件只能由Photos等应用程序打开。另一方面，文本文件只能包含字符，可以在任何文本编辑器中打开，并且是可读的。例如，任何可以通过记事本等文本编辑器打开的`.txt`文件都是文本文件。'
- en: '**Schema support**: A schema is an outline, diagram, or model that defines
    the structure of various types of data. The schema stores field-level information
    such as the *data type*, *max size*, or *default value*. A schema can be associated
    with the data, which helps with the following:'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模式支持**：模式是一个大纲、图表或模型，它定义了各种类型数据的结构。模式存储字段级别的信息，如*数据类型*、*最大大小*或*默认值*。模式可以与数据相关联，这有助于以下方面：'
- en: Data validation
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据验证
- en: Data serialization and compression
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据序列化和压缩
- en: A way to communicate the data to all its consumers to easily understand and
    interpret it
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种将数据传达给所有消费者以便轻松理解和解释的方法
- en: Data formats may or may not support schema enforcement. Also, a schema can be
    included along with the data, or it can be shared separately with the schema registry.
    The schema registry is a centralized registry of schemas so that different applications
    can add or remove fields independently, enabling better decoupling. This makes
    it suitable for schema evolution and validation.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 数据格式可能支持或不支持模式强制。此外，模式可以与数据一起包含，或者可以与模式注册表分开共享。模式注册表是一个集中注册模式的地方，以便不同的应用程序可以独立地添加或删除字段，从而实现更好的解耦。这使得它适合模式演变和验证。
- en: '**Schema evolution**: As a business grows, more columns get added or changes
    are made to the column data type, which results in the schema changing over time.
    Even as the schema evolves, it is important to have backward compatibility for
    your old data. Schema evolution provides a mechanism to update the schema while
    maintaining backward compatibility. A few data formats, such as **Avro**, support
    schema evolution, which is helpful in an agile business; as a dataset’s schema
    can change over time.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模式演变**：随着业务的增长，更多的列被添加或列数据类型发生变化，这导致模式随时间而变化。即使模式在演变，保持旧数据的向后兼容性也很重要。模式演变提供了一种在保持向后兼容性的同时更新模式的方法。一些数据格式，如**Avro**，支持模式演变，这在敏捷业务中很有帮助；因为数据集的模式可能会随时间变化。'
- en: '**Row versus columnar storage**: To understand row versus columnar storage,
    let’s take a look at the following diagram:'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**行与列存储**：为了理解行与列存储的区别，让我们看一下以下图表：'
- en: '![Figure 2.2 – Row versus columnar storage ](img/B17084_02_002.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图2.2 – 行与列式存储](img/B17084_02_002.jpg)'
- en: Figure 2.2 – Row versus columnar storage
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 – 行与列式存储
- en: The preceding diagram shows how the same data will be stored in row-based storage
    versus column-based storage. This example shows how sales data is stored in a
    columnar format versus a row-based data storage format. In a row-based format,
    all data is stored row-wise – that is, the columns of a specific row are stored
    adjacent to each other. Since the data is stored row-wise, it is ideal for scenarios
    where it is preferable to read or write data row-wise, such as in **Online Transaction
    Processing** (**OLTP**).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表显示了相同的数据在基于行存储和基于列存储中的存储方式。这个例子显示了销售数据以列式格式存储与基于行的数据存储格式相比的情况。在基于行的格式中，所有数据都是按行存储的——也就是说，特定行的列是相邻存储的。由于数据是按行存储的，因此它非常适合那些更倾向于按行读取或写入数据的场景，例如在**在线事务处理**（**OLTP**）中。
- en: On the other hand, as evident in the preceding diagram, columnar storage stores
    the values of the same column in an adjacent memory block. So, columns are stored
    together. Since it stores data in a columnar fashion, it can optimize storage
    space by storing repetitive column values once and pointers for each row (this
    is indicated by a striking of the repetitive `Clothes` value in the `Columnar
    Storage` part of the preceding diagram). This kind of storage is very useful for
    scenarios where only a subset of columns is read repetitively and doesn’t expect
    transactional writes. Two typical use cases that are widely used are **Online
    Analytical Processing** (**OLAP**) and big data processing. Both are mainly used
    for analytical queries on huge datasets. In big data, the columnar format gives
    the added advantage of being splittable and enables partition creation, which
    helps process the data faster.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，正如前一个图表所示，列式存储将同一列的值存储在相邻的内存块中。因此，列是存储在一起的。由于它以列式存储数据，可以通过一次存储重复的列值和每行的指针来优化存储空间（这在前一个图表的“列式存储”部分通过重复的“Clothes”值表示）。这种存储方式对于只重复读取部分列且不期望进行事务性写入的场景非常有用。两个典型的用例是**在线分析处理**（**OLAP**）和大数据处理。两者主要用于对大型数据集进行查询分析。在大数据中，列式格式提供了可分割的优势，并允许创建分区，这有助于加快数据处理速度。
- en: '**Splittable**: Another important factor is whether the file can be partitioned
    or split into multiple files. This factor plays a role when the data volume is
    huge or the velocity is too high, as in the case of big data. Big data files can
    be stored in a distributed filesystem such as **HDFS** if the underlying data
    format is splittable. By doing so, processing such partitioned big data becomes
    much faster.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可分割性**：另一个重要因素是文件是否可以被分割或拆分为多个文件。当数据量巨大或速度过高时，例如在大数据中，这个因素就会发挥作用。如果底层数据格式是可分割的，大数据文件可以存储在分布式文件系统如**HDFS**中。这样做，处理这种分割的大数据会变得更快。'
- en: '**Compression**: Data processing performance often depends on the data’s size.
    Compression reduces the size of the data on disk, which increases network I/O
    performance (however, it might take more time to decompress it while processing).
    It also reduces the data packet size when this data flows over the network, and
    hence the data transfer rates as well. The following table shows a few popular
    data compression algorithms and their features:'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**压缩**：数据处理性能通常取决于数据的大小。压缩可以减小磁盘上的数据大小，从而提高网络I/O性能（然而，在处理时可能需要更多时间来解压）。它还可以在数据通过网络流动时减小数据包的大小，从而降低数据传输速率。下表显示了几个流行的数据压缩算法及其特性：'
- en: '| **Name** | **Lossless Compress** | **Compression Ratio** | **Splitable**
    | **Compression Speed** | **Decompress Speed** |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **无损压缩** | **压缩比率** | **可分割** | **压缩速度** | **解压速度** |'
- en: '| **Gzip** | Yes | 2.7x‒3x | No | 100 MBps | 440 MBps |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| **Gzip** | 是 | 2.7x—3x | 否 | 100 MBps | 440 MBps |'
- en: '| **Snappy** | Yes | 2x | No | 580 MBps | 2020 MBps |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| **Snappy** | 是 | 2x | 否 | 580 MBps | 2020 MBps |'
- en: '| **LZ4** | Yes | 2.5x | No | 800 MBps | 4220 MBps |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| **LZ4** | 是 | 2.5x | 否 | 800 MBps | 4220 MBps |'
- en: '| **Zstd** | Yes | 2.8x | Yes | 530 MBps | 1360 MBps |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| **Zstd** | 是 | 2.8x | 是 | 530 MBps | 1360 MBps |'
- en: Table 2.1 – Different compression techniques
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.1 – 不同的压缩技术
- en: '**Companion technologies**: Sometimes, the choice of data format is dependent
    on a companion technology. For example, in a Hadoop environment, if we are planning
    to process the data using a Hive MapReduce job, it might be a good idea to use
    ORC format over Parquet format. But on the other hand, if all our transformations
    are done using Apache Spark, Parquet may be a better choice.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**配套技术**：有时，数据格式的选择取决于配套技术。例如，在一个Hadoop环境中，如果我们计划使用Hive MapReduce作业处理数据，那么使用ORC格式而不是Parquet格式可能是一个好主意。但另一方面，如果我们所有的转换都是使用Apache
    Spark完成的，那么Parquet可能是一个更好的选择。'
- en: In this section, we learned about the features and characteristics of various
    data formats and how they affect the storage and processing of data elements.
    However, it is important for an architect to be aware of the popular data formats
    and how they can be used judiciously.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了各种数据格式的特性和特点，以及它们如何影响数据元素的存储和处理。然而，对于一个架构师来说，了解流行的数据格式以及如何明智地使用它们是非常重要的。
- en: Popular data formats
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 流行数据格式
- en: 'In this section, we will discuss a few popular data formats that are worth
    knowing about. You will encounter these when you try to develop a data engineering
    solution. They are as follows (we covered two popular data formats, JSON and XML,
    in the *Semi-structured data* section, in the *Data types* subsection):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论一些值得了解的流行数据格式。当你尝试开发数据工程解决方案时，你将遇到这些格式。它们如下（我们在“半结构化数据”部分和“数据类型”子部分中介绍了两种流行的数据格式，JSON和XML）：
- en: '**Delimiter Separated Format**: This is a text data format where newline is
    used as a record delimiter and there can be specific field delimiters based on
    which type of delimiter-separated file we are dealing with. Two of the most popular
    delimiter-separated formats are **Comma Separated Value** (**CSV**) and **Tab
    Separated Value** (**TSV**). While in CSV, the field delimiter is a comma, for
    TSV it is a tab. Optionally, they can have a header record. Although it doesn’t
    support splitting, it provides a very good compression ratio. This format doesn’t
    support null values or schema evolution.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分隔符分隔格式**：这是一种文本数据格式，其中换行符用作记录分隔符，并且可以根据我们处理的是哪种类型的分隔符分隔文件来使用特定的字段分隔符。两种最流行的分隔符分隔格式是**逗号分隔值**（**CSV**）和**制表符分隔值**（**TSV**）。在CSV中，字段分隔符是逗号，而对于TSV，它是制表符。它们可以可选地包含一个标题记录。尽管它不支持拆分，但它提供了非常好的压缩率。此格式不支持空值或模式演变。'
- en: Due to the simplicity of the format, it is quite popular in batch processing
    scenarios as well as real-time stream processing. However, the lack of schema
    evolution, partitioning capabilities, and non-standardized formatting makes its
    usage limited and not recommended for many use cases.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 由于格式的简单性，它在批量处理场景以及实时流处理中也非常受欢迎。然而，缺乏模式演变、分区能力和非标准化格式使得其使用有限，并且不推荐用于许多用例。
- en: '`avro-tools-<version>.jar`. The command to convert Avro into a human-readable
    JSON format is as follows:'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`avro-tools-<version>.jar`。将Avro转换为人类可读的JSON格式的命令如下：'
- en: '[PRE2]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`avro` data is always accompanied by its schema, which can be read using `avro-tools-<version>.jar`,
    like so:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`avro`数据总是伴随着其模式，可以使用`avro-tools-<version>.jar`读取，如下所示：'
- en: '[PRE3]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If we had a binary Avro file equivalent to that of the JSON described while
    explaining Semi-structured data in the *Data types* section, the `avro` schema
    would look as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一个与在“数据类型”部分解释半结构化数据时描述的JSON等效的二进制Avro文件，那么`avro`模式将如下所示：
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The full source code for the preceding code snippet is available on GitHub at
    [https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/blob/main/Chapter02/avroschema.json](https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/blob/main/Chapter02/avroschema.json).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码片段的完整源代码可在GitHub上找到，链接为[https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/blob/main/Chapter02/avroschema.json](https://github.com/PacktPublishing/Scalable-Data-Architecture-with-Java/blob/main/Chapter02/avroschema.json)。
- en: '**Parquet** is an open source column-based data storage that’s ideal for analytical
    loads. It was created by Cloudera in collaboration with Twitter. Parquet is very
    popular in *big data engineering* because it provides a lot of storage optimization
    options, as well as provides great columnar compression and optimization. Like
    Avro, it also supports splittable files and schema evolution. It is quite flexible
    and has very good support for nested data structures. Parquet gives great read
    performance; it especially works very well with Apache Spark'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Parquet** 是一种开源的基于列的数据存储，非常适合分析负载。它是由 Cloudera 与 Twitter 合作创建的。Parquet 在
    *大数据工程* 中非常受欢迎，因为它提供了许多存储优化选项，以及提供了出色的列式压缩和优化。与 Avro 一样，它也支持可分割文件和模式演变。它非常灵活，并且对嵌套数据结构有很好的支持。Parquet
    提供了出色的读取性能；它与 Apache Spark 工作得非常好'
- en: Let’s try to understand how a Parquet file is structured. The following diagram
    shows the Parquet file structure:![Figure 2.3 – Parquet file format ](img/B17084_02_004.jpg)
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让我们尝试理解 Parquet 文件的结构。以下图表显示了 Parquet 文件的结构：![图 2.3 – Parquet 文件格式](img/B17084_02_004.jpg)
- en: Figure 2.3 – Parquet file format
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3 – Parquet 文件格式
- en: A Parquet file contains a header and a footer. The header only consists of a
    marker called **PAR1**, denoting that it’s a parquet file. Then, the file is divided
    into row groups, where each row group denotes a set of rows contained in a chunk
    of data. Each chunk of data is equal to the block size of the Parquet file (128
    MB by default). Each row group contains a chunk for every column. Again, each
    column chunk consists of one or more pages. Each page in a column consists of
    *n* number of rows whose size is less than or equal to a configured page size.
    Each column chunk stores metadata as well (min/max value, number of nulls, and
    so on). The footer contains metadata for all row groups, as well as the schema
    of the data.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Parquet 文件包含一个头部和一个尾部。头部仅由一个名为 **PAR1** 的标记组成，表示它是一个 Parquet 文件。然后，文件被分为行组，其中每个行组表示包含在数据块中的一组行。每个数据块的大小等于
    Parquet 文件的块大小（默认为 128 MB）。每个行组包含每个列的一个数据块。同样，每个列数据块由一个或多个页面组成。列中的每个页面包含 *n* 行，其大小小于或等于配置的页面大小。每个列数据块还存储元数据（最小/最大值、空值数量等）。尾部包含所有行组的元数据以及数据的模式。
- en: '**Optimized Row Columnar** (**ORC**): This is yet another open source file
    format developed in the Hadoop ecosystem by Hortonworks in collaboration with
    Facebook. ORC is another form of columnar data storage that supports excellent
    compression and column optimization. Let’s look at the ORC file structure to understand
    how it is different from the Parquet format. The following diagram shows the structure
    of an ORC file format:'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优化行列存储**（**ORC**）：这是由 Hortonworks 在与 Facebook 合作下，在 Hadoop 生态系统内开发的另一种开源文件格式。ORC
    是一种支持出色压缩和列优化的列式数据存储形式。让我们看看 ORC 文件结构，以了解它与 Parquet 格式的不同之处。以下图表显示了 ORC 文件格式的结构：'
- en: '![Figure 2.4 – ORC file structure ](img/B17084_02_005.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.4 – ORC 文件结构](img/B17084_02_005.png)'
- en: Figure 2.4 – ORC file structure
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4 – ORC 文件结构
- en: In ORC format, each file consists of multiple strips. The default stripe size
    is 250 MB. Each stripe is subdivided into index data, row data, and a stripe footer.
    The index data contains indexes and the row data consists of actual data, but
    both of them are stored in columnar format. The stripe footer contains column
    encodings and their location. The file footer contains information about the list
    of stripes, the number of rows in each stripe, and the data type of each column.
    Apart from that, it contains stripe-level statistical information such as min,
    max, and sum. Finally, the postscript contains information regarding the length
    of the file’s footer, metadata section, and compression-related information.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ORC 格式中，每个文件由多个条带组成。默认条带大小为 250 MB。每个条带被细分为索引数据、行数据和条带尾部。索引数据包含索引，行数据由实际数据组成，但它们都以列式格式存储。条带尾部包含列编码及其位置。文件尾部包含有关条带列表、每个条带的行数以及每列的数据类型的信息。除此之外，它还包含条带级别的统计信息，如最小值、最大值和总和。最后，后缀包含有关文件尾部长度、元数据部分和压缩相关信息的说明。
- en: Let’s now understand how to choose from the different data formats.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来了解如何从不同的数据格式中进行选择。
- en: How to choose between Avro, Parquet, and ORC
  id: totrans-81
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 如何在 Avro、Parquet 和 ORC 之间进行选择
- en: 'To choose the correct data format, we must consider the following:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 要选择正确的数据格式，我们必须考虑以下因素：
- en: '**Read or write-intensive query pattern**: For a write-intensive use case,
    a row-based format works better as appending new records becomes easier. So, Avro
    would be a better choice for write-intensive use cases. On the other hand, if
    a read-intensive use case needs to read a subset of columns more frequently, a
    columnar data format such as Parquet or ORC is a suitable choice.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**读写密集型查询模式**：对于读写密集型用例，基于行的格式工作得更好，因为追加新记录变得更容易。因此，对于读写密集型用例，Avro会是一个更好的选择。另一方面，如果读写密集型用例需要更频繁地读取列的子集，那么像Parquet或ORC这样的列式数据格式是一个合适的选择。'
- en: '**Compression**: This is a very important aspect when choosing a data format
    because compression reduces both the time and storage required to store or transmit
    data. For big data use cases, compression involves a huge role. Row-based storage
    is not suitable for such scenarios. So, for big data analytical use cases, columnar
    storage such as Parquet or ORC is preferred. Also, more compression is required
    if transforming/processing big data creates a lot of intermediate reads and writes.
    In such a scenario, ORC is preferred because it gives a better compression ratio
    than Parquet. For example, if you are running a MapReduce job or a **Hive Query
    Language** (**HQL**) query on Hive with the MapReduce engine, ORC will perform
    better than Parquet.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**压缩**：在选择数据格式时，这是一个非常重要的方面，因为压缩可以减少存储或传输数据所需的时间和存储空间。对于大数据用例，压缩起着巨大的作用。基于行的存储不适合这种场景。因此，对于大数据分析用例，像Parquet或ORC这样的列式存储更受欢迎。此外，如果转换/处理大数据产生了大量的中间读取和写入，则需要更多的压缩。在这种情况下，ORC是首选的，因为它比Parquet提供了更好的压缩比率。例如，如果您在Hive上使用MapReduce引擎运行MapReduce作业或**Hive查询语言**（**HQL**）查询，ORC的表现将优于Parquet。'
- en: '**Schema Evolution**: In many data engineering use cases, schemas change frequently
    over time as new columns get added or dropped as business requirement changes.
    If there are frequent changes in the data schema and you need backward schema
    compatibility, Avro is the best choice. Avro supports very advanced schema evolution,
    compatibility, and versioning while keeping the schema definition simple in JSON
    format.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模式演进**：在许多数据工程用例中，随着新列的添加或删除以及业务需求的变化，模式会随着时间的推移而频繁变化。如果数据模式经常发生变化，并且您需要向后兼容性，那么Avro是最佳选择。Avro支持非常先进的模式演进、兼容性和版本控制，同时保持模式定义在JSON格式中的简单性。'
- en: '**Nested Columns**: If your use case is suitable for a row-based format, Avro
    works great with the nested column structure. Otherwise, if the use case is suitable
    for a columnar data format and you have a lot of nested complex columns, then
    Parquet is the ideal data format for such use cases.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌套列**：如果您的用例适合基于行的格式，Avro与嵌套列结构配合得很好。否则，如果用例适合列式数据格式，并且您有很多嵌套的复杂列，那么Parquet是这种用例的理想数据格式。'
- en: '**Platform Support**: Finally, the platform or framework plays a very important
    role. Hive works best with ORC, while Apache Spark and Delta Lake have great support
    for Parquet. Avro or JSON is often a good choice for Kafka.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平台支持**：最后，平台或框架起着非常重要的作用。Hive与ORC配合得最好，而Apache Spark和Delta Lake对Parquet有很好的支持。对于Kafka，Avro或JSON通常是一个不错的选择。'
- en: In this section, we learned about various data formats such as text, Parquet,
    Avro, and others. In the next section, we will learn how data (which can be in
    text, Parquet, or any other format) can be stored using different data storage
    formats.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了各种数据格式，如文本、Parquet、Avro等。在下一节中，我们将学习如何使用不同的数据存储格式来存储数据（这些数据可以是文本、Parquet或任何其他格式）。
- en: Understanding file, block, and object storage
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解文件、块和对象存储
- en: In this section, we will cover the various data storage formats that are essential
    for an architect who is planning to store their data. Data storage formats organize,
    keep, and present data in different ways, each with its pros and cons. The available
    data storage formats are file, block, and object.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍对计划存储数据的架构师至关重要的各种数据存储格式。数据存储格式以不同的方式组织、保存和展示数据，每种格式都有其优缺点。可用的数据存储格式有文件、块和对象。
- en: File storage organizes and exposes data as a hierarchy of files and folders,
    whereas block storage divides the data into chunks and stores them in organized,
    evenly sized volumes. Finally, object storage manages the data in a space-optimized
    fashion and links it to its associated metadata.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 文件存储将数据组织并暴露为文件和文件夹的层次结构，而块存储将数据划分为块，并将它们存储在组织良好、大小均匀的卷中。最后，对象存储以空间优化的方式管理数据，并将其与其关联的元数据链接起来。
- en: 'Now, let’s dive deeper by discussing their basic concepts, pros and cons, and
    the use cases where they are applied. Let’s begin by discussing the simplest and
    the oldest of them all: file storage.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入探讨它们的基本概念、优缺点以及它们被应用的使用场景。让我们从最简单、最古老的一种：文件存储开始讨论。
- en: File storage
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文件存储
- en: In file-level storage, data is stored as a single piece of information inside
    a file. This file is given a name, can contain metadata, and resides inside a
    directory or subdirectory. When you need to find a file, the computer needs to
    know the absolute path of the file to search and read the file.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在文件级存储中，数据以单个信息块的形式存储在文件中。这个文件被赋予一个名称，可以包含元数据，并位于目录或子目录中。当你需要查找文件时，计算机需要知道文件的绝对路径以进行搜索和读取文件。
- en: 'The pros and cons of file storage are as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 文件存储的优缺点如下：
- en: '**Pros**: It’s simple, has broad capabilities, and can store anything'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优点**：简单、功能广泛，可以存储任何东西'
- en: '**Cons**: Not ideal for storing huge volumes as there is no option to scale
    up, only to scale out'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺点**：不适合存储大量数据，因为没有扩展上规模的选择，只有扩展到规模的选择'
- en: 'A few typical use cases are as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一些典型的用例如下：
- en: File storage is ideal for file sharing in offices and other environments for
    its sheer simplicity; for example, NAS.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件存储因其简单性非常适合办公室和其他环境中的文件共享；例如，NAS。
- en: Local archiving. NAS provides excellent support for storing archival data.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地归档。NAS为存储归档数据提供了出色的支持。
- en: Data protection and security. File-level storage is an old technology, but due
    to the test of time and a broad variety of uses, its policy, standard, and protection
    capabilities are all advanced. This makes it a great candidate for data protection
    use cases.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据保护和安全。文件级存储是一种老技术，但由于时间的考验和广泛的应用，其策略、标准和保护能力都很先进。这使得它成为数据保护用例的理想选择。
- en: Let’s now take a look at block-level storage.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在来看看块级存储。
- en: Block storage
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 块级存储
- en: In block-level storage, the data is divided into small chunks of data and assigned
    unique chunk identifiers. Since the chunk of data is small and has a unique identifier,
    it can be stored anywhere. Also, a group of data chunks consists of a logical
    unit called a volume. In block-level storage, you can add a volume of data easily
    to scale up the infrastructure by adding blocks.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在块级存储中，数据被分成小块数据，并分配唯一的块标识符。由于数据块小且具有唯一标识符，它可以存储在任何地方。此外，一组数据块组成一个逻辑单元，称为卷。在块级存储中，你可以通过添加块轻松地添加数据卷以扩展基础设施。
- en: One of the interesting things is how it handles metadata. Unlike a file-based
    architecture, there are no additional details associated with block storage other
    than its address. Here, the operating system controls the storage management,
    which makes it ideal storage for high-performance use cases.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个有趣的地方在于它如何处理元数据。与基于文件的架构不同，除了地址之外，块存储没有其他附加细节。在这里，操作系统控制存储管理，这使得它成为高性能用例的理想存储。
- en: 'The pros and cons of block-level storage are as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 块级存储的优缺点如下：
- en: '**Pros**: It provides metadata handling by controlling the OS or database,
    making it highly performant. You can also easily scale storage up and down.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优点**：通过控制操作系统或数据库来处理元数据，使其性能极高。你也可以轻松地扩展和缩减存储。'
- en: '**Cons**: It can be expensive. Also, externalizing metadata handling in the
    application layer means more headaches when managing metadata.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺点**：可能很昂贵。此外，在应用层外部化元数据处理意味着在管理元数据时会有更多麻烦。'
- en: 'A few typical use cases are as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 一些典型的用例如下：
- en: '**Databases**: Databases usually use block storage. For example, AWS Relational
    Data Service uses AWS Elastic Block Storage volumes as its storage to store data.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据库**：数据库通常使用块存储。例如，AWS关系数据服务使用AWS Elastic Block Storage卷作为其存储来存储数据。'
- en: '**Virtualization**: Virtualization software such as **VMware**, **Hyper-V**,
    and **Oracle VirtualBox** use block storage as their filesystems for the virtual
    operating system.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**虚拟化**：如**VMware**、**Hyper-V**和**Oracle VirtualBox**等虚拟化软件使用块存储作为虚拟操作系统的文件系统。'
- en: '**Cloud-based instances**: Cloud-based instances such as AWS EC2 use block
    storage (AWS Elastic Block Storage) as their hard disk storage.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于云的实例**：如AWS EC2等基于云的实例使用块存储（AWS Elastic Block Storage）作为其硬盘存储。'
- en: '**Email servers**: Microsoft’s email server, Exchange, uses block storage as
    its standard storage system.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电子邮件服务器**：微软的电子邮件服务器Exchange使用块存储作为其标准存储系统。'
- en: Let’s look at object-level storage next.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们接下来看看对象级存储。
- en: Object storage
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对象存储
- en: Object-level storage stores data in isolated containers called objects, which
    have unique identifiers and flat structures. This makes data retrieval super easy
    as you can retrieve an object by using the unique identifier, irrespective of
    the location it is stored.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 对象级存储将数据存储在称为对象的独立容器中，这些对象具有唯一的标识符和平坦的结构。这使得数据检索变得非常容易，因为你可以通过使用唯一的标识符来检索对象，而不管它存储的位置在哪里。
- en: 'The pros and cons of object-level storage are as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 对象级存储的优缺点如下：
- en: '**Pros**: Object storage provides great *metadata flexibility*. For example,
    you can customize metadata so that the application is associated with an object
    or you can set the priority of an application to an object. You can pretty much
    do any customization. This flexibility makes object storage strong and super easy
    to manage.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优点**：对象存储提供了极大的*元数据灵活性*。例如，你可以自定义元数据，以便应用程序与对象相关联，或者你可以将应用程序的优先级设置为对象。你几乎可以做任何自定义。这种灵活性使得对象存储强大且易于管理。'
- en: Apart from metadata flexibility, object storage is known for its *accessibility*
    as it has a REST API to access, which makes it accessible from any platform or
    language.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 除了元数据灵活性外，对象存储因其*可访问性*而闻名，因为它有一个REST API来访问，这使得它可以从任何平台或语言访问。
- en: Object storage is extremely *scalable*. Scaling out object architecture is as
    simple as adding nodes to an existing storage cluster. With the rapid growth of
    data and the cloud’s pay-as-you-go model, this feature has helped object storage
    become the most sought-after storage for data engineering needs of the present
    and future.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 对象存储具有极高的*可扩展性*。扩展对象架构就像向现有的存储集群添加节点一样简单。随着数据的快速增长和云计算的按需付费模式，这一特性帮助对象存储成为当前和未来数据工程需求中最受欢迎的存储方式。
- en: '**Cons**: With so many positives, there are certain drawbacks to object storage.
    The biggest and most notable one is that objects can’t be modified. However, you
    can create a newer version of the object. In some use cases such as big data processing,
    this is a boon instead of a headache.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺点**：尽管有这么多优点，对象存储也存在一些缺点。最明显和最突出的一点是对象无法修改。然而，你可以创建一个新版本的对象。在某些用例中，如大数据处理，这反而是一个福音而不是头痛。'
- en: 'A few typical use cases are as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 一些典型的用例如下：
- en: '**Big data**: Due to scalability and metadata flexibility, huge volumes, as
    well as unstructured data, can be stored and read easily from object storage.
    This makes it suitable for big data storage.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大数据**：由于可扩展性和元数据灵活性，大量数据以及非结构化数据可以轻松存储和从对象存储中读取。这使得它非常适合大数据存储。'
- en: '**Cloud**: Again, due to scalability, object storage is a perfect candidate
    for cloud systems. Amazon S3 is Amazon’s object storage solution and is very popular.
    Also, customizable metadata helps Amazon S3 objects have a life cycle defined
    through the AWS console or its SDKs.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**云**：再次，由于可扩展性，对象存储是云系统的理想候选者。Amazon S3是亚马逊的对象存储解决方案，并且非常受欢迎。此外，可定制的元数据有助于通过AWS控制台或其SDKs定义Amazon
    S3对象的生存周期。'
- en: '**Web Apps**: Object storage’s easy accessibility using a REST API makes it
    a perfect candidate to be used as a backend for web apps. For example, AWS S3
    alone is used as a cheap and quick backend for static websites.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Web应用**：对象存储通过REST API轻松访问，使其成为用作Web应用后端的理想候选者。例如，AWS S3单独就被用作静态网站的廉价且快速的备份。'
- en: With that, we have covered the various kinds of data storage. In the next section,
    we will learn how enterprise data (stored in any of the aforementioned storage
    formats) is organized into different kinds of data repositories, which enables
    other applications to retrieve, analyze, and query that data.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们已经涵盖了各种数据存储方式。在下一节中，我们将学习企业数据（存储在任何上述存储格式中）是如何组织成不同类型的数据仓库的，这使得其他应用程序能够检索、分析和查询这些数据。
- en: The data lake, data warehouse, and data mart
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据湖、数据仓库和数据集市
- en: To build a data architecture, an architect needs to understand the basic concept
    and differences between a data lake, data warehouse, and data mart. In this section,
    we will cover the modern data architectural ecosystem and where the data lake,
    data warehouse, and data mart fit into that landscape.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建数据架构，架构师需要了解数据湖、数据仓库和数据集市之间的基本概念和区别。在本节中，我们将介绍现代数据架构生态系统，以及数据湖、数据仓库和数据集市在该景观中的位置。
- en: 'The following diagram depicts the landscape of a modern data architecture:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了现代数据架构的概览：
- en: '![Figure 2.5 – Landscape of a modern data architecture ](img/B17084_02_006.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图2.5 – 现代数据架构概览](img/B17084_02_006.jpg)'
- en: Figure 2.5 – Landscape of a modern data architecture
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5 – 现代数据架构景观
- en: As we can see, various types of data get ingested into the data lake, where
    it lands in the raw zone. The data lake consists of structured, semi-structured,
    and unstructured data ingested directly from data sources. Data lakes have a zone
    consisting of cleansed, transformed, and sorted datasets that serve various downstream
    data processing activities such as data analytics, advanced analytics, publishing
    as Data-as-a-Service, AI, ML, and many more. This is called the **curated zone**.
    The data lake acts as a source for creating a data warehouse, which is a structured
    data repository built for a specific line of business.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，各种类型的数据被摄入到数据湖中，并在原始区域着陆。数据湖由直接从数据源摄入的结构化、半结构化和非结构化数据组成。数据湖有一个区域，包含清洗、转换和排序后的数据集，为各种下游数据处理活动提供服务，如数据分析、高级分析、作为数据即服务的发布、人工智能、机器学习等。这被称为**精选区域**。数据湖作为创建数据仓库的来源，而数据仓库是一个为特定业务线构建的结构化数据存储库。
- en: Data lake
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据湖
- en: In a modern data architecture, data from various sources is ingested into a
    data lake. A data lake is a data storage repository that contains structured,
    semi-structured, and unstructured data. In most cases, the usage of the data in
    a data lake is not predefined. Usually, once data is ingested and stored in a
    data lake, various teams use that data for analytics, reports, business intelligence,
    and other usages.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代数据架构中，来自各种来源的数据被摄入到数据湖中。数据湖是一个包含结构化、半结构化和非结构化数据的数据存储库。在大多数情况下，数据湖中数据的用途不是预先定义的。通常，一旦数据被摄入并存储在数据湖中，各个团队就会使用这些数据进行分析、报告、商业智能和其他用途。
- en: 'However, internally, a data lake contains different data zones. The following
    are the different data zones that are available in a data lake:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在内部，数据湖包含不同的数据区域。以下是在数据湖中可用的不同数据区域：
- en: '**Raw data zone**: The raw data from various data sources is loaded into this
    zone. Here, the data that’s loaded is in raw form. This data can be unstructured,
    uncleaned, and unformatted. This is also known as the landing zone.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**原始数据区域**：来自各种数据源的原生数据被加载到这个区域。在这里，加载的数据是原始形式的。这些数据可能是非结构化的、未清洗的、未格式化的。这也被称为着陆区。'
- en: '**Master data zone**: This data zone usually contains reference data that augments
    the analytical or transformational activities of data present in the raw zone
    or curated zone.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主数据区域**：这个数据区域通常包含参考数据，它增强了原始区域或精选区域中数据的分析或转换活动。'
- en: '**User data zone**: Sometimes, in certain data lakes, the user can manually
    drop certain data. They are usually static. This portion of the data lake is called
    the user data zone.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户数据区域**：在某些数据湖中，用户可以手动删除某些数据。它们通常是静态的。这个数据湖的部分被称为用户数据区域。'
- en: '**Curated data zone**: This is the data publishing layer of the data lake.
    It contains cleansed, transformed, and sorted data. The data present in this layer
    is usually structured. Data may be stored in large flat files, as key-value stores,
    as data documents, in a star schema, or in a denormalized format. All data governance,
    data management, and security policies apply to this layer as this is the main
    consumption layer of the data lake.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精选数据区域**：这是数据湖的数据发布层。它包含清洗、转换和排序后的数据。这个层中的数据通常是结构化的。数据可能存储在大平面文件中、作为键值存储、作为数据文档、在星型模式中或以非规范化格式。所有数据治理、数据管理和安全策略都适用于这一层，因为这是数据湖的主要消费层。'
- en: '**Archived data zone**: The archive zone consists of data that has been offloaded
    by other systems such as a data warehouse or the curated zone due to aging. Data
    in this zone can’t usually be modified but can be appended. This kind of data
    is used for historical analysis or auditing purposes. Usually, a cheaper data
    storage technology is used to store archived data. Technologies such as Amazon
    S3 provide more advanced capabilities to progressively move data to cheaper solutions
    automatically as time progresses using an S3 bucket’s life cycle policy.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存档数据区域**：存档区域由其他系统（如数据仓库或精选区域）因老化而卸载的数据组成。这个区域中的数据通常不能修改，但可以追加。这类数据用于历史分析或审计目的。通常，使用更便宜的数据存储技术来存储存档数据。例如，Amazon
    S3等技术提供更高级的能力，可以自动使用S3存储桶的生命周期策略随着时间的推移将数据逐步迁移到更便宜解决方案。'
- en: Let’s move on to data warehouses next.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续讨论数据仓库。
- en: Data warehouse
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据仓库
- en: A data warehouse is a sorted central repository that contains information that
    has been curated from multiple data sources in a structured user-friendly fashion
    for data analytics. A good amount of discovery, analysis, planning, and data modeling
    is required before ingesting the data in a data warehouse. It is highly cleansed,
    transformed, and structured. As evident from *Figure 2.6*, the data warehouse
    is built from a data lake in modern data engineering pipelines. While data lakes
    are usually centralized raw data zones for the enterprise or organization, data
    warehouses are usually built per business unit or department. Each data warehouse
    is structured such that it caters to the need of that particular department. A
    deep dive into data warehouses and their schema types will be discussed in [*Chapter
    4*](B17084_04.xhtml#_idTextAnchor062), *ETL Data Load – A Batch-Based Solution
    to Ingest Data in a Data Warehouse*.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 数据仓库是一个经过排序的中心存储库，它以结构化且用户友好的方式收集了来自多个数据源的信息，用于数据分析。在将数据导入数据仓库之前，需要进行大量的发现、分析、规划和数据建模工作。数据仓库中的数据经过高度清洗、转换和结构化。正如*图2.6*所示，数据仓库在现代数据工程管道中是从数据湖构建的。虽然数据湖通常是企业或组织的集中式原始数据区域，但数据仓库通常是按业务单元或部门构建的。每个数据仓库的结构都是针对特定部门的需求而设计的。关于数据仓库及其模式类型将详细讨论于[*第4章*](B17084_04.xhtml#_idTextAnchor062)，*ETL数据加载
    – 数据仓库中的批量数据导入解决方案*。
- en: Data marts
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集市
- en: Data marts are usually a subset of a data warehouse that focuses on a single
    line of business. While a data warehouse is typically few 100 GBs to TBs in size,
    data marts are usually less than 100 GB in size. Data marts provide great read
    performance as it contains data which is analyzed, designed, and stored for a
    very specific line of business. For example, from a centralized company data warehouse,
    there can be a specific data mart for the HR department, one for the finance department,
    and another for the sales department.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集市通常是数据仓库的一个子集，专注于单一业务线。虽然数据仓库的大小通常是几个100GB到TB，但数据集市的大小通常小于100GB。数据集市提供了出色的读取性能，因为它包含针对特定业务线分析、设计和存储的数据。例如，从集中的公司数据仓库中，可以为人力资源部门、财务部门和销售部门分别有一个特定的数据集市。
- en: 'The following table captures the difference between a data lake and a data
    warehouse:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 下表捕捉了数据湖与数据仓库之间的差异：
- en: '| **Characteristics** | **Data Lake** | **Data warehouse** |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| **特征** | **数据湖** | **数据仓库** |'
- en: '| **Load Pattern** | ETL(Extract, Load, and Transform) | ETL(Extract, Transform,
    and Load) |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| **加载模式** | ETL（提取、加载和转换） | ETL（提取、转换和加载） |'
- en: '| **Type Of Data Stored** | Structured, semi-structured and unstructured |
    Structured |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| **存储的数据类型** | 结构化、半结构化和非结构化 | 结构化 |'
- en: '| **Analysis Pattern** | Acquire, analyze, and then determine structure of
    curated data | Create the structure first and then acquire the data for insights
    |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| **分析模式** | 获取、分析，然后确定整理数据的结构 | 首先创建结构，然后获取数据以获取洞察 |'
- en: '| **Data Ingestion Pattern** | Batch processing, real-time, Batch processing
    near real-time processing | Batch processing |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| **数据摄入模式** | 批处理、实时、接近实时的批处理 | 批处理 |'
- en: '| **Schema Application Time** | Schema-on-read i.e., schema is applied while
    reading the data | Schema-on-write i.e., schema is determined and is available
    when data is written |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| **模式应用时间** | 读取时应用模式，即模式在读取数据时应用 | 写入时确定模式，即模式在数据写入时确定并可用 |'
- en: Table 2.2 – Data lake versus a data warehouse
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.2 – 数据湖与数据仓库的比较
- en: So far, we have learned how various data repositories are used and how they
    enable enterprise data platforms. Data in these repositories can be stored as
    files or objects, but they can be stored in an organized data collection called
    a database, which can retrieve, manage, and search data easily. In the next section,
    we will discuss databases in detail.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了各种数据存储库的使用方法以及它们如何使企业数据平台成为可能。这些存储库中的数据可以存储为文件或对象，但它们也可以存储在称为数据库的有序数据集中，这样就可以轻松检索、管理和搜索数据。在下一节中，我们将详细讨论数据库。
- en: Databases and their types
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据库及其类型
- en: In this section, we will cover the various types of databases that are commonly
    used to create modern data engineering solutions. We will also try to explore
    the possible scenario when a specific type of database will be used.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍各种常用的数据库类型，用于创建现代数据工程解决方案。我们还将尝试探索在特定情况下使用特定类型数据库的可能场景。
- en: 'A database is a systematic collection of data or information that’s stored
    in such a way that it can easily be accessed, retrieved, and managed. In modern-day
    data engineering, primarily, databases can be broadly classified into two categories,
    as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库是一个系统化的数据或信息集合，以易于访问、检索和管理的方式存储。在现代数据工程中，数据库可以大致分为两大类，如下所示：
- en: '**Relational database**: This is a kind of database known for storing structured
    datasets. Each type of dataset is related to another, and relational databases
    provide an easy way to establish a relationship between different kinds of datasets.
    We will discuss relational databases in detail later in this chapter.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关系型数据库**：这是一种以存储结构化数据集而闻名的数据库。每种数据集都与另一种数据集相关联，关系型数据库提供了一种简单的方法来建立不同类型数据集之间的关系。我们将在本章后面详细讨论关系型数据库。'
- en: '**NoSQL databases** or **non-relational databases**: NoSQL databases are non-relational
    databases, where data can be stored in some form other than a tabular format.
    NoSQL supports unstructured, semi-structured, and structured data. No wonder NoSQL
    stands for *Not only SQL*!'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NoSQL数据库**或**非关系型数据库**：NoSQL数据库是非关系型数据库，数据可以以表格格式以外的某种形式存储。NoSQL支持非结构化、半结构化和结构化数据。难怪NoSQL代表的是*不仅限于SQL*！'
- en: 'The following diagram depicts the types of databases employed in a modern data
    engineering context:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了在现代数据工程环境中使用的数据库类型：
- en: '![Figure 2.6 – Types of databases  ](img/B17084_02_008.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图2.6 – 数据库类型](img/B17084_02_008.jpg)'
- en: Figure 2.6 – Types of databases
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6 – 数据库类型
- en: Now, let’s discuss the various database types in detail.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们详细讨论各种数据库类型。
- en: Relational database
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关系型数据库
- en: 'A relational database, as discussed earlier, stores structural data. Each type
    of data in a relational database is stored in a container called a database table
    or, simply, a table. Each table needs to be defined first before data is loaded
    into that table. The table definition contains the column names or field names,
    their data type, and their size (optionally). Relational databases are further
    subdivided into two types: hierarchical databases and RDBMSs.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，关系型数据库存储结构化数据。关系型数据库中的每种数据类型都存储在一个称为数据库表或简称为表的容器中。在数据加载到表中之前，必须首先定义每个表。表定义包含列名或字段名、它们的数据类型以及它们的大小（可选）。关系型数据库进一步细分为两种类型：层次数据库和关系数据库管理系统（RDBMS）。
- en: Hierarchical database
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 层次数据库
- en: 'These are databases where data is stored in a tree-like structure. The databases
    consist of a series of data records. Each record contains a set of fields that
    are determined by the type of records (this is also called a segment). Each segment
    can be related to another segment by relationships called *links*. These types
    of databases are known for *parent-child relationships*. The model is simple but
    can only support one-to-many relationships. The following diagram shows an example
    of a hierarchical database model:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是数据以树状结构存储的数据库。数据库由一系列数据记录组成。每个记录包含一组字段，这些字段由记录类型确定（这也可以称为段）。每个段可以通过称为*链接*的关系与另一个段相关联。这类数据库以*父子关系*而闻名。模型简单，但只能支持一对一和多对一的关系。以下图展示了层次数据库模型的一个示例：
- en: '![Figure 2.7 – An example of a hierarchical data model ](img/B17084_02_009.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![图2.7 – 层次数据模型的示例](img/B17084_02_009.jpg)'
- en: Figure 2.7 – An example of a hierarchical data model
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7 – 层次数据模型的示例
- en: As shown in the preceding diagram, `Member` is the root segment. One record
    of the `Member` segment contains the ID `001`. There are two child segments to
    the root segment called `Address` and `Language`. In the `Address Segment` part,
    we can see three record instances – that is, `Address Mail`, `Address Home`, and
    `Address Work`. The `Language Segment` part also has instances such as `Spoken`
    and `Written`.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，`Member`是根段。`Member`段的记录包含ID `001`。根段有两个子段，称为`Address`和`Language`。在`Address
    Segment`部分，我们可以看到三个记录实例——即`Address Mail`、`Address Home`和`Address Work`。`Language
    Segment`部分也有例如`Spoken`和`Written`这样的实例。
- en: Examples of hierarchical databases include IBM **Information Management System**
    (**IMS**) and RDM Mobile.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 层次数据库的例子包括IBM **信息管理系统**（**IMS**）和RDM Mobile。
- en: RDBMS
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RDBMS
- en: RDBMS is a relational database management system that uses SQL as its programming
    and querying interface. It is the most popular and established kind of database
    across the industry. Data is stored in tables, which represent specific entities.
    Tables have a clearly defined set of columns, along with their data type. Each
    row in a table is called a record. Each table can contain primary keys that uniquely
    identify a record. Each table supports a variety of indexes. One table can be
    linked to another table by a foreign key index. RDBMS can support one-to-many
    and many-to-many relationships. They are very powerful and have been the powerhouses
    behind most modern applications for many decades.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: RDBMS是一种使用SQL作为其编程和查询接口的关系型数据库管理系统。它是整个行业中最为流行和成熟的数据库类型。数据存储在表中，表代表特定的实体。表有一组明确定义的列，以及它们的数据类型。表中的每一行称为一条记录。每个表可以包含唯一标识记录的主键。每个表支持多种索引。一个表可以通过外键索引与另一个表相连接。RDBMS可以支持一对一和多对多关系。它们非常强大，并且已经成为了过去几十年大多数现代应用背后的动力源泉。
- en: Examples of RDBMSs include MySQL, Oracle, PostgreSQL, Amazon RDS, and Azure
    SQL.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: RDBMS的例子包括MySQL、Oracle、PostgreSQL、Amazon RDS和Azure SQL。
- en: '*When to use*: RDBMS is pretty much used everywhere you need multi-row ACID
    transactions and where you require complex joins. Web applications, employee management
    systems, and financial organization''s online transactions are a few examples
    of where RDBMS is used.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '*何时使用*：RDBMS几乎在需要多行ACID事务和需要复杂连接的任何地方都会被使用。Web应用、员工管理系统和金融机构的在线交易是一些RDBMS被使用的例子。'
- en: NoSQL database
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NoSQL数据库
- en: 'NoSQL, as discussed earlier in this section, supports unstructured as well
    as semi-structured data. This is possible because it supports flexible schema.
    Also, NoSQL databases store and process data in a distributed manner and hence
    can scale out infinitely. The usage of distributed computing in NoSQL database
    architectures helps them support a tremendous volume of data and makes them a
    great choice for big data processing. The different ways a relational database
    and a NoSQL database handle scaling can be seen in the following diagram:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如本节前面所述，NoSQL支持非结构化数据以及半结构化数据。这是因为它支持灵活的模式。此外，NoSQL数据库以分布式方式存储和处理数据，因此可以无限扩展。NoSQL数据库架构中分布式计算的使用有助于它们支持巨大的数据量，使它们成为大数据处理的一个很好的选择。以下图表展示了关系型数据库和NoSQL数据库处理扩展的不同方式：
- en: '![Figure 2.8 – Scale-up versus scale-out ](img/B17084_02_010.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![图2.8 – 升级与扩展对比](img/B17084_02_010.jpg)'
- en: Figure 2.8 – Scale-up versus scale-out
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8 – 升级与扩展对比
- en: As we can see, a relational database scales up the same instance. However, that
    creates a limitation of scaling. Also, scaling up is a costlier operation. On
    the other hand, NoSQL uses commodity hardware, which is cheap, and the architecture
    is such that to scale it, it needs to be scaled out. This means that NoSQL can
    scale infinitely and is cheaper to scale.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，关系型数据库扩展的是相同的实例。然而，这创造了一个扩展的限制。此外，升级是一个成本较高的操作。另一方面，NoSQL使用的是廉价的通用硬件，其架构是这样的，为了扩展，它需要向外扩展。这意味着NoSQL可以无限扩展，并且扩展成本更低。
- en: NoSQL databases can be further categorized into specific kinds of databases.
    We will discuss each of them briefly while providing examples and usages.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: NoSQL数据库可以进一步细分为特定类型的数据库。我们将简要讨论每个类型，并提供示例和用法。
- en: Key-value store
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 键值存储
- en: Key-value stores are the simplest kind of NoSQL databases. The data that’s stored
    is in a key and value format. The attribute name is stored in the *key*, while
    the value of the attribute is stored in the *value*. Here, the key needs to be
    a string, but the value can be an object of any type. This means that the value
    can be a JSON, an XML, or some custom serialized object.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 键值存储是最简单的NoSQL数据库类型。存储的数据以键值格式存在。属性名称存储在*键*中，而属性值存储在*值*中。在这里，键需要是一个字符串，但值可以是任何类型的对象。这意味着值可以是JSON、XML或某些自定义序列化对象。
- en: A few examples of key-value stores are Redis, Memcached, and RocksDB.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 一些键值存储的例子包括Redis、Memcached和RocksDB。
- en: '*When to use*:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '*何时使用*：'
- en: In a microservice or an application. If you need a lookup table that needs to
    be read fast, then an in-memory key-value store such as Redis and Memcached is
    a good choice. Again, while Memcached supports concurrent reads, it doesn’t support
    values that are complex like Redis does. Cloud services such as AWS ElastiCache
    support both of these databases. If you are interested, you can find a more detailed
    comparison between Redis and Memcached at [https://aws.amazon.com/elasticache/redis-vs-memcached/](https://aws.amazon.com/elasticache/redis-vs-memcached/).
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在一个微服务或应用程序中。如果你需要一个需要快速读取的查找表，那么内存中的键值存储，如Redis和Memcached，是一个不错的选择。同样，虽然Memcached支持并发读取，但它不支持像Redis那样复杂的值。云服务如AWS
    ElastiCache支持这两种数据库。如果你感兴趣，你可以在[https://aws.amazon.com/elasticache/redis-vs-memcached/](https://aws.amazon.com/elasticache/redis-vs-memcached/)找到Redis和Memcached之间更详细的比较。
- en: In real-time event stream processing, the state needs to be maintained if the
    current event processing is dependent on the state of an older event. This kind
    of real-time processing is called stateful stream processing. In stateful stream
    processing, RocksDB is a great choice to maintain the state as a key-value pair.
    Kafka Streams uses RocksDB internally to maintain the state for stateful stream
    processing.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在实时事件流处理中，如果当前事件处理依赖于较旧事件的状态，则需要维护状态。这种实时处理称为有状态流处理。在有状态流处理中，RocksDB是一个很好的选择，可以将状态作为键值对来维护。Kafka
    Streams内部使用RocksDB来维护有状态流处理的状态。
- en: Next, let’s take a look at document-based databases.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们来看看基于文档的数据库。
- en: Document-based database
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于文档的数据库
- en: Document databases are NoSQL databases that give you an easy way to store and
    query data from a document. A document is defined as a semi-structured data format
    such as JSON or XML. Document databases support nested elements as well, such
    as nested JSON and JSON arrays. Each document in a document database is stored
    in a key-value pair, where the key is a unique ID for the document and the value
    is the document that is stored. Document databases support indexing on any field
    of the document, even if it is a nested field.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 文档数据库是NoSQL数据库，它为你提供了一种简单的方式来存储和查询文档数据。文档被定义为一种半结构化数据格式，如JSON或XML。文档数据库还支持嵌套元素，如嵌套JSON和JSON数组。文档数据库中的每个文档都存储在一个键值对中，其中键是文档的唯一ID，值是存储的文档。文档数据库支持对文档的任何字段进行索引，即使它是嵌套字段。
- en: A few examples of document-based databases are MongoDB, Apache CouchDB, Azure
    Cosmos DB, AWS DocumentDB, and ElasticSearch.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 一些基于文档的数据库的例子包括MongoDB、Apache CouchDB、Azure Cosmos DB、AWS DocumentDB和ElasticSearch。
- en: '*When to use*:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '*何时使用*：'
- en: When you want to publish curated data from a data lake or a data mart to web
    applications by using a microservice or REST API. Since web applications run on
    JavaScript, they can easily parse a JSON document. Storing a well-designed JSON
    document in a document database such as MongoDB or AWS DocumentDB gives the web
    application amazing performance.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你想要通过微服务或REST API将数据湖或数据集市中的精选数据发布到Web应用程序时。由于Web应用程序运行在JavaScript上，它们可以轻松解析JSON文档。在MongoDB或AWS
    DocumentDB等文档数据库中存储精心设计的JSON文档，可以为Web应用程序提供惊人的性能。
- en: If you are receiving feeds from multiple dynamic data feeds, such as social
    media feeds from Twitter, LinkedIn, and Facebook, and the schema of these feeds
    is evolving, you must process and publish this data together by extracting certain
    data points or running some kind of aggregation over them, then Apache CouchDB
    may be an excellent choice. Simply put, if you are consuming document data and
    have no control over the inbound schema, a document-based data store is a great
    choice.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你正在接收来自多个动态数据源的数据，例如来自Twitter、LinkedIn和Facebook的社交媒体源，并且这些源的模式正在演变，你必须通过提取某些数据点或对它们进行某种聚合来一起处理和发布这些数据，那么Apache
    CouchDB可能是一个极好的选择。简单来说，如果你正在消费文档数据并且无法控制传入的模式，基于文档的数据存储是一个很好的选择。
- en: If your lookup needs are not catered by a key-value store. If the value is a
    document that has a very complex schema or that the cost of the storage in the
    key-value store is becoming too high because of the volume of the data, then a
    document-based database is the next most obvious choice.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的查找需求无法由键值存储来满足。如果值是一个具有非常复杂模式或由于数据量过大而导致键值存储中的存储成本变得过高的文档，那么基于文档的数据库是下一个最明显的选择。
- en: If you are creating a search repository for a business, then you might want
    to store the data in a search engine storage such as Elasticsearch, a document-based
    database. It creates a reverse text index (called the Lucene index) while storing
    the data. This is a special document-based database where each record is stored
    as a document, along with a unique key. Elasticsearch provides amazing search
    performance. However, data should only be stored in Elasticsearch if you want
    to perform a high-performance text-based search over the data or to create some
    visualization out of the data.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你正在为业务创建一个搜索存储库，那么你可能希望将数据存储在搜索引擎存储中，如基于文档的数据库Elasticsearch。它在存储数据时创建反向文本索引（称为Lucene索引）。这是一个特殊的基于文档的数据库，其中每个记录都存储为文档，并附带一个唯一的键。Elasticsearch提供了惊人的搜索性能。然而，只有当你想要在数据上执行高性能的基于文本的搜索或从数据中创建一些可视化时，才应该将数据存储在Elasticsearch中。
- en: Let’s now explore columnar databases.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来探讨列式数据库。
- en: Columnar database
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 列式数据库
- en: 'A columnar database stores data in a columnar format. Columnar databases are
    created using Big table. According to a paper published by Google that introduced
    Bigtable, it is *a sparse, distributed, persistent multidimensional sorted map*.
    At its core, each columnar database is a map. Here, each data record is associated
    with a key called the row key. These keys are unique and lexicographically sorted.
    The data that’s stored in a columnar database is persisted in a distributed filesystem
    that provides high availability of the data. Instead of columns, we define column
    families in a columnar database. Each column family can consist of any number
    of columns. The columns inside a column family are not fixed for all records and
    can be added dynamically. This means that in most data records, one or more columns
    may be empty or non-existent, so this data structure is sparse.  This allows you
    to dynamically add columns to a record. This makes columnar databases a great
    choice for storing unstructured data. The following diagram tries to capture the
    essence of a columnar database:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 列式数据库以列式格式存储数据。列式数据库是使用Bigtable创建的。根据谷歌发布的一篇介绍Bigtable的论文，它是一个*稀疏的、分布式的、持久的、多维排序映射*。在其核心，每个列式数据库都是一个映射。在这里，每个数据记录都与一个称为行键的键相关联。这些键是唯一的，并且按字典顺序排序。存储在列式数据库中的数据持久化在提供高数据可用性的分布式文件系统中。在列式数据库中，我们定义列族而不是列。每个列族可以包含任意数量的列。列族内部的列对于所有记录不是固定的，并且可以动态添加。这意味着在大多数数据记录中，一个或多个列可能是空的或不存在，因此这种数据结构是稀疏的。这允许你动态地向记录添加列。这使得列式数据库成为存储非结构化数据的一个很好的选择。以下图表试图捕捉列式数据库的精髓：
- en: '![Figure 2.9 – Columnar database structure ](img/B17084_02_11.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图2.9 – 列式数据库结构](img/B17084_02_11.jpg)'
- en: Figure 2.9 – Columnar database structure
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9 – 列式数据库结构
- en: As shown in the preceding diagram, the records are divided into regions. One
    or more regions reside on a node in a distributed filesystem such as HDFS or GFS.
    Each column family inside a region is stored as a separate file. Again, each column
    inside a column family can support versioning, which makes columnar storage truly
    multi-dimensional.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，记录被划分为区域。一个或多个区域位于分布式文件系统（如HDFS或GFS）的节点上。区域内部的每个列族都存储为单独的文件。同样，列族内部的每个列都可以支持版本控制，这使得列式存储真正是多维的。
- en: Examples include Apache HBase, Cassandra, and Apache Kudu.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，包括Apache HBase、Cassandra和Apache Kudu。
- en: '*When to use*:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '*何时使用*:'
- en: In ad agency and marketing campaigns, a columnar data store is used to store
    the events of user clicks and user choices in real time. These real-time events
    are used on the fly to optimize the ads shown to a user or offers to send to a
    customer.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在广告公司和营销活动中，列式数据存储用于实时存储用户点击和用户选择的事件。这些实时事件被即时用于优化向用户展示的广告或发送给客户的优惠。
- en: Another example is data received from Kafka as a stream of events that are small
    in size. These need to be stored in HDFS so that they can be analyzed or processed
    periodically using some form of batch application. Here, a columnar database is
    preferred since storing the data directly in HDFS or a warehouse such as Hive
    will create too many small files, which, in turn, will create too much metadata,
    thus slowing down the Hadoop cluster’s overall performance. Columnar storage is
    written to disk when the region size is reached and is usually placed in sequential
    files, so they are ideal for this kind of storage.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个例子是从Kafka接收的事件流数据，这些事件数据量小。这些数据需要存储在HDFS中，以便可以定期使用某种形式的批量应用程序进行分析或处理。在这里，列式数据库是首选，因为直接在HDFS或类似Hive的仓库中存储数据将创建太多小文件，这反过来又会创建太多元数据，从而降低Hadoop集群的整体性能。当达到区域大小时，列式存储被写入磁盘，并且通常放置在顺序文件中，因此它们非常适合这种存储。
- en: They are great databases for massive dynamic spikes in data. For example, they
    are great for handling massive data surges when sales are on during the holiday
    season.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们是处理大量动态数据波动的优秀数据库。例如，在假日季节销售活动期间，它们非常适合处理大量数据激增。
- en: Next, let’s take a look at the graph database.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看图数据库。
- en: Graph database
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图数据库
- en: A graph database is a database where data is stored in a graph structure. Essentially,
    this means that graph databases not only store the data but also the relationships
    between it. With the advent of social networking and since the data of every domain
    has become more connected, there is a growing need to not only query data but
    query the connections between the data. Also, in social networks, it is necessary
    to explore neighboring data points (for example, LinkedIn needs to explore data
    adjacency to show whether a person is connected to your profile as a 1st level,
    2nd level, or 3rd level connection). Although relational databases can be used
    to get relationships using joins, a database can store, process, and query connections
    efficiently only if it natively supports relationships.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图数据库是一种将数据存储在图结构中的数据库。本质上，这意味着图数据库不仅存储数据，还存储数据之间的关系。随着社交网络的出现以及每个领域的数据都变得更加相互连接，不仅需要查询数据，还需要查询数据之间的连接。在社交网络中，探索邻近数据点（例如，LinkedIn需要探索数据邻近度以显示一个人是否作为一级、二级或三级连接与您的个人资料相连）是必要的。尽管可以使用连接来获取关系，但只有数据库原生支持关系时，才能有效地存储、处理和查询连接。
- en: 'Most graph databases use a popular modeling approach called the **property
    graph model**. Here, data is organized into nodes, relationships, and properties.
    The following diagram shows an example of data stored using the property graph
    model:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数图数据库使用一种流行的建模方法，称为**属性图模型**。在这里，数据被组织成节点、关系和属性。以下图显示了使用属性图模型存储数据的示例：
- en: '![Figure 2.10 – Example of a property graph model ](img/B17084_02_012.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图2.10 – 属性图模型的示例](img/B17084_02_012.jpg)'
- en: Figure 2.10 – Example of a property graph model
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.10 – 属性图模型的示例
- en: In the property graph model, there are nodes and relationships. `name`, `data_of_birth`,
    and `employee_ID`.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在属性图模型中，有节点和关系。例如，`name`、`data_of_birth`和`employee_ID`。
- en: Relationships are directed and use named connections between two named entities
    or nodes. For example, as shown in the preceding diagram, `HAS_CEO` is a relationship
    between `HAS_CEO` relationship has a property called `start_date`.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 关系是有向的，并使用命名连接在两个命名实体或节点之间。例如，如前图所示，`HAS_CEO`是`HAS_CEO`关系，它有一个名为`start_date`的属性。
- en: Just like SQL standards, which are used to query RDBMS, graph databases can
    be queried using GQL. GQL is a newly announced ISO standard that helps query graph
    databases. One of the more popular open source GQLs available is openCypher. (You
    can learn more about openCypher at [https://opencypher.org/](https://opencypher.org/).)
    Other popular graph database query languages include Cypher, TinkerPop3, and SPARQL.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 就像SQL标准用于查询RDBMS一样，图数据库可以使用GQL进行查询。GQL是一个新宣布的ISO标准，有助于查询图数据库。更受欢迎的开源GQL之一是openCypher。（您可以在[https://opencypher.org/](https://opencypher.org/)了解更多关于openCypher的信息。）其他流行的图数据库查询语言包括Cypher、TinkerPop3和SPARQL。
- en: Some examples of graph databases are Neo4J, ArangoDB, RedisGraph, Amazon Neptune,
    and GraphDB.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 一些图数据库的例子包括Neo4J、ArangoDB、RedisGraph、Amazon Neptune和GraphDB。
- en: '*When to use*:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '*何时使用*：'
- en: Fraud call detection.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欺诈电话检测。
- en: Recommendation engines.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐引擎。
- en: Customer engagement on travel websites.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旅行网站上的客户参与度。
- en: Referral relationships. For example, using a graph database, a healthcare provider
    can identify the various other providers they can get a referral from. This helps
    target specific clients and build a relationship that can be beneficial for both
    providers.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Helps in a marketing campaign to identify influencers in a connected network
    by querying the number of incoming connections to a particular node.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we discussed various types of databases and when they should
    be used. We covered a few examples and sample use cases where a particular database
    should be chosen and why. In the next section, we will look at a few considerations
    a data architect should keep in mind while designing data models for various databases.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Data model design considerations
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will briefly discuss various design considerations you
    should consider while designing a data model for the various databases discussed
    in the previous section. The following aspects need to be considered while designing
    a data model:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '**Normalized versus denormalized**: Normalization is a data organization technique.
    It is used to reduce redundancy in a relationship or set of relationships. This
    is highly used in RDBMS, and it is always a best practice in RDBMS to create a
    normalized data model. In a normalized data model, you store a column in one of
    the tables (which is most suitable), rather than storing the same column in multiple
    tables. When fetching data, if you need the data of that column, you can join
    the tables to fetch that column. The following diagram shows an example of normalized
    data modeling using the crows-feet notation:'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![ Figure 2.11 – Normalized data modeling ](img/B17084_02_013.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
- en: Figure 2.11 – Normalized data modeling
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding diagram, none of the columns are repeated or redundant. Now,
    suppose we need to show an order that should display `customer name`, `Customer
    ID`, `Order ID`, `item name`, and `Order date`. To fetch this information, we
    can write a join query, like this:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'On the other hand, if we are designing the same thing for a NoSQL database,
    the focus should not be on reducing redundancy or normalizing the data. Instead,
    we should focus on the read speed. Such a change in design mindset is triggered
    by two important factors. First, NoSQL works with a huge volume of data and stores
    the data in distributed commodity hardware. So, data storage is not costly, and
    joins may not work efficiently if the volume of data is in hundreds of TBs or
    PBs. Second, NoSQL doesn’t have the `JOIN` kind of queries, because NoSQL databases
    are non-relational. The following is an example of a document data model storing
    the same information that needs to be fetched:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As we can see, a single document contains all the necessary information, so
    this means a lot of redundant data. However, for big data scenarios, NoSQL works
    perfectly fine and provides great performance.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '**Query-first versus schema-first pattern**: While designing a data model in
    NoSQL, you must ask yourself what queries are going to run on this data model.
    The data model design in NoSQL usually starts with the kind of analytical query
    that will run on the model. This helps design a correct key for a document or
    a record in a NoSQL database. Also, in the case of a columnar database, it helps
    group columns in a column family based on the query that will run on the data.
    Such optimization helps NoSQL databases run queries with awesome performance on
    big data or unstructured data.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查询优先与模式优先模式**：在设计 NoSQL 数据模型时，你必须问自己将要在这个数据模型上运行哪些查询。NoSQL 中的数据模型设计通常从将在模型上运行的类型分析查询开始。这有助于为
    NoSQL 数据库中的文档或记录设计正确的键。此外，在列式数据库的情况下，它有助于根据将要运行在数据上的查询来对列族中的列进行分组。这种优化有助于 NoSQL
    数据库在大数据或非结构化数据上以惊人的性能运行查询。'
- en: On the other hand, RDBMS is designed to store data in a predefined schema that
    has been normalized and the relationships are very well defined. Since SQL is
    a declarative language and can query tables along with any related table during
    runtime, queries are not considered while designing an RDBMS data model.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，RDBMS 是设计用来存储在预定义的、经过规范化的模式中，其中关系定义得非常明确。由于 SQL 是一种声明性语言，并且可以在运行时查询任何相关表，因此在设计
    RDBMS 数据模型时不会考虑查询。
- en: '**Cost versus speed optimization**: With the advent of cloud databases and
    cloud-based solutions, understanding the cost considerations is a very important
    factor for a modern data architect. For example, when it comes to storage versus
    **Input/Output Operations Per Second** (**IOPS**), IOPS are always costlier than
    storage in cloud-based models. However, understanding the difference in how IOPS
    is calculated for an RDBMS or document store can help you save costs and effort
    in the longer term. An RDBMS IOPS is based on the page or the block size. So,
    RDBMS IOPS is determined by the number of pages it has accessed. However, in a
    document database, IOPS is based on the number of DB read/writes that happen in
    that database.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本与速度优化**：随着云数据库和基于云的解决方案的出现，理解成本考虑因素对于现代数据架构师来说是一个非常重要的因素。例如，当涉及到存储与每秒输入/输出操作数（**IOPS**）相比时，在基于云的模型中，IOPS
    总是比存储更昂贵。然而，了解 RDBMS 或文档存储中 IOPS 的计算差异可以帮助你在长期内节省成本和精力。RDBMS 的 IOPS 基于页面或块大小。因此，RDBMS
    的 IOPS 由它访问的页面数量决定。然而，在文档数据库中，IOPS 基于该数据库中发生的 DB 读取/写入次数。'
- en: Another example is that if, in an AWS DocumentDB, you give a greater number
    of indexes, you might get a better speed, but too many indexes will increase IOPS
    considerably, so it might cost you more. A safe limit of indexes per collection
    is five.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是，如果在 AWS DocumentDB 中，你提供了更多的索引，你可能会获得更好的速度，但过多的索引会显著增加 IOPS，因此可能会花费你更多。每个集合的索引安全限制是五个。
- en: '**Indexes**: If you have a database, where you have a huge number of reads
    and you need to have great read performance, then you should consider having indexes
    in your database. Indexes help improve your read and update performance in your
    database. On the other hand, if you have a write-heavy application, indexes can
    slow down your insert performance.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**索引**：如果你有一个数据库，其中你有很多读取操作并且需要拥有出色的读取性能，那么你应该考虑在你的数据库中拥有索引。索引有助于提高你在数据库中的读取和更新性能。另一方面，如果你有一个写入密集型的应用程序，索引可能会减慢你的插入性能。'
- en: '**Data distributions**: NoSQL databases are based on the scale-out architecture,
    where the data is stored and distributed across commodity nodes. One of the reasons
    that NoSQL databases have great performance for huge data volumes is that they
    can read or write data in parallel in the distributed nodes. However, if not designed
    properly, the data can be stored unevenly, which can cause a huge volume of data
    to be present in one node. This kind of uneven distribution of data in a distributed
    database is called **data skew**.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据分布**：NoSQL 数据库基于横向扩展架构，数据存储和分布在商品节点上。NoSQL 数据库对大量数据具有出色性能的一个原因是它们可以在分布式节点上并行读取或写入数据。然而，如果设计不当，数据可能会存储不均匀，这可能导致大量数据存在于一个节点上。这种在分布式数据库中的数据不均匀分布称为**数据倾斜**。'
- en: Often, the problem of a node containing unusually high amounts of data, which
    can cause read or write bottlenecks for the database, is called **hotspotting**.
    Often, this happens due to a lack of understanding of the design principles of
    NoSQL databases and poor key design. In columnar databases, choosing an incremental
    sequence number as a key often leads to hotspotting. Instead, in both document
    and columnar databases, unique keys should be chosen and a combination of a few
    key column values should be concatenated in a particular order, preferably at
    least one of them being a text value. Techniques such as salting and MD5 encryption
    are used while designing the keys to help avoid hotspotting.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，一个节点包含异常大量数据的问题，这可能导致数据库的读写瓶颈，被称为**热点问题**。这种情况通常是由于对NoSQL数据库的设计原则缺乏理解以及关键设计不当造成的。在列式数据库中，选择增量序列号作为键通常会导致热点问题。相反，在文档和列式数据库中，应选择唯一键，并将几个键列值的组合以特定顺序连接起来，最好至少有一个是文本值。在设计键时使用如盐值和MD5加密等技术，有助于避免热点问题。
- en: In this section, we covered the most obvious design considerations you should
    look at after you have chosen a database. While these considerations are basic
    for any data model design, there are other finer data model design techniques
    that are specific to the database you are choosing. We strongly recommend that
    you go over the official documentation of the database you’ve chosen for your
    solutions before you design your data model.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了在选择数据库后你应该考虑的最明显的设计考虑因素。虽然这些考虑因素对任何数据模型设计都是基本的，但还有其他更精细的数据模型设计技术，这些技术是特定于你所选择的数据库的。我们强烈建议你在设计数据模型之前，仔细阅读你所选择数据库的官方文档。
- en: Summary
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered the various data types and data formats that are
    available. We also discussed the various popular data formats that are used in
    modern data engineering and the compression techniques that are compatible with
    each. Once we understood the data types and formats, we explored various data
    storage formats – file, block, and object storage – we can use to store the data.
    Then, we discussed various kinds of enterprise data repositories in detail – data
    lake, data warehouse, and data marts. Once we covered the basics of data, including
    the different types and their storage, we briefly discussed databases and their
    types. We discussed various examples of databases, the USP of each kind of database,
    and when a particular kind of database should be chosen over another. We explored
    possible use cases when a database should be used.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了各种可用的数据类型和数据格式。我们还讨论了在现代数据工程中使用的各种流行数据格式以及与每种格式兼容的压缩技术。一旦我们了解了数据类型和格式，我们就探索了各种数据存储格式——文件、块和对象存储——我们可以用来存储数据。然后，我们详细讨论了各种企业数据存储库——数据湖、数据仓库和数据集市。一旦我们涵盖了数据的基础知识，包括不同类型及其存储，我们简要地讨论了数据库及其类型。我们讨论了各种数据库的例子，每种数据库的独特卖点，以及在何时应该选择一种数据库而不是另一种。我们还探讨了何时应该使用数据库的可能用例。
- en: Finally, we briefly covered the basic design considerations that a data architect
    should keep in mind while designing their data model using any chosen database.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们简要地概述了数据架构师在设计数据模型时应考虑的基本设计考虑因素。
- en: Now that you know about data types, formats, databases, and when to use what,
    in the next chapter, we will explore the various platforms where data engineering
    solutions can be deployed and run.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了数据类型、格式、数据库以及何时使用什么，在下一章中，我们将探讨数据工程解决方案可以部署和运行的各种平台。
