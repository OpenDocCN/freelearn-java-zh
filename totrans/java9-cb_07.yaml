- en: Concurrent and Multithreaded Programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Concurrent programming has always been a difficult task. It might sound easy,
    but it is a source of many hard-to-solve problems. In this chapter, we will show
    you different ways of incorporating concurrency and some best practices, such
    as immutability, which will help in creating better, concurrent applications.
    We will also discuss the implementation of some commonly used patterns, such as
    divide-conquer and publish-subscribe, using the constructs provided by Java. We
    will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the basic element of concurrency - thread
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different synchronization approaches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Immutability as a means to achieve concurrency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using concurrent collections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the executor service to execute async tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using fork/join to implement divide-and-conquer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using flow to implement the publish-subscribe pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Concurrency--the ability to execute several procedures in parallel--becomes
    increasingly important as big data analysis moves into the mainstream of modern
    applications. Having CPUs or several cores in one CPU helps increase the throughput,
    but the growth rate of data volume will always outpace hardware advances. Besides,
    even in a multiple CPU system, one still has to structure the code and think about
    resource sharing to take advantage of the available computational power.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapters, we demonstrated how lambdas with functional interfaces
    and parallel streams made concurrent processing a part of the toolkit of every
    Java programmer. One can easily take advantage of this functionality with minimal
    guidance, if at all.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will describe some other--old (that existed before Java
    9) and new--Java features and APIs that allow more control over concurrency. The
    high-level concurrency Java API has been around since Java 5\. The JDK Enhancement
    Proposal (JEP) 266, *More Concurrency Updates,* introduced *an interoperable publish-subscribe
    framework, enhancements to the CompletableFuture API, and various other improvements* to
    Java 9 in the `java.util.concurrent` package. But before we dive into the details
    of the latest additions, let's review the basics of concurrent programming in
    Java and see how to use them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Java has two units of execution: process and thread. A process usually represents
    the whole JVM, although an application can create another process using `ProcessBuilder`.
    But since the multiprocess case is outside the scope of this book, we will focus
    on the second unit of execution, that is, a thread, which is similar to a process
    but less isolated from other threads and requires fewer resources for execution.'
  prefs: []
  type: TYPE_NORMAL
- en: A process can have many threads running and at least one thread called the main
    thread. Threads can share resources, including memory and open files, which allows
    better efficiency, but comes with a price of higher risk of unintended mutual
    interference and even blocking of the execution. This is where programming skills
    and an understanding of the concurrency technique are required. And this is what
    we are going to discuss in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Using the basic element of concurrency - thread
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will look at the `java.lang.Thread` class and see what it
    can do for concurrency and program performance in general.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Java application starts as the main thread (not counting system threads that
    support the process). It can then create other threads and let them run in parallel
    (sharing the same core via time slicing of having a dedicated CPU for each thread).
    This can be done using the `java.lang.Thread` class that implements the `Runnable`
    functional interface with only one `run()` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways of creating a new thread: creating a subclass of `Thread`
    or implementing the `Runnable` interface and passing the object of the implementing
    class to the `Thread` constructor. We can invoke the new thread by calling the
    `start()` method of the `Thread` class (which, in turn, calls the `run()` method
    that we implemented).'
  prefs: []
  type: TYPE_NORMAL
- en: Then, we can either let the new thread run until its completion or pause it
    and let it continue again. We can also access its properties or intermediate results,
    if needed.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we create a class called `AThread` that extends `Thread` and override
    its `run()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we wanted the thread to generate a stream of integers in a
    certain range. Then, we peeked into each emitted integer (the method `peek()` cannot
    change the stream element) and called the static method `doSomething()` of the
    main class in order to make the thread busy for some time. Refer to the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, this method generates another stream of integers in the range
    of `i` and `99999`, then converts the stream into a stream of doubles, calculates
    the square root of each of the stream elements, and finally calculates an average
    average of the stream. We discard the result and return the passed-in parameter
    (as a convenience that allows us to keep the fluent style in the stream pipe of
    the thread, which ends up printing out each element). Using this new class, we
    can now demonstrate the concurrent execution of the three threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The first thread generates the integers `1`, `2`, and `3`, the second generates
    the integers `11`, `12`, and `13`, and the third thread (main one) generates `21`,
    `22`, and `23`.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned before, we can rewrite the same program by creating and using
    a class that could implement the `Runnable` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'So, you can run the same three threads like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also take advantage of `Runnable` being a functional interface and avoid
    creating an intermediate class by passing in a lambda expression instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Which implementation is better depends on your goal and style. Implementing
    `Runnable` has an advantage (and in some cases, the only possible option) that
    it allows the implementation to extend from another class. It is particularly
    helpful when you would like to add thread-like behavior to an existing class.
    You can even invoke method `run()` directly, without passing the object to the
    `Thread` constructor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using a lambda expression wins over `Runnable` implementation when only method `run()` implementation
    is needed, no matter how big it is. If it is too big, you can have it isolated
    in a separate method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: One would be hard pressed to come up with a shorter implementation of the same
    functionality.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we run any of the preceding versions, we will get something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a7d8b2a4-7c0d-453a-bfb6-e27ee4448308.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the three threads print out their numbers in parallel, but the
    sequence depends on the particular JVM implementation and underlying operating
    system. So, you will probably get different output. Besides, it also changes from
    run to run.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Thread` class has several constructors that allow you to set the thread
    name and the group it belongs to. Grouping of threads helps manage them in case
    there are many threads running in parallel. The class also has several methods
    that provide information about the thread''s status and properties and allow you
    to control its behavior. Add these two lines to the preceding example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'You''ll get something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6bc78a6a-ddb4-4594-a619-de660561eb1c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, say, you add names to the threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the output will show the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f5d7fac4-bd4b-4ff9-bac0-95c654d2c7d4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The thread''s `id` is generated automatically and cannot be changed, but it
    can be reused after the thread is terminated. The thread name, on the other hand,
    can be shared by several threads. Priority can be set programmatically with a
    value between `Thread.MIN_PRIORITY` and `Thread.MAX_PRIORITY`. The smaller the
    value, the more time the thread is allowed to run (which means it has higher priority).
    If not set, priority value defaults to `Thread.NORM_PRIORITY`. The state of a
    thread can have one of the following values:'
  prefs: []
  type: TYPE_NORMAL
- en: '`NEW`: When a thread has not yet started'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RUNNABLE`: When a thread is being executed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BLOCKED`: When a thread is blocked and is waiting for a monitor lock'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`WAITING`: When a thread is waiting indefinitely for another thread to perform
    a particular action'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TIMED_WAITING`: When a thread is waiting for another thread to perform an
    action for up to a specified waiting time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TERMINATED`: When a thread has exited'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will talk about the `BLOCKED` and `WAITING` states in one of our recipes
    later.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `sleep()` method can be used to suspend the thread execution for a specified
    (in milliseconds) period of time. The complementary method `interrupt()` sends
    `InterruptedException` to the thread that can be used to wake up the *sleeping*
    thread. Let''s work this out in the code and create a new class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code produces intermediate results, which are stored in the property
    `result`. Each time a new result is produced, the thread sleeps for one second.
    In this specific example, written for demonstration purposes only, the code does
    not do anything particularly useful.  It just iterates over a set of values and
    considers each of them a result. In a real-world code, you would do some calculations
    here based on the current state of the system or something and assign the calculated
    value to the property `result`. Now let''s use this class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding program generates a stream of integers: 21, 22, ..., 28\. After
    each integer is generated, the main thread interrupts the `thr1` thread and lets
    it generate the next result, which is then accessed via the `getCurrentResult()`
    method and analyzed. If the current result is an even number, the filter allows
    the generated number flow to be printed out. If not, it is skipped. Here is a
    possible result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/47552ae2-9a12-4c4a-88b4-e35729ad770c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It will be different if the program is run on different computers, but you
    get the idea: this way, one thread can control the output of another thread.'
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are two other important methods that allow threads to cooperate. First
    is the `join()` method that allows the current thread to wait until another thread
    is terminated. Overloaded versions of `join()` accept the parameters that define
    how long the thread has to wait before it could do something else.
  prefs: []
  type: TYPE_NORMAL
- en: The `setDaemon()` method terminates the thread automatically after all the non-daemon
    threads are terminated. Usually, it is used for background and supporting processes.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Refer to the following recipes in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Different synchronization approaches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Immutability as a means to achieve concurrency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using concurrent collections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the executor service to execute async tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using fork/join to implement divide-and-conquer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using flow to implement the publish-subscribe pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different synchronization approaches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, you will learn about the two most popular and basic methods
    of managing concurrent access to common resources in Java: a `synchronized` method
    and a `synchronized` block.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Two or more threads modifying the same value while other threads reading it
    is the most general description of a problem of concurrent access. Subtler problems include
    *thread interference* and *memory consistency errors*, both producing unexpected
    results in seemingly benign fragments of code.  We are going to demonstrate such
    cases and ways to avoid them.
  prefs: []
  type: TYPE_NORMAL
- en: 'At first glance, it seems quite straightforward: just allow only one thread
    at a time to modify/access the resource and that''s it. But if the access takes
    a long time, then it creates a bottleneck that might eliminate the advantage of
    having many threads working in parallel. Or, if one thread blocks access to one
    resource while waiting for access to another resource and the second thread blocks
    access to the second resource while waiting for access to the first one, then
    it creates a problem called a deadlock. These are two very simple examples of
    the possible challenges a programmer has to tackle while dealing with multiple
    threads.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we''ll check out a problem caused by concurrency. Let''s create a `Calculator`
    class that has the `calculate()`: method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This method assigns an input value to a property and then calculates its square
    root. We also inserted code that generates a stream of 10 values. We did this
    in order to keep the method busy for some time. Otherwise, everything is done
    so quickly that there will be little chance for any concurrency to occur. Also,
    we wanted the return value to be obviously the same all the time, so we did not
    complicate it by having calculations and made the method busy by an unrelated
    activity. Now we are going to use it in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Even for a novice, it will be obvious that two threads accessing the same object
    will have a good chance of stepping on each other's toes. As you can see, the
    `Random` interface implementation prints out the sum of the same three numbers,
    that is, 1, 2, and 3, after each one of them is processed by the `calculate()` method
    of the object of `Calculator`. Inside `calculate()`, each number is multiplied
    by two and then pushed through the square root extraction process. The operation
    is so simple that we can even calculate it by hand in advance. The result is going
    to be `5.863703305156273`. And again, to the first thread, we have added the `peek()`
    operator with 10 double-generating code to make it run a bit slower to give concurrency
    a better chance to happen. If you run these examples on your computer and do not
    see the effect of concurrency, try to increase the number of doubles by replacing
    `10` with `100`, for example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now run the code. Here is one of the possible results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1f97f474-3cce-45e2-ad94-0bf99e8a72b5.png)'
  prefs: []
  type: TYPE_IMG
- en: One thread got the correct result, while the other did not. Apparently, in the
    period between setting the value of the `prop` property and then using it to return
    the result of the `calculate()` method, the other thread managed to assign its
    (smaller) value to `prop`. This is the case of thread interference.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways to protect code from such a problem: using a `synchronized`
    method or a `synchronized` block; these help include lines of code that are always
    executed as an atomic operation without any interference from another thread.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Making a `synchronized` method is easy and straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We just add the `synchronized` keyword in front of the method definition. Now,
    no matter how big a stream of doubles is generated, the result of our program
    is always going to be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/abd436e8-31d5-4436-aea3-a1a1d0fff1b7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is because another thread cannot enter the `synchronized` method until
    the current thread (the one that has entered the method already) has exited it.
    This approach may cause performance degradation if the method takes a long time
    to execute, so many threads might be blocked, waiting for their turn to use the
    method. In such cases, a `synchronized` block can be used to wrap several lines
    of code in an atomic operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you can do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We can do this because by studying the code, we have discovered that we can
    rearrange it such that the synchronized portion will be much smaller, thus having
    fewer chances to become a bottleneck.
  prefs: []
  type: TYPE_NORMAL
- en: 'A `synchronized` block acquires a lock on an object, any object for that matter.
    It could be, for example, a dedicated one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The advantage of a dedicated lock is that you can be sure that such a lock will
    be used for accessing a particular block only. Otherwise, the current object (`this`)
    might be used to control access to another block; in a huge class, you might not
    notice this while writing your code. A lock can also be acquired from a class,
    which is even more susceptible to sharing for unrelated purposes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We did all these examples just for demonstrating synchronization approaches.
    If they were to be real code, we would just let each thread create its own `Calculator`
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This would be in line with the general idea of making lambda expressions independent
    of the context in which they are created. This is because in a multithreaded environment,
    one never knows how the context would look during their execution. The cost of
    creating a new object every time is negligible unless a large amount of data has
    to be processed, and testing ensures that the object creation overhead is noticeable.
    Making the `calculate()` method (and the property) static (which is tempting as
    it avoids object creation and preserves the fluent style) would not eliminate
    the concurrency problem because one shared (at the class level this time) value
    of the property would still remain in place.
  prefs: []
  type: TYPE_NORMAL
- en: Memory consistency errors can have many forms and causes in a multithreaded
    environment. They are well discussed in the Javadoc of the `java.util.concurrent` package.
    Here we will mention only the most common case caused by lack of visibility. When
    one thread changes a property value, the other might not see the change immediately,
    and you cannot use `synchronized` keyword for a primitive type. In such a situation,
    consider using the `volatile` keyword for such a property; it guarantees its read/write
    visibility between different threads.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Different types of locks for different needs and with different behavior are
    assembled in the `java.util.concurrent.locks` package.
  prefs: []
  type: TYPE_NORMAL
- en: The `java.util.concurrent.atomic` package provides support for lock-free, thread-safe
    programming on single variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following classes provide synchronization support too:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Semaphore`: This restricts the number of threads that can access some resource'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CountDownLatch`: This allows one or more threads to wait until a set of operations
    being performed in other threads are completed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CyclicBarrier`: This allows a set of threads to wait for each other to reach
    a common barrier point'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Phaser`: This provides a more flexible form of barrier that may be used to
    control phased computation among multiple threads'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Exchanger`: This allows two threads to exchange objects at a rendezvous point
    and is useful in several pipeline designs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each object in Java is inherited from the base object's `wait()`, `notify()`,
    and `notifyAll()` methods; these can also be used to control threads' behavior
    and their access to and release from locks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Collections` class has methods that make various collections synchronized.
    However, this means that only the modifications of the collection could become
    thread-safe, not the changes to the collection members. Also, while traversing
    the collection via its iterator, it has to be protected too because an iterator
    is not thread-safe. Here is a Javadoc example of the correct usage of a synchronized
    map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'To add more to your plate as a programmer, you have to realize that the following
    code is not thread-safe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This is because although `List l` is synchronized, in multithreaded processing,
    it is quite possible that some other code would add more elements to the list
    (then the intended last does not reflect the reality) or remove an element (then
    the code fails with `IndexOutOfBoundException`).
  prefs: []
  type: TYPE_NORMAL
- en: The ones described here are a few of the most often encountered concurrency
    problems. These problems are not easy to solve. That is why it is not surprising
    that more and more developers now take a more radical approach. They avoid managing
    the state. Instead, they prefer writing non-blocking code for asynchronous and
    parallel processing data in a set of stateless operations. We saw similar code
    in the chapter about stream pipelines. It seems that Java and many modern languages
    and computer systems are evolving in this direction.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Refer to the following recipes in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Immutability as a means to achieve concurrency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using concurrent collections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the executor service to execute async tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using fork/join to implement divide-and-conquer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using flow to implement the publish-subscribe pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Immutability as a means to achieve concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to use immutability against problems caused
    by concurrency.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A concurrency problem most often occurs when different threads modify and read
    data from the same shared resource. Decreasing the number of modifying operations
    diminishes the risk of concurrency issues. This is where immutability--the condition
    of read-only values--enters the stage.
  prefs: []
  type: TYPE_NORMAL
- en: Object immutability means an absence of means to change its state after the
    object has been created. It does not guarantee thread safety but helps to increase
    it significantly and provide sufficient protection from concurrency problems in
    many practical applications.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new object instead of reusing an existing one (by changing its state
    via setters and getters) is often perceived as an expensive approach. But with
    the power of modern computers, there has to be a huge number of object creations
    done for performance to be affected in any significant way. And even if that is
    the case, programmers often prefer some performance degradation as the price for
    getting more reliable results.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here is a very basic class that produces mutable objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'To make it immutable, we need to remove the setter and add the `final` keyword
    to its only property and the class itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Adding the `final` keyword to a class prevents it from being extended, so its
    methods cannot be overridden. Adding `final` to a private property is not as obvious.
    The motivation is somewhat complex and has to do with the way the compiler reorders
    the fields during object construction. If the field is declared `final`, it is
    treated by the compiler as synchronized. That is why adding `final` to a private property
    is necessary to make the object completely immutable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The challenge mounts up if the class is composed of other classes, especially
    mutable ones. When this happens, the injected class might bring in code that would
    affect the containing class. Also, the inner (mutable) class, which is retrieved
    by references via the getter, could then be modified and propagate the change
    inside the containing class. The way to close such holes is to generate new objects
    during the composition of the object retrieval. Here is an example of this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In our examples, we used very simple code. If more complexity is added to any
    of the methods, especially with parameters (and especially when some of the parameters
    are objects), it is possible you''ll get concurrency issues again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Even if this method belongs to `ImmutableClass` and does not affect the state
    of the `ImmutableClass` object, it is still a subject of the thread's race and
    has to be analyzed and protected as needed.
  prefs: []
  type: TYPE_NORMAL
- en: The `Collections` class has methods that make various collections unmodifiable.
    It means that the modification of the collection itself becomes read only, not
    the collection members.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Refer to the following recipes in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Using concurrent collections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the executor service to execute async tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using fork/join to implement divide-and-conquer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using flow to implement the publish-subscribe pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using concurrent collections
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn about the thread-safe collections of the `java.util.concurrent` package.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A collection can be synchronized if you apply one of the `Collections.synchronizeXYZ()` methods
    to it; here, we have used XYZ as a placeholder that represents either `Set`, `List`,
    `Map`, or one of the several collection types (see the API of the `Collections`
    class). We have already mentioned that the synchronization applies to the collection
    itself, not to its iterator or the collection members.
  prefs: []
  type: TYPE_NORMAL
- en: Such synchronized collections are also called **wrappers** because all of the
    functionality is still provided by the collections passed as parameters to the `Collections.synchronizeXYZ()` methods,
    so the wrappers provide only thread-safe access to them. The same effect could
    be achieved by acquiring a lock on the original collection. Obviously, such a
    synchronization incurs a performance overhead in a multithreading environment causing
    each thread to wait for its turn to access the collection.
  prefs: []
  type: TYPE_NORMAL
- en: A well-tuned application for performance implementation of thread-safe collections
    is provided by the `java.util.concurrent` package.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Each of the concurrent collections of the `java.util.concurrent` package implements
    (or extends, if it is an interface) one of the four interfaces of the `java.util`
    package: `List`, `Set`, `Map`, or `Queue`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `List` interface has only one implementation: the `CopyOnWriteArrayList` class.
    According to the Javadoc of this class, *all mutative operations (add, set, and
    so on) are implemented by making a fresh copy of the underlying array.... The
    "snapshot" style iterator method uses a reference to the state of the array at
    the point that the iterator was created. This array never changes during the lifetime
    of the iterator, so interference is impossible and the iterator is guaranteed
    not to throw ConcurrentModificationException. The iterator will not reflect additions,
    removals, or changes to the list since the iterator was created. Element-changing
    operations on iterators themselves (remove, set, and add) are not supported. These
    methods throw UnsupportedOperationException.* To demonstrate the behavior of the `CopyOnWriteArrayList` class,
    let''s compare it with `java.util.ArrayList` (which is not a thread-safe implementation
    of `List`). Here is the method that adds an element to the list while iterating
    on the same list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'If we execute this code, the result would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9d3be92f-49be-46b4-82f2-572566dfa397.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, `ArrayList` throws `ConcurrentModificationException` when the
    list is modified while being iterated (we used the same thread for simplicity
    and because it leads to the same effect, as in the case of another thread modifying
    the list). The specification, though, does not guarantee that the exception will
    be thrown or the list modification applied (as in in our case), so a programmer
    should not base the application logic on such behavior. The `CopyOnWriteArrayList` class,
    on the other hand, tolerates the same intervention; however, notice that it does
    not add a new element to the current list because the iterator was created from
    a snapshot of the fresh copy of the underlying array.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s try to remove a list element concurrently while traversing the list,
    using this method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'If we execute this, we will get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a6bf9320-f196-4fa3-b905-1b1d9e2c1608.png)'
  prefs: []
  type: TYPE_IMG
- en: The behavior is similar to the previous example. The `CopyOnWriteArrayList` class
    tolerates the concurrent access to the list but does not modify the current list's
    copy.
  prefs: []
  type: TYPE_NORMAL
- en: 'We knew `ArrayList` would not be thread-safe for a long time, so we used a
    different technique to remove an element from the list while traversing it. Here
    is how this was done before the Java 8 release:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s try this and run the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The result will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7617419e-7428-4f5d-a99c-784f45e87586.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is exactly what Javadoc warned about: "*Element-changing operations on
    iterators themselves (remove, set, and add) are not supported. These methods throw
    UnsupportedOperationException."* We should remember this when upgrading an application
    to make it work in a multithreaded environment: just changing from `ArrayList()`
    to `CopyOnWriteArrayList` would not be enough if we use an iterator to remove
    a list element.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since Java 8, we have a better way to remove an element from a collection using
    a lambda, which we can and should use from now on (leaving plumbing details to
    the library):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'So let''s do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6896d051-ab90-460b-a691-cb94a0459c97.png)'
  prefs: []
  type: TYPE_IMG
- en: It is short and has no problem with any of the collections and in line with
    the general trend of having a stateless parallel computation that uses streams
    with lambdas and functional interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, after we upgrade an application to use the `CopyOnWriteArrayList` class, we
    can take advantage of a simpler way of adding a new element to the list (without
    first checking whether it is already there):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'With `CopyOnWriteArrayList`, this can be done as an atomic operation, so one
    does not need to synchronize this block of code: if-not-present-then-add.'
  prefs: []
  type: TYPE_NORMAL
- en: Now let's review the concurrent collections of the `java.util.concurrent` package
    implementing the `Set` interface. There are three such implementations: `ConcurrentHashMap.KeySetView`,
    `CopyOnWriteArraySet` , and `ConcurrentSkipListSet`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The first one is just a view of the keys of `ConcurrentHashMap`. It is backed
    up by `ConcurrentHashMap` (can be retrieved by the `getMap()` method). We will
    review the behavior of  `ConcurrentHashMap` later.
  prefs: []
  type: TYPE_NORMAL
- en: The second implementation of `Set` in the `java.util.concurrent` package is
    the `CopyOnWriteArraySet` class. Its behavior is similar to the `CopyOnWriteArrayList` class.
    In fact, it uses the `CopyOnWriteArrayList` class's implementation under the hood.
    The only difference is that it does not allow duplicate elements in the collection.
  prefs: []
  type: TYPE_NORMAL
- en: 'The third (and the last) implementation of `Set` in the `java.util.concurrent` package
    is `ConcurrentSkipListSet`; it implements a subinterface of `Set` called `NavigableSet`.
    According to the Javadoc of the `ConcurrentSkipListSet` class, insertion, removal,
    and access operations are safely executed concurrently by multiple threads*.* There
    are some limitations described in Javadoc too:'
  prefs: []
  type: TYPE_NORMAL
- en: It does not permit the use of `null` elements.
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: The size of the set is calculated dynamically by traversing the collection,
    so it may report inaccurate results if this collection is modified during the
    operation.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The operations `addAll()`, `removeIf()`, or `forEach()` are not guaranteed to
    be performed atomically. The `forEach()` operation, if concurrent with an `addAll()`
    operation for example, *might observe only some of the added elements* (as stated
    in the Javadoc).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The implementation of class  `ConcurrentSkipListSet` is based on the `ConcurrentSkipListMap` class,
    which we will discuss shortly. To demonstrate the behavior of the `ConcurrentSkipListSet` class,
    let''s compare it with the `java.util.TreeSet` class (non-concurrent implementation
    of `NavigableSet`). We start with removing an element:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, this code is not very efficient; we''ve removed the same element
    many times without checking its presence. We have done this just for demo purposes.
    Besides, since Java 8, the same method `removeIf()` works for `Set` just fine.
    But we would like to bring up the behavior of the new class `ConcurrentSkipListSet`, so
    let''s execute this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ce19ea45-db92-4768-807c-1da31f1a4669.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As expected, the `ConcurrentSkipListSet` class handles the concurrency and
    even removes an element from the current set, which is helpful. It also removes
    an element via an iterator without an exception. Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Run this for `TreeSet` and  `ConcurrentSkipListSet`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll not get any exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1f1522f2-e50d-4343-9240-286bf57739fa.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is because, according to the Javadoc, the iterator of `ConcurrentSkipListSet`
    is weakly consistent, which means the following (according to Javadoc):'
  prefs: []
  type: TYPE_NORMAL
- en: They may proceed concurrently with other operations
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: They will never throw `ConcurrentModificationException`
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: They are guaranteed to traverse elements as they existed upon construction exactly
    once, and may (but are not guaranteed to) reflect any modifications subsequent
    to construction (from Javadoc).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This not guaranteed part is somewhat disappointing, but it is better than getting
    an exception, like with `CopyOnWriteArrayList`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding to a `Set` class is not as problematic as to a `List` class because
    `Set` does not allow duplicates and handles the necessary checks internally:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run this, we''ll get the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f66129c3-7a84-4265-ac8b-72b758f97cee.png)'
  prefs: []
  type: TYPE_IMG
- en: As before, we observe that the concurrent `Set` version handles concurrency
    better.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we turn to the `Map` interface that has two implementations in the java.util.concurrent package:
    `ConcurrentHashMap` and `ConcurrentSkipListMap`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `ConcurrentHashMap` class *supports full concurrency of retrievals and high
    concurrency for updates* (from Javadoc). It is a thread-safe version of `java.util.HashMap`
    and is analogous to `java.util.Hashtable` in this respect. In fact, the `ConcurrentHashMap` class meets
    the requirements of the same functional specification as `java.util.Hashtable`,
    although its implementation is *somewhat different in synchronization details *(from
    Javadoc).
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike `java.util.HashMap` and `java.util.Hashtable`, `ConcurrentHashMap` supports,
    according its JavaDoc, *a set of sequential and parallel bulk operations that,
    unlike most Stream methods, are designed to be safely, and often sensibly, applied
    even with maps that are being concurrently updated by other threads*:'
  prefs: []
  type: TYPE_NORMAL
- en: '`forEach()`: This performs a given action on each element'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '`search()`: This returns the first available non-null result of applying a
    given function to each element'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reduce()`: This accumulates each element (there are five overloaded versions)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: These bulk operations accept a `parallelismThreshold` argument that allows deferring
    parallelization until the map size reaches the specified threshold. Naturally,
    when the threshold is set to `Long.MAX_VALUE`, there will be no parallelism whatsoever.
  prefs: []
  type: TYPE_NORMAL
- en: There are many other methods in the class API, so refer to its Javadoc for an
    overview.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike `java.util.HashMap` (and similar to `java.util.Hashtable`), neither `ConcurrentHashMap` nor
    `ConcurrentSkipListMap` allow null to be used as a key or value.
  prefs: []
  type: TYPE_NORMAL
- en: The second implementation of `Map`--the `ConcurrentSkipListSet` class--is based,
    as we mentioned before, on the `ConcurrentSkipListMap` class, so all the limitations of
    the `ConcurrentSkipListSet` class we just described apply to the `ConcurrentSkipListMap` class
    too. The `ConcurrentSkipListSet` class is practically a thread-safe version of
    `java.util.TreeMap`. `SkipList` is a sorted data structure that allows fast search
    concurrently. All the elements are sorted based on their natural sorting order
    of keys. The `NavigableSet` functionality we demonstrated for the `ConcurrentSkipListSet` class is
    present in the `ConcurrentSkipListMap` class too. For many other methods in the
    class API, refer to its Javadoc.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s demonstrate the difference in the behavior in response to concurrency
    between the `java.util.HashMap`, `ConcurrentHashMap`, and `ConcurrentSkipListMap` classes.
    First, we will write the method that generates a test `Map` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the code that adds an element to a `Map` object concurrently:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Run this for all three implementations of `Map`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'If we do this, we get an output for `HashMap` for the first key only:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d1868213-4bf8-4a75-bf12-b337f0f42c05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We also get an output for `ConcurrentHashMap` and `ConcurrentSkipListMap` for
    all the keys, including the newly added ones. Here is the last section of the `ConcurrentHashMap` output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3add6164-1a06-46e4-8a2c-f158894894bc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As mentioned already, the appearance of `ConcurrentModificationException` is
    not guaranteed. Now we see that the moment it is thrown (if at all) is the moment
    when the code discovers that the modification has taken place. In the case of
    our example, it happened on the next iteration. Another point worth noticing is
    that the current set of keys changes even as we sort of isolate the set in a separate
    variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This reminds us not to dismiss the changes propagated through the objects via
    their references.
  prefs: []
  type: TYPE_NORMAL
- en: 'To save the book space and your time, we will not show the code for concurrent
    removal and just summarize the results. As expected, `HashMap` throws exception `ConcurrentModificationException`
    when an element is removed in any of the following ways. Here''s the first way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the second way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'It allows concurrent removal via `Iterator` in two ways. Here''s the first
    way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'And here is the second way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s the third way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: By contrast, the two concurrent `Map` implementations allow any of the above
    ways of removal concurrently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar behavior is also exhibited by all the concurrent implementations of
    the `Queue` interface: `LinkedTransferQueue`, `LinkedBlockingQueue`, `LinkedBlockingDequeue`,
    `ArrayBlockingQueue`, `PriorityBlockingQueue`, `DelayQueue`, `SynchronousQueue`,
    `ConcurrentLinkedQueue`, and `ConcurrentLinkedDequeue`, all in the `java.util.concurrent`
    package. But to demonstrate all of them would require a separate volume, so we
    leave it up to you to browse the Javadoc and provide an example of `ArrayBlockingQueue`
    only. The queue will be represented by the `QueueElement` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The queue producer will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The following will be the queue consumer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Its results may look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/774a9db0-6d17-4aa2-b1fd-174c3f946db3.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we select which collections to use, read the Javadoc and see whether
    the limitations of the collection are acceptable for your application.
  prefs: []
  type: TYPE_NORMAL
- en: For example, as per the Javadoc, the `CopyOnWriteArrayList` class *is ordinarily
    too costly, but may be more efficient than alternatives when traversal operations
    vastly outnumber mutations, and is useful when you cannot or don't want to synchronize
    traversals, yet need to preclude interference among concurrent threads.* Use it
    when you do not need to add new elements at different positions and do not require
    sorting. Otherwise, use `ConcurrentSkipListSet`.
  prefs: []
  type: TYPE_NORMAL
- en: The `ConcurrentSkipListSet` and `ConcurrentSkipListMap` classes, as per the
    Javadoc, *provide expected average log(n) time cost for the contains, add, and
    remove operations and their variants.* *Ascending ordered views and their iterators
    are faster than descending ones.* Use them when you need to iterate quickly through
    the elements in a certain order and prefer sorting by default.
  prefs: []
  type: TYPE_NORMAL
- en: Use `ConcurrentHashMap` when the concurrency requirements are very demanding
    and you need to allow locking on the write operation but do not need to lock the
    element.
  prefs: []
  type: TYPE_NORMAL
- en: '`ConcurrentLinkedQueque` and `ConcurrentLinkedDeque` are an appropriate choice
    when many threads share access to a common collection. `ConcurrentLinkedQueque`
    employs an efficient non-blocking algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: '`PriorityBlockingQueue` is a better choice when natural order is acceptable
    and you need fast adding of elements to the tail and fast removing of elements
    from the head of the queue. Blocking means that the queue waits to become non-empty
    when retrieving an element and waits for space to become available in the queue
    when storing an element.'
  prefs: []
  type: TYPE_NORMAL
- en: '`ArrayBlockingQueue`, `LinkedBlockingQueue`, and `LinkedBlockingDeque` have
    a fixed size (bounded). The other queues are unbounded.'
  prefs: []
  type: TYPE_NORMAL
- en: Use these and similar characteristics and recommendations as the guidelines
    but execute comprehensive testing and performance measuring before and after implementing
    your functionality.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Refer to the following recipes in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the executor service to execute async tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using fork/join to implement divide-and-conquer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using flow to implement the publish-subscribe pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the executor service to execute async tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to use `ExecutorService` to implement controllable
    thread execution.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In an earlier recipe, we demonstrated how to create and execute threads using
    the `Thread` class directly. It is an acceptable mechanism for a small number
    of threads that run and produce results predictably quickly. For big-scale applications
    with longer running threads with complex logic (which might keep them alive for
    an unpredictably long time) and/or a number of threads growing unpredictably too,
    a simple create-and-run-until-exit approach might result in an `OutOfMemory` error
    or require a complex customized system of threads' status maintenance and management.
    For such cases, `ExecutorService` and related classes of the `java.util.concurrent`
    package provide an out-of-the-box solution that relieves a programmer of the need
    to write and maintain a lot of infrastructural code.
  prefs: []
  type: TYPE_NORMAL
- en: At the foundation of the Executor Framework lies an `Executor` interface that
    has only one `void execute(Runnable command)` method that executes the given command
    at some time in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'Its subinterface `ExecutorService` adds methods that allow you to manage the
    executor:'
  prefs: []
  type: TYPE_NORMAL
- en: The `invokeAny()`, `invokeAll()`, and `awaitTermination()` methods and `submit()` allow
    you to define how the threads will be executed and if they are expected to return
    some values or not
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `shutdown()` and `shutdownNow()` methods allow you to shut down the executor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `isShutdown()` and `isTerminated()` methods provide the status of the executor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The objects of `ExecutorService` can be created with the static factory methods
    of the `java.util.concurrent.Executors` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '`newSingleThreadExecutor()` - This creates an `Executor` method that uses a
    single worker thread operating off an unbounded queue. It has an overloaded version
    with `ThreadFactory` as a parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`newCachedThreadPool()` - This creates a thread pool that creates new threads
    as needed, but reuses previously constructed threads when they are available. It
    has an overloaded version with `ThreadFactory` as a parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`newFixedThreadPool(int nThreads)` - This creates a thread pool that reuses
    a fixed number of threads operating off a shared unbounded queue. It has an overloaded
    version with `ThreadFactory` as a parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `ThreadFactory` implementation allows you to override the process of creating
    new threads, enabling applications to use special thread subclasses, priorities,
    and so on. A demonstration of its usage is outside the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One important aspect of the behavior of the `Executor` interface you need to
    remember is that once created, it keeps running (waiting for new tasks to execute)
    until the Java process is stopped. So, if you would like to free memory, the `Executor` interface
    has to be stopped explicitly. If not shut down, forgotten executors will create
    a memory leak. Here is one possible way to make sure no executor is left behind:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'You can pass a worker (an implementation of either the `Runnable` or `Callable` functional
    interface) for execution to `ExecutorService` in a variety of ways, which we will
    see shortly. In this example, we executed two threads: one using the `execute()`
    method and another using the `submit()` method. Both methods accept `Runnable`
    or `Callable`, but we used only `Runnable` in this example. The `submit()` method returns
    `Future`, which represents the result of an asynchronous computation.'
  prefs: []
  type: TYPE_NORMAL
- en: The `shutdown()` method initiates an orderly shutdown of the previously submitted
    tasks and prevents any new task from being accepted. This method does not wait
    for the task to complete the execution. The `awaitTermination()` method does that.
    But after `shutdownDelaySec`, it stops blocking and the code flow gets into `finally`
    block, where the `isTerminated()` method returns `true` if all the tasks are completed
    following the shutdown. In this example, we have two tasks executed in two different
    statements, but note that other methods of `ExecutorService` accept a collection
    of tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In such a case, when the service is shutting down, we iterate over the collection
    of `Future` objects. We call each task and cancel it if it is not completed yet,
    possibly doing something else that had to be done before canceling the task. How
    much time to wait (value of `shutdownDelaySec`) has to be tested for each application
    and the possible running tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the `shutdownNow()` method says this: *attempts to stop all actively
    executing tasks, halts the processing of waiting tasks, and returns a list of
    the tasks that were awaiting execution* (according to the Javadoc).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can collect and assess the results. In a real application, we typically
    do not want to shut down a service often. We just check the status of the tasks
    and collect results of those that return true from the `isDone()` method. In the
    above code example, we just show how to make sure that when we do stop the service,
    we do it in a controlled manner, without leaving behind any runaway process. If
    we run that code example, we will get the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c6dd14bc-8a2a-4216-933b-efdb49cacd86.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Generalize the preceding code and create a method that shuts down a service
    and the task that has returned `Future`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Enhance the example by making the `Runnable` (using lambda expression) sleep
    for some time (simulating useful work to be done):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Notice the two parameters: `shutdownDelaySec` (that defines how long the service
    will wait without allowing new tasks to be submitted before moving on and shutting
    itself down, eventually) and `threadSleepSec` (that defines how long the worker
    is sleeping, indicating that the simulating process is doing its job).
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the new code for different implementations of `ExecutorService` and values
    of `shutdownDelaySec` and `threadSleepSec`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'This is how the output may look like (it might be slightly different on your
    computer, depending on the exact timing of the events controlled by the operating
    system):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/72c92273-0613-457e-ac41-ee268941a01e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Analyze the results. In the first example, we find no surprise because of the
    following line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: It is blocking for three seconds, whereas each worker works for one second only.
    So it is enough time for each worker to complete its work even for a single-thread
    executor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s make the service wait for one second only:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fe87a199-b14e-47ba-9aeb-912d3429af43.png)'
  prefs: []
  type: TYPE_IMG
- en: When you do this, you will notice that none of the tasks will be completed.
    In this case, worker `One` was interrupted (see the last line of the output),
    while task `Two` was canceled.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s make the service wait for three seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a1106c9b-f169-4c22-858b-ec93a86baad1.png)'
  prefs: []
  type: TYPE_IMG
- en: Now we see that worker `One` was able to complete its task, while worker `Two`
    was interrupted.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ExecutorService` interface produced by `newCachedThreadPool()` or `newFixedThreadPool()`
    performs similarly on a one-core computer. The only significant difference is
    that if the `shutdownDelaySec` value is equal to the `threadSleepSec` value, then
    they both allow you to complete the threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4d7286f3-51a5-494d-a668-8e30fc334dac.png)'
  prefs: []
  type: TYPE_IMG
- en: This was the result of using `newCachedThreadPool()`. The output of the example
    using `newFixedThreadPool()` looks exactly the same on a one-core computer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `Future` object as a returned value when you need more control over
    the task, not just submit one and wait. There is another method called `submit()`
    in the `ExecutorService` interface that allows you to not only return a `Future`
    object, but also include the result that is passed to the method as a second parameter
    in the return object. Let''s check out an example of this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The value of `result` is `42`. This method can be helpful when you have submitted
    many workers (`nWorkers`) and need to know which one is completed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Well, the catch is that `future.get()` is a blocking method. This is why we
    use a version of the `get()` method that allows us to set the `delaySec` timeout.
    Otherwise, `get()` blocks the iteration.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s move a step closer to real-life code and create a class that implements
    `Callable` and allows you to return a result from a worker as an object of the `Result` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: An actual numeric result is returned by the `getResult()` method. Here we also
    included the name of the worker and how long the thread is expected to sleep (to
    work) just for convenience and to better illustrate the output.
  prefs: []
  type: TYPE_NORMAL
- en: 'The worker itself is going to be an instance of the `CallableWorkerImpl` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the number `42` is an actual numeric result, which a worker supposedly
    calculated (while sleeping). The class  `CallableWorkerImpl` implemented interface `CallableWorker` :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: We had to make the methods default and return some data (they will be overridden
    by the class implementation anyway) to preserve its `functional interface` status.
    Otherwise, we would not be able to use it in lambda expressions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will also create a factory that will generate a list of workers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can use all these new classes and methods to demonstrate the `invokeAll()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The `printResults()` method outputs the results received from the workers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'To get the results, again we use a version of the `get()` method with timeout
    settings. Run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Its output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/be8e4318-8490-4fd0-8660-970c74b8dd60.png)'
  prefs: []
  type: TYPE_IMG
- en: It's probably worth reminding that the three workers were created with sleep
    time 1, 2, and 3 seconds correspondingly, while the waiting time before the service
    shuts down is one second. This is why all the workers were canceled.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now if we set the waiting time to six seconds, the output of the single-thread
    executor will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f39a119a-87b0-47ec-a95f-fac460d3e347.png)'
  prefs: []
  type: TYPE_IMG
- en: Naturally, if we increase the waiting time again, all the workers would be able
    to complete their tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ExecutorService` interface produced by `newCachedThreadPool()` or `newFixedThreadPool()`
    performs much better even on a one-core computer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ed6d36e5-fbdc-439c-8d77-ba7cbc5d60ce.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, all the threads were able to complete even with three seconds
    of waiting time.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an alternative, instead of setting a timeout during the service shutdown,
    you can possibly set it on the overloaded version of the `invokeAll()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'There is one particular aspect of the `invokeAll()` method''s behavior that
    often gets overlooked and causes surprises for first-time users: it returns only
    after all the tasks are complete (either normally or by throwing an exception). Read
    the Javadoc and experiment until you recognize that this behavior is acceptable
    for your application.'
  prefs: []
  type: TYPE_NORMAL
- en: 'By contrast, the `invokeAny()` method blocks only until at least one task is
    *completed successfully (without throwing an exception), if any do. Upon normal
    or exceptional return, tasks that have not completed are canceled* (according to
    Javadoc). Here is an example of the code that does this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: You can experiment with it, setting different values for the waiting time (`shutdownDelaySec`)
    and sleep time for threads until you are comfortable with how this method behaves.
    As you can see, we have reused the `shutdownAndCancelTasks()` method by passing
    an empty list of `Future` objects since we do not have them in this case.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two more static factory methods in the `Executors` class that create
    instances of `ExecutorService`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`newWorkStealingPool()`: This creates a work-stealing thread pool using the
    number of available processors as its target parallelism level. It has an overloaded
    version with a parallelism level as a parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unconfigurableExecutorService(ExecutorService executor)`: This returns an
    object that delegates all the defined `ExecutorService` methods to the given executor,
    except for those methods that might otherwise be accessible using casts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, a subinterface of the `ExecutorService` interface, called `ScheduledExecutorService`,
    enhances the API with the capability to schedule a thread execution in future
    and/or their periodic execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The objects of `ScheduledExecutorService` can be created using the static factory
    methods of the `java.util.concurrent.Executors` class too:'
  prefs: []
  type: TYPE_NORMAL
- en: '`newSingleThreadScheduledExecutor()`: This creates a single-threaded executor
    that can schedule commands to run after a given delay or to execute them periodically.
    It has an overloaded version with `ThreadFactory` as a parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`newScheduledThreadPool(int corePoolSize)`: This creates a thread pool that
    can schedule commands to run after a given delay or to execute them periodically.
    It has an overloaded version with `ThreadFactory` as a parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unconfigurableScheduledExecutorService( ScheduledExecutorService executor
    )`: This returns an object that delegates all the defined `ScheduledExecutorService`
    methods to the given executor, but not any other methods that might otherwise
    be accessible using casts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Executors` class also has several overloaded methods that accept, execute,
    and return `Callable` (which, by contrast with `Runnable`, contains the result).
  prefs: []
  type: TYPE_NORMAL
- en: 'The `java.util.concurrent` package also includes classes that implement `ExecutorService`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The ThreadPoolExecutor class**: This executes each submitted task using one
    of the several pooled threads, normally configured using the `Executors` factory
    methods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The ScheduledThreadPoolExecutor**** class**: This extends the `ThreadPoolExecutor`
    class and implements the `ScheduledExecutorService` interface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The ForkJoinPool class**: This manages the execution of workers (`ForkJoinTask`
    processes) using a work-stealing algorithm. We will discuss it in the next recipe.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instances of these classes can be created via class constructors that accept
    more parameters, including the queue that holds the results, for providing more
    refined thread pool management.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Refer to the following recipes in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Using fork/join to implement divide-and-conquer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using flow to implement the publish-subscribe pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using fork/join to implement divide-and-conquer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to use the fork/join framework for the divide-and-conquer
    computation pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned in the previous recipe, the `ForkJoinPool` class is an implementation
    of the `ExecutorService` interface that manages the execution of workers--`ForkJoinTask`
    processes--using the work-stealing algorithm. It takes advantage of multiple processors,
    if available, and works best on tasks that can be broken down into smaller tasks
    recursively, which is also called a *divide-and-conquer* strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Each thread in the pool has a dedicated double-ended queue (deque) that stores
    tasks, and the thread picks up the next task (from the head of the queue) as soon
    as the current task is completed. When another thread finishes executing all the
    tasks in its queue, it can take a task (steal it) from the tail of a non-empty
    queue of another thread.
  prefs: []
  type: TYPE_NORMAL
- en: As with any `ExecutorService` implementation, the fork/join framework distributes
    tasks to worker threads in a thread pool. This framework is distinct because it
    uses a work-stealing algorithm. Worker threads that run out of tasks can steal
    tasks from other threads that are still busy.
  prefs: []
  type: TYPE_NORMAL
- en: Such a design balances the load and allows an efficient use of the resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'For demonstration purposes, we are going to use the API created in [Chapter
    3](488da544-ff73-4ef7-9d57-00b67479defd.xhtml), *Modular Programming*: the `TrafficUnit`,
    `SpeedModel`, and `Vehicle` interfaces and the `TrafficUnitWrapper`, `FactoryTraffic`,
    `FactoryVehicle`, and `FactorySpeedModel` classes. We will also rely on the streams
    and stream pipelines described in [Chapter 3](488da544-ff73-4ef7-9d57-00b67479defd.xhtml),
    *Modular Programming*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Just to refresh your memory, here is the `TrafficUnitWrapper` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also slightly modify the existing API interface and make it a bit more
    compact by introducing a new `DateLocation` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: It will also allow you to hide the details and help you see the important aspects
    of this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All computations are encapsulated inside a subclass of one of the two subclasses
    (`RecursiveAction` or `RecursiveTask<T>`) of the abstract `ForkJoinTask` class.
    You can extend either `RecursiveAction` (and implement the `void compute()` method)
    or `RecursiveTask<T>` (and implement the `T compute()` method). As you may have
    probably noticed, you can choose to extend the `RecursiveAction` class for tasks
    that do not return any value, and extend `RecursiveTask<T>` when you need your
    tasks to return a value. In our demo, we are going to use the latter because it
    is slightly more complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say we would like to calculate the average speed of traffic in a certain
    location on a certain date and time and driving conditions (all these parameters
    are defined by the property `DateLocation` object). Other parameters will be as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`timeSec`: The number of seconds during which the vehicles have a chance to
    accelerate after stopping at the traffic light'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trafficUnitsNumber`: The number of vehicles to include in the average speed
    calculation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Naturally, the more vehicles included in the calculations, the better the prediction.
    But as this number increases, the number of calculations increases too. This gives
    rise to the need to break down the number of vehicles into smaller groups and
    compute the average speed of each group in parallel with the others. Yet, there
    is a certain minimal number of calculations that is not worth splitting between
    two threads. Here''s what Javadoc has to say about it: *As a very rough rule of
    thumb, a task should perform more than 100 and less than 10000 basic computational
    steps, and should avoid indefinite looping. If tasks are too big, then parallelism
    cannot improve throughput. If too small, then memory and internal task maintenance
    overhead may overwhelm processing.* Yet, as always, the final answer about the
    best minimal number of calculations without splitting will come from testing.
    This is why we recommend to pass it as a parameter. We will call this parameter
    `threshold`. Notice that it also serves as a criterium for exiting from the recursion.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will call our class (task) `AverageSpeed` and extend `RecursiveTask<Double>`
    because we would like to have as a result of the average speed value of the `double`
    type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we finish writing the code for the `compute()` method, let''s write
    the code that will execute this task. There are several ways to do this. We can
    use `fork()` and `join()`, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: This technique provided the name for the framework. The `fork()` method, according
    to Javadoc, a*rranges to asynchronously execute this task in the pool the current
    task is running in, if applicable, or using the ForkJoinPool.commonPool() if not
    in ForkJoinPool().* In our case, we did not use any pool yet, so `fork()` is going
    to use `ForkJoinPool.commonPool()` by default. It places the task in the queue
    of a thread in the pool. The `join()` method returns the result of the computation
    when it is done.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `createTask()` method contains the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: Notice the values of the `trafficUnitsNumber` and `threshold` parameters. This
    will be important for analyzing the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way to accomplish this is to use either the `execute()` or `submit()` method--each
    providing the same functionality--for the execution of the task. The result of
    the execution can be retrieved by the `join()` method (the same as in the previous
    example):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'The last method we are going to review is `invoke()`, which is equivalent to
    calling the `fork()` method followed by the `join()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: Naturally, this is the most popular way to start the divide-and-conquer process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s get back to the `compute()` method and see how it can be implemented.
    First, let''s implement the `if` block (that calculates the average speed of less
    than `threshold` vehicles). We will use the technique and code we described in
    [Chapter 3](488da544-ff73-4ef7-9d57-00b67479defd.xhtml), *Modular Programming*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: We get the `trafficUnitsNumber` of the vehicles from `FactoryTraffic`, and we
    create an object of `TrafficUnitWrapper` for each emitted element and call the `setSpeedModel()`
    method on it (by passing in the newly generated `SpeedModel` object, based on
    the emitted `TrafficUnit` object). Then we calculate the speed, get an average
    of all the speeds in the stream, and get the result as `double` from the `Optional`
    object (the return type of the `average()` operation). We then print out the result
    and round to get a more presentable format.
  prefs: []
  type: TYPE_NORMAL
- en: It is also possible to achieve the same result using a traditional `for` loop.
    But, as mentioned before, it seems that Java follows the general trend of more
    fluent and stream-like style, geared towards processing a large amount of data.
    So, we recommend you get used to it.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 15](823213ae-b820-450c-abb8-8a98a70caf70.xhtml), *Testing*, you
    will see another version of the same functionality that allows better unit testing
    of each step in isolation, which again supports the view that unit testing, along
    with writing code, helps you make your code more testable and decreases the need
    for rewriting it later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s review the options of the `else` block implementation. The first
    few lines are always going to be the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: We divide the `trafficUnitsNumber` number by two (we do not worry about possible
    loss of one unit in the case of an average across a big set) and create two tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following--the actual task execution code--can be written in several different
    ways. Here is the first possible solution, which is familiar to us already, that
    comes to mind:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'If we do this, we will see the same output (but with different speed values)
    three times:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c694c38c-ce64-4682-baa3-7b2b12c613d6.png)'
  prefs: []
  type: TYPE_IMG
- en: You see how the original task of calculating average speed over 1,001 units
    (vehicles) was first divided by two several times until the number of one group
    (62) fell under the threshold of 100\. Then, an average speed of the last two
    groups was calculated and combined (joined) with the results of other groups.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way to implement an `else` block of the `compute()` method could be
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s how the result will look:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4df2d4d0-0ef5-47a3-9838-ae440af6c6e9.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see how, in this case, the `compute()` method (of the second task) was
    called recursively many times until it reached the threshold by the number of
    elements, then its results were joined with the results of the call to the `fork()`
    and `join()` methods of the first task.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned before, all this complexity can be replaced by a call to the `invoke()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'It produces a result similar to the one produced by calling `fork()` and `join()`
    on each of the tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f9ffedad-2fd0-431f-9624-e4de7fec800b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Yet, there is an even better way to implement an `else` block of the `compute()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'If this looks complex to you, just notice that it is just a stream-like way
    to iterate over the results of `invokeAll()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'It is also to iterate over the results of calling `join()` on each of the returned
    tasks (and combining the results into average). The advantage is that we yield
    to the framework to decide how to optimize the load distribution. The result is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e65ae659-3593-4eb7-a719-f536471c7d09.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see it differs from any of the preceding results and can change depending
    on the availability and load of the CPUs on your computer.
  prefs: []
  type: TYPE_NORMAL
- en: Using flow to implement the publish-subscribe pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn about the new publish-subscribe capability introduced
    in Java 9.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Among many other features, Java 9 introduced these four interfaces in the `java.util.concurrent.Flow` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: With this, Java stepped into the world of reactive programming--programming
    with the asynchronous processing of data streams.
  prefs: []
  type: TYPE_NORMAL
- en: We discussed streams in [Chapter 3](488da544-ff73-4ef7-9d57-00b67479defd.xhtml),
    *Modular Programming* and pointed out that they are not data structures, as they
    do not keep data in memory. The stream pipeline does nothing until an element
    is emitted. Such a model allows minimal resource allocation and uses resources
    only as needed. The application behaves *in response* to the appearance of the
    data it reacts to, thus the name.
  prefs: []
  type: TYPE_NORMAL
- en: In a publish-subscribe pattern, the main two actors are a `Publisher` and a
    `Subscriber`. `Publisher` streams data (publishes), and `Subscriber` listens to
    data (subscribes).
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Flow.Publisher<T>` interface is a functional interface. It only has one
    abstract method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: According to the Javadoc, this method *adds the given Flow.Subscriber<T> if
    possible. If already subscribed, or the attempt to subscribe fails, the onError()
    method of theFlow.Subscriber<T> is invoked with an IllegalStateException. Otherwise,
    the onSubscribe() method of theFlow.Subscriber<T> is invoked with a new Flow.Subscription.
    Subscribers may enable receiving items by invoking the request() method of thisFlow.Subscription
    and may unsubscribe by invoking its cancel() method.*
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Flow.Subscriber<T>` interface has four methods; some of them were mentioned
    just now:'
  prefs: []
  type: TYPE_NORMAL
- en: '`void onSubscribe(Flow.Subscription subscription)` is invoked prior to invoking
    any other `Subscriber` methods for the given `Subscription`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void onError(Throwable throwable)` is invoked upon an unrecoverable error
    encountered by a `Publisher` or `Subscription`, after which no other `Subscriber`
    methods are invoked by the `Subscription`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void onNext(T item)` is invoked with the `Subscription`''s next item'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void onComplete()`: This method is invoked when it is known that no additional
    `Subscriber` method invocations will occur for a `Subscription`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `Flow.Subscription` interface has two methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`void cancel()`: This method causes the `Subscriber` to (eventually) stop receiving
    messages'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void request(long n)`: This method adds the given n number of items to the
    current unfulfilled demand for this subscription'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Flow.Processor<T,R>` interface is outside the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To save some time and space, instead of creating our own implementation of
    the `Flow.Publisher<T>` interface, we can use the `SubmissionPublisher<T>` class from
    the `java.util.concurrent` package. But, we will create our own implementation
    of the `Flow.Subscriber<T>` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also implement the `Flow.Subscription` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we just followed Javadoc recommendations and expect the `onSubscribe()`
    method of a subscriber to be called when the subscriber is added to a publisher.
  prefs: []
  type: TYPE_NORMAL
- en: Another detail to notice is that the `SubmissionPublisher<T>` class has the `submit(T
    item)` method that, according to Javadoc, *publishes the given item to each current
    subscriber by asynchronously invoking its onNext() method, blocking uninterruptibly
    while resources for any subscriber are unavailable*. This way, the `SubmissionPublisher<T>`
    class submits items to the current subscribers until it is closed. This allows
    item generators to act as reactive-streams publishers.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate this, let''s create several subscribers and subscriptions using
    the `demoSubscribe()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'Then use them in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code creates three subscribers, connected to the same publisher
    with a dedicated subscription. The last line generates a stream of numbers 1,
    2, 3, and 4 and submits each of them to the publisher. We expect that every subscriber
    will get each of the generated numbers as the parameter of the `onNext()` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `finally` block, we included the code you are already familiar with
    from the previous recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run the preceding code, the output may look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/df995979-dce0-4fad-b7ea-95cbbf1ecab3.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, because of asynchronous processing, the control gets to the
    `finally` block very quickly and waits for 1 sec before shutting down the service.
    This period of waiting is enough for the items to be generated and passed to the
    subscribers. We also confirmed that every generated item was sent to each of the
    subscribers. The three `null` values were generated every time the `onSubscribe()`
    method of each of the subscribers is called.
  prefs: []
  type: TYPE_NORMAL
- en: It is reasonable to expect that in future Java releases, there will be more
    support added for reactive (asynchronous and non-blocking) functionality.
  prefs: []
  type: TYPE_NORMAL
