<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Serialization</h1>
                </header>
            
            <article>
                
<p>In modern (internet) computing, we often forget that entities must be transmitted from one computer to another. In order to be able to transmit the entities, they must first be serialized.</p>
<p>Serialization is the process of transforming an object into a stream of bytes commonly used to transmit it from one computer to another.</p>
<p>Deserialization, as the name implies, is the opposite of serialization, that is, to convert a stream of bytes into an object (for didactic purposes, we can say that the object is inflated or rehydrated), normally from the side that receives the message. Kafka provides <strong>Serializer</strong>/<strong>Deserializer</strong> (<strong>SerDe</strong>) for the primitive data types (byte, integer, long, double, String, and so on).</p>
<p>In this chapter, a new company is introduced: Kioto (standing for Kafka Internet of Things). This chapter covers the following topics:</p>
<ul>
<li>How to build a Java <kbd>PlainProducer</kbd>, a consumer, and a processor</li>
<li>How to run a Java <kbd>PlainProducer</kbd> and a processor</li>
<li>How to build a custom serializer and a custom deserializer</li>
<li>How to build a Java <kbd>CustomProducer</kbd>, a consumer, and a processor</li>
<li>How to run a Java <kbd>CustomProducer</kbd> and a processor</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Kioto, a Kafka IoT company</h1>
                </header>
            
            <article>
                
<p><span>Kioto is a fictional company d</span><span>edicated to energy production and distribution. To operate, Kioto has several <strong>Internet of Things</strong> (<strong>IoT</strong>) devices.</span></p>
<p>Kioto also wants to build an enterprise service bus with Apache Kafka. Its goal is to manage all of the messages received by all of the machines' IoT sensors every minute. Kioto has hundreds of machines in several locations, sending thousands of different messages per minute to the enterprise service bus.</p>
<p class="mce-root"/>
<p>As mentioned, Kioto has a lot of IoT on its machines that continuously send status messages to a control center. These machines generate electricity, so it is very important for Kioto to know exactly the machines' uptime and their state (running, shutting down, shutdown, starting, and so on).</p>
<p>Kioto also needs to know the weather forecast, because some machines should not operate over certain temperatures. Some machines display different behavior based on the environmental temperature. It is different starting a machine in cold rather than in warm conditions, so the start up time is important when calculating the uptime. To warrant the continuous electricity supply, the information has to be precise. It is always better to face an electrical power failure having to start the machines from a warm temperature rather than from cold temperature.</p>
<p><em>Listing 4.1</em> shows the health check event in JSON format.</p>
<p>The following is the content of <em>Listing 4.1</em>,<em> </em><kbd>healthcheck.json</kbd><span>:</span> </p>
<pre>{<br/>   "event":"HEALTH_CHECK",<br/>   "factory":"Duckburg",<br/>   "serialNumber":"R2D2-C3P0",<br/>   "type":"GEOTHERMAL",<br/>   "status":"RUNNING",<br/>   "lastStartedAt":"2017-09-04T17:27:28.747+0000",<br/>   "temperature":31.5,<br/>   "ipAddress":"192.166.197.213"}<br/>}</pre>
<div class="CDPAlignCenter CDPAlign packt_figref"> Listing 4.1: healthcheck.json</div>
<p class="mce-root">The proposed representation of this message in JSON has the following properties:</p>
<ul>
<li><kbd>event</kbd>: The string with the message's type (in this case, <kbd>HEALTH_CHECK</kbd>)</li>
<li><kbd>factory</kbd>: The name of the city where the plant is physically located</li>
<li><kbd>serialNumber</kbd>: The machine's serial number</li>
<li><kbd>type</kbd>: Represents the machine's type, which could be <kbd>GEOTHERMAL</kbd>, <kbd>HYDROELECTRIC</kbd>, <kbd>NUCLEAR</kbd>, <kbd>WIND</kbd>, or <kbd>SOLAR</kbd></li>
<li><kbd>status</kbd>: The point on the life cycle: <kbd>RUNNING</kbd>, <kbd>SHUTTING-DOWN</kbd>, <kbd>SHUT-DOWN</kbd>, <kbd>STARTING</kbd></li>
<li><kbd>lastStartedAt</kbd>: The last start time</li>
<li><kbd>temperature</kbd>: A float representing the machine's temperature in degrees celsius </li>
<li><kbd>ipAddress</kbd>: The machine's IP address</li>
</ul>
<p>As we can see, JSON is a human-readable message format.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Project setup</h1>
                </header>
            
            <article>
                
<p>The first step is to create the Kioto project. Create a directory called <kbd>kioto</kbd>. Go to that directory and execute the following command:</p>
<pre><strong>$ gradle init --type java-library</strong></pre>
<p>The output is something like the following:</p>
<pre><strong>Starting a Gradle Daemon (subsequent builds will be faster)</strong><br/><strong>BUILD SUCCESSFUL in 3s</strong><br/><strong>2 actionable tasks: 2 execute BUILD SUCCESSFUL</strong></pre>
<p>Gradle creates a default project in the directory, including two Java files called <kbd>Library.java</kbd> and <kbd>LibraryTest.java</kbd>; delete both files.</p>
<p>Your directory should be similar to the following:</p>
<ul>
<li><kbd>- build.gradle</kbd></li>
<li><kbd>- gradle</kbd></li>
<li><kbd>-- wrapper</kbd></li>
<li><kbd>--- gradle-wrapper.jar</kbd></li>
<li><kbd>--- gradle-vreapper.properties</kbd></li>
<li><kbd>- gradlew</kbd></li>
<li><kbd>- gradle.bat</kbd></li>
<li><kbd>- settings.gradle</kbd></li>
<li><kbd>- src</kbd></li>
<li><kbd>-- main</kbd></li>
<li><kbd>--- java</kbd></li>
<li><kbd>----- Library.java</kbd></li>
<li><kbd>-- test</kbd></li>
<li><kbd>--- java</kbd></li>
<li><kbd>----- LibraryTest.java</kbd></li>
</ul>
<p><span>Modify the <kbd>build.gradle</kbd> file and replace it with <em>Listing 4.2</em>.</span></p>
<p class="mce-root"/>
<p>The following is the content of <em>Listing 4.2</em>, the Kioto Gradle build file:</p>
<pre>apply plugin: 'java'<br/>apply plugin: 'application'<br/>sourceCompatibility = '1.8'<br/>mainClassName = 'kioto.ProcessingEngine'<br/>repositories {<br/>    mavenCentral()<br/>    maven { url 'https://packages.confluent.io/maven/' }<br/>}<br/>version = '0.1.0'<br/>dependencies {<br/>    compile 'com.github.javafaker:javafaker:0.15'<br/>    compile 'com.fasterxml.jackson.core:jackson-core:2.9.7'<br/>    compile 'io.confluent:kafka-avro-serializer:5.0.0'<br/>    compile 'org.apache.kafka:kafka_2.12:2.0.0'<br/>}<br/>jar {<br/>    manifest {<br/>        attributes 'Main-Class': mainClassName<br/>    } from {<br/>        configurations.compile.collect {<br/>            it.isDirectory() ? it : zipTree(it)<br/>        }<br/>    }<br/>    exclude "META-INF/*.SF"<br/>    exclude "META-INF/*.DSA"<br/>    exclude "META-INF/*.RSA"<br/>}</pre>
<p>Some library dependencies added to the application are as follows:</p>
<ul>
<li><kbd>kafka_2.12</kbd>, the necessary dependencies for Apache Kafka</li>
<li><kbd>javafaker</kbd>, the necessary dependencies for JavaFaker</li>
<li><kbd>jackson-core</kbd>, for JSON parsing and manipulation</li>
<li><kbd>kafka-avro-serializer</kbd>, to serialize in Kafka with Apache Avro</li>
</ul>
<p>Note that to use the <kbd>kafka-avro-serializer</kbd> function, we added the Confluent repository in the repositories section.</p>
<p>To compile the project and download the required dependencies, type the following command:</p>
<pre><strong>$ gradle compileJava</strong></pre>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>The output should be similar to the following:</p>
<pre><strong>BUILD SUCCESSFUL in 3s</strong><br/><strong>1 actionable task: 1 executed</strong></pre>
<p>The project can also be created with Maven, SBT, or even from the IDE. But for simplicity, it was created with Gradle. For more information about these projects, visit the following:</p>
<ul>
<li>Gradle's main page: <a href="http://www.gradle.org">http://www.gradle.org</a></li>
<li>Maven's main page: <a href="http://maven.apache.org">http://maven.apache.org</a></li>
<li>SBT's main page: <a href="http://www.scala-sbt.org/">http://www.scala-sbt.org/</a></li>
<li>Jackson's main page: <a href="https://github.com/FasterXML">https://github.com/FasterXML</a></li>
<li>JavaFaker's main page: <a href="https://github.com/DiUS/java-faker">https://github.com/DiUS/java-faker</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The constants</h1>
                </header>
            
            <article>
                
<p>The first step is to code our <kbd>Constants</kbd> class. This class is a static class with all of the <kbd>Constants</kbd> needed in our project.</p>
<p>Open the project with your favorite IDE and, under the <kbd>src/main/java/kioto</kbd> <span>directory, </span>create a file called <kbd>Constants.java</kbd> with the content of <em>Listing 4.3</em>.</p>
<p><span>The following is the content of </span><em>Listing 4.3</em>, <kbd>Constants.java</kbd><span>:</span> </p>
<pre>package kioto;<br/>import com.fasterxml.jackson.databind.ObjectMapper;<br/>import com.fasterxml.jackson.databind.SerializationFeature;<br/>import com.fasterxml.jackson.databind.util.StdDateFormat;<br/>public final class Constants {<br/>  private static final ObjectMapper jsonMapper;<br/>  static {<br/>    ObjectMapper mapper = new ObjectMapper();<br/>    mapper.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);<br/>    mapper.setDateFormat(new StdDateFormat());<br/>    jsonMapper = mapper;<br/>  }<br/>  public static String getHealthChecksTopic() {<br/>    return "healthchecks";<br/>  }<br/>  public static String getHealthChecksAvroTopic() {<br/>    return "healthchecks-avro";<br/>  }<br/>  public static String getUptimesTopic() {<br/>    return "uptimes";<br/>  }<br/>  public enum machineType {GEOTHERMAL, HYDROELECTRIC, NUCLEAR, WIND, SOLAR}<br/>  public enum machineStatus {STARTING, RUNNING, SHUTTING_DOWN, SHUT_DOWN}<br/>  public static ObjectMapper getJsonMapper() {<br/>    return jsonMapper;<br/>  }<br/>}</pre>
<p>In our <kbd>Constants</kbd> class, there are some methods that we will need later. These are as follows:</p>
<ul>
<li><kbd>getHealthChecksTopic</kbd>: It returns the name of the health checks input topic</li>
<li><kbd>getHealthChecksAvroTopic</kbd>: It returns the name of the topic with the health checks in Avro</li>
<li><kbd>getUptimesTopic</kbd>: It returns the name of the <kbd>uptimes</kbd> topic</li>
<li><kbd>machineType</kbd>: This is an <kbd>enum</kbd> with the types of the Kioto energy producing machines types</li>
<li><kbd>machineType</kbd>: This is an <kbd>enum</kbd> with the types of the Kioto machines' possible statuses</li>
<li><kbd>getJsonMapper</kbd>: It returns the object mapper for JSON serialization and we set the serialization format for dates</li>
</ul>
<p>This is a <kbd>Constants</kbd> class; in languages such as Kotlin, the constants don't require an independent class, but we are using Java. Some purists of object-oriented programming argue that to code constant classes is an object-oriented anti-pattern. However, for simplicity here, we need some constants in our system.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">HealthCheck message</h1>
                </header>
            
            <article>
                
<p>The second step is to code the <kbd>HealthCheck</kbd> class. This class is a <strong>Plain Old Java Object</strong> (<strong>POJO</strong>). The <kbd>model</kbd> class is the template for the value object.</p>
<p>Open the project with your favorite IDE and, in the <kbd>src/main/java/kioto</kbd> directory, create a file called <kbd>HealthCheck.java</kbd> with the content of <em>Listing 4.4</em>.</p>
<p><span>The following is the content of </span><em>Listing 4.4</em>,<em> </em><kbd>HealthCheck.java</kbd><span>:</span><span> </span></p>
<pre>package kioto;<br/>import java.util.Date;<br/>public final class HealthCheck {<br/>  private String event;<br/>  private String factory;<br/>  private String serialNumber;<br/>  private String type;<br/>  private String status;<br/>  private Date lastStartedAt;<br/>  private float temperature;<br/>  private String ipAddress;<br/>}</pre>
<div class="packt_figref CDPAlignCenter CDPAlign">Listing 4.4:<em> </em>HealthCheck.java</div>
<p>With your IDE, generate the following:</p>
<ul>
<li>A no-parameter constructor</li>
<li>A constructor with all of the attributes passed as parameters</li>
<li>The getters and the setters for each attribute</li>
</ul>
<p>This is a data class, a POJO in Java. In languages such as Kotlin, the model classes require so much less boilerplate code, but now we are in Java. Some purists of object-oriented programming argue that value objects is an object-oriented anti-pattern. However, the serialization libraries to produce messages need these classes.</p>
<p>To generate fake data with JavaFaker, our code should be as shown in <em>Listing 4.5</em>.</p>
<p><span>The following is the content of </span><em>Listing 4.5</em>, a health check mock generator with JavaFaker:</p>
<pre>HealthCheck fakeHealthCheck =<br/>   new HealthCheck(<br/>        "HEALTH_CHECK",<br/>        faker.address().city(),                    //1<br/>        faker.bothify("??##-??##", true),    //2<br/>              Constants.machineType.values()<br/>                   [faker.number().numberBetween(0,4)].toString(), //3<br/>        Constants.machineStatus.values()<br/>                   [faker.number().numberBetween(0,3)].toString(), //4<br/>        faker.date().past(100, TimeUnit.DAYS),           //5<br/>        faker.number().numberBetween(100L, 0L),          //6<br/>        faker.internet().ipV4Address());                 //7</pre>
<p>The following is an analysis of how to generate fake health check data:</p>
<ul>
<li>In line <kbd>//1</kbd>, <kbd>address().city()</kbd> generates a fictitious city name</li>
<li>In line <kbd>//2</kbd>, in the expression <kbd>?</kbd> for alpha <kbd>#</kbd> for numeric, <kbd>true</kbd> if alpha is uppercase</li>
<li>In line <kbd>//3</kbd>, we use the machine type <kbd>enum</kbd> in <kbd>Constants</kbd> , and a fake number between <kbd>0</kbd> and <kbd><kbd>4</kbd></kbd></li>
<li>In line <kbd>//4</kbd>, we use the machine status <kbd>enum</kbd> in <kbd>Constants</kbd> and a fake number between <kbd>0</kbd> and <kbd>3</kbd>, inclusively</li>
<li>In line <kbd>//5</kbd>, we are saying that we want a fake date between the past <kbd>100</kbd> days from today</li>
<li>In line <kbd>//6</kbd>, we build a fake IP address</li>
</ul>
<p>Here, we depend on the attributes order of the constructor. Other languages, such as Kotlin, allow specifying each assigned attribute name.</p>
<p>Now, to transform our Java POJO into a JSON string, we use the method in the <kbd>Constants</kbd> class—something like the following:</p>
<pre>String fakeHealthCheckJson fakeHealthCheckJson = Constants.getJsonMapper().writeValueAsString(fakeHealthCheck);</pre>
<p>Don't forget that this method throws a JSON processing exception.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Java PlainProducer</h1>
                </header>
            
            <article>
                
<p>As we already know, to build a Kafka Message producer that we use the Java client library, in particular the producer API (in the following chapters, we will see how to use Kafka Streams and KSQL).</p>
<p>The first thing we need is a data source; to make it simple we need to produce our mock data. Each message will be a health message with all of its attributes. The first step is to build a producer to send these messages in JSON format to a topic, as in the example:</p>
<pre><strong>{"event":"HEALTH_CHECK","factory":"Port Roelborough","serialNumber":"QT89-TZ50","type":"GEOTHERMAL","status":"SHUTTING_DOWN","lastStartedAt":"2018-09-13T00:36:39.079+0000","temperature":28.0,"ipAddress":"235.180.238.3"}</strong><br/><br/><strong>{"event":"HEALTH_CHECK","factory":"Duckburg","serialNumber":"NB49-XL51","type":"NUCLEAR","status":"RUNNING","lastStartedAt":"2018-08-18T05:42:29.648+0000","temperature":49.0,"ipAddress":"42.181.105.188"}</strong><br/><strong>...</strong></pre>
<p>Let's start by creating a Kafka producer that we will use to send the input messages.</p>
<p>As we already know, there are two requisites that all of the Kafka producers should have: they must be <kbd>KafkaProducer</kbd> and have specific properties set, as shown in <em>Listing 4.6</em>.</p>
<p class="mce-root"/>
<p><span>The following is the content of</span> <em>Listing 4.6,</em> the constructor method for <kbd>PlainProducer</kbd>:</p>
<pre>import org.apache.kafka.clients.producer.KafkaProducer;<br/>import org.apache.kafka.clients.producer.Producer;<br/>import org.apache.kafka.common.serialization.StringSerializer;<br/>public final class PlainProducer {<br/>  private final Producer&lt;String, String&gt; producer;<br/>  public PlainProducer(String brokers) {<br/>    Properties props = new Properties();<br/>    props.put("bootstrap.servers", brokers);                //1<br/>    props.put("key.serializer", StringSerializer.class);    //2<br/>    props.put("value.serializer", StringSerializer.class);  //3<br/>    producer = new KafkaProducer&lt;&gt;(props);                  //4<br/>  }<br/>  ...<br/>}</pre>
<p>An analysis of the <kbd>PlainProducer</kbd> constructor includes the following:</p>
<ul>
<li>In line <kbd>//1</kbd>, the list of the brokers where our producer will be running</li>
<li>In line <kbd>//2</kbd>, the serializer type for the messages' keys (we will see serializers later)</li>
<li>In line <kbd>//3</kbd>, the serializer type for the messages' values (in this case, the values are strings)</li>
<li>In line <kbd>//4</kbd>, with these properties we build a <kbd>KafkaProducer</kbd> with string keys and string values, for example, <span> </span><kbd>&lt;String, String&gt;</kbd></li>
<li>Note that properties behave like a HashMap; in languages such as Kotlin, the properties assignment could be made using the <kbd>=</kbd> <span>operator, rather than by calling a method</span></li>
</ul>
<p>We are using a string serializer for both keys and values: in this first approach, we will serialize the values to JSON manually using Jackson. We will see later how to write a custom serializer.</p>
<p>Now, in the <kbd>src/main/java/kioto/plain</kbd> directory, create a file called <kbd>PlainProducer.java</kbd> with the content of <em>Listing 4.7</em>.</p>
<p><span>The following is the content of </span><em>Listing 4.7</em>,<em> </em><span><kbd>PlainProducer.java</kbd></span><span>:</span><span> </span></p>
<pre>package kioto.plain;<br/>import ...<br/>public final class PlainProducer {<br/>  /* here the Constructor code in Listing 4.6 */<br/>  public void produce(int ratePerSecond) {<br/>    long waitTimeBetweenIterationsMs = 1000L / (long)ratePerSecond; //1<br/>    Faker faker = new Faker();<br/>    while(true) { //2<br/>      HealthCheck fakeHealthCheck /* here the code in Listing 4.5 */;<br/>      String fakeHealthCheckJson = null;<br/>      try {<br/>        fakeHealthCheckJson = Constants.getJsonMapper().writeValueAsString(fakeHealthCheck); //3<br/>      } catch (JsonProcessingException e) {<br/>         // deal with the exception<br/>      }<br/>      Future futureResult = producer.send(new ProducerRecord&lt;&gt;<br/>         (Constants.getHealthChecksTopic(), fakeHealthCheckJson)); //4<br/>      try {<br/>        Thread.sleep(waitTimeBetweenIterationsMs); //5<br/>        futureResult.get(); //6<br/>      } catch (InterruptedException | ExecutionException e) {<br/>         // deal with the exception<br/>      }<br/>    }<br/>  }<br/>  public static void main(String[] args) {<br/>    new PlainProducer("localhost:9092").produce(2); //7<br/>  }<br/>}</pre>
<p>An analysis of the <kbd>PlainProducer</kbd> class includes the following:</p>
<ul>
<li>In line <kbd>//1</kbd>, <kbd>ratePerSecond</kbd> is the number of messages to send in a one second period</li>
<li>In line <kbd>//2</kbd>, to simulate repetition, we use an infinite loop (try to avoid this in production)</li>
<li>In line <kbd>//3</kbd>, the code to serialize as JSON a Java POJO</li>
<li>In line <kbd>//4</kbd>, we use a Java Future to send the message to <kbd>HealthChecksTopic</kbd></li>
<li>In line <kbd>//5</kbd>, we wait this time to send messages again</li>
<li>In line <kbd>//6</kbd>, we read the result of the future created previously</li>
<li>In line <kbd>//7</kbd>, everything runs on the broker in localhost in port <kbd>9092</kbd>, sending two messages at intervals of one second</li>
</ul>
<p>It is important to note that here we are sending records without a key; we only specified the value (a JSON string), so the key is <kbd>null</kbd>. We are also calling the <kbd>get()</kbd> method on the result in order to wait for the write acknowledgment: without that, messages could be sent to Kafka but are lost without our program noticing the failure.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the PlainProducer</h1>
                </header>
            
            <article>
                
<p>To build the project, run this command from the <kbd>kioto</kbd> directory:</p>
<pre><strong>$ gradle jar</strong></pre>
<p>If everything is okay, the output is something like the following:</p>
<pre><strong>BUILD SUCCESSFUL in 3s</strong><br/><strong>1 actionable task: 1 executed</strong></pre>
<ol>
<li>From a command-line terminal, move to the <kbd>confluent</kbd> directory and start it by typing the following:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ ./bin/confluent start</strong></pre>
<ol start="2">
<li>The broker is running on port <kbd>9092</kbd>. To create the <kbd>healthchecks</kbd> topic, execute the following:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ ./bin/kafka-topics --zookeeper localhost:2181 --create --topic             <br/>healthchecks --replication-factor 1 --partitions 4</strong></pre>
<ol start="3">
<li>Run a console consumer for the <kbd>healthchecks</kbd> topic by typing the following:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ ./bin/kafka-console-consumer --bootstrap-server localhost:9092       <br/>--topic healthchecks</strong></pre>
<ol start="4">
<li>From our IDE, run the main method of the <kbd>PlainProducer</kbd></li>
<li>The output on the console consumer should be similar to the following:</li>
</ol>
<pre style="padding-left: 60px"><strong>{"event":"HEALTH_CHECK","factory":"Lake Anyaport","serialNumber":"EW05-HV36","type":"WIND","status":"STARTING","lastStartedAt":"2018-09-17T11:05:26.094+0000","temperature":62.0,"ipAddress":"15.185.195.90"}</strong><br/><br/><strong>{"event":"HEALTH_CHECK","factory":"Candelariohaven","serialNumber":"BO58-SB28","type":"SOLAR","status":"STARTING","lastStartedAt":"2018-08-16T04:00:00.179+0000","temperature":75.0,"ipAddress":"151.157.164.162"}</strong><br/><br/><strong>{"event":"HEALTH_CHECK","factory":"Ramonaview","serialNumber":"DV03-ZT93","type":"SOLAR","status":"RUNNING","lastStartedAt":"2018-07-12T10:16:39.091+0000","temperature":70.0,"ipAddress":"173.141.90.85"}</strong><br/><strong>...</strong></pre>
<p class="mceNonEditable"/>
<p>Remember that, when producing data, there are several write guarantees that we could achieve.</p>
<p>For example, in case of a network failure or a broker failure, is our system ready to lose data?</p>
<p>There is a trade-off among three factors: the availability to produce messages, the latency in the production, and the guarantee of the safe write.</p>
<p>In this example, we just have one broker, and we use the default value for <kbd>acks</kbd> of 1. When we call the <kbd>get()</kbd> method in the future, we are waiting for the broker acknowledgment, that is, we have a guarantee that the message is persisted before sending another message. In this configuration, we don't lose messages, but our latency is higher than in a fire and forget schema.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Java plain consumer</h1>
                </header>
            
            <article>
                
<p>As we already know, to build a Kafka message consumer, we use the Java client library—in particular, the consumer API (in the following chapters, we will see how to use Kafka Streams and KSQL).</p>
<p>Let's create a Kafka consumer that we will use to receive the input messages.</p>
<p>As we already know, there are two requisites that all of the Kafka consumers should have: to be a <kbd>KafkaConsumer</kbd> and to set the specific properties, such as  those shown in <em>Listing 4.8</em>.</p>
<p><span>The following is the content of</span> <em>Listing 4.8</em>, the constructor method for plain consumer:</p>
<pre>import org.apache.kafka.clients.consumer.KafkaConsumer;<br/>import org.apache.kafka.clients.consumer.Consumer;<br/>import org.apache.kafka.common.serialization.StringSerializer;<br/>public final class PlainConsumer {<br/>  private Consumer&lt;String, String&gt; consumer;<br/>  public PlainConsumer(String brokers) {<br/>    Properties props = new Properties();<br/>    props.put("group.id", "healthcheck-processor");         //1<br/>    props.put("bootstrap.servers", brokers);                   //2<br/>    props.put("key.deserializer", StringDeserializer.class);   //3<br/>    props.put("value.deserializer", StringDeserializer.class); //4<br/>    consumer = new KafkaConsumer&lt;&gt;(props);                        //5<br/>  }<br/>  ...<br/>}</pre>
<p class="mce-root"/>
<p>An analysis of the plain consumer constructor includes the following:</p>
<ul>
<li>In line <kbd>//1</kbd>, the group ID of our consumer, in this case, <kbd>healthcheck-processor</kbd></li>
<li>In line <kbd>//2</kbd>, the list of <kbd>brokers</kbd> where our consumer will be running</li>
<li>In line <kbd>//3</kbd>, the deserializer type for the messages' keys (we will see deserializers later)</li>
<li>In line <kbd>//4</kbd>, the deserializer type for the messages' values, in this case, values are strings</li>
<li>In line <kbd>//5</kbd>, with these properties, we build a <kbd>KafkaConsumer</kbd> with string keys and string values, for example, <span> </span><kbd>&lt;String, String&gt;</kbd></li>
</ul>
<p>For the customers, we need to provide a group ID to specify the consumer group that our consumer will join.</p>
<p>In the case that multiple consumers are started in parallel, through different threads or through different processes, each consumer will be assigned with a subset of the topic partitions. In our example, we created our topic with four partitions, which means that, to consume the data in parallel, we could create up to four consumers.</p>
<p>For a consumer, we provide deserializers rather than serializers. Although we don't use the key deserializer (because if you remember, it is <kbd>null</kbd>), the key deserializer is a mandatory parameter for the consumer specification. On the other hand, we need the deserializer for the value, because we are reading our data in a JSON string, whereas here we deserialize the object manually with Jackson.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Java PlainProcessor</h1>
                </header>
            
            <article>
                
<p>Now, in the <kbd>src/main/java/kioto/plain</kbd> <span>directory, </span>create a file called <kbd>PlainProcessor.java</kbd> with the content of <em>Listing 4.9</em>.</p>
<p><span>The following is the content of </span><em>Listing 4.9</em>, <kbd>PlainProcessor.java</kbd> (part 1):</p>
<pre>package kioto.plain;<br/>import ...<br/>public final class PlainProcessor {<br/>  private Consumer&lt;String, String&gt; consumer;<br/>  private Producer&lt;String, String&gt; producer;<br/>  public PlainProcessor(String brokers) {<br/>    Properties consumerProps = new Properties();<br/>    consumerProps.put("bootstrap.servers", brokers);<br/>    consumerProps.put("group.id", "healthcheck-processor");<br/>    consumerProps.put("key.deserializer", StringDeserializer.class);<br/>    consumerProps.put("value.deserializer", StringDeserializer.class);<br/>    consumer = new KafkaConsumer&lt;&gt;(consumerProps);<br/>    Properties producerProps = new Properties();<br/>    producerProps.put("bootstrap.servers", brokers);<br/>    producerProps.put("key.serializer", StringSerializer.class);<br/>    producerProps.put("value.serializer", StringSerializer.class);<br/>    producer = new KafkaProducer&lt;&gt;(producerProps);<br/>  }</pre>
<p>An analysis of the first part of the <kbd>PlainProcessor</kbd> class includes the following:</p>
<ul>
<li>In the first part, we declare a consumer, as in <em>Listing 4.8</em></li>
<li>In the second part, we declare a producer, as in <em>Listing 4.6</em></li>
</ul>
<p>Before continuing to write code, let's remember the project requirements for the Kioto stream processing engine.</p>
<p>Putting it all together, the specification is to create a stream engine that does the following:</p>
<ul>
<li>Generates messages to a Kafka topic called <strong>healthchecks</strong></li>
<li>Reads messages from the Kafka topic called <strong>healthchecks</strong></li>
<li>Calculates the uptime based on the start up time</li>
<li>Writes the messages in a Kafka topic called <strong>uptimes</strong></li>
</ul>
<p>This entire process is detailed in <em>Figure 4.1</em>, that is, the Kioto stream processing application:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/e950097d-1b87-4c2d-b542-1ae7a2c74fef.png" style=""/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span><span>Figure 4.1: The messages are generated into HealthChecksTopic, then read, and finally the calculated uptimes are written it in the uptimes topic.</span></span></div>
<p>Now that we're in the <kbd>src/main/java/kioto/plain</kbd> directory, let's complete the <kbd>PlainProcessor.java</kbd> file with the content of <em>Listing 4.10</em>.</p>
<p><span>The following is the content of </span><em>Listing 4.10</em>, <kbd>PlainProcessor.java</kbd> (part 2):</p>
<pre> public final void process() {<br/>    consumer.subscribe(Collections.singletonList(<br/>               Constants.getHealthChecksTopic()));           //1<br/>    while(true) {<br/>      ConsumerRecords records = consumer.poll(Duration.ofSeconds(1L)); //2<br/>      for(Object record : records) {                //3<br/>        ConsumerRecord it = (ConsumerRecord) record;<br/>        String healthCheckJson = (String) it.value();<br/>        HealthCheck healthCheck = null;<br/>        try {<br/>          healthCheck = Constants.getJsonMapper()<br/>           .readValue(healthCheckJson, HealthCheck.class);     // 4<br/>        } catch (IOException e) {<br/>            // deal with the exception<br/>        }<br/>        LocalDate startDateLocal =healthCheck.getLastStartedAt().toInstant()<span>                   .atZone(ZoneId.systemDefault()).toLocalDate();        //5<br/></span>        int uptime =<br/>             Period.between(startDateLocal, LocalDate.now()).getDays();  //6<br/>        Future future =<br/>             producer.send(new ProducerRecord&lt;&gt;(<br/>                              Constants.getUptimesTopic(),<br/>                              healthCheck.getSerialNumber(),<br/>                              String.valueOf(uptime)));                  //7<br/>        try {<br/>          future.get();<br/>        } catch (InterruptedException | ExecutionException e) {<br/>          // deal with the exception<br/>        }<br/>      }<br/>    }<br/>  }<br/>  public static void main( String[] args) {<br/>    (new PlainProcessor("localhost:9092")).process();<br/>  }<br/>}</pre>
<div class="CDPAlignCenter CDPAlign packt_figref"><span><span>Listing 4.10: PlainProcessor.java (part 2)</span></span></div>
<p>An analysis of the <kbd>PlainProcessor</kbd> includes the following:</p>
<ul>
<li>In line <kbd>//1</kbd>, the consumer is created and subscribed to the source topic. This is a dynamic assignment of the partitions to our customer and join to the customer group. </li>
<li>In line <kbd>//2</kbd>, an infinite loop to consume the records, the pool duration is passed as a parameter to the method pool. The customer waits no longer than one second before return.</li>
<li>In line <kbd>//3</kbd>, we iterate over the records.</li>
<li>In line <kbd>//4</kbd>, the JSON string is deserialized to extract the health check object.</li>
<li>In line <kbd>//5</kbd>, the start time is transformed formatted at the current time zone.</li>
<li>In line <kbd>//6</kbd>, the uptime is calculated.</li>
<li>In line <kbd>//7</kbd>, the uptime is written to the <kbd>uptimes</kbd> topic, using the serial number as the key and the uptime as value. Both values are written as normal strings.</li>
</ul>
<p>The moment at which the broker returns records to the client also depends on the <kbd>fetch.min.bytes</kbd> value; its default is 1, and is the minimum data amount to wait before the broker is available to the client. Our broker returns as soon as 1 byte of data is available, while waiting a maximum of one second.</p>
<p>The other configuration property is <kbd>fetch.max.bytes</kbd>, which defines the amount of data returned at once. With our configuration, the broker will return all of the available records (without exceeding the maximum of 50 MB).</p>
<p>If there are no records available, the broker returns an empty list.</p>
<p>Note that we could reuse the producer that generates the mock data, but it is clearer to use another producer to write <kbd>uptimes</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the PlainProcessor</h1>
                </header>
            
            <article>
                
<p>To build the project, run the following command from the <kbd>kioto</kbd> directory:</p>
<pre><strong>$ gradle jar</strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>If everything is correct, the output is something like the following:</p>
<pre><strong>BUILD SUCCESSFUL in 3s</strong><br/><strong>1 actionable task: 1 executed</strong></pre>
<ol>
<li>Our broker is running on port <kbd>9092</kbd>, so to create the <kbd>uptimes</kbd> topic, execute the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ ./bin/kafka-topics --zookeeper localhost:2181 --create --topic <br/>uptimes --replication-factor 1 --partitions 4</strong></pre>
<ol start="2">
<li>Run a console consumer for the <kbd>uptimes</kbd> topic, as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ ./bin/kafka-console-consumer --bootstrap-server localhost:9092 <br/>--topic uptimes --property print.key=true</strong></pre>
<ol start="3">
<li>From our IDE, run the main method of <kbd>PlainProcessor</kbd></li>
<li>From our IDE, run the main method of <kbd>PlainProducer</kbd></li>
<li>The output on the console consumer for the <kbd>uptimes</kbd> topic should be similar to the following:</li>
</ol>
<pre style="padding-left: 60px"><strong>EW05-HV36   33</strong><br/><strong>BO58-SB28   20</strong><br/><strong>DV03-ZT93   46</strong><br/><strong>...</strong></pre>
<p>We have said that, when producing data, there are two factors to think about; one is the delivery guarantee, and the other is the partitioning.</p>
<p>When consuming data, we have to think about the following four factors:</p>
<ul>
<li>The number of consumers to run in parallel (in parallel threads and/or parallel processes)</li>
<li>The amount of data to consume at once (think in terms of memory)</li>
<li>The time to wait to receive messages (throughput and latency)</li>
<li>When to mark a message as processed (committing offset)</li>
</ul>
<p>If <kbd>enable.auto.commit</kbd> is set to <kbd>true</kbd> (the default is <kbd>true</kbd>), the consumer automatically will commit the offsets in the next call to the poll method.</p>
<p>Note that the whole batch of records is committed; if something fails and the application crashes after processing only some messages, but not all of the batch, the events are not committed and they will be reprocessed by other consumer; this way to process data is called at least once processing. </p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Custom serializer</h1>
                </header>
            
            <article>
                
<p>So far, we have seen how to produce and consume JSON messages using plain Java and Jackson. We will see here how to create our custom serializers and deserializers.</p>
<p>We have seen how to use <kbd>StringSerializer</kbd> in the producer and <kbd>StringDeserializer</kbd> in the consumer. Now, we will see how to build our own SerDe to abstract the serialization/deserialization processes away from the core code of the application.</p>
<p>To build a custom serializer, we need to create a class that implements the <kbd>org.apache.kafka.common.serialization.Serializer</kbd> interface. This is a generic type, so we can indicate the custom type to be converted into an array of bytes (serialization).</p>
<p>In the <kbd>src/main/java/kioto/serde</kbd> <span>directory, </span>create a file called <kbd>HealthCheckSerializer.java</kbd> with the content of <em>Listing 4.11</em>.</p>
<p><span>The following is the content of </span><em>Listing 4.11</em>,<span> </span><kbd>HealthCheckSerializer.java</kbd><span>:</span> </p>
<pre>package kioto.serde;<br/>import com.fasterxml.jackson.core.JsonProcessingException;<br/>import kioto.Constants;<br/>import java.util.Map;<br/>import org.apache.kafka.common.serialization.Serializer;<br/>public final class HealthCheckSerializer implements Serializer {<br/>  @Override<br/>  public byte[] serialize(String topic, Object data) {<br/>    if (data == null) {<br/>      return null;<br/>    }<br/>    try {<br/>      return Constants.getJsonMapper().writeValueAsBytes(data);<br/>    } catch (JsonProcessingException e) {<br/>      return null;<br/>    }<br/>  }<br/><br/>  @Override<br/>  public void close() {}<br/>  @Override<br/>  public void configure(Map configs, boolean isKey) {}<br/>}</pre>
<div class="CDPAlignCenter CDPAlign packt_figref">Listing 4.11: <span><span>HealthCheckSerializer.java</span></span></div>
<p>Note that the serializer class is located in a special module called <strong>kafka-clients</strong> in the <kbd>org.apache.kafka</kbd> route. The objective here is to use the serializer class instead of Jackson (manually).</p>
<p>Also note that the important method to implement is the <kbd>serialize</kbd> method. The <kbd>close</kbd> and <kbd>configure</kbd> methods can be left with an empty body.</p>
<p>We import the <kbd>JsonProcessingException</kbd> of Jackson just because the <kbd>writeValueAsBytes</kbd> method throws this exception, but we don't use Jackson for serialization.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Java CustomProducer</h1>
                </header>
            
            <article>
                
<p>Now, to incorporate the serializer in our producer, there are two requisites that all Kafka producers should fulfill: to be a <kbd>KafkaProducer</kbd>, and to set the specific properties, such as <em>Listing 4.12</em>.</p>
<p><span>The following is the content of </span><em>Listing 4.12</em>,<em> </em>the constructor method for <kbd>CustomProducer</kbd>:</p>
<pre>import kioto.serde.HealthCheckSerializer;<br/>import org.apache.kafka.clients.producer.KafkaProducer;<br/>import org.apache.kafka.clients.producer.Producer;<br/>import org.apache.kafka.common.serialization.StringSerializer;<br/>public final class CustomProducer {<br/>  private final Producer&lt;String, HealthCheck&gt; producer;<br/>  public CustomProducer(String brokers) {<br/>    Properties props = new Properties();<br/>    props.put("bootstrap.servers", brokers);                    //1<br/>    props.put("key.serializer", StringSerializer.class);        //2<br/>    props.put("value.serializer", HealthCheckSerializer.class); //3<br/>    producer = new KafkaProducer&lt;&gt;(props);                      //4<br/>  }</pre>
<p>An analysis of the <kbd>CustomProducer</kbd> constructor includes the following:</p>
<ul>
<li>In line <kbd>//1</kbd>, this is the list of the brokers where our producer will be running.</li>
<li>In line <kbd>//2</kbd>, the serializer type for the messages' keys in this case keys remains as strings. In line <kbd>//3</kbd><span>, this is the serializer type for the messages' values, in this case, the values are <kbd>HealthCheck</kbd>.</span></li>
<li>In line <kbd>//4</kbd>, with these properties we build a <kbd>KafkaProducer</kbd> with string keys and <kbd>HealthCheck</kbd> values, for example,<span> </span><kbd>&lt;String, HealthCheck&gt;</kbd>.</li>
</ul>
<p class="mce-root"/>
<p>Now, in the <kbd>src/main/java/kioto/custom</kbd> directory, create a file called <kbd>CustomProducer.java</kbd> with the content of <em>Listing 4.13</em>.</p>
<p><span>The following is the content of </span><em>Listing 4.13</em>,<span> </span><kbd>CustomProducer.java</kbd><span>:</span></p>
<pre>package kioto.plain;<br/>import ...<br/>public final class CustomProducer {<br/>  /* here the Constructor code in Listing 4.12 */<br/>  public void produce(int ratePerSecond) {<br/>    long waitTimeBetweenIterationsMs = 1000L / (long)ratePerSecond; //1<br/>    Faker faker = new Faker();<br/>    while(true) { //2<br/>      HealthCheck fakeHealthCheck /* here the code in Listing 4.5 */;<br/>      Future futureResult = producer.send( new ProducerRecord&lt;&gt;(<br/>         Constants.getHealthChecksTopic(), fakeHealthCheck));       //3<br/>      try {<br/>        Thread.sleep(waitTimeBetweenIterationsMs); //4<br/>        futureResult.get();      //5          <br/>      } catch (InterruptedException | ExecutionException e) {<br/>        // deal with the exception<br/>      }<br/>    }<br/>  }<br/>public static void main(String[] args) {<br/>    new CustomProducer("localhost:9092").produce(2); //6<br/>  }<br/>}</pre>
<div class="CDPAlignCenter CDPAlign packt_figref"><span>Listing 4.13: CustomProducer.java</span></div>
<p>An analysis of the <kbd>CustomProducer</kbd> class includes the following:</p>
<ul>
<li>In line <kbd>//1</kbd>, <kbd>ratePerSecond</kbd> is the number of messages to send in a one-second period</li>
<li>In line <kbd>//2</kbd>, to simulate repetition, we use a infinite loop (try to avoid this in production)</li>
<li>In line <kbd>//3</kbd>, we use a Java future to send the message to <kbd>HealthChecksTopic</kbd></li>
<li>In line <kbd>//4</kbd>, we wait this time to send messages again</li>
<li>In line <kbd>//5</kbd>, we read the result of the future created previously</li>
<li>In line <kbd>//6</kbd>, everything runs on the broker in localhost in port <kbd>9092</kbd>, sending two messages in an interval of one second</li>
</ul>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the CustomProducer</h1>
                </header>
            
            <article>
                
<p>To build the project, run the following command from the <kbd>kioto</kbd> directory:</p>
<pre><strong>$ gradle jar</strong></pre>
<p>If everything is okay, the output is something like the following:</p>
<pre>BUILD SUCCESSFUL in 3s<br/>1 actionable task: 1 executed</pre>
<ol>
<li>Run a console consumer for <kbd>HealthChecksTopic</kbd> as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ ./bin/kafka-console-consumer --bootstrap-server localhost:9092 </strong><br/><strong>--topic healthchecks</strong></pre>
<ol start="2">
<li>From our IDE, run the main method of the <kbd>CustomProducer</kbd></li>
<li>The output on the console consumer should be similar to the following:</li>
</ol>
<pre style="padding-left: 60px"><strong>{"event":"HEALTH_CHECK","factory":"Lake Anyaport","serialNumber":"EW05-HV36","type":"WIND","status":"STARTING","lastStartedAt":"2018-09-17T11:05:26.094+0000","temperature":62.0,"ipAddress":"15.185.195.90"}</strong><br/><br/><strong>{"event":"HEALTH_CHECK","factory":"Candelariohaven","serialNumber":"BO58-SB28","type":"SOLAR","status":"STARTING","lastStartedAt":"2018-08-16T04:00:00.179+0000","temperature":75.0,"ipAddress":"151.157.164.162"}</strong><br/><br/><strong>{"event":"HEALTH_CHECK","factory":"Ramonaview","serialNumber":"DV03-ZT93","type":"SOLAR","status":"RUNNING","lastStartedAt":"2018-07-12T10:16:39.091+0000","temperature":70.0,"ipAddress":"173.141.90.85"}</strong><br/><br/><strong>...</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Custom deserializer</h1>
                </header>
            
            <article>
                
<p>In a similar way, to build a custom deserializer, we need to create a class that implements the <kbd>org.apache.kafka.common.serialization.Deserializer</kbd> interface. We must indicate how to convert an array of bytes into a custom type (deserialization).</p>
<p>In the <kbd>src/main/java/kioto/serde</kbd> directory, create a file called <kbd>HealthCheckDeserializer.java</kbd> with the content of <em>Listing 4.14</em>.</p>
<p class="mce-root"/>
<p><span>The following is the content of </span><em>Listing 4.14</em>,<span> </span><kbd>HealthCheckDeserializer.java</kbd><span>:</span> </p>
<pre>package kioto.serde;<br/>import kioto.Constants;<br/>import kioto.HealthCheck;<br/>import java.io.IOException;<br/>import java.util.Map;<br/>import org.apache.kafka.common.serialization.Deserializer;<br/>public final class HealthCheckDeserializer implements Deserializer {<br/>  @Override<br/>  public HealthCheck deserialize(String topic, byte[] data) {<br/>    if (data == null) {<br/>      return null;<br/>    }<br/>    try {<br/>      return Constants.getJsonMapper().readValue(data, HealthCheck.class);<br/>    } catch (IOException e) {<br/>      return null;<br/>    }<br/>  }<br/>  @Override<br/>  public void close() {}<br/>  @Override<br/>  public void configure(Map configs, boolean isKey) {}<br/>}</pre>
<div class="CDPAlignCenter CDPAlign packt_figref">Listing 4.14<span>: HealthCheckDeserializer.java</span></div>
<p>Note that the deserializer class is located in a module called kafka-clients in the <kbd>org.apache.kafka</kbd> route. The objective here is to use the deserializer class instead of Jackson (manually).</p>
<p>Also note that the important method to implement is the <kbd>deserialize</kbd> method. The <kbd>close</kbd> and <kbd>configure</kbd> methods can be left with an empty body.</p>
<p>We import the <kbd>HealthCheck</kbd> class because the <kbd>readValue</kbd> method requires a POJO (a class with public constructor and public getters and setters). Note also that all of the POJO attributes should be serializables.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Java custom consumer</h1>
                </header>
            
            <article>
                
<p>Let's create a Kafka consumer that we will use to receive the custom input messages.</p>
<p>Now, in order to incorporate the deserializer in our consumer, there are two requisites that all of the Kafka consumers should have: to be a <kbd>KafkaConsumer</kbd>, and to set the specific properties, such as those in <em>Listing 4.15</em>.</p>
<p><span>The following is the content of </span><em>Listing 4.15</em>, the constructor method for <kbd>CustomConsumer</kbd>:</p>
<pre>import kioto.HealthCheck;<br/>import kioto.serde.HealthCheckDeserializer;<br/>import org.apache.kafka.clients.consumer.KafkaConsumer;<br/>import org.apache.kafka.clients.consumer.Consumer;<br/>import org.apache.kafka.common.serialization.StringSerializer;<br/>public final class CustomConsumer {<br/>  private Consumer&lt;String, HealthCheck&gt; consumer;<br/>  public CustomConsumer(String brokers) {<br/>    Properties props = new Properties();<br/>    props.put("group.id", "healthcheck-processor");//1<br/>    props.put("bootstrap.servers", brokers);//2<br/>    props.put("key.deserializer", StringDeserializer.class);//3<br/>    props.put("value.deserializer", HealthCheckDeserializer.class); //4<br/>    consumer = new KafkaConsumer&lt;&gt;(props);//5<br/>  }<br/>  ...<br/>}</pre>
<p>An analysis of the <kbd>CustomConsumer</kbd> constructor includes the following:</p>
<ul>
<li>In line <kbd>//1</kbd>, the group ID of our consumer, in this case, <kbd>healthcheck- processor</kbd></li>
<li>In line <kbd>//2</kbd>, the list of the brokers where our consumer will be running</li>
<li>In line <kbd>//3</kbd>, the deserializer type for the messages' keys; in this case, the keys remains as strings</li>
<li>In line <kbd>//4</kbd>, the deserializer type for the messages' values; in this case, the values are <kbd>HealthChecks</kbd></li>
<li>In line <kbd>//5</kbd>, with these properties, we build a <kbd>KafkaConsumer</kbd> with string keys and <kbd>HealthChecks</kbd> values, for example, <kbd>&lt;String, HealthCheck&gt;</kbd></li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p>For a consumer, we provide deserializers rather than serializers. Although we don't use the key deserializer (because if you remember, it is <kbd>null</kbd>), the key deserializer is a mandatory parameter for the consumer specification. On the other hand, we need the deserializer for the value, because we are reading our data in a JSON string; here, we deserialize the object with the custom deserializer. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Java custom processor</h1>
                </header>
            
            <article>
                
<p>Now, in the <kbd>src/main/java/kioto/custom</kbd> directory, create a file called <kbd>CustomProcessor.java</kbd> with the content of <em>Listing 4.16</em>.</p>
<p><span>The following is the content of </span><em>Listing 4.16</em>, <kbd>CustomProcessor.java</kbd> (part 1):</p>
<pre>package kioto.custom;<br/>import ...<br/><br/>public final class CustomProcessor {<br/><br/>  private Consumer&lt;String, HealthCheck&gt; consumer;<br/>  private Producer&lt;String, String&gt; producer;<br/><br/>  public CustomProcessor(String brokers) {<br/>    Properties consumerProps = new Properties();<br/>    consumerProps.put("bootstrap.servers", brokers);<br/>    consumerProps.put("group.id", "healthcheck-processor");<br/>    consumerProps.put("key.deserializer", StringDeserializer.class);<br/>    consumerProps.put("value.deserializer",                        HealthCheckDeserializer.class);<br/>    consumer = new KafkaConsumer&lt;&gt;(consumerProps);<br/>    Properties producerProps = new Properties();<br/>    producerProps.put("bootstrap.servers", brokers);<br/>    producerProps.put("key.serializer", StringSerializer.class);<br/>    producerProps.put("value.serializer", StringSerializer.class);<br/>    producer = new KafkaProducer&lt;&gt;(producerProps);<br/>  }</pre>
<p>An analysis of the first part of the custom processor class includes the following:</p>
<ul>
<li>In the first part, we declare a consumer, as in <em>Listing 4.15</em></li>
<li>In the second part, we declare a producer, as in <em>Listing 4.13</em></li>
</ul>
<p>Now, in the <kbd>src/main/java/kioto/custom</kbd> <span>directory, </span>let's complete the <kbd>CustomProcessor.java</kbd> file with the content of <em>Listing 4.17</em>.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p><span>The following is the content of </span><em>Listing 4.17</em>, <kbd>CustomProcessor.java</kbd> (part 2):</p>
<pre>public final void process() {<br/>    consumer.subscribe(Collections.singletonList(<br/>             Constants.getHealthChecksTopic()));           //1<br/>    while(true) {<br/>      ConsumerRecords records = consumer.poll(Duration.ofSeconds(1L)); //2<br/>      for(Object record : records) {                 //3<br/>        ConsumerRecord it = (ConsumerRecord) record;<br/>        HealthCheck healthCheck = (HealthCheck) it.value(); //4<br/>        LocalDate startDateLocal =healthCheck.getLastStartedAt().toInstant()<br/>                 .atZone(ZoneId.systemDefault()).toLocalDate();         //5<br/>        int uptime =<br/>             Period.between(startDateLocal, LocalDate.now()).getDays();  //6<br/>        Future future =<br/>             producer.send(new ProducerRecord&lt;&gt;(<br/>                              Constants.getUptimesTopic(),<br/>                              healthCheck.getSerialNumber(),<br/>                             String.valueOf(uptime)));                  //7<br/>        try {<br/>          future.get();<br/>        } catch (InterruptedException | ExecutionException e) {<br/>          // deal with the exception<br/>        }<br/>      }<br/>    }<br/>  }<br/>  public static void main( String[] args) {<br/>    new CustomProcessor("localhost:9092").process();<br/>  }<br/>}</pre>
<p>An analysis of the <kbd>CustomProcessor</kbd> process method includes the following:</p>
<ul>
<li>In line <kbd>//1</kbd>, here the consumer is created and subscribed to the source topic. This is a dynamic assignment of the partitions to our customer and join to the customer group.</li>
<li>In line <kbd>//2</kbd>, an infinite loop to consume the records, the pool duration is passed as a parameter to the method pool. The customer waits no longer than one second before return.</li>
<li>In line <kbd>//3</kbd>, we iterate over the records.</li>
<li>In line <kbd>//4</kbd>, the JSON string is deserialized to extract the <kbd>HealthCheck</kbd> object.</li>
<li>In line <kbd>//5</kbd>, the start time is transformed in format at the current time zone.</li>
<li>In line <kbd>//6</kbd>, the uptime is calculated.</li>
<li>In line <kbd>//7</kbd>, the uptime is written to the <kbd>uptimes</kbd> topic, using the serial number as the key and the uptime as the value. Both values are written as normal strings.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the custom processor</h1>
                </header>
            
            <article>
                
<p>To build the project, run the following command from the <kbd>kioto</kbd> directory:</p>
<pre><strong>$ gradle jar</strong></pre>
<p>If everything is correct, the output is something like the following:</p>
<pre><strong>BUILD SUCCESSFUL in 3s</strong><br/><strong>1 actionable task: 1 executed</strong></pre>
<ol>
<li>Run a console consumer for the <kbd>uptimes</kbd> topic as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ ./bin/kafka-console-consumer --bootstrap-server localhost:9092 </strong><br/><strong>--topic uptimes --property print.key=true</strong></pre>
<ol start="2">
<li>From our IDE, run the main method of <kbd>CustomProcessor</kbd></li>
<li>From our IDE, run the main method of <kbd>CustomProducer</kbd></li>
<li>The output on the console consumer for the <kbd>uptimes</kbd> topic should be similar to the following:</li>
</ol>
<pre style="padding-left: 60px"><strong>EW05-HV36   33</strong><br/><strong>BO58-SB28   20</strong><br/><strong>DV03-ZT93   46</strong><br/><strong>...</strong></pre>
<p>Now, we have seen how to create our own SerDe to abstract the serialization code from our application's main logic. Now you know how a Kafka SerDe works.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we learned how to build a Java PlainProducer, a consumer, and a processor, and we have shown how <span>to build a custom serializer and a custom deserializer.</span></p>
<p><span>Also, we learned how </span><span>to build a Java CustomProducer, a consumer, and a processor, and h</span><span>ow to run the Java CustomProducer and the processor.</span></p>
<p>In this chapter, we have seen how to serialize/deserialize with Kafka using JSON, plain, and binary formats. Avro is a common serialization type for Kafka. We will see how to use Avro in <a href="f7fa5729-8bf7-41c8-aba6-aa5f8663394f.xhtml" target="_blank">Chapter 5</a>, <em>S</em><span><em>chema Registry</em>,</span> along with the use of the Kafka schema registry.</p>


            </article>

            
        </section>
    </body></html>