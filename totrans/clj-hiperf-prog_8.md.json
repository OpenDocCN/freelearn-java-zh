["```java\nlein with-profile dev,benchmark test\n```", "```java\nlein with-profile dev,c17,perf test\n```", "```java\n[ch.qos.logback/logback-classic \"1.1.2\"]\n[ch.qos.logback/logback-core    \"1.1.2\"]\n[org.slf4j/slf4j-api            \"1.7.9\"]\n[org.codehaus.janino/janino     \"2.6.1\"]  ; for Logback-config\n[org.clojure/tools.logging      \"0.3.1\"]\n```", "```java\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<configuration>\n\n  <appender name=\"FILE\"\n            class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n    <file>${logfile.general.name:-logs/application.log}</file>\n    <rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\">\n      <!-- daily rollover -->\n      <fileNamePattern>${logfile.general.name:-logs/application.log}.%d{yyyy-MM-dd}.%i.gz</fileNamePattern>\n      <timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\">\n        <!-- or whenever the file size reaches 100MB -->\n        <maxFileSize>100MB</maxFileSize>\n      </timeBasedFileNamingAndTriggeringPolicy>\n      <!-- keep 30 days worth of history -->\n      <maxHistory>30</maxHistory>\n    </rollingPolicy>\n    <append>true</append>\n    <encoder class=\"ch.qos.logback.core.encoder.LayoutWrappingEncoder\">\n      <layout class=\"ch.qos.logback.classic.PatternLayout\">\n        <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>\n      </layout>\n <immediateFlush>false</immediateFlush>\n    </encoder>\n  </appender>\n\n <appender name=\"AsyncFile\" class=\"ch.qos.logback.classic.AsyncAppender\">\n <queueSize>500</queueSize>\n <discardingThreshold>0</discardingThreshold>\n <appender-ref ref=\"FILE\" />\n </appender>\n\n  <!-- You may want to set the level to DEBUG in development -->\n  <root level=\"ERROR\">\n <appender-ref ref=\"AsyncFile\" />\n  </root>\n\n  <!-- Replace com.example with base namespace of your app -->\n  <logger name=\"com.example\" additivity=\"false\">\n    <!-- You may want to set the level to DEBUG in development -->\n    <level value=\"INFO\"/>\n <appender-ref ref=\"AsyncFile\" />\n  </logger>\n\n</configuration>\n```", "```java\n(defn summarize [daily-data]  ; daily-data is a map\n  (let [s (items-summary (:items daily-data))]\n    (-> daily-data\n      (select-keys [:digest :invoices])  ; keep required k/v pairs\n      (assoc :summary s))))\n\n;; now inside report generation code\n(-> (fetch-items period-from period-to :interval-day)\n  (map summarize)\n  generate-report)\n```", "```java\n(def ^:const K 1024)\n\n;; create the buffered reader using custom 128K buffer-size\n(-> filename\n  java.io.FileInputStream.\n  java.io.InputStreamReader.\n  (java.io.BufferedReader. (* K 128)))\n```", "```java\n(require '[clojure.java.jdbc :as jdbc])\n\n;; using prepare-statement directly\n(with-open\n  [stmt (jdbc/prepare-statement\n          conn sql :fetch-size 1000 :max-rows 9000)\n   rset (resultset-seq (.executeQuery stmt))]\n  (vec rset))\n\n;; using query\n(jdbc/query db [{:fetch-size 1000}\n           \"SELECT empno FROM emp WHERE country=?\" 1])\n```", "```java\n(require '[clojure.java.jdbc :as jdbc])\n\n;; multiple SQL statements\n(jdbc/db-do-commands\n  db true\n  [\"INSERT INTO emp (name, countrycode) VALUES ('John Smith', 3)\"\n   \"UPDATE emp SET countrycode=4 WHERE empid=1379\"])\n\n;; similar statements with only different parametrs\n(jdbc/db-do-prepared\n  db true\n  \"UPDATE emp SET countrycode=? WHERE empid=?\"\n  [4 1642]\n  [9 1186]\n  [2 1437])\n```", "```java\n(require '[clojure.java.jdbc :as j])\n\n(def db {:subprotocol \"mysql\"\n         :subname \"//127.0.0.1:3306/clojure_test\"\n         :user \"clojure_test\" :password \"clojure_test\"})\n\n;; the snippet below uses N+1 selects\n;; (typically characterized by SELECT in a loop)\n(def rq \"select order_id from orders where status=?\")\n(def tq \"select * from items where fk_order_id=?\")\n(doseq [order (j/query db [rq \"pending\"])]\n  (let [items (j/query db [tq (:order_id order)])]\n    ;; do something with items\n    â€¦))\n\n;; the snippet below avoids N+1 selects,\n;; but requires fk_order_id to be indexed\n(def jq \"select t.* from orders r, items t\n  where t.fk_order_id=r.order_id and r.status=? order by t.fk_order_id\")\n(let [all-items (group-by :fk_order_id (j/query db [jq \"pending\"]))]\n  (doseq [[order-id items] all-items]\n    ;; do something with items\n    ...))\n```", "```java\n(import 'java.util.concurrent.LinkedBlockingDeque)\n(import 'java.util.concurrent.TimeUnit)\n(import 'java.util.concurrent.ThreadPoolExecutor)\n(import 'java.util.concurrent.ThreadPoolExecutor$AbortPolicy)\n(def tpool\n  (let [q (LinkedBlockingDeque. 100)\n        p (ThreadPoolExecutor$AbortPolicy.)]\n    (ThreadPoolExecutor. 1 10 30 TimeUnit/SECONDS q p)))\n```", "```java\n(require '[org.httpkit.server :as hk])\n\n;; handler is a typical Ring handler\n(hk/run-server handler {:port 3000 :thread 32 :queue-size 600})\n```", "```java\n(require '[aleph.http :as a])\n\n;; handler is a typical Ring handler\n(a/start-server handler {:executor tpool})\n```"]