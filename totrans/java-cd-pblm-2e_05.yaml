- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Arrays, Collections, and Data Structures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter includes 24 problems covering three main topics. We start with
    several problems related to the new Vector API dedicated to parallel data processing.
    We continue with several data structures, including Rope, Skip List, K-D Tree,
    Zipper, Binomial Heap, Fibonacci Heap, Pairing Heap, Huffman Coding, and so on.
    Finally, we discuss the three most popular join algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of this chapter, you’ll know how to write code for exploiting data
    parallel processing, exploiting a bunch of cool and lesser-known data structures,
    and how join operations work. And, as a bonus, you’ll be familiar with the JDK
    21 Sequenced Collections API.
  prefs: []
  type: TYPE_NORMAL
- en: Problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Use the following problems to test your programming prowess on Java arrays,
    collections, and data structures. I strongly encourage you to give each problem
    a try before you turn to the solutions and download the example programs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Introducing parallel computations with arrays**: Explain in a few paragraphs
    what data parallel processing is and how it works.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Covering the Vector API’s structure and terminology**: Explain with examples
    the Vector API terminology. Cover notions such as element type, shape, species,
    lanes, and so on.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Summing two arrays via the Vector API**: Write an application that uses the
    Vector API for summing up two Java arrays.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Summing two arrays unrolled via the Vector API**: Write an application that
    uses the Vector API for summing two Java arrays using the *unrolled* technique.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Benchmarking the Vector API**: Given two arrays, `x[]` and `y[]`, write an
    application that benchmarks the computation `z[] = x[] + y[]`, `w[] = x[] * z[]
    * y[]`, `k[] = z[] + w[] * y[]` using plain Java and the Vector API.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Applying the Vector API to compute FMA**: Provide a Vector API implementation
    of the famous Fused Multiply Add (FMA).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Multiplying matrices via the Vector API**: Write a Vector API implementation
    for multiplying two matrices.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Hooking the image negative filter with the Vector API**: Write a program
    that uses the Vector API to apply the negative filter to an image.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Dissecting factory methods for collections**: Exemplify several approaches
    for creating unmodifiable/immutable maps, lists, and sets in Java.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Getting a list from a stream**: Provide several snippets of code useful for
    collecting `Stream` content into a Java `List`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Handling map capacity**: Explain what the capacity of a Java `Map` is and
    how it can be used to control the number of effective mappings.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tackling Sequenced Collections**: Provide in-depth dive into the JDK 21 Sequenced
    Collections API. Exemplify this API on your favorite Java collections and explain
    what the alternatives before this API are.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing the Rope data structure**: Explain what the Rope data structure
    is and provide a Java implementation for its main operations (index, insert, delete,
    concatenation, and split).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing the Skip List data structure**: Explain and exemplify the Skip
    List data structure.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing the K-D Tree data structure**: Provide a brief introduction of
    K-D Trees and a Java implementation for 2-D Trees.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing the Zipper data structure**: Explain and exemplify on a tree
    the Zipper data structure.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing the Binomial Heap data structure**: Provide a deep coverage of
    a Binomial Heap data structure. Explain its main operations and exemplify them
    in a Java implementation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing the Fibonacci Heap data structure**: Explain and exemplify the
    Fibonacci Heap data structure.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing the Pairing Heap data structure**: Explain and exemplify the
    Pairing Heap data structure.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing the Huffman Coding data structure**: The Huffman Coding algorithm
    was developed by David A. Huffman in 1950\. Explain its usage and exemplify it
    via a Java implementation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing the Splay Tree data structure**: A Splay Tree is a flavor of
    **Binary Search Tree** (**BST**). Explain what its particularities are and provide
    an implementation of its main operations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing the Interval Tree data structure**: An Interval Tree is another
    flavor of **Binary Search Tree** (**BST**). Highlight its usage and exemplify
    it via a Java implementation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Introducing the Unrolled Linked List data structure**: Explain and exemplify
    the Unrolled Linked List data structure.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Implementing join algorithms**: There are three famous join algorithms: Nested
    Loop Join, Hash Join, and Sort Merge Join. Explain and exemplify each of them
    in two tables that are involved in a one-to-many relationship.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The following sections describe solutions to the preceding problems. Remember
    that there usually isn’t a single correct way to solve a particular problem. Also,
    remember that the explanations shown here include only the most interesting and
    important details needed to solve the problems. Download the example solutions
    to see additional details and to experiment with the programs at [https://github.com/PacktPublishing/Java-Coding-Problems-Second-Edition/tree/main/Chapter05](https://github.com/PacktPublishing/Java-Coding-Problems-Second-Edition/tree/main/Chapter05).
  prefs: []
  type: TYPE_NORMAL
- en: 107\. Introducing parallel computations with arrays
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There was a time when CPUs were only capable of performing operations on data
    in the traditional mode known as **Single Instruction, Single Data** (**SISD**)
    or von Neumann architecture. In other words, one CPU cycle can process a single
    instruction and a single piece of data. The processor applies that instruction
    to that data and returns a result.
  prefs: []
  type: TYPE_NORMAL
- en: 'Modern CPUs are capable of performing parallel computations and working in
    a mode known as **Single Instruction, Multiple Data** (**SIMD**). This time, one
    CPU cycle can apply a single instruction on multiple pieces of data simultaneously,
    which theoretically should speed things up and improve performance. The following
    diagram highlights these statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1.png](img/B19665_05_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.1: SISD vs. SIMD'
  prefs: []
  type: TYPE_NORMAL
- en: If we add two arrays *X* and *Y* via an SISD-based CPU, then we expect that
    each CPU cycle will add an element from *X* with an element from *Y*. If we do
    the same task on a SIMD-based CPU, then each CPU cycle will simultaneously perform
    the addition on chunks from *X* and *Y*. This means that an SIMD CPU should complete
    the task faster than the SISD CPU.
  prefs: []
  type: TYPE_NORMAL
- en: This is the big picture! When we come closer, we see that CPU architectures
    come in many flavors, so it is quite challenging to develop an application capable
    of leveraging the best performance of a specific platform.
  prefs: []
  type: TYPE_NORMAL
- en: The two big competitors in the market, Intel and AMD, come with different SIMD
    implementations. It is not our goal to dissect this topic in detail, but it can
    be useful to know that the first popular desktop SIMD was introduced in 1996 by
    Intel under the name MMX (x86 architecture). In response, the AIM alliance (made
    up of Apple, IBM, and Freescale Semiconductor) promoted AltiVec – an integer and
    single-precision floating-point SIMD implementation. Later on, in 1999, Intel
    introduced the new SSE system (using 128-bit registers).
  prefs: []
  type: TYPE_NORMAL
- en: 'Since then, SIMD has evolved via extensions such as Advanced Vector Extensions
    (AVX, AVX2 (256-bit registers) and AVX-512 (512-bit registers)). While AVX and
    AVX2 are supported by Intel and AMD, the AVX-512 introduced in 2022 is supported
    only by the latest Intel processors. The following figure helps illustrate all
    of this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2.png](img/B19665_05_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.2: SIMD implementation history'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5.2* is just the SIMD representation of a CPU structure. In reality,
    the platforms are much more complex and come in many flavors. There is no silver
    bullet and each platform has its strong and weak points. Trying to explore the
    strong points and avoid the weaknesses is a real challenge for any programming
    language trying to leverage the performance of a specific platform with high expectations.'
  prefs: []
  type: TYPE_NORMAL
- en: For instance, what is the proper set of instructions that JVM should generate
    in order to squeeze out the best performance from a specific platform on computations
    that involve vectors (arrays)? Well, starting with JDK 16 (JEP 338), Java provides
    an incubator module, `jdk.incubator.vector`, known as the Vector API. The goal
    of this API is to allow developers to express, in a very platform-agnostic way,
    vector computations that are transformed at runtime in optimal vector hardware
    instructions on supported CPU architectures.
  prefs: []
  type: TYPE_NORMAL
- en: Starting with JDK 21 (JEP 448), the Vector API reached the sixth incubator,
    so we can try out some examples that take advantage of data-parallel accelerated
    code in contrast to scalar implementation. Running examples based on this incubator
    API can be done by adding the `--add-modules=jdk.incubator.vector` and `--enable-preview`
    VM options.
  prefs: []
  type: TYPE_NORMAL
- en: But, before that, let’s cover the Vector API structure and terminology.
  prefs: []
  type: TYPE_NORMAL
- en: 108\. Covering the Vector API’s structure and terminology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Vector API is mapped by the `jdk.incubator.vector` module (and a package
    with the same name). A `jdk.incubator.vector.Vector` instance starts from a generic
    abstract combination characterized by a *type* and a *shape*. A vector is an instance
    of the `Vector<E>` class.
  prefs: []
  type: TYPE_NORMAL
- en: The vector element type
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A `Vector<E>` has an *element type* (`ETYPE`), which is one of the Java primitive
    types: `byte`, `float`, `double`, `short`, `int`, or `long`. When we write `Vector<E>`,
    we say that `E` is the boxed version of `ETYPE` (for instance, when we write `Vector<Float>`,
    `E` is `Float`, and `ETYPE` is `float`). For more convenience, Java declares a
    specialized subtype for each *element type*, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3.png](img/B19665_05_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.3: Specialized vector subtypes'
  prefs: []
  type: TYPE_NORMAL
- en: Even if `E` is a boxed type, there is no boxing-unboxing overhead because `Vector<E>`
    works internally on `ETYPE` and thus on primitive types.
  prefs: []
  type: TYPE_NORMAL
- en: Besides the *element type*, a vector is also characterized by a *shape*.
  prefs: []
  type: TYPE_NORMAL
- en: The vector shape
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A vector is also characterized by a *shape* (also referred to as `VSHAPE`) representing
    the size or capacity in bits of the vector. It can be 64, 128, 256, or 512 bits.
    Each of these values is wrapped by the `VectorShape` enumeration (for instance,
    the `S_128_BIT` enum item represents a shape of length 128 bits) next to an extra
    enum item representing the maximum length supported on the platform (`S_Max_BIT`).
    This is determined automatically on the currently running Java platform.
  prefs: []
  type: TYPE_NORMAL
- en: The vector species
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A vector characterized by its *element type* and *shape* determines a unique
    *vector species,* which is a fixed instance of `VectorSpecies<E>`. This instance
    is shared by all vectors having the same shape and `ETYPE`. We can think of `VectorSpecies<E>`
    as a factory used to create vectors of the required *element type* and *shape*.
    For instance, we can define a factory for creating vectors of the `double` type
    having a size of 512 bits as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'If you just need a factory for vectors of the maximal bit-size supported by
    the current platform independent of the element type, then rely on `S_Max_BIT`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If you just need the largest vector *species* for your *element type* (here,
    `double`) for the current platform, then rely on `ofLargestShape()`. This vector
    *species* is chosen by the platform and it has a *shape* with the largest possible
    bit-size for your *element type* (don’t confuse this with `S_Max_BIT`, which is
    independent of the *element type*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Or, maybe you need the vector *species* preferred by the current platform for
    your *element type*. This can be achieved via `ofPreferred()` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The preferred *species* is the most convenient approach when you don’t want
    to bother specifying an explicit *shape*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Important note**'
  prefs: []
  type: TYPE_NORMAL
- en: The preferred *species* is the most optimal *shape* for the given *element type*
    on the current platform (runtime).
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, for convenience, each specialized vector (`IntVector`, `FloatVector`,
    and so on) defines a set of static fields for covering all possible *species*.
    For example, the static field `DoubleVector.SPECIES_512` can be used for *species*
    representing `DoubleVector` instances of 512-bit size (`VectorShape.S_512_BIT`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want the maximal *species*,then rely on `SPECIES_MAX`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Or, if you want the preferred *species*,then rely on `SPECIES_PREFERRED`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You can easily inspect the *element type* and *shape* of a `VectorSpecies`
    instance via the `elementType()` and `vectorShape()` methods as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: So far, you know how to create vector *species* (vector factories). But, before
    starting to create vectors and apply operations on them, let’s talk about vector
    *lanes*.
  prefs: []
  type: TYPE_NORMAL
- en: Vector lanes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A `Vector<E>` is like a fixed-sized Java array made of *lanes*. The *lane count*
    is returned by the `length()` method and is called `VLENGTH`. The *lane count*
    is equal to the number of scalar elements stored in that vector.
  prefs: []
  type: TYPE_NORMAL
- en: If you know the *element size* and the *shape* of the vector, then you can compute
    the number of *lanes* as (*shape*/*element size*). You should get the same result
    as returned by `length()`. The *element size* is returned by `elementSize()`,
    and the *shape* is returned by `vectorBitSize()` or `vectorShape().vectorBitSize()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, a vector whose *shape* is 256 bits with an *element type* of
    `float` (which is 32 bits (4 bytes) in Java) holds 8 `float` scalar elements,
    so it has 8 *lanes*. The following figure illustrates this statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4.png](img/B19665_05_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.4: Computing the number of lanes'
  prefs: []
  type: TYPE_NORMAL
- en: Based on this example, you can easily compute the number of *lanes* for any
    other vector configuration. Next, let’s see why it is important to know about
    *lanes*.
  prefs: []
  type: TYPE_NORMAL
- en: Vector operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Applying operations on vectors is the climax of our efforts. The number of *lanes*
    estimates the SIMD performance because vector operations operate on *lanes*. A
    single vector operation affects a *lane* as a unit of work. For instance, if our
    vector has 8 *lanes*, it means that SIMD will perform 8 *lanewise* operations
    at once.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following figure, you can see a comparison of SISD vs. SIMD in this
    context:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5.png](img/B19665_05_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.5: SISD vs. SIMD'
  prefs: []
  type: TYPE_NORMAL
- en: While SISD has a single scalar as a unit of work, SIMD has 8 scalars (8 *lanes*),
    which explains why SIMD offers a significant performance bump over SISD.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, a `Vector<E>` is operated on *lanes*. Mainly, we have *lanewise* operations
    (such as addition, division, and bit shifts) and *cross-lane* operations that
    reduce all *lanes* to a single scalar (for instance, summing all *lanes*). The
    following figure depicts these statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6.png](img/B19665_05_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.6: Lanewise and cross-lane operations'
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, a `Vector<E>` can be operated on with a `VectorMask<E>`. This is
    a sequence of `boolean` values that can be used by some vector operations to filter
    the selection and operation of lane elements of the given input vectors. Check
    out the following figure (the addition operation is applied only when the mask
    contains 1):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7.png](img/B19665_05_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.7: Lanewise addition with mask'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important note**'
  prefs: []
  type: TYPE_NORMAL
- en: Note that masks are not supported by all CPUs. A CPU that doesn’t support masks
    may face degradation in performance.
  prefs: []
  type: TYPE_NORMAL
- en: Speaking about vector operations, you should definitely take a look at the `Vector`
    and `VectorOperators` documentation. In the `Vector` class, we have methods that
    apply operations between two vectors. For instance, we have methods for binary
    operations (such as `add()`, `div()`, `sub()`, and `mul()`), for comparisons (such
    as `eq()`, `lt()`, and `compare()`), for mathematical operations (such as `abs()`),
    and so on. Moreover, in `VectorOperators` we have a bunch of nested classes (for
    instance, `VectorOperators.Associative`) and several constants representing *lanewise*
    operations such as trigonometric functions (`SIN`, `COS`, and so on), bitwise
    shifting operations (`LSHL` and `LSHR`), mathematical operations (`ABS`, `SQRT`,
    and `POW`), and so on.
  prefs: []
  type: TYPE_NORMAL
- en: In the following problems, you’ll see a part of these operations at work, but
    for now let’s touch on the last essential topic, creating vectors.
  prefs: []
  type: TYPE_NORMAL
- en: Creating vectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We already know that having a `VectorSpecies` is like having a factory for creating
    vectors of the required *element type* and *shape*. Now, let’s see how we can
    use such a factory to effectively create vectors (fill them up with scalars) that
    get involved in solving real problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s assume the following *species* (a vector of 8 *lanes*, 32*8=256):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Next, let’s create the most common types of vectors.
  prefs: []
  type: TYPE_NORMAL
- en: Creating vectors of zeros
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s assume that we need a vector containing only zeros. A quick approach
    relies on the `zero()` method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This produced a vector with 8 *lanes* of 0.0\. The same thing can be obtained
    from the specialized `IntVector` class as well via `zero(VectorSpecies<Integer>
    species)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: You can easily extrapolate this example to `FloatVector`, `DoubleVector`, and
    so on.
  prefs: []
  type: TYPE_NORMAL
- en: Creating vectors of the same primitive value
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Creating a vector and loading it up with a primitive value can quickly be accomplished
    via the `broadcast()` method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The same thing can be obtained from the specialized `IntVector` class as well
    via `broadcast(VectorSpecies<Integer> species, int e)` or `broadcast(VectorSpecies<Integer>
    species, long e)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, we can use it to broadcast a vector of zeros as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Finally, let’s see the most common use case for creating a vector.
  prefs: []
  type: TYPE_NORMAL
- en: Creating vectors from Java arrays
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creating vectors from Java arrays is the most common use case. Practically,
    we start from a Java array and call the `fromArray()` method name.
  prefs: []
  type: TYPE_NORMAL
- en: Using fromArray() from VectorSpecies
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The `fromArray()` method is available in `VectorSpecies` as `fromArray(Object
    a, int offset)`. Here is an example of creating a vector from an array of integers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the `varr` length (8) is equal to the vector length and we start from
    index 0, the resulting vector will contain all the scalars from the array. This
    is no longer true in the following example where the last 4 scalars will not be
    part of the resulting vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The scalars 8, 9, 10, and 11 are not present in the resulting array. Here is
    another example, using `offset` = 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This time, the scalars 0, 1, 10, and 11 are not present in the resulting array.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pay attention that the length of the Java array shouldn’t be less than the
    vector’s length. For instance, the following example will cause an exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Since the Java array length is 6 (less than 8), this will cause a `java.lang.IndexOutOfBoundsException`
    instance. So, the minimum accepted length for `varr` is 8.
  prefs: []
  type: TYPE_NORMAL
- en: Using fromArray() from specialized vectors
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Each specialized vector class provides a bunch of `fromArray()` flavors. For
    instance, the `IntVector` exposes the popular `fromArray(VectorSpecies<Integer>
    species, int[] a, int offset)` method, which can be used in a straightforward
    way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If we prefer the `fromArray(VectorSpecies<Integer> species, int[] a, int offset,
    VectorMask<Integer> m)` flavor, then we can filter the selected scalars from the
    Java array via `VectorMask`. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on a one-to-one match, we can easily observe that the resulting vector
    will fetch only the scalars 2, 5, and 6\. The resulting vector will be: [0, 0,
    2, 0, 0, 5, 6, 0].'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another flavor of `fromArray()` is `fromArray(VectorSpecies<Integer> species,
    int[] a, int offset, int[] indexMap, int mapOffset)`. This time, we use a map
    of indexes to filter the selected scalars:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting array will be: [11, 11, 11, 12, 12, 29, 29, 29]. We have 11 from
    index 0, 12 from index 1, and 29 from index 6.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, we can apply `VectorMask` to the previous index map via `fromArray(VectorSpecies<Integer>
    species, int[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Integer>
    m)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting vector is: `[0, 0, 11, 0, 0, 29, 29, 0]`.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating vectors from memory segments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Memory segments* are a topic covered in detail in *Chapter 7* as part of the
    Foreign Function and Memory API, but as a quick teaser, here is an example of
    creating a vector from a memory segment via `IntVector.fromMemorySegment()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The created vector is: [11, 21, 12, 7, 33, 1, 3, 6].'
  prefs: []
  type: TYPE_NORMAL
- en: In the bundled code, you can find several more examples for manipulating data
    across lane boundaries such as slicing, un-slicing, shuffling/rearranging, compressing,
    expanding, converting, casting, and reinterpreting shapes.
  prefs: []
  type: TYPE_NORMAL
- en: In the next problem, we start creating complete examples that exploit what we’ve
    learned so far.
  prefs: []
  type: TYPE_NORMAL
- en: 109\. Summing two arrays via the Vector API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Summing two arrays is the perfect start for applying what we’ve learned in
    the preceding two problems. Let’s assume that we have the following Java arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'For computing `z=x+y` via the Vector API, we have to create two `Vector` instances
    and rely on the `add()` operation, `z=x.add(y)`. Since the Java arrays hold integer
    scalars, we can use the `IntVector` specialization as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: In Java, an integer needs 4 bytes, so 32 bits. Since `x` and `y` hold 8 integers,
    we need 8*32=256 bits to represent them in our vector. So, relying on `SPECIES_256`
    is the right choice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can apply the `add()` operation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Done! It is time for JVM to generate the optimal set of instructions (data-parallel
    accelerated code) that will compute our addition. The result will be a vector
    as [5, 7, 5, 9, 6, 9, 15, 15].
  prefs: []
  type: TYPE_NORMAL
- en: This was a simple case but not quite realistic. Who would employ parallel computational
    capabilities for summing up two arrays having a couple of elements?! In the real
    world, `x` and `y` may have much more than 8 elements. Most probably, `x` and
    `y` have millions of items and are involved in multiple calculation cycles. That
    is exactly when we can leverage the power of parallel computation.
  prefs: []
  type: TYPE_NORMAL
- en: 'But, for now, let’s assume that `x` and `y` are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: If we apply the previous code (based on `SPECIES_256`), the result will be the
    same because our vectors can accommodate only the first 8 scalars and will ignore
    the rest. If we apply the same logic but use `SPECIES_PREFERRED`, then the result
    is unpredictable since the vector’s shape is specific to the current platform.
    However, we can intuit that we will accommodate the first `n` (whatever that `n`
    is) scalars but not all.
  prefs: []
  type: TYPE_NORMAL
- en: 'This time, we need to chunk the arrays and use a loop to traverse the arrays
    and compute `z_chunk = x_chunk + y_chunk`. The result of summing two chunks is
    collected in a third array (`z`) until all chunks are processed. We define a method
    that starts as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'But, how big should a chunk be? The first challenge is represented by the loop
    design. The loop should start from 0, but what are the upper bound and the step?
    Typically, the upper bound is the length of `x`, so 34\. But, using `x.length`
    is not exactly useful because it doesn’t guarantee that our vectors will accommodate
    as many scalars as possible from the arrays. What we are looking for is the largest
    multiple of `VLENGTH` (vector’s length) that is less than or equal to `x.length`.
    In our case, that is the largest multiple of 8 that is less than 34, so 32\. This
    is exactly what the `loopBound()` method returns, so we can write the loop as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The loop step is the vector’s length. The following diagram pre-visualizes
    the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8.png](img/B19665_05_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.8: Computing z = x + y in chunks'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, at the first iteration, our vectors will accommodate the scalars from index
    0 to 7\. At the second iteration, the scalars are from index 8 to 15, and so on.
    Here is the complete code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The `intoArray(int[] a, int offset)` transfers the scalars from a vector to
    a Java array. This method comes in different flavors next to `intoMemorySegment()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting array will be: [7, 11, 7, 10, 2, 5, 11, 11, 6, 12, 9, 11, 4,
    8, 8, 9, 6, 8, 10, 12, 8, 12, 12, 13, 4, 8, 8, 9, 6, 8, 10, 12, **0**, **0**].
    Check out the last two items … they are equal to 0\. These are the items that
    result from `x.length - upperBound` = 34 – 32 = 2\. When the largest multiple
    of `VLENGTH` (vector’s length) is equal to `x.length`, this difference will be
    0, otherwise, we will have the rest of the items that have not been computed.
    So, the previous code will work as expected only in the particular case when `VLENGTH`
    (vector’s length) is equal to `x.length`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Covering the remaining items can be accomplished in at least two ways. First,
    we can rely on a `VectorMask` as in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The `indexInRange()` computes a mask in the range `[i, x.length-1]`. Applying
    this mask will result in the following `z` array: [7, 11, 7, 10, 2, 5, 11, 11,
    6, 12, 9, 11, 4, 8, 8, 9, 6, 8, 10, 12, 8, 12, 12, 13, 4, 8, 8, 9, 6, 8, 10, 12,
    5, 12]. Now, the last two items are computed as expected.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important note**'
  prefs: []
  type: TYPE_NORMAL
- en: As a rule of thumb, avoid using `VectorMask` in loops. They are quite expensive
    and may lead to a significant degradation in performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another approach for dealing with these remaining items is to go for a piece
    of traditional Java code as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Practically, we sum up the remaining items in a Java traditional loop outside
    the vectors loop. You can check these examples in the bundled code.
  prefs: []
  type: TYPE_NORMAL
- en: 110\. Summing two arrays unrolled via the Vector API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this problem, we take the example of summing two arrays from the previous
    problem and re-write the loop in an *unrolled* fashion.
  prefs: []
  type: TYPE_NORMAL
- en: '*Loop unrolling* can be applied manually (as we will do here) or by the compiler,
    and it stands for an optimization technique meant to reduce the loop iteration
    count.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case, in order to reduce the loop iteration count, we use more vectors
    to repeat the sequence of loop body statements that are responsible for summing
    the items. If we know that our arrays are long enough to always require at least
    4 loop iterations, then rewriting the code as follows will reduce the loop iterations
    by 4 times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Consider the following `x` and `y` vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Calling the `sumPlus(x, y, z)` method written in the previous problem will require
    4 loop iterations to complete. Calling `sumUnrolled(x, y, z)` will require a single
    iteration to complete.
  prefs: []
  type: TYPE_NORMAL
- en: 111\. Benchmarking the Vector API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Benchmarking the Vector API can be accomplished via JMH. Let’s consider three
    Java arrays (`x`, `y`, `z`) each of 50,000,000 integers, and the following computation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'So, the final result is stored in a Java array named `k`. And, let’s consider
    the following benchmark containing four different implementations of this computation
    (using a mask, no mask, *unrolled*, and plain scalar Java with arrays):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this benchmark on an Intel(R) Core(TM) i7-3612QM CPU @ 2.10GHz machine
    running Windows 10 produced the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.9.png](img/B19665_05_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.9: Benchmark results'
  prefs: []
  type: TYPE_NORMAL
- en: Overall, executing the computation using data-parallel capabilities gives the
    best performance, highest throughput, and best average time.
  prefs: []
  type: TYPE_NORMAL
- en: 112\. Applying the Vector API to compute FMA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a nutshell, **Fused Multiply Add** (**FMA**) is the mathematical computation
    (a*b) + c, which is heavily exploited in matrix multiplications. That’s all we
    need to cover for this problem, but if you need a primer on FMA, consider *Java
    Coding Problems, First Edition*, *Chapter 1*, *problem 38*.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing FMA via the Vector API can be done via the `fma(float b, float
    c)` or `fma(Vector<Float> b, Vector<Float> c)` operation, the latter is the one
    you’ll see in an example shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s assume that we have the following two arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Computing FMA(`x`, `y`) can be expressed as the following sequence: 4+0=4 →
    10+4=14 → 6+14=20 → 40+20=60 → 5+60=65 → 32+65=97\. So, FMA(`x`, `y`) = 97\. Expressing
    this sequence via the Vector API can be done as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Have you noticed the code line `sum = xVector.fma(yVector, sum)`? This is equivalent
    to `sum = xVector.mul(yVector).add(sum)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The novelty here consists of the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'This is an associative *cross-lane* reduction operation (see *Figure 5.6*).
    Before this line, the sum vector looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: By applying the `reduceLanes(VectorOperators.ADD)`, we sum the values of this
    vector and reduce it to the final result, 97.0\. Cool, right?!
  prefs: []
  type: TYPE_NORMAL
- en: 113\. Multiplying matrices via the Vector API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s consider two matrices of 4x4 denoted as `X` and `Y`. `Z=X*Y` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.10.png](img/B19665_05_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.10: Multiplying two matrices (X * Y = Z)'
  prefs: []
  type: TYPE_NORMAL
- en: Multiplying `X` with `Y` means multiplying the first row from `X` with the first
    column from `Y`, the second row from `X` with the second column from `Y`, and
    so on. For instance, (1 x 3) + (2 x 7) + (5 x 5) + (4 x 5) = 3 + 14 + 25 + 20
    = 62\. Basically, we repeatedly apply FMA computation and fill up `Z` with the
    results.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this context, and based on the previous problem about computing FMA, we
    can produce the following code for multiplying `X` with `Y`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: In the bundled code, you can find this example next to another one using `SPECIES_512`.
  prefs: []
  type: TYPE_NORMAL
- en: 114\. Hooking the image negative filter with the Vector API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An image is basically a matrix of pixels represented in the **Alpha, Red, Green,
    Blue** (**ARGB**) spectrum. For instance, an image of 232x290 can be represented
    as a matrix of 67,280 pixels. Applying specific filters (sepia, negative, grayscale,
    and so on) to an image typically requires processing each pixel from this matrix
    and performing certain calculations. For instance, the algorithm for applying
    the negative filter to an image can be used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.11.png](img/B19665_05_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.11: Apply the negative filter effect to an image'
  prefs: []
  type: TYPE_NORMAL
- en: For each pixel, we extract the color components A, R, G, and B. We subtract
    the R, G, and B values from 255, and finally, we set the new value to the current
    pixel.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s assume that we have an array (`pixel[]`) containing all pixels of an image.
    Next, we want to pass `pixel[]` as an argument to a method powered by the Vector
    API capable of applying the negative filter and setting the new values directly
    in `pixel[]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a possible implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: In the first part, we extract A, R, G, and B into four vectors (`alphaVector`,
    `redVector`, `greenVector`, and `blueVector`) by applying the `LSHR` *lanewise*
    operation. Afterward, we subtract R, G, and B from 255 and compute the new R,
    G, and B by applying the `LSHL` *lanewise* operation. Next, we compute the new
    color by applying the bitwise logical disjunction (`|`) between the new A, R,
    G, and B values. Finally, we set the new color in the `pixel[]` array.
  prefs: []
  type: TYPE_NORMAL
- en: 115\. Dissecting factory methods for collections
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using factory methods for collections is a must-have skill. It is very convenient
    to be able to quickly and effortlessly create and populate unmodifiable/immutable
    collections before putting them to work.
  prefs: []
  type: TYPE_NORMAL
- en: Factory methods for maps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For instance, before JDK 9, creating an unmodifiable map could be accomplished
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'This is useful if, at some point in time, you need an unmodifiable map from
    a modifiable one. Otherwise, you can take a shortcut as follows (this is known
    as the *double-brace initialization* technique and, generally, an anti-pattern):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'If you need to return an unmodifiable/immutable map from a `Stream` of `java.util.Map.entry`
    then here you go:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Moreover, let’s not forget the empty and singleton maps (quite useful to return
    a map from a method instead of `null`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Starting with JDK 9, we can rely on a more convenient approach for creating
    unmodifiable/immutable maps thanks to JEP 269: *Convenience Factory Methods for
    Collections*. This approach consists of `Map.of()`, which is available from 0
    to 10 mappings or, in other words, is overloaded to support 0 to 10 key-value
    pairs. Here, we use `Map.of()` for three mappings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Maps created via `Map.of()` don’t allow `null` keys or values. Such attempts
    will end up in a `NullPointerException`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you need more than 10 mappings then you can rely on `static <K,V> Map<K,V>
    ofEntries(Entry<? Extends K,? extends V>... entries)` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, creating an unmodifiable/immutable map from an existing one can be
    done via `static <K,V> Map<K,V> copyOf(Map<? extends K,? extends V> map)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: If the given map is unmodifiable then Java will most probably not create a copy
    and will return an existing instance. In other words, `imap == map` will return
    `true`. If the given map is modifiable then most probably the factory will return
    a new instance, so `imap == map` will return `false`.
  prefs: []
  type: TYPE_NORMAL
- en: Factory methods for lists
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before JDK 9, a modifiable `List` could be used for creating an unmodifiable
    `List` with the same content as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'A common approach for creating a `List` consists of using `Arrays.asList()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: However, keep in mind that this is a fixed-size list, not an unmodifiable/immutable
    list. In other words, operations that attempt to modify the list size (for instance,
    `ilist.add(…)`) will result in `UnsupportedOperationException`, while operations
    that modify the current content of the list (for instance, `ilist.set(…)`) are
    allowed.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you need to return an unmodifiable/immutable `List` from a `Stream` then
    here you go:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Moreover, creating an empty/singleton list can be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Starting with JDK 9+, it is more convenient to rely on the `List.of()` factory
    methods available for 0 to 10 elements (`null` elements are not allowed):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'If you need a copy of an existing list then rely on `List.copyOf()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: If the given list is unmodifiable then Java will most probably not create a
    copy and will return an existing instance. In other words, `ilist == list` will
    return `true`. If the given list is modifiable then the factory will most likely
    return a new instance, so `ilist == list` will return `false`.
  prefs: []
  type: TYPE_NORMAL
- en: Factory methods for sets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Creating `Set` instances follows the same path as `List` instances. However,
    note that there is no `singletonSet()`. To create a singleton set, simply call
    `singleton()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: You can find more examples in the bundled code. You may also be interested in
    *Problem 109* from *Java Coding Problems*, *First Edition*, which covers unmodifiable
    versus immutable collections. Moreover, please consider the next problem presented
    here as well, since it provides more info on this context.
  prefs: []
  type: TYPE_NORMAL
- en: 116\. Getting a list from a stream
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Collecting a `Stream` into a `List` is a popular task that occurs all over the
    place in applications that manipulate streams and collections.
  prefs: []
  type: TYPE_NORMAL
- en: 'In JDK 8, collecting a `Stream` into a `List` can be done via the `toList()`
    collector as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Starting with JDK 10, we can rely on the `toUnmodifiableList()` collector (for
    maps, use `toUnmodifiableMap()`, and for sets, `toUnmodifiableSet()`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Obviously, the returned list is an unmodifiable/immutable list.
  prefs: []
  type: TYPE_NORMAL
- en: 'JDK 16 has introduced the following `toList()` default method in the `Stream`
    interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this method to collect a `Stream` into an unmodifiable/immutable list
    is straightforward (pay attention that this is not like `Collectors.toList()`,
    which returns a modifiable list):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: In the bundled code, you can also find an example of combining `flatMap()` and
    `toList()`.
  prefs: []
  type: TYPE_NORMAL
- en: 117\. Handling map capacity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s assume that we need a `List` capable of holding 260 items. We can do
    it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: The array underlying `ArrayList` is created directly to accommodate 260 items.
    In other words, we can insert 260 items without worrying about resizing or enlarging
    the list several times in order to hold these 260 items.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following this logic, we can reproduce it for a map as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: So, now we can assume that we have a map capable of accommodating 260 mappings.
    Actually, no, this assumption is not true! A `HashMap` works on the *hashing*
    principle and is initialized with an initial capacity (16 if no explicit initial
    capacity is provided) representing the number of internal buckets and a default
    *load factor* of 0.75\. What does that mean? It means that when a `HashMap` reaches
    75% of its current capacity, it is doubled in size and a rehashing takes place.
    This guarantees that the mappings are evenly distributed in the internal buckets.
    But, for significantly large maps, this is an expensive operation. Javadoc states
    that “*creating a HashMap with a sufficiently large capacity will allow the mappings
    to be stored more efficiently than letting it perform automatic rehashing as needed
    to grow the table*.”
  prefs: []
  type: TYPE_NORMAL
- en: In our case, it means that a map can hold 260 x 0.75 = 195 mappings. In other
    words, when we insert the 195^(th) mapping, the map will be automatically resized
    to 260 * 2 = 520 mappings.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a `HashMap` for 260 mappings, we have to calculate the initial capacity
    as the number of mappings/load factor: 260 / 0.75 = 347 mappings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Or, if we want to express it as a formula, we can do it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Starting with JDK 19, this formula has been hidden behind the `static <K,V>
    HashMap<K,V> newHashMap(int numMappings)` method. This time, `numMappings` represents
    the number of mappings, so we can write this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Analog methods exist for `HashSet`, `LinkedHashSet`, `LinkedHashMap`, and `WeakHashMap`.
  prefs: []
  type: TYPE_NORMAL
- en: 118\. Tackling Sequenced Collections
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Sequenced Collections API was added as a final feature in JDK 21 under JEP
    431\. Its main goal is to make the navigation of Java collections easier by providing
    a common API to all collections having a well-defined encounter order.
  prefs: []
  type: TYPE_NORMAL
- en: A Java collection with a well-defined encounter order has a well-defined first
    element, second element, and so on, until the last element. The encounter order
    is the order in which an `Iterator` will iterate the elements of a collection
    (list, set, sorted set, map, and so on). The encounter order can take advantage
    of stability over time (lists) or not (sets).
  prefs: []
  type: TYPE_NORMAL
- en: 'This API consists of 3 interfaces named `SequencedCollection` (valid for any
    collection that has a well-defined encounter order), `SequencedSet` (extends `SequencedCollection`
    and `Set` to provide support for Java sets), and `SequencedMap` (extends `Map`
    to give support to any Java map that has a well-defined encounter order). In the
    following diagram, you can see the locations of these 3 interfaces in the collections
    type hierarchy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![aFigure1.png](img/B19665_05_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.12: The location of the Sequenced Collections API in the collections
    type hierarchy'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `SequencedCollection` API targets four main operations on a collection:
    getting the first/last element, adding a new element in the first/last position,
    removing the first/last element, and reversing a collection.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `SequencedCollection` API defines 7 methods, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`getFirst()` gets the first element of the current collection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`getLast()` gets the last element of the current collection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`addFirst(E e)` adds the given element `e` as the first element of the current
    collection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`addLast(E e)` adds the given element `e` as the last element of the current
    collection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`removeFirst()` removes the first element of the current collection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`removeLast()` removes the last element of the current collection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reversed()` returns the reverse collection of the current collection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SequencedSet` extends `SequencedCollection` and overrides the `reversed()`
    method to return `SequencedSet`.'
  prefs: []
  type: TYPE_NORMAL
- en: '`SequencedMap` defines the following methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`firstEntry()` returns the first entry (first key-value mapping) from the current
    map'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lastEntry()` returns the last entry (last key-value mapping) from the current
    map'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`putFirst(K k, V v)` attempts to insert (or replace) the given key-value mapping
    as the first mapping in the current map'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`putLast(K k, V v)` attempts to insert (or replace) the given key-value mapping
    as the last mapping in the current map'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pollFirstEntry()` removes and returns the first entry (first key-value mapping)
    from the current map (if no entry is present then it returns `null`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pollLastEntry()` removes and returns the last entry (last key-value mapping)
    from the current map (if no entry is present then it returns `null`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reversed()` returns the reverse map of the current map'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sequencedEntrySet()` returns a `SequencedSet` view of the entry set (`entrySet()`)
    of the current map'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sequencedKeySet()` returns a `SequencedSet` view of the key set (`keyset()`)
    of the current map'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sequencedValues()` returns a `SequencedCollection` view of the values (`values()`)
    of the current map'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The well-defined encounter order is a property spread across the collections
    type hierarchy, so we have to consider that the Sequenced Collections API works
    completely with some collections, partially with others, and not at all with yet
    others. Let’s tackle a few common collections and try out this new API.
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Sequenced Collections API to lists
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Java lists (implementations of `List`) rely on indexes to support a well-defined
    (stable) encounter order, so they are a perfect candidate for the Sequenced Collections
    API.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s see how we can exploit the Sequenced Collections API for two of
    the most popular implementations of `List`. Obviously, we are talking about `ArrayList`
    and `LinkedList`. `ArrayList` and `LinkedList` implement `SequencedCollection`.
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Sequenced Collections API to ArrayList and LinkedList
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s assume that we have the following `ArrayList` and `LinkedList`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Getting the first element from `ArrayList` is quite simple. The first element
    is at index 0, so calling `get(0)` is all we need to do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Getting the last element is a little trickier. We don’t know the index of the
    last element but we know the size of the list, so we can write this (it is not
    neat, but it works):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, if we rely on the JDK 21 Sequenced Collections API then
    we can get the first and last elements as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: That’s really neat and applies to the `LinkedList` as well! We don’t involve
    any explicit indexes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding an element in the first position means adding an element at index 0
    via the well-known `add(index, element)`. Moreover, adding an element in the last
    position means calling the `add(element)` method without an explicit index as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding the same elements via the Sequenced Collections API can be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Removing the first/last element can be done via the `remove()` method and the
    proper indexes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'If we know the value of the last element then we can remove it without an explicit
    index as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Removing the same elements via the Sequenced Collections API can be done as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: So, using the Sequenced Collections API is straightforward. No arguments are
    involved. And, this works for `LinkedList` as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reversing the list can be done via the `Collections.reverse()` helper. This
    method reverses the given list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, the Sequenced Collections API returns a new list representing
    the reverse of the given list as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: Again, the same code works for `LinkedList` as well. So, the Sequenced Collections
    API works perfectly for lists.
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Sequenced Collections API to sets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Java sets (implementations of `Set`) can be split into two categories. We have
    sorted sets (implementations of `SortedSet`) that support a well-defined (stable)
    encounter order and sets that make no guarantees as to the iteration order (`HashSet`).
  prefs: []
  type: TYPE_NORMAL
- en: A `SortedSet` has an order dictated by the logic of a comparator (*natural ordering*
    or `Comparator`). When we insert a new element in a sorted set, the comparator
    logic decides where this element will land, so we don’t know the index value of
    an element. However, a sorted set has the notion of first and last elements and
    an `Iterator` will iterate the elements in the order settled by the comparator.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, a set such as `HashSet` has no guarantees as to the iteration
    order. The elements of a `HashSet` are ordered by its internal hashing algorithms.
    An `Iterator` over a `HashSet` iterates its elements in no particular order and,
    when we insert a new element, we have no idea where this element will land in
    the `HashSet`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s see how we can exploit the Sequenced Collections API for three of
    the most popular sets. We choose `HashSet` (an implementation of `Set`), `LinkedHashSet`
    (an extension of `HashSet`), and `TreeSet` (an implementation of `NavigableSet`
    that extends `SortedSet`).
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Sequenced Collections API to HashSet
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A `HashSet` iterates its elements in no particular order, which means that a
    `HashSet` has no idea (stability) of the first, second, or last elements. Iterating
    the same `HashSet` multiple times may result in different outputs. In this context,
    we can add an element to a set via the `add(E e)` method. The element will be
    added only if it doesn’t exist already and will land in a position computed by
    the `HashSet` internal hashing algorithms. Moreover, we can remove an element
    by its value via `remove(Object o)`. Since the order of elements is not stable,
    it doesn’t make sense to reverse `HashSet`. In this context, the Sequenced Collections
    API doesn’t work at all, so `HashSet` doesn’t take advantage of this API.
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Sequenced Collections API to LinkedHashSet
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A `LinkedHashSet` is a `HashSet` that relies on a doubly-linked list to maintain
    a well-defined encounter order. A `LinkedHashSet` implements `SequencedSet`, so
    it can take advantage of the Sequenced Collections API. Let’s deep dive into the
    following `LinkedHashSet`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'The `LinkedHashSet` doesn’t expose an API for getting the first/last elements.
    However, we can rely on the well-defined encounter order and on the `Iterator`
    (or `Stream`) API to get the first element as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'This is not neat, and for the last element it is even worse:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'Fortunately, JDK 21 simplifies this task via the `getFirst()` and `getLast()`
    methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding an element into `LinkedHashSet` is possible only if that element doesn’t
    exist. This is normal since sets don’t accept doubles as lists. However, adding
    on the first position is not an easy task (we can do it if we transform `LinkedHashSet`
    into another collection, add the element on the first position, and convert back
    to `LinkedHashSet`) so we skipped that here. Adding an element to the last position
    is easy via the `add()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'But if we rely on the Sequenced Collections API, then we can add on the first/last
    position via `addFirst()`/`addLast()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'Removing the first/last element is possible only if we know the values of those
    elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Obviously, this approach is not robust and safe and you’ll prefer to get the
    first/last elements as you saw earlier via `Iterator`/`Stream`, and call `remove()`
    on those elements afterward. However, the more appropriate option is to rely on
    the Sequenced Collections API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'There is no other straightforward solution to reverse `LinkedHashSet` than
    using the Sequenced Collections API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: So, as you can see, the Sequenced Collections API really simplifies the usage
    of `LinkedHashSet`. Cool!
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Sequenced Collections API to TreeSet
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A `TreeSet` is a sorted set that implements `NavigableSet` (an extension of
    `SortedSet`) so it takes advantage of all methods of a sorted set plus some navigation
    methods. It also implements `SequencedCollection` and `SequencedSet`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider the following `TreeSet`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Relying on the default comparator for strings (that is, natural ordering, which
    compares two strings lexicographically), the sorted set will be *five*, *four*,
    *one*, *three*, *two*. So, the first element is *five*, and the last element is
    *two*. Getting the first/last element of a sorted set can be done via the `first()`
    and `last()` methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'So, the Sequenced Collections API doesn’t bring significant value in this case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding a new element to the first/last position in a sorted set is not possible.
    Since the order of elements is dictated by a comparator (natural ordering or an
    explicit `Comparator`), we cannot guarantee that an added element will land in
    the first or last position. For instance, the following code will not add the
    elements as we may expect (zero as the first element, and six as the last element):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: After applying the lexicographical criteria, the resulting sorted set will be
    *five*, *four*, *one*, *six*, *three*, *two*, *zero*. So, *zero* is actually the
    last element and *six* is the fourth element.
  prefs: []
  type: TYPE_NORMAL
- en: Trying to apply the Sequenced Collections API (`addFirst()`/`addLast()`) will
    throw an `UnsupportedOperationException` exception.
  prefs: []
  type: TYPE_NORMAL
- en: 'How about removing the first/last elements from a sorted set? Since we can
    get the first/last elements of a tree set, we can also remove them as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'The Sequenced Collections API implementation represents a shortcut of the previous
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'Reversing a sorted set can be done via `descendingSet()` or `descendingIterator()`.
    Both of them are available in `TreeSet`, so here is the usage of `descendingSet()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'It is much neater to rely on the Sequenced Collections API as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: Cool, right?!
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Sequenced Collections API to maps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Java maps (implementations of `Map`) may have a well-defined encounter order
    (for instance, `LinkedHashMap` (implementation of `Map` and `SequencedMap`), `TreeMap`
    (implementation of `SortedMap` and `SequencedMap`)) or an unstable order over
    time (for instance, `HashMap` implementation of `Map`). Exactly as in the case
    of `HashSet`, `HashMap` cannot take advantage of the Sequenced Collections API.
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Sequenced Collections API to LinkedHashMap
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`LinkedHashMap` is a map with a well-defined encounter order. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'Getting the first entry (`Map.Entry`) from a linked hash map can be done via
    the `Iterator`/`Stream` API as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'The same logic can be applied to get the first key (via `keyset()`) or the
    first value (via `values()`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'Getting the last entry/key/value requires code that is even uglier than the
    previous code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the Sequenced Collections API is really useful for avoiding such
    painful and cumbersome code. For instance, getting the first element from `LinkedHashMap`
    via the Sequenced Collections API can be done via `firstEntry()`/`lastEntry()`
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'While there is no `firstKey()`/`lastKey()` or `firstValue()`/`lastValue()`,
    we can get the first key/value via `sequencedKeySet()` and `sequencedValues()`
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'The same logic can be applied for entries as well via `sequencedEntrySet()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: But, obviously, using `firsEntry()`/`lastEntry()` is neater.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding a new entry on the last position is possible by simply calling `put(K
    key, V value)`. However, adding a new entry to the first position cannot be done
    that easily. But, we can create a new `LinkedHashMap` and put the new entry into
    it. Afterwards, we copy the entries from the original `LinkedHashMap` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting `slinkedhashmap` will contain the following entries: *0=zero,
    1=one, 2=two, 3=three, 4=four, 5=five, 6=six*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Obviously, this is far from an optimal and elegant approach. We would do better
    to rely on the Sequenced Collections API’s `putFirst()`/`putLast()` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: That’s quite neat!
  prefs: []
  type: TYPE_NORMAL
- en: 'Removing the first/last entry can be done in two steps. First, we get the first/last
    entry from `LinkedHashMap` via the `Iterator`/`Stream` APIs. Second, we rely on
    the `remove()` method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'Wow! That’s ugly, right?! Fortunately, the Sequenced Collections API exposes
    `pollFirstEntry()`/`pollLastEntry()` precisely for this purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'Reversing `LinkedHashMap` is also tricky. There are multiple cumbersome approaches,
    one of which is to create a new `LinkedHashMap`. Then, employ the `descendingIterator()`
    API to iterate the original `LinkedHashMap` from end to start while adding to
    the new `LinkedHashMap`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'This code is hard to digest! It would be better to use the Sequenced Collections
    API, which exposes the `reversed()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: That’s simple!
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Sequenced Collections API to SortedMap (TreeMap)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`SortedMap` extends `SequencedMap` and keeps its entries sorted by the natural
    ordering or by an explicit `Comparator`. Let’s give it a try on a `TreeMap` implementation
    of `SortedMap`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: 'Getting the first/last entry from `TreeMap` can be done via the `firstKey()`
    and `lastKey()` methods respectively, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'If we prefer the Sequenced Collections API, then we can use `firstEntry()`/`lastEntry()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, sorted maps can take advantage of `sequencedKeySet()`, `sequencedValues()`,
    and `sequencedEntrySet()` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: 'Since a sorted map keeps its entries ordered based on the natural ordering
    or an explicit `Comparator`, we cannot add an entry on the first/last position.
    In other words, what we want to insert on the first/last position may land anywhere
    in the sorted map depending on the `Comparator` logic. In this context, the Sequenced
    Collections API represented by `putFirst()`/`putLast()` will throw `UnsupportedOperationException`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'Removing the first/last entry can be done via the `remove()` methods as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: 'The Sequenced Collections API can significantly reduce this code via `pollFirstEntry()`
    and `pollLastEntry()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'Reversing a sorted map can be done via `descendingMap()` (or `descendingKeySet()`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: 'Or, we can keep things simple via the Sequenced Collections API, which exposes
    the `reversed()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: Done! As you have just seen, the Sequenced Collections API is quite useful and
    easy to use. Feel free to exploit it on other collections as well.
  prefs: []
  type: TYPE_NORMAL
- en: 119\. Introducing the Rope data structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Prerequisite**: Starting with this problem, we will cover a bunch of complex
    data structures that require previous experience with binary trees, lists, heaps,
    queues, stacks, and so on. If you are a novice in the data structure field, then
    I strongly recommend you postpone the following problems until you manage to read
    *The Complete Coding Interview Guide in Java*, which provides deep coverage of
    these preliminary topics.'
  prefs: []
  type: TYPE_NORMAL
- en: When we need to handle large amounts of text (for instance, if we were developing
    a text editor or a powerful text search engine), we have to deal with a significant
    number of complex tasks. Among these tasks, we have to consider appending/concatenating
    strings and memory consumption.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Rope data structure is a special binary tree that aims to improve string
    operations while using memory efficiently (which is especially useful for large
    strings). Its Big O goals are listed in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.12.png](img/B19665_05_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.13: Big O for Rope'
  prefs: []
  type: TYPE_NORMAL
- en: 'Being a binary tree, a Rope can be shaped via the classical `Node` class as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: 'Each node holds pointers to its children (left and right) and the total weight
    of the nodes in its left subtree (`weight`). Leaf nodes store small chunks of
    the large string (`str`). Here is a Rope for the text *I am a very cool rope*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.13.png](img/B19665_05_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.14: Rope sample'
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s implement the main operations of a Rope, starting with searching
    by index. `Rope` is a static class containing all the following operations.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing indexAt(Node node, int index)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `indexAt(Node node, int index)` method attempts to find the character at
    the given `index`. This is a recursive process based on a simple rule, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: If `index > (weight - 1)` then `index = index - weight` and move to the right
    node.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `index < weight` then just move to the left node.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These two steps are repeated until we hit a leaf node and we return the character
    at the current `index`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s assume that we want to return the character from `index` 5, which is
    `e` (see *Figure 5.14*):'
  prefs: []
  type: TYPE_NORMAL
- en: Starting from the root, we have `index` = 5, `index` < 8, so we move left.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, `index` = 5, 5 > 3, so `index` = 5 – 3 = 2 and we move right.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, `index` = 2, 2 > 1, so `index` = 2 – 1 = 1 and we move right.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The right node is a leaf node, so we return `charAt(1)`, which is `e`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 5.14.png](img/B19665_05_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.15: Implementing indexAt()'
  prefs: []
  type: TYPE_NORMAL
- en: 'In code form, this algorithm is quite simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: Next, let’s talk about concatenating two Ropes.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing concat(Node node1, Node node2)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Concatenating two Ropes (`node1` and `node2`) is a straightforward step-by-step
    algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new root node that has the weight of the leaf nodes in `node1`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The new root node has `node1` as its left child and `node2` as its right child.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optional rebalancing (this isn’t implemented here, but takes the form of classic
    binary tree rebalancing).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram represents the concatenation of two Ropes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.15.png](img/B19665_05_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.16: Concatenating two Ropes'
  prefs: []
  type: TYPE_NORMAL
- en: 'In code form, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: Next, let’s insert a new node.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing insert(Node node, int index, String str)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to insert a piece of a string at a certain index in the original string,
    we have to split the original string and perform two concatenations. The algorithm
    has three steps, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Split the original string at a given index into two strings, `s1` and `s2`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concatenate `s1` and the given `str` into `s3`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concatenate `s1` with the new `s3`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In code form, we get the following implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: Next, let’s see how to delete a substring.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing delete(Node node, int start, int end)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Deleting a substring from the original string between `start` and `end` requires
    two splits and one concatenation. The algorithm consists of three steps, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Split the original string at `start` into `s1` and `s2`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Split `s2` at `end` into `s3` and `s4`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concatenate `s1` and `s4`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In code form, we have the following implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: Finally, let’s talk about splitting a Rope.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing split(Node node, int index)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Splitting a Rope into two Ropes is an operation that should come with two considerations:'
  prefs: []
  type: TYPE_NORMAL
- en: The split should take place at the last character (index).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The split should take place at the middle character (index).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both of these cases are considered in the implementation listed in the bundled
    code. Since this code is simple but quite large, we skipped it here for brevity.
  prefs: []
  type: TYPE_NORMAL
- en: 120\. Introducing the Skip List data structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Skip List data structure is a probabilistic data structure built on top
    of a linked list. A Skip List uses an underlying linked list to keep a sorted
    list of items, but it also provides the capability to skip certain items in order
    to speed up operations such as insert, delete, and find. Its Big O goals are listed
    in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.16.png](img/B19665_05_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.17: Big (O) for Skip List'
  prefs: []
  type: TYPE_NORMAL
- en: 'A Skip List has two types of layers. The base layer (or the lower layer, or
    layer 0) consists of a regular linked list that holds the sorted list of all items.
    The rest of the layers contain sparse items and act as an “express line” meant
    to speed up the search, insert, and delete items. The following figure helps us
    to visualize a Skip List with three layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.17.png](img/B19665_05_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.18: Skip List sample'
  prefs: []
  type: TYPE_NORMAL
- en: So, this Skip List holds on layer 0 the items 1, 2, 3, 4, 5, 8, 9, 10, 11, and
    34 and has two express lines (layer 1 and layer 2) containing sparse items. Next,
    let’s see how we can find a certain item.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing contains(Integer data)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Searching certain items starts on layer *n*, continues layer *n*-1, and so on
    until layer 0\. For instance, let’s assume that we want to find item 11.
  prefs: []
  type: TYPE_NORMAL
- en: We start on layer 2 and continue running on this layer until we find a node
    >= 11\. Since the value 11 doesn’t exist on layer 2, we search for an item less
    than 11 and we find 10.
  prefs: []
  type: TYPE_NORMAL
- en: We get down on layer 1 and continue searching. Based on the same logic we find
    item 10 again. Layer 1 doesn’t contain item 11 either. If it had contained it,
    then we would have stopped the search.
  prefs: []
  type: TYPE_NORMAL
- en: 'We go down again, this time to layer 0 (the base layer containing all items),
    and continue searching until we find item 11\. The following figure depicts our
    search path:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.18.png](img/B19665_05_19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.19: Finding an item in a Skip List'
  prefs: []
  type: TYPE_NORMAL
- en: By following the highlighted path, we can see that we skipped a significant
    number of items until we found item 11.
  prefs: []
  type: TYPE_NORMAL
- en: 'In code form, this operation can be implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: Next, let’s see how we can insert a new item.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing insert(Integer data)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Inserting a new item takes place on a randomly chosen layer. In other words,
    the layer of an item is chosen randomly at insertion time. We can insert it into
    an existing layer or create a new layer specially for this new item. We can create
    new layers until we hit an arbitrary chosen `MAX_NUMBER_OF_LAYERS` (we have `MAX_NUMBER_OF_LAYERS`
    = 10).
  prefs: []
  type: TYPE_NORMAL
- en: 'During the insertion algorithm, we apply the following steps to search for
    the proper place for the item to insert:'
  prefs: []
  type: TYPE_NORMAL
- en: If the item of the next node is less than the item to insert, then we continue
    moving forward on the same layer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the item of the next node is greater than the item to insert, then we save
    the pointer to the current node and continue by moving one layer down. The search
    continues from here.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At some point, we will reach the base layer (layer 0). Since this layer holds
    all items, we know for sure that we will find a slot here for the new item.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following figure, item 7 was inserted on Layer 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.19.png](img/B19665_05_20.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.20: Inserting an item in a Skip List'
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation is straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: The `incrementLayerNo()` is a method that randomly decides the layer on which
    the new item will be inserted.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing delete(Integer data)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Deleting an item is a simple operation. We start from the top layer, find the
    item to delete, and then delete it. The challenge is to pay attention to only
    eliminating the item by correctly linking the remaining nodes. The implementation
    is simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: Challenge yourself to implement a Skip List on top of the Java built-in `LinkedList`.
    It will be fun and give you the chance to explore the Skip List data structure
    a step further.
  prefs: []
  type: TYPE_NORMAL
- en: 121\. Introducing the K-D Tree data structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A K-D Tree (also referred to as a K-dimensional tree) is a data structure that
    is a flavor of **Binary Search Tree** (**BST**) dedicated to holding and organizing
    points/coordinates in a K-dimensional space (2-D, 3-D, and so on). Each node of
    a K-D Tree holds a point representing a multi-dimensional space. The following
    snippet shapes a node of a 2-D Tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: Instead of a `double[]` array, you may prefer `java.awt.geom.Point2D`, which
    is dedicated to representing a location in *(x, y)* coordinate space.
  prefs: []
  type: TYPE_NORMAL
- en: 'Commonly, K-D Trees are useful for performing different kinds of searches such
    as nearest-neighbor searches and range queries. For instance, let’s assume a 2-D
    space and a bunch of *(x, y)* coordinates in this space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: 'We can represent these coordinates using the well-known X-Y coordinates system,
    but we can also store them in a K-2D Tree as in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.20.png](img/B19665_05_21.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.21: A 2D space represented in X-Y coordinates system and K-2D Tree'
  prefs: []
  type: TYPE_NORMAL
- en: But, how did we build the K-D Tree?
  prefs: []
  type: TYPE_NORMAL
- en: Inserting into a K-D Tree
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We insert our coordinates (`cords`) one by one starting with `coords[0]` = (3,5).
    The (3,5) pair becomes the root of the K-D Tree. The next pair of coordinates
    is (1,4). We compare *x* of the root with *x* of this pair and we notice that
    1 < 3, which means that (1,4) becomes the left child of the root. The next pair
    is (5,4). At the first level, we compare the *x* of the root with 5 and we see
    that 5 > 3, so (5,4) becomes the right child of the root. The following figure
    illustrates the insertion of (3,5), (1,4), and (5,4).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.21.png](img/B19665_05_22.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.22: Inserting (3,5), (1,4), and (5,4)'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we insert the pair (2,3). We compare the *x* components of (2,3) and (3,5)
    and we see that 2 < 3, so (2,3) goes to the left of the root. Next, we compare
    the *y* component of (2,3) and (1,4) and we see that 3 < 4, so (2,3) goes to the
    left of (1,4).
  prefs: []
  type: TYPE_NORMAL
- en: Next, we insert the pair (4,2). We compare the *x* components of (4,2) and (3,5)
    and we see that 4 > 3, so (4,2) goes to the right of the root. Next, we compare
    the *y* component of (4,2) and (5,4) and we see that 2 < 4, so (4,2) goes to the
    left of (5,4). The following figure illustrates the insertion of (2, 3), and (4,2).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.22.png](img/B19665_05_23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.23: Inserting (2,3) and (4,2)'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we insert the pair (3,2). We compare the *x* components of (3,2) and (3,5)
    and we see that 3 = 3, so (3,2) goes to the right of the root. Next, we compare
    the *y* component of (3,2) and (5,4) and we see that 2 < 4, so (3,2) goes to the
    left of (5,4). Next, we compare the *x* component of (3,2) and (4,2) and we see
    that 3 < 4, so (3,2) goes to the left of (4,2).
  prefs: []
  type: TYPE_NORMAL
- en: Next, we insert the pair (5,2). We compare the *x* components of (5,2) and (3,5)
    and we see that 5 > 3, so (5,2) goes to the right of the root. Next, we compare
    the *y* component of (5,2) and (5,4) and we see that 2 < 4, so (5,2) goes to the
    left of (5,4). Next, we compare the *x* component of (5,2) and (4,2) and we see
    that 5 > 4, so (5,2) goes to the right of (4,2). The following figure outlines
    the insertion of (3,2), and (5,2).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.23.png](img/B19665_05_24.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.24: Inserting (3,2) and (5,2)'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we insert the pair (2,1). We compare the *x* components of (2,1) and (3,5)
    and we see that 2 < 3, so (2,1) goes to the left of the root. Next, we compare
    the *y* component of (2,1) and (1,4) and we see that 1 < 4, so (2,1) goes to the
    left of (1,4). Next, we compare the *x* component of (2,1) and (2,3) and we see
    that 2 = 2, so (2,1) goes to the right of (2,3).
  prefs: []
  type: TYPE_NORMAL
- en: Next, we insert the pair (2,4). We compare the *x* components of (2,4) and (3,5)
    and we see that 2 < 3, so (2,4) goes to the left of the root. Next, we compare
    the *y* component of (2,4) and (1,4) and we see that 4 = 4, so (2,4) goes to the
    right of (1,4).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we insert the pair (2,5). We compare the *x* components of (2,5) and
    (3,5) and we see that 2 < 3, so (2,5) goes to the left of the root. Next, we compare
    the *y* component of (2,5) and (1,4) and we see that 5 > 4, so (2,5) goes to the
    right of (1,4). Next, we compare the *x* component of (2,5) and (2,4) and we see
    that 2 = 2, so (2,5) goes to the right of (2,4). The following figure illustrates
    the insertion of (2,1), (2,4), and (2,5).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.24.png](img/B19665_05_25.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.25: Inserting (2,1), (2,4), and (2,5)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Done! So inserting has two simple rules:'
  prefs: []
  type: TYPE_NORMAL
- en: We compare components alternatively starting with *x*. At level one, we compare
    *x*, at level two, we compare *y*, at level three we compare *x*, at level four
    we compare *y*, and so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When comparing (*x1*, *y1*) with (*x2*, *y2*), if *x2*>= *x1* or *y2*>= *y1*
    (depending on which component is being compared) then the (*x2*,*y2*) node goes
    to the right (*x1*,*y1*), otherwise to the left.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Based on these statements, the implementation of a 2-D model is straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: Another approach for inserting in a K-D Tree relies on a sorting algorithm for
    sorting the coordinates. This implementation is not provided here.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the nearest neighbor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finding the nearest neighbor is the classical operation performed on a K-D
    Tree. We have a given point (*x*,*y*), and we want to know what the nearest point
    is from the K-D Tree. For instance, we may want to find the nearest neighbor of
    (4,4) – check the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.25.png](img/B19665_05_26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.26: Find the nearest neighbor of (4,4)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The nearest neighbor of (4,4) is (5,4). In a nutshell, finding the nearest
    neighbor is about finding the shortest distance from the given point to any other
    point present in the K-D Tree. We start from the root and compute the distance
    between the given point (or target node) and the current node. The shortest distance
    wins. The implementation starts like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: 'The `nearest()` method is a recursive solution for finding the minimum distance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: In the bundled code, you can find the missing parts of the preceding code, such
    as the method for computing the distance between two points.
  prefs: []
  type: TYPE_NORMAL
- en: Searching and deleting items from a K-D Tree is similar to performing these
    operations on a BST, so nothing new.
  prefs: []
  type: TYPE_NORMAL
- en: Challenge yourself to implement a 3-D Tree.
  prefs: []
  type: TYPE_NORMAL
- en: 122\. Introducing the Zipper data structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Zipper data structure is meant to facilitate cursor-like navigation capabilities
    over another data structure such as a tree. Moreover, it may provide capabilities
    for manipulating the tree like adding nodes, removing nodes, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: The Zipper is created on the top of a tree and is characterized by the current
    position of the cursor and the current range or the current visibility area. At
    any moment, the Zipper doesn’t see or act on the entire tree; its actions are
    available only on a subtree or a range of the tree relative to its current position.
    The modification accomplished via the Zipper is visible only in this range, not
    in the entire tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to navigate and determine the current range, a Zipper must be aware
    of the tree structure. For instance, it must be aware of all the children of each
    node, which is why we start from an interface that must be implemented by any
    tree that wants to take advantage of a Zipper:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: 'A tree that implements `Zippable` ensures that it exposes its children to the
    Zipper. For instance, a tree `Node` implementation can be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: 'The following figure illustrates the characteristics of a Zipper at some moment
    in time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.26.png](img/B19665_05_27.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.27: The Zipper position and range on an arbitrary tree'
  prefs: []
  type: TYPE_NORMAL
- en: The Zipper’s current position is represented by the node labeled **55** – the
    Zipper cursor is on position 55\. The highlighted gray area is the zipper’s current
    range/visibility. Everything that happens in this area is invisible outside of
    it. From the current position, the Zipper can move `down()`, `up()`, `left()`,
    and `right()`. Every move will refine the Zipper range accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the Zipper is applied to a tree, each node of the tree (`Node`) becomes
    a Zipper-node, represented here by the `ZipNode` class. As you can see in the
    following code, a `ZipNode` acts as a wrapper of a `Node` and represents the unit
    of work for the Zipper:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: 'The remaining code handles the initialization of children in a lazy fashion
    (on demand):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: All the Zipper operations act on a `ZipNode`, not on a `Node`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we have the Zipper range implementation, which basically defines the
    gray part of *Figure 5.27*. We have the parent node and the left/right siblings
    of the current range:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: '`ZipperRange` works in tandem with `Cursor`, which contains the implementation
    of the Zipper actions (`down()`, `up()`, `left()`, `right()`, `rightMost()`, `leftMost()`,
    `clear()`, `add()`, `addAll()`, `insertLeft()`, `insertRight()`, `remove()`, `removeLeft()`,
    `removeRight()`, and so on):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: Since this code is significantly large, the remainder was skipped here. You
    can find it in the bundled code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we have the `Zipper` class. This class is used for creating a Zipper
    via the `createZipper()` method. It is also used for recreating/updating the tree
    based on the modifications done via the Zipper. This is done in the `unwrapZipper()`
    method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: In the bundled code, you can find the complete implementation and an example
    of using the Zipper on a given tree.
  prefs: []
  type: TYPE_NORMAL
- en: 123\. Introducing the Binomial Heap data structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Binomial Heap data structure is a set composed of Binomial Trees. Each Binomial
    Tree is a Min Heap, which means that it follows the *min-heap* property. In a
    nutshell, a heap is a Min Heap if its items are in descending order, meaning that
    the minimum item is the root (more details are available in *The Complete Coding
    Interview Guide in Java* book).
  prefs: []
  type: TYPE_NORMAL
- en: 'In a nutshell, a Binomial Tree is ordered and typically defined in a recursive
    fashion. It is denoted as B[k], where k implies the following properties:'
  prefs: []
  type: TYPE_NORMAL
- en: A Binomial Tree has 2^k nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The height of a Binomial Tree is equal to k.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The root of a Binomial Tree has the degree k, which is the greatest degree.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A B[0] Binomial Tree has a single node. A B[1] Binomial Tree has two B[0] Trees,
    and one of them is a left subtree of the other one. A B[2] Tree has two B[1],
    one of which is the left subtree of the other. In general, a B[k] Binomial Tree
    contains two B[k-1] Binomial Trees, one of which is the left subtree of the other
    (two B[k-1] Trees are linked to the composed B[k]). In the following figure, you
    can see B[0], B[1], B[2], B[3], and B[4]:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.27.png](img/B19665_05_28.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.28: B[0]-B[4] Binomial Trees'
  prefs: []
  type: TYPE_NORMAL
- en: 'The goals of a Binomial Heap from a Big O perspective are listed in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.28.png](img/B19665_05_29.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.29: Big O for Binomial Heap'
  prefs: []
  type: TYPE_NORMAL
- en: In the following figure, you can see a sample of a Binomial Heap. The roots
    of the Binomial Trees (here, 9, 1, and 7) within a Binomial Heap are represented
    via a linked list referred to as the *root list*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.27.png](img/B19665_05_30.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.30: Binomial Heap sample'
  prefs: []
  type: TYPE_NORMAL
- en: In other words, as you can easily intuit from this figure, a Binomial Heap is
    an extension (or a flavor) of a Binary Heap, which provides high performance for
    merging or unioning two heaps and is a perfect fit for the task of implementing
    priority queues.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on this figure, we can define the skeleton of a Binomial Heap as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: 'If we represent the relevant part of a `Node` as a diagram, we obtain the following
    figure (here, you can see the internal structure of a `Node` for items 11 and
    25):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.30.png](img/B19665_05_31.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.31: Expanding a Node'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the main structure of a Binomial Heap, let’s cover several
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing insert(int key)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Inserting a new key into a Binomial Heap is a two-step operation. In the first
    step, we create a new heap containing only the given key (a `Node` wrapping the
    given key). Second, we union the current heap with this newly created heap as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: The union operation is depicted as the last operation of this problem.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing findMin()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finding the minimum key of a Binomial Heap requires us to loop through the
    *root list* (which is a linked list) and find the smallest key. This can be optimized
    from *O(log n)* to *O(1)* if we decide to maintain a pointer to the minimum root.
    However, the *O(log n)* approach is listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: Since our Binomial Heap holds primitive integers, we use `Integer.MIN_VALUE`
    as an equivalent to “no value.” If you adjust the implementation to use `Integer`
    or generic `T`, then you can replace `Integer.MIN_VALUE` with `null`.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing extractMin()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before extracting the minimum key, we have to find it. Afterward, we delete
    it. Finally, we have to union the resulting subtrees as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: 'The `deleteTreeRoot()` is a helper method useful for deleting the given root
    and performing a union on the remaining sub-trees:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: Implementing decreaseKey(int key, int newKey)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Decreasing a key value means replacing an existing key with a smaller one.
    When this operation happens, the new key may be smaller than the key of its parent,
    which means that the *min-heap* property is violated. This scenario requires us
    to swap the current node with its parent, its parent with its grandparent, and
    so on until we reestablish compliance with the *min-heap* property. The implementation
    starts as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: 'The `goUp()` method is a helper method used to reestablish the *min-heap* property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: As you will see next, this helper is useful for deleting a node as well.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing delete(int key)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Deleting a key is done by first finding the corresponding `Node` and decreasing
    it to the minimum (`Integer.MIN_VALUE`). Next, we delete the minimum from the
    heap and connect the remaining sub-trees. The implementation relies on the `goUp()`
    and `deleteTreeRoot()` helpers listed in the previous sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: Finally, let’s talk about union heaps.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing unionHeap(BinomialHeap heap)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Consider two Binomial Heaps (H1 and H2). The goal of the union operation is
    to create H3 by unifying H1 with H2\. Let’s assume that H1 (having a conventional
    string representation used by our application as 31 22 [ 40 ] 8 [ 13 [ 24 ] 11
    ]) and H2 (55 24 [ 45 ] 3 [ 7 [ 29 [ 40 ] 9 ] 5 [ 37 ] 18 ]) are those from the
    following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.31.png](img/B19665_05_32.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.32: Two Binomial Heaps, H1 and H2'
  prefs: []
  type: TYPE_NORMAL
- en: 'The contract of unification starts with an initial merging of H1 and H2 in
    the order of their degrees. In our case, the merge operation produces the following
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.32.png](img/B19665_05_33.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.33: Merging H1 and H2'
  prefs: []
  type: TYPE_NORMAL
- en: 'This operation is performed by the following helper method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to combine the Binomial Trees of the same order. While we traverse
    the roots of the merged heaps (here, 31, 55, 22, 24, 8, and 3), we use three pointers
    denoted as PREV-X (the previous node of the current node), X (the current node),
    and NEXT-X (the next node of the current node). These pointers help us to solve
    the following four cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Case 1*: X and NEXT-X have different orders. In this case, we just move the
    X pointer ahead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Case 2*: X, NEXT-X, and NEXT-NEXT-X have the same order. In this case, we
    just move the X pointer ahead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Case 3*: X and NEXT-X have the same order, different from NEXT-NEXT-X. And
    if X.KEY<= NEXT-X.KEY, then NEXT-X becomes the child of X.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Case 4*: X and NEXT-X have the same order, different from NEXT-NEXT-X. And
    if X.KEY>NEXT-X.KEY, then X becomes the child of NEXT-X.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we apply these four cases to our example, we notice that after merging H1
    and H2, we are in *Case 3* since X and NEXT-X have the same order (B[0]), which
    is different from the order of NEXT-NEXT-X (which is B[1]) and X.KEY = 31 < 55
    = NEXT-X.KEY. So, NEXT-X becomes the child of X, as in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.33.png](img/B19665_05_34.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.34: Applying Case 3'
  prefs: []
  type: TYPE_NORMAL
- en: 'Going further, we notice that X, NEXT-X, and NEXT-NEXT-X have the same order
    B[1]. This means that we are in *Case 2*, so we have to move the X pointer forward,
    as in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.34.png](img/B19665_05_35.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.35: Applying Case 2'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we are in *Case 3* again. We see that X and NEXT-X have the same order
    (B[1]), which is different from the order of NEXT-NEXT-X (B[2]). And, we also
    see that X.KEY = 22 < 24 = NEXT-X.KEY, so NEXT-X becomes the child of X, as in
    the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.35.png](img/B19665_05_36.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.36: Applying Case 3 again'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we are in *Case 4*. We see that X and NEXT-X have the same order (B[2])
    which is different from the order of NEXT-NEXT-X (B[3]). And, we also see that
    X.KEY = 22 > 8 = NEXT-X.KEY, so X becomes the child of NEXT-X, as in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.36.png](img/B19665_05_37.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.37: Applying Case 4'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we are in *Case 4* again. We see that X and NEXT-X have the same order
    (B[3]), which is different from the order of NEXT-NEXT-X (null). And, we also
    see that X.KEY = 8 > 3 = NEXT-X.KEY, so X becomes the child of NEXT-X, as in the
    following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.37.png](img/B19665_05_38.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.38: Applying Case 4 again'
  prefs: []
  type: TYPE_NORMAL
- en: At this point, none of the four cases is valid so this is the final form of
    the Binomial Heap.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on this example, we can implement the union operation as follows (notice
    the highlighted cases in the following code):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: 'The `linkNodes()` method is a helper method that links the current node with
    the next node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: Done! You can find the complete application in the bundled code.
  prefs: []
  type: TYPE_NORMAL
- en: 124\. Introducing the Fibonacci Heap data structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Fibonacci Heap is a flavor of Binomial Heap with excellent performance in
    *amortized time* for operations such as insert, extract minimum, and merge. It
    is an optimal choice for implementing priority queues. A Fibonacci Heap is made
    of trees, and each tree has a single root and multiple children arranged in a
    heap-ordered fashion. The root node with the smallest key is always placed at
    the beginning of the list of trees.
  prefs: []
  type: TYPE_NORMAL
- en: It is called a Fibonacci Heap because each tree of order *k* has at least F[k+2]
    nodes, where F[k+2] is the (*k*+2)^(th) Fibonacci number.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following figure, you can see a Fibonacci Heap sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.39.png](img/B19665_05_39.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.39: Fibonacci Heap sample'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main operations in a Fibonacci Heap are (Big O represents the *amortized
    time*): insert (O(1)), decrease key (O(1)), find the minimum (O(1)), extract minimum
    (O(log n)), deletion (O(log n)), and merge (O(1)). You can find an implementation
    of these operations in the bundled code.'
  prefs: []
  type: TYPE_NORMAL
- en: 125\. Introducing the Pairing Heap data structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Pairing Heap is a flavor of Binomial Heap with the capability of self-adjusting/rearranging
    to keep itself balanced. It has very good performance in *amortized time* and
    is a good fit for the task of implementing priority queues.
  prefs: []
  type: TYPE_NORMAL
- en: A Pairing Heap is a pairing tree with a root and children. Each heap of a Pairing
    Heap represents a value and has a set of children that are also heaps. The value
    of a heap is always less than (*min-heap* property) or greater than (*max-heap*
    property) the value of its children heaps.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following figure, you can see a Min Pairing Heap:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.38.png](img/B19665_05_40.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.40: A Min Pairing Heap sample'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main operations in a Pairing Heap are: insert (O(1)), decrease key (actual
    time: O(1), amortized time O(log n)), find the minimum (O(1)), extract the minimum
    (actual time: O(n), amortized time (O (log n)), and merge (actual time: O(1),
    amortized time (O(log n)). You can find an implementation of these operations
    in the bundled code.'
  prefs: []
  type: TYPE_NORMAL
- en: 126\. Introducing the Huffman Coding data structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Huffman Coding algorithm was developed by David A. Huffman in 1950 and can
    easily be understood via an example. Let’s assume that we have the string shown
    in the following figure.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.40.png](img/B19665_05_41.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.41: Initial string'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s assume that each character needs 8 bits to be represented. Since we have
    14 characters, we can say that we need 8*14=112 bits to send this string over
    a network.
  prefs: []
  type: TYPE_NORMAL
- en: Encoding the string
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The idea of Huffman Coding is to compress (shrink) such strings to a smaller
    size. For this, we create a tree of character frequencies. A `Node` of this tree
    can be shaped as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: 'For instance, the following figure shows the calculation of the frequency of
    each character from our string in ascending order:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.41.png](img/B19665_05_42.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.42: Calculating the frequency of each character'
  prefs: []
  type: TYPE_NORMAL
- en: 'After sorting, these characters are stored in a **priority queue** (**PQ**).
    Each character will become a leaf node in a tree by following several steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 1*: Create a node with two children (a partial tree). The left child
    holds the minimum frequency, and the right child holds the next minimum frequency.
    The node itself holds the sum of its left and right children.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Step 2*: Remove these two frequencies from the PQ.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Step 3*: Insert this partial tree into the PQ.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Step 4*: Repeat steps 1-3 until the PQ is empty and we obtain a single tree
    from these partial trees.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we apply *steps 1-3* twice, we obtain the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.42.png](img/B19665_05_43.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.43: Applying steps 1-3 twice'
  prefs: []
  type: TYPE_NORMAL
- en: 'In code form, these steps appear as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: 'By repeating these steps until the PQ is empty, we obtain the final tree. Next,
    for each node of this tree that is not a leaf, we assign the value 0 to the left
    edge and 1 to the right edge. This is the encoding step that can be coded as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: 'The final result looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.43.png](img/B19665_05_44.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.44: The final tree'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, sending this tree over the network will send the compressed string. The
    next figure gives us the new size of this string:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.44.png](img/B19665_05_45.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.45: The size of the compressed string'
  prefs: []
  type: TYPE_NORMAL
- en: So, we reduce the size of the string from 112 bits to 41 bits. This is the compressed
    or encoded string.
  prefs: []
  type: TYPE_NORMAL
- en: Decoding the string
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Decoding the string is a simple step. We take each code and traverse the tree
    to find the assigned character. For instance, we take *0111* and we find *d*,
    we take *110* and we find *a*, and so on. Decoding can be implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: After processing all of the code, we should obtain the decoded string.
  prefs: []
  type: TYPE_NORMAL
- en: 127\. Introducing the Splay Tree data structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Splay Tree is a flavor of **Binary Search Tree** (**BST**). Its particularity
    consists of the fact that it is a self-balancing tree that places the recently
    accessed items at the root level.
  prefs: []
  type: TYPE_NORMAL
- en: The *splaying* operation or *splaying* an item is a process that relies on tree
    rotations meant to bring the item to the root position. Every operation on the
    tree is followed by *splaying*.
  prefs: []
  type: TYPE_NORMAL
- en: So, the goal of *splaying* is to bring the most recently used item closer to
    the root. This means that subsequent operations on these items will be performed
    faster.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *splaying* operation relies on six rotations:'
  prefs: []
  type: TYPE_NORMAL
- en: Zig rotation – the tree rotates to the right (every node rotates to the right)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zag rotation – the tree rotates to the left (every node rotates to the left)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zig-Zig rotation – double Zig rotation (every node moves twice to the right)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zag-Zag rotation – double Zag rotation (every node moves twice to the left)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zig-Zag rotation – a Zig rotation followed by a Zag
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zag-Zig rotation – a Zag rotation followed by a Zig
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the bundled code, you can find an implementation of a Splay Tree. Moreover,
    you can use this visualizer: [https://www.cs.usfca.edu/~galles/visualization/SplayTree.html](https://www.cs.usfca.edu/~galles/visualization/SplayTree.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 128\. Introducing the Interval Tree data structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An Interval Tree is a flavor of **Binary Search Tree** (**BST**). Its particularity
    consists of the fact that it holds intervals of values. Beside the interval itself,
    a `Node` of an Interval Tree holds the maximum value of the current interval and
    the maximum value of the subtree rooted with this `Node`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In code form, an Interval Tree is shaped as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s consider that we have the following intervals of integers: [4, 7], [1,
    10], [7, 23], [6, 8], [9, 13], and [2, 24].'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing insert(Interval interval)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first interval ([4, 7]) becomes the root of the tree. Next, we compare the
    interval [1, 10] to [4, 7] by comparing the left side of the interval. Since 1
    < 4, the interval [1, 10] goes to the left of the root.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we compare the interval [7, 23] with [4, 7]. Since 7 > 4, the interval
    [7, 23] goes to the right of [4, 7]. Applying the same logic for the rest of the
    interval will result in the following tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.45.png](img/B19665_05_46.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.46: The interval tree'
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous logic (insert operation, O(log n)) is materialized in code form
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: Other operations specific to an interval tree are searching the intervals that
    overlap the given interval (O(log n)) and deleting (O (log n)). You can find the
    implementations in the bundled code.
  prefs: []
  type: TYPE_NORMAL
- en: 129\. Introducing the Unrolled Linked List data structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An Unrolled Linked List is a flavor of a linked list that stores arrays (multiple
    items). Each node of an Unrolled Linked List can store an array. It is like combining
    the powers of an array with those of a linked list. In other words, an Unrolled
    Linked List is a data structure with a low memory footprint and high performance
    on insertion and deletion.
  prefs: []
  type: TYPE_NORMAL
- en: Insertion and deletion from an Unrolled Linked List have different implementations.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, we can insert arrays (`insert(int[] arr)`), which means that for
    each insertion, we create a new node and insert that array into it.
  prefs: []
  type: TYPE_NORMAL
- en: Deleting an item is equivalent to removing the item from the specified index
    in the proper array. If, after deletion, the array is empty, then it is removed
    from the list as well.
  prefs: []
  type: TYPE_NORMAL
- en: Another approach assumes that the Unrolled Linked List has a fixed capacity
    (each node holds an array of this capacity). Further, we insert items one by one
    by following a low-water mark of 50%. This means that if we insert an item that
    cannot be added to the current node (array), then we create a new node and insert
    into it half of the original node’s items plus this item.
  prefs: []
  type: TYPE_NORMAL
- en: Deleting an item uses the reverse logic. If the number of items in a node drops
    below 50%, then we move the items from the neighboring array over to get back
    to a low-water mark above 50%. If the neighboring array also drops below 50%,
    then we have to merge these two nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find both approaches in the bundled code. On the other hand, you can
    challenge yourself to provide an Unrolled Linked List implementation that extends
    the JVM Collections API. You can start from either of the following two approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs: []
  type: TYPE_PRE
- en: Add this implementation to your GitHub portfolio and you’ll impress your interviewer.
  prefs: []
  type: TYPE_NORMAL
- en: 130\. Implementing join algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Join algorithms are typically used in databases, mainly when we have two tables
    in a one-to-many relationship and we want to fetch a result set containing this
    mapping based on a join predicate. In the following figure, we have the `author`
    and `book` tables. An author can have multiple books and we want to join these
    tables to obtain a result set as the third table.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.46.png](img/B19665_05_47.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.47: Joining two tables (author and book)'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three popular join algorithms for solving this problem: Nested Loop
    Join, Hash Join, and Sort Merge Join. While databases are optimized to choose
    the most appropriate join for the given query, let’s try to implement them in
    plain Java on the following two tables expressed as records:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: 'Our goal is to join the `Author` and `Book` records by matching the `Author.authorId`
    and `Book.authorId` attributes. The result should be a projection (`ResultRow`)
    that contains `authorId`, `name`, `title`, and `bookId`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: Next, let’s talk about Nested Loop Join.
  prefs: []
  type: TYPE_NORMAL
- en: Nested Loop Join
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Nested Loop Join algorithm relies on two loops that traverse both relations
    to find records that match the joining predicate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: The time complexity of this algorithm is O(n*m) where *n* is the size of `authorsTable`
    and *m* is the size of `booksTable`. This is quadratic complexity, which makes
    this algorithm useful only for small datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Hash Join
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As the name suggests, Hash Join relies on *hashing*. So, we have to create
    a hash table from the authors table (the table with fewer records) and afterward
    we loop through the books table to find their authors in the created hash table
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE156]'
  prefs: []
  type: TYPE_PRE
- en: The time complexity of this algorithm is O(n+m), where *n* is the size of `authorsTable`
    and *m* is the size of `booksTable`. So, this is better than Nested Loop Join.
  prefs: []
  type: TYPE_NORMAL
- en: Sort Merge Join
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As the name suggests, Sort Merge Join starts by sorting the two tables by the
    attribute of the join. Afterward, we loop the two tables and apply the join predicate
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE157]'
  prefs: []
  type: TYPE_PRE
- en: The time complexity of the Sort Merge Join algorithm is O(nlog(n) + mlog(m))
    where *n* is the size of `authorsTable` and *m* is the size of `booksTable`. So,
    this is better than Nested Loop Join and Hash Join.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered a lot of interesting topics. We started with the
    new Vector API for empowering parallel data processing, then we continued with
    a bunch of cool data structures like Zipper, K-D Trees, Skip List, Binomial Heap,
    and so on. We finished with a nice overview of the three main join algorithms.
    Moreover, we’ve covered the JDK 21 Sequenced Collections API.
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://discord.gg/8mgytp5DGQ](https://discord.gg/8mgytp5DGQ )'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code1139613064111216156.png)'
  prefs: []
  type: TYPE_IMG
