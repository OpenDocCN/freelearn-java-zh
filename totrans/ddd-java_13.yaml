- en: '*Chapter 10*: Beginning the Decomposition Journey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A distributed system is one in which the failure of a computer you didn’t even
    know existed can render your own computer unusable.
  prefs: []
  type: TYPE_NORMAL
- en: — Leslie Lamport
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have a working application for **Letter of Credit** (**LC**) application
    processing, which is bundled along with other components as a single package.
    Although we have discussed the idea of subdomains and bounded contexts, the separation
    between these components is logical rather than physical. Furthermore, we have
    primarily focused on the *LC Application Processing* aspect of the overall solution.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will look at how to extract the LC Application Processing
    bounded context into a component that is physically disparate and, hence, enables
    us to deploy them independently of the rest of the solution. We will discuss the
    various options that are available to us, the rationale for choosing a given option,
    and the implications that we need to be cognizant of.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Continuing our design journey
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decomposing our monolith
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changes to frontend interactions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changes in database interactions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have learned what it takes to design well-factored
    APIs—both remote procedure calls and event-based. For event-based APIs, you will
    gain an understanding of the various guarantees that might be needed to create
    robust solutions. Finally, you will also learn how to manage consistency when
    using multiple data stores.
  prefs: []
  type: TYPE_NORMAL
- en: Continuing our design journey
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the preceding chapters, we had a solution for LC Application Processing
    that worked as an in-process component of the remainder of the overall application.
    From a logical perspective, our realization of the LC application is similar to
    the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – The current view of the LC application monolith'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_10.1.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.1 – The current view of the LC application monolith
  prefs: []
  type: TYPE_NORMAL
- en: Although the **LC Application Processing** component is loosely coupled with
    the rest of the application, we are still required to coordinate with several
    other teams to realize the business value. This could inhibit our ability to innovate
    at a pace that is faster than the slowest contributor in the ecosystem. This is
    because all teams need to be production-ready before a deployment can happen.
    This can be further exacerbated by the fact that individual teams might be at
    different levels of engineering maturity. Let’s look at some options regarding
    how we can achieve a level of independence from the rest of the ecosystem by physically
    decomposing our components into distinctly deployable artifacts.
  prefs: []
  type: TYPE_NORMAL
- en: Decomposing our monolith
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First and foremost, the **LC Application Processing** component exposes only
    in-process APIs when other components interact with it. This includes interactions
    with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The frontend
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Published/consumed events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To extract LC Application Processing functionality into its own, independently
    deployable component, remotely invokable interfaces will have to be supported
    instead of the in-process ones that we currently have. So, let’s examine the remote
    API options for each.
  prefs: []
  type: TYPE_NORMAL
- en: Changes to frontend interactions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Currently, the `CommandGateway` for commands and `QueryGateway` for queries),
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ch10-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'One very simple way to replace these in-process calls is to introduce some
    form of **Remote Procedure Call** (**RPC**). Now our application looks similar
    to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Introducing remote interaction with the frontend'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_10.2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.2 – Introducing remote interaction with the frontend
  prefs: []
  type: TYPE_NORMAL
- en: When working with in-process interactions, we are simply invoking methods on
    objects within the confines of the same process. However, when we switch to using
    out-of-process calls, there are quite a few considerations. These days when working
    with remote APIs, we have several popular choices in the form of **JSON**-based
    web services, **GraphQL**, **gRPC**, and more. While it is possible to make use
    of a completely custom format to facilitate the communication, DDD advocates the
    use of the **Open Host Service pattern** ([https://ddd-book.karthiks.in/10-distributing-into-multiple-components.html#_open_host_service_ohs](https://ddd-book.karthiks.in/10-distributing-into-multiple-components.html#_open_host_service_ohs))
    using a published language that we covered in [*Chapter 9*](B16716_09_Final_NM_ePub.xhtml#_idTextAnchor138),
    *Integrating with External Systems*. Even with the open host service style of
    communication, there are a few considerations, some of which we discuss in the
    following subsections.
  prefs: []
  type: TYPE_NORMAL
- en: Protocol options
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several options available to us when exposing remote APIs. These
    days, using a JSON-based API (often labeled as **Representation State Transfer**
    or **REST**) seems to be quite popular. However, this isn’t the only option available
    to us. In a resource-based approach, the first step is to identify a resource
    (noun) and then map the interactions (verbs) associated with the resource as a
    next step. In an action-based approach, the focus is on the actions to be performed.
    Arguably, REST takes a resource-based approach, whereas **graphQL**, **gRPC**,
    **SOAP**, and more, seem to be action-based. Let’s take an example of an API where
    we want to start a new LC application. In a RESTful world, this could look something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/10-2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In comparison, with a graphQL implementation, this could look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/10-3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In our experience, designing APIs using REST does result in some form of dilution
    when attempting to mirror the language of the domain—because the focus is first
    and foremost on resources. Purists will be quick to point out that the preceding
    example is not RESTful because there is no resource named `start-new` and that
    we should leave the URL to simply include the name of the resource (use /lc- applications
    instead of `/lc-applications/start-new`). Our approach is to place more importance
    on remaining true to the ubiquitous language as opposed to being dogmatic about
    adherence to technical purity.
  prefs: []
  type: TYPE_NORMAL
- en: Transport format
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we have two broad choices: **text-based** (for example, **JSON** or **XML**)
    versus **binary** (for example, protocol buffers, [https://developers.google.com/protocol-buffers](https://developers.google.com/protocol-buffers),
    or Avro, [https://avro.apache.org/](https://avro.apache.org/)). If non-functional
    requirements (such as performance) are met, our preference is to use text-based
    protocols as a starting point. That’s because it can afford the flexibility of
    not needing any additional tools to visually interpret the data (when debugging).'
  prefs: []
  type: TYPE_NORMAL
- en: When designing a remote API, we have the option of choosing a format that enforces
    a schema (for example, protocol buffers or Avro) or something less formal such
    as plain JSON. In such cases, in order to stay true to the ubiquitous language,
    the process might have to include additional governance in the form of more formal
    design and code reviews, documentation, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Compatibility and versioning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As requirements evolve, there will be a need to enhance the interfaces to reflect
    these changes. This will mean that our ubiquitous language will also change over
    time, rendering old concepts obsolete. The general principle is to maintain backward
    compatibility with consumers for as long as possible. But this does come at the
    cost of having to maintain old and new concepts together—leading to a situation
    where it can become hard to tell what is relevant versus what is not. Using an
    explicit versioning strategy can help to manage this complexity up to an extent—where
    newer versions might be able to break backward compatibility with older ones.
    However, it is also not feasible to continue supporting a large number of incompatible
    versions indefinitely. Hence, it is important to make sure that the versioning
    strategy makes deprecation and retirement agreements explicit.
  prefs: []
  type: TYPE_NORMAL
- en: REST APIs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We recognize that there are several options when exposing web-based APIs, and
    claims of using a REST approach seem quite common these days. REST was coined
    by Roy Fielding as part of his doctoral dissertation. The idea of what constitutes
    REST has been a matter of debate and, arguably, remains ambiguous even today.
    Leonard Richardson introduced the notion of a maturity model for HTTP-based REST
    APIs that somewhat helped provide some clarity. The model describes broad conformance
    to REST in four levels, with each level being more mature than the preceding one:'
  prefs: []
  type: TYPE_NORMAL
- en: '0. **Adhoc**: Where APIs are designed without the use of any perceptible structure.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources**: Where APIs are designed around a *thing* that makes sense on
    its own (usually, this is a noun). Here, a very small subset of verbs (either
    a GET or a POST) could be used to model all operations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**HTTP verbs**: Where APIs are designed by making use of a standard set of
    operations that can be performed on a resource (for example, GET for reads, POST
    for creates, PUT for updates, DELETE for deletes, and more).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**HATEOAS**: Where APIs include hypermedia links to help clients discover our
    API in a self-service manner.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In our experience, most web service-based solutions that claim to be RESTful
    seem to stop at level 2\. Roy Fielding, the inventor of REST, seems to claim that
    *REST APIs must be hypertext-driven* ([https://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven](https://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven)).
    In our opinion, the use of hypertext controls in APIs allows them to become self-documenting
    and, thereby, promotes the use of the ubiquitous language more explicitly. More
    importantly, it also indicates what operations are applicable for a given resource
    at that time in its life cycle. For example, let’s look at a sample response where
    all pending LC applications have been listed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/10-4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding example, there are two `lc-applications` listed. Based on the
    current status of the LC, the links provide a means to act on the LC appropriately.
    In addition to the *self* link, the first LC application shows a submit link denoting
    that it can be submitted, whereas the second application shows the approve and
    reject links, but not a submit link. Presumably, this is because it has already
    been submitted. Also, notice how the response does not need to include a status
    attribute so that they can use this to deduce which operations are relevant for
    the LC application at that time (this is an example of the *tell**,* *don’t ask*
    principle, [https://martinfowler.com/bliki/TellDontAsk.html](https://martinfowler.com/bliki/TellDontAsk.html)).
    While this might be a subtle nuance, we felt that it is valuable to point out
    in the context of our DDD journey.
  prefs: []
  type: TYPE_NORMAL
- en: So, we have looked at a few considerations when moving from an in-process API
    to an out-of-process API. There are quite a few other considerations, specifically
    pertaining to non-functional requirements (such as performance, resilience, error
    handling, and more). We will look at these in more detail in [*Chapter 11*](B16716_11_Final_NM_ePub.xhtml#_idTextAnchor164),
    *Decomposing into Finer-Grained Components*.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a handle on how we can work with APIs that interact with the
    frontend, let’s look at how we can handle event publication and consumption *remotely*.
  prefs: []
  type: TYPE_NORMAL
- en: Changes for event interactions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Currently, our application publishes and consumes domain events over an in-process
    bus that the **Axon** framework makes available.
  prefs: []
  type: TYPE_NORMAL
- en: 'We publish events when processing commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ch10-5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Publishing an event when processing a command successfully and consume events
    to expose query APIs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ch10-6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We subscribe to an event using the Axon-provided `@EventHandler` annotation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In order to process events remotely, we need to introduce an explicit infrastructure
    component in the form of an event bus. Common options include message brokers
    such as **ActiveMQ** and **RabbitMQ**, or a distributed event streaming platform,
    such as **Apache Kafka**. Application components can continue to publish and consume
    events as before—only, now, they will happen using an out-of-process style of
    invocation. Logically, this now causes our application to look similar to the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Introducing an out-of-process event bus'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_10.3.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.3 – Introducing an out-of-process event bus
  prefs: []
  type: TYPE_NORMAL
- en: When working with events within the confines of a single process, assuming synchronous
    processing (event publishing and consumption on the same thread), we do not encounter
    a majority of problems that only become apparent when the publisher and the consumer
    are distributed across multiple processes. Let’s examine some of these in more
    detail next.
  prefs: []
  type: TYPE_NORMAL
- en: Atomicity guarantees
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Previously, when the publisher processed a command by publishing an event and
    the consumer(s) handled it, transaction processing occurred as a single atomic
    unit, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4 – ACID transaction processing within the monolith'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_10.4.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.4 – ACID transaction processing within the monolith
  prefs: []
  type: TYPE_NORMAL
- en: Notice how all the highlighted operations in the preceding diagram happen as
    part of a single database transaction. This allows the system to be strongly consistent
    from end to end. When the event bus is distributed to work within its own process,
    atomicity cannot be guaranteed as it was previously. Each of the preceding numbered
    operations works as an independent transaction. This means that they can fail
    independently, which can lead to data inconsistencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve this problem, let’s look at each step of the process in more detail,
    starting with command processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Command processing transaction semantics'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_10.5.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.5 – Command processing transaction semantics
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider a situation where we save to the database but fail to publish
    the event. Consumers will remain oblivious of the event that is occurring and
    become inconsistent. On the flip side, if we publish the event but fail to save
    it in the database, the command processing side itself becomes inconsistent—not
    to mention that the query side now thinks that a domain event occurred, when,
    in fact, it did not. Again, this leads to inconsistency. This **dual-write** problem
    is fairly common in distributed event-driven applications. If command processing
    has to work in a foolproof manner, saving to the database and publishing to the
    event bus have to happen atomically—both operations should succeed or fail in
    unison. Here are a few solutions that we have used to solve this issue (in increasing
    order of complexity):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Do nothing**: Arguably, this approach is not really a solution; however,
    it might be the only placeholder until a more robust solution is in place. While
    it might be puzzling to see this being listed as an option, we have seen several
    occasions where this is indeed how event-driven systems have been implemented.
    We leave this here as a word of caution so that teams become cognizant of the
    pitfalls.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transaction synchronization**: In this approach, multiple resource managers
    are synchronized in a way that a failure in any one system will trigger a cleanup
    in the others where the transaction has already been committed. It is pertinent
    to note that this might not be foolproof, as it might lead to cascading failures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Information
  prefs: []
  type: TYPE_NORMAL
- en: The Spring Framework provides support for this style of behavior through the
    `TransactionSynchronization` interface and the now deprecated `ChainedTransactionManager`
    interface. Please refer to the framework documentation for further details. Needless
    to say, this interface should not be used without careful consideration of the
    business requirements.
  prefs: []
  type: TYPE_NORMAL
- en: '**Distributed transactions**: Another approach is to make use of distributed
    transactions. A distributed transaction is a set of operations on data that is
    performed across two or more resource managers (usually, these are databases)
    using techniques such as **two-phase commit** ([https://martinfowler.com/articles/patterns-of-distributed-systems/two-phase-commit.html](https://martinfowler.com/articles/patterns-of-distributed-systems/two-phase-commit.html)).
    Typically, this functionality is implemented using pessimistic locking on the
    underlying resource managers (databases) and could present scaling challenges
    in highly concurrent environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transactional outbox**: None of the preceding methods are completely foolproof
    in the sense that there still exists a window of opportunity where the database
    and the event bus can become inconsistent (this is true even with two-phase commits).
    One way to circumvent this problem is by completely eliminating the dual-write
    problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this solution, the command processor writes to its database and the intended
    event to an *outbox* table in a local transaction. A separate poller component
    polls the outbox table and writes to the event bus. Polling can be computationally
    intensive and could lead back to the dual write problem again because the poller
    has to keep track of the last written event. This could be avoided by making event
    processing idempotent on the consumer so that processing duplicate events do not
    cause issues, especially in extremely high concurrency and volume scenarios. Another
    way to mitigate this issue is to use a **Change Data Capture** (**CDC**) tool
    (such as **Debezium**, [https://debezium.io/](https://debezium.io/)) and Oracle
    LogMiner ([https://en.wikipedia.org/wiki/OracleLogMiner](https://en.wikipedia.org/wiki/OracleLogMiner)).
    Most modern databases ship with tools to make this easier, and they may be worth
    exploring. One way to implement this is to use the **transactional outbox pattern**,
    as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.6 – The transactional outbox pattern'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_10.6.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.6 – The transactional outbox pattern
  prefs: []
  type: TYPE_NORMAL
- en: The transactional outbox pattern is a robust approach for dealing with the dual-write
    problem. However, it also introduces a non-trivial amount of operational complexity.
    In one of our previous implementations, we made use of transactional synchronization
    to ensure that we never missed writes to the database. Additionally, we ensured
    that the event bus was highly available through redundancy on both the compute
    and storage tiers and, most importantly, by avoiding *any* business logic on the
    event bus.
  prefs: []
  type: TYPE_NORMAL
- en: Delivery guarantees
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Previously, because all of our components worked within a single process, the
    delivery of events to the consumers was guaranteed at least as long as the process
    stayed alive. Even if event processing failed on the consumer side, it was fairly
    straightforward to detect the failure because exception handling was fairly straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, rollbacks were straightforward because the production and consumption
    of events happened as part of a single database transaction. With the LC processing
    application now becoming a remote component, event delivery becomes a lot more
    challenging. When it comes to message delivery semantics, there are three basic
    categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**At-most-once delivery**: This means that each message might be delivered
    once or not at all. Arguably, this style of delivery is the easiest to implement
    because the producer creates messages in a fire-and-forget fashion. This might
    be okay in environments where the loss of some messages is tolerated. For example,
    data from click-stream analytics or logging can fall into this category.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**At-least-once delivery**: This means that each message will be delivered
    more than once with no messages being lost. Delivery of undelivered messages is
    retried—potentially infinitely. This style of delivery might be required when
    it is not feasible to lose messages, but where it would be tolerable to process
    the same message more than once. For example, analytical environments can tolerate
    duplicate message delivery or have duplicate detection logic to discard already
    processed messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Exactly-once delivery**: This means that each message is delivered exactly
    once without either being lost or duplicated. This style of message delivery is
    extremely hard to implement, and a lot of solutions could approach exactly-once
    semantics with some implementation help from the consumers where duplicate messages
    are detected and discarded with the producer sticking to at-least-once delivery
    semantics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For domain event processing, most teams will, of course, prefer to have exactly-once
    processing semantics, given that they would not want to lose any of these events.
    However, given the practical difficulties guaranteeing *exactly-once* semantics,
    it is not unusual to approach exactly-once processing by having the consumer process
    events in an idempotent manner or designing events to make it easier to detect
    errors.
  prefs: []
  type: TYPE_NORMAL
- en: For example, consider a `MonetaryAmountWithdrawn` event, which includes `accountId`
    and `withdrawalAmount`. This event could carry an additional `currentBalance`
    attribute so that the consumer will know if they are out of sync with the producer
    when processing the withdrawal. Another way to do this is for the consumer to
    keep track of the last *n* events processed. When processing an event, the consumer
    can check whether this event has already been processed. If so, they can detect
    it as a duplicate and simply discard it. Again, all the preceding methods add
    a level of complexity to the overall system. Despite all these safeguards, consumers
    could still find themselves out of sync with the system of record (the command
    side that produces the event). If so, as a last resort, it might be necessary
    to use partial or full event replays ([https://ddd-book.karthiks.in/10-distributing-into-multiple-components.html#_historic_event_replays](https://ddd-book.karthiks.in/10-distributing-into-multiple-components.html#_historic_event_replays)),
    which was discussed in [*Chapter 7*](B16716_07_Final_NM_ePub.xhtml#_idTextAnchor112),
    *Implementing Queries*.
  prefs: []
  type: TYPE_NORMAL
- en: Ordering guarantees
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In an event-driven system such as the one we are building, it is desirable for
    consumers to receive events in a deterministic order. Not knowing the order or
    receiving it in the wrong order could result in inaccurate outcomes. Let’s consider
    the example of `LCApplicationAddressChangedEvent` occurring twice in *quick succession*.
    If these changes are processed in the wrong order, we could end up displaying
    the wrong address as their current one. This does not necessarily mean that events
    need to be ordered for all use cases. Let’s consider another example where we
    receive `LCApplicationSubmittedEvent` more than once erroneously when it is not
    possible to submit a given LC application more than once. All such notifications
    after the first can be ignored.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a consumer, it is important to know whether events will be ordered or not
    so that we can make design considerations for out-of-order events. One default
    might be to accommodate for out-of-order events as a default. In our experience,
    this does tend to make the resulting design more complicated, especially in cases
    where the order does matter. Here, we will discuss three-event ordering strategies
    and their implications for both the producer and the consumer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16716_10_Table_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In most applications, per aggregate ordering might be a good place to start
    and cater to most business scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Durability and persistence guarantees
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When an event is published to the event bus, the happy path scenario is that
    the intended consumer(s) can process it successfully. However, there are scenarios
    that can cause message processing to be impacted adversely. Let’s examine each
    of these scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Slow consumer**: The consumer is unable to process events as fast as the
    producers are publishing them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Offline consumer**: The consumer is unavailable (down) at the time of the
    events being published.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Failing consumer**: The consumer is experiencing errors when trying to process
    events.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In each of these cases, we could develop a backlog of unprocessed events. Because
    these are domain events, we need to prevent the loss of these events until the
    consumer has been able to process them successfully. There are two communication
    characteristics that need to be true for this to work successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.7 – Persistence versus durability'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_10.7.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.7 – Persistence versus durability
  prefs: []
  type: TYPE_NORMAL
- en: '**Persistence**: This is the communication style between the **Producer** instance
    and the **Event Bus** instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Durability**: This is the communication style between the **Event Bus** instance
    and the **Consumer** instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Firstly, messages need to be persistent (that is, stored on disk), and secondly,
    the message subscription (the relationship between the consumer and the event
    bus) needs to be durable (persist across **Event Bus** restarts). It is important
    to note that events have to be made persistent by the producer for them to be
    consumed durably by the consumer.
  prefs: []
  type: TYPE_NORMAL
- en: Processing guarantees
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When an event is processed by the query side component, as shown here, the
    following steps occur:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.8 – Event processing failure scenarios'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_10.8.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.8 – Event processing failure scenarios
  prefs: []
  type: TYPE_NORMAL
- en: The event is consumed (either through a push or a pull) from the **Event Bus**
    instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Transformation logic is applied to the payload of the event.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The transformed payload is saved in the query side store.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Each of these steps can encounter failures. Irrespective of the cause of failure,
    the event should be durable (as discussed earlier) so that it can be processed
    later when the issue is fixed. These errors can be broadly segregated into four
    categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16716_10_Table_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we have looked at the changes that we need to make because of the introduction
    of an out-of-process event bus. Having done this allows us to actually extract
    the **LC Application Processing** component into its own independently deployable
    unit, which will look similar to the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.9 – LC Application Processing deployed independently'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_10.9.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.9 – LC Application Processing deployed independently
  prefs: []
  type: TYPE_NORMAL
- en: However, we are continuing to use a common datastore for the **LC Application
    Processing** component. Let’s look at what is involved in segregating this into
    its own store.
  prefs: []
  type: TYPE_NORMAL
- en: Changes in database interactions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While we have extracted our application component into its own unit, we continue
    to be coupled at the database tier. If we are to achieve true independence from
    the monolith, we need to break this database dependency. Let’s look at the changes
    involved in making this happen.
  prefs: []
  type: TYPE_NORMAL
- en: Data migration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As a first step to start using a database of our own, we will need to start
    migrating data from the command side event store and the query store(s), as shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.10 – Data migration'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_10.10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.10 – Data migration
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case, we have the command side event store and the query store(s) that
    will need to be migrated out. To minimize effort from the outset, it might be
    prudent to do a simple homogenous migration by keeping the source and target database
    technologies identical. In advance of the cut-over, among other things, it will
    be essential to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Profile** to make sure that latency numbers are within tolerable limits'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test** to make sure that the data has migrated correctly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Minimize downtime** by understanding and agreeing on **SLAs**, such as the
    **Recovery Time Objective** (**RTO**) and **Recovery Point Objective** (**RPO**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cut-over
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If we have made it so far, we are ready to complete the migration of the LC
    Application Processing from the rest of the monolith. The logical architecture
    of our solution now looks similar to the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.11 – Independent data persistence'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16716_Figure_10.11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.11 – Independent data persistence
  prefs: []
  type: TYPE_NORMAL
- en: With this step, we have successfully completed the migration of our first component.
    There is still quite a lot of work to do. Arguably, our component was already
    well-structured and loosely coupled with the rest of the application. Despite
    that, moving from an in-process model to an out-of-process model between bounded
    contexts is quite an involved process—as should be evident from the work we have
    done in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how we can extract a bounded context from an existing
    monolith, although you could argue that this was from a reasonably well-structured
    one. We looked at the challenges involved in decomposing the monolith from various
    interaction points such as the frontend, event exchanges, and the database. You
    should have an understanding of what it takes to go from an in-process event-driven
    application to an out-of-process one.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at how to extract pieces out of a monolith
    that might not be as well-structured, possibly very close to the dreaded big ball
    of mud.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information, please refer to the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven](https://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://martinfowler.com/articles/patterns-of-distributed-systems/two-phase-commit.html](https://martinfowler.com/articles/patterns-of-distributed-systems/two-phase-commit.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://debezium.io/](https://debezium.io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
