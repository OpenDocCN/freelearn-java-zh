- en: Monitor Your Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to an application's performance, you will quickly need to know
    what your application does and get the metrics of performance. In this chapter,
    we will identify a few ways to get insights on applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, in this chapter, we will learn how to monitor our application''s behavior
    in order to be able to compare it with the response times and execution times
    we observe. This will therefore show you the following:'
  prefs: []
  type: TYPE_NORMAL
- en: How to add monitoring or profiling to an existing application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to read important figures corresponding to the monitoring of an application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to ensure that the application performance is monitored and that any unexpected
    changes are visible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Java tools to know what my application is doing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Two critical factors are directly linked to performance when you take an application
    as a black box:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Memory usage**: If too much memory is consumed, it can slow down the application
    or even make it dysfunctional'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CPU time**: If an operation is too slow, it will consume a lot of CPU cycles
    and impact the overall performance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Without too much external tooling (except the **Java Development Kit** (**JDK**)
    and/or operating system tools), you can easily extract a lot of information and
    start working on the performance.
  prefs: []
  type: TYPE_NORMAL
- en: The jcmd command – the small command line utility that does a lot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since Java 8, the JDK has been coming with the `jcmd` command, which allows
    you to execute commands on a local Java instance using the same user/group as
    the instance you want to check.
  prefs: []
  type: TYPE_NORMAL
- en: 'The usage of `jcmd`, although command-based, is quite simple. To understand
    it, we will first start our quote manager application with the command we saw
    in [Chapter 1](f8931396-0636-41a9-8bf7-2b67bb424b76.xhtml), *Money – The Quote
    Manager Application*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now in another console, just execute `jcmd`. On my system, it will dump what
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The first column is the **process ID** (**PID**) of the program and what follows
    is the launching command (main and parameters). Since we launched our server with
    maven, we can identify it with the maven main (`org.codehaus.plexus.classworlds.launcher.Launcher`)
    or with the parameters that exactly match the command we launched (`clean package
    embedded-glassfish:run`).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you launch a standalone GlassFish, you will probably have a line like the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This one is pretty verbose but you can identify that the main (first string)
    references `glassfish` and you can find the domains directory to distinguish between
    multiple instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'To just give you another idea, if you use Apache Tomcat or TomEE, you will
    identify it with this line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we have the PID of our Java process; we can pass it to `jcmd`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, for our previous maven GlassFish instance, it will look like the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the output is basically a list of commands that you can invoke
    using `jcmd`. A lot of these commands are informative, such as `VM.version` (which
    will just log which JVM you are using), but some commands are actual actions,
    such as `GC.run` (which will call `System.gc()`). Concerning the performance,
    we are interested in `Thread.print`, which is a replacement of `jstack`. GC data
    commands, such as `GC.class_histogram`, are related to the garbage collection
    data, while the `JFR` commands are related to **Java Flight Recorder**.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start with the most basic but also probably the most important command: `Thread.print`.
    This will allow us to see what our application is doing by digging into the *current* thread
    stack of our application.
  prefs: []
  type: TYPE_NORMAL
- en: Thread.print
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you execute the `Thread.print` command, the output will look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Since reproducing the full output of this command will take the entire chapter,
    it has been replaced by a skeleton of sorts of the thread stacks. What is important
    here is to identify that each block starting with a line that has quotes is a
    thread.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the dump repeats this pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'When the server is idle—that is, when it is not serving any request or executing
    any scheduled tasks—we can identify that most of the threads are just waiting
    for a task (in thread pools):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'To understand this dump, you will need to know how `ExecutorService` works.
    It basically creates threads with tasks called *Workers*, and each work can take
    some tasks from a queue (to simplify things). Here we can see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ThreadPoolExecutor$Work`, which means that we are in a thread pool task handler'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LinkedBlockingQueue.take`, which means that the thread is waiting for a new
    task'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can also identify in this dump some incoming requests in the I/O layer,
    such as waiting for a socket to connect to an NIO `Selector`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: An important line here is either `epollWait` (if you are familiar with OS natives)
    or `Selector*.select` (if you are more familiar with the Java side of the code,
    which means it is waiting for a connection).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, if we inject some requests into our application (let''s just use Apache
    Bench or **AB** to undertake some `GET` requests on our `findById` endpoint),
    we can see some threads that are actually working. (Note that because of its length
    and to avoid having several pages of thread stacktrace, the `[...]` have been
    shortened):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: There are other kinds of thread stacks but this one is particularly interesting,
    as we can identify most of our endpoint stacks. Keep in mind that we are calling
    a JAX-RS endpoint that calls JPA to find a quote that will rely on `DataSource`
    to connect to the current database. We can identify the JAX-RS layer with `org.glassfish.jersey
    lines`, the JPA layer with the `org.eclipse.persistence` lines, our application
    with our own package (`com.github.rmannibucau`, in this example), and the datasource
    connection retrieval with the `ConnectionManager` lines. We can also identify
    that Jersey (JAX-RS implementation of GlassFish) is deployed over Tomcat, thanks
    to the `org.apache.catalina` packages (but only for the application pipeline management)
    and Grizzly for I/O handling (`org.glassfish.grizzly` packages).
  prefs: []
  type: TYPE_NORMAL
- en: 'This analysis is interesting as it shows something you need to take care of
    in Java EE: Java EE defines APIs but the runtime actually runs implementations.
    You rarely see `javax.*` entries in thread dumps, so you may need to check which
    implementations your server uses to make your analysis easier and faster.'
  prefs: []
  type: TYPE_NORMAL
- en: Now the question is, can we conclude anything about this stack? Yes, of course!
    We can conclude that our application goes through the stack we expected. However,
    in terms of the performance, it doesn't mean anything. What will be impacting
    is how often you see the same stack being called. Concretely, if you see 30 threads
    over 100 waiting in a particular call, it may mean that this is a good place to
    optimize. If the stack even adds BLOCKED next to the line, it means that you need
    to ensure it is normal for the application to lock here and, maybe, change something
    (either the code or the configuration).
  prefs: []
  type: TYPE_NORMAL
- en: 'Before going on to the next section, keep in mind that you can get the same
    kind of output in multiple ways. The `jstack` tool is another Java tool that you
    can use for doing more or less the same thing, but an interesting tip is to use
    Linux (or Windows) native tools to get exactly the same information. If you have
    JRE (Java without the development tools) instead of JDK, here is how to do it
    on Linux:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `GC.class_histogram` command allows you to get a heap histogram. We will
    deal with this in the coming sections. But just to sum up very quickly, the heap
    is where most of your Java objects will go. Therefore, it is important to see
    how it is used.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we execute the `GC.class_histogram` command in our process, the output will
    look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Here again, it is a partial output (truncated in multiple places) since it
    is too verbose for this book. If we find most of the environments we know, it
    is important to notice the following things:'
  prefs: []
  type: TYPE_NORMAL
- en: '`com.mysql` for the JDBC driver our application uses'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`com.github.rmannibucau` for our application (the quote entity in particular)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`com.sun.enterprise` for the GlassFish server'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`org.jboss.weld` for the CDI container of GlassFish'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`org.hibernate.validator` for the GlassFish bean validation implementation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sun`, `com.sun`, `java`, and so on for the JVM'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, an important thing is to be able to interpret these figures. The first
    column is not very important but the next two are. As written in the table header,
    they represent the number of instances and their size in bytes.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you run several concurrent requests on your server and filter the output
    for your quote entity, you can see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This line means that the heap currently has 591 instances of `Quote` and it
    takes 42,552 bytes.
  prefs: []
  type: TYPE_NORMAL
- en: This means that it is a statistic you can check in real time while the server
    is running. But as it is written in the command help, it impacts the server (slows
    it down), so you need to use it for tuning purposes only.
  prefs: []
  type: TYPE_NORMAL
- en: The last interesting figure of the `GC.class_histogram` command is the total
    size of the heap, which is the last number printed. In our previous output, it
    was 61,027,800 bytes (about 61 MB).
  prefs: []
  type: TYPE_NORMAL
- en: JVisualVM – the UI for JVM monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `jcmd` command is a great command-line tool but is a bit raw. However, the
    JVM provides additional tooling to yield metrics linked to performance and, in
    particular, the CPU and memory. `JVisualVM` and `JConsole` are two such tools
    packaged with the JDK (not the JRE). Since both are pretty similar, we will only
    deal with `JVisualVM` in this section, but most of the information and tools can
    be used with `JConsole` as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'To launch `JVisualVM`, you just have to execute a command of the same name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Once launched, you will see the welcome screen of `jvisualvm`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d7a26942-48ca-4a2f-b280-6b95d6291fae.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To start using `jvisualvm`, you will need to select a JVM. This is done through
    the tree on the left-hand side of the screen. The two options are Local and Remote.
    In this case, we''ll run the server on our local machine, so it is automatically
    detected by `jvisualvm` (just ensure to start it from the same JDK as the one
    the server is using). In the previous screenshot, you can see three processes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`VisualVM`: This is a Java process and detects itself.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GlassFish`: This is a standalone GlassFish server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`org.codehaus.plexus.classworlds.launcher.Launcher`: This is a maven process.
    If you start GlassFish with maven, as we saw in [Chapter 1](f8931396-0636-41a9-8bf7-2b67bb424b76.xhtml), *Money
    – The Quote Manager Application*, this is the process to choose.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once you have identified your process in the list, you need to double-click
    on it and you will get the following screen showing high-level information about
    the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7ea6385a-b6ba-40fb-b27a-d48215f06c26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once you have selected a JVM on the left, the right pane will show information
    about the JVM. It is organized in tabs:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Overview: This gives high-level information about the JVM (process ID, main
    class, arguments, Java version, system properties, and so on).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Monitor: This gives an overview of the CPU usage, the memory usage (in particular,
    the heap), the number of classes loaded, and the number of threads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Threads: This gives a live view of the existing threads managed by the JVM
    and shows the thread state over time (whether it is idled or active). Here is
    a screenshot:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/aaa560d5-7b79-43dc-ad75-58df9d02a6a5.png)'
  prefs: []
  type: TYPE_IMG
- en: The legend is in the bottom-right corner and uses colors to help this view to
    be readable: green for running, purple for sleeping, yellow for wait, red for
    fork, and orange for monitor.
  prefs: []
  type: TYPE_NORMAL
- en: What is interesting are the green blocks. This is when a thread does something.
    If you take the http-listener(x) threads for instance, you can see that they are
    orange and green. The orange part is when the threads are waiting for requests
    and the green part is when they are serving something. This view must be coupled
    with the thread dumps (or thread stack view) to ensure that the waiting threads
    are actually waiting for something relevant (such as waiting for some I/O), which
    the application does not control.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sampler: This tab is very interesting and allows you to capture what the server
    is doing in terms of CPU and memory. We find some information that we had with
    `jcmd`, but this is easier to use. All you need to do is to click on the CPU or
    Memory button and `jvisualvm` will start capturing the related information. Here
    is the memory view that you will get once some samples have been captured:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/9a972a09-dc1f-46ae-a3a8-57e670c2de75.png)'
  prefs: []
  type: TYPE_IMG
- en: This view is really close to the GC histogram command of `jcmd`; you'll find
    the class name, the corresponding size in bytes, and the number of instances.
    You can filter the visible classes at the bottom using any pattern related to
    your application; in this screenshot, we filtered by Quote.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you capture some CPU samples, the view is centered on the methods and their
    execution time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6b32bad0-b22b-4ecd-81ba-b667df2bf656.png)'
  prefs: []
  type: TYPE_IMG
- en: The first column is the method identifier and the other columns show the corresponding
    time for the respective methods. Self Time is the time of the method itself. Self
    Time (CPU) is the same but ignores waiting time (locks and so on). Same goes for
    the Total Time columns. What is the main difference between the Self Time and
    the Total Time columns? The Total Time columns include further method calls, which
    the Self Time columns don't.
  prefs: []
  type: TYPE_NORMAL
- en: While on the CPU view, you can click on Thread Dump to get a thread dump, the
    same as for `jcmd` but it is directly accessible in `jvisualvm`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Profiler: This is the last tab of the JVM view and provides more or less the
    same view as the Sampler tab. The main difference is the way it captures the data.
    Don''t worry if the time between your click and the first data you can see is
    quite long in Profiler. While the Sampler tab just takes a *screenshot* of the
    JVM (memory or thread stacks) from time to time and generates approximate statistics
    from them, the Profiler tab modifies the classes (actual bytecode) to capture
    accurate data. This implies that the sampling overhead is not very huge but the
    profiling overhead can be if it affects all the codebase, including the fast methods
    (which are instrumented by default). If you want precise metrics, you will need
    to use the profiler, but it is recommended that you hit the Settings checkbox
    to precisely tune which classes you want to get the metrics for and not let the
    defaults, which are too wide to not affect the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to connect remotely
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Connecting locally is easy since `jvisualvm` will just locally look up the running
    JVM. But for connecting remotely, you will need some more setup.
  prefs: []
  type: TYPE_NORMAL
- en: All the communication relies on JMX and, therefore, you need to set up a remote
    JMX connection. This relies on what is called a connector (can be seen as a small
    embedded JMX server). There are multiple protocols available but out of the box;
    they rely on RMI communications and system properties to be configured.
  prefs: []
  type: TYPE_NORMAL
- en: 'To add these system properties, the fastest and easiest way is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: It will enable JMX on port 1234 and disable SSL and security. For performances,
    we don't need more, but if you want to keep it in production, you may need to
    configure the security and SSL. For more details on how to do so, you can refer
    to the Oracle website at [https://docs.oracle.com/javase/8/docs/technotes/guides/management/agent.html](https://docs.oracle.com/javase/8/docs/technotes/guides/management/agent.html).
  prefs: []
  type: TYPE_NORMAL
- en: Once this is configured, you just have to right-click on the Local item in the
    tree on the left side, select Add JMX Connection, and fill in the related information
    (host/port and the potential credentials if you've configured the security).
  prefs: []
  type: TYPE_NORMAL
- en: Java Mission Control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since Java 7u40, the JDK has included the Java Flight Recorder tool. If you
    remember the available commands in `jcmd`, you had some `JFR.*` options, which
    are directly related to this tool. It allows you to capture a set of JVM events.
    It is coupled with **Java Mission Control** (**JMC**), which enables you to analyze
    and exploit the JVM events.
  prefs: []
  type: TYPE_NORMAL
- en: 'Launching it is easy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Once it is launched, you''ll get a welcome screen; the view looks similar to
    the `jvisualvm` view, with a list of the available processes on the left-hand
    side:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/88479a83-56f5-41db-91d6-ac8e0c6883f4.png)'
  prefs: []
  type: TYPE_IMG
- en: You can use the same kind of hints as for `jvisualvm` to identify the process. If
    you are not quite sure, don't hesitate to use the `jps -v` command, which will
    show you the command line and its PID for each running JVM (which will allow you
    to identify the number in parentheses in JMC).
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you''ve identified your process, you can right-click on it and select
    the Start JMX console to have a view similar to `jvisualvm` and specific to the
    selected JVM:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eb6fd349-8bd8-410e-a755-1a0333595293.png)'
  prefs: []
  type: TYPE_IMG
- en: You find the CPU (processor here), the memory, and thread information, and also
    the MBean view, which is how the JVM can export the internal data in a standard
    manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'One interesting thing is when you go to the Diagnostic Commands tab you will
    recognize the `jcmd` commands listed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/90602a7e-d088-4c1f-951d-74ce83713c37.png)'
  prefs: []
  type: TYPE_IMG
- en: This pane allows you to execute the `jcmd` commands directly from the UI. Here,
    we are interested in the **Java Flight Recorder** (**JFR**) commands, as we want
    more information about our JVM.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous screenshot, you may have noted that there is a Flight Recorder
    item on the left tree. It provides a UI for these commands. However, if you hit
    Start Recording, you will get the following error:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/43cd46f7-8ad2-4d86-958f-727a669504d1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To use Java Flight Recorder, you need to add the following options to your
    JVM:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: These two options will activate the Java Flight Recorder features. To add them
    to GlassFish, you can edit the `$GLASSFISH_HOME/glassfish/domains/domain1/config/domain.xml`
    file and add it to the `java-config` block after `jvm-options`. Alternatively,
    you can use the `create-jvm-options` command line's `glassfish` command. In any
    case, you will need to restart (or start) your server after this modification.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to test it using our maven GlassFish, you can just add them to
    `MAVEN_OPTS`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Now the options are activated on the JVM; you can go back to Java Mission Control
    and hit Start Recording on the Start Flight Recorder item. It will ask you a file
    location to store the recording and either a duration or a limit (size/age) for
    the recording. Finally, you can select whether you want to profile your server
    or just to monitor it. Here again, the difference is in the associated overhead.
    Let's select profiling for now. You can then hit Next and select what you want
    to monitor. An important parameter is the heap one, but if you continue through
    the wizard, you will see that you can precisely customize what you monitor, including
    the I/O. Once everything is well configured, simply hit Finish. It will proceed
    with the recording and open it once done.
  prefs: []
  type: TYPE_NORMAL
- en: For the first time, select 1 min as the recording duration; it will prevent
    you from waiting for too long.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the recording is done, you should get a view similar to the following
    one, showing the captured data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2c39e00f-0dbb-4552-b92d-c6da0799d962.png)'
  prefs: []
  type: TYPE_IMG
- en: Looking at the top, we can see the event timeline. You can click on it to refine
    the time-slot selection. The counters show the summary of the capture in terms
    of memory and CPU. Finally, at the bottom, you have the CPU and memory graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'What makes this tool more advanced than the previous one is the fact that you
    can visualize the code hotspot in the Code tab (the tabs are on the left in this
    tool) and the I/O in a single tool. The in-built JDK also makes it quite easy
    to use, whereas the overhead is not as important (if you select continuous monitoring,
    a counterpart is that the statistics won''t be very accurate but close enough
    so as to give you an idea). A major strength of this tool is the Call Tree view
    of the Code tab. It allows you to associate, through a stack, the method execution
    time cost with the method calls. For instance, while the server was running, this
    capture shows that the cost of our `findAll` method is mainly related to the way
    we are mapping each quote that requires using the JPA layer (eclipselink) and
    the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a5185f39-2577-4661-8380-12f600d29bba.png)'
  prefs: []
  type: TYPE_IMG
- en: This view is a really great way to investigate the hotspots of the application.
    It kind of merges the thread dumps and the profiling views (sometimes called *Path
    Tracking*) and enables you to get directly to the costly operations.
  prefs: []
  type: TYPE_NORMAL
- en: GlassFish ad hoc monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many servers have inbuilt monitoring capabilities. This depends highly on the
    server, but it can give some interesting insights without having to use another
    tool. This is precious when you don't control the machine or don't have the permissions
    to access/configure the server.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate this kind of monitoring, let''s use our Java EE reference implementation:
    GlassFish.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once started with the normal `./bin/asadmin start-domain` command, you can
    activate monitoring with this additional command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Indeed, there is a symmetric command if you want to deactivate monitoring:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'You can list the monitors available with the `get` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This output shows that the Jersey monitoring level is `HIGH` but other ones
    are disabled (`OFF`).
  prefs: []
  type: TYPE_NORMAL
- en: 'An alternative is to use the administration UI (by default on `http://localhost:4848`,
    for a standalone installation). Going to your configuration part on the left tree,
    you will have a Monitoring item where you can access the exact same entries:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e9ffa0f-3b31-410a-8722-aa4d3308a839.png)'
  prefs: []
  type: TYPE_IMG
- en: Selecting the level you want on the left of the table for the corresponding
    module will activate the associated monitoring. Once the monitoring is activated,
    you'll generally need to restart the server to let GlassFish take it into account.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once it is done, you can access the associated information through the Monitoring
    Data item of the left tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6d6d1771-f9b8-49be-80b4-9579ca0fae1c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, you can see the monitored instances. (If you use a standalone GlassFish,
    you will probably have a single entry.) The View Monitoring Data column will let
    you select the data you want to see. If you click on Application, for instance,
    you will obtain the corresponding screen with the information filled in, depending
    on the monitoring level you activated before. Here is a sample screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/606466a5-ce14-4b6b-8fb7-200cf0cb782c.png)'
  prefs: []
  type: TYPE_IMG
- en: Depending on the application, this is more or less useful. However, for us (a
    JAX-RS service), the Request Statistics block is interesting even if it gives
    high-level information. We can use it to monitor the maximum response time and
    error count. By itself, it will not be enough to improve the performance, but
    it will enable us to compare it with the client-side information; we can then
    easily obtain and validate our performance testing.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to keep in mind that servers often give aggregated performance
    figures for recent production monitoring, not performance tuning. This doesn't
    mean that it is useless but that you will only rely on ad hoc monitoring to validate
    your performance measurement pipeline (your client or your request injector, to
    put it simply).
  prefs: []
  type: TYPE_NORMAL
- en: Libraries monitor your application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We saw what the JVM provides us with tools and what the server gives us performance
    hints, but there are a lot of libraries intended to help you work on the performance.
  prefs: []
  type: TYPE_NORMAL
- en: Counters, gauges, timers, and more
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The most famous library is probably *Metrics* from Dropwizard ([http://metrics.dropwizard.io](http://metrics.dropwizard.io))
    but all libraries share more or less the same sort of API. The metrics are centered
    around a few important concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Gauges**: These provide the measure of a value at a certain time. They are
    intended to build a time series. Most famous examples are the CPU or memory usages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Counters**: These are long values, often associated with a gauges in order
    to build time series.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Histogram**: This structure allows you to compute the statistics around a
    value, for instance, the mean or the percentiles of request lengths.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Timers**: These are a bit like histograms; they compute other metrics based
    on one metric. Here, the goal is to have information about the rate of a value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Health checks**: These are less related to the performance; they allows you
    to validate that a resource (such as a database) is working or not. Health checks
    throw a warning/error if the resource isn''t working.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All these libraries provide different ways to export/expose the collected data.
    Common configurations are related to JMX (through MBeans), Graphite, Elasticsearch,
    and so on, or just the console/logger as the output.
  prefs: []
  type: TYPE_NORMAL
- en: How can these concepts be linked to the performance? The most important features
    for us will be the gauges and the counters. The gauges will enable us to make
    sure the server is doing well (for example, the CPU is not always at 100%, the
    memory is well released, and so on). The counters will enable us to measure the
    execution time. They will also enable us to export the data in an aggregated storage
    if you test against multiple instances, allowing you to detect some potential
    side effects of one instance on another one (if you have any clustering for example).
  prefs: []
  type: TYPE_NORMAL
- en: Concretely, we want to measure some important segments of our code. In the extreme
    case, if you don't know anything about the application, you will likely want to
    measure all parts of the code then refine it when you have more knowledge about
    your application.
  prefs: []
  type: TYPE_NORMAL
- en: 'To be very concrete and illustrate what we are trying to achieve, we want to
    replace application methods by this kind of pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'In other words, we want to surround our business code with a timer to collect
    statistics about our execution time. One common and *poor man* solution you can
    be tempted to start with is to use loggers to do it. It often looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code manually measures the execution time of the method and, then,
    dumps the result with a description text in a specific logger to identify the
    code portion it is related to.
  prefs: []
  type: TYPE_NORMAL
- en: In doing so, the issue you will encounter is that you will not get any statistics
    about what you measure and will need to preprocess all the data you collect, delaying
    the use of the metrics to identify the hotspots of your application and work on
    them. This may not seem like a big issue, but as you are likely to do it many
    times during a benchmark phase, you will not want to do it manually.
  prefs: []
  type: TYPE_NORMAL
- en: Then, the other issues are related to the fact that you need to add this sort
    of code in all the methods you want to measure. Thus, you will pollute your code
    with monitoring code, which is rarely worth it. It impacts even more if you add
    it temporarily to get metrics and remove it later. This means that you will try
    to avoid this kind of work as much as possible.
  prefs: []
  type: TYPE_NORMAL
- en: The final issue is that you can miss the server or library (dependency) data,
    as you don't own this code. That means that you may spend hours and hours working
    on a code block that is, in fact, not the slowest one.
  prefs: []
  type: TYPE_NORMAL
- en: Instrumenting the code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The immediate question is *how do you instrument the code you want to measure
    without having to modify it?* The first goal is to avoid being too intrusive in
    the code and, also, to avoid affecting the entire application just for the duration
    of a benchmark. The second goal is to be able to *toggle* the instrumentation
    and to be able to deactivate it in order to measure the application without monitoring
    (particularly, if you put it everywhere) and ignore the associated overhead on
    the metrics you take.
  prefs: []
  type: TYPE_NORMAL
- en: 'Nowadays, in Java and Java EE state, you have several options to instrument
    the code. We will browse through most of them, but here is an overview of the
    choices you have:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Choice 1 – manual**: In this solution, you wrap the instance you use with
    a *Factory* of the monitoring framework you rely on, and the returned instance
    is wrapped in a monitored proxy (new instance delegating to the original one).
    Concretely, it can look like the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: From what we talked about earlier, this has a drawback of impacting the code
    and limiting the instrumentation to the code you own (or can modify). However,
    the big advantage is that it is simple to integrate and works with any kind of
    code (managed by the EE container or not). Concretely, most of the monitoring
    libraries will have such a utility and often just use it internally in other kinds
    of integrations.
  prefs: []
  type: TYPE_NORMAL
- en: '**Choice 2 – through CDI (or the interceptor API)**: The Java EE standard way
    to *inject* logic into a service is to use an interceptor. We will detail how
    it works in a dedicated part but the overall idea is to flag a method as being
    monitored. Here again, the limitation will be to have access to the code you want
    to monitor through the CDI container. However, it is less impacting than the previous
    solution in terms of coding.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your application relies on Spring, the Spring framework has the same kind
    of tooling (referenced as *AOP* in their documentation). So, the same concept
    applies even if it is activated a bit differently.
  prefs: []
  type: TYPE_NORMAL
- en: '**Choice 3 – through a javaagent**: The javaagent is the most powerful way
    to instrument the code. The drawback is that you need to configure it directly
    on the JVM, while the good point is that you can monitor almost every class (except
    for a few of the JVM itself).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some containers (such as Tomcat/TomEE for instance) allow you to configure `java.lang.instrument.ClassFileTransformer`. This
    will basically enable you to perform bytecode instrumentation at load time (dynamically).
    This allows you to benefit from almost the same power as that of a javaagent,
    except that you will not be able to instrument the container—and potentially,
    a part of the JVM—but only the classes of the application. However, it is still
    more powerful than CDI instrumentation as it sees all the classes of the application,
    not only the ones that the CDI processes.
  prefs: []
  type: TYPE_NORMAL
- en: CDI instrumentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If we focus back on the Metrics library, we will find several CDI integrations.
    The global idea is to decorate the code with some annotation and automatically
    get the metrics associated with the executed code. Clearly, it will impact your
    code this way (using [https://github.com/astefanutti/metrics-cdi](https://github.com/astefanutti/metrics-cdi)
    for instance):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The `@Timed` annotation will automatically wrap the method execution in a Metrics
    timer and will therefore provide the statistics about the execution time of the
    method. The relevant code of the interceptor associated with the `@Timed` annotation
    is very close to this logic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This is exactly what we want to achieve but it has one trap we didn''t think
    about yet: the exception handling. To understand this point, we can compare the
    code used in the retired project (called Apache Sirona), which had the following
    differently implemented feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'What is important to see here is that the code path changes in the case of
    an exception. In terms of statistics, this implies that failures will have a different
    marker from successful calls in the metrics report. This is important to notice
    because the execution time of a failure is rarely comparable to a success, even
    for simple methods. Let''s take a simple finder example from our quote manager
    application and observe this. Here is the line we will investigate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'A normal call with a valid ID will be around 6 to 7 ms (on my reference machine,
    with my personal configuration). The `EntityManager#find` method can take any
    type for the identifier, so if we pass a wrong type (such as `String` instead
    of `long` ) then the call should compile and execute. Eclipselink will complain
    with an exception but the performance impact is something interesting: 0 ms! Indeed,
    this example is very extreme and is a bug, but if you have some rate limiting
    on an endpoint or some sanity checks at the beginning of the methods, the same
    impact can be observed.'
  prefs: []
  type: TYPE_NORMAL
- en: This means that if the framework you are using is putting all the invocations
    (with errors or not) in the same bucket, you can have a very good performance
    but a very slow application, since the average of the success/failure makes the
    figures look good.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing your own configurable monitoring interceptor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Implementing a CDI interceptor is not that complicated. Thus, you may want
    to have your own if you do not find a library matching your expectations. It can
    have two kinds of direct impact on the way you use monitoring:'
  prefs: []
  type: TYPE_NORMAL
- en: Be able to control the counters you use depending on the case you are in. This
    includes success/failure handling, but it can also be tenant-related (if your
    application is handling multiple tenants). This can be very important if you do
    not use the exact same system as the tenant (one can have a slower database than
    the other, for instance).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be able to configure the monitored beans. Yes, with CDI you can also avoid having
    to decorate the beans you want to monitor and just do it automatically from a
    configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first step to create a CDI interceptor is to have what CDI calls *interceptor
    binding*. It is the annotation you will use on your beans that will mark the method
    as being monitored. Here is a simple one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: It is a normal annotation that you can put in a method (or a class to mark all
    the methods as being monitored). The only particular thing is its `@InterceptorBinding`
    marker.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, to link this interceptor bind to the actual interceptor implementation,
    you create an interceptor with the same annotation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The method being decorated with `@AroundInvoke` will handle the method invocation,
    and being decorated with `@AroundTimeout`, it will also support EJB timer callbacks
    (`@Timeout`).
  prefs: []
  type: TYPE_NORMAL
- en: Note that if you also want to monitor the constructors, you can do so, but you
    will need to implement an `@AroundConstruct` method (with the same sort of implementation
    as our `monitor` method). The fact that our interceptor is decorated with `@Priority`
    automatically enables it, and you do not need to activate it in `beans.xml`.
  prefs: []
  type: TYPE_NORMAL
- en: With this code, you can decorate any method with `@Monitored` and, assuming
    that your `Context` stores the metrics, you will get your figures in the reporting
    solution you used.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, one goal of writing a custom implementation was also to be able to
    configure it. With CDI, it can be done with `Extension`. The global idea will
    be to observe the application types/methods, and if one is configured to be monitored,
    we will add `@Monitored` automatically. This way, we''ll have no code impact in
    the application and we can easily activate/deactivate monitoring by simply changing
    our configuration. For the configuration, we can just start with a `performance.properties`
    resource as follows (note that it will be easy to change to a particular file
    outside the application):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This code uses the `BeforeBeanDiscovery` event (beginning of the CDI lifecycle)
    to load our configuration. Here, you can read from whatever place you want. A
    small optimization is to have a special key to check whether the extension is
    activated or not. If it is set to something other than true, then we will just
    skip all other events. In case it is enabled, we'll observe all the discovered
    types through the `ProcessAnnotatedType` event. If the bean should be monitored
    (our test is very simple here, we just check whether the class name suffixed with* monitor*
    is true in our configuration), then we override `AnnotatedType`, keeping all its
    information but adding `@Monitored` into the set of the class's annotations.
  prefs: []
  type: TYPE_NORMAL
- en: You can do exactly the same at the method level, wrapping `AnnotatedMethod`
    returned by `AnnotatedType#getMethods`. The logic is the same; you just need to
    have one more configuration level (for methods).
  prefs: []
  type: TYPE_NORMAL
- en: 'The `WrappedAnnotatedType` implementation is a simple delegation implementation,
    except for the annotation accessors, where a new set is used instead of the original
    one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the only logic is in `getAnnotation` and in the constructor
    where a new set of annotations is created to replace the original one.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, to enable `Extension` and let the CDI find it, we just put its qualified
    name in `META-INF/services/javax.enterprise.inject.spi.Extension` in our project
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: Once this extension is added to your application (you can develop it as a library
    and just add the `jar` file inside your `war` package if you want), you can configure
    it through `performances.properties`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case, monitoring our quote service looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: What's more, you can add a line by the class you want to monitor. Don't forget
    to restart between updates in this file, since the configuration and the CDI model's
    wrapping is done only at startup.
  prefs: []
  type: TYPE_NORMAL
- en: Javaagent – a complex but powerful instrumentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you go back again to metrics, you can find existing javaagents even if they
    are less numerous, since writing an agent is a bit more complicated.
  prefs: []
  type: TYPE_NORMAL
- en: A javaagent is a particular kind of the main method provided by the JVM that
    enables you to register `ClassFileTransformer`, which is a way to modify the classes'
    bytecode before they get loaded. In other words, you will write some code and
    compile it, but the JVM will never execute it. Instead, it will execute a rewritten
    version of the code.
  prefs: []
  type: TYPE_NORMAL
- en: We will not detail how to do it here. In fact, it is more complicated than writing
    an interceptor (you need to take care of the classloaders, write low-level bytecode
    with the ASM library or an equivalent, and so on). However, it is important to
    see that the scope of a javaagent is the JVM—not an application, not a container,
    but the full JVM. For technical reasons, as you may guess, you can not instrument
    all the JVM classes, but all the classes that are loaded after the javaagent are
    started (which is already far enough).
  prefs: []
  type: TYPE_NORMAL
- en: Instrumenting `java.net.HttpURLConnection` is a good example of instrumentation
    using a javaagent.
  prefs: []
  type: TYPE_NORMAL
- en: This class is often used to implement a Java HTTP client, but it is often hidden
    by libraries (such as a JAX-RS client implementation). Therefore, it is not easy
    to have the current request and framework time if you cannot measure this specific
    class.
  prefs: []
  type: TYPE_NORMAL
- en: That is how a javaagent will be way more powerful than a CDI or a Spring instrumentation.
  prefs: []
  type: TYPE_NORMAL
- en: To give you an idea of what you can do with a javaagent, we will configure the
    Sirona project in our quote manager application.
  prefs: []
  type: TYPE_NORMAL
- en: Sirona javaagent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To keep it simple and easy to understand, we will use maven, but you can follow
    the same steps on any application server, since javaagent is set up on the JVM
    and not on a particular server.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to download the javaagent `jar` file. To do so with maven,
    you can just add the dependency maven plugin in your `pom.xml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'It is configured to download sirona-javaagent shaded JAR (all in one bundle).
    Now, if you execute this maven command, you should obtain the javaagent JAR in
    your maven project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Once this command is executed, you should find a `sirona-javaagent.jar` file
    next to your pom.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have the javaagent, we need to configure it. To make it simple,
    sirona supports a `sirona.properties` configuration file in the current directory,
    so we will use it. Here''s what it will contain to activate monitoring in our
    application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The `CounterListener`-related configuration is about the scope of the monitoring:
    what is instrumented and what is not. Here, we just instrument our application
    package and make Sirona ignoring the JVM classes (*container* is an alias for
    a set of built-in exclusions). Then, we configure `CounterDataStore` where the
    metrics are stored. In this example, we use a logging flavor (the metrics will
    then be outputted in a logger) and a CSV formatting. This is the simplest way,
    but you can also configure it to output the data in Elasticsearch, Graphite or
    any external system. Then, we configure our storage to log every 5 seconds (5000
    ms)—this is mainly for demonstration, but in real life, you will probably want
    to wait for a minute or so. Next, we request the storage to be cleared after collection.
    This last point means that every time the data is logged, the data is reset. It
    avoids keeping the startup data from having side-effects on the runtime data.
    Finally, the last line deactivates the path tracking feature of Sirona, which
    is built in with the javaagent, but we do not need it here.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that everything is configured, we just need to ensure that our application
    is ready to run (you can re-execute `mvn clean package` if you have a doubt) and
    then launch it with the javaagent on the JVM (maven if you launch GlassFish with
    maven or directly GlassFish if you use a standalone instance):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, adding a javaagent is as simple as adding the `-javaagent` option
    on the JVM, followed by the path of the JAR.
  prefs: []
  type: TYPE_NORMAL
- en: If the agent is natively developed and not done in Java, the command would be
    quite similar (but using `-agentlib`). This is how you can distinguish between
    Java and native agents, but the principle remains the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have started the server, if you wait for a few seconds (~5 seconds
    as for our configuration), you will start getting some output related to the metrics
    Sirona took:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: The output format depends on the logger configuration. Out of the box, it is
    not that fancy, but if you configure your logger, you will get a plain CSV output.
    By default in Sirona, the logger name will be `com.github.rmannibucau.sirona.counters`.
    If you want to configure this particular logger in a specific file without a specific
    formatter pattern, you will have to use the logger name and not the class name.
  prefs: []
  type: TYPE_NORMAL
- en: 'To keep it simple for us, we will just change the `SimpleFormatter` format
    in the JVM (it will affect all loggers using this formatter):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Note that depending on your operating system, you may (or may not) need to escape
    the dollars, as in the previous example (it was for Linux).
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the server starts with this new configuration, the output is more readable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: What is interesting here is that you can directly import this in a CSV editor,
    including Microsoft Excel or LibreOffice Calc, and work on the data (sort it,
    compare it, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: 'To efficiently work on the data, you need to know what the columns are. For
    this particular datastore, here is the header list:'
  prefs: []
  type: TYPE_NORMAL
- en: Timer/counter name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Timer/counter role (*performance* means the execution time is measured, *failure*
    means an exception has occurred)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hits (indicates how often the method has been called in the measuring window)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Max concurrency (indicates what the maximum of a concurrent call for a method
    in the measuring window is)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Max (gives the maximum execution time)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Min (gives the minimum execution time)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mean (gives the the average execution time)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sum (gives the sum of all the execution times)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Standard deviation of all the execution times of the window
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In your investigations into finding the bottleneck of a method to dig into (in
    order to optimize the performance), you will have to take multiple datasets into
    account. The first data will be the *sum*. If you sort by *sum* (decreasing order),
    the first method will be the one consuming a lot of time for your application.
    However, you need to validate it against the number of hits. For instance, if
    you have a single hit, then you know that caching this method's data will not
    be helpful. The standard deviation (or comparing the min/max range) will also
    give you an idea of the method’s behavior. If the range is high, then you need
    to investigate what this method does, and why it is fast sometimes and slow some
    other times.
  prefs: []
  type: TYPE_NORMAL
- en: Once you've found a good method to investigate, you can reuse the tools we talked
    about earlier to dig into the method. Having this level of information to start
    working is generally easier to deal with and more centered on the application
    overview than the detailed view, which can be hard (or long) to organize. It is
    always easier to drill down the performance data than starting from the detailed
    view.
  prefs: []
  type: TYPE_NORMAL
- en: Now, to show you how powerful a javaagent can be, we will temporarily change
    our sirona configuration a bit. We will exclude the Oracle package (just to override
    the default exclusion, which is the whole JVM), and we will include `HttpURLConnection`.
  prefs: []
  type: TYPE_NORMAL
- en: The goal for our application can be to compare the time we spend in the provisioning
    versus the current network cost, which we can not optimize as it is linked to
    our environment, which we assume to be constant during the benchmark phase.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what the configuration looks like now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Only the two first lines change, and you can see that the JVM is no more excluded
    to be able to instrument the sum package and that `HttpUrlConnection` is now included
    in the white list of instrumented classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We relaunch our server, and after the provisioning, we get these new outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: The configuration change includes the JVM HTTP client monitoring, and we can
    now have a part of the time spent in the actual network as well as the time spent
    in the client code itself, with retries and all the logic it embeds. This is the
    kind of information you cannot get without a javaagent.
  prefs: []
  type: TYPE_NORMAL
- en: '*Modern* architectures tend to encourage microservices. This means that you
    will mainly split your overall system into subsystems with a clear responsibility
    separation. It implies a lot of issues, such as the requirement to handle transactions
    across different systems (what XA was doing in its time), the addition of multiple
    remote communications, which slows down the overall process, and so on, but it
    comes with the advantage of allowing you to develop systems more rapidly and to
    go into production more easily in general. There is always a trade-off.'
  prefs: []
  type: TYPE_NORMAL
- en: In any case, if you work on the performance, you may have to deal with such
    a system now and, therefore, need to know which tools can help you.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are mainly two kinds of solutions that will help a lot:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data aggregation**: All the data of all the applications will be aggregated
    in a single system. For instance, the previously captured execution times of N
    instances will be stored in a single *database* (such as InfluxDB or Elasticsearch).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tracing**: The entire system will propagate a single *transaction ID* (also
    called *request ID*), which will enable you to identify the request (user action)
    across all the systems and the stage you are at (third system of the pipeline,
    for instance).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SQL Monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a lot of applications, most of the time will be taken by the SQL queries'
    execution. Therefore, it is important to monitor them. You can use one of the
    previous techniques but there are also some specific ways to monitor them.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, the idea is to replace the native driver you use (the Oracle, MySQL
    ones, for instance) with a monitoring driver, which will wrap the default driver
    and delegate all the logic to the original one, adding some metrics on top of
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, using sirona JDBC driver ([http://repo.maven.apache.org/maven2/com/github/rmannibucau/sirona/sirona-jdbc/0.6/](http://repo.maven.apache.org/maven2/com/github/rmannibucau/sirona/sirona-jdbc/0.6/))
    for our datasource, we will define the application DataSource this way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The driver's class name is now the monitoring one, and the URL changed a bit
    to configure the monitoring driver. Here, with Sirona, you append `sirona` before
    the native driver URL and after the `jdbc:` prefix, and you add the `delegateDriver`
    query parameter to the URL with the classname of the native driver as the value.
  prefs: []
  type: TYPE_NORMAL
- en: Once done, Sirona will automatically create counters for each statement and
    add it to its report.
  prefs: []
  type: TYPE_NORMAL
- en: This kind of solution works very well with prepared statements, as you will
    reuse the same *key* (the SQL value). This is generally what any JPA provider
    does.
  prefs: []
  type: TYPE_NORMAL
- en: This visualization, between Java and the database, can help determine the slow
    queries. There are a lot of implementations of such a type. Just pick the one
    you prefer, between Sirona, Jamon, JavaSimon, Log4jJDBC, P6Spy, and others.
  prefs: []
  type: TYPE_NORMAL
- en: Data aggregation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices—or more generally services with small scopes—are fast-moving applications
    in general, and it is easy to add/remove them in a global system. In this condition,
    the performance will need to be comparable and validatable against any change
    of the sibling services (which can impact the central service by overusing or
    misusing it).
  prefs: []
  type: TYPE_NORMAL
- en: Being able to have a centralized vision of all the systems is a key to understanding
    how optimizing another application can make your application go faster. The corollary
    of this statement is that when you depend on another application, which is too
    slow for your SLA, you need to be aware of it as soon as possible. Once identified,
    you can add caching or alternative ways to make your application less dependent
    on others and behave faster.
  prefs: []
  type: TYPE_NORMAL
- en: It is not always possible—for instance, in our quote manager application, we
    can't get data about Yahoo—but in a microservice structure, you will often get
    a company policy or at least contacts to be able to discuss it and implement it.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, it is mainly about agreeing on a way of identifying the application
    (which is just about defining a convention in the overall system, shared by all
    the subsystems) and the data format put inside the aggregator. For instance, you
    can say that you will use the `Company-ID` HTTP header as a request identifier
    and the log format will be `${Company-Id} | ${Tenant-Id} | ${Machine-Id} | ${Execution-Time}
    | ${action/method} | ${message}`.
  prefs: []
  type: TYPE_NORMAL
- en: This is just a simple example, but the idea is to be able to browse the log
    across applications pretty quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Once you know what you will log, you need to select a system to store your data.
    Here, you have a lot of choices but do not forget to check whether you can exploit
    the data once it is stored. It means that you need to ensure you have a good user
    interface that will fulfill your expectations on top of the storage.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most known are these:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Elastic stack: It is based on Elasticsearch to store the data and Kibana to
    visualize it. It is available for free.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Splunk: It is a custom stack dedicated to the aggregation of data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Grafana: It is mainly a UI tool, but it is pluggable on most of the monitoring
    databases, including Elasticsearch, Graphite or InfluxDB.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are multiple options for tracing (Zipkin, Dapper, and others) but a few
    of them seem to have become mainstream. One of them is the OpenTracing initiative
    ([http://opentracing.io/](http://opentracing.io/)). All share more or less the
    same design based on spans.
  prefs: []
  type: TYPE_NORMAL
- en: The global idea is to let each transaction’s actors mark their presence with
    a span. A span contains an identifier, some metadata about the invocation, and
    the execution time. The identifier is generally composed of multiple values representing
    the overall trace identifier (the request marker), the span identifier, and, often,
    the parent identifier.
  prefs: []
  type: TYPE_NORMAL
- en: When correctly installed, the tracing happens on the client and server sides,
    so you have a full vision of the system handling, and it is associated with the
    processing time of each part of the system. It is really about ensuring that every
    part of your system is properly instrumented—each time you exit or enter a system,
    you must be set up to handle the associated tracing. This includes HTTP clients/servers,
    and also the JDBC or NoSQL drivers.
  prefs: []
  type: TYPE_NORMAL
- en: As for the monitoring libraries, this relies on storage, but there are also
    local implementations (a bit like our CSV logger when we talked about the Sirona
    javaagent) you can use to test your configuration or use as fallbacks if you can’t
    have a real monitoring database. However, using local outputs with such systems
    will make your work harder and longer, since it is really about aggregating multiple
    data to have a consolidated vision. What you need to understand is that you shouldn't
    hesitate to invest in setting a server dedicated to the data collection. It will
    not only help you for performance, but also for tracing your system. So, it is
    a worthy investment!
  prefs: []
  type: TYPE_NORMAL
- en: APM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find tools called **Application Performance Management** (**APM**) on
    the market. These are really the Rolls Royce of monitoring tools and allow you
    to trace completely all the steps of the application, to go back in time to understand
    what happened, and to deduce the cause of a support issue very quickly. The paid
    offers generally include the infrastructure as well, which is not a negligible
    point, since it leads to a lot of data manipulation.
  prefs: []
  type: TYPE_NORMAL
- en: Technically, they reuse several of the previous techniques but are really an
    all-in-one solution, which makes them very valuable. However, they are generally
    expensive and rarely open source.
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, you can find a few open source implementations, such as PinPoint([https://github.com/naver/pinpoint](https://github.com/naver/pinpoint)),
    InspectIT([https://github.com/inspectIT/inspectIT](https://github.com/inspectIT/inspectIT)),
    and Glowroot([https://glowroot.org/](https://glowroot.org/)). In terms of a leading
    proprietary, solution you can find New Relic ([https://newrelic.com/java](https://newrelic.com/java)),
    DripStat ([https://dripstat.com](https://dripstat.com)), or DynaTrace ([https://www.dynatrace.com/](https://www.dynatrace.com/)).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this part, we saw a lot of ways to gather information about the JVM and
    your application. We also saw that the JVM itself provides a set of tools to give
    you information about the memory, CPU, and garbage collection. Most of them are
    available through the command line (which can be very handy when benchmarking
    a machine without any UI), but they also come with several user interfaces, enabling
    you to get the information easily once you can connect to the JVM. One of these
    tools is the JMC: it gives you a lot of information and even allows you to drill
    down into the method invocations to have a detailed view of your application.'
  prefs: []
  type: TYPE_NORMAL
- en: However, it is not enough and you may need to get access to the server information
    about the pool usage, and in this case, the server can give you some more information
    about configuration issues (such as a pool configured too small). Then, a set
    of libraries allows you to get the monitoring information in a more efficient
    and performance-oriented way, which enables you to investigate the application
    without a deep knowledge or any assumption about it. Note that these tools (such
    as Metrics or Sirona) also aggregate more data and often have plugins for the
    servers, which can prevent you from using the server-specific monitoring to get
    a more global vision.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we saw that in multisystem applications, you will need to ensure you
    can monitor your applications and also the ones linked to them so that you can
    identify the impacts on your own applications and try to decrease them if too
    impacting.
  prefs: []
  type: TYPE_NORMAL
- en: All of these tools, in some way, have some kind of overlap, but they all fulfill
    different needs and answer to a different trade-off between ease, information
    completeness, and investment. Depending on the knowledge you have about the application
    you are working on, and the investment you can afford for the code and infrastructure
    of the application of the benchmarking platform, you will pick a solution.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will investigate the impact of resources on applications
    and their performance. We will go through the Java memory management and the server
    resource handling, such as `DataSource` and `ConnectionFactory`.
  prefs: []
  type: TYPE_NORMAL
