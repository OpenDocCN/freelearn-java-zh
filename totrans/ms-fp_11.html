<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Introduction to the Actor Model</h1>
                </header>
            
            <article>
                
<p>In the previous chapter, we the discussed patterns and techniques of advanced functional programming in modern programming languages. However, you may have noticed that we were always dealing with cases of sequential programming. The closest that we have ever gotten to real parallelism was when we discussed the Applicative type class.</p>
<p>In this chapter, we will go deeper into the topic of modern functional solutions for parallelism. The following<span> </span>are the topics that we will be covering in this chapter:</p>
<ul>
<li>Overview of parallelism solutions</li>
<li class="h1">Traditional model synchronization on monitors</li>
<li class="h1">The actor model as a replacement for the traditional model</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Overview of parallelism solutions</h1>
                </header>
            
            <article>
                
<p>If you remember, the Applicative type class gives us an abstraction to define parallel computations. It was set against the <kbd>Monad</kbd> class, which is an abstraction to define sequential computational.</p>
<p class="mce-root">In the <span><em>Type Classes</em> section in</span> <a href="baec5eab-0c98-4407-8f73-9a1a2b9726c4.xhtml" target="_blank">Chapter 8</a>, <em>Basic Type Classes and Their Usage</em>, we reasoned that Applicatives are needed to provide you with a primitive to define independent computational. Parallelism can also be modeled by the Applicative. However, it is precisely the idea of independence for motivating force behind this type class.</p>
<p class="mce-root">Parallelism and concurrency require a different approach. They give rise to problems that are not normally encountered in sequential programming, and these problems have their own techniques so that they can be solved in object-oriented programming. However, these techniques are even more error-prone and hard to reason about than regular object-oriented and imperative programming. Hence, a bunch of other techniques were devised in order to simplify the process of developing concurrent software.</p>
<p class="mce-root"/>
<p class="mce-root">So far, we still cannot say that we have an ideal approach to parallel and concurrent programming. Whenever concurrency is involved, programming gets much more difficult than in a single-threaded case, even in the case of the use of the most modern techniques and approaches. Modern systems tend to be distributed, and there is a high demand on the scalability of such systems. This means that in the modern world, it is often the case that a single application must run on several machines that can be located in different parts of the world. Also, there is a requirement on the scalability of such systems. Scalability means that whenever you add extra processing power, such as extra machines to the cluster, the existing program must run seamlessly on these new machines without you needing to write extra programming code. Basically, scalability means that software must run on any number of machines as well as it does on a single machine.</p>
<p class="mce-root">Obviously, in such scenarios, chaos is inevitable. So far, we do not have a single solution to the issues that arise in the context of distributed fault-tolerant and highly available systems. Attempts were made to create approaches and mathematical theories that address this issue in the 20<sup>th</sup> century. Here, we are talking primarily about a class of mathematical theories called process calculi. Process calculi is a set of mathematical theories that are precisely aimed to describe processes that happen concurrently with the help of mathematical logic and mathematical laws. Some notable examples of process calculi include <strong>Algebra of Communicating Processes</strong> (<strong>ACP</strong>), which has an implementation in Scala called SubScript (see <a href="http://subscript-lang.org/">subscript-lang.org</a>)<a href="http://subscript-lang.org/"/>, pi-calculus, <strong>Calculus of Communicating Systems</strong> (<strong>CCS</strong>). Attempts were made to implement these theories in practice. However, today, we cannot say that any given theory addresses the entire range of problems faced by modern programmers in-depth and with convenience.</p>
<p class="mce-root">Also, in recent years, a range of engineering approaches have been developed specifically for the development of concurrent and parallel applications. One such approach is reactive programming. This approach is mostly based on engineering your application in terms of streams, data sources, and sinks. This kind of approach can be very useful in the context of an application that is heavy on data flow, which means that there is a large volume of data that is constantly moving from one part of an application to another.</p>
<p class="mce-root">A practical application of such reactive programming is applications that are heavy on events. For example, many mobile applications rely on event propagation and reacting to events. This means that a good strategy to describe this kind of application would be to reason about data streams and data sources, as well as reactions to data as first-class citizens of the application. Normally, these kinds of application would be described in terms of callbacks and reactions to events. However, reasoning in terms of streams gets you a toolset of proper abstractions. In the previous chapter, we saw that when we frequently encounter errors and side effects, then making them first-class citizens of your programs and reasoning about them explicitly can be very beneficial to troubleshoot your application and to reduce the chance of an error.</p>
<p class="mce-root">It's the same thing here—when we have an application that is heavy on data and events, then reasoning in terms of streams can be pretty beneficial. There is an entire range of implementations of this approach for a wide range of programming languages.</p>
<p class="mce-root">However, programming in terms of event streams and reactive programming is not always what you want. It's true that certain applications that are heavy on events and data processing may be reasonable to describe in terms of data streams. However, this is not always the case.</p>
<p class="mce-root">As we have discussed previously, a wide range of theories and approaches have been developed to address the difficulties of parallel programming. Some of them can be regarded as more functional. For example, some libraries for functional programming for Scala, such as <kbd>Cats</kbd> or <kbd>ScalaZ</kbd>, provide certain primitives to allow for concurrent and parallel programming. Some of these approaches have a more object-oriented flavor. For example, some of the process calculi mentioned previously tend to have a deal of object-oriented spirit in them, which means that they introduce certain kinds of primitives that are very much comparable to objects in object-oriented programming. Some theories and approaches reside on the edge between functional programming and object-oriented programming and cannot be clearly classified as members of any of these approaches. For example, this can be the reactive approach to programming. Although it is heavy on functions and uses Lambda calculus to compose these functions, the trade-off is often type safety.</p>
<p class="mce-root">The presence of the amount of theories and approaches for concurrent programming means that this topic is highly speculative. It is often the case that techniques and theories that work well for one application will not show themselves as being well for another. Therefore, it is necessary to remark this book's stance on the topic. In this book, we take a pragmatic approach to functional programming, which means that the aim of this book is to give you a toolset to solve practical problems in a functional manner. So far, one of the most pragmatic and best approaches toward parallel programming is the actors model. While it is possibly not the most elegant modal from a functional programming perspective, since it still lacks a satisfactory type safety, it is something that is highly scalable and works well in practice. In this chapter of this book, we will be studying the actor approach to the functional programming of parallel applications, and we will see how to use modern actor-based technology to write real-world parallel and scalable applications with the help of the actor model.</p>
<p class="mce-root">However, before we jump into discussing the actor model and its practical applications, it is necessary to understand all of the challenges that are faced by parallel programming, and how they are solved in the traditional model of object-oriented programming with the traditional approach. So, first of all, let's take a look at the traditional approach to parallel programming, that is, multi-threading with synchronization and monitors.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Traditional model synchronization on monitors</h1>
                </header>
            
            <article>
                
<p class="mce-root">Concurrency scenarios occur when you have two or more operations that are executed in parallel one with another. This parallelism can be either true parallelism or simulated parallelism. True parallelism is when your application is executed in parallel on two different CPU cores, like so:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/30f64707-8d2c-486e-bacc-3e4c681c1c41.png" style="width:12.67em;height:10.75em;"/></div>
<p class="mce-root"/>
<p class="mce-root">Simulated parallelism is when all of your parallel tasks are executed on the same processor core, however the processor switches from one task to another from time to time. Every task is composed of so-called atomic actions—smallest tasks that cannot be interrupted until they complete. The processor can take a certain amount of atomic actions from one task, and then execute a certain number of atomic tasks from another task:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/8fa70dc4-0ab7-4b51-9b64-5e79ff76ef13.png" style="width:11.17em;height:12.50em;"/></div>
<p class="mce-root"/>
<p class="mce-root">When you are writing a parallel application, you will often come across a situation where your tasks need to communicate one with another. One such situation when this may happen is when your concurrent tasks need to access some kind of resource that can be external or internal to the application, which is not thread-safe. In this situation, they will need to coordinate their access to this resource. Here, we have stumbled upon a very important concept to parallel programming, that is thread safety. Thread-safe resources can be accessed from any number of threads in parallel without worrying about whether something can go wrong. However, resources that are not thread-safe must be accessed from one side at a time. A typical example of a thread-safe resource is an immutable data structure. A typical example of a non-thread-safe resource is a shared mutable state.</p>
<p class="mce-root">What can possibly go wrong if you access a resource that is not thread-safe from more than one thread? Consider the example of writing to a file. Consider that you are writing an application for an online shop that is intended to generate a list of goods in some format. Consider that you need to read from a file listing goods in CSV and then transform them in some way:</p>
<pre class="mce-root">Name,Price<br/>TV Set,100<br/>iPhone 8,300<br/>Samsung Galaxy S5,300<br/>MacBook Pro,2500<br/>MacBook Air,1500</pre>
<p class="mce-root">Consider that you need to output the same goods in JSON using the <kbd>Circe</kbd> library that we have already learned about:</p>
<pre class="mce-root">{"Name":"TV Set","Price":100}<br/>{"Name":"iPhone 8","Price":300}<br/>{"Name":"Samsung Galaxy S5","Price":300}<br/>{"Name":"MacBook Pro","Price":2500}<br/>{"Name":"MacBook Air","Price":1500}</pre>
<p class="mce-root">Also consider that you want to perform this operation in parallel. What you need to do here is take every row of the CSV file and convert it into some JSON output. Then, we need to write this output into the output file. Here, we have a bunch of operations that are not dependent one on another. Every transformation of every row is independent on any other transformation of any other row. So, what we might want to do is take these tasks in parallel from two threads. Therefore, one thread will process the first half of the list, and the other thread will process the second half of the list.</p>
<p class="mce-root">The output to a file can be modeled as a certain transaction, like so:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/08cc1a4b-4dde-481f-9cdb-451dea9a2075.png" style="width:12.42em;height:14.75em;"/></div>
<p class="mce-root">In the preceding diagram, you can see that we have the operation of opening the file for writing, then executing certain atomic actions that write the data into the file, and then closing the file. For simplicity, the process of writing a string called <kbd>Hello</kbd> into a file may not look like the following:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/2492799d-0719-4cc3-b93f-f7eb9c1ca60f.png" style="width:15.25em;height:22.92em;"/></div>
<p class="mce-root">In the preceding diagram, we can see that the entire transaction is not atomic. It is composed of atomic operations, and is writing individual characters in our case. A note should be made here that the preceding example is only an example. Different implementations of writing logic might implement the transaction process differently so that the preceding atomic operations might not hold true for all environments. However, the preceding example illustrates this point very well, since most implementations still write to a file in a non-thread-safe manner using atomic actions. The entire writing transaction is not atomic.</p>
<p class="mce-root">Let's consider what happens if we try and write into the same file from two different threads:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/3c384403-3929-4b1e-a4f3-ea767b24f61a.png" style="width:20.08em;height:33.17em;"/></div>
<p class="mce-root">So, as you can see, we do not have any guarantee regarding the order in which the atomic tasks of every transaction get executed. So, as the preceding scenario comes through, you will end up with the following output to a file:</p>
<pre class="mce-root"><strong>WHoerllldo</strong></pre>
<p class="mce-root">That is what we mean when we say that an operation or a resource is not thread-safe. This means that it is only permitted to work with the source from a single thread. Working from two threads with the same resource can be done as follows:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img src="assets/5c7086ef-0671-44c5-a82f-bc1234e68670.png" style="width:17.00em;height:30.58em;"/></p>
<p class="mce-root">So, obviously, the preceding two threads must be aware of one another and of the order in which they should be executed. More precisely, we should somehow impose a guarantee that only one thread at a time will have access to the shared resource. In other words, we need to synchronize the threads somehow.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Synchronization</h1>
                </header>
            
            <article>
                
<p class="mce-root">The simplest approach that can be used to synchronize the threads is called synchronization. It is implemented on the language level and is a standard construct in most programming languages.</p>
<p class="mce-root">The idea is as follows. Certain chunks of your programming code can be made guarded, which means they cannot be executed by the thread unless a certain condition is true. The condition in question is ownership of a so-called monitor. Therefore, a thread can own certain monitors. In a JVM setting, a monitor can be any object. So, on the JVM level, we can declare that a thread owns a monitor. Threads can take ownership and release the ownership of monitors at their own discretion. Another rule is that a monitor can only be held by one thread at a time. When a thread wants to take a monitor that is already held by another thread, then this thread must wait until this monitor is released and becomes available to it once more.</p>
<p class="mce-root">The preceding framework can be used in order to synchronize threads with one with another. You can do so as follows. Whenever we have a resource that is not thread-safe and needs to be accessed from more than one thread, we guard the code by accessing it with the <kbd>synchronized</kbd> keyword, that is, in the case of Java or Scala. This can be done as follows:</p>
<pre class="mce-root">val target = new File("sample.txt")<br/> target.synchronized {<br/>   FileUtils.writeStringToFile(target, "Hello World", "utf8")<br/>}</pre>
<p class="mce-root">The preceding code is executed in the context of some thread. Every instruction is executed in the thread in sequence. When the thread reaches the <kbd>synchronized</kbd> keyword, it attempts to take the object in question as a monitor. If this object is owned by some other thread, this thread goes into sleep mode. This means it does nothing until notified that the monitor is released and available for it to acquire. Once the monitor is available, it is acquired by this thread. This thread now has a guarantee that no other threat will take the same monitor until it is held by itself. Then, this thread executes the code in a <kbd>synchronized</kbd> block.</p>
<p class="mce-root">After the code is executed, the monitor is released by the current thread. The semantics of the execution will be as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/b1368add-9d93-4536-979d-1e26e759982a.png" style="width:12.67em;height:14.33em;"/></p>
<p class="mce-root">The preceding approach might look good in theory. However, there are a bunch of serious problems that can be encountered in such a scenario. These problems are pretty hard to debug, and they cannot be spotted by modern compilers. The existence of such problems demands a better framework for reasoning and defining concurrent and parallel applications. Next, let's take a look at what these problems are.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Problems with the traditional model – race conditions and deadlocks</h1>
                </header>
            
            <article>
                
<p class="mce-root">The problems start to appear when more than one resource gets involved. Consider, for example, a slightly modified version of the preceding program. In the previous example, we had to write the result of the computation into a file. Consider that, at the same time as doing the computations themselves, we need to keep track of what they're doing in a log file. This kind of practice can be useful in a real-world scenario for debugging purposes.</p>
<p class="mce-root">So, the plan is as follows. First, the entire input file is read into the program memory. In our current scenario, threads are heterogeneous, which means that they have different tasks to accomplish. Homogeneous threads are generally easier to work with because they behave similarly and are controlled from one place. However, this is not always the case in the real world. So, let's consider threads with the following tasks. The first thread will be tasked with the conversion from CSV to JSON, as in the previous example. Also, it must report about how the conversion goes into the log file. The other thread will perform a different task. Let it compute some statistics over the file in question, for example, an average price of all the goods that the online shop is trading.</p>
<p class="mce-root"/>
<p class="mce-root">Let's see how such a program might be implemented in a traditional synchronization scenario. Before diving into this example, let's define some convenience methods and values that we will use in the example. You will need the following imports:</p>
<pre>import scala.collection.JavaConverters._<br/><br/>import java.io.File<br/>import java.nio.charset.Charset<br/><br/>import org.apache.commons.io.FileUtils</pre>
<p>For file operations, we will use the Apache Commons IO library. The dependency on it must be declared in <kbd>build.sbt</kbd>:</p>
<pre>libraryDependencies += "commons-io" % "commons-io" % "2.6"</pre>
<p>The convenience methods are as follows:</p>
<pre>// Files we will be working with<br/>   val input = new File("goods.csv" )<br/>   val log = new File("log.txt" )<br/>   val output = new File("goods.json")<br/><br/>// Encoding for the file I/O operations<br/>   val encoding = "utf8"<br/><br/>// Convenience method to construct threads<br/>   def makeThread(f: =&gt; Unit): Thread =<br/>    new Thread(new Runnable {<br/>      override def run(): Unit = f<br/>    })<br/><br/>// Convenience method to write log<br/>   def doLog(l: String): Unit = {<br/>     FileUtils.write(<br/>       log<br/>     , l + "\n"<br/>     , encoding<br/>     , true // Append to the file rather than rewrite it<br/>     )<br/>     println(s"Log: $l") // Trace console output<br/>   }<br/><br/>// Convenience method to read the input file<br/>   def readInput(): List[(String, Int)] =<br/>     FileUtils.readLines(input, encoding).asScala.toList.tail</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<pre>       .map(_.split(',').toList match {<br/>         case name :: price :: Nil =&gt; (name, price.toInt)<br/>       })</pre>
<p class="mce-root">With the stage set, let's proceed to the example. First of all, let's take a look at the first thread tasked with the conversion from CSV to JSON. The first thing you might want to do in this thread is open the file we're going to work on and read it to a list:</p>
<pre class="mce-root">val csv2json: Thread = makeThread {<br/>  val inputList: List[(String, Int)] =<br/>    input.synchronized {<br/>      val result = readInput()<br/>/*...*/</pre>
<p class="mce-root">Since files are not thread-safe resources, the first thing that we need to do is take a monitor on the file. Immediately after reading this file, we might want to report to the log that the operation was performed successfully. So, we might want to take a monitor on the log file and report the operation as follows:</p>
<pre class="mce-root">log.synchronized {<br/>  doLog(s"Read ${result.length} lines from input")<br/>}</pre>
<p>Notice that the monitor of the log file is released immediately after we are done with that reporting. So, <kbd>inputListcode</kbd> looks as follows:</p>
<pre>val inputList: List[(String, Int)] =<br/>  input.synchronized {<br/>    val result = readInput()<br/>    log.synchronized {<br/>      doLog(s"Read ${result.length} lines from input")<br/>    }<br/>    result<br/>  }</pre>
<p>Once we are done with reading the file, we perform the operation of conversion on every row of the input file, and then we write the result into the output file:</p>
<pre class="mce-root">val json: List[String] =<br/>  inputList.map { case (name, price) =&gt;<br/>    s"""{"Name": "$name", "Price": $price}""" }<br/><br/>FileUtils.writeLines(output, json.asJava)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>So, the entire code for the first thread looks as follows:</p>
<pre>val csv2json: Thread = makeThread {<br/>  val inputList: List[(String, Int)] =<br/>    input.synchronized {<br/>      val result = readInput()<br/>      log.synchronized {<br/>        doLog(s"Read ${result.length} lines from input")<br/>      }<br/>      result<br/>    }<br/><br/>  val json: List[String] =<br/>    inputList.map { case (name, price) =&gt;<br/>      s"""{"Name": "$name", "Price": $price}""" }<br/><br/>  FileUtils.writeLines(output, json.asJava)<br/>}</pre>
<p>Now, let's take a look at the other thread. It is tasked by the objective of computing certain statistics to our input file. More precisely, what we can do is compute some sort of aggregate function on all of the prices of the goods. For example, we might consider computing the average, the maximum value, and the minimum value of the set. However, we might also want to configure this thread with the exact metrics we want to compute:</p>
<pre class="mce-root">def statistics(avg: Boolean = true, max: Boolean = false, min: Boolean = false): Thread</pre>
<p>As you can see, we were able to specify which exact metrics we need to compute. A reasonable step would be to report this information to a log file before doing anything else:</p>
<pre class="mce-root">log.synchronized {<br/>  doLog(s"Computing the following stats: avg=$avg, max=$max, min=$min")<br/>}</pre>
<p class="mce-root">The first thing that we do here is take a monitor on the log file and report the metrics. The next thing we need to do is actually read the file:</p>
<pre class="mce-root">val inputList: List[(String, Int)] = log.synchronized {<br/>  doLog(s"Computing the following stats: avg=$avg, max=$max, min=$min")<br/>  val res = input.synchronized { readInput() }<br/>  doLog(s"Read the input file to compute statistics on it")<br/>  res<br/>}</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>Since we also need to report the fact that the file was read successfully to the log, we decide to release the log monitor, but only after the file is successfully read. Notice how the snippet that reports the metrics gets incorporated into the <kbd>inputList</kbd> code, so that both the statistics and the <kbd>Read the input file</kbd> reporting can be done under the same <kbd>synchronized</kbd> code block.</p>
<p class="mce-root">After reading the input file, we are able to compute the required metrics on this input file based on the parameters specified by the user as follows:</p>
<pre>val prices: List[Int] = inputList.map(_._2)<br/>def reportMetrics(name: String, value: =&gt; Double): Unit = {<br/>  val result = value<br/>  log.synchronized { doLog(s"$name: $result") }<br/>}<br/><br/>if (avg) reportMetrics("Average Price", prices.sum /<br/>  prices.length.toDouble)<br/>if (max) reportMetrics("Maximal Price", prices.max)<br/>if (min) reportMetrics("Minimal Price", prices.min)</pre>
<p>Therefore, the entire code for the <kbd>statistics</kbd> thread will look like the following:</p>
<pre>def statistics(avg: Boolean = true, max: Boolean = false, min: Boolean = false): Thread = makeThread {<br/>  val inputList: List[(String, Int)] = log.synchronized {<br/>    doLog(s"Computing the following stats: avg=$avg, max=$max, min=$min")<br/>    val res = input.synchronized { readInput() }<br/>    doLog(s"Read the input file to compute statistics on it")<br/>    res<br/>  }<br/><br/>  val prices: List[Int] = inputList.map(_._2)<br/>  def reportMetrics(name: String, value: =&gt; Double): Unit = {<br/>    val result = value<br/>    log.synchronized { doLog(s"$name: $result") }<br/>  }<br/><br/>  if (avg) reportMetrics("Average Price", prices.sum / prices.length.toDouble)<br/>  if (max) reportMetrics("Maximal Price", prices.max)<br/>  if (min) reportMetrics("Minimal Price", prices.min)<br/>}</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p class="mce-root">What happens if you run this thread in parallel with the first thread?</p>
<pre class="mce-root">csv2json.start()<br/>statistics(true, true, true).start()</pre>
<p class="mce-root">You may notice that, sometimes, the program hangs and becomes non-responsive. This situation is called a <strong>deadlock</strong>.</p>
<p class="mce-root">Basically, the problem here is that the two threads are racing for the resources. It is a race condition of who takes which monitor first. The first thread takes the monitor on the input file, and then it takes the monitor on the log. Then, it releases the monitor on the lock, and then it releases the monitor on the input file:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/b26dab53-8f3e-485f-890a-3b94cb6a6a30.png" style="width:18.83em;height:18.33em;"/></div>
<p>In the preceding diagram, the orange bar represents the code that is executed under the input monitor. The blue bar is the code under the log monitor. In this particular case, the blue code also owns the input monitor, since it has not been released from the time of its execution yet.</p>
<p class="mce-root">The second thread, in contrast, does these operations in a different order. First, it takes a lock on the log file. Then, it takes the lock on the input file, and then it releases the lock on the input file, before releasing the lock on the log file:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/442b21f4-7289-4e13-9845-4448e6ae9a2b.png" style="width:16.42em;height:15.67em;"/></div>
<p class="mce-root">The two threads depend on the same set of resources, and the order in which they acquire them is not defined. This means that they will be competing for these resources, and when you run the program several times, the order of resources in acquisition will be different from run to run.</p>
<p class="mce-root">Let's take a look at a case where an application works well:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/2880eb78-a06a-4b26-ad8a-767350d766b7.png" style="width:20.17em;height:21.17em;"/></div>
<p class="mce-root">In the preceding diagram, the first thread takes the monitor on input and then it takes a monitor on the log, but after that, the second thread attempts to take the lock on the log, but it is late to do that. Therefore, it is forced to wait until the other thread finishes. The first thread has acquired all of the locks it is dependent on, and so it finishes successfully. After it finishes, it releases all of monitors it owns, and the second thread is capable of taking them.</p>
<p class="mce-root">Now, let's take a look at how and why exactly the application gets a deadlock:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c0787699-8448-43c1-b377-9070fe798a24.png" style="width:27.58em;height:15.75em;"/></div>
<p class="mce-root">So, in the example above, the first thread takes the monitor on the input file. Together with it, the second thread takes the monitor on the log file. After that, in order to proceed, the first thread needs a monitor on the log file, but it cannot take it because the second thread has already taken it, and so it is forced to wait.</p>
<p class="mce-root">The second thread needs the monitor on the input file in order to proceed. However, it cannot take it because it is owned by the first thread, and so it is also forced to wait. This means we have ended up in a situation where neither of the threads can proceed until the other thread finishes, and so neither of the threads ever finishes. This kind of situation is called a deadlock.</p>
<p class="mce-root">A quick fix may be to make the threads and take the monitor in the same order. For example, if the first thread takes the monitor on the input file and then a monitor on the log file, we might want to enforce the same order on the second thread as well. So, the second thread will look as follows:</p>
<pre class="mce-root">def statisticsSafe(avg: Boolean = true, max: Boolean = false, min: Boolean = false): Thread = makeThread {<br/><strong>  val inputList: List[(String, Int)] = input.synchronized {</strong><br/><strong>    log.synchronized {</strong><br/><strong>      doLog(s"Computing the following stats: avg=$avg, max=$max, min=$min")</strong><br/><strong>      val res = readInput()</strong><br/><strong>      doLog(s"Read the input file to compute statistics on it")</strong><br/><strong>      res</strong><br/><strong>    }</strong><br/><strong>  }</strong><br/><br/>  val prices: List[Int] = inputList.map(_._2)<br/>  def reportMetrics(name: String, value: =&gt; Double): Unit = {<br/>    val result = value<br/>    log.synchronized { doLog(s"$name: $result") }<br/>  }<br/><br/>  if (avg) reportMetrics("Average Price", prices.sum / prices.length.toDouble)<br/>  if (max) reportMetrics("Maximal Price", prices.max)<br/>  if (min) reportMetrics("Minimal Price", prices.min)<br/>}</pre>
<p class="mce-root">The preceding chunk of code in bold is what was changed compared to the <kbd>statistics</kbd> thread definition. Now, whoever takes the monitor on the input file first is guaranteed to finish the execution. This is because, in the preceding application, it is impossible to take the monitor on the log file unless you already own the monitor on the input file. So, whoever takes the monitor on the input file is guaranteed to be able to take the same monitor on the log file.</p>
<p class="mce-root">The fix might work in the short term. However, you might have already noticed that it is suboptimal. In the previous example, we had a pretty simple situation. We only had two threads and two resources they depend on. That kind of simple setting is not likely to happen in the real world. Real-world applications are likely to have dozens of threads in them and depend on dozens of resources. Also, debugging the preceding complexity was tricky. If only two threats were capable of producing such complexity and required a lot of our brain power to do the analysis and find the problem, imagine how this complexity can grow in magnitude in a real-world setting.</p>
<p class="mce-root">This is precisely why the standard synchronization approach to parallel programming is not practical in the long run. It's fine as a low-level model of programming so that people build some high-level primitives on top of it. However, we cannot use it in practice efficiently. These kinds of problems with threads and concurrent applications provided a motivation to create newer, more robust approaches to reasoning about concurrent programming. We already discussed some of them briefly at the beginning of this chapter. Now, let's talk about the actor model in more detail.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The actor model as a replacement for the traditional model</h1>
                </header>
            
            <article>
                
<p class="mce-root">One of the most popular approaches to dealing with the complexity discussed previously is the actor approach to concurrent programming. If you look at the preceding examples in detail, you will notice one thing about them, that is, global reasoning. Whenever we have several threads that need to communicate in one with another, we are forced to reason about them together. So, we cannot take one thread and reason about it independently from other threads.</p>
<p class="mce-root">As we saw previously, the solution to the deadlock problem was to change the order in which the monitors were taken in the second thread so that the order matched the one in the first thread. Basically, when we are working in the scope of the second thread, we are forced to take into account the operations done in the first thread.</p>
<p class="mce-root">Global reasoning produces mental load on the programmer's mind. One of the central points of this book is that purely functional programming aims to reduce the mental load on the programmer's mind by reducing the scope of reasoning about the programs.</p>
<p class="mce-root">How can we tackle the problem of the global scope and shared mutable state as the means of communication between threads in the context of concurrent programming? The response of the actors model would be to provide a set of abstractions to ensure that whenever you are programming a parallel application, you are able to forget that you are working in a concurrent environment. The central point behind the actors model, the central idea of why it is created, and why it exists, is to make your program within a concurrent environment as if you were dealing with a single threaded application, which means you no longer need to think about taking monitors or accessing resources in a thread-safe manner.</p>
<p class="mce-root">The actor model does this by providing you with a set of abstractions and a set of conventions that you must follow as part of the model. A central abstraction of the actor model is, not surprisingly, an actor. An actor can be roughly thought of as a thread. It is not necessarily mapped one-to-one on threads; in fact, it is a more lightweight primitive, and you might have thousands upon thousands of actors. The way their concurrency is managed is in abstracted away. However, the right way to think about actors is that they are the concurrency primitives of the actor model.</p>
<p class="mce-root"/>
<p class="mce-root">An actor can own certain resources, and if it does, it is guaranteed that no other actor owns or has access to these sources. For example, if an actor has a reference to a file, it is guaranteed that no other actor has the same reference to the same file, so it is not able to write or read from the file. If it does need to access a resource owned by another actor, it needs to ask the owner actor to perform the required operation on behalf of this actor. Since all of the operations over a non-thread-safe or resource are done by one and only one actor, and actors are sequential and single threaded entities, there is no danger that some non-thread-safe behavior will emerge in this context.</p>
<p class="mce-root">How exactly does one actor ask another actor to perform an action? This is done by messaging. Every actor has a so-called <strong>mailbox</strong>. A mailbox is a place where all of the incoming communications to this actor are stored. A single unit of communication in the actor model is a message. A message can be anything as long as it complies with the constraints of the actor model, which we will be discussing later. A mailbox is a queue. Therefore, the messages from many actors that run and send messages in parallel may arrive to the single actor, and they will get sorted into a single sequential queue. An actor is guaranteed to process only one message at a time. So, the way it works is that the actor waits on its mailbox for mail. Then, it takes one letter at a time and processes it sequentially.</p>
<p class="mce-root">One way regarding how exactly to process the incoming mail is defined in the body of an actor in terms of reactions to different kinds of incoming mail. So, for every type of mail the actor is capable of handling, it defines a certain function that is supposed to be executed whenever this letter arrives to the actor.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deadlock example revisited</h1>
                </header>
            
            <article>
                
<p class="mce-root">So far, we have looked at the actors model at a glance. We have not learned any practical implementations of the actor model just yet. However, it can be instructive to take a look at how our previous example can be implemented so that we are rid of the complexity that we have faced with it.</p>
<p class="mce-root">First of all, we have discussed that actors are primitives of concurrency of the actors model. In the preceding example, the primitives of concurrency were two threads that performed some operations. So, it is reasonable to map the operations that we need to perform from the two threads onto two actors of the actor model. So now, instead of two threads, we have two actors. One actor is supposed to generate JSON from CSV, and the other actor is supposed to compute some statistics on the CSV file.</p>
<p class="mce-root">In the preceding example, we had two files that we were supposed to work with and two threads that needed to get access to both of the files. The actors model requires that only one actor must own a given resource. So, if the first actor needs a resource, the second actor cannot have it. In our situation, the first and second actors need to work with the input file and the log file. How should we tackle this situation? How should we make it compliant with the actor model?</p>
<p class="mce-root">The solution is that none of the two actors should own this resource. Instead, we should create a third actor that is responsible for running operations that involve these resources. Then, whenever we need to do something with a result, we send a message to that actor asking to perform the required operation.</p>
<p class="mce-root">Since our actor, let's call it process manager, controls access to the input file and the log file, we must expect the request from other actors to perform operations relevant to this resource. In other words, we also need to define the reactions to all the possible messages that it might receive. Hence, we need to think about what kind of operations request we might get from other actors. We can consider the following requests:</p>
<ul>
<li class="mce-root">First, we get the input file. This message is a request to read the input file and send it back to the requesting actor as an immutable collection. Sharing an immutable resource between two actors is perfectly fine since immutable resources are thread-safe.</li>
<li class="mce-root">Secondly, we may be expecting a request to write into the log file. Upon receiving this request, the resource manager actor will perform a write operation into the log file with the message that was sent to it.</li>
</ul>
<p class="mce-root"/>
<p class="mce-root">Once we have the resource manager actor, we can express the example like so:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/6ae66c87-28e7-47de-9a01-74a53ebd18d0.png" style="width:30.50em;height:31.17em;"/></div>
<p class="mce-root">Now, the first two actors that do the actual job are defined in terms of messages and communication with the resource manager. The first actor asks the process manager to send it an input file. Upon receiving a response from the resource manager, it starts its operations, and whenever it performs a significant action that requires logging, it sends the log message to the resource manager. No monitors are taken in this situation since all of the resources are owned by a single actor. All of the other actors are not calling them directly—they are just asking the resource actor to perform the operations on their behalf.</p>
<p class="mce-root">The second actor has a similar situation to itself. First of all, it sends a log message to the resource manager with the statistics it is going to compute. Secondly, it requests the input file from the resource manager. Finally, upon receiving the input file as a separate message, it performs the computation and also contacts our resource manager whenever it needs logging.</p>
<p class="mce-root">None of the actors need to take monitors or synchronize one with another in order to ensure that the non-thread-safe resources are safe to work with. They are all owned by a single actor, and this single actor works with them sequentially from its own single thread. The messages that the other actors send to it may arrive in parallel, but they will be aggregated in a single mailbox, and they will not be processed right away. The resource actor processes messages at its own pace, at its own time, whenever it has the resources and the processing time allocated to the underlying system. It is guaranteed that this actor will process the messages one at a time, and no two messages will be processed in parallel. Hence, we have a greatly increased level of thread safety.</p>
<p class="mce-root">Also, noticed that in the preceding diagram, we have a scenario that would cause a deadlock in the standard synchronization model. The first actor needs to access the file, and then it needs to access the log, and the second actor needs to access the log and then the file. Previously in this chapter, we discussed how this kind of situation yields the possibility of a deadlock. Here, the deadlock is no longer possible, since the resources are controlled by a single actor.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, we had a brief overview of the motivation and the idea behind the actor model. We saw how the architecture of applications can be expressed in terms of what the actor model might look like. In the next chapter, we will dive deeper into the model and see how to use it in practice. We will learn some practical implementations and frameworks of the models that we can use in our projects right away.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li class="mce-root">How does the synchronization model work in synchronizing parallel computations?</li>
<li class="mce-root">How does a deadlock occur? Describe a scenario in which a deadlock can occur.</li>
<li class="mce-root">What are the main abstractions and constraints of the actor model?</li>
<li class="mce-root">How does the actor model help prevent the problems that usually arise under the synchronization model?</li>
</ol>


            </article>

            
        </section>
    </body></html>