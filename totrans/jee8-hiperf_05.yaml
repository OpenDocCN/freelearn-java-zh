- en: Scale Up – Threading and Implications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展 - 线程及其影响
- en: Scalability has always been a concern for Java and, thus, a thread-related API
    was introduced in Java version 1.0\. The idea is to be able to benefit from the
    most modern hardware updates in order to parallelize the processing of applications.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性一直是Java的关注点，因此，在Java 1.0版本中引入了与线程相关的API。其理念是能够从最新的硬件更新中受益，以便并行处理应用程序。
- en: Being able to handle multiple requests in parallel is crucial for a Java EE
    server to scale, but in our modern Java world, you also need to be able to control
    your own threads. Also, Java EE introduced the required API to do it in good conditions.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 能够并行处理多个请求对于Java EE服务器进行扩展至关重要，但在我们现代的Java世界中，您还需要能够控制自己的线程。此外，Java EE引入了所需的API，以便在良好的条件下进行操作。
- en: 'In this chapter, we will go through the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨以下主题：
- en: Java EE threading model
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java EE线程模型
- en: Data consistency across threads
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程间的数据一致性
- en: Java EE hidden thread usages
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java EE隐藏的线程使用
- en: How to integrate reactive programming with the Java EE programming model
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将响应式编程与Java EE编程模型集成
- en: Java EE threading model
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java EE线程模型
- en: The Java EE philosophy has, for a long time, been able to give its users a well-defined
    and safe programming model. This is why most of the Java EE defaults are about
    being thread-safe, and that several specifications such as **Enterprise Java Beans**
    (**EJB**) defaults were preventing custom thread usage. It does not mean Java
    EE was ignoring threads at all, but explicitly using thread pools from an application
    was not very natural. Also, most of the time, the adopted coding style was either
    against Java EE's (strict) rules or were very verbose.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Java EE哲学长期以来一直能够为用户提供一个定义良好且安全的编程模型。这就是为什么大多数Java EE默认设置都是关于线程安全的，以及像**企业JavaBeans（EJB**）这样的规范默认阻止自定义线程使用。这并不意味着Java
    EE完全忽视了线程，但显式地从一个应用程序中使用线程池并不很自然。此外，大多数时候，采用的编码风格要么违反Java EE的（严格）规则，要么非常冗长。
- en: Before detailing the new API added by Java EE to help you develop concurrent
    applications, let's see the basic Java EE model and how it can already help you
    to scale.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在详细说明Java EE新增的API以帮助您开发并发应用程序之前，让我们先看看基本的Java EE模型以及它如何已经可以帮助您进行扩展。
- en: 'If we take back the specifications included in Java EE 8 (full profile), we''ll
    get a long list. Now, if we check which specifications use threads, the list will
    be shorter and we can find some common points among them. Here is a table trying
    to represent whether the specifications manage dedicated threads or not and whether
    they explicitly interact with threads (handling cross-thread calls by using the
    provided threads) or simply use the caller (contextual) thread:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们回顾Java EE 8（完整配置）中包含的规范，我们会得到一个长长的列表。现在，如果我们检查哪些规范使用线程，列表将会缩短，我们可以在它们之间找到一些共同点。以下是一个表格，试图表示规范是否管理专用线程以及它们是否明确与线程交互（通过使用提供的线程处理跨线程调用）或简单地使用调用者（上下文）线程：
- en: '| **Specification** | **Manage dedicated threads** | **Interacts with threads**
    | **Comment** |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| **规范** | **管理专用线程** | **与线程交互** | **注释** |'
- en: '| EJB 3.2 | Yes | Yes | `@Asynchronous` allows you to execute tasks in a dedicated
    thread pool. `@Lock` used with `@Singleton` allows you to control the thread safety
    of the bean. |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| EJB 3.2 | 是 | 是 | `@Asynchronous` 允许您在专用线程池中执行任务。与`@Singleton`一起使用`@Lock`允许您控制bean的线程安全性。|'
- en: '| Servlet 4.0 | Yes | Yes | Every request is executed in a single thread provided
    by the container by default. When using `AsyncContext`, you can execute the task
    in a custom thread and resume the request from another thread later. |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| Servlet 4.0 | 是 | 是 | 默认情况下，每个请求都在容器提供的单个线程中执行。当使用`AsyncContext`时，您可以在自定义线程中执行任务，并在稍后从另一个线程恢复请求。|'
- en: '| JSP 2.3/JSP Debugging 1.0 | No | No | Inherits from the servlet model. |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| JSP 2.3/JSP Debugging 1.0 | 否 | 否 | 继承自servlet模型。|'
- en: '| EL 3.0 | No | No | Uses the caller context. |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| EL 3.0 | 否 | 否 | 使用调用者上下文。|'
- en: '| JMS 2.0 | Yes | No | By itself, JMS can be seen as a specific sort of connector
    (as in *Connector 1.7*) but put a few specific words on this case. JMS has two
    sorts of usages: on the server side and on the client side. The server side is
    generally a network server expecting connection. This is where dedicated threads
    will be used (such as any socket server). Then, the processing will be fully delegated
    to the connector. On the client side, it generally inherits from the caller context
    but also uses custom threads, as it is asynchronous by design. So, it needs its
    own thread pools to handle this part of the JMS specification. |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| JMS 2.0 | 是 | 否 | 本身，JMS 可以被视为一种特定的连接器（如 *Connector 1.7*），但在这个案例中要特别说明。JMS
    有两种使用方式：在服务器端和客户端。服务器端通常是一个网络服务器，等待连接。这就是将使用专用线程的地方（如任何套接字服务器）。然后，处理将完全委托给连接器。在客户端，它通常继承自调用上下文，但也使用自定义线程，因为它按设计是异步的。因此，它需要自己的线程池来处理
    JMS 规范的这一部分。|'
- en: '| JTA 1.2 | No | Yes | JTA doesn''t manage threads but *binds* its context
    to threads. Concretely, when a transaction starts, it is only valid for the initial
    thread. |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| JTA 1.2 | 否 | 是 | JTA 不管理线程，而是 *绑定* 其上下文到线程。具体来说，当事务开始时，它仅对初始线程有效。|'
- en: '| JavaMail 1.6 | Yes | No | JavaMail being the link between your Java code
    and the way mails are sent/received, the implementation is, here again, linked
    to a socket, and thus, it often relies on dedicated threads. |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| JavaMail 1.6 | 是 | 否 | JavaMail 作为你的 Java 代码与发送/接收邮件方式之间的桥梁，其实现再次与套接字相关联，因此，它通常依赖于专用线程。|'
- en: '| Connector 1.7 | Yes | Yes | Connector specification is the standard way to
    interact with external systems (bi-directional ways even if connector implementations
    often handle only one way). However, it generally uses dedicated threads in two
    layers, the first one being related to the network interactions and the second
    one being related to the container interaction that generally goes through `WorkManager`,
    which is the ancestor of the *Concurrency Utilities for Java EE* specification.
    Like JTA, it also uses context-related information that is often bound to the
    thread. Finally, since it interacts with the JTA, a part of the interactions is,
    by design, bound to threads. |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| Connector 1.7 | 是 | 是 | Connector 规范是与外部系统交互的标准方式（即使连接器实现通常只处理单向，双向方式）。然而，它通常在两层中使用专用线程，第一层与网络交互相关，第二层与容器交互相关，通常通过
    `WorkManager` 进行，它是 *Java EE 并发实用工具规范* 的前身。像 JTA 一样，它也使用与线程相关联的上下文信息。最后，由于它与 JTA
    交互，交互的一部分按设计绑定到线程上。|'
- en: '| Web Services 1.4 / JAX-RPC 1.1 | No | No | Web services generally just inherit
    from the servlet contextual threading model. |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| Web Services 1.4 / JAX-RPC 1.1 | 否 | 否 | Web 服务通常只是继承自 servlet 上下文线程模型。|'
- en: '| JAX-RS 2.1 | Yes | Yes | JAX-RS inherits from the servlet contextual model,
    but since JAX-RS 2.0, the server can asynchronously handle the requests, thanks
    to Servlet 3.0 `AsyncContext`. In this case, the developer must notify the container
    when a request is completed and interacts with threads, as it is generally done
    from a different thread from the servlet one.On the client side, JAX-RS 2.1 now
    has a reactive API, able to use custom threads to do the execution. |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| JAX-RS 2.1 | 是 | 是 | JAX-RS 继承自 servlet 上下文模型，但自从 JAX-RS 2.0 以来，服务器可以异步处理请求，这得益于
    Servlet 3.0 的 `AsyncContext`。在这种情况下，当请求完成时，开发者必须通知容器，并且与线程交互，因为这通常是在与 servlet
    线程不同的线程中完成的。在客户端，JAX-RS 2.1 现在有一个反应式 API，能够使用自定义线程进行执行。|'
- en: '| WebSocket 1.1 | Yes/No | Yes/No | Normally, the WebSocket specification was
    designed to be implemented on top of the servlet specification, which is really
    the Java EE central transport. However, for several cases, it may be needed to
    use some customization of the threading for WebSocket needs (long connections).
    This part highly depends on the container. The last thing is that some custom
    WebSocket threads may be needed to handle connection evictions and things like
    that, but it has less impact on the end user and performance. |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| WebSocket 1.1 | 是/否 | 是/否 | 通常，WebSocket 规范被设计为在 servlet 规范之上实现，这实际上是 Java
    EE 的核心传输。然而，在几个情况下，可能需要使用一些针对 WebSocket 需求（长连接）的线程定制。这部分高度依赖于容器。最后，可能需要一些自定义的
    WebSocket 线程来处理连接驱逐等问题，但这对接端用户和性能的影响较小。|'
- en: '| JSON-P 1.1 / JSON-B 1.0 | No | No | This specification (JSON low-level API
    and JSON binding) does not have any thread-related operations and simply executes
    in the caller context. |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| JSON-P 1.1 / JSON-B 1.0 | 否 | 否 | 这个规范（JSON低级API和JSON绑定）没有任何线程相关操作，并且简单地执行在调用者上下文中。
    |'
- en: '| Concurrency Utilities for Java EE 1.0 | Yes | Yes | Concurrency utilities
    mainly have the ability to define *Java EE thread pools* and, indeed, they manage
    custom threads. It also transparently facilitates (through `ContextService`) the
    propagation of some contexts, such as security, JNDI context, transaction, and
    so on. Note that, however, the propagation is not standard and you may need to
    check out your server documentation to know what it does precisely. |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| Java EE 并发工具 1.0 | 是 | 是 | 并发工具主要具有定义 *Java EE 线程池* 的能力，实际上它们管理自定义线程。它还通过
    `ContextService` 透明地促进某些上下文的传播，例如安全、JNDI 上下文、事务等。请注意，然而，传播不是标准的，您可能需要查看服务器文档以了解它确切的功能。
    |'
- en: '| Batch 1.0 | Yes | No | JBatch is asynchronous by design. When you launch
    a batch, the invocation returns before the batch is done, as it can be very long.
    To handle such behavior JBatch has its own thread pools. |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 批处理 1.0 | 是 | 否 | JBatch按设计是异步的。当你启动一个批处理时，调用在批处理完成之前返回，因为它可能非常长。为了处理这种行为，JBatch有自己的线程池。
    |'
- en: '| JAXR 1.0 | No | No | This specification is rarely used and has become old
    (before Java introduced nio). Being a client, it doesn''t use custom threads.
    |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| JAXR 1.0 | 否 | 否 | 这个规范很少使用，并且已经过时（在Java引入nio之前）。作为一个客户端，它不使用自定义线程。 |'
- en: '| Java EE Management 1.1 (or 1.2) | Yes/No | No | This specifications allows
    you to interact with the server and its definitions (resources and applications).
    It uses another transport technology, so it generally needs dedicated threads.
    |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| Java EE 管理规范 1.1（或1.2） | 是/否 | 否 | 这个规范允许您与服务器及其定义（资源和应用）交互。它使用另一种传输技术，因此通常需要专用线程。
    |'
- en: '| JACC 1.5 | No | No | This is a specification linking an authorization policy
    with the Java EE container. It is contextually executed. |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| JACC 1.5 | 否 | 否 | 这是一个将授权策略与Java EE容器链接的规范。它是上下文执行的。 |'
- en: '| JASPIC 1.1 | No | No | This is a security specification, also contextually
    executed. |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| JASPIC 1.1 | 否 | 否 | 这是一个安全规范，也是上下文执行的。 |'
- en: '| Java EE Security API 1.0 | No | No | This is the last security API of Java
    EE, making it pretty usable, but it stays contextual to the caller. |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| Java EE 安全API 1.0 | 否 | 否 | 这是Java EE的最后一个安全API，使其非常实用，但它仍然与调用者上下文相关。 |'
- en: '| JSTL 1.2 | No | No | Inherits from the servlet model. |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| JSTL 1.2 | 否 | 否 | 继承自servlet模型。 |'
- en: '| Web Service Metadata 2.1 | No | No | This mainly involves annotations for
    web services, so there''s  no particular threading model. |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| Web 服务元数据 2.1 | 否 | 否 | 这主要涉及Web服务的注解，所以没有特定的线程模型。 |'
- en: '| JSF 2.3 | No | No | Inherits from the servlet threading model (this is a
    simplification but good enough for this book''s context). |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| JSF 2.3 | 否 | 否 | 继承自servlet线程模型（这是一个简化，但对于本书的上下文来说足够好了）。 |'
- en: '| Common annotations 1.3 | No | No | Just a set of APIs reused by other specifications,
    no particular behavior directly bound here. |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 常见注释 1.3 | 否 | 否 | 只是一组由其他规范复用的API，没有直接绑定在这里的特殊行为。 |'
- en: '| Java Persistence 2.2 (JPA) | No | No | Inherits from the caller context.
    |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| Java 持久化 2.2 (JPA) | 否 | 否 | 继承自调用者上下文。 |'
- en: '| Bean Validation 2.0 | No | No | Inherits from the caller context. |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| Bean 验证 2.0 | 否 | 否 | 继承自调用者上下文。 |'
- en: '| Interceptors 1.2 | No | No | Inherits from the caller context. |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 拦截器 1.2 | 否 | 否 | 继承自调用者上下文。 |'
- en: '| Contexts and Dependency Injection for Java EE 2.0 (CDI) | Yes | Yes | CDI
    2.0 supports asynchronous events, which rely on a dedicated thread pool. CDI being
    about *contexts*, also binds contextual data to threads such as the `@RequestScoped`
    context. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| Java EE 上下文和依赖注入 2.0 (CDI) | 是 | 是 | CDI 2.0支持异步事件，这些事件依赖于一个专用的线程池。CDI关于
    *上下文*，也将上下文数据绑定到线程，例如 `@RequestScoped` 上下文。 |'
- en: '| Dependency Injection for Java 1.0 (@Inject) | No | No | This is mainly a
    set of annotations of CDI, so there''s no real thread-related behavior here. |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| Java 1.0 依赖注入 (@Inject) | 否 | 否 | 这主要是CDI的一组注解，所以这里没有真正的线程相关行为。 |'
- en: 'If we review all the thread usages, we can distinguish between some categories:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们回顾所有线程的使用情况，我们可以区分以下类别：
- en: 'Asynchronous usages: the specification using threads not to block the caller
    execution (such as JAX-RS client, Batch API, CDI asynchronous events, and so on)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异步用法：使用线程不阻塞调用者执行的规范（例如JAX-RS客户端、批处理API、CDI异步事件等）
- en: Network-related implementations that need threads for the selector (partly accepting
    the connections) and request handling
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要线程进行选择器（部分接受连接）和请求处理的网络相关实现
- en: 'In terms of code context, this is generally related to the outbound layers
    of the code. Indeed, the network is an outbound of the application, but asynchronous
    usages are also in the sense that they split the execution into two branches:
    the caller context that continues and a new branch that is no more linked to the
    caller.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码上下文中，这通常与代码的外出层有关。确实，网络是应用程序的外出，但异步使用也在此意义上，因为它们将执行分成两个分支：继续执行的调用上下文和一个不再与调用者相关的新分支。
- en: What does it mean for you? When you take the lead on an application, at least
    from a performance or configuration point of view, you need to be clear about
    the thread execution path of the application (when the application uses a different
    thread from the one it got affected by, when the request entered into the system).
    This is also true for inter-system architectures, such as microservices, where
    you need to track the execution context breakdowns.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这对你意味着什么？当你负责一个应用程序时，至少从性能或配置的角度来看，你需要清楚了解应用程序的线程执行路径（当应用程序使用一个不同于受影响的线程时，当请求进入系统时）。这也适用于像微服务这样的跨系统架构，你需要跟踪执行上下文的分解。
- en: Thread data and consistency
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程数据和一致性
- en: Before getting Java EE-specific, it is important to step back a moment and understand
    the implications of concurrency on the programming model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在具体到Java EE之前，重要的是退一步理解并发对编程模型的影响。
- en: Concurrent data access
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发数据访问
- en: When a single thread accesses data, then the access is always thread-safe, and
    it is not possible for a thread to mutate data while another one is reading it.
    When you increase the number of threads and multiple threads can access the same
    data structure instances, it is possible for a thread to read the data that's
    currently being modified, or for two concurrent modifications to happen, leading
    to an inconsistent result.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当单个线程访问数据时，访问总是线程安全的，一个线程在另一个线程读取数据时不可能修改数据。当你增加线程数量，并且多个线程可以访问相同的数据结构实例时，一个线程可能会读取正在被修改的数据，或者可能发生两个并发修改，导致不一致的结果。
- en: 'Here is a schema representing this issue with two threads. Keep in mind that
    a Java EE server often handles  around 100 to 1000 threads, so the effects are
    more impacting:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个用两个线程表示这个问题的模式。请记住，Java EE服务器通常处理大约100到1000个线程，因此影响更为显著：
- en: '![](img/68e59b4f-1bb0-4fab-8e82-d359d7e6bb26.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/68e59b4f-1bb0-4fab-8e82-d359d7e6bb26.png)'
- en: In this simple example, we have a thread (**Thread 1**) setting data that is
    supposed to be a complex structure. In parallel, we have another thread (**Thread
    2**) accessing the data. In the  preceding diagram, the very thin black line represents
    the thread life, whereas the bold black line represents the method execution in
    the thread's context. The blue box represents the data setter/getter execution
    time and the red zone represents the overlap of both threads on the data usage.
    In other words, you can consider that the vertical unit is time.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的例子中，我们有一个线程（**Thread 1**）正在设置数据，这些数据应该是一个复杂结构。同时，我们还有另一个线程（**Thread 2**）正在访问这些数据。在先前的图中，非常细的黑线代表线程的生命周期，而粗黑线则代表线程上下文中的方法执行。蓝色方框代表数据设置/获取的执行时间，红色区域代表两个线程在数据使用上的重叠。换句话说，你可以认为垂直单位是时间。
- en: 'To understand what can be the impact of such a code without any protection,
    let''s materialize the data structure with this simple code:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解没有保护的代码可能产生的影响，让我们用以下简单代码具体化数据结构：
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This simple structure aims to store a `String` value and handle a state (`initialized`),
    which allows the structure to prevent access to the data if uninitialized.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的结构旨在存储一个`String`值并处理一个状态（`initialized`），这允许结构在未初始化时防止对数据的访问。
- en: 'If we apply this structure on our previous picture timeline, it is possible
    that **Thread 2** calls `getData` and fails with `IllegalStateException`, whereas
    the `setData` method is called and sets the `initialized` variable. In other words,
    the structure (`getData`) was accessed while it was changing and, thus, the behavior
    was not consistent with the complete state of the data. In this case, the error
    is not dramatic, but if you take another example summing some values, you will
    just get the wrong data:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这个结构应用到我们之前的图片时间线上，可能的情况是**线程2**调用`getData`失败并抛出`IllegalStateException`，而`setData`方法被调用并设置了`initialized`变量。换句话说，结构（`getData`）在变化时被访问，因此其行为与数据的完整状态不一致。在这种情况下，错误并不严重，但如果你考虑另一个例子，比如求和某些值，你将只会得到错误的数据：
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If the execution of `sum` is done and `value` is accessed at the same time,
    then the account value will be wrong, the reporting will potentially be inconsistent,
    and the validation (which likely considers *credit+debit=0*) will fail, making
    this account erroneous.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`sum`的执行和`value`的访问同时进行，那么账户的值将会错误，报告可能会不一致，验证（可能考虑*信用+借记=0*）将失败，使这个账户出现错误。
- en: 'If you look one step further and integrate some EE features, you will quickly
    understand that the situation is even worse. Let''s take the case of a JPA entity,
    such as `Quote`, and assume that two threads are differently modifying the entity:
    one thread modifies the price and the other one modifies the name. What will happen
    when each thread updates the entity? The database can''t handle both the updates
    at the same time, so if there is no failure, then the last update will win and
    only one of the two updates will be taken into account.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你再进一步看看并集成一些EE功能，你会很快明白情况会更糟。让我们以一个JPA实体为例，比如`Quote`，并假设两个线程正在不同地修改实体：一个线程修改价格，另一个线程修改名称。当每个线程更新实体时会发生什么？数据库无法同时处理这两个更新，所以如果没有失败，则最后一个更新将获胜，只有其中一个更新会被考虑。
- en: JPA provides optimistic and pessimistic locking to properly solve the aforementioned
    problem. As a general rule, try to use optimistic locking until you really need
    pessimistic locking. In fact, it will give you a better performance even if it
    will require you to potentially handle a retry logic if relevant.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: JPA提供了乐观锁和悲观锁来正确解决上述问题。一般来说，尽量使用乐观锁，直到你真正需要悲观锁。实际上，即使它可能需要你处理重试逻辑，它也会给你更好的性能。
- en: Java and thread safety
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java和线程安全
- en: This section doesn't intend to explain all the solutions that Java provides
    to ensure the thread safety of your code but just to give you some highlights
    on Java Standalone API, you can reuse in Java EE application if needed.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这一节并不打算解释Java提供的所有确保代码线程安全的解决方案，只是给你一些关于Java Standalone API的亮点，如果需要，你可以在Java
    EE应用程序中重用。
- en: Synchronized
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 同步
- en: 'Surely the oldest solution, but still available in Java, the `synchronized`
    keyword allows you to ensure that methods are not concurrently executed. You just
    need to add it in your method definition as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这是最古老的解决方案，但在Java中仍然可用，`synchronized`关键字允许你确保方法不会被并发执行。你只需在你的方法定义中添加它，如下所示：
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This is the exact same structure as the one we just saw. But now, thanks to
    the `synchronized` keyword added to each method, the call to a method would enforce
    concurrent calls to other synchronized methods to wait for the first one to end
    before being executed. Concretely, it will chain method execution like in a single
    thread.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们所看到的结构完全相同。但现在，多亏了添加到每个方法的`synchronized`关键字，对方法的调用将强制并发调用其他同步方法等待第一个方法执行完毕后再执行。具体来说，它将像单线程一样链式执行方法。
- en: The `synchronized` keyword is linked to an instance, so two different instances
    that are synchronized will not lock each other. It is also possible to use `synchronized`
    as a block and pass the instance to synchronize on. If you do so and pass a static
    instance, then you will lock all the instances that can prevent the application
    from scaling if on a common code path.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`synchronized`关键字与一个实例相关联，所以两个不同实例即使被同步也不会相互锁定。也可以将`synchronized`用作代码块，并将实例传递给要同步的实例。如果你这样做，并传递一个静态实例，那么你将锁定所有实例，这可能会阻止应用程序在公共代码路径上扩展。'
- en: Locks
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 锁
- en: Java 1.5 introduces the `Lock` interface with its `java.util.concurrent` package,
    which contains a lot of concurrency-related classes. It achieves the same goal
    as that of `synchronized` but allows you to control manually the scope of the
    synchronized code.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Java 1.5 通过 `java.util.concurrent` 包引入了 `Lock` 接口，该包包含许多与并发相关的类。它实现了与 `synchronized`
    相同的目标，但允许您手动控制同步代码的范围。
- en: The performance of `Lock` and `synchronized` differs between Java versions,
    but recent versions have progressed a lot. And generally, if you don't optimize
    a computing algorithm, choosing one or the other will lead to something close.
    However, it is generally better to use `Lock` if the number of concurrent threads
    accessing the instance is high.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`Lock` 和 `synchronized` 的性能在不同版本的 Java 中有所不同，但最新版本已经取得了很大的进步。一般来说，如果您不优化计算算法，选择其中一个或另一个将导致结果相似。然而，如果同时访问实例的并发线程数量很高，通常最好使用
    `Lock`。'
- en: 'As `Lock` is an interface, it needs an implementation. The JRE comes with a
    default implementation called `ReentrantLock`. Replacing a `synchronized` block
    is done in the following way:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `Lock` 是一个接口，它需要一个实现。JRE 提供了一个默认实现，称为 `ReentrantLock`。替换 `synchronized` 块的方式如下：
- en: '[PRE3]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The lock instantiation is directly done through the `new` keyword. We will note
    here that `ReentrantLock` can take a Boolean parameter to request it to respect
    a fair order for the lock invocations (the default is `false` and generally good
    enough in terms of performance). Once you have a locked instance, you can call
    the `lock()` method to ensure that you are the only one executing the code. Once
    you are done with your protected code, you can call `unlock()` to release the
    current thread and let another one execute its code. Also, note that all this
    locking logic assumes that the lock is shared across the thread. Thus, the instantiation
    is generally done once per instance (in the constructor or in a `@PostConstruct`
    method).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 锁的实例化是通过 `new` 关键字直接完成的。我们在此处指出，`ReentrantLock` 可以接受一个布尔参数来请求它尊重锁调用的公平顺序（默认为
    `false`，在性能方面通常足够好）。一旦您有一个已锁定的实例，您可以通过调用 `lock()` 方法来确保您是唯一执行代码的人。一旦您完成受保护的代码，您可以通过调用
    `unlock()` 来释放当前线程，让另一个线程执行其代码。此外，请注意，所有这些锁定逻辑都假设锁是在线程之间共享的。因此，实例化通常在每个实例中只进行一次（在构造函数或
    `@PostConstruct` 方法中）。
- en: It is vital to call the `unlock()` method; otherwise, other locked threads will
    never be released.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 `unlock()` 方法至关重要；否则，其他锁定线程将永远不会被释放。
- en: 'A more common usage of the Lock API is to split the lock and unlock calls into
    two. For instance, to take Java EE usage, you can lock an instance when a request
    starts and unlock it when the request ends in order to ensure that a single request
    is accessing it. This is feasible with Servlet 3 through a listener, even for
    asynchronous requests. But you will not have a block that you can surround; instead,
    you will have multiple callbacks, which you need to integrate with the following:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Lock API 更常见的用法是将锁定和解锁调用分成两个。例如，以 Java EE 的使用为例，你可以在请求开始时锁定一个实例，在请求结束时解锁它，以确保单个请求正在访问它。这可以通过
    Servlet 3 中的监听器实现，即使是异步请求也可以。但您将没有可以包围的块；相反，您将拥有多个回调，您需要将其与以下内容集成：
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'With this listener added to `AsyncContext`, the lock will follow the request''s
    life cycle. The usage will probably look as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 将此监听器添加到 `AsyncContext` 后，锁定将遵循请求的生命周期。使用方式可能如下所示：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Once `AsyncContext` is obtained, we add the lock listener onto it and execute
    the request. The lock will be released when the request ends because of a timeout,
    an exception, or, simply, a normal termination.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦获得 `AsyncContext`，我们将其添加到锁监听器上并执行请求。当请求因超时、异常或简单地说，正常终止时，锁定将被释放。
- en: This sort of implementation with a synchronized block is quite hard and often
    requires some workarounds. This is an example where the Lock API is more powerful.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这种使用同步块的实现相当困难，通常需要一些解决方案。这是一个 Lock API 更强大的例子。
- en: 'We will not detail it here, but the `ReadWriteLock` API gives you a holder
    for two locks: one is used to protect read accesses, and the other one for write
    accesses. The goal is to let read accesses be done in parallel and ensure that
    write accesses are done only when a single thread accesses the data.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在此处不会详细说明，但 `ReadWriteLock` API 为您提供了两个锁的持有者：一个用于保护读访问，另一个用于写访问。目标是让读访问可以并行进行，并确保只有在单个线程访问数据时才进行写访问。
- en: java.util.concurrent
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: java.util.concurrent
- en: 'Although a detailed coverage of the Java Standalone is beyond the context of
    this book, it is important to know that Java 7 and Java 8 got a lot of enhancements
    in this area. So don''t hesitate to go through its packages. Among the interesting
    classes, we can note the following:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Java独立并发编程的详细覆盖超出了本书的范围，但了解Java 7和Java 8在这个领域有很多增强是很重要的。所以不要犹豫，去查看它的包。在有趣的类中，我们可以注意以下内容：
- en: '`CountDownLatch`: This is a simple and efficient way to ensure that N threads
    are waiting a condition owned by another thread (a bit like a starter in a race).'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CountDownLatch`：这是一种简单而有效的方式，确保N个线程正在等待另一个线程拥有的条件（有点像赛跑中的起跑器）。'
- en: '`Semaphore`: This allows you to represent and implement permission *buckets*.
    The most interesting part is that you can increase and decrease the associated
    counter. It can be a simple way to implement a bulkhead solution.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Semaphore`：这允许你表示和实现权限*桶*。最有趣的部分是你可以增加和减少相关的计数器。它可以是一种实现防波堤解决方案的简单方式。'
- en: '`CyclicBarrier`: This is a way to synchronize multiple threads in some points
    of the code. Its API is interesting because it allows you to add shared logic
    that can be executed on all the threads. It can be seen as the opposite of `CountDownLatch`.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CyclicBarrier`：这是一种在代码的某些点上同步多个线程的方式。它的API很有趣，因为它允许你添加可以在所有线程上执行的共享逻辑。它可以被视为`CountDownLatch`的对立面。'
- en: '`Phaser`: This is a more flexible barrier implementation than `CyclicBarrier`
    and `CountDownlatch`.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Phaser`：这是一种比`CyclicBarrier`和`CountDownLatch`更灵活的屏障实现。'
- en: '`Atomic*`: This is a way to update a data instance atomically.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Atomic*`：这是一种原子更新数据实例的方式。'
- en: The volatile data
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 易变数据
- en: Finally, to conclude this part of the Java Standalone concurrent programming,
    it is necessary to keep in mind why the `volatile` keyword is important. This
    keyword allows you to request the JVM to refresh the value it reads every time
    it accesses the data.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了总结这部分Java独立并发编程的内容，有必要记住为什么`volatile`关键字很重要。这个关键字允许你请求JVM每次访问数据时刷新它读取的值。
- en: 'It is very simple to use; just add the `volatile` keyword on the field declaration:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 使用非常简单；只需在字段声明中添加`volatile`关键字：
- en: '[PRE6]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: To understand why this keyword changes everything, you need to keep in mind
    that the JVM can have some thread-related *caching* of the field values (this
    is very low-level caching and has nothing to do with what we'll see in the next
    section). Adding this keyword as in the previous snippet forces us to bypass this
    cache. It is supposed to be a bit slower. However, the usage is often fast by
    itself, so it is generally worth it.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解为什么这个关键字会改变一切，你需要记住JVM可以有一些与线程相关的*缓存*字段值（这是一种非常底层的缓存，与我们将在下一节看到的内容无关）。像前一个片段中那样添加这个关键字强迫我们绕过这个缓存。它应该会慢一些。然而，单独使用时通常很快，所以通常值得这样做。
- en: Java EE and threads
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java EE 和线程
- en: As we saw at the beginning of the chapter, Java EE can silently use threads.
    Any thread usage is important to identify even if it is good to rely on the Java
    EE implementation, because it is code that you don't have to maintain. The issue
    with not identifying the thread is that you can come across cases where your context
    (`ThreadLocal`) will not be available or will be available with the wrong values.
    The other pitfall of not identifying the thread is that you may end up abusing
    the thread and consuming way more resources on the machine than you need. Let's
    review a few representative cases of such usages.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章开头看到的，Java EE可以静默地使用线程。任何线程的使用都很重要，即使依赖于Java EE实现也是好的，因为这是你不需要维护的代码。不识别线程的问题是你可能会遇到你的上下文（`ThreadLocal`）不可用或带有错误值的情况。不识别线程的另一个陷阱是你可能会滥用线程，在机器上消耗比所需更多的资源。让我们回顾一些此类用法的代表性案例。
- en: CDI asynchronous events
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CDI异步事件
- en: 'CDI 2.0 introduces the notion of asynchronous events. It is a manner of asynchronously
    firing an event for the caller. Here is a sample usage:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: CDI 2.0引入了异步事件的观念。这是一种为调用者异步触发事件的方式。以下是一个示例用法：
- en: '[PRE7]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This code snippet sends an asynchronous event, thanks to `fireAsync`. The interesting
    part of this API is that it returns `CompletionStage`, which enables you to chain
    some logic after the event has notified all the asynchronous observers.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代码片段通过`fireAsync`发送异步事件。这个API有趣的部分是它返回`CompletionStage`，这使你能够在事件通知所有异步观察者之后链式调用一些逻辑。
- en: 'Asynchronous events notify only asynchronous observers. It uses a new observer
    marker: `@ObserverAsync`. Here is a signature sample:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 异步事件仅通知异步观察者。它使用一个新的观察者标记：`@ObserverAsync`。以下是一个签名示例：
- en: '`public void onEvent(@ObservesAsync MyEvent event);`'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`public void onEvent(@ObservesAsync MyEvent event);`'
- en: The way the CDI handles the submission of this kind of events is by using `CompletionFuture.all`
    or by chaining the asynchronous observers in a single asynchronous thread (this
    is configurable in Weld; OpenWebBeans only supports the first solution). In any
    case, it submits individual futures to a CDI thread pool. The pool configuration
    is not yet completely standard, though it is important to know that it is feasible
    in all the containers and is an important tuning configuration for your application
    if you rely on it.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: CDI 处理此类事件提交的方式是通过使用 `CompletionFuture.all` 或通过在单个异步线程中链式异步观察者（在 Weld 中可配置；OpenWebBeans
    仅支持第一种解决方案）。无论如何，它将单个未来提交到 CDI 线程池。尽管池配置尚未完全标准化，但重要的是要知道它在所有容器中都是可行的，并且如果你依赖它，它是应用程序的重要调优配置。
- en: Several containers will default to the common fork join pool of the JVM, which
    doesn't scale a lot. So, you will probably want to provide a custom thread pool
    dedicated to your application usage.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 几个容器将默认使用 JVM 的通用 ForkJoin 池，这并不具备很好的可扩展性。因此，你可能需要提供一个专门针对应用程序使用的自定义线程池。
- en: 'In terms of the user code, it is important to prefer the signature taking a `NotificationOptions` instance
    to `fireAsync` (which generally falls back on the default container pool). Doing
    so will allow you to give a custom pool:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在用户代码方面，优先选择接受 `NotificationOptions` 实例签名的 `fireAsync` 方法（通常回退到默认容器池）是很重要的。这样做将允许你提供一个自定义池：
- en: '[PRE8]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This signature enables you to pass a custom pool and to properly tune it (using
    EE concurrency utilities for Java EE, for instance). It will also enable you to
    specify the pool you are using by event and to avoid putting them all in the same
    bucket. In fact, it can potentially lead to locking your application if there
    are some dependencies between the usages!
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 此签名允许你传递一个自定义池，并对其进行适当的调优（例如，使用 Java EE 并发工具）。它还将允许你通过事件指定所使用的池，并避免将它们全部放入同一个桶中。实际上，如果存在一些使用依赖关系，这可能会潜在地锁定你的应用程序！
- en: Last tip on this API is to make sure that you synchronize the event if you mutate
    it, to get a new state after through `CompletionStage`. You can use any of the
    Java Standalone techniques we talked about previously.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '关于此 API 的最后一个提示是，如果你修改了事件，请确保通过 `CompletionStage` 获取新状态时同步事件。你可以使用我们之前讨论过的任何
    Java 独立技术。 '
- en: EJB @Asynchronous
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EJB @Asynchronous
- en: EJB was one of the earliest Java EE specifications. At that time, it was the
    specification getting the most attention and features. Now, it is slowly being
    replaced by CDI and integrations, with other specifications such as JTA, JPA,
    and so on. However, it still contains a set of useful features that you don't
    find elsewhere in Java EE.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: EJB 是最早的 Java EE 规范之一。当时，它是受到最多关注和功能最丰富的规范。现在，它正逐渐被 CDI 和集成所取代，以及其他规范，如 JTA、JPA
    等。然而，它仍然包含一些在其他 Java EE 中找不到的有用功能。
- en: 'EJB also has an asynchronous solution. It is more direct compared to CDI, since
    you can mark a method as asynchronous:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: EJB 也有异步解决方案。与 CDI 相比，它更为直接，因为你可以将一个方法标记为异步：
- en: '[PRE9]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`@Asynchronous` requests the server to execute the task in the EJB thread pool.
    The method can return void, but if it needs to return a value, it must return
    `Future`. With Java 8, it is easy to return `CompletionFuture`. However, since
    this API was designed before that, the easiest way was to return `AsyncResult`,
    which was provided by the specification, and pass it the actual value you want
    to return. Note that the container will wrap the returned `Future` value to add
    a particular specification handling, so you will not be able to cast it to `CompletionFuture`,
    even if that is the implementation you choose in your code.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`@Asynchronous` 请求服务器在 EJB 线程池中执行任务。该方法可以返回 void，但如果需要返回值，则必须返回 `Future`。在
    Java 8 中，返回 `CompletionFuture` 很容易。然而，由于这个 API 在那时之前就已经设计好了，最简单的方法是返回规范提供的 `AsyncResult`，并将你想要返回的实际值传递给它。请注意，容器将包装返回的
    `Future` 值以添加特定的规范处理，因此即使你在代码中选择了该实现，你也不能将其转换为 `CompletionFuture`。'
- en: Here again, the pool configuration is highly dependent on the server, but it
    is generally workable and important, depending on the usage of this API in the
    application. If your application uses it a lot but the container provides only
    two threads and a small pool queue, then you will not scale very far.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，池配置高度依赖于服务器，但通常是可以工作的，并且很重要，这取决于应用程序中此 API 的使用情况。如果您的应用程序大量使用它，但容器只提供两个线程和一个小池队列，那么您将无法扩展很远。
- en: EE concurrency utilities for Java EE
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java EE 并发工具
- en: Java EE 7 introduces a new specification called EE concurrency utilities for
    Java EE. The main target is not only to provide a way to work with threads from
    your EE application, but also to handle EE context propagation, including security,
    transaction, and so on.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Java EE 7 引入了一个名为 EE 并发工具的新规范，用于 Java EE。主要目标不仅是为了提供一个从 EE 应用程序中处理线程的方法，而且还包括处理
    EE 上下文传播，例如安全、事务等。
- en: When using this API, remember that the propagated context highly depends on
    the container. This API is, however, a very good choice compared to a custom thread
    pool management because the configuration is outside the application and *standard* for
    the container, and also because it gives you the ability to benefit from the API
    that we will see in this section.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用此 API 时，请记住，传播的上下文高度依赖于容器。然而，与自定义线程池管理相比，此 API 是一个非常好的选择，因为配置在应用程序之外，并且对于容器来说是*标准*的，并且因为它使您能够从本节中将要看到的
    API 中受益。
- en: What is very clever to do at the specification level is to reuse the standard
    APIs, such as `ExecutorService`, `ScheduledExecutorService`, and so on. This gives
    the developers the ability to use them as a replacement for the SE API. In particular,
    it enables you to integrate transparently with third-party libraries.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在规范级别非常巧妙的事情是重用标准 API，例如 `ExecutorService`、`ScheduledExecutorService` 等。这使开发者能够将它们用作
    SE API 的替代品。特别是，它使您能够透明地与第三方库集成。
- en: 'For example, you can integrate with RxJava ([https://github.com/ReactiveX/RxJava](https://github.com/ReactiveX/RxJava)), as
    you would do with any thread pool:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可以与 RxJava ([https://github.com/ReactiveX/RxJava](https://github.com/ReactiveX/RxJava))
    集成，就像您与任何线程池做的那样：
- en: '[PRE10]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This code integrates the Java EE WebSocket API with the RxJava Flowable API.
    The global idea is to let the consumers handle the WebSocket messages, without
    knowing it comes from WebSocket. This makes it easier to test (replacing the WebSocket
    layer by a mock) and it decouples the code from the WebSocket layer.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将 Java EE WebSocket API 与 RxJava Flowable API 集成。全局思想是让消费者处理 WebSocket 消息，而无需知道它来自
    WebSocket。这使得测试更容易（通过用模拟替换 WebSocket 层）并且使代码与 WebSocket 层解耦。
- en: In our service, we inject `ManagedExecutorService`, which is mainly `ExecutorService` managed
    by the container, and we wrap it in the thread pool API of RxJava through the `Scheduler` API.
    Then we are done; we can use any asynchronous operation of RxJava relying on the
    Java EE threads and, therefore, the context. In the previous code snippet, it
    allowed us to debounce the messages (limit the number of messages emitted per
    unit of time) in one simple line.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的服务中，我们注入 `ManagedExecutorService`，它主要是由容器管理的 `ExecutorService`，并通过 `Scheduler`
    API 将其包装在 RxJava 的线程池 API 中。然后我们就完成了；我们可以使用任何依赖于 Java EE 线程和上下文的 RxJava 的异步操作。在之前的代码片段中，它允许我们在一行中减少消息（限制每单位时间内发出的消息数量）。
- en: 'Technically, we implement `Iterator<>` to integrate with RxJava, but we could
    use `Future` or any other type supported by the Flowable API. The iterator is
    the part integrating with RxJava. However, to integrate with the WebSocket API,
    we can also implement `MessageHandler`, which allows us to see the incoming message
    and register it at our endpoint in the previous snippet. Here is a potential handler
    implementation:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 技术上，我们实现 `Iterator<>` 以与 RxJava 集成，但我们也可以使用 `Future` 或 Flowable API 支持的任何其他类型。迭代器是与
    RxJava 集成的部分。然而，为了与 WebSocket API 集成，我们还可以实现 `MessageHandler`，这允许我们查看传入的消息并在之前的代码片段中的端点注册它。以下是一个潜在的处理程序实现：
- en: '[PRE11]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Our publisher stacks the received messages and then serves them through the `Iterator<>`
    API. It requires some synchronization, as we saw in the previous section, to make
    sure we are able to correctly answer the iterator contract. Concretely, we cannot
    return anything in `hasNext()` if the connection was not closed or if we did not
    receive any message. Otherwise, it will stop the iterations.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的发布者将接收到的消息堆叠起来，然后通过`Iterator<>` API提供服务。正如我们在上一节中看到的，它需要一些同步，以确保我们能够正确回答迭代器合约。具体来说，如果连接未关闭或我们没有收到任何消息，我们无法在`hasNext()`中返回任何内容。否则，它将停止迭代。
- en: ManagedExecutorService
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ManagedExecutorService
- en: 'As a quick reminder, `ExecutorService` is the standard Java Standalone abstraction
    for a thread pool. `ManagedExecutorService` is the Java EE flavor. If you compare
    both the APIs, you will notice that it inherits from all the features of its standalone
    siblings, but it gets enriched with an auditing: a submitted task (`Runnable`)
    can implement the ManagedTask API, which will associate a listener to the task,
    which will be notified of the task''s phase (`Submitted`, `Starting`, `Aborted`,
    and `Done`).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 作为快速提醒，`ExecutorService`是Java Standalone的标准线程池抽象。`ManagedExecutorService`是Java
    EE版本。如果你比较这两个API，你会注意到它继承了其独立兄弟的所有功能，但它增加了审计功能：提交的任务（`Runnable`）可以实现`ManagedTask
    API`，这将给任务关联一个监听器，该监听器会通知任务的阶段（`Submitted`、`Starting`、`Aborted`和`Done`）。
- en: 'ManagedTask globally gives the following to the container:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ManagedTask全局给容器以下内容：
- en: The listener that ManagedTask uses
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ManagedTask使用的监听器
- en: 'A set of properties to customize the behavior of the execution. Three main
    standard properties are defined and portably usable on all the containers:'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一组属性用于自定义执行行为。定义了三个主要标准属性，并且可以在所有容器上便携使用：
- en: '`javax.enterprise.concurrent.LONGRUNNING_HINT`: This allows the container to
    change the thread setup for a long time, taking the tasks to complete (using other
    thread priorities or potentially using dedicated threads)'
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`javax.enterprise.concurrent.LONGRUNNING_HINT`：这允许容器更改长时间运行的线程设置，将任务完成（使用其他线程优先级或可能使用专用线程）'
- en: '`javax.enterprise.concurrent.TRANSACTION`: This can take the `SUSPEND` value that
    will suspend the current transaction (if any) and resume it after the task is
    completed'
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`javax.enterprise.concurrent.TRANSACTION`：这可以取`SUSPEND`值，这将挂起当前事务（如果有）并在任务完成后恢复它'
- en: '`USE_TRANSACTION_OF_EXECUTION_THREAD`: This propagates the transaction of the
    calling thread'
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`USE_TRANSACTION_OF_EXECUTION_THREAD`：这传播调用线程的事务'
- en: 'If you cannot make your task implementing ManagedTask, then you also have *bridge*
    adapters to link a normal task to a listener through the  `ManagedExecutors` factory:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不能使你的任务实现`ManagedTask`，那么你也有`*bridge*`适配器来通过`ManagedExecutors`工厂将一个普通任务连接到一个监听器：
- en: '[PRE12]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This simple invocation will create `Runnable` and you can therefore submit to
    `ManagedExecutorService`, which also implements `ManagedTask` with the `myListener` listener.
    Indeed, there are wrapper factory methods for `Callable`, with the properties
    we mentioned earlier, to ensure it covers all the `ManagedTask` API's features.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的调用将创建`Runnable`，因此你可以将其提交给`ManagedExecutorService`，它也实现了带有`myListener`监听器的`ManagedTask`。实际上，还有用于`Callable`的包装工厂方法，具有我们之前提到的属性，以确保它覆盖了所有`ManagedTask`
    API的功能。
- en: In terms of the overall platform consistency, it is important that this API
    tends to make EJB `@Asynchronous` legacy.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在整体平台一致性方面，这个API倾向于使EJB `@Asynchronous`成为遗留功能。
- en: ManagedScheduledExecutorService
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ManagedScheduledExecutorService
- en: '`ManagedScheduledExecutorService` is `ScheduledExecutorService` Java EE API.
    Like `ExecutorService`, it integrates with the ManagedTask API.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`ManagedScheduledExecutorService`是Java EE API的`ScheduledExecutorService`。像`ExecutorService`一样，它集成了`ManagedTask
    API`。'
- en: However, this scheduling-related API goes a bit further, providing two new methods
    to schedule a task—`Runnable` or `Callable` —based on a dedicated API (`Trigger`).
    This API enables you to handle the scheduling programmatically and it avoids relying
    on a constant time interval or delay.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个与调度相关的API更进一步，提供了两个新的方法来根据专用API（`Trigger`）调度任务——`Runnable`或`Callable`。这个API允许你以编程方式处理调度，并避免依赖于固定的时间间隔或延迟。
- en: Even if, theoretically, this scheduling API can be distributed and was designed
    to support it, it is generally implemented with local support only. However, it
    is a good alternative to EJB `@Schedule` or `TimerService` when clustering is
    not mandatory, which is actually often the case in practice.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 即使从理论上讲，这个调度API可以分布式实现，并且被设计为支持它，但它通常只实现本地支持。然而，当不需要集群时，它是一个很好的EJB `@Schedule`或`TimerService`的替代品，这在实践中实际上很常见。
- en: Java EE threads
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java EE线程
- en: 'The EE concurrency utilities also provide a Java EE ThreadFactory, which creates `ManageableThread`
    instead of a plain thread. The main difference is that they provide an `isShutdown()`
    method, allowing you to know whether the current thread is shutting down and,
    thereby, exit the process if it is indeed shutting down. `ManagedExecutors.isCurrentThreadShutdown()`
    allows you to directly test this flag, handling the casting of the thread automatically.
    This means that a long running task can be implemented as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: EE并发工具还提供了一个Java EE的`ThreadFactory`，它创建的是`ManageableThread`而不是普通的线程。主要区别在于它们提供了一个`isShutdown()`方法，允许你了解当前线程是否正在关闭，并因此，如果确实正在关闭，退出进程。`ManagedExecutors.isCurrentThreadShutdown()`允许你直接测试这个标志，并自动处理线程的转换。这意味着一个长时间运行的任务可以按以下方式实现：
- en: '[PRE13]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: You may think that testing only the thread state would be enough, but you still
    need an application state to ensure that you integrate with the application life
    cycle. Don't forget that the thread can be bound to the container and not the
    application deployment time. Also, depending on the strategy you define for the
    threads, you can evict them at runtime, potentially through the administration
    API of the container.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会认为仅测试线程状态就足够了，但你仍然需要一个应用程序状态来确保你与应用程序生命周期集成。不要忘记线程可以绑定到容器而不是应用程序部署时间。此外，根据你为线程定义的策略，你可以在运行时将其驱逐，可能通过容器的管理API。
- en: ContextService
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ContextService
- en: 'The last interesting API of the EE concurrency utilities is `ContextService`.
    It allows you to create proxies, based on interfaces, inheriting from the context
    propagation of the `Managed*` API. You can see it as a way of using managed thread
    pool features in the standalone thread pools that you don''t control:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: EE并发工具的最后一个有趣的API是`ContextService`。它允许你创建基于接口的代理，继承自`Managed*` API的上下文传播。你可以将其视为在不受你控制的独立线程池中使用管理线程池功能的一种方式：
- en: '[PRE14]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Here, we wrap our task in a contextual proxy and we submit the wrapped task
    through a framework that we don't control. However, the execution will still be
    done in the EE context of the caller (same JNDI context, for instance), and using
    another framework is not much affecting.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将我们的任务包装在一个上下文代理中，并通过我们无法控制的框架提交包装后的任务。然而，执行仍然会在调用者的EE上下文中完成（例如，相同的JNDI上下文），使用另一个框架并不会影响很大。
- en: This `ContextService` is limited to proxy interfaces and doesn't support subclass
    proxying like CDI does for instance. Java EE understands that modern development
    is composed of motley frameworks and stacks and that it can't control everything
    and anything. This trend is traduced by the introduction of a new sort of API
    to easily integrate with others and enable any use case, rather than introducing
    a lot of new APIs, which will not evolve very well.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`ContextService`仅限于代理接口，并且不支持像CDI那样进行子类代理。Java EE明白现代开发是由各种框架和堆栈组成的，它无法控制一切。这种趋势通过引入一种新的API来体现，这种API可以轻松与其他系统集成并支持任何用例，而不是引入大量新的API，这些API可能不会很好地进化。
- en: It is important in terms of performance and monitoring—it not only allows you
    to easily trace invocations and application behavior but also to optimize the
    application with caching, as we will see in the next chapter.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在性能和监控方面非常重要——它不仅允许你轻松跟踪调用和应用程序行为，还可以通过缓存优化应用程序，正如我们将在下一章中看到的。
- en: EJB @Lock
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EJB @Lock
- en: The previous part showed that EJB `@Asynchronous` and `@Schedule` can be replaced
    with the new EE concurrency utilities in some measure. However, there are still
    some EJB APIs that are not easy to replace without coding them yourself. The `@Lock`
    API is one of them.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 前一部分展示了EJB的`@Asynchronous`和`@Schedule`可以通过某些程度地替换为新的EE并发工具。然而，还有一些EJB API在没有自己编码的情况下不容易替换，`@Lock`
    API就是其中之一。
- en: The global idea is to ensure that the data owned by the EJB (`@Singleton`) is
    accessed in a thread-safe context.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 整体思路是确保EJB（`@Singleton`）拥有的数据在线程安全的环境中访问。
- en: Indeed, this API is limited to the singleton EJB, since without a single instance
    usable in a concurrent environment, it doesn't make sense to lock.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，此API仅限于单例EJB，因为没有在并发环境中可用的单个实例，锁定就没有意义。
- en: 'The usage is straightforward, as you just decorate a method or the bean with `@Lock`,
    passing `READ` or `WRITE` in the parameter, depending on the kind of access:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 使用方法很简单，您只需用`@Lock`装饰一个方法或bean，并根据访问类型传递`READ`或`WRITE`参数：
- en: '[PRE15]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If you remember the part about Java Standalone, it is very close to the `synchronized`
    usage, as we define a lock on a block. However, the semantic is closer to the `ReadWriteLock`
    API.  This was a will of the API design as this is the way it is often implemented.
    Now, why mix both the styles (block and read/write API)? It enables you to scale
    on the read, keeping the API very simple (bound to blocks). However, it already
    fits a lot of cases!
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还记得关于Java Standalone的部分，它与`synchronized`的使用非常相似，因为我们在一个块上定义了锁。然而，其语义更接近`ReadWriteLock`
    API。这是API设计的一个意愿，因为这是它通常实现的方式。那么，为什么混合这两种风格（块和读写API）呢？这使您能够在读取时进行扩展，同时保持API非常简单（绑定到块）。然而，它已经适合很多情况！
- en: 'In terms of the performance, it is important to know that you can mix it with
    a timeout through `@AccessTimeout`:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在性能方面，重要的是要知道您可以通过`@AccessTimeout`将其与超时混合：
- en: '[PRE16]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Here, we request the container to fail with the `ConcurrentAccessTimeout` exception
    if the lock (read or write) is not acquired after 500 milliseconds.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们要求容器在500毫秒后未能获取锁（读取或写入）时，通过`ConcurrentAccessTimeout`异常失败。
- en: For a reactive application, correctly configuring the timeouts is crucial and
    important to ensure that the application doesn't start with a huge response time
    because of all the threads waiting for a response. This means that you have to
    define a fallback behavior in the case of a timeout. To say it differently, you
    need to define a timeout to ensure you match your SLA, but you also need to define
    what to do when you get a timeout in order to avoid 100% of errors in case the
    server is overloaded.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个响应式应用程序，正确配置超时至关重要，并且对于确保应用程序不会因为所有线程都在等待响应而以巨大的响应时间启动非常重要。这意味着您必须定义超时情况下的回退行为。换句话说，您需要定义超时以确保您符合SLA，但您还需要定义在超时时应该做什么，以避免在服务器过载时出现100%的错误。
- en: The microprofile initiative has been created by most Java EE vendors and is
    mainly based on the CDI. So, even if it is not part of the Java EE, it integrates
    very well with it. Its primary targets are microservices, and, therefore, they
    define a bulkhead API and other concurrent solutions. However, it is an interesting
    solution if the `@Lock` is too simple for your needs.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 微profile倡议是由大多数Java EE供应商创建的，主要基于CDI。因此，即使它不是Java EE的一部分，它也能很好地与之集成。其主要目标是微服务，因此它们定义了一个bulkhead
    API和其他并发解决方案。然而，如果`@Lock`对于您的需求来说过于简单，它是一个有趣的解决方案。
- en: HTTP threads
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HTTP线程
- en: HTTP layers (server and client) are about network and connections. Therefore,
    they require some threading to handle the client connections on the server side
    and, potentially, the reactive processing on the client side. Let's go through
    these particular settings, which directly impact the scalability of your application.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP层（服务器和客户端）涉及网络和连接。因此，它们需要在服务器端处理客户端连接以及在客户端侧进行潜在的反应式处理时使用一些线程。让我们逐一了解这些特定设置，这些设置直接影响到您应用程序的可扩展性。
- en: Server side
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务器端
- en: The entry point of any web request is the HTTP container. Here, the server configuration
    is always server-dependent, but most of the vendors will share the same concepts.
    It is important to tune that part to make sure that the outbound of your application
    is not unintentionally throttling it too much; otherwise, you will limit the scalability
    of your application for no reason.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 任何Web请求的入口点是HTTP容器。在这里，服务器配置始终依赖于服务器，但大多数供应商将共享相同的概念。重要的是调整这部分，以确保您的应用程序的输出不会无意中过度限制；否则，您将无端地限制应用程序的可扩展性。
- en: 'For instance, for GlassFish, you can configure the HTTP connector in the UI
    administration or the corresponding configuration file. Here is what it looks
    like:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对于GlassFish，您可以在UI管理界面或相应的配置文件中配置HTTP连接器。以下是它的样子：
- en: '![](img/d05f44a1-4cbe-429c-bfd0-36dfd19509f1.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d05f44a1-4cbe-429c-bfd0-36dfd19509f1.png)'
- en: 'This page is really about the tuning of the HTTP connector (not the binding
    address, port, or the supported SSL cipher algorithms). The corresponding configurations
    are summarized in the following table:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这个页面实际上是在讨论HTTP连接器的调整（而不是绑定地址、端口或支持的SSL加密算法）。相应的配置总结在下表中：
- en: '| **Configuration name** | **Description** |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| **配置名称** | **描述** |'
- en: '| Max connections | This is the maximum number of requests per client in the
    keep-alive mode. This is not the maximum number of connections the server supports,
    compared with the other Java EE servers. |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 最大连接数 | 这是保持活动模式下每个客户端的最大请求数量。这与其他Java EE服务器相比，这不是服务器支持的最大连接数。 |'
- en: '| Timeout | This is the timeout after which the connection can be dropped in
    the keep-alive mode if still idle. Here again, it is a client-based configuration
    and not a request timeout like in most of the other servers. |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 超时 | 这是连接在保持活动模式下空闲一段时间后可以断开的时间长度。这里同样，这是一个基于客户端的配置，而不是像大多数其他服务器中的请求超时。 |'
- en: '| Request timeout | This is the duration after which the request will timeout
    and fail from the client point of view. |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 请求超时 | 这是请求将在客户端超时并失败的时间长度。 |'
- en: '| Buffer size/length | Buffers are used to read the incoming data in the input
    streams. Adjusting this size to avoid memory overflows will significantly increase
    the performance, since the server will no longer have to create a new volatile
    buffer to read the data. This tuning can be hard to do if the application does
    lots of things. The trade-off is to not use too much memory and to avoid unexpected
    allocations. Thus, the closer you are to the most common requests in terms of
    size (a bit more than this value actually), the better you will behave.  |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 缓冲区大小/长度 | 缓冲区用于读取输入流中的数据。调整此大小以避免内存溢出将显著提高性能，因为服务器将不再需要创建一个新的易失性缓冲区来读取数据。如果应用程序做了很多事，这种调整可能很难做。权衡是不要使用太多内存，并避免意外的分配。因此，你越接近最常见请求的大小（实际上略大于此值），你的表现就越好。 
    |'
- en: '| Compression | Compression is mainly for browser-based clients (supporting
    GZIP). It will automatically compress the content of the configure mime types
    if the size of the resource is more than the minimum configuration size. Concretely,
    it can, for instance, affect a JavaScript of 2MB (which is no longer rare today).
    This will use some CPU resources to do the compression, but the space gain on
    text-based resources (HTML, JavaScript, CSS, and so on) is generally worth it,
    as the network duration will be reduced a lot. |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 压缩 | 压缩主要用于基于浏览器的客户端（支持GZIP）。如果资源的尺寸超过最小配置尺寸，它将自动压缩配置的MIME类型的内容。具体来说，它可以影响一个2MB的JavaScript文件（这在今天已不再罕见）。这将使用一些CPU资源来进行压缩，但基于文本的资源（HTML、JavaScript、CSS等）的空间节省通常是值得的，因为网络持续时间将大大减少。
    |'
- en: 'These parameters are mainly about the network optimization but are crucial
    to ensure that the application stays responsive. They are also influencing the
    way the HTTP threads are used, because bad tuning can imply more work for the
    server. Now, you also have an HTTP thread pool in GlassFish (as in most servers)
    that you can configure. Here is the corresponding screen:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这些参数主要关于网络优化，但对于确保应用程序保持响应性至关重要。它们还影响着HTTP线程的使用方式，因为不当的调整可能会给服务器带来更多的工作。现在，在GlassFish（以及大多数服务器）中，你还可以配置HTTP线程池。以下是相应的屏幕截图：
- en: '![](img/0b6b61da-be49-4375-9305-9ea9e4cc52d5.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0b6b61da-be49-4375-9305-9ea9e4cc52d5.png)'
- en: The configuration of GlassFish is very common for a thread pool—its sizes (maximum/minimum),
    the queue size (the number of tasks that can be added even if the pool is full),
    and the timeout (when a thread is removed from the pool if not used).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: GlassFish的线程池配置非常常见——其大小（最大/最小）、队列大小（即使池已满，也可以添加的任务数量），以及超时（如果线程未被使用，则从池中移除）。
- en: When you are benchmarking your application, ensure that you monitor the CPU
    usage of your application and the thread stacks (or profiling, depending on the
    way you monitor your server/application) to identify bad configuration. For instance,
    if you see a CPU usage of 50% and a few active threads, then you may need to increase
    the pool size. The overall goal is to make the CPU usage very high (85-95%) and
    the response time of the server almost constant. Note that it is not recommended
    to go up to 100% for the CPU usage because, then, you'll reach the limitations
    of the machine; the performance won't be relevant anymore and you will just see
    the response time increasing boundlessly.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在基准测试你的应用程序时，确保你监控应用程序的CPU使用率和线程堆栈（或根据你监控服务器/应用程序的方式，进行剖析），以识别不良配置。例如，如果你看到50%的CPU使用率和一些活跃的线程，那么你可能需要增加池的大小。总体目标是使CPU使用率非常高（85-95%），并且服务器的响应时间几乎保持不变。请注意，不建议将CPU使用率提高到100%，因为那时，你会达到机器的限制；性能将不再相关，你将只会看到响应时间无限增加。
- en: This is a general rule for any thread pool that can become very important when
    going reactive. So, always try to name the threads of the application with a prefix
    that corresponds to the role that they have in order to ensure that you can identify
    them in the thread dumps.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对任何可能变得非常重要的线程池的一般规则，尤其是在转向响应式编程时。因此，始终尝试使用与它们在应用程序中扮演的角色相对应的前缀来命名应用程序的线程，以确保你可以在线程转储中识别它们。
- en: Client side
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户端端
- en: 'Since JAX-RS 2.1, the client has been made to be reactive. As a quick reminder,
    here is what it can look like:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 自从JAX-RS 2.1以来，客户端已经被设计成响应式的。作为一个快速提醒，这里是什么样子：
- en: '[PRE17]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This is normal JAX-RS client API usage, except for the call to `rx()`, which
    wraps the response into `CompletionStage`. The only interest is to become asynchronous;
    otherwise, it will just be another layer with poor gain in terms of user experience.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对JAX-RS客户端API的正常使用，除了对`rx()`的调用，它将响应包装到`CompletionStage`中。唯一的兴趣是变得异步；否则，它将只是另一个层，用户体验的提升微乎其微。
- en: The way the implementation handles asynchronous invocations is up to the implementation,
    but with Jersey (the reference implementation) and in a Java EE container, you
    will default to the managed executor service. Note that outside an EE container,
    Jersey will create a very big thread pool.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 实现处理异步调用的方式取决于实现方式，但在Jersey（参考实现）和Java EE容器中，你将默认使用托管执行器服务。请注意，在EE容器之外，Jersey将创建一个非常大的线程池。
- en: This kind of configuration is the key to your application, since each client
    is supposed to have a different pool to ensure that it doesn't affect the other
    parts of the application, and also because thread usages can be different and
    may need different constraints. However, it is not yet standardized and, thus,
    you will need to check which implementation your server uses and how the configuration
    can be used. In general, the client-side configuration is accessible through the
    client's properties, so it is not that hard. However, sometimes, you may be limited
    by container integration. In such a case, you can wrap the invocation into your
    own pool and not use the `rx()` API to fully control it.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这种配置是您应用程序的关键，因为每个客户端都应该有一个不同的池，以确保它不会影响应用程序的其他部分，并且因为线程使用可能不同，可能需要不同的约束。然而，这尚未标准化，因此您需要检查您的服务器使用哪种实现以及如何使用配置。一般来说，客户端配置可以通过客户端的属性访问，所以并不难。但是，有时您可能受到容器集成的限制。在这种情况下，您可以将调用包装到自己的池中，并且不要使用`rx()`
    API来完全控制它。
- en: To conclude this section, we can expect in some time (Java EE 8 and this new
    JAX-RS 2 API) that this `rx()` method will be implemented directly using the NIO
    API, and therefore, it becomes really reactive at the network level and not just
    through another thread pool.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结本节，我们可以在一段时间后（Java EE 8和这个新的JAX-RS 2 API）期待`rx()`方法将直接使用NIO API实现，因此，它在网络层面上真正变得响应式，而不仅仅是通过另一个线程池。
- en: We just saw that Java EE brings solutions to handle your application threading
    properly, but modern developments often require new paradigms. These modifications
    require a small change in the way the application is developed. Let's go through
    one of these new patterns.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚看到Java EE带来了处理应用程序线程的正确解决方案，但现代开发往往需要新的范式。这些修改需要应用程序开发方式的小幅改变。让我们通过这些新模式之一来了解一下。
- en: Reactive programming and Java EE
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 响应式编程和Java EE
- en: 'Reactive programming lets your code be called instead of calling your code.
    You can visualize it as being event-based instead of procedural. Here is an example
    to compare both the styles:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 响应式编程允许你的代码被调用而不是调用你的代码。你可以将其视为基于事件而不是过程的。以下是一个比较两种风格的示例：
- en: '[PRE18]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This is a very simple and common implementation of a business method where we
    call two services: `validator` and `service`. The first one will validate the
    data by checking whether it exists in the database, the values are in the expected
    ranges, and so on, while the second one will actually process the updates (a database,
    for instance).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常简单且常见的业务方法实现，其中我们调用两个服务：`validator`和`service`。第一个服务将通过检查数据是否存在于数据库中、值是否在预期范围内等来验证数据，而第二个服务将实际处理更新（例如数据库）。
- en: The issue with this style is that the data validation and persistence are bound
    in a single `processData` method, which defines the entire execution environment
    (threading, context, and so on).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这种风格的问题在于数据验证和持久化被绑定在单个`processData`方法中，该方法定义了整个执行环境（线程、上下文等）。
- en: 'In the reactive style, it can be rewritten to replace the synchronous calls
    by a *chain*:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在响应式风格中，它可以重写为用*链*替换同步调用：
- en: '[PRE19]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: In this example, we used the Java 8 stream API, but using a reactive library
    such as RxJava generally makes more sense; you will understand why in the next
    paragraph. This code does the same thing as the previous one, but it orchestrates
    the calls through the definition of a chain, instead of making the calls directly.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用了Java 8流API，但使用像RxJava这样的响应式库通常更有意义；你将在下一段中理解原因。此代码与上一个代码执行相同的功能，但它通过定义链来编排调用，而不是直接进行调用。
- en: What is interesting with this pattern is that you split your logic (`validator`, `service`)
    from the way it is used (the stream in the previous example). It implies that
    you can enrich the way the calls are orchestrated, and if you think about the
    example of RxJava that we saw earlier, you can immediately think about executing
    each method in different threads.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模式有趣的地方在于你将逻辑（`validator`、`service`）与其使用方式（前一个例子中的流）分开。这意味着你可以丰富调用的编排方式，如果你考虑我们之前看到的RxJava示例，你就可以立即想到在不同的线程中执行每个方法。
- en: One common use case of such a pattern is when the response time is more important
    than the resources used. In other words, if you don't care about consuming more
    CPU cycles if it helps reduce the time you need to respond to your client, then
    you can put this pattern in place. If you are working with multiple concurrent
    data providers, or if you need to contact multiple remote services to process
    the data, then you will do the three invocations concurrently upfront. And once
    you have all the responses, you will execute the actual processing.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式的一个常见用例是当响应时间比使用的资源更重要时。换句话说，如果你不介意消耗更多的CPU周期，只要这有助于减少你响应客户端所需的时间，那么你可以实施这种模式。如果你正在与多个并发数据提供者一起工作，或者如果你需要联系多个远程服务来处理数据，那么你将一开始就并发执行这三个调用。一旦你有了所有响应，你将执行实际的处理。
- en: 'To illustrate this, you can assume that the data has a contract identifier,
    a customer identifier, and an account identifier associated with the corresponding
    entities through three different remote services. The synchronous implementation
    of such a case will be something like the following:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一点，你可以假设数据有一个合同标识符、一个客户标识符和一个与相应实体关联的账户标识符，这些标识符通过三个不同的远程服务关联。此类情况的同步实现可能如下所示：
- en: '[PRE20]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This will work. However, assuming that a remote call is about 10 ms, your method
    will then take more than 30 ms to process the data.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这将有效。然而，假设远程调用大约需要10毫秒，那么你的方法处理数据将需要超过30毫秒。
- en: 'You can optimize it a bit by doing the three requests concurrently:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过并发执行三个请求来对其进行一点优化：
- en: '[PRE21]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In this case, you will reduce the invocation duration to 10 ms, more or less.
    However, you will block the thread for 10 ms (the three parallel invocations).
    The `CompletableFuture.allOf(...).get()` line waits for all the three asynchronous
    operations (`CompletableFutures`) to complete, keeping the thread unusable for
    other requests/processing.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你将减少调用持续时间到大约10毫秒。然而，你将阻塞线程10毫秒（三个并行调用）。`CompletableFuture.allOf(...).get()`这一行等待所有三个异步操作（`CompletableFutures`）完成，使得线程无法用于其他请求/处理。
- en: The direct implication is that you will not scale and will not be able to process
    many concurrent requests even if your CPU is probably doing nothing (that is,
    you are waiting on I/O if you obtain a thread dump at that time).
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 直接影响是，即使你的 CPU 可能什么都没做（即，如果你当时获取线程转储，你正在等待 I/O），你也不会扩展，并且无法处理许多并发请求。
- en: 'The way to enhance this is to ensure that the main thread is not blocked and
    that the processing is triggered only when all the data is received:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 增强这种方法的方式是确保主线程不被阻塞，并且只有在所有数据都接收后才开始处理：
- en: '[PRE22]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In this case, we still execute our three remote invocations in parallel—potentially,
    in a managed executor service if you need to access EE features—and, then, we
    wait for all three results to be retrieved in order to do our processing. However,
    we just register our processing to be done once the entire data is readable, and
    we don't block the thread waiting for this *ready* state; thus, we will be able
    to serve more requests simultaneously.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们仍然并行执行我们的三个远程调用——如果你需要访问 EE 功能，可能是在一个管理执行器服务中——然后，我们等待所有三个结果按顺序检索，以便进行我们的处理。然而，我们只是在整个数据可读时注册我们的处理，我们不会阻塞线程等待这个*就绪*状态；因此，我们将能够同时服务更多的请求。
- en: What is important in going reactive is to try to avoid synchronizations as much
    as possible in order to ensure any thread time is active processing. Of course,
    it has limitations, like some JDBC drivers, which are still synchronous, it will
    block a thread waiting for I/O operations. Yet, with microservices becoming common,
    it is easy to add a lot of latency to your code and reduce the application scalability
    if you don't take care of it.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在走向响应式编程时，重要的是尽可能避免同步，以确保任何线程时间都是活跃的处理。当然，它有限制，比如一些 JDBC 驱动程序仍然是同步的，它将阻塞线程等待
    I/O 操作。然而，随着微服务的普及，如果不注意它，很容易给代码添加很多延迟，并降低应用程序的可伸缩性。
- en: A way to represent this kind of programming mentally is to visualize the CPU
    usage as a big queue and each element of the queue as some active computing time
    consumer (that is, a task). Then, your program is just a big event loop polling
    this task queue and executing the tasks. What is the result?—almost no passive
    time, only active time!
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在心理上表示这种编程方式的方法是将 CPU 使用率想象成一个大的队列，队列中的每个元素都是一些活跃的计算时间消费者（即，一个任务）。然后，你的程序只是一个大事件循环轮询这个任务队列并执行任务。结果是什么？——几乎没有被动时间，只有活跃时间！
- en: Indeed, being asynchronous implies that all the work will become asynchronous
    (thread handling, context switching, queue management, and synchronization). Even
    if most of these tasks are hidden and done for you by the stack, it may make the
    CPU busy and slow down the application, compared with the same code executed in
    a single thread. This is true and means that you can't use this pattern for every
    single invocation. You need to ensure that you use it when relevant and when there
    is potentially a passive usage of the CPU (blocking time, sleep, and so on). Though,
    if you respect this pattern, you should be able to work with concurrency better
    than staying synchronous everywhere. Of course, this is a compromise because if
    you have a background task (a scheduled task executed once a day, for instance),
    you will not care about the waiting time since it concerns a single thread. This
    type of programming will only pay when used in accurate places, but if you respect
    this usage, you will really get a saner final behavior. However, don't forget
    that it brings more complexity because tracking is no more natural in Java (stack
    traces are almost no more useful since you don't have the full stack if you don't
    use a thread-tracing solution).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，异步意味着所有的工作都将变为异步（线程处理、上下文切换、队列管理和同步）。即使大多数这些任务都是隐藏的，并且由堆栈为你完成，这也可能使 CPU
    过载并减慢应用程序的速度，与在单个线程中执行相同的代码相比。这是真的，这意味着你不能为每个调用都使用这种模式。你需要确保你在相关的时候使用它，当有可能被动使用
    CPU（阻塞时间、睡眠等）的时候。尽管如此，如果你遵守这个模式，你应该能够比在所有地方都保持同步更好地处理并发。当然，这是一个妥协，因为如果你有一个后台任务（例如，每天执行一次的计划任务），你不会关心等待时间，因为它只涉及一个线程。这种编程方式只有在准确的位置使用时才会产生效益，但如果你遵守这种使用方式，你将真正获得更合理的最终行为。然而，不要忘记，它带来了更多的复杂性，因为跟踪在
    Java 中不再那么自然（堆栈跟踪几乎不再有用，因为你如果没有使用线程跟踪解决方案，就没有完整的堆栈）。
- en: Message passing and Java EE
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消息传递和 Java EE
- en: Message passing pattern refers to several theories, but in this part, we'll
    mainly care about the asynchronous flavor. One illustration of this pattern is
    the actor flavor. An actor is *something* that can receive messages, send messages
    to other actors, create other actors, and designate the behavior for the next
    received message.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 消息传递模式涉及多个理论，但在这个部分，我们将主要关注异步风格。这种模式的一个例子是演员风格。演员是*某种*可以接收消息、向其他演员发送消息、创建其他演员以及指定下一个接收到的消息的行为的实体。
- en: 'It is important to understand the basis of the underlying concepts:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 理解底层概念的基础非常重要：
- en: Global communication relies on an asynchronous bus
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全局通信依赖于一个异步总线
- en: C*urrent* message processing of an actor is based on a state (a bit like an
    internal state machine)
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 演员当前的*消息*处理基于一个状态（有点像内部状态机）
- en: An actor can create other actors to process a message
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 演员可以创建其他演员来处理一条消息
- en: With such a pattern, it is highly recommended to have immutable messages to
    avoid any concurrency issues and hard-to-debug behavior (or non-deterministic
    behavior) going across the actor flow.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种模式，强烈建议使用不可变消息以避免任何并发问题以及难以调试的行为（或非确定性行为）在演员流程中发生。
- en: 'Java EE doesn''t allow you to handle everything of this pattern out of the
    box, but most of it is already here:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: Java EE 并不提供现成的处理这种模式所有功能的工具，但其中大部分功能已经存在：
- en: CDI provides a bus
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CDI 提供了一个总线
- en: CDI (asynchronous) observers are beans, so you can have a state machine
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CDI（异步）观察者是一些豆类，因此你可以拥有一个状态机
- en: The delegation chain (new actors) can be handled through a CDI context bound
    to the messages
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理链（新演员）可以通过与消息绑定的 CDI 上下文来处理
- en: Of course, this stays a poor man's implementation, compared with real actor
    systems, but it already gives you a solid pattern to avoid passive usage of threads,
    and, by the way, you should think about it when creating an internal architecture
    for your application.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，与真正的演员系统相比，这仍然是一个简陋的实现，但它已经为你提供了一个坚实的模式来避免线程的被动使用，顺便说一下，当创建应用程序的内部架构时，你应该考虑这一点。
- en: Summary
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you saw how Java EE ensures that you can parallelize the computing
    of your applications, and make your applications scale better and process multiple
    concurrent requests.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，你看到了 Java EE 如何确保你可以并行化应用程序的计算，并使你的应用程序更好地扩展并处理多个并发请求。
- en: Using Java Standalone synchronization mechanisms, Java EE threading management
    solutions and API will let you get the best out of your hardware and integrate
    with third-party libraries very easily.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Java 独立同步机制、Java EE 线程管理解决方案和 API，你可以充分利用你的硬件并轻松地与第三方库集成。
- en: 'Now that we have seen what is related to the CPU, we need to go through the
    machine''s other main resource that you can exploit to make your application''s
    behavior better: the memory. When processing can''t be optimized and is too impacting
    on the application, the solution is often just to skip it as much as possible.
    The most common—and probably, efficient—way of doing so is to make sure that the
    data is computed once and reused while valid. This is where the caching enters
    into the game and this is what our next chapter will be about.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了与 CPU 相关的内容，我们需要了解机器的另一个主要资源，你可以利用它来使你的应用程序行为更好：内存。当处理无法优化并且对应用程序影响太大时，通常的解决方案就是尽可能跳过它。这样做最常见——也许也是最有效的方法——就是确保数据只计算一次并在有效期间重复使用。这就是缓存介入游戏的地方，这也是我们下一章将要讨论的内容。
