- en: Libraries for Pure Functional Programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we discussed the purely functional style with the help
    of essential libraries such as `cats`. This library performs quite well on tasks
    of purely functional programming, but in practice, that is not quite enough for
    comfortable programming.
  prefs: []
  type: TYPE_NORMAL
- en: If you take a look at conventional imperative languages such as Java, you will
    see that they usually have a lot of libraries and infrastructure for performing
    specific tasks. Moreover, it is also possible to argue that the choice of programming
    language is primarily driven by the infrastructure it provides.
  prefs: []
  type: TYPE_NORMAL
- en: This way, for example, Python is a de facto standard for machine learning, because
    it provides an elaborate set of scientific libraries to perform scientific computing,
    and R is a de facto standard for statistical computing. Companies often choose
    Scala because it provides access to Spark and Akka libraries for machine learning
    and distributed computing.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, when talking about a particular programming style, it is of great importance
    to also mention that it is an infrastructure that is developed around the staff.
    In this chapter, we will cover this infrastructure by looking at a bunch of other
    libraries that exist for purely functional programming in Scala with `cats`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The Cats effect
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Server-side programming
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will start this chapter by looking at the concurrency library for `cats`.
  prefs: []
  type: TYPE_NORMAL
- en: Cats effect
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Cats effect is a library for concurrent programming in `cats`. Its main
    feature is a bunch of type classes, data types, and concurrency primitives to
    describe concurrent programming in Scala with `cats`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The concurrency primitives support among other things:'
  prefs: []
  type: TYPE_NORMAL
- en: Resource management—think try-with-resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Seamless composition of parallel computations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Communication between parallel computations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will start discussing the library by looking at its central concurrency primitive, `IO`,
    and some capabilities of Cats that we will need in the process of discussing it.
  prefs: []
  type: TYPE_NORMAL
- en: ProductR
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before diving deep into the library and discussing its features, we need to
    mention a particular operator that is frequently used throughout this library.
    We have already discussed the Applicative type class, and that it is useful for
    parallel composition.
  prefs: []
  type: TYPE_NORMAL
- en: An operator from this type class that is frequently used in `cats` is a so-called
    right product operator.
  prefs: []
  type: TYPE_NORMAL
- en: The operator in question takes two computations, performs a product between
    them, and takes only the right-hand result. Particularly in the Cats effect, the
    operator is frequently used to specify that one event should happen after another.
  prefs: []
  type: TYPE_NORMAL
- en: It also has a symbolic form, which looks like this: `*>`.
  prefs: []
  type: TYPE_NORMAL
- en: IO – the concurrence data type
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The primary data type that the Cats effect offers is IO. This is a data type
    that defines a computation that is to be performed at some point in the future.
    For example, you can have the following expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Crucial detail to notice about IO is that it is precisely a description of the
    computation. Here, `cats` supports a so-called computation as a value paradigm.
    Computation as a value dictates that you should not evaluate your competition
    straight away, but you should store the descriptions of these computations. This
    way, you will be able to evaluate them at any point in the future.
  prefs: []
  type: TYPE_NORMAL
- en: This approach has a number of benefits, and this is what we are going to discuss
    next.
  prefs: []
  type: TYPE_NORMAL
- en: Referential transparency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first benefit Cats has is referential transparency. In the preceding example,
    the computation to print hello world to the command line will not be evaluated
    right away. It is side effecting, and the fact that we do not evaluate it right
    away means it is referentially transparent. You can evaluate the computation as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: IO has a bunch of methods, the names of which are prepended with the `unsafe`
    word.
  prefs: []
  type: TYPE_NORMAL
- en: Unsafe methods are generally what their prefix says, `unsafe`. This means that
    they may block, produce side effects, throw exceptions, and do other things that
    may cause you a headache. Following the description of the IO type in the documentation
    itself, you should only call such a method once, ideally at the end of your program.
  prefs: []
  type: TYPE_NORMAL
- en: So, basically, the main idea is that you describe your entire program in terms
    of the IO primitive, using the conveniences provided by this primitive by the
    Cats effect library. Once your entire application is described, you can run the
    application.
  prefs: []
  type: TYPE_NORMAL
- en: Inversion of control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since a computation expressed in terms of IO is not executed immediately but
    is merely stored as a description of a computation, it is possible to execute
    the computation against different execution strategies. For example, you may want
    to run the computation against various concurrent backends, each with its own
    concurrency strategies. You may want to run a competition synchronously or asynchronously.
    Later in this chapter, we will see how exactly this is done.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchrony with IO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The central domain of the application of the Cats effect is asynchronous programming.
    Asynchronous programming is an event-driven style of programming, where you do
    not waste threads and other resources on blocking, waiting for some event to happen.
  prefs: []
  type: TYPE_NORMAL
- en: Consider, for example, that you have a web server that handles incoming HTTP
    requests. It has a pool of threads that are used by the server to handle each
    request. Now, the handlers themselves may require some blocking operations. For
    example, contacting a database for contacting an external HTTP API can be a potentially
    blocking operation. This is because the database or an HTTP API does not respond
    immediately as a rule. This means that if a request handler needs to contact such
    a resource, it will need to wait for the service to reply.
  prefs: []
  type: TYPE_NORMAL
- en: If such waiting is done naively, by blocking an entire thread and reviving it
    once the request is available, we have a situation where we waste threads. If
    such a server comes under a high load, there is a danger that all of the threads
    will be blocked for the majority of the time. Blocking means that they do not
    do anything and are just waiting for a response from a resource. Since they are
    not doing anything, these threads could have well been used to handle other requests
    that possibly do not require such kinds of blocking.
  prefs: []
  type: TYPE_NORMAL
- en: Precisely for this reason, current server-side programming is aimed toward asynchronous
    processing, which means that if a handler needs to contact some potentially blocking
    resource, it contacts it. However, once it has nothing else to do, it is supposed
    to release its thread. It will continue the computation once the response it is
    waiting for is available.
  prefs: []
  type: TYPE_NORMAL
- en: This kind of strategy allows for very lightweight concurrent modules that do
    not waste threads. This also ensures that the threads are busy with useful work
    most of the time, and not with blocking.
  prefs: []
  type: TYPE_NORMAL
- en: However, this model requires dedicated libraries and server-side technologies
    that are specifically built with asynchrony in mind. The Cats effect precisely
    aims to meet such asynchronous requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a look at some examples which demonstrate in practice how blocking
    differs from asynchrony and how Cats facilitates asynchrony. You will also learn
    a bunch of Cats effect APIs in the process of looking at these examples.
  prefs: []
  type: TYPE_NORMAL
- en: Blocking example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, let''s take a look at the API behind creating an asynchronous IO action:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/265727b1-1148-4184-84d6-4729f59758c3.png)'
  prefs: []
  type: TYPE_IMG
- en: So, you can supply an arbitrary task into an `apply` method of IO, and this
    will construct the description of this task.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can model blocking of a computation by using the `Thread.sleep` Java API
    under the IO apply method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the preceding example will block its thread. IO may be just a description
    of a computation. However, the computations are supposed to get executed at some
    point. In the JVM world, any computation runs on a thread. In the preceding example,
    we are using the Java `Thread.sleep` API to explicitly say that we need to block
    a thread the computation is running on for one second, or 1,000 milliseconds.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the help of the preceding primitive, let''s compose an infinite computation
    that will be easy for us to trace and study. If we have a long-running computation
    that outputs something to the command line in equal periods of time, we can easily
    see whether and how the computation is progressing. Typically, such an infinite
    computation would be possible in terms of a loop. In functional programming, a
    loop can be created in terms of Monad''s `tailRecM`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, you can see a Monadic infinite loop that utilizes IO
    to describe an infinite computation. First of all, the computation will output
    the name of the current thread, the name of the current task, and the number that
    will be incremented from iteration to iteration.
  prefs: []
  type: TYPE_NORMAL
- en: The thread output can be useful to trace which thread the computation is running
    on. This information can be used to see how threads in a given thread pool are
    allocated. The prefix is necessary to distinguish one task from another in case
    we want to run several such computations at once. We will do this in order to
    see how such a task performs in a concurrency setting.
  prefs: []
  type: TYPE_NORMAL
- en: Testing out such a blocking task in concurrent environment models requires an
    HTTP server under a high load. There, you also have a multitude of tasks of the
    same nature running concurrently. The preceding example models a situation where
    a handler task blocks the underlying thread.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the identifier number is used to identify the progress of a given task
    so that we can see how evenly the tasks progress and whether any task is getting
    choked.
  prefs: []
  type: TYPE_NORMAL
- en: Since, in the preceding example, we were motivated by the ability to test tasks
    in the concurrency settings, next, we will talk briefly about the concurrency
    environment we are going to run the tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency infrastructure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The concurrency environment is represented by an execution context, which is
    a Scala class. The official documentation defines it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fe9abd00-668c-4d79-b98a-3d458518d117.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It is a standard Scala class with a single method to run a Java `Runnable`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/420e034c-d13b-48e7-99fa-839c77d0e4d1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'An execution context is necessary whenever we are dealing with concurrency
    primitives in Scala, such as Future. The Cats effect also relies on this type
    to describe its own execution environment. We can construct an execution context
    and specify the number of threads available in its thread pool as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we are using the `fromExecutor` method of the `ExecutionContext` class,
    which is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9b80d494-eb16-4fa8-8471-db9199cbe54a.png)'
  prefs: []
  type: TYPE_IMG
- en: This method uses the Java API to construct the execution context. In our concrete
    preceding example, we are constructing an execution contact that possesses a fixed
    thread pool that has two threads.
  prefs: []
  type: TYPE_NORMAL
- en: Another motivating factor for our example was running multiple instances of
    the same concurrently. Next, we will be looking at the API to provide this functionality.
  prefs: []
  type: TYPE_NORMAL
- en: Running tasks in bunches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can define a function to run an arbitrary IO task on a given execution context
    in multiple instances, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `bunch` function takes the number of tasks we need to launch concurrently
    as the first argument. As a second argument, it takes a function `gen` to construct
    tasks. The function takes a string as its first argument, which is the name of
    the task. In the conditions where we have the same task to run in multiple instances,
    it is crucial to distinguish them somehow. Therefore, we need to provide the name
    to the generator function.
  prefs: []
  type: TYPE_NORMAL
- en: To understand the output type of the function, let's take a look at the body
    of the function.
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, the body constructs a list of `n` elements. The intention is
    to use the list to specify the loop to create the tasks. We then create the required
    number of tasks by using the `map` function on the list we have created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we are using the traverse function, which does something to each task
    we have just created. Let''s take a look at what happens inside the traverse function
    to see how parallelism is achieved in the Cats effect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The main point of interest is the `start` function. Let''s take a look at how
    it is defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/549d348a-3e20-48a5-a6a9-a12295d0cd1e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The function in question produces a so-called `Fiber` under the IO primitive.
    Let''s take a look at how `Fiber` is defined and what it is all about:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/64e6ee05-fe69-4637-b758-18ff6a2f310d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It defines the following API:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f0a504b4-e6f5-4b0f-b3d9-cf7761afa4c7.png)'
  prefs: []
  type: TYPE_IMG
- en: Usually, waiting in an IO-based Monadic flow blocks execution. Of course, that
    blocking is done asynchronously. However, if you're calling the `start` method
    on an IO, it will not block the Monadic flow. Instead, it will return immediately
    with a `Fiber` object.
  prefs: []
  type: TYPE_NORMAL
- en: Think of a `Fiber` object as a remote control unit for the underlying alpha
    complication. It defines two methods, `cancel` and `join`. These two methods can
    be used to communicate with the underlying computation. The `cancel` method cancels
    the competition, and the `join` method blocks the current Monadic flow until an
    underlying IO computation finishes. `join` returns the value of this computation
    in the Monadic floor.
  prefs: []
  type: TYPE_NORMAL
- en: Also, notice that these `cancel` and `join` methods are all returning an IO
    primitive. This means that you can use this method from a Monadic flow.
  prefs: []
  type: TYPE_NORMAL
- en: So, why are we using the `start` method from our bunch example?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Remember, our tasks are infinite. We have defined them has an infinite loop
    that blocks every second. The job of traverse is to evaluate all of the tasks
    supplied to it and return a combined task under a single effect type, in this
    case, IO. However, our tasks cannot be evaluated to some concrete result since
    they are infinite. Hence, we will perform the start call on every task in order
    to specify that we do not need the task's result itself; we can only be satisfied
    with the remote control unit for this task. This way, the traverse method will
    not wait for any single task to finish, but will start all of them asynchronously
    on the execution context we discussed previously.
  prefs: []
  type: TYPE_NORMAL
- en: Heavy load with blocking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, imagine that our `taskHeavy` is a handler for an HTTP server. The server
    is undergoing a heavy load and has `1000` ongoing requests. This means that we
    need to create `1000` tasks to handle them. With the `bunch` method, we can define
    such handling as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that we have encountered another new primitive in this example. It is
    a `shift` method that''s defined on the IO data type. It is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/03d84edb-7e47-49b6-b2c3-54e99d37edd0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `shift` method is an instruction for the execution to get shifted to an `ExecutionContext`,
    which is present as an implicit dependency in scope. Here, we implicitly depend
    on a `Timer` object and not an `ExecutionContext`. The `ExecutionContext` can
    be used to derive a `Timer` object using an implicit method that is a part of
    the IO API:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/95318aa0-2298-4dab-83bd-5d9e062f295a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Since we have an `ExecutionContext` in the implicit scope, we can call the
    `shift` method to shift the execution of the current IO computation to the thread
    pool with have defined. Also notice the `*>` operator here, which we discussed
    previously in this chapter. It says that the second competition should be executed
    after the first one, which is the shift to a concurrent context. We also ran the
    example in place to see how it goes with the help of `unsafeRunSync`. The output
    of the program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1af49cec-3c98-4209-80b5-1541648c31b3.png)'
  prefs: []
  type: TYPE_IMG
- en: The first thing to notice here is that both of the threads we have in our `ExecutionContext`
    are used to process the tasks. You can see that by looking at the name of the
    threads output by the task. It changes from task to task. However, also take note
    that it is only the first two tasks that get the chance to be executed. This is
    because we are using a blocking call to `Thread.sleep` to specify and delay our
    execution. So, in the setting of the infinite handling tasks, such a server, it
    would only be able to handle two requests at a time. In a setting where you need
    to handle `1000` requests, this is inadequate.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's see how we can benefit from asynchrony to specify lightweight concurrency
    primitives to handle that volume of requests.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronous tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can asynchronously define the preceding computation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that this method is defined similarly to the previous task. However,
    we no longer block the thread. Instead, we are using a built-in IO primitive called `sleep`.
    `sleep` is a non-blocking primitive, meaning that it does not block the underlying
    thread. That is, it is a description of the `sleep` operation. Remember, all of
    the computations happening defined in terms of IO are descriptions of computations
    and not computations themselves. So, you can define a `sleep` operation as you
    please. Hence, it is reasonable to define this operation in an unblocking manner
    so that the underlying thread gets released when this `sleep` operation is encountered,
    and the computation is resumed when the execution environment receives a signal
    stating that the `sleep` operation was terminated successfully. A similar principle
    is used in all asynchronous computations. We can run this task as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8e1949a9-6ba6-46fb-b263-03a0460e5133.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice how all of the `1000` tasks get enough resources to get executed. This
    is because each of these tasks releases the underlying thread once they do not
    need it anymore. Hence, even with two threads, we are able to handle 1,000 tasks
    at once successfully. So, computations described asynchronously are quite lightweight
    and can be used in systems that are designed for high loads. Next, let's take
    a look at how you can create an asynchronous IO primitive yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Constructing asynchronous tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: IO provides an API that allows you to transform an existing computation based
    on callbacks into an asynchronous IO. This can be used to port existing computation
    to IO in an asynchronous manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose you have the following computation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Like we saw previously, it is blocking a thread as it uses `Thread.sleep` to
    block the computation. The entire point of the computation is that it does not
    return immediately.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at how you can asynchronously run the computation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are using an already familiar way to lift a synchronous computation
    into an IO data type. We have already seen the consequences of doing so in our
    previous example. This time, since our computation is not infinite, let''s take
    a look at the time difference of handling this computation versus an asynchronous
    competition we are about to construct from it. To do so, we will need a benchmarking
    capability:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we are constructing a benchmarking capability that will
    run IO and will report on how long it took to run the computation.
  prefs: []
  type: TYPE_NORMAL
- en: The first thing to notice here is how computation as a value strategy that IO
    implies can be beneficial to augment computations. Here, the benchmark method
    accepts an IO that is not yet evaluated. It is just a description of a computation.
    Next, it wraps this computation in a capability to measure time, and, finally,
    it returns the result of the computation, together with the benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, notice how we are using the `Timer` data type here. We have already briefly
    touched on the `Timer` class in the context of the execution context of the IO
    primitive. The `Timer` class happens to be an execution context that IO uses to
    manage its threading:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8bbf3032-f573-4fe7-a84c-5655149ca804.png)'
  prefs: []
  type: TYPE_IMG
- en: '`Timer` defines the following abstract methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5ac021b4-7fd1-4bc1-a0b6-00ba741ac609.png)'
  prefs: []
  type: TYPE_IMG
- en: We are already familiar with the `shift` method. It can be used to shift the
    execution context of a given IO flow into this `Timer`. Remember that `Timer`
    can be constructed from a standard Scala `ExecutionContext`. Other methods that
    `Timer` defines are needed for time measurement. One of them is `clockMonotonic`,
    which we are using for our preceding benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we may want to define a `benchmarkFlush` method to report the measurements
    to the command line as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will try and run our synchronous example concurrently in multiple
    instances while measuring its time. But first of all, we will need a `bunch` function
    to launch multiple instances of this task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The first part of this function is similar to the one we had in the previous
    example. However, we have this function slightly extended with the following appendix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Remember that the original version of our bunch function started computations
    asynchronously from its `traverse` method. The result was a list of `Fibers` that
    we were not interested in. In the task of benchmarking, we are interested in the
    time when all the computations terminate. Hence, we would like to use the `join`
    method of the `Fibers` that are returned to create a combined IO data type that
    succeeds when all of the computations succeed. Notice that we still need the `start`
    capability for the tasks to be started asynchronously and not sequentially. If
    you don't use the `start` method from the `traverse` method here, tasks we are
    trying to start in the bunch will be executed synchronously, and we need parallel
    execution to utilize our shared thread pool.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can run the synchronous example in a `bunch` under the benchmark,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0262cf11-caa9-44e5-a3ee-b93cd1fdf274.png)'
  prefs: []
  type: TYPE_IMG
- en: It took us five seconds to compute 10 tasks. This is because each of the tasks
    blocks the underlying thread for one second, and we have two threats in our execution
    context.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we'll take a look at how to define an asynchronous version of the same
    task.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First of all, we need to remark what exactly we mean by the word asynchronous.
    We mean asynchronous with respect to the thread pool that the IO data type is
    executed on. We assume that we have no control of the task itself, and we are
    not able to redefine it. In fact, we do not care about how it is implemented;
    all we care about is the precise moment when it terminates. The task here is to
    prevent the threads of this precise IO execution from blocking.
  prefs: []
  type: TYPE_NORMAL
- en: 'To achieve this, we can use the `IO.async` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c27285a4-05d7-4659-ab0e-21e329817001.png)'
  prefs: []
  type: TYPE_IMG
- en: This method has a somewhat tricky signature. So, first, let's take a look in
    brief at what it does. Given a particular computation, it provides a callback
    with which it can notify the IO task to be constructed. The IO task returned from
    the `async` method will be considered completed once the underlying computation
    calls the callback provided to it.
  prefs: []
  type: TYPE_NORMAL
- en: The benefit of this approach is that the IO does not care about where or how
    the computational runs. It only cares about when it is completed.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the `async` method is a function, the argument to which is another function
    with the following signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: It is a callback that an underlying computation will call on its completion.
    It is provided to the user of the `async` method by IO, and acts as a notification
    stating that the IO should be considered completed.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's take a look at how this method can be used to create asynchronous
    computations.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can redefine our previous example in terms of `async` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: So, here, we are using the `IO.async` primitive to lift our computation into
    an asynchronous context. First of all, this `async` method gives us a callback
    as an input. We are supposed to call this callback once we are done with our computation.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we dispatch our heavy computation to some other execution context. In
    our case, it is merely starting another thread that does not belong to the thread
    pool on which we are executing our IO. Many scenarios are possible here, especially
    in the context of purely asynchronous computations, that is, the ones that do
    not use blocking at all. For example, you could imagine registering a callback
    on another asynchronous action from `async`. This can be useful, for example,
    for GUI programming. However, in this example, using a separate thread will suffice.
    The only thing to keep in mind is that threads are heavyweight primitives. Although
    we are not blocking the IO thread pool, we are still creating threads, and we
    are still blocking them. This can drain the resources of the system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can run our computation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1fd47afc-5165-460d-8b33-80023744919c.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that we were able to compute the operation in two seconds. This is because
    the IO tasks are no longer blocking the underlying execution thread pull the IO
    is executed on. So, once one IO goes to sleep, it releases its thread.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will pay a little bit more attention to `Fibers` and how you can utilize
    them for concurrent programming.
  prefs: []
  type: TYPE_NORMAL
- en: Fibers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we previously discussed, Fibers are essentially remote control units for
    IO. Let's see how this can be used in practice to run operations in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: The computation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Suppose that you have some long-running competition. Suppose that the computation
    in question has the task of finding a sum of numbers on a specific range. The
    computation is long-running because the invocation must pause for half a second
    from number to number:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We are defining our competition in terms of a Monadic loop. In the body of the
    flow of the loop, we have two terminal cases. The first terminal case is when
    the current number is equal to the upper bound of our range. In that case, the
    result is the running total plus that number.
  prefs: []
  type: TYPE_NORMAL
- en: Another terminal case is when the number is greater than the upper range of
    the loop. In principle, this situation should never arise, but it is still a good
    idea to guard against it to prevent infinite loops. In this scenario, we return
    the running total without adding the current number.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also notice the `pure` method, which is used in these non-terminal cases. It
    is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a0ce1cee-5993-40ce-acab-b8b440442402.png)'
  prefs: []
  type: TYPE_IMG
- en: It lifts a value into the IO context without doing anything else with it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we have a non-terminal case of the Monadic loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We have some debugging output stating the current thread and the current status
    of the computation. Then, we block the execution asynchronously by using the `IO.sleep`
    primitive.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we return with a new state of the computation, that is, the next number,
    and the updated running total.
  prefs: []
  type: TYPE_NORMAL
- en: The computation is long-running because it will pause for half a second on each
    number.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's see what happens if we want to combine the results of two such computations.
  prefs: []
  type: TYPE_NORMAL
- en: IO combination without Fibers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Consider that we need to compute a sum of two ranges, and then sum the results.
    A naive way to combine is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we combine our computations using the Monadic flow.
    Let''s see what happens if we try and run the competition under a benchmark function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of the preceding execution is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/380011da-dc89-4732-a245-542013df5c1a.png)'
  prefs: []
  type: TYPE_IMG
- en: First, notice that the first range gets computed first. The second range does
    not even start until the first range finishes. Also notice how both of the threads
    of the thread pool get utilized in the process of computation. This can be considered
    a waste of threads and resources since we could use both of the threads to compute
    sums in parallel. However, we are doing so sequentially here.
  prefs: []
  type: TYPE_NORMAL
- en: 'We may argue that the preceding scenario occurs because we are using the Monadic
    flow. As you may recall, Monads define sequential composition. It is not possible
    to start the next computation until the previous computation finishes. Also, we
    know that Applicative is used for cases of parallelism. Can we apply the `traverse`
    function to compute all of our computations in parallel? Let''s try:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Now, the computations are independent one from another. What happens if we run
    them?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The output looks precisely the same as it did in the preceding sequential example,
    which means that the default implementation of Applicative for IO runs the computations
    one by one, even though they are independent.
  prefs: []
  type: TYPE_NORMAL
- en: How can the situation be remedied with the help of Fibers? Let's take a look
    at how we can launch the computations in parallel with Fibers.
  prefs: []
  type: TYPE_NORMAL
- en: IO combination with Fibers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Previously, we briefly touched on the topic of Fibers. They are remote control
    units for underlying computations. We know that on any IO, we can call a `start`
    method, and that will cause it to run asynchronously, which means that it will
    not block the current execution flow of the IO effect type. Also, you know that
    we can later block on a Fiber in order to obtain the result. Notice that, here,
    we are blocking with respect to the Monadic flow. It is precisely the Monadic
    flow that is getting blocked, that is, the execution of the Monadic instructions
    gets suspended. The underlying thread IO used to run is not blocked by anything.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how we can implement our sum example with the help of Fibers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Our sum instructions are executed asynchronously with respect to the Monadic
    flow, which means that the Monadic flow application will not wait for either of
    the two sums to finish and will proceed directly through the first two instructions
    without blocking. The result is that both of the computations get submitted for
    execution and will be executed in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: 'After that, we can block on the Fibers to obtain the results. We can run the
    application as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/045e158b-fc1d-4da4-9f04-91698eacc9f8.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, both of the tasks are executed concurrently. The time needed to compute
    the tasks is reduced by a factor of 2.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's take a look at another capability of Fibers, namely to cancel the
    underlying computation.
  prefs: []
  type: TYPE_NORMAL
- en: Canceling Fibers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Suppose we have one range shorter than another, and we would like to cancel
    the longer range computation when the first one is completed. You can do this
    with Fibers as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We can run it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'And the result of the execution is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6c17f512-d4b0-451a-8d3c-e05cb5b6897d.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that the second range gets cancelled once the first range finishes its
    execution.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we have discussed the currency capabilities of the Cats effects
    library in detail. It is the primary objective of the library. However, it has
    a bunch of other useful methods and primitives. So, next, we will take a look
    at one of these primitives—the `bracket` primitive—which is a try-with-resources
    for Cats.
  prefs: []
  type: TYPE_NORMAL
- en: Bracket
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Often, we encounter a situation where we need to access a resource that we
    need to close afterwards. This can be a file reference, a database session, a
    HTTP connection, or something else. The Cats effect has a dedicated primitive
    to allow you to work with such resources securely. In Java, there is a dedicated
    statement for handling resources, which is try-with-resources. Scala does not
    have a similar statement. However, the situation changes with the `bracket` method,
    which is defined on the IO primitive:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/75d5b6ae-baa6-4740-9c31-0c12b9eab7dd.png)'
  prefs: []
  type: TYPE_IMG
- en: As it says in the documentation, the `bracket` primitive makes the underlying
    execution engine treat the result of this IO as a resource to be closed. With
    the `bracket` function, you can pass two arguments. The first one specifies what
    you wanted to do with the underlying process. It is very much like the argument
    to the `flatMap` function. The second function is the specification of how to
    close the underlying resource. This second function will be called after the computation
    is finished, no matter how it finished. It could have finished with an error or
    canceled, however, the cleanup function will be called in any situation. This
    prevents memory leaks that can be a problem in the situation of a high-performance
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at how we can use it as an example. First of all, we need
    a closable resource, the closed status of which we can easily check. We can define
    it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we have defined a database session connection. It has
    a `closed` flag which prevents any statements to be run against this session when
    it is set. Next, we have the `runStatement` method, which performs some execution
    logic to model a statement run against a database.
  prefs: []
  type: TYPE_NORMAL
- en: This `runStatement` method deserves special attention because it demonstrates
    the power of treating computations as values. First of all, you can see that we
    define the computation logic in the `computation` value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Afterwards, we check whether the `closed` flag is set. If it isn''t, we return
    the computation as usual. However, if it is, we return an error. The error method
    is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3f2cdf87-1612-4ac3-a978-c1fa2f792c19.png)'
  prefs: []
  type: TYPE_IMG
- en: It terminates the ongoing IO computation due to a failure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s define a few helper methods with which we are going to test our
    bracket primitive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we have a function to create a database, and a function
    to query users from this database connection. Everything is done under the IO
    data type.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s create a setup that will allow us to see whether a connection
    was closed or not. We can do so by creating a Monadic flow under the bracket primitive,
    and from the flow, we are going to leak the reference to our session to a variable
    outside the flow that we are going to check afterward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: So, in the preceding code, we are using the bracket from the computation value.
    We are on the Monadic flow inside this bracket, and as a part of this Monadic flow,
    we are selecting the users to verify that our program works correctly. Finally,
    we leak the resource to a variable outside the flow. The cleanup function is defined
    as closing the session.
  prefs: []
  type: TYPE_NORMAL
- en: 'The result of running the preceding computation is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/07d634ce-1bad-4bc0-b32a-18c7077b728a.png)'
  prefs: []
  type: TYPE_IMG
- en: Together with the asynchronous capabilities of IO, bracket provides you with
    a great primitive that can be used in an asynchronous environment where you would
    like to guard against memory leaks.
  prefs: []
  type: TYPE_NORMAL
- en: Server-side programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One large domain for applying functional programming is server-side programming.
    Server-side programming refers to web applications that constantly run on a server,
    and have the ability to communicate with the outer world. Such an application
    will typically listen on a port for incoming HTTP requests. After a request arrives,
    it will perform some work on the server, and reply back to the requesting client
    with the result of the computation.
  prefs: []
  type: TYPE_NORMAL
- en: Applications of such systems are wide. Everything from regular websites to mobile
    applications to **Software as a Service** (**SaaS**) systems are made as web applications.
    Also, once you have a web application that constantly runs on a server, communicates
    with the outer world via a well-defined protocol, and performs some computations,
    you can have a multitude of clients for such an application. For example, you
    may have an HTML-based frontend, together with a mobile application, together
    with integration with third-party applications via API.
  prefs: []
  type: TYPE_NORMAL
- en: Scala and the Cats infrastructure happens to have great support for server-side
    programming. They contain all the primitives that you will need to accept HTTP
    requests, map them to your domain model objects, communicate with the database,
    and reply back to the client. In this section, we will see how exactly it is done.
  prefs: []
  type: TYPE_NORMAL
- en: But first of all, let's get a brief overview of the general architecture of
    server-side applications, as well as specify the application we are going to be
    using as an example for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The architecture of a server-side application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First of all, a server application includes a server. A server is an application
    that will constantly run on the given machine and listen to a given HTTP port
    for incoming connections. The incoming connections are typically HTTP connections
    that follow a certain protocol.
  prefs: []
  type: TYPE_NORMAL
- en: Communication protocol
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A popular way to structure a communication protocol of a web application is
    to follow the RESTful paradigm of communication.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the application listens for HTTP requests, it is reasonable that these
    requests are made to a certain path. For example, a typical HTTP request contains
    the following headers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: So, as you can see, the request contains a destination string or a so-called
    path, together with HTTP headers. You can reason about the resources the server
    exposes as entities that have certain behaviors and data defined on them. The
    RESTful paradigm dictates that the capabilities the server side exposes via HTTP
    must have the paths and HTTP methods reflect the resources and their behavior
    that is to be performed.
  prefs: []
  type: TYPE_NORMAL
- en: For example, consider that you have a server that manages a forum. We will have
    users and forum posts. Regarding the behaviors, over time, we will want to create
    new posts and users, list existing posts and users, and modify and delete them.
  prefs: []
  type: TYPE_NORMAL
- en: 'These behaviors can be exposed via the HTTP RESTful API as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: So, the HTTP methods reflect the nature of the behavior to be performed by the
    server. The paths reflect the nature of resources involved in the given behavior.
  prefs: []
  type: TYPE_NORMAL
- en: The client must frequently send extra information to the server. The server
    is supposed to reply to the client with a certain result. This request and response
    data must follow a certain format that is understandable to both the client and
    the server. Furthermore, since a web application can be exposed not only to one
    client but to a multitude of potential third-party clients, it is necessary that
    such a protocol must be standardized. The same way as the HTTP protocol is a standard
    protocol which a multitude of independent parties understand and implement, the
    same way the requests and responses protocol must also be supported by a multitude
    of independent parties. This is because they will need some libraries to encode
    and decode this request, and we do not want an overhead for them so that they
    can implement them themselves.
  prefs: []
  type: TYPE_NORMAL
- en: So, a standard way to encode the requests and responses is to use JSON or XML.
    In this example, we will be using JSON because it has much better support than
    XML in Scala. Furthermore, the Cats family of libraries includes capabilities
    to work with JSON easily.
  prefs: []
  type: TYPE_NORMAL
- en: The communication protocol is only a small part of what is involved in the server
    architecture. Next, we will briefly discuss which components a server is composed
    of.
  prefs: []
  type: TYPE_NORMAL
- en: The software architecture of a server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first component that any server must have is an application that is capable
    of listening to HTTP requests and responding to them. Such a component is called
    an HTTP server software. Besides that, most servers need some persistence component—a
    database. Next, the server will need a way to communicate with the database. So,
    we need the database access layer.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, an orchestration solution is necessary for the preceding components
    to play well together, which means that we need an easy capability to bootstrap
    both the server and the database, and a way to define the communication between
    them. It is important that the orchestration is well-defined and is reproducible,
    with minimal setup on a variety of different environments. This is important because
    you do not want to write the server once for one platform and not be able to port
    it easily to other platforms.
  prefs: []
  type: TYPE_NORMAL
- en: The preceding components are the basic components for any server-side software.
    Of course, more complex server-side applications involve much more complex architectures;
    however, for the purposes of our example, this will suffice.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's discuss the example we are going to use to demonstrate server-side
    programming with the cats and Typelevel libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Example specification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The example in question will be an online store. So, we will have the entities
    for the customers, the goods, and we will have an ability to describe orders that
    the customers make.
  prefs: []
  type: TYPE_NORMAL
- en: We will store all of these entities in a database, and we will expose the functionality
    to create new users and new orders, and to list existing orders and goods via
    an HTTP interface.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's take a look at how this architecture can be put into practice. We
    will be discussing the architecture as a whole, and we will be introducing various
    functional programming libraries in the process. This will facilitate an integrated
    view of how server-side programming can be done with Cats.
  prefs: []
  type: TYPE_NORMAL
- en: Please keep in mind that we will not be going in-depth into any of the libraries
    we are going to discuss, as this would deserve its own book. Also, we have already
    mentioned that cat is on the leading edge of functional programming technology,
    which means that the library develops quickly, and the in-depth information that
    we could have covered would have become obsolete very soon. However, the general
    architectural principles will probably stay the same for a substantial time to
    come.
  prefs: []
  type: TYPE_NORMAL
- en: Orchestration and infrastructure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First of all, we will be talking about our infrastructure and the software we
    will use to implement our architecture.
  prefs: []
  type: TYPE_NORMAL
- en: There will be two separate components to our server-side software. First of
    all, it is Scala-based server-side software, and second of all, it is a Postgres-based
    database.
  prefs: []
  type: TYPE_NORMAL
- en: These two components are orchestrated together via Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Although the topics discussed in this subsection do not deal with functional
    programming, it is necessary to understand the big picture in order to understand
    which setting the functional server will operate in.
  prefs: []
  type: TYPE_NORMAL
- en: Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will define all of the components involved in other software as Docker services
    in a `docker-compose` file.
  prefs: []
  type: TYPE_NORMAL
- en: Docker-compose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The file as a whole will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The file consists of two services—the Postgres service and the backend service.
    The Postgres service is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: This service defines a container named `mastering_postgres`. The `build` directive
    specifies that we want to build the contents of the `Postgres` folder, which is
    located in the current folder, to a separate Docker image. The port's directive
    specifies which ports the container will expose. The container in question will
    run the database, so we need to expose the ports that the database will be running
    on. Basically, it is a mapping from the ports of the container to the ports of
    the host machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second service is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: It also provides the name of its container, and it specifies that we want to
    build the contents of the current folder into a separate image. Docker will look
    for a `Dockerfile` in the provided directory and will build it into a separate
    image. Next, since this container will host an HTTP server, we also need to perform
    the port mapping so that we can listen to HTTP connection of the host machine
    from the container.
  prefs: []
  type: TYPE_NORMAL
- en: After that, we have the `volumes` array. This array specifies the directories
    on the local machine to be mounted to the directories on the container. In the
    current example, we mount a set of directories of the container that are responsible
    for caching. The first entry is an `ivy2` cache that is used by Scala and SBT
    to store their dependencies. After that, we also mount the SBT root folder, which
    hosts the SBT installation. Finally, we mount the cache folder, which is another
    location where SBT stores its dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: We perform these mounts of the cache directories so that the container remembers
    what it fetched from invocation to invocation. So, you will not need to wait for
    the application to fetch its dependencies every time you restart the Docker container
    because all of the dependencies will be stored on the host machine under the directories
    that we have mounted.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we mount the current directory to the examples directory under the
    container. This is done so that we can access the Scala sources from the container.
    So, we will be able to run the application from the context of the Docker container,
    which means that we will be able to access all of the infrastructure defined by
    the `docker-compose` file.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we have an `environment` array. This array specifies the environmental
    variables set the container will be initialized with. We have the variables that
    specify the host and port of the Postgres database. We will use these environmental
    variables in the Scala sources to specify the location of the database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we have two technical entries in the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: These are related to the ability to access the running Docker container from
    the command line. So, we should be able to open a command line on a running Docker
    container due to these two entries. Basically, they specify how the Docker container
    should allocate and treat a console device. If you are interested more in this
    or any other of the Docker entries, please consult the Docker documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's discuss the two Dockerfiles corresponding to the two services we
    have defined in `docker-compose`.
  prefs: []
  type: TYPE_NORMAL
- en: Dockerfiles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Dockerfiles contain the descriptions of how a particular image must be built.
    We have two images: one is for the database, and the other one is for the backend.
    Let''s start with the database image first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The Docker file only contains two lines of code. First of all, we inherit from
    an existing image of Postgres. Second, we copy all of the SQL files from the current
    directory to a special directory in the Docker image. This is a standard initialization
    procedure described in the documentation of the Postgres image we inherit from.
    The main idea is to initialize the database with a schema that we are going to
    use. Our schema is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: We also have three tables. First, we have a table for customers and goods. Both
    customers and goods have an ID that uniquely identifies them. Also, goods has
    some goods-specific parameters, such as the price and the stock count. Finally,
    we have a table that will link customers to goods as orders.
  prefs: []
  type: TYPE_NORMAL
- en: After that, we will populate our database with some sample goods that we are
    going to run our test queries on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s take a look at our backend image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: The image inherits from a standard Scala SBT image so that we are going to have
    Scala and SBT in scope. After that, we define some SBT plugins that we are going
    to use. The first one is to speed up downloading the dependencies, and the second
    one is used to start the server in a separate JVM. We are going to start a server
    in a separate JVM because, in this way, we will retain the possibility to manage
    the server, and start and restart it from the SBT console.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we set the working directory to our examples directory.
  prefs: []
  type: TYPE_NORMAL
- en: You will find the instructions on how to run the `Dockerfile` in the `README`
    file of the examples repository.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we are familiar with the architecture of the components involved, let's
    start by taking a more detailed look at how the backend software is constructed
    using Scala.
  prefs: []
  type: TYPE_NORMAL
- en: Backend architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The backend is composed of three separate layers. We have a model layer for
    the model of our business domain, the database access later, and the server layer
    itself. Let's take a look at these layers in turn and see how they can be implemented
    with Typelevel libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The model is represented by a single Scala file. It contains case classes that
    model our database. Notice that here, we are using plain Scala case classes without
    any other augmentations. If you are familiar with libraries for the Java-like
    Hibernate, you will know that there is an entire class of libraries for so-called
    **object-relational mapping** (**ORM**). These libraries intend to provide a seamless
    mapping of object-oriented concepts to the database schema. The main idea is to
    be able to manage the database, query it, and update it without the need to perform
    SQL statements explicitly. Such libraries aim to provide you with an object-oriented
    API that allows performing these operations while abstracting the underlying SQL
    engine.
  prefs: []
  type: TYPE_NORMAL
- en: Such libraries proved to be a bad idea because of the leaking abstractions.
    There are corner cases that these kinds of ORM libraries are not able to handle
    well. These libraries may not allow you to perform certain functionality that's
    native to a given database.
  prefs: []
  type: TYPE_NORMAL
- en: In modern functional programming, object-relational mapping is considered a
    bad practice. The current consensus seems to be that executing plain old SQL statements
    is the best way to model interaction with the database. So, unlike object-relational
    mapping libraries, we are not required to modify our domain model specifically
    to match the needs of the object-relational framework we are working under. We
    are not required to implement an interface from our model classes. We are able
    to define our domain model in terms of plain old case classes.
  prefs: []
  type: TYPE_NORMAL
- en: Database layer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A database layer is implemented in terms of the Doobie library. Each entity
    has a separate Scala file, where there is a singleton object, which has all of
    the methods that we need for the purposes of this application. For example, let''s
    take a look at the API that the `customer` object exposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: So, we have several database access methods, and each of them returns an IO—precisely
    the same IO we were learning about in the previous section. The Doobie library
    we are going to have a look at in this section integrates nicely with the Cats
    effect, and we are able to leverage the IO in order to communicate with the database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at how one such method is implemented in terms of Doobie,
    and what the model of operation of Doobie is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Here, we have several things going on. First, we have an SQL statement under
    a string interpolator that Doobie provides. Now, in Scala, you are able to define
    custom string interpolators that have a form of a certain keyword, written just
    before the string literal. In our case, such a keyword is `sql`. The main idea
    of string interpolators is that, on compile time, they are going to transform
    a string in a certain way, possibly producing an entirely different object.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s find out what exactly the string interpolator is doing to the
    string. To do so, we will consult the documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/81f43873-0ac5-4116-a4c7-6712015180e9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So, `sql` is an alias for `fr0` and is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c438f9f5-ed8b-4bc4-8a72-c52ddc267f4c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This object has two methods to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/abf5e587-0a33-4d05-bd0b-fb2e71003f30.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that one of these methods is a macro definition. The macro definition
    is a special method in Scala, which is invoked at compile time. It is used for
    metaprogramming in Scala. String interpolators are usually implemented in terms
    of macros.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, macro transforms a string into a `Fragment` object. A fragment is a model
    of an SQL statement under a string interpolator. Notice that, in the preceding
    screenshot, the string interpolator also gives us external variables to be used
    in SQL statements, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Interpolation is done by the dedicated Doobie macro. It interpolates the variables
    in a secure way so that you do not need to worry about escaping the variables
    that you are inserting into an SQL query—this way, you don't get an SQL injection.
    Doobie performs the escapes for you.
  prefs: []
  type: TYPE_NORMAL
- en: One thing to notice about the technique employed by Doobie here is that your
    SQL code to interact with the database is defined as a string. However, this string
    is processed at compile time. This provides you with a measure of type safety
    and compiler assistance at compile time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at the fragment definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/770bf606-5a06-446b-bc62-9fde80a8edb1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fragment has the following API exposed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6eab09be-6bb4-45d4-b227-ef3221d25647.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For our purposes, the following two methods are of particular importance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/072fecec-8741-42f5-aef7-787e71b7d31e.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding method is used for query operations, such as selecting from the
    database.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following method is used for update operations, such as making modifications
    to the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1a2e3322-9895-459b-a06d-e1064a9e382f.png)'
  prefs: []
  type: TYPE_IMG
- en: A fragment is a model of the statement that you have passed to the string interpolator.
    However, this model does not store the information about which exact operation
    you want to perform against the database. So, to specify this kind of operation,
    you call the `update` or `query` methods on `Fragment`. An `update` method is
    used for insert and update operations, and the `query` method is used for `select`
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, we are calling the `update` method because we perform an insert
    query. Next, an `Update0` object is generated from the fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4cf9f196-062f-4790-9b6b-35a083d155f1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It exposes the following API:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0ec0d938-de5c-41ec-a42f-9540ea301778.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that its API is divided into two sections. First, there is the diagnostics
    section. Since Doobie constructs an internal model of your query, it allows you
    to run certain tests on it to check whether your parameters passed to the query
    are of correct types and whether the query itself is composed correctly. We also
    have the execution API. The execution API is what you use in order to run the
    query.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that all of the methods from the execution category return a type under
    the `ConnectionIO` effect type. `ConnectionIO` is essentially a so-called free
    object. If a fragment and `Update0` are models of the SQL query you are about
    to run, the free object of `ConnectionIO` models the precise steps the program
    needs to take against the database to run this query. The free object is a concept
    that comes from abstract algebra. Essentially, the idea is to model the computation
    under the free object without actually running it. The idea is precisely the same
    as with the IO effect type that we looked at in the previous section. That type
    is also a free object.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we are calling the `UniqueGeneratedKeys` method in our example.
    The method is aware that the underlying database will generate a primary key for
    the insert operation we are about to perform. In our case, the primary key is
    an integer, and we are passing a type parameter of integer to the method.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have a look at the `ConnectionIO` definition, you will see that it is
    a `Free` Monad:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/47d743ae-9497-4e10-baf5-df4e81da8e22.png)'
  prefs: []
  type: TYPE_IMG
- en: So, the underlying implementation of DB operations is done using the free Monad
    library, which is also a part of the Cats infrastructure. As we have previously
    said, we will not go into detail about these auxiliary libraries and ideas since,
    by themselves, they deserve a separate book. So, here, the main catch to make
    is that the Doobie library starts from constructing a model of your SQL query
    and provides you with an API to gradually transform it into the model of the computation
    to be performed against your database. Everywhere, the paradigm of computation
    as a value is maintained, and nothing is run until explicitly instructed to.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are able to run the `ConnectionIO` under the given effect type using the `transact`
    operation on it. This operation is injected via a Rich Wrapper, which is defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/25bb8703-cbed-40d3-8de5-6ff523ca346d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following constructor is used to construct the wrapper:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/836cd659-1ef3-4859-8013-79eb3bc9fc82.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It exposes only a single method:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f9d8c294-10b2-49e9-aebd-7788738616ac.png)'
  prefs: []
  type: TYPE_IMG
- en: Essentially, the method is tasked by running the computation under a certain
    effect type when given a transactor for the database. Now, the transactor for
    the database is a driver that knows how to communicate with the underlying database.
    Notice that so far, Doobie exposes the database-independent API, which is expected
    of this kind of library. So, the information that is database-specific is stored
    under the `Transactor` object, which must be implemented for your database in
    order for you to run database queries against that database.
  prefs: []
  type: TYPE_NORMAL
- en: Also notice that the effect type that we are passing to the `transact` method
    has a type parameter. This parameter specifies the effect type under which we
    are going to run our computation. Remember that `ConnectionIO` is just a description
    of the computation to be performed. In order to perform it, we need to specify
    which effect type we are going to perform it under.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, we are using the `tr` variable as the transactor. So, let''s
    take a look at how it is defined to understand the semantics of our example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are using the built-in Doobie method to construct the transactor, given
    the full class name of the database driver for the database that we are going
    to use. In our case, we are using Postgres, and we are passing the fully qualified
    name of the Postgres driver to the driver manager construction API.
  prefs: []
  type: TYPE_NORMAL
- en: The next argument to the driver manager construction method is the address of
    the database we are going to connect to. Here, we are connecting to a Postgres
    database, and we are reading its host and port from the environmental variables.
    Remember that, when we were discussing the Docker orchestration of the backend
    and the database, we discussed that the backend has environmental variables populated
    from the `docker-compose` file. These variables specify where the database resides
    for the backend to connect to it.
  prefs: []
  type: TYPE_NORMAL
- en: After the connection string, we have a login and password for the database.
    In our case, login and password are standard connection strings for the Docker
    Postgres image that we are using.
  prefs: []
  type: TYPE_NORMAL
- en: Also, notice that our transactor is constructed for the effects type of IO.
    This means that when we are going to run the query against this transactor, the
    result will be an IO.
  prefs: []
  type: TYPE_NORMAL
- en: Let's recall what IO is. It is a description of the computation to take place.
    However, `ConnectionIO` is also a description of a computation that is going to
    take place. So, when we are executing the `transact` statement on the `ConnectionIO`,
    we are not actually running it as a computation but translating it from one free
    language to another. We are translating it from `ConnectionIO` to IO. This kind
    of translation from one free language to another is quite common in purely functional
    programming. A useful intuition for when it may be useful may be that of high-level
    programming languages versus low-level programming languages. When you compile
    a language such as Scala or Java, a translation happens from the high-level language
    to the low-level language of the bytecode.
  prefs: []
  type: TYPE_NORMAL
- en: For humans, it is more convenient to program in a high-level language, but for
    the machines, it is more convenient to consume a low-level language. Hence, before
    we actually run the program, we must first translate it from a high-level language
    to a low-level language.
  prefs: []
  type: TYPE_NORMAL
- en: Something along these lines can also be said about translating from one free
    effect type to another free effect type. Essentially, when aiming to specify all
    of our computations as values, we will sooner or later encounter a situation when
    certain tasks can be easily described using one, higher level language. However,
    it is more convenient to run them when they are expressed in a lower level language.
    So, the translation takes place from a higher level language to a lower level
    language.
  prefs: []
  type: TYPE_NORMAL
- en: In our example, we are performing their translation from `ConnectionIO`, which
    is a domain-specific language for describing interactions with a database, to
    the IO language, which is a general purpose low-level language that can describe
    any input-output operation.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, our create method of the `customer` object outputs as IO, which we
    can later run when we need their results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at the additional methods that we have already mentioned
    are members of the `customer` object. First of all, let''s take a look at the `list`
    method that is supposed to list all of the customers that are present in the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The `selectCustomerSql` variable is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'We define this query in a separate variable since we are going to reuse it
    in other queries, as we will see a little bit later. Notice how we are using the
    other string interpolators that are available as part of Doobie:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2cc07c35-73d0-4d5d-a879-d355063a882c.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from the documentation, Doobie provides you with several ways
    to specify fragments as string interpolators. The main difference is whether or
    not they have a trailing whitespace after them. Such a trailing whitespace may
    be very useful if you want to compose your fragments with other fragments later.
    To make sure that you don't need to worry about the separating two fragments you
    are going to concatenate with a whitespace, there is a default string interpolator
    which injects the white space for you. We will see how this is useful later.
  prefs: []
  type: TYPE_NORMAL
- en: Returning to our `list` example, as you can see, we are running the query method
    on a fragment. This is to be contrasted with the `update` method on the `create`
    method of the `customer` object. We are performing a `select` query, and so we
    are going to run the `query` method.
  prefs: []
  type: TYPE_NORMAL
- en: The method generates a `Query` object. An interesting thing to notice here is
    that Doobie can automatically convert the result from the raw data returned from
    the database to the data type of your choice. So, we provide the `Customer` type
    as the type parameter to the query, and Doobie is able to automatically infer
    a way to convert the results to this type. In general, such conversions are supported
    out of the box for case classes, tuples, and primitive types. This is accomplished
    at compile time metaprogramming, via macros and type-level computations. This
    useful feature from Doobie places allows it to pose a direct competition to traditional
    object-relational mapping libraries because you are able to map your results to
    your domain model at no additional cost.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Query0` object produced by the `query` method is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/781e4d0b-8ecd-458a-b1cf-7767c2c5e8ea.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s take a look at its API. It consists of two parts we are interested in.
    First, the Diagnostics part:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d0c6047c-4807-4cb2-a191-487163ac3e62.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, the Results part:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5d5879ce-e5d7-437a-a542-9525c01432c6.png)'
  prefs: []
  type: TYPE_IMG
- en: As with the case of `Update`, the API is separated into diagnostics and results
    sections. It is the results section that is most interesting to us here. Notice
    that it contains various methods specifying which kind of result you are expecting
    to retrieve from your database query. For example, the `option` method is to be
    called when you expect that the query may be returned empty. The `unique` method
    is to be called when you expect one and only one result from the query. Finally,
    the `to` method is to be called whenever you would like to convert your result
    to some collection. Actually, as you can see, there is no restriction that you
    can only build a collection from the given result here. As long as your result
    type conforms to the `F[_]` type form, you should be able to build whatever you
    want, provided that you have a type class this method implicitly depends on. Most
    frequently, this method is used to create collections from the database.
  prefs: []
  type: TYPE_NORMAL
- en: Other methods for this API can also be used for other types of the results.
    However, for the purpose of this tutorial, these three will suffice.
  prefs: []
  type: TYPE_NORMAL
- en: Returning to our list example, we are calling the `to` method on it to produce
    a list of all of the customers. As a result, we are getting a `ConnectionIO` type,
    which we have already discussed. We then run it against our transactor, like we
    did previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at the `get` method of the `Customer` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The first thing to notice here is that we are performing fragment concatenation.
    So, the query to select the customers from the database remains the same. However,
    we are using the concatenation method defined on `Fragment` to concatenate it
    with another fragment and produce a compound fragment. The concatenation method
    is defined on the fragment as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b43747e3-3a49-4b8e-8923-ebcf38b7afde.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that the trailing white space on the left-hand `Fragment` comes in handy
    here. Remember that we have discussed that the `selectCustomerSql` fragment is
    constructed with a strength interpolator that injects a trailing whitespace into
    the resulting fragment. This is useful precisely for these concatenation situations
    where we need to concatenate two fragments sequentially. Notice that we do not
    need to prepend a white space to the second fragment with the filter condition
    because the first fragment is already built with concatenation in mind.
  prefs: []
  type: TYPE_NORMAL
- en: After that, we run the `query` method similarly to the way we did in the example
    of listing all customers. However, here, we are only expecting one customer. Hence,
    we will call the `unique` method on the query object. Finally, we will call the `transact`
    method to convert the `ConnectionIO` to `IO`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s take a look at the `findByName` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: This method performs a lookup of customers by name. Notice that it is defined
    very similarly to getting a customer by ID. However, we are not calling the `unique`
    method on the query object, but the `option` method. This is because we built
    the method with the possibility of an empty query result in mind. Whenever we
    request a user by ID, we are assuming that the user with the given ID exists in
    the database, at least for the purposes of this example. However, when we are
    looking up a user in the database, we assume that the user with a given name might
    not exist.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, our `findByName` method returns an `Option[Customer]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two final methods that we are going to discuss are the `update` and `delete`
    methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: These methods bring nothing new in terms of the Doobie API and are constructed
    using the API, which we have already learned about.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let ''s see how this example works against a live database. To test this
    example, we will use the following application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding application tests all of the methods that we have discussed so
    far. First, we create a few customers to work with. Then, we test lookup by name.
    After that, we test the listing of all customers in the database. After that,
    we test getting a customer by ID. Finally, we test the `update` and `delete` operations
    on the customers. The result of running the preceding application is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b35e16d4-4f96-4b6b-b7d4-f0a42259841f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Besides the methods for the customers, we will also need methods that define
    how to work with the goods. So, we will need a method to create a good, and we
    can define it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'We will need methods to query the goods table, too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will need `update` and `delete` methods to modify the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need a database access object for the orders so that we can modify
    and list them. We will need the following method defined on the order object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Since these methods do not introduce any new functionality and only demonstrate
    the use of what we have learned of Doobie so far, we will not go into detail regarding
    these methods.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will see how server-side programming can be performed with purely functional
    style, and how it can leverage the database objects we have defined so far.
  prefs: []
  type: TYPE_NORMAL
- en: Server-side programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the purposes of server-side programming, we will be using libraries called
    `HTTP4S` and `Circe`. `HTTP4S` is a library with which you can bootstrap an HTTP
    server, accept requests, and define how to respond to them. `Circe` is a library
    with which you can convert JSON strings to domain objects.
  prefs: []
  type: TYPE_NORMAL
- en: '`HTTP4S` leverages IO under the hood so that it can be nicely integrated into
    our existing database infrastructure that outputs IO, as well as so that we can
    be sure that our server runs asynchronously. `Circe` uses a technique of compile-time
    programming via macros (which we have already discussed briefly) to define how
    to convert JSON strings into Scala case classes or traits.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to bootstrap our server as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Under the hood, `HTTP4S` relies on the other library for server-side programming,
    that is, the `Blaze` library. As we have already mentioned, the infrastructure
    for server-side programming involves a wide range of various libraries, so the
    gist to capture here is the big picture of how server-side programming is done.
  prefs: []
  type: TYPE_NORMAL
- en: We are calling several configuration methods on the `BlazeBuilder` object. The
    `bindHttp` method specifies which host and port we are going to listen to. In
    this case, the host is set to `localhost` or `0.0.0.0`, and the port is set to
    `8888`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we define the handlers that the server will use. This is done by the `mountService`
    method. In this case, we bind a single handler, `all`, to the root path of this
    server. The `all` handler is a handler we are about to define.
  prefs: []
  type: TYPE_NORMAL
- en: When we are done configuring the server, we will call the `serve` method on
    it. The method returns a Stream which is a member of another library that is a
    part of the Cats infrastructure. The library is called FS2 (for Functional Streams)
    and is a dedicated library for working with Streams in a functional way. The Stream
    is lazily evaluated,  and in order to run it under IO, we are going to run the compile
    and drain methods on this Stream. The gist of this method is that it is going
    to run a lazy, side-effecting Stream, under the effects type of IO. The IO is
    returned from the drain method. Next, we run the IO using the `unsafeRunSync`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: So, as you can see, quite a lot of libraries are involved in bootstrapping an
    HTTP server in functional programming. However, the central idea is the same across
    all of these libraries. They all leverage the same effect type, IO, and they all
    subscribe to the idea of lazily evaluated, referentially transparent computations
    as values. This means that no computation is run by default; they all are stored
    as descriptions of computations. Since every library has its own domain, some
    libraries might have their own language to describe their computations. However,
    these domain-specific languages are ultimately translated into the single, low-level
    IO language.
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in understanding what is going on here in more detail,
    the best way to do so is to examine the Scala API documentation for the libraries
    that we have mentioned. Examining the methods that you are calling, the types
    that they are returning, and understanding the meaning of the methods and the
    types in question can get you a long way in understanding what is going on inside
    this library.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will take a look at how the handlers for the web server are defined.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `all` handler is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: This is a combination of several other handlers. The technique to be noted here
    is composability. So, we are capable of composing the other handlers with the
    help of the composition operator.
  prefs: []
  type: TYPE_NORMAL
- en: 'The composition in question is an `or` composition, which means that incoming
    requests will be checked against every handler specified by the composition operator
    in turn. The first handler that is capable of handling the request will be used.
    The individual handlers that compose the whole `all` handler are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'We will create our new customer handler with the help of the `HttpService`
    object. The method we are calling is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6e3f87af-eec2-437e-b9d0-24d8112ed349.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It takes a partial function that maps a request to a response under an effect
    type `F`. A request contains what you would expect a request to have. Here is
    a definition and some of the API methods that it exposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/18b6e019-d271-4815-9585-cd59bce53628.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It exposes the following API:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2e6bb790-b11f-4f15-ab34-c7b736fd6167.png)'
  prefs: []
  type: TYPE_IMG
- en: The partial function passed into the request returns a response under an effect
    type. Currently, the only supported effect type is IO. The fact that it returns
    the response under an effect type means that the server is built with asynchrony
    in mind.
  prefs: []
  type: TYPE_NORMAL
- en: A handler constructed this way will match any incoming request against the partial
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `HttpService` constructed by the call is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ae184c6b-9d91-4688-ac2f-78a4702bcdf3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It is an alias for the `Kleisli` type. `Kleisli` is a part of the `cats` core
    library and is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/62090901-0506-4e45-b694-3e9d92ee6420.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So, essentially, it is nothing more than a function you would pass to, say,
    the `flatMap` method. It is a function of the following kind:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: The partial function we are using to construct the handler does a few things
    here. First of all, notice that there's a DSL to conveniently extract the HTTP
    method and a path from the request. These extractors come from the `HTTP4S` API
    and can be used to match on requests conveniently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we are starting a Monadic flow over IO:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: The `as` call is supposed to extract the `Customer` object from the incoming
    request body. The assumption is made that the body is a valid JSON string, and
    the `Circe` library will be used under the hood to convert the incoming request
    body to the requested data type. You do not need to perform any other specifications
    of how exactly a JSON must be converted to a case class, as `Circe` defines how
    to do that under the hood.
  prefs: []
  type: TYPE_NORMAL
- en: The next thing that we do is we create a customer in the database. We are using
    the database access object that we defined previously in this section to do this.
    As a result, we get the ID of a newly created customer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we construct the response to our query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'We are using the call to the `Ok` method to define the `Ok` response code `200`.
    `Ok` is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ac62b2a5-d356-482b-b2d4-56cbdeed2d88.png)'
  prefs: []
  type: TYPE_IMG
- en: '`Status` is an abstract class that does not have an `apply` method, which is
    necessary for the object to be callable. So, we should not be able to call it.
    The reason we are able to call it in our program is because the method is injected
    into the `Ok` object via the following Rich Wrapper:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ab064298-efbc-4a60-a2e2-3e4eea60c613.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It exposes the following API:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6b18ddcf-459e-4802-922a-b7928a55689b.png)'
  prefs: []
  type: TYPE_IMG
- en: This wrapper is parametrized by an effect type under which the response is computed
    and returned. Currently, `HTTP4S` only supports the IO effect type, but this is
    not a problem since all of the other libraries of Typelevel infrastructure also
    speak the language of IO.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice that we specify a `payload` for the response. It is specified with the `success`
    method, which is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: So, the payload is set to an ordinary Scala, `Map[String, Int]` (Int is inferred
    because the argument to `success` is an integer). Since we are using `Circe`,
    this Scala collection will be automatically encoded into JSON and returned to
    the requesting client. Again, this is provided out of the box at no additional
    cost.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, the `placeOrder` handler is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'It largely uses the functionality that we have already discussed. However,
    a few remarks should be made:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'First of all, `HTTP4S` provides the capability to extract various parameters
    from requests, such as cookies. In the preceding code, we extract the cookie header
    from all of the request headers. If the operation was not successful, we would
    raise an error via an `IO` method. Essentially, rising an error from IO gets the
    entire Monadic flow short-circuited. This is similar to throwing an exception
    from imperative code, except that the IO effect type will take care of error handling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding line, notice how we are able to extract the JSON body of the
    incoming request as a Scala map. So, not only the primitive types and case classes
    are supported by `Circe`, but also the Scala collection types. `Circe` automatically
    derives encoders and decoders for JSON on compile time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the preceding response sets the entire case class as its payload.
    We are returning a case class that's nested inside a Scala map. `Circe` is able
    to encode this data structure into JSON seamlessly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, two list handlers are defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Since our database returns the result in IO and since we are using `Circe` to
    encode the model objects into JSON automatically, we can `flatMap` the response
    from the database to wrap it into the response status code. We are able to specify
    this entire handler as a thin wrapper on top of a database access method in just
    one line.
  prefs: []
  type: TYPE_NORMAL
- en: Querying the server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the example repository, there is a shell script that you can use to query
    the server once you start it. You can start the server with the following command
    from the SBT console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: Notice that this command must be run under the Docker image. So, it will not
    work if you just run an SBT console on your machine from the example repository;
    you will need first to run the Docker image, then run the command from the SBT
    console that is started on that Docker image.
  prefs: []
  type: TYPE_NORMAL
- en: 'After that, you can use the client shell script to query the database server.
    For example, we can create the new customer as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5c7932d1-7da4-4e9e-8521-67f1977287c3.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice how the response is a nicely formatted JSON with an ID of the created
    customer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can list all of the goods that are present in the database so that
    we can place an order:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9ad70984-cf8f-4312-b97a-0709089576c9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So, we got a JSON array of all the goods as the response. We can place an order
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1c5d0905-7e09-4d31-b46f-d621609dac43.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And finally, we can list all of the orders to confirm that we have the order
    in the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b69642e6-4426-49c6-b3da-6bafa2b13682.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have covered the broad infrastructure that the Typelevel
    umbrella of libraries provides for purely functional programming. First, we learned
    the foundation for asynchronous programming with Cats, that is, the Cats effect
    library. We discussed the `IO` concurrency primitive and the philosophy of computations
    as values. After that, we learned the foundations for the server-side programming,
    which involves a range of libraries. The libraries in question were responsible
    for HTTP request handling and database access, while utilizing a JSON conversion
    library under the hood. We have had a birds-eye overview of what programming with
    these may look like.
  prefs: []
  type: TYPE_NORMAL
- en: By now, we have covered enough of material for us to start writing industrial
    software in a purely functional way. In the next chapter, we will see more advanced
    patterns of functional programming. These patterns will help our architectures
    solve broader range of problems and make them more flexible.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Explain the difference between blocking and non-blocking programming.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is asynchronous programming mandatory for high-load systems?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does computation as a value approach benefit concurrent programming?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is an `IO` effect type?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What capabilities for asynchronous programming does `IO` expose?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
