<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Building Applications Using the MicroProfile API</h1>
                </header>
            
            <article>
                
<p>At this point, you should have a good understanding of how to use the most common Java APIs (CDI, REST, JSON, JPA) in a Quarkus application. In this chapter, we will be adding a whole bunch of APIs called the MicroProfile specification. By mastering the topics in this chapter, you will be able to shape up <span class="hs_cos_wrapper hs_cos_wrapper_meta_field hs_cos_wrapper_type_rich_text"><span>components that have built </span><span>upon the core features of the Java EE, which allows for a straightforward development experience when</span> <span>implementing microservices, increasing the robustness of your applications, and reducing the risk of</span> <span>over-designing and reinventing the same patterns.</span> <span>Topics you will learn to include</span></span> how to add fault tolerance and health checks to your services, how to check your service's metrics, how to trace and document them, and how to create lean REST clients for your endpoints. Other features, such as configuration, security, and Reactive Messaging, will be covered in upcoming chapters.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>An overview of the MicroProfile API and how it can complement the Enterprise API</li>
<li>How the MicroProfile API can fit into your Quarkus projects</li>
<li>Some exposure on how to run the MicroProfile API in the cloud</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>You can find the source code for the project in this chapter on GitHub at <a href="https://github.com/PacktPublishing/Hands-On-Cloud-Native-Applications-with-Java-and-Quarkus/tree/master/Chapter06">https://github.com/PacktPublishing/Hands-On-Cloud-Native-Applications-with-Java-and-Quarkus/tree/master/Chapter06</a><a href="https://github.com/PacktPublishing/Hands-On-Cloud-Native-Applications-with-Java-and-Quarkus/tree/master/Chapter06">.</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting started with the MicroProfile API</h1>
                </header>
            
            <article>
                
<p class="mce-root">The Java Enterprise API is a great set of technologies for building applications, but it has historically lacked some features that are needed if you want to move your application to the cloud. For instance, there is no specific API to handle configuration properties that can be injected into your services, nor is there a formal way to describe how clients can interact with REST endpoints. Also, it would definitely help to include some features so that we can monitor an application's health or load-balance requests; these are currently managed by vendors with custom technologies.</p>
<p class="mce-root">The Eclipse MicroProfile project is a collaboration initiative that's driven by top application vendors and aims to <span class="st">optimize the Enterprise API for Java applications, including all the features we have mentioned here.</span></p>
<p class="mce-root"><span class="st">A bird's-eye view of the Eclipse MicroProfile specification shows how rich this environment is in the 3.2 release:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/351b4899-58e2-40a9-aef0-aa01b8b7acb7.png" style=""/></div>
<p>In this chapter, we will delve into the following areas of the MicroProfile specification:</p>
<ul>
<li><strong>The Eclipse MicroProfile Configuration</strong>: Provides a unified way to configure your services by injecting the configuration data from a static file or from environment variables.</li>
<li><strong>The Eclipse MicroProfile Health Check</strong>: Provides the ability to probe the state of a service; for example, whether it's running or not, whether it lacks disk space, or whether there is an issue with the database connection.</li>
<li class="mce-root"><strong>The Eclipse MicroProfile Fault Tolerance</strong>: A<span class="st">llows you to define a strategy in the event of your services failing, for example, configuring</span> timeouts, retry policies, fallback methods, and Circuit Breaker processing.</li>
<li class="mce-root"><strong>The Eclipse MicroProfile Metrics</strong>: Provides a standard way for MicroProfile services to export monitoring data to external agents. Metrics also provide a common Java API that exposes their telemetry data.</li>
<li><strong>The Eclipse MicroProfile OpenAPI</strong>: Provides a set of Java interfaces to document your services in a standard way.</li>
<li><strong>The Eclipse MicroProfile OpenTracing</strong>: Provides a set of instrumentation libraries for tracing components such as JAX-RS and CDI.</li>
<li><strong>The Eclipse MicroProfile Rest Client</strong>: This builds upon the JAX-RS API and provides a type safe, unified approach for invoking RESTful services over HTTP.</li>
</ul>
<p>Although not discussed in this chapter, Quarkus also supports MicroProfile <strong>JWT RBAC</strong>, which outlines a proposal for using <strong>OpenID Connect</strong> (<strong>OIDC</strong>)-based <strong>JSON Web Tokens</strong> (<strong>JWTs</strong>) for <strong>role-based access control</strong> (<strong>RBAC</strong>) in your service endpoints. In the next chapter, which is about security, we will cover this topic in more detail.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting started with MicroProfile projects</h1>
                </header>
            
            <article>
                
<p>To learn about the single MicroProfile API, you will need the following projects, which can be found under the <kbd>Chapter06</kbd> folder in this book's GitHub repository:</p>
<ul>
<li><kbd>fault-tolerance</kbd>: A project that shows us how to use the MicroProfile Fault Tolerance API</li>
<li><kbd>health</kbd>: A project that focuses on the MicroProfile Health Check API</li>
<li><kbd>openapi-swagger</kbd>: A project that implements OpenAPI interfaces</li>
<li><kbd>opentracing</kbd>: A project that implements the OpenTracing API</li>
<li><kbd>rest-client</kbd>: A project that focuses on the MicroProfile REST Client API</li>
</ul>
<p>Most of the preceding projects are derived from the <strong>customer service</strong> Hibernate application that we discussed in <a href="078ed3f6-b849-4240-a0d4-cf3bd58c00ab.xhtml">Chapter 5</a>, <em>Managing Data Persistence with Quarkus</em>. Therefore, a basic requirement is to have a PostgreSQL database up and running so that we can run our projects. We remind you that this can be done with just a one-line script:</p>
<pre><strong>docker run --ulimit memlock=-1:-1 -it --rm=true --memory-swappiness=0 --name quarkus_test -e POSTGRES_USER=quarkus -e POSTGRES_PASSWORD=quarkus -e POSTGRES_DB=quarkusdb -p 5432:5432 postgres:10.5</strong></pre>
<p class="mce-root">Next, we recommend importing the whole <kbd>Chapter06</kbd> folder into your IDE so that you can have the full set of projects at your fingertips as you continue with this chapter. That being said, we will start by discussing the MicroProfile Health Check API.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Eclipse MicroProfile Health Check</h1>
                </header>
            
            <article>
                
<p>In the cloud environment, it is essential to allow services to report, and eventually publish, the overall health status to a defined endpoint. This can be achieved through MicroProfile Health Check, which allows a service to report the overall status as <kbd>"UP"</kbd> if it is available and <kbd>"DOWN"</kbd> if it is unavailable. This information can be collected by a service orchestrator, which can then use the health reports to make decisions.</p>
<p>Let's put these concepts into practice with the <kbd>Chapter06/health</kbd> example. First off, in order to use the health extension, we have included the following dependency in the <kbd>pom.xml</kbd> file:</p>
<pre><span>&lt;dependency&gt;<br/></span><span>  &lt;groupId&gt;</span>io.quarkus<span>&lt;/groupId&gt;<br/></span><span>  &lt;artifactId&gt;</span>quarkus-smallrye-health<span>&lt;/artifactId&gt;<br/></span><span>&lt;/dependency&gt;</span></pre>
<p>Once the preceding library is available, we can add an implementation of the <kbd>org.eclipse.microprofile.health.HealthCheck</kbd> interface, which allows us to check the service status. The following is the <kbd>DBHealthCheck</kbd> class, which verifies the status of the PostgreSQL database connection:</p>
<pre><strong>@Health</strong><br/>@ApplicationScoped<br/><span>public class </span>DBHealthCheck <span>implements </span>HealthCheck {<br/><br/>    @ConfigProperty(name = <span>"db.host"</span>)<br/>    String host<span>;<br/></span><span><br/></span><span>    </span>@ConfigProperty(name = <span>"db.port"</span>)<br/>    Integer port<span>;<br/></span><span><br/></span><span>    </span>@Override<br/>    <span>public </span>HealthCheckResponse call() {<br/><br/>        HealthCheckResponseBuilder responseBuilder = <br/>        HealthCheckResponse.named(<span>"Database connection<br/>         health check"</span>)<span>;<br/></span><span><br/></span><span>        try </span>{<br/><span>            </span>serverListening(host<span>,</span>port)<span>;<br/></span><span>            </span>responseBuilder.up()<span>;<br/></span><span>        </span>} <span>catch </span>(Exception e) {<br/>            <span>// cannot access the database<br/></span><span>            </span>responseBuilder.down()<br/>                    .withData(<span>"error"</span><span>, </span>e.getMessage())<span>;<br/></span><span>        </span>}<br/>        <span>return </span>responseBuilder.build()<span>;<br/></span><span>    </span>}<br/><br/>    <span>private void </span>serverListening(String host<span>, int </span>port) <span>throws <br/>     </span>IOException<br/>    {<br/>        Socket s = <span>new </span>Socket(host<span>, </span>port)<span>;<br/></span><span>        </span>s.close()<span>;</span><span><br/></span><span>    </span>}<br/>}</pre>
<p>This class contains two core implementations of the MicroProfile specifications:</p>
<ol>
<li>First of all, we have the <kbd>@Health</kbd> annotation, which works in combination with the <kbd>@ApplicationScoped</kbd> CDI context to return the health status check each time a request to <kbd>http://localhost:9080/health</kbd> is received.</li>
<li>This class also uses the <strong>MicroProfile Configuration API</strong> to inject the PostgreSQL database host and port it into the bean. The following is an excerpt from the <kbd>application.properties</kbd> file:</li>
</ol>
<pre style="padding-left: 60px">db.host=${POSTGRESQL_SERVICE_HOST:localhost}<br/>db.port=${POSTGRESQL_SERVICE_PORT:5432}<br/>quarkus.datasource.url=jdbc:postgresql://${db.host}:${db.port}/postgres</pre>
<div class="packt_infobox">As you can see, if the <kbd>POSTGRESQL_SERVICE_HOST</kbd> and <kbd>POSTGRESQL_SERVICE_PORT</kbd> environment variables aren't set, the default values (<kbd>localhost</kbd> and <kbd>5432</kbd>) are used and stored in the <kbd>db.host</kbd> and <kbd>db.port</kbd> variables.</div>
<p>The target host and port are reached via a TCP socket and, on a successful attempt, a <kbd>responseBuilder.up()</kbd> will be returned. Otherwise, <kbd>responseBuilder.down()</kbd> will indicate a failure.</p>
<p>You can start the Quarkus project with the following command:</p>
<pre><strong>$ mvn compile quarkus:dev</strong></pre>
<p>Then, assuming that the database is up and running, let's try to access the <kbd>http://localhost:9080/health</kbd> endpoint:</p>
<pre>curl http://localhost:8080/health<br/>{<br/>    "status": "UP",<br/>    "checks": [<br/>        {<br/>            "name": "Database connection health check",<br/>            "status": "UP"<br/>        },<br/>        {<br/>            "name": "File system Readiness check",<br/>            "status": "UP"<br/>        }<br/>    ]<br/>}</pre>
<p>The response acknowledges the status of the database connection. Let's also verify the condition where the database is unavailable. A simple <em>Ctrl</em> + <em>C</em> from the PostgreSQL shell will send the appropriate signal to stop the process. You should see the following output on the console:</p>
<pre><strong>2019-07-27 09:47:25.564 UTC [54] LOG:  shutting down</strong><br/><strong>2019-07-27 09:47:25.601 UTC [1] LOG:  database system is shut down</strong></pre>
<p>Now, check the status of the database connection through the <kbd>/health</kbd> endpoint once more:</p>
<pre>{<br/>    "status": "DOWN",<br/>    "checks": [<br/>        {<br/>            "name": "Database connection health check",<br/>            "status": "DOWN",<br/>            "data": {<br/>                "error": "Connection refused (Connection refused)"<br/>            }<br/>        }<br/>    ]<br/>}</pre>
<p>As you can see from the preceding output, the JSON that was returned changed the status to <kbd>"DOWN"</kbd> and set the error message in the error field. This example sets our first milestone: checking the application's health. We can further refine our health check policies by using liveness and readiness checks, which we will discuss in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using liveness and readiness checks</h1>
                </header>
            
            <article>
                
<p>According to the newest MicroProfile specifications, health checks are now to be used with a more specific model to help us determine the cause of potential issues. Therefore, it's recommended you migrate the legacy <kbd>@HealthCheck</kbd> to one of the following checks:</p>
<ul>
<li><strong>Readiness checks</strong>: This check can indicate that a service is <em>temporarily</em> unable to serve traffic. This can be due to, for example, the fact that an application may be loading some configuration or data. In such cases, you don't want to shut down the application but, at the same time, you don't want to send it requests either. Readiness checks are supposed to cover this scenario.</li>
<li><strong>Liveness checks</strong>: Services running 24/7 can sometimes undergo a transition to broken states, for example, because they have hit <kbd>OutOfMemoryError</kbd>. Therefore, they cannot recover except by being restarted. You can, however, be notified of this scenario by defining a liveness check that probes the liveness of the service.</li>
</ul>
<p>In order to implement both checks, you can simply replace the <kbd>@org.eclipse.microprofile.health.HealthCheck</kbd> annotation with more specific ones, such as <kbd>@org.eclipse.microprofile.health.Liveness</kbd> and <kbd>@org.eclipse.microprofile.health.Readiness</kbd>.</p>
<p>In the following example, we have implemented a <kbd>@Readiness</kbd> check to verify whether a lock file exists (for example, due to a pending task) and emit a <kbd>"DOWN"</kbd> status when this file is detected:</p>
<pre><strong>@Readiness</strong><br/>@ApplicationScoped<br/>public class ReadinessHealthCheck implements HealthCheck {<br/> <br/>     @Override<br/>     public HealthCheckResponse call() {<br/>         HealthCheckResponseBuilder responseBuilder = <br/>          HealthCheckResponse.named("File system Readiness check");<br/> <br/>         boolean tempFileExists = <br/>          Files.exists(Paths.get("/tmp/tmp.lck"));<br/>         if (!tempFileExists) {<br/>             responseBuilder.up();<br/>         }<br/>         else {<br/>             responseBuilder.down().withData("error", "Lock file <br/>              detected!");<br/>         }<br/>         return responseBuilder.build(); <br/>     }<br/>}</pre>
<p>Readiness checks are verified through the <kbd>"/health/ready"</kbd> URI. You can check this by requesting the following URL: <kbd>http://localhost:8080/health/ready</kbd>:</p>
<pre><strong>$ curl http://localhost:8080/health/ready</strong></pre>
<p>If no file has been detected, you will see something similar to the following output:</p>
<pre><strong>{</strong><br/><strong>     "status": "UP",</strong><br/><strong>     "checks": [</strong><br/><strong>         {</strong><br/><strong>             "name": "File system Readiness check",</strong><br/><strong>             "status": "UP"</strong><br/><strong>         }</strong><br/><strong>     ]</strong><br/><strong> }</strong></pre>
<p>Now, let's learn how to add a <strong>liveness check</strong> to our services. We will check the amount of free memory that's needed to run the service and return a liveness check based on a certain memory threshold, which we have set to one gigabyte:</p>
<pre><strong>@Liveness</strong><br/>@ApplicationScoped<br/><span>public class </span>MemoryHealthCheck <span>implements </span>HealthCheck {<br/>    <span>long </span>threshold = <span>1024000000</span><span>;<br/></span><span>    </span>@Override<br/>    <span>public </span>HealthCheckResponse call() {<br/>        HealthCheckResponseBuilder responseBuilder =<br/>          HealthCheckResponse.named(<span>"MemoryHealthCheck <br/>        Liveness check"</span>)<span>;<br/></span><span>        long </span>freeMemory = Runtime.getRuntime().freeMemory()<span>;<br/></span><span><br/></span><span>        if </span>(freeMemory &gt;= threshold) {<br/>            responseBuilder.up()<span>;<br/></span><span>        </span>}<br/>        <span>else </span>{<br/>            responseBuilder.down()<br/>                    .withData(<span>"error"</span><span>, </span><span>"Not enough free memory!<br/>                     Please restart application"</span>)<span>;<br/></span><span>        </span>}<br/>        <span>return </span>responseBuilder.build()<span>;<br/></span><span>    </span>}<br/><br/>}</pre>
<p>You can now verify the service's liveness with cURL, as follows:</p>
<pre><strong>curl http://localhost:8080/health/live</strong></pre>
<p>Since the default Quarkus JVM settings don't permit the amount of memory we have set in the threshold, the status of the service will indicate <kbd>"DOWN"</kbd>, as follows:</p>
<pre>{<br/>     "status": "DOWN",<br/>     "checks": [<br/>         {<br/>             "name": "MemoryHealthCheck Liveness check",<br/>             "status": "DOWN",<br/>             "data": {<br/>                 "error": "Not enough free memory! Please restart <br/>                  application"<br/>             }<br/>         }<br/>     ]<br/> }</pre>
<p>Before we move on to the next API in our checklist, it is worth checking how health checks can be triggered in a cloud environment using Kubernetes probe checks. We'll learn how to do this in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Letting OpenShift manage unhealthy services</h1>
                </header>
            
            <article>
                
<p>In the examples so far, we have seen how to detect different health checks scenarios. One of the greatest advantages of running a Kubernetes native environment is that you can react automatically to changes in an application's status. More specifically, it is possible to probe the following checks through the application's deployment descriptors:</p>
<ul>
<li><strong>Liveness probe</strong>: Kubernetes provides a liveness probe to determine whether the container that it's been configured in is still running. Should the liveness probe fail, the <kbd>kubelet</kbd> agent kills and restarts the container.</li>
<li><strong>Readiness probe</strong>: Kubernetes provides the readiness probe to signal that an application is temporarily unable to serve traffic, for example, because a configuration is being loaded. In such cases, you don't want to stop the application, but you don't want to allow any requests in either.</li>
</ul>
<p>As you can see, the preceding probes match the MicroProfile Health Checks that were defined in the latest specifications. As a proof of concept, we will be deploying <span>our example application </span>into MiniShift as a binary build. As usual, we will start by creating a new project from the shell (or the web console, if you prefer doing things this way):</p>
<pre><strong>oc new-project quarkus-microprofile</strong></pre>
<p>As you may remember, we need to add a PostgreSQL application to our project that will be found by our checks:</p>
<pre><strong>oc new-app -e POSTGRESQL_USER=quarkus -e POSTGRESQL_PASSWORD=quarkus -e POSTGRESQL_DATABASE=quarkusdb postgresql</strong></pre>
<p>Then, you can finally push the Quarkus MicroProfile Health application we have just built onto the cloud. The following script will be used for this purpose:</p>
<pre> # Build native application<br/><strong> mvn package -Pnative -Dnative-image.docker-build=true -DskipTests=true</strong><br/> <br/> # Create a new Binary Build named "quarkus-microprofile"<br/> <strong>oc new-build --binary --name=quarkus-microprofile -l app=quarkus-microprofile</strong><br/> <br/> # Set the dockerfilePath attribute into the Build Configuration<br/><strong> oc patch bc/quarkus-microprofile -p '{"spec":{"strategy":{"dockerStrategy":{"dockerfilePath":"src/main/docker/Dockerfile.native"}}}}'</strong><br/> <br/> # Start the build, uploading content from the local folder:<br/> <strong>oc start-build quarkus-microprofile --from-dir=. --follow</strong><br/> <br/> # Create a new Application, using as Input the "quarkus-microprofile" Image Stream:<br/><strong> oc new-app --image-stream=quarkus-microprofile:latest</strong><br/> <br/> # Expose the Service through a Route:<br/><strong> oc expose svc/quarkus-microprofile</strong></pre>
<p>The preceding script should be nothing new for you, so let's move on to the OpenShift console, where we can check the status of our project:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/eef95c5f-57dd-4533-a4a0-80598369ae3d.png" style=""/></div>
<p class="mce-root">Now, check the <span class="packt_screen">Deployments</span> configuration of your project and select <span class="packt_screen">Edit Health Checks</span>:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/348a0741-0c6f-4edf-ae16-1e287bf36a25.png" style=""/></div>
<p>Within the <span class="packt_screen">Health Checks</span> UI, you can choose which health check you want to add:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/d4f8967f-2381-47f9-94b6-65276b858b5a.png"/></div>
<p>Let's start with the <span class="packt_screen">Readiness Probe</span>. By selecting it, you will be taken to the following UI:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/e2c33096-b028-4abc-a5d9-7919c20e2abf.png" style=""/></div>
<p>The key parameter to select is <span class="packt_screen">Path</span>, which should match our MicroProfile readiness URI (<kbd>health/ready</kbd>). Apart from that, you can also configure the following properties:</p>
<ul>
<li><kbd>initialDelaySeconds</kbd>: The number of seconds after the container has started before liveness or readiness probes are initiated.</li>
<li><kbd>timeoutSeconds</kbd>: The number of seconds after which the probe times out. Defaults to 1 second. The minimum value is <kbd>1</kbd>.</li>
</ul>
<p>Now, let's configure the <span class="packt_screen">Liveness Probe</span>:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c71efc35-bf5a-4a38-a28f-00737791e70b.png" style=""/></div>
<p class="mce-root">Except for <span class="packt_screen">Path</span>, which will be <kbd>health/live</kbd>, w<span>e can leave the other default values.</span> Save your changes as-is. Now, let's try to break a few things. For example, we will create a lock file in the Pod where the application is running. This will immediately trigger a failure in the readiness probe. Let's check a list of Pods from the shell with the following command:</p>
<pre class="mce-root"><strong>$ oc get pods</strong></pre>
<p>The output that's returned is as follows:</p>
<pre class="mce-root"><strong>NAME                           READY     STATUS      RESTARTS   AGE</strong><br/><strong>quarkus-microprofile-1-build   0/1       Completed   0          20m</strong><br/><strong>quarkus-microprofile-1-rxp4r   1/1       Running     0          20m</strong></pre>
<p>Okay, we will now run a remote shell against this running Pod:</p>
<pre class="mce-root"><strong>$ oc rsh quarkus-microprofile-1-rxp4r</strong></pre>
<p>We're in. Now, create a file named <kbd>/tmp/tmp.lck</kbd></p>
<pre class="mce-root"><strong>sh-4.4$ touch /tmp/tmp.lck</strong></pre>
<p>In a couple of seconds (depending on the initial delay setting), your Pod won't be available anymore. You can see this from the <span class="packt_screen">Overview</span> panel:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/a963448a-8234-4c0d-905a-a05137b354dc.png" style=""/></div>
<p class="mce-root">This change will also be reflected in system events, which can be captured through the <kbd>oc get events</kbd> command, as follows:</p>
<pre><strong>$ oc get events</strong><br/><strong>quarkus-microprofile-3-mzl6f.15b54cfc42ddb728    Pod                     spec.containers{quarkus-microprofile}    Warning   Unhealthy kubelet, localhost            </strong><br/><strong>Readiness probe failed: HTTP probe failed with statuscode: 503</strong></pre>
<p>Finally, it's worth mentioning that our application also includes a liveness check, which verifies that the amount of available memory is greater than a certain threshold. Whether you have hit the threshold or not, the liveness probe depends on the amount of memory allowed at startup for MiniShift. A digression into OpenShift's application memory sizing would take us beyond the scope of this book, but it's worth reading more about it by looking at the official docs: <a href="https://docs.okd.io/latest/dev_guide/application_memory_sizing.html">https://docs.openshift.com/container-platform/3.9/dev_guide/application_memory_sizing.html</a>.</p>
<p>Maintaining your application's status so that it's healthy is a key element to consider when designing your applications. On the other hand, enabling your services to react to failures or performance degradation is no less important. Don't worry, though <span>â€“</span> the next section will teach you how to handle failures using the MicroProfile Fault Tolerance API.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Eclipse MicroProfile Fault Tolerance API</h1>
                </header>
            
            <article>
                
<p>The <strong>Fault Tolerance</strong> specification is a fundamental API that can be used to handle the unavailability of your microservices by endorsing a set of policies that can improve the resiliency of your applications. The following fault tolerance policies are available:</p>
<ul>
<li class="mce-root"><strong>Timeout</strong>: Defines a timeout for the execution of a service call</li>
<li class="mce-root"><strong>Fallback</strong>: Provides a contingency solution when a failure occurs</li>
<li class="mce-root"><strong>Retry</strong>: Allows you to retry execution based on criteria</li>
<li class="mce-root"><strong>Bulkhead</strong>: Isolates partial service failures while the rest of the system can still work</li>
<li class="mce-root"><strong>Circuit Breaker</strong>: Defines criteria for automatic fast-fails to prevent system degradation caused by overloading</li>
<li class="mce-root"><strong>Asynchronous</strong>: Allows us to invoke an operation asynchronously</li>
</ul>
<p>Let's look at these concepts in practice by using the <kbd>Chapter06/fault-tolerance</kbd> example. First off, in order to use the fault-tolerance extension, we have included the following dependency in the <kbd>pom.xml</kbd> file:</p>
<pre><span>&lt;dependency&gt;<br/></span><span>  &lt;groupId&gt;</span>io.quarkus<span>&lt;/groupId&gt;<br/></span><span>  &lt;artifactId&gt;</span>io.quarkus:quarkus-smallrye-fault-tolerance<span>&lt;/artifactId&gt;<br/></span><span>&lt;/dependency&gt;</span></pre>
<p>Let's start with the Timeout, Fallback, and Retry policies, which are commonly used together since they complement each other.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using Timeout, Fallback, and Retry to create resilient services</h1>
                </header>
            
            <article>
                
<p>In simple terms, the <kbd>@org.eclipse.microprofile.faulttolerance.Timeout</kbd> annotation can be used to specify the maximum time (in ms) allowed for returning a response in a method. Here is an example <kbd>findAll</kbd> method that times out after 250 ms:</p>
<pre><strong>@Timeout(<span>250</span>)</strong><br/><span>public </span>List&lt;Customer&gt; findAll() {<br/><br/>    randomSleep()<span>;</span><span><br/></span><span>    return </span>entityManager.createNamedQuery(<span>"Customers.findAll"</span><span>, </span>Customer.<span>class</span>)<br/>            .getResultList()<span>;</span><span><br/></span>}<br/><br/><span>private void </span>randomSleep() {<br/>    <span>try </span>{<br/>        Thread.sleep(<span>new </span>Random().nextInt(<span>400</span>))<span>;<br/></span><span>    </span>} <span>catch </span>(java.lang.InterruptedException e) {<br/>        e.printStackTrace()<span>;<br/></span><span>    </span>}<br/><br/>}</pre>
<p>The random sleep that's triggered by the finder method can be used to allow some occasional execution failures.</p>
<p>In order to mitigate time-outs or other failures, you can decorate your methods with the <kbd>@Fallback</kbd> policy so that you can specify an alternate execution path in the case of failure:</p>
<pre>@Timeout(<span>250</span>)<br/><strong>@Fallback(fallbackMethod = <span>"findAllStatic"</span>)</strong><br/><span>public </span>List&lt;Customer&gt; findAll() {<br/><br/>    randomSleep()<span>;</span><span><br/></span><span>    return </span>entityManager.createNamedQuery(<span>"Customers.findAll"</span><span>, <br/>    </span>Customer.<span>class</span>)<br/>            .getResultList()<span>;<br/></span><span><br/></span>}<br/><span>private </span>List&lt;Customer&gt; findAllStatic() {<br/>    LOGGER.info(<span>"Building Static List of Customers"</span>)<span>;<br/></span><span>    </span>return buildStaticList()<span>;<br/></span><span><br/></span>}</pre>
<p>In this example, we are redirecting the execution to the <kbd>findAllStatic</kbd> method if any failure arises in the <kbd>findAll</kbd> method. The <kbd>findAllStatic</kbd> method will return a static list of <kbd>Customer</kbd> objects (please check the source code example for this chapter to see the implementation of this).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Applying a retry policy to your failures</h1>
                </header>
            
            <article>
                
<p>Sometimes, failures in the execution of your methods are caused by temporary issues such as network congestion. If we are confident that the issue can be resolved in accordance with our business SLA, we can include a <kbd>@Retry</kbd> annotation to allow us to reiterate the execution of failed methods a certain number of times.</p>
<p>For example, by adding the <kbd>@Retry(maxRetries = 3)</kbd> annotation, we will attempt to load data from the database three more times before using a static list of customers:</p>
<pre>@Timeout(<span>250</span>)<br/>@Fallback(fallbackMethod = <span>"findAllStatic"</span>)<br/><strong>@Retry(maxRetries = <span>3</span>)</strong><br/><span>public </span>List&lt;Customer&gt; findAll() {<br/><br/>    randomSleep()<span>;</span><span><br/></span><span>    return </span>entityManager.createNamedQuery(<span>"Customers.findAll"</span><span>, <br/>     </span>Customer.<span>class</span>)<br/>            .getResultList()<span>;<br/></span><span><br/></span>}</pre>
<p>It is worth mentioning that the <kbd>@Retry</kbd> annotation can be configured to retry only a subset of specific exceptions. This can be seen in the following example, where we're using <kbd>@Retry</kbd> over <kbd>RuntimeException</kbd> and <kbd>TimeoutException</kbd>:</p>
<pre class="prettyprint"><span class="lit">@</span><span class="highlight"><span class="lit">Retry</span></span><span class="pun">(</span><span class="pln">retryOn </span><span class="pun">=</span><span class="pln"> </span><span class="pun">{</span><span class="typ">RuntimeException</span><span class="pun">.</span><span class="kwd">class</span><span class="pun">,</span><span class="pln"> </span><span class="typ">TimeoutException</span><span class="pun">.</span><span class="kwd">class</span><span class="pun">},</span><span class="pln"> maxRetries </span><span class="pun">=</span><span class="pln"> </span><span class="lit">3</span><span class="pun">)</span></pre>
<p>Now, let's learn how to apply a fault tolerance pattern named <strong>Circuit Breaker</strong> to our services.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Circuit Breaker</h1>
                </header>
            
            <article>
                
<p><strong>Circuit Breaker</strong> is a core pattern for creating resilient services. It can be used to prevent repeatable exceptions by instantly denying new requests. The MicroProfile Fault Tolerance API uses the <kbd>@CircuitBreaker</kbd> annotation to control incoming requests. A software Circuit Breaker is similar to an electrical circuit breaker since it has the following states:</p>
<ul>
<li><strong>Closed state</strong>: A closed-circuit represents a fully functional system that's available to its clients.</li>
<li><strong>Half-open circuit</strong>: When some failures are detected, the state can change to half-open. In this state, it checks whether the failed component is restored. If so, it closes the circuit. Otherwise, it moves to an open state.</li>
<li><strong>Open state</strong>: An open state means the service is temporarily disabled. After checks have been made, you can verify whether it's safe to switch to a half-open state.</li>
</ul>
<p>Here is an example:</p>
<pre><strong>@CircuitBreaker(successThreshold = <span>5</span><span>, </span>requestVolumeThreshold = <span>4</span><span>, </span>failureRatio=<span>0.75</span><span>,<br/></span><span>        </span>delay = <span>1000</span>)</strong><br/><span>public </span>List&lt;Orders&gt; findAll(Long customerId) {<br/><br/>    possibleFailure()<span>;<br/></span><span>    return  </span>(List&lt;Orders&gt;) <br/>    entityManager.createNamedQuery(<span>"Orders.findAll"</span>)<br/>            .setParameter(<span>"customerId"</span><span>, </span>customerId)<br/>            .getResultList()<span>;<br/></span>}<br/><span>private void </span>possibleFailure() {<br/>    <span>if </span>(<span>new </span>Random().nextFloat() &lt; <span>0.5f</span>) {<br/>    <span>throw new </span>RuntimeException(<span>"Resource failure."</span>)<span>;<br/></span>}</pre>
<p>In the preceding example, the <kbd>@CircuitBreaker</kbd> policy applies to the <kbd>findAll</kbd> method of the <kbd>OrderRepository</kbd> class. Because of that, if, within the last four invocations, 75% failed, then the circuit transits to an open state. The circuit will stay open for 1,000 ms. When a circuit is open, a <kbd>CircuitBreakerOpenException</kbd> will be thrown instead of actually invoking the method.</p>
<p>Please note that, like the retry method, the <kbd>@CircuitBreaker</kbd> also allows us to define failure criteria through the <kbd>failon</kbd> annotation parameter. This can be seen in the following example:</p>
<pre>@CircuitBreaker(failOn=<span class="pun">{</span><span class="typ">RuntimeException</span><span class="pun">.</span><span class="kwd">class</span><span class="pun">}</span>, successThreshold = <span>5</span><span>, </span>requestVolumeThreshold = <span>4</span><span>, </span>failureRatio=<span>0.75</span><span>,</span><span> </span>delay = <span>1000</span>)</pre>
<p>In the preceding example, if a <kbd>RuntimeException</kbd> is thrown in the method, then the execution is counted by the <kbd>CircuitBreaker</kbd> as a failure; otherwise, it is counted as a success.</p>
<p>Now that we know about the background of the core Fault Tolerance API, let's learn how to further enhance our application's robustness with bulkhead and asynchronous patterns.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using asynchronous and bulkhead policies</h1>
                </header>
            
            <article>
                
<p><span class="st">Asynchronous programming is not a new pattern for Enterprise developers. However, when used in combination with the <kbd>BulkHead</kbd> policy, you can achieve a powerful fault tolerance pattern for your microservices. In a nutshell, if you annotate a method with <kbd>@Asynchronous</kbd>, it will be executed asynchronously on a separate thread.</span></p>
<p>In the following example, we are performing some logic in the <kbd>createOrder</kbd> method, which spins off some debugging in a separate thread by means of the <kbd>writeSomeLogging</kbd> method, which returns a <kbd>CompletableFuture</kbd> instance:</p>
<pre><span>public void </span>createOrder(Orders order<span>, </span>Customer c) {<br/>    order.setCustomer(c)<span>;<br/></span><span>    </span>entityManager.persist(order)<span>;<br/></span><span>    </span>writeSomeLogging(order.getItem())<span>;<br/></span><span><br/></span>}<br/>@Asynchronous<br/><span>private </span>Future writeSomeLogging(String item) {<br/>        LOGGER.info(<span>"New Customer order at: "</span>+<span>new </span>java.util.Date())<span>;<br/></span><span>        </span>LOGGER.info(<span>"Item: {}"</span><span>, </span>item)<span>;<br/></span><span>        return </span>CompletableFuture.completedFuture(<span>"ok"</span>)<span>;<br/></span>}</pre>
<p>When <kbd>@Bulkhead</kbd> is used with <kbd>@Asynchronous</kbd>, the thread pool isolation approach will be used. The thread pool approach allows us to configure the maximum concurrent requests together with a certain queue size, just like a semaphore. Here is the updated example, which includes the <kbd>@Bulkhead</kbd> policy:</p>
<pre>// maximum 5 concurrent requests allowed, maximum 10 requests allowed in the waiting queue<br/>@Asynchronous<br/>@Bulkhead(value = <span>5</span><span>, </span>waitingTaskQueue = <span>10</span>)<br/><span>private </span>Future writeSomeLogging(String item) {<br/>        LOGGER.info(<span>"New Customer order at: "</span>+<span>new </span>java.util.Date())<span>;<br/></span><span>        </span>LOGGER.info(<span>"Item: {}"</span><span>, </span>item)<span>;<br/></span><span>        return </span>CompletableFuture.completedFuture(<span>"ok"</span>)<span>;<br/></span>}</pre>
<p>That was a whirlwind tour of the fault tolerance policies that are available in the MicroProfile API. Let's move on to the next section, which is about capturing service metrics.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Eclipse MicroProfile Metrics API</h1>
                </header>
            
            <article>
                
<p>The MicroProfile Metrics specification provides us with a unified way of exporting your services' monitored data to management agents. This helps us perform proactive checks on some key statistics indicators, such as the number of times and the rate at which a service has been requested, the duration of each request, and so on.</p>
<p>Let's get coding. Here, we will focus on the <kbd>Chapter06/metrics</kbd> example. First off, in order to use the metrics extension, we have included the following dependency in the <kbd>pom.xml</kbd> file:</p>
<pre><span>&lt;dependency&gt;<br/></span><span>  &lt;groupId&gt;</span>io.quarkus<span>&lt;/groupId&gt;<br/></span><span>  &lt;artifactId&gt;</span><span>io.quarkus:quarkus-smallrye-metrics&lt;/artifactId&gt;<br/></span><span>&lt;/dependency&gt;</span></pre>
<p>Now, we'll provide an overview of the metrics annotations that have been added on top of our REST service. Let's start with the <kbd>@Counted</kbd> annotation, which tracks how many times a request has been made:</p>
<pre><span>@GET<br/></span><strong><span>@Counted</span>(<span>description </span>= <span>"Customer list count"</span><span>, </span><span>absolute </span>= <span>true</span>)</strong><br/><span>public </span>List&lt;Customer&gt; <span>getAll</span>() {<br/>    <span>return </span><span>customerRepository</span>.findAll()<span>;<br/></span>}</pre>
<p>Within the <kbd>@Counted</kbd> annotation, we have provided a description and set the <kbd>absolute</kbd> flag to <kbd>true</kbd>, which means the class's package name will not be prepended to the metric name.</p>
<p>Let's compile and run the application:</p>
<pre><strong>$ mvn compile quarkus:dev</strong></pre>
<p>Now, let's reload the home page, which will trigger a list of customers. Next, we'll gather some metrics. There are two entry points for our metrics:</p>
<ul>
<li><kbd>http://localhost:8080/metrics</kbd>: This endpoint will return all the metrics, including system metrics where the application is running.</li>
<li><kbd>http://localhost:8080/metrics/application</kbd>: This endpoint will just return metrics that are emitted by the applications that have been deployed.</li>
</ul>
<p>We will choose the latter option here, as follows:</p>
<pre><strong>$ curl http:/localhost:8080/metrics/applications</strong></pre>
<p>Since we have loaded the home page twice, the expected output should be as follows:</p>
<pre> # HELP application:get_all Customer list count<br/> # TYPE application:get_all counter<br/> application:get_all 2.0</pre>
<p>The next annotation is the <kbd>@Timed</kbd> annotation, which keeps track of the duration of an event. Let's apply it to the <kbd>getAll</kbd> method as well:</p>
<pre><strong><span>@Timed</span>(<span>name </span>= <span>"timerCheck"</span><span>, </span><span>description </span>= <span>"How much time it takes to load the Customer list"</span><span>, </span><span>unit </span>= MetricUnits.<span>MILLISECONDS</span>)</strong><br/><span>public </span>List&lt;Customer&gt; <span>getAll</span>() {<br/>    <span>return </span><span>customerRepository</span>.findAll()<span>;<br/></span>}</pre>
<p>You should be able to retrieve a detailed report about the invocation rates of the preceding method (which includes rate/sec, rate/min rate/5 min, plus statistics quantile metrics). For the sake of brevity, here is an excerpt from it:</p>
<pre># TYPE application:com_packt_quarkus_chapter6_customer_endpoint_timer_check_rate_per_second 
application:com_packt_quarkus_chapter6_customer_endpoint_timer_check_rate_per_second 0.04980015712212517
# TYPE application:com_packt_quarkus_chapter6_customer_endpoint_timer_check_one_min_rate_per_second 
application:com_packt_quarkus_chapter6_customer_endpoint_timer_check_one_min_rate_per_second 0.09447331054820299
# TYPE application:com_packt_quarkus_chapter6_customer_endpoint_timer_check_five_min_rate_per_second 
application:com_packt_quarkus_chapter6_customer_endpoint_timer_check_five_min_rate_per_second 0.17214159528501158

. . . .
application:com_packt_quarkus_chapter6_customer_endpoint_timer_check_seconds{quantile="0.999"} 0.004191615</pre>
<p>On the other hand, if you need just a basic metric that records a single unit of data, you can use the <kbd>@Gauge</kbd> annotation:</p>
<pre><strong><span>@Gauge</span>(<span>name </span>= <span>"peakOfOrders"</span><span>, </span><span>unit </span>= MetricUnits.<span>NONE</span><span>, </span><span>description </span>= <span>"Highest number of orders"</span>)</strong><br/><span>public </span>Number <span>highestNumberOfOrders</span>() {<br/>    <span>return </span><span>orderRepository</span>.countAll()<span>;<br/></span>}</pre>
<p>The Gauge metric will display the following metric after two requests have landed on the preceding method:</p>
<pre># HELP application:com_packt_quarkus_chapter6_order_endpoint_peak_of_orders Highest number of orders
# TYPE application:com_packt_quarkus_chapter6_order_endpoint_peak_of_orders gauge
application:com_packt_quarkus_chapter6_order_endpoint_peak_of_orders 2.0</pre>
<p>After this fast-paced introduction to MicroProfile metrics, let's learn how to document our endpoint resources with OpenAPI and Swagger.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Configuring OpenAPI and the Swagger UI</h1>
                </header>
            
            <article>
                
<p>The OpenAPI specification aims to provide a set of Java interfaces and programming models that can natively produce OpenAPI v3 documents from JAX-RS services. The default OpenAPI implementation in Quarkus provides an out-of-the-box standard documentation for all the exposed services that can be generated through the <kbd>/openapi</kbd> endpoint.</p>
<p>Nevertheless, you can augment JAX-RS services even further using specific annotations to provide more insights about the endpoint, its parameters, and the response. Moving on to the code, we will focus on the <kbd>Chapter06/openapi-swagger</kbd> example. As you can check from its configuration, we have added the following extension to the project:</p>
<pre>&lt;dependency&gt;<br/>   &lt;groupId&gt;io.quarkus&lt;/groupId&gt;<br/>   &lt;artifactId&gt;quarkus-smallrye-openapi&lt;/artifactId&gt;<br/> &lt;/dependency&gt;</pre>
<p>Since we have several REST endpoints available in our project, we can check the generated OpenAPI document at <kbd>http://localhost:8080/openapi</kbd>. Here is the (truncated) output for our customer service application:</p>
<pre><strong>$ curl http://localhost:8080/openapi</strong><br/><strong> ---</strong><br/><strong> openapi: 3.0.1</strong><br/><strong> info:</strong><br/><strong>   title: Generated API</strong><br/><strong>   version: "1.0"</strong><br/><strong> paths:</strong><br/><strong>   /customers:</strong><br/><strong>     get:</strong><br/><strong>       responses:</strong><br/><strong>         200:</strong><br/><strong>           description: OK</strong><br/><strong>           content:</strong><br/><strong>             application/json:</strong><br/><strong>               schema:</strong><br/><strong>                 type: array</strong><br/><strong>                 items:</strong><br/><strong>                   type: object</strong><br/><strong>                   properties:</strong><br/><strong>                     id:</strong><br/><strong>                       format: int64</strong><br/><strong>                       type: integer</strong><br/><strong>                     name:</strong><br/><strong>                       type: string</strong><br/><strong>                     orders:</strong><br/><strong>                       type: array</strong><br/><strong>                       items:</strong><br/><strong>                         type: object</strong><br/><strong>                         properties:</strong><br/><strong>                           id:</strong><br/><strong>                             format: int64</strong><br/><strong>                             type: integer</strong><br/><strong>                           item:</strong><br/><strong>                             type: string</strong><br/><strong>                           price:</strong><br/><strong>                             format: int64</strong><br/><strong>                             type: integer</strong><br/><strong>                     surname:</strong><br/><strong>                       type: string</strong></pre>
<p>As you can see, with minimal effort we have produced a JSON document that describes the functionalities of our service without requiring direct access to the underlying source code or any other documentation.</p>
<p>Apart from this, the OpenAPI can be used as a foundation for powerful UIs such as <strong>Swagger</strong>, which is a great tool for visualizing and interacting with your APIs. Its UI is automatically generated from your OpenAPI specification.</p>
<p>In order to get rolling with Swagger, you just need to point to <kbd>http://localhost:8080/swagger-ui/</kbd>. By doing this, you will end up on the Swagger home page:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/1942eb14-4dad-43ba-8e5a-314f26f77855.png" style=""/></div>
<p>From there, you can easily test any available operation by expanding it and clicking on the <span class="packt_screen">Try it out</span> button:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/06531d2f-64d8-4344-b902-700c831b7335.png" style=""/></div>
<p>A default Response body will be generated. Adjust it to your needs and click on <span class="packt_screen">Execute</span>. As a result, you will see the returned value (if any) from our operation in the <span class="packt_screen">Response body</span> text area:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c3f519f9-8d83-4db2-baf9-aa6ecf4ca03b.png" style=""/></div>
<p>Optionally, you can click on the <span class="packt_screen">Download</span> button to save the response locally.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Customizing the output of OpenAPI</h1>
                </header>
            
            <article>
                
<p>According to the OpenAPI specification (<a href="https://swagger.io/specification/">https://swagger.io/specification/</a>), it is possible to customize the full schema of objects that are returned by the <kbd>/openapi</kbd> Servlet. This can be done by adding specific annotations to your endpoints classes and methods. Although none of these annotations are mandatory, we will mention some common ones that can improve the readability of your OpenAPI schema.</p>
<p>For example, the <kbd>@org.eclipse.microprofile.openapi.annotations.tags.Tag</kbd> annotation can be used as a qualifier to describe a group of specific operations related to the endpoint. This annotation can be applied at the class level. In order to describe a single resource method, you can use the <kbd>org.eclipse.microprofile.openapi.annotations.Operation</kbd> tag, which can be applied at the method level. Then, a description of the operation parameters can be included with the <kbd>org.eclipse.microprofile.openapi.annotations.parameters.Parameter</kbd> tag. Finally, the <kbd>org.eclipse.microprofile.openapi.annotations.responses.APIResponse</kbd> tag describes a single response from an API operation. You can attach multiple <kbd>APIResponse</kbd> annotations to a single method to control the response for each response code.</p>
<p>The following example shows the customization being applied to the <kbd>CustomerEndpoint</kbd> class in practice:</p>
<pre><strong>@Tag(name = <span>"OpenAPI Example"</span><span>, </span>description = <span>"Quarkus CRUD Example"</span>)</strong><br/><span>public class </span>CustomerEndpoint {<br/><br/>    <span>@Inject </span>CustomerRepository <span>customerRepository</span><span>;<br/></span><span><br/></span><strong><span>   </span></strong><strong><span> </span>@Operation(operationId = <span>"all"</span><span>, </span>description = <span>"Getting All <br/>     customers"</span>)</strong><br/><strong>    @APIResponse(responseCode = <span>"200"</span><span>, </span>description = <span>"Successful <br/>     response."</span>)</strong><br/>    <span>@GET<br/></span><span>    </span><span>public </span>List&lt;Customer&gt; <span>getAll</span>() {<br/>        <span>return </span><span>customerRepository</span>.findAll()<span>;<br/></span><span>    </span>}<br/><br/>    <span>@POST<br/></span><span>    </span><strong><span>public </span>Response <span>create</span>( @Parameter(description = <span>"The new <br/>     customer."</span><span>, </span>required = <span>true</span>) Customer customer)</strong> {<br/><br/>        <span>customerRepository</span>.createCustomer(customer)<span>;<br/></span><span>        return </span>Response.<span>status</span>(<span>201</span>).build()<span>;</span><span><br/></span><span>    </span>}<br/><br/>    <span>@PUT<br/></span><span>    </span><strong><span>public </span>Response <span>update</span>(@Parameter(description = <span>"The customer to <br/>     update."</span><span>, </span>required = <span>true</span>)</strong> <strong>Customer customer)</strong> {<br/>        <span>customerRepository</span>.updateCustomer(customer)<span>;<br/></span><span>        return </span>Response.<span>status</span>(<span>204</span>).build()<span>;<br/></span><span>    </span>}<br/>    <span>@DELETE<br/></span><span>    </span><strong><span>public </span>Response <span>delete</span>(@Parameter(description = <span>"The customer to <br/>     delete."</span><span>, </span>required = <span>true</span>) <span>@QueryParam</span>(<span>"id"</span>) Long customerId)</strong> {<br/>        <span>customerRepository</span>.deleteCustomer(customerId)<span>;<br/></span><span>        return </span>Response.<span>status</span>(<span>204</span>).build()<span>;<br/></span><span>    </span>}<br/><br/>}</pre>
<p>For the sake of brevity, we have just tagged the <kbd>CustomerEndpoint</kbd> service with OpenAPI annotations. We leave it to you to update the <kbd>OrderEndpoint</kbd> service so that you can verify your new skills.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Eclipse MicroProfile OpenTracing API</h1>
                </header>
            
            <article>
                
<p>Distributed tracing plays a key role in the era of microservices as it lets you trace the flow of a request across different services. In order to accomplish microservice tracing, we can instrument our services to log messages to a distributed tracing server that can collect, store, and display this information in various formats.</p>
<p>The <kbd>OpenTracing</kbd> specification does not address which distributed system is in charge of collecting the tracing data, but a widely adopted end-to-end open source solution is <strong>Jaeger</strong> (<a href="https://www.jaegertracing.io/">https://www.jaegertracing.io/</a>),which fully implements the <kbd>OpenTracing</kbd> standard.</p>
<p>Let's see OpenTracing in action by switching to the <kbd>Chapter06/opentracing</kbd> example. First off, in order to use the opentracing extension, the following dependency must be added to your project:</p>
<pre><span>&lt;dependency&gt;<br/></span><span>  &lt;groupId&gt;</span>io.quarkus<span>&lt;/groupId&gt;<br/></span><span>  &lt;artifactId&gt;</span>io.quarkus:quarkus-smallrye-opentracing<span>&lt;/artifactId&gt;<br/></span><span>&lt;/dependency&gt;</span></pre>
<div class="packt_infobox">As a matter of fact, when adding this extension, an implementation of an <kbd>io.opentracing.Tracer</kbd> object will be made available to your application. This means that all your HTTP requests will be automatically traced.</div>
<p>In terms of configuration, we need to provide some details about the Jaeger endpoint. This can be done either with the <kbd>application.properties</kbd> file or using environment variables. The following shows how we have configured the <kbd>application.properties</kbd> file to emit a tracing notification to a Jaeger endpoint running on localhost and listening to port <kbd>14268</kbd>:</p>
<pre>quarkus.jaeger.service-name=quarkus-service<br/>quarkus.jaeger.sampler-type=const<br/>quarkus.jaeger.sampler-param=1<br/>quarkus.jaeger.endpoint=http://localhost:14268/api/traces</pre>
<p>Within the preceding configuration, we have also defined the service name (<kbd>quarkus-service</kbd>) and the sampler type. In the sampler type definition, <kbd>"</kbd> always makes the same decision for all traces. It either samples all the traces (<kbd>sampler-param=1</kbd>) or none of them (<kbd>sampler-param=2</kbd>).</p>
<p>Now, we can start the Jaeger service. The simplest way to do this is by running it as a Docker container. The following command will start the <kbd>jaegertracing/all-in-one</kbd> container image, forwarding the UDP/TCP port of the Docker container to localhost: </p>
<pre><strong>docker run -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 -p 5775:5775/udp -p 6831:6831/udp -p 6832:6832/udp -p 5778:5778 -p 16686:16686 -p 14268:14268 -p 9411:9411 jaegertracing/all-in-one:latest</strong></pre>
<p>Now, we can start using our customer service application and execute some operations with it. Then, we can log into the Jaeger console, which is available at <kbd>http://localhost:16686</kbd>:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/72bfbd3e-f95b-437c-b209-19486cc6bb9e.png" style=""/></div>
<p>As shown in the preceding screenshot, in the left panel of the Jaeger UI you can see a combo box named <span class="packt_screen">Service</span>, which contains a list of the services that are available for tracing. You should see in it the default <span class="packt_screen">jaeger query service</span><span class="st">, which allows us to trace the query service. Provided that you have configured your Quarkus application to emit notifications, you should be able to see <span class="packt_screen">quarkus-service</span> enlisted. Select it and then check the next combo box, which is <span class="packt_screen">Operation</span>. This combo box contains all the operations that have been traced for that particular service. Here is a partial view of the UI that contains the combo box:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/48b7e635-2b1b-4f4c-b45e-26d633a4da4d.png" style=""/></div>
<p class="CDPAlignLeft CDPAlign">If you select <span class="packt_screen">all</span>, on the screen you should be able to see all the traces for all the HTTP requests to <kbd>quarkus-service</kbd>, as shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/987aa7b9-6cae-46fd-b2ee-c646f35ef20f.png" style=""/></div>
<p>From there, you can choose to gather more details about a single trace by clicking on it. You will see a comprehensive timeline with details such as the execution time, remote caller, and errors reported:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/283fb5ff-3c3d-4ffd-a78c-8507dc2dd1c1.png" style=""/></div>
<p>If you want to download and elaborate on the trace file, you can also choose to trace your operation as JSON by selecting <span class="packt_screen">Trace JSON</span> in the top-right corner.</p>
<p>There are quite a lot of possibilities for tracing your application with Jaeger. We advise referring to <a href="https://www.jaegertracing.io/">https://www.jaegertracing.io/</a> if you want to become a ninja at tracing your microservices!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Eclipse MicroProfile REST Client API</h1>
                </header>
            
            <article>
                
<p>The last MicroProfile extension we will discuss in this chapter is the REST client extension. The goal of this API is to provide you with a type safe way to invoke REST services in a microservice architecture.</p>
<div class="packt_infobox">Don't confuse the MicroProfile REST client API with the JAX-RS Client API! They implement different standards: the JAX-RS Client API is implemented according to JSR 370 ( <a href="https://www.jcp.org/en/jsr/detail?id=370">https://www.jcp.org/en/jsr/detail?id=370</a>), while the MicroProfile REST Client API follows the standard specified here: <a href="http://microprofile.io/project/eclipse/microprofile-rest-client">http://microprofile.io/project/eclipse/microprofile-rest-client</a>.</div>
<p>In order to learn about the REST client API, we will be using it as a template for the <kbd>Chapter06/rest-client</kbd> application. This project is nothing but a cut-down version of our customer service, which just contains interfaces instead of service implementations. In terms of configuration, we have added the following dependency to the <kbd>pom.xml</kbd> file of our <kbd>rest-client</kbd> project:</p>
<pre><span>&lt;dependency&gt;<br/></span><span>  &lt;groupId&gt;</span>io.quarkus<span>&lt;/groupId&gt;<br/></span><span>  &lt;artifactId&gt;</span>quarkus-rest-client<span>&lt;/artifactId&gt;<br/></span><span>&lt;/dependency&gt;</span></pre>
<p>Next, we have replaced the concrete service implementations with two interfaces: one named <kbd>CustomerEndpointItf</kbd> and another named <kbd>OrdersEndpointItf</kbd>. Here is <kbd>CustomerEndpointITf</kbd>:</p>
<pre><span>@RegisterRestClient<br/></span><span>@Path</span>(<span>"customers"</span>)<br/><span>@Produces</span>(<span>"application/json"</span>)<br/><span>@Consumes</span>(<span>"application/json"</span>)<br/><span>public interface </span>CustomerEndpointItf {<br/>    <span>@GET<br/></span><span>    </span>List&lt;Customer&gt; <span>getAll</span>()<span>;<br/></span><span><br/></span><span>    </span><span>@POST<br/></span><span>    </span>Response <span>create</span>(Customer customer)<span>;<br/></span><span><br/></span><span>    </span><span>@PUT<br/></span><span>    </span>Response <span>update</span>(Customer customer)<span>;<br/></span><span><br/></span><span>    </span><span>@DELETE<br/></span><span>    </span>Response <span>delete</span>(Long customerId)<span>;<br/></span>}</pre>
<p>Here is <kbd>OrdersEndpointItf</kbd>:</p>
<pre><span><strong>@RegisterRestClient</strong><br/></span><span>@Path</span>(<span>"orders"</span>)<br/><span>@Produces</span>(<span>"application/json"</span>)<br/><span>@Consumes</span>(<span>"application/json"</span>)<br/><span>public interface </span>OrderEndpointItf {<br/>    <span>@GET<br/></span><span>    </span>List&lt;Orders&gt; <span>getAll</span>(<span>@QueryParam</span>(<span>"customerId"</span>) Long customerId)<span>;<br/></span><span><br/></span><span>    </span><span>@POST<br/></span><span>    @Path</span>(<span>"/{customer}"</span>)<br/>    Response <span>create</span>(Orders order<span>, </span><span>@PathParam</span>(<span>"customer"</span>) Long <br/>     customerId)<span>;<br/></span><span><br/></span><span>    </span><span>@PUT<br/></span><span>    </span>Response <span>update</span>(Orders order)<span>;<br/></span><span><br/></span><span>    </span><span>@DELETE<br/></span><span>    @Path</span>(<span>"/{order}"</span>)<br/>    Response <span>delete</span>(<span>@PathParam</span>(<span>"order"</span>) Long orderId)<span>;<br/></span>}</pre>
<p>Note the <kbd>@org.eclipse.microprofile.rest.client.inject.RegisterRestClient</kbd> annotation, which makes the REST client injectable through the CDI using the <kbd>@org.eclipse.microprofile.rest.client.inject.RestClient</kbd> annotation. Let's learn how to do this in practice in the <kbd>CustomerEndpoint</kbd>:</p>
<pre><span>public class </span>CustomerEndpoint {<br/><br/><strong>    <span>@Inject<br/></span></strong><span><strong>    @RestClient</strong><br/></span><strong><span>    </span>CustomerEndpointItf <span>customer</span></strong><span><strong>;</strong><br/></span><span><br/></span><span>    </span><span>@GET<br/></span><span>    </span><span>public </span>List&lt;Customer&gt; <span>getAll</span>() {<br/>        <span>return </span><span>customer</span>.getAll()<span>;<br/></span><span>    </span>}<br/>    <span>@POST<br/></span><span>    </span><span>public </span>Response <span>create</span>(Customer c) {<br/>        <span>return </span><span>customer</span>.create(c)<span>;<br/></span><span>    </span>}<br/>    <span>@PUT<br/></span><span>    </span><span>public </span>Response <span>update</span>(Customer c) {<br/>        <span>return </span><span>customer</span>.update(c)<span>;<br/></span><span>    </span>}<br/>    <span>@DELETE<br/></span><span>    </span><span>public </span>Response <span>delete</span>(Long customerId) {<br/>        <span>return </span><span>customer</span>.delete(customerId)<span>;<br/></span><span>    </span>}<br/><br/>}</pre>
<p>As you can see, we have replaced the REST client implementation by delegating the execution to the interface we have registered as a REST client. At this point, you may be wondering how the REST client knows about the remote endpoint. That's a good question, and the answer is contained in the <kbd>application.properties</kbd> file:</p>
<pre><span>com.packt.quarkus.chapter6.restclient.CustomerEndpointItf/mp-rest/url</span><span>=</span><span>http://localhost:8080<br/></span><span>com.packt.quarkus.chapter6.restclient.CustomerEndpointItf/mp-rest/scope</span><span>=</span><span>java.inject.Singleton<br/></span><span>com.packt.quarkus.chapter6.restclient.OrderEndpointItf/mp-rest/url</span><span>=</span><span>http://localhost:8080<br/></span><span>com.packt.quarkus.chapter6.restclient.OrderEndpointItf/mp-rest/scope</span><span>=</span><span>java.inject.Singleton</span></pre>
<p>As you can see from the first line, all the requests to the REST client interface will result in a call to the remote endpoint base URL, which is qualified using the following expression:</p>
<pre>&lt;Fully Qualified REST Client Interface&gt;/mp-rest/url=&lt;Remote REST base URL&gt;</pre>
<p>Also, the default scope of the REST client interface has been configured as a <strong>singleton</strong>, which instructs Quarkus to instantiate the singleton once, passing its reference to other objects during the injection. Other supported scope values are <kbd>@Dependent</kbd>, <kbd>@ApplicationScoped</kbd>, and <kbd>@RequestScoped</kbd>, the latter being the default one. Check the CDI specifications for more details about the different scopes (<a href="http://www.cdi-spec.org/">http://www.cdi-spec.org/</a>).</p>
<p>In order to run the test, we need an application that returns a list of <kbd>Customers</kbd> through the <kbd>http://localhost:8080/customers</kbd> endpoint and a list of <kbd>Orders</kbd> through the <kbd>http://localhost:8080/orders</kbd> endpoint. For this purpose, we can launch any version of our customer service application that implements the preceding endpoints, as follows:</p>
<pre><strong>cd Chapter05/hibernate</strong><br/><br/><strong>$ mvn quarkus:dev</strong></pre>
<p>Let's go back to our example:</p>
<pre><strong>cd Chapter06/rest-client</strong></pre>
<p>Now, we can run the REST Client test with the following command:</p>
<pre><strong>$ mvn compile test</strong></pre>
<p>You should see the following output in the console:</p>
<pre><strong>[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.988 s - in com.packt.quarkus.chapter6.restclient.CustomerEndpointTest</strong><br/><strong> 2019-08-04 19:29:43,592 INFO  [io.quarkus] (main) Quarkus stopped in 0.003s</strong><br/><strong>[INFO] Results:</strong><br/><strong>[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0</strong></pre>
<p>This means that you managed to run full CRUD operations against the remote customer endpoint. As proof of this, you should be able to see the SQL statements that were executed on the service console:</p>
<pre>    select<br/>         orders0_.id as id1_1_0_,<br/>         orders0_.customer_id as customer4_1_0_,<br/>         orders0_.item as item2_1_0_,<br/>         orders0_.price as price3_1_0_,<br/>         customer1_.id as id1_0_1_,<br/>         customer1_.name as name2_0_1_,<br/>         customer1_.surname as surname3_0_1_<br/>     from<br/>         Orders orders0_<br/>     left outer join<br/>         Customer customer1_<br/>             on orders0_.customer_id=customer1_.id<br/>     where<br/>         orders0_.id=?</pre>
<p>Please note that the preceding log requires that you have turned on SQL tracing, as discussed in <a href="078ed3f6-b849-4240-a0d4-cf3bd58c00ab.xhtml" target="_blank">Chapter 5</a>, <em>Managing Data Persistence with Quarkus</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we took a comprehensive overview of the MicroProfile specification and how to integrate it with Quarkus applications.</p>
<p>We started with an overview of the MicroProfile API and how it fits into the overall picture of cloud-based microservices. Then, we covered the major MicroProfile specifications.</p>
<p>First, we looked at the Health API and how it can report the liveness and readiness of your services. Then, we covered the Fault Tolerance API, which can be used to design resilient services. Next, we discussed the application's telemetry data and how it can be collected using the Metrics API. Another key aspect we covered was documenting of services and tracing the flow of requests, which can be carried out using the OpenAPI and tracing specifications. Finally, we learned how to create REST clients to simplify our interaction with remote services.</p>
<p>By now, you should have a clear picture of how to design a complete Quarkus Enterprise application, although we still haven't mastered a key aspect: Quarkus application security. That's what we are going to learn about in the next chapter.</p>


            </article>

            
        </section>
    </body></html>