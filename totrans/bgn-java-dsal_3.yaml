- en: Hash Tables and Binary Search Trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the preceding chapter, we introduced the concept of data structures by looking
    at arrays, linked lists, queues, and stacks. In this chapter, we will use some
    of these primitive structures to build more complex ones. We'll start the chapter
    by looking at hash tables, which are useful data structures for fast key-value
    lookup. In the second part of the chapter, we will learn about a more complex
    data structure that supports range queries, called binary trees.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Describe how hash tables work
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement two main techniques to deal with hash collisions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Characterize different hashing choices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explain the terminology, structure, and operations of binary trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demonstrate various tree traversal techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define balanced binary search trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing Hash Tables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A data structure that gives us the ability to insert, search, and optionally
    delete elements in a collection is called a **data dictionary**. Commonly, the
    type of data used is a key-value pair association, where we insert the key-value
    pair but search using a key to obtain the value.
  prefs: []
  type: TYPE_NORMAL
- en: Hash tables provide us with a fast data structure for organizing these key value
    pairs and implementing our data dictionary. They are useful in a wide variety
    of applications due to the quick lookup and ease of use for in-memory data storage.
    Insertion and search operations have a typical average runtime complexity of *O(1)*.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Hash Tables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at an example problem to help us understand the need for hash tables.
    Imagine you are a teacher, instructing a class of a maximum capacity of 30 students.
    The students sit at their assigned desks every day. To make your life easier,
    you decide to assign a sequential number from one to 30 to each desk. You then
    use this number to identify each student, and use your self-developed app to bring
    up the student''s records after you enter the desk number (see *Figure 3.1*).
    This way, you can quickly look up details such as the student''s name, date of
    birth, notes, and exam history:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/edfe6217-a5f9-4529-90a1-38aee455f640.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.1: App for displaying student''s records for student at desk number
    eight'
  prefs: []
  type: TYPE_NORMAL
- en: In this problem, a simple array can be used to store all students' records in
    memory. Each of the array's positions can contain one student record. This would
    allow you to access the array directly using a strategy of *index = deskNumber
    - 1*. If, in a particular year you have fewer students, and not all the desks
    are occupied, you will place nulls at the corresponding array index. This solution
    is shown in *Figure 3.2*.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is an example of direct addressing, where each student''s record is accessed using
    a key (the desk number). This type of solution can only be used when the possible
    key range is small enough to fit in an array which is directly in memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/738f0a76-df15-4b08-b50f-cab05fce1cec.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.2: Example of direct addressing'
  prefs: []
  type: TYPE_NORMAL
- en: To help us determine how efficiently we are using memory, we can measure the
    load factor. The load factor is simply a metric showing how fully utilized our
    data structure is. When the class is at max capacity, all the elements in the
    array will contain a record. We say that the load factor of our data structure
    is 1 (or at 100%). If, for example, only 15 students out of 30 spaces have registered
    for a particular year, the load factor is 0.5 (50%). A lower load factor value
    means that we are under-utilizing and wasting memory.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's expand our example to include not just a class but an entire school,
    and instead of teaching one class, you have now been promoted to the head of the
    entire school. In this new position, you want to keep student records for every
    person currently enrolled. You also want to store historical records for any past
    students that are no longer in the school. You decide to use the national ID or
    passport number as a key to uniquely identify each one of your students. Assuming
    this is a US or an EU school, the national ID or passport number typically consists
    of nine numeric digits or more.
  prefs: []
  type: TYPE_NORMAL
- en: Since our input range is quite big, directly addressing this would be very impractical.
  prefs: []
  type: TYPE_NORMAL
- en: Since the US passport number (or national ID) is typically nine numeric digits, we
    would have to construct a huge array to store any possible number. For a nine-digit
    numeric range, the array's size would be 1,000,000,000\. Assuming each pointer
    is four bytes, this array alone would  consume almost 4 GB! The load factor of
    this example would also be terribly low. Most of the array will be empty, as the
    school will only have a few thousand present and past students.
  prefs: []
  type: TYPE_NORMAL
- en: We can still store the students' records in an array sized to a few thousand.
    All we need to do is find a way to squeeze our input key range into our array
    index range. Essentially, this means mapping our nine-digit numeric passport into
    a four-digit one. This job can be done by what is known as a hash function. A
    hash function would accept a key (our passport number) and return an array index
    within the size of our array (see *Figure 3.3*).
  prefs: []
  type: TYPE_NORMAL
- en: 'We say that a hash function maps our input key universe to our chosen hash
    range, which in this example is our array size:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6a09b166-4f1a-4a62-8b2c-0f819930271f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.3: Using hash functions'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using a hash function enables us to use a much smaller array and saves us a
    lot of memory. However, there is a catch. Since we are forcing a bigger key space
    into a smaller one, there is a risk that multiple keys map to the same hashed
    array index. This is what is called a **collision**; we have a key hash to an
    already filled position. The strategy on how to deal with collisions together
    with the choice of hash function make up our hash table. The following code snippet
    shows a Java interface that defines our hash table API. We will gradually implement
    this interface in later sections of this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.1: Hashtable interface. Source class name: Hashtable'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/FK1q6k](https://goo.gl/FK1q6k) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: In Java, the classes `java.util.Hashtable` and `java.util.HashMap` both implement
    the interface `HashTable`. The main difference between the two classes is that
    the `HashMap` is unsynchronized and permits nulls.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we first introduced direct addressing by looking at an example
    scenario. Later, we expanded the problem to a bigger key space, showing how hash
    tables can be used in such a scenario. In the next section, we will see two common
    solutions for dealing with hash table collisions.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with Collisions with Chaining
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What do we do when two keys hash to the same slot in our array? Overwriting
    the element in our array is not an option as this would mean losing records. One
    common solution to deal with collisions is a technique called **chaining**. In
    this solution, the hash table data is stored outside the actual array itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea behind chaining is that each entry in our hash array has a pointer
    to its own linked list. Any items we add to our hash table are stored in these
    linked lists. Initially, every entry in the array is initialized to contain an
    empty linked list. Whenever we insert a particular array slot in the hash table,
    we insert it at the head of the linked list associated with that position. In
    this way, we can support hash collisions. Another insert, on an already occupied
    array slot, would result in a new item at the head of its linked list. *Figure
    3.4* shows an example in which two entries with different keys have hashed to
    the same array slot, resulting in the two records stored in the linked list:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/31c99548-bf7a-480e-bf9c-537ea923bc44.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.4: Using linked lists to chain multiple entries in one hash slot'
  prefs: []
  type: TYPE_NORMAL
- en: Searching for a particular key requires first locating the array slot, and then
    traversing the linked list, one item at a time, looking for the required key until
    there is a match or the end of the list is reached. *Snippet 3.2* shows the search
    (`get`) and insert (`put`). The delete (`remove`) operation can be found by the
    URL provided after the snippet. We make use of Java's linked list collection for
    this hash table implementation. In the constructor, the array is initialized with
    the given capacity, and each element is filled with an empty linked list.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Java linked list collections enables us to use Java's lambda expressions
    when searching for the key in the `get(key)` method. When searching, we try to
    match the key with the ones found in the linked list and only return the optional
    value if a match is found.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the lambda expressions also enables us to implement the `delete` operation
    in a clean manner by just calling the `removeif()` method with a key-matching
    predicate (the `delete` operation can be found by the URL provided after the code
    snippet):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.2: The chained hash table. Source class name: ChainedHashTable'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/mrzQfY](https://goo.gl/mrzQfY) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: The best case runtime complexity for the search operation (`get()` method) shown
    in *Snippet 3.2* when the hash table contains *n* items is when we have no collisions,
    resulting in *O(1)*, and the worst is when we have n collisions, resulting in
    *O(n)*.
  prefs: []
  type: TYPE_NORMAL
- en: The `HashProvider` interface shown in *Snippet 3.2* simply provides us with
    a method that implements a hash function. We will implement this interface in
    the following sections when we explore different hash techniques. The runtime
    complexity for the chained hash table is dictated by how long our linked lists
    get. The best case is when every single item we insert in the hash table hashes
    to a different slot, that is, when there are no collisions. In the best case,
    we have a runtime of *O(1)* when each linked list only contains one item, and
    we can directly access any item.
  prefs: []
  type: TYPE_NORMAL
- en: The worst-case is the other extreme, when every single item hashes to the same
    value, resulting in a linked list with n items. When this happens, the performance
    degrades to *O(n)* time to search for the required key. This is because we need
    to traverse the linked list of *n* nodes to search the required key.
  prefs: []
  type: TYPE_NORMAL
- en: This worst runtime complexity of *O(n)* is applicable to all hash tables, not
    just chained ones. However, on average, and if the right hash function is chosen,
    the runtime performance of hash tables can be close to *O(1)*.
  prefs: []
  type: TYPE_NORMAL
- en: A chained hash table has no load limit. Even in situations where none of the
    slots are empty, we can still add more items to the hash tables by continuing
    to append to the linked lists. This means that the load factor of a chained hash
    table can exceed the value of 1.
  prefs: []
  type: TYPE_NORMAL
- en: Chained hash tables are the most popular collision resolution implementation.
    The reason for this is that they are easy to implement, provide a good performance,
    and unlike some other techniques, allow the hash table structure to scale dynamically,
    and grow beyond the load factor of *1*. In the next section, we will discuss another
    solution dealing with collisions, called **open addressing**.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with Collisions with Open Addressing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we saw how we can deal with collisions using linked
    lists at each array position. A chained hash table will keep on growing without
    any load limit. Open addressing is just another way of tackling hash collisions.
    In open addressing, all items are stored in the array itself, making the structure
    static with a maximum load factor limit of *1*. This means that once the array
    is full, you can't add any more items. The advantage of using open addressing
    is that, since you're not using linked lists, you're saving a bit of memory since
    you don't have to store any pointer references.
  prefs: []
  type: TYPE_NORMAL
- en: You can then use this extra memory to have an even larger array and hold more
    of your key value pairs. To insert in an open-addressed hash table, we hash the
    key and simply insert the item in the hash slot, the same as a normal hash table.
    If the slot is already occupied, we search for another empty slot and insert the
    item in it. The manner in which we search for another empty slot is called the
    **probe sequence**.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple strategy, shown in *Figure 3.5*, is to search by looking at the next
    available slot. This is called **linear probing**, where we start from the array
    index at the hash value and keep on increasing the index by one until we find
    an empty slot. The same probing technique needs to be used when searching for
    a key. We start from the hash slot and keep on advancing until we match the key
    or encounter an empty slot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7091d53a-8d89-4771-b0ac-6a3fc775c52e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.5: Linear probing in open addressing'
  prefs: []
  type: TYPE_NORMAL
- en: The next code snippet shows the pseudocode for linear probing insert. In this
    code, after we find the hash value we keep on increasing a pointer by one, searching
    for an empty slot.
  prefs: []
  type: TYPE_NORMAL
- en: Once we reach the end of the array, we wrap around to the start using the *modulus*
    operator. This technique is similar to one we used when we implemented array-based
    stacks. We stop increasing the array pointer either when we find a null value
    (empty slot) or when we get back to where we started, meaning the hash table is
    full. Once we exit the loop, we store the key-value pair, but only if the hash
    table is not full.
  prefs: []
  type: TYPE_NORMAL
- en: 'The pseudocode is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.3: Pseudocode for inserting using linear probing'
  prefs: []
  type: TYPE_NORMAL
- en: Searching for a key is similar to the insert operation. We first need to find
    the hash value from the key and then search the array in a linear fashion until
    we encounter the key, find a null value, or traverse the length of the array.
  prefs: []
  type: TYPE_NORMAL
- en: If we want to delete items from our open, addressed hash table, we cannot simply
    remove the entry from our array and mark it as null. If we did this, the search
    operation would not be able to check all possible array positions for which the
    key might have been found. This is because the search operation stops as soon
    as it finds a null.
  prefs: []
  type: TYPE_NORMAL
- en: One solution is to add a flag at each array position to signify that an item
    has been deleted without setting the entry to null. The search operation can then
    be modified to continue past entries marked as deleted. The insert operation also
    needs to be changed so that, if it encounters an entry marked as deleted, it writes
    the new item at that position.
  prefs: []
  type: TYPE_NORMAL
- en: Linear probing suffers from a problem called **clustering**. This occurs when
    a long succession of non-empty slots develop, degrading the search and insert
    performance. One way to improve this is to use a technique called **quadratic
    probing**. This strategy is similar to linear probing, except that we probe for
    the next empty slot using a quadratic formula of the form *h + (ai + bi²)*, where
    *h* is the initial hash value, and *a* and *b* are constants. *Figure 3.6* shows
    the difference between using linear and quadratic probing with *a = 0* and *b
    = 1*. The diagram shows the order in which both techniques explore the array.
  prefs: []
  type: TYPE_NORMAL
- en: 'In quadratic probing, we would change *Snippet 3.3* to check at array indexes
    of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/89bf429a-fa38-4aee-b961-c970c6e2ace1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.6 Linear versus quadratic probing
  prefs: []
  type: TYPE_NORMAL
- en: Although quadratic probing reduces the effect of clustering, it suffers from
    a problem called secondary clustering. This is a milder form of clustering, however,
    it will still degrade performance. In addition, the constants *a* and *b*, and
    the array size need to be carefully chosen so that the probing explores the entire
    array.
  prefs: []
  type: TYPE_NORMAL
- en: One other probing strategy used in open-addressing hash tables is called **double
    hashing**. This makes use of another hash function to determine the step offset
    from the initial hash value. In double hashing, we probe the array using the expression
    *h + ih'(k)*, where *h* is the hash value and *h'(k)* is a secondary hash function
    applied on the key. The probing mechanism is similar to linear probing, where
    we start with an *i* of zero and increase by one on every collision. Doing so
    results in probing the array every *h'(k)* step. The advantage of double hashing
    is that the probing strategy changes on every key insert, reducing the chances
    of clustering.
  prefs: []
  type: TYPE_NORMAL
- en: In double hashing, care must be taken to ensure that the entire array is explored.
    This can be achieved using various tricks. For example, we can size our array
    to an even number and make sure the secondary hash function returns only odd numbers.
  prefs: []
  type: TYPE_NORMAL
- en: Carrying out the Linear Probing Search Operation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The aim here is to develop pseudocode for the search operation in linear probing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Write pseudocode similar to *Snippet 3.3* to show the search operation. The operation
    should return null if the key is not found in the hash table. The search function
    should have a signature as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The pseudocode can be developed as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.4: Solution pseudocode for searching using linear probing'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have seen another manner for dealing with hash collisions
    by keeping all items in the array itself, saving memory, but limiting the structure
    statically. In the next subsection, we shall go into detail about some of the
    various hash functions available.
  prefs: []
  type: TYPE_NORMAL
- en: Remainder and Multiplication Hash Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For hash tables, a hash function maps a specific key's space into a smaller
    number range. More formally, a hash function, *f*, maps keys of a specific data
    type to integers in a fixed interval *[0,..., N - 1]*. We say *f(x)* hashes the
    value of *x*.
  prefs: []
  type: TYPE_NORMAL
- en: The hash function can accept only numeric data types. To allow us to use hash
    tables on more complex data types, we usually need to convert all these types
    into numeric representations. This translation varies, depending on the type of
    data. For example, a character can be changed into its UTF-8 (or ASCII) numeric
    equivalent. Converting a full string can be done by converting each character
    separately and then using a strategy to combine the characters into one value.
  prefs: []
  type: TYPE_NORMAL
- en: In Java, the `hashCode()` method converts an object into a numeric representation,
    which is ready to be used by a hash function. It is present in the object class
    and can be overridden using a custom implementation.
  prefs: []
  type: TYPE_NORMAL
- en: There are many techniques on how we can map keys from a wide range into smaller
    ones. An ideal hash function is one that reduces collisions to a minimum. In other
    words, when a good hash function is used, each key has the same probability of
    filling any of the slots in our array. In practice, finding an ideal hash function
    is very difficult unless we know the input distribution.
  prefs: []
  type: TYPE_NORMAL
- en: A simple technique to implement a hash function is what is known as the **remainder
    method**. The hash function simply takes in any numeric key, divides it by the
    table size (size of the array), and uses the resultant remainder as the hash value.
    This value can then be used as an index on the array.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows how the remainder hashing method can be implemented
    in Java using the modulus operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.5: The remainder method. Source class name: RemainderHashing'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/wNyWWX](https://goo.gl/wNyWWX) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: The reminder method might result in many collisions if care is not taken when
    choosing an appropriate table size. Once again, consider the example given in
    the beginning of this section where we are using the student's passport or national
    ID number to identify a student in the school. To demonstrate the problem, we
    use an array-based hash table with a size of 1,000 elements. It just so happens
    that in the country where the school is based, the last four digits of the passport
    numbers represent the year of birth of the passport holder.
  prefs: []
  type: TYPE_NORMAL
- en: When using the remainder method in this scenario, all the students with the
    same year of birth will hash to the same value, causing a lot of collisions on
    the hash table.
  prefs: []
  type: TYPE_NORMAL
- en: A better choice of a table size is to use a prime number, ideally not too close
    to the power of 2\. For example, the value of 1,447 is a good choice in our example,
    since it's not too close to 1,024 or 2,048 (2^(10) and 2^(11)) and is also prime.
    Using this value as a table size for our example would reduce collisions.
  prefs: []
  type: TYPE_NORMAL
- en: Using the remainder method restricts us on the choice of size for our hash table
    (to reduce the chance of collisions). To address this, we can use a different
    hashing technique, called the **multiplication method**. In this method, we multiply
    the key by a constant double value, *k*, in the range *0 < k < 1*. We then extract
    the fractional part from the result and multiply it by the size of our hash table.
  prefs: []
  type: TYPE_NORMAL
- en: 'The hash value is then the floor of this result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3aea6a0b-1dfa-4092-9355-77455fc9f222.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Where:'
  prefs: []
  type: TYPE_NORMAL
- en: '*k* is a decimal in the range between 0 and 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*s* is the size of the hash table'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x* is the key'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the Multiplication Method for a Hash Table
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The aim here is to develop a code in Java for implementing the multiplication
    method for a hash table.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Implement a class with a method which accepts an integer and returns a hash
    value using the multiplication method shown in this section. The constant *k*
    is passed in as the class constructor. The method signature should be:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code shows an implementation for the multiplication hash function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.6: Solution for the multiplication method. Source class name: MultiplicationHashing.'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/xJ7i1b](https://goo.gl/xJ7i1b) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have seen two basic techniques on how to compute hash values,
    the remainder method and the multiplication method. Both of these strategies are
    widely used in hash tables.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will examine yet another mechanism, called **universal
    hashing**.
  prefs: []
  type: TYPE_NORMAL
- en: Universal Hashing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Both the remainder and multiplication hashing methods have a common vulnerability.
    If an attacker knows the details of our hash function (table size and any constant
    values), he/she could devise an input key sequence resulting in a collision on
    every item, turning our hash table into a linked list and slowing down our program.
    To address this problem, a hashing technique called universal hashing can be used.
  prefs: []
  type: TYPE_NORMAL
- en: Universal hashing works by choosing a random function from a universal set of
    hash functions at the start of execution. This makes it difficult for an attacker
    to guess the exact workings of the hashing technique used. By using this technique,
    the same sequence of keys will produce a different sequence of hash values on
    every execution.
  prefs: []
  type: TYPE_NORMAL
- en: A set of hash functions, *H*, with size *n*, where each function maps a universe
    of keys ∪ to a fixed range of *[0, s)*, is said to be universal for all pairs,
    where *a*, *b ∈ ∪*, *a ≠ b* and the probability that *h(a) = h(b)*, *h ∈ H* is
    less than or equal to *n/s*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can construct our set of universal hash functions by using two integer variables,
    *i* in a range of *[1, p)*, and *j* in a range of *[0, p)*, where *p* is a prime
    number larger than any possible value of the input key universe. We can then generate
    any hash function from this set using:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8bb2319b-4912-42a6-b894-271b6b11f47e.png)'
  prefs: []
  type: TYPE_IMG
- en: Where *s* is the size of the hash table and *x* is the key.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.7: Universal hashing for integer keys. Source class name: UniversalHashing'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/5Kv7qG](https://goo.gl/5Kv7qG) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: Java provides hash tables and built-in hashing mechanisms using the `Object.hashcode()`
    method. As a result of this, it is very difficult to implement a universal hashing
    table which integrates with Java's existing `hashcode()` method, since the `i`
    and `j` variables in the preceding code would have to be shared between different
    objects being inserted in the same table.
  prefs: []
  type: TYPE_NORMAL
- en: 'For more information and mathematical proofs about why we pick a larger than
    key prime number, refer to Carter and Wegman, *Universal Classes of Hash Functions*,
    *Journal of Computer and System Sciences*: [https://doi.org/10.1016/0022-0000(79)90044-8](https://doi.org/10.1016/0022-0000(79)90044-8).'
  prefs: []
  type: TYPE_NORMAL
- en: Universal hashing provides us with good results, minimizing collisions, and
    is immune to malicious attacks, since the function parameters are chosen at random.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity: Implementing Open Addressing'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Scenario**'
  prefs: []
  type: TYPE_NORMAL
- en: We have been asked to develop an algorithm to search and remove data from a
    hash table using the open addressing technique.
  prefs: []
  type: TYPE_NORMAL
- en: '**Aim**'
  prefs: []
  type: TYPE_NORMAL
- en: To implement a hash table using open addressing with linear probing.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prerequisites**'
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve this activity, you have to implement the methods found in the class
    that is available on GitHub at the following URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson3/activity/openaddressing/OpenAddrHashTable.java](https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson3/activity/openaddressing/OpenAddrHashTable.java)'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have your project set up, you can run the following unit test for this
    activity by running:'
  prefs: []
  type: TYPE_NORMAL
- en: '`**gradlew test --tests com.packt.datastructuresandalg.lesson3.activity.openaddressing***`'
  prefs: []
  type: TYPE_NORMAL
- en: '**Steps for Completion**'
  prefs: []
  type: TYPE_NORMAL
- en: Study the pseudocode shown in *Snippet 3.3* and *Snippet 3.4*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement them in Java
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a container class that will hold your key and value in the hash table
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Have a flag on this container to indicate when an item is deleted
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use this flag in the insert operation to overwrite it if it is deleted
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Getting Started with Binary Search Trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like hash tables, binary search trees are fast lookup data structures for organizing
    key value pairs and implement the data dictionary operations. In addition to providing
    insert, search, and delete, binary tree supports efficient querying such as finding
    minimum and maximum, successor, and predecessor. When using balanced binary search
    trees, insert and search operations have a worst-case runtime complexity of *O(log
    n)*. This is a big theoretical improvement over the worst-case scenario of a hash
    table, which is *O(n)*.
  prefs: []
  type: TYPE_NORMAL
- en: Binary Tree Structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The structure of a binary tree is composed of a series of nodes connected together
    via pointers. *Figure 3.8* shows the fundamental relation between nodes. Each
    node can have a maximum of two child nodes, a left one and a right one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each node (except the top-level node) also has exactly one parent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7ab6a211-a10f-45e0-9da5-0451b3557c4f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.8: Showing a simple binary tree relation'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.9* shows some more terminology applied to binary trees. In this diagram,
    we also show that binary tree nodes can hold data items by showing the node storing different
    shapes. The top-level node is called the root node. The root node in a tree structure
    is the only node that doesn''t have a parent. Nodes that don''t have any children
    are called leaf nodes. The height of a tree is the number of hops it would take
    you to get from the root node to the furthest leaf node. The diagram shows an example
    of a tree which has a height of 2.'
  prefs: []
  type: TYPE_NORMAL
- en: The height of a tree is an important metric, as it affects the performance.
    The shallower a tree is (smaller height), the more performant a tree structure
    is.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2182c344-d7d7-4f7e-8206-ea8eb1a98530.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.9: Binary tree terminology'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to a linked list, the binary tree structure is modeled using pointers
    and node objects. In a linked list node, we only have a next pointer, referencing
    the next node in the list. Similarly, in a binary tree node we have two pointers,
    each one linking to one child. These are the left and right child pointers. The
    following code snippet shows how we can model the binary tree node using a Java
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.8: The Binary tree node class. Some getters and setters have been
    omitted for brevity. Source class name: BinaryTreeNode'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/D6Jvo2](https://goo.gl/D6Jvo2) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then have another class representing the binary tree itself, where the operations
    will be implemented. This class only needs to hold a pointer to the root node,
    since any node can be reached by starting from the root node and navigating down.
    In the following code snippet, we show an interface declaring the binary tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.9: Binary tree interface. Source class name: BinaryTree.'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/jRcLhu](https://goo.gl/jRcLhu) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have introduced the structure and terminology of binary
    trees. We then learned how to model each node using Java classes. In the next
    section, we will continue building on these concepts by introducing binary search
    trees and implementing the insert and search operations.
  prefs: []
  type: TYPE_NORMAL
- en: Binary Search Tree Operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Binary search trees are normal binary trees in which data is organized in an
    ordered manner. Consider the same problem we encountered in the previous section,
    of the school keeping a student's records by using the passport numbers as a key.
    *Figure 3.10* shows an example of how you can organize the data in a binary tree.
  prefs: []
  type: TYPE_NORMAL
- en: Note how at each node the left child has a key which is less than its own. On
    the other hand, the right child has a larger key. Shown in the diagram, the root
    node has a left child containing a key of a smaller value than the root key. On
    the other hand, the right child has a key of a larger value than the root.
  prefs: []
  type: TYPE_NORMAL
- en: 'This rule is repeated through the entire tree. In a binary search tree, the
    left child will always have a smaller key than the parent, while the right child
    will have a larger one. Using this binary search tree property, we can create
    efficient operations on the tree structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ecfba1cb-3fe1-43ce-9cdc-b80f506be227.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.10: An example of a binary search tree'
  prefs: []
  type: TYPE_NORMAL
- en: As a result of this simple rule, the tree exhibits important properties. For
    example, note how all the nodes that are descendants of the left child of the
    root node have a smaller key than the root. This property is valid for any node
    of the tree. All keys on the left subtree of a node will always have smaller keys,
    and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: 'Searching in a binary search tree requires us to follow some simple instructions.
    We start at the root and at each node, we ask ourselves: "<q class="pcalibre5
    pcalibre4 calibre33">Is the key we''re looking for equal to less than, or greater
    than the key on this node?</q>" If the key is equal, we''re done and we have found
    our node. If the key is less, we follow the left child pointer, otherwise we follow
    the right one. We repeat this step until we find our key or hit a *null child
    pointer*.'
  prefs: []
  type: TYPE_NORMAL
- en: Another important property of a binary search tree is being able to easily find the
    maximum and minimum key in the tree. Finding the maximum key in a binary tree
    is easy. Conceptually, this is the rightmost node. This can be found by starting
    at the root and always picking the right child until there isn't any right child
    to choose. The reverse is valid (picking the left child) for the minimum key.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet shows the search implementation. In this implementation,
    we use the power of recursion to perform the search. We start by checking if the
    tree is empty by checking whether the root is null. If a root node is present,
    we compare the key and either return the value or recursively search the child
    nodes. To compare the key, we assume the provided key implements the comparable
    interface. Using Java''s optional flat mapping makes our implementation much more
    concise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.10: Binary search tree search operation. Source class name: SimpleBinaryTree.'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/xE2GvH](https://goo.gl/xE2GvH) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Java''s `objectA.compareTo(objectB)` method in the comparable interface returns a
    negative integer, zero, or a positive integer as `objectA` is less than, equal
    to, or greater than `objectB`. Thus, the following statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Is conceptually the same as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Inserting in a binary tree follows the same logic as the search operation. We
    start from the root and keep on looking for a location where we need to create
    a new node. This is shown in the next code snippet. Like the search operation,
    this Java implementation is also recursive. If the root node is absent we just
    create a new one, otherwise we recursively insert the key value pair each time
    by choosing the left or right child depending on the value of the key.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have three stopping conditions for the recursive call that are, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: When the *key is equal* to the one on the node, we simply overwrite the entry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the *left child is not present*, we create a new node with the key value
    pair
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the *right child is not present*, we create a new node with the key value
    pair
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code demonstrates the binary search tree insert operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.11: Binary search tree insert operation. Source class name: SimpleBinaryTree'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/hHpeiP](https://goo.gl/hHpeiP) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Binary tree deletion requires matching the subtree structure with a number
    of patterns and performing different actions with each case. In some situations,
    it requires that you connect the subtree with the parent of the deleted node,
    which can be quite complex. For this reason, the deletion algorithm is beyond
    the scope of this book. For information on the deletion operation, you may refer
    to the following sources:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The Art of Computer Programming, Volume 3: Sorting and Searching*, by Donald
    Knuth.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paul E. Black, "binary search tree", in Dictionary of *Algorithms and Data Structures*
    [online], Vreda Pieterse and Paul E. Black, eds. January 26, 2015\. Available
    at [https://www.nist.gov/dads/HTML/binarySearchTree.html](https://www.nist.gov/dads/HTML/binarySearchTree.html).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Searching for a Minimum Key in a Binary Tree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The aim is to implement a method in Java to search for the minimum key in a
    binary tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a method to the binary tree implementation with the following signature:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The method needs to find the minimum key in the tree and return it. If the tree
    is empty, it should return an empty optional.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finding the minimum in a binary search tree requires us to always follow the left
    child node until we reach a node with no left child pointer. The following code
    demonstrates this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.12: Minimum key operation. Source class name: SimpleBinaryTree.'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/YbZz6i](https://goo.gl/YbZz6i) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have introduced binary search trees and explored how they
    can be used to organize key value pairs. We also saw how binary search trees can
    be used for simple range queries, such as finding the maximum and minimum keys.
    In the next section, we learn about all the different ways we can traverse a binary
    search tree.
  prefs: []
  type: TYPE_NORMAL
- en: Traversing a Binary Search Tree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Traversing a binary tree is the process of stepping through each node of the
    tree and performing some sort of action on the data contained in the node (such
    as printing the key value pair). There are two main techniques to perform tree
    traversal: depth-first search and breadth-first search, more commonly known as
    DFS and BFS, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: In depth-first search, the algorithm goes down a path of tree nodes until it
    cannot go any further. Once it cannot go further, it backtracks and discovers
    any remaining unexplored branches. A recursive implementation is shown in the
    following code. In this traversal method, a different output sequence is produced
    depending on where the action is executed in the method.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a **preorder** execution, we perform the action immediately, as soon as
    a new node is discovered. A **postorder** execution, on the other hand, is when
    both children of a node have been explored and we''re about to backtrack. An **inorder**
    execution is done when the left child has been processed but before processing
    the right one. When using an inorder traversal, the keys in the binary search
    trees will be processed in ascending order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.13: Depth-first search. Source class name: SimpleBinaryTree'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/xMzkbE](https://goo.gl/xMzkbE) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the breadth-first search traversal, the algorithm explores the binary tree
    one level at a time, left to right. The traversal starts from the root node and
    finishes at the leaf nodes. The output of an example binary tree is shown in *Figure
    3.11*. To implement a BFS traversal of a binary tree, we can make use of a queue
    initialized to contain the root node. Then, while the queue is not empty, we read
    the first node on the queue, process it, and add first the left and then the right
    child to the queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0e506e9a-dfee-4baa-b211-c002bbe27a13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.11: Breadth-first search on a binary tree'
  prefs: []
  type: TYPE_NORMAL
- en: 'We show the pseudocode of this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.14: Pseudocode for breadth-first search'
  prefs: []
  type: TYPE_NORMAL
- en: If we substitute the queue with a stack, the algorithm shown in *Snippet 3.14*
    changes from breadth-first search to the non-recursive depth-first search. In
    fact, the way to implement a non-recursive DFS is to make use of a stack.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity: Implementing BFS in Java'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Scenario**'
  prefs: []
  type: TYPE_NORMAL
- en: We have been asked to write code to implement an algorithm that searches the binary
    tree one level at a time, left to right. The traversal starts from the root node and
    finishes at the leaf nodes.
  prefs: []
  type: TYPE_NORMAL
- en: '**Aim**'
  prefs: []
  type: TYPE_NORMAL
- en: To apply BFS traversal in Java.
  prefs: []
  type: TYPE_NORMAL
- en: '**Steps for Completion**'
  prefs: []
  type: TYPE_NORMAL
- en: Implement the algorithm shown in the preceding code in Java.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the Java `LinkedList` collection to implement the queue shown in the pseudocode.
    The method signature should be as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we have learned about the various ways we can traverse a binary
    tree and the different ordering produced by each strategy. We have also seen how
    these algorithms can be implemented both in a recursive and in an iterative manner.
    In the next section, we will discuss a more restrictive type of binary search
    tree that ensures our data structure maintains a good performance, even in the
    worst input case.
  prefs: []
  type: TYPE_NORMAL
- en: Balanced Binary Search Trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The performance of a binary search tree is proportional to its height. This
    is because the search and insert operations start from the root and proceed down
    the tree one node at a time, doing a key comparison at each step. The taller the
    tree, the more steps are needed to accomplish this. Thus, if we determine the
    maximum possible height of a binary tree in relation to its input, we can find
    out the worst runtime complexity.
  prefs: []
  type: TYPE_NORMAL
- en: If we insert keys in a binary tree, by always adding on the right child of the
    parent node, we end up with a tree similar to the one shown on the left-hand side
    of *Figure 3.12*. In this diagram, only the right child pointers on each node
    are being used. We end up with a tree of height *n*, where *n* is the number of
    items added to our data structure. We get this kind of one-sided tree when the
    key input pattern is in order.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the example shown in *Figure 3.12*, we first insert 5 as a root, then 7
    is added as the right child, the next is 12 as the next right child, and so on.
    Always inserting an increasing number results in the next node on the right. This
    one type of input pattern makes our binary search tree operations (search, insert,
    and delete) behave in the worst-case runtime of *O(n)*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d5df6774-db10-4444-8504-d745772daded.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.12: Unbalanced versus balanced binary trees'
  prefs: []
  type: TYPE_NORMAL
- en: The result is similar if we start from a big number and decrease it each time.
    We end up with a mirror of the tree shown on the left-hand side of *Figure 3.12*.
  prefs: []
  type: TYPE_NORMAL
- en: The output of a BFS traversal in a normal binary search tree when the key insert
    order is "1,2,3,4,5,6,7" would be in the same order as the input, that is, "1,2,3,4,5,6,7". We
    end up  creating a new right child at every insert. Since BFS traversal processes
    one level after another, starting from the root, the traversal output is the same
    as the input.
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 3.12*, on the right-hand side, we show another binary tree containing
    the same keys. This binary tree has been restructured with the effect that the
    tree is now shorter. Note that the tree is still valid, that is, the left child
    always has a key that is smaller than its parent, and vice versa. A balanced binary
    tree has a height of about *log[2]n*.
  prefs: []
  type: TYPE_NORMAL
- en: If we manage to find a way to rebalance the binary search tree at each insert
    in *O(log n)* or better, the worst-case runtime performance for inserts and searches
    would also be of *O(log n)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Luckily, various algorithms exist that self-balance the tree structure as you
    perform inserts. Some of the most common ones are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: AVL trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Red black trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AA trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these algorithms check that the binary tree is following specific balancing
    rules at key insert. If, due to a new node being inserted, the tree becomes unbalanced,
    the self-balancing algorithm kicks in and restructures some of the nodes to keep
    the tree balanced. The technique to rebalance the nodes relies on tree rotations,
    where under certain conditions some of the parent and child nodes are rotated.
    Importantly, these modifications are also performed in the worst-case of *O(log
    n)*, meaning that both inserts and searches on binary trees have a worst runtime
    complexity of *O(log n)*. In this section, we will examine tree rotations as they
    are the base operation for most self-balancing trees.
  prefs: []
  type: TYPE_NORMAL
- en: 'For more information about self-balancing trees, you may refer the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The Art of Computer Programming*, *Volume 3: Sorting and Searching by **Donald
    Knuth*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Paul E. Black, "*red-black tree*", in *Dictionary of Algorithms and Data Structures*
    [online], Vreda Pieterse and Paul E. Black, eds. 13 April 2015\. Available at
    the link: [https://www.nist.gov/dads/HTML/redblack.html](https://www.nist.gov/dads/HTML/redblack.html).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.13* shows an example of a left and right rotation. Note how the node
    being rotated (node 5 in the right rotation and 9 in the left rotation) ends up
    being the new parent. Importantly, there is a constant number of child pointer
    reassignments. The properties of a binary search tree are still valid after a
    tree rotates, that is, a left child pointer always has a smaller key that points
    to its parent, and vice versa. This means that we can perform any number of these
    tree rotations and our binary search tree will still be valid:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7f5c66a9-a6a2-42bf-96d1-c40479d1c864.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.13: Left and right tree rotations'
  prefs: []
  type: TYPE_NORMAL
- en: '*Snippet 3.15* shows how we perform a right rotation in Java. The method accepts
    a top-level node that needs rotation (node 5 in *Figure 3.13*) and its parent
    node. The method requires the parent node since it has to reassign its child pointer.
    Performing the opposite right rotation on the tree node is the mirror image of
    the following method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.15: Java implementation of the left tree rotation. Source class name: SimpleBinaryTree'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/Ts3JBu](https://goo.gl/Ts3JBu) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: Applying Right Tree Rotation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The aim is to implement a right tree rotation in Java.
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify *Snippet 3.15* to make the method perform a right tree rotation instead of
    a left tree rotation. The following code shows the required modification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 3.16: Java implementation of the right tree rotation. Source class
    name: SimpleBinaryTree'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://goo.gl/KKDWUa](https://goo.gl/KKDWUa) to access this code.
  prefs: []
  type: TYPE_NORMAL
- en: The right rotation is an exact mirror image of the left rotation. It's enough
    to change all the left references with right references and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we saw how we can improve the performance of binary search
    trees by using tree rotations to balance the data structure. This enables the
    tree to remain of a shorter height with a runtime complexity of *O(log n)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity: Retrieving the Successor of an Element When the Tree is Traversed
    in Inorder'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Scenario**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to write a method that, given a key as an argument, returns the next
    in order key found in the binary search tree. If the key given as an argument
    is not found, the method should still return the next in order key. If the binary
    tree is empty or all the stored keys are smaller than the argument, then the return
    value should be empty. For example, using a collection of {10, 13, 52, 67, 68,
    83} stored in the binary search tree:'
  prefs: []
  type: TYPE_NORMAL
- en: An input of 13 results in 52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An input of 67 results in 68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An input of 55 results in 67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An input of 5 results in 10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An input of 83 results in `Optional.empty`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An input of 100 results in `Optional.empty`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any input on an empty binary tree results in `Optional.empty`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both the in order successor and predecessor algorithms have many applications.
    As an example, think about if you had to keep a scoreboard at some sports event
    where you only want to show the first three runners. If you keep your data in
    a binary search tree, you can find the maximum key and then work out the next
    two predecessor nodes.
  prefs: []
  type: TYPE_NORMAL
- en: The solution needs to have a runtime complexity of *O(log n)*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Aim**'
  prefs: []
  type: TYPE_NORMAL
- en: To retrieve the successor of an element when the tree is traversed in inorder.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prerequisites**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Implement the following method, provided in the `InOrderSuccessorBinaryTree` class
    that extends the `SimpleBinaryTree` class, which is available on GitHub at the following
    link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson3/activity/inordersuccessor/InOrderSuccessorBinaryTree.java](https://github.com/TrainingByPackt/Data-Structures-and-Algorithms-in-Java/blob/master/src/main/java/com/packt/datastructuresandalg/lesson3/activity/inordersuccessor/InOrderSuccessorBinaryTree.java)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'If you have your project set up, you can run the unit test for this activity
    by running:'
  prefs: []
  type: TYPE_NORMAL
- en: '`gradlew test --tests com.packt.datastructuresandalg.lesson3.activity.inordersuccessor*`'
  prefs: []
  type: TYPE_NORMAL
- en: '**Steps for Completion**'
  prefs: []
  type: TYPE_NORMAL
- en: Use a non-recursive search operation first to find the first node with a key
    equal to or less than the input
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Realize that the inorder successor can be in only one of two places, either
    as a parent of this node or the minimum key on the subtree of the right child
    of this node (if any)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have studied two of the most commonly used data structures
    for implementing the data dictionary operation. Hash tables provide fast in-memory
    insertion and lookup operations. In addition, binary trees also give us the ability
    to perform various range queries such as successor, predecessor, minimum and maximum.
    In this chapter, we have seen examples of both data structures, and implementations
    of these operations.
  prefs: []
  type: TYPE_NORMAL
