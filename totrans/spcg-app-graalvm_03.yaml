- en: '*Chapter 2*: JIT, HotSpot, and GraalJIT'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第二章*：JIT、HotSpot和GraalJIT'
- en: In the previous chapter, we learned about C1 and C2 compilers and the kind of
    code optimizations and de-optimizations that C2 compilers perform at runtime.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了C1和C2编译器以及C2编译器在运行时执行的代码优化和去优化类型。
- en: In this chapter, we will deep dive into the C2 just-in-time compilation and
    introduce Graal's just-in-time compilation. **Just-In-Time** (**JIT**) compilation
    is one of the key innovations that enabled Java to compete with traditional **ahead-of-time**
    (**AOT**) compilers. As we learned in the previous chapter, JIT compilation evolved
    with C2 compilers in JVM. The C2 JIT compiler constantly profiles code execution
    and applies various optimizations and de-optimizations at runtime to compile/recompile
    the code.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨C2即时编译，并介绍Graal的即时编译。**即时**（**JIT**）编译是Java能够与传统**编译时**（**AOT**）编译器竞争的关键创新之一。正如我们在上一章所学，JIT编译随着JVM中的C2编译器而发展。C2
    JIT编译器持续分析代码执行情况，并在运行时应用各种优化和去优化，以编译/重新编译代码。
- en: This chapter will be a hands-on session, where we will take a sample code and
    analyze how the C2 JIT compiler works and introduce Graal JIT.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将是一个实战环节，我们将分析一个示例代码，了解C2 JIT编译器的工作原理，并介绍Graal JIT。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Understand how the JIT compiler works
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解JIT编译器的工作原理
- en: Learn how code is optimized by JIT by identifying HotSpots
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过识别热点区域来了解JIT如何优化代码
- en: Use profiling tools to demonstrate how the JIT compiler works
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用分析工具演示JIT编译器的工作原理
- en: Understand how GraalVM JIT works on top of JVM JIT
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解GraalVM JIT在JVM JIT之上是如何工作的
- en: By the end of this chapter, you will have a clear understanding of the internal
    workings of the JIT compiler and how GraalVM extends it further. We will be using
    sample Java code and profiling tools such as JITWatch to gain a deeper understanding
    of how JIT works.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将清楚地了解JIT编译器的内部工作原理以及GraalVM如何进一步扩展它。我们将使用示例Java代码和JITWatch等分析工具来深入了解JIT的工作方式。
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To follow the instructions given in this chapter, you will require the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要遵循本章中给出的说明，你需要以下工具：
- en: All the source code referred to in this chapter can be downloaded from [https://github.com/PacktPublishing/Supercharge-Your-Applications-with-GraalVM/tree/main/Chapter02](https://github.com/PacktPublishing/Supercharge-Your-Applications-with-GraalVM/tree/main/Chapter02).
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中提到的所有源代码都可以从[https://github.com/PacktPublishing/Supercharge-Your-Applications-with-GraalVM/tree/main/Chapter02](https://github.com/PacktPublishing/Supercharge-Your-Applications-with-GraalVM/tree/main/Chapter02)下载。
- en: Git ([https://github.com/git-guides/install-git](https://github.com/git-guides/install-git))
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Git ([https://github.com/git-guides/install-git](https://github.com/git-guides/install-git))
- en: Maven ([https://maven.apache.org/install.html](https://maven.apache.org/install.html))
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maven ([https://maven.apache.org/install.html](https://maven.apache.org/install.html))
- en: OpenSDK ([https://openjdk.java.net/](https://openjdk.java.net/)) and JavaFX
    ([https://openjfx.io/](https://openjfx.io/))
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenSDK ([https://openjdk.java.net/](https://openjdk.java.net/)) 和 JavaFX ([https://openjfx.io/](https://openjfx.io/))
- en: JITWatch ([https://www.jrebel.com/blog/understanding-java-jit-with-jitwatch#:~:text=JITWatch%20is%20a%20log%20analyser,to%20the%20Adopt%20OpenJDK%20initiative](https://www.jrebel.com/blog/understanding-java-jit-with-jitwatch#:~:text=JITWatch%20is%20a%20log%20analyser,to%20the%20Adopt%20OpenJDK%20initiative))
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JITWatch ([https://www.jrebel.com/blog/understanding-java-jit-with-jitwatch#:~:text=JITWatch%20is%20a%20log%20analyser,to%20the%20Adopt%20OpenJDK%20initiative](https://www.jrebel.com/blog/understanding-java-jit-with-jitwatch#:~:text=JITWatch%20is%20a%20log%20analyser,to%20the%20Adopt%20OpenJDK%20initiative))
- en: The Code in Action video for this chapter can be found at [https://bit.ly/3w7uWlu](https://bit.ly/3w7uWlu).
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的“代码实战”视频可以在[https://bit.ly/3w7uWlu](https://bit.ly/3w7uWlu)找到。
- en: Setup environment
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置环境
- en: In this section, we will set up all the prerequisite tools and environments
    that are required to follow on with the rest of the chapter.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将设置所有必需的先决工具和环境，以便继续学习本章的其余部分。
- en: Installing OpenJDK Java
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装OpenJDK Java
- en: You can install OpenJDK from [https://openjdk.java.net/install/](https://openjdk.java.net/install/).
    This URL has detailed instructions on how to install OpenJDK. We also require
    JavaFX. Please refer to [https://openjfx.io/](https://openjfx.io/) for more details
    on how to install JavaFX.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从[https://openjdk.java.net/install/](https://openjdk.java.net/install/)安装OpenJDK。此URL提供了安装OpenJDK的详细说明。我们还需要JavaFX。请参阅[https://openjfx.io/](https://openjfx.io/)以获取有关安装JavaFX的更多详细信息。
- en: Installing JITWatch
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装JITWatch
- en: JITWatch is one of the most widely used log analysis and visualization tools
    for understanding the behavior of the JIT compiler. This is also widely used in
    analyzing the code and identifying opportunities for better performance tuning.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: JITWatch is an active open source project hosted at [https://github.com/AdoptOpenJDK/jitwatch](https://github.com/AdoptOpenJDK/jitwatch).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: 'The typical commands for installing JITWatch are as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Taking a deep dive into HotSpot and the C2 JIT compiler
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we walked through the evolution of JVM and how the
    C2 JIT compiler evolved. In this section, we will dig deeper into the JVM C2 JIT
    compiler. Using sample code, we will go through the optimizations that the JIT
    compiler performs at runtime. To appreciate the Graal JIT compiler, it is very
    important to understand how the C2 JIT compiler works.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Profile-guided optimization is the key principle for JIT compilers. While AOT
    compilers can optimize the static code, most of the time, that is just not good
    enough. It's important to understand the runtime characteristics of the application
    to identify opportunities for optimization. JVM has a built-in profiler that dynamically
    instruments the application to profile some key parameters and to identify opportunities
    for optimizations. Once identified, it will compile that code to the native language
    and switch from running the interpreted code to faster-compiled code. The optimizations
    are based on profiling and educated assumptions that are made by JVM. If any of
    these assumptions are incorrect, JVM will de-optimize and switch back to running
    interpreted code. This is called **Mixed Mode Execution**.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows a flow of how JVM performs the profile-guided optimizations
    and switches between different modes of execution:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – JIT compilation'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_2.01.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.1 – JIT compilation
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: The Java source code (`.java`) is compiled to bytecode (`.class`), which is
    an intermediate representation of the code. JVM starts to run the bytecode with
    the inbuilt interpreter. The interpreter uses a bytecode to machine code mapping,
    converts the bytecode instructions to machine code one statement at a time, and
    then executes it.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: 'While JVM executes these instructions, it also tracks the number of times a
    method is invoked. When the method invocation count of a particular method exceeds
    the compiler threshold, it spins off a compiler to compile that method on a separate
    compilation thread. There are two types of compilers that JVM uses to compile
    the code: C1 (client) and C2 (server) JIT compilers. The compiled code is stored
    in the code cache, so that the next time that method is invoked, JVM will execute
    the code from the code cache instead of interpreting it. JIT compilers perform
    various optimizations to the code, and hence, over time, the application performs
    better. The rest of this section will walk through these various components in
    detail.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Code cache
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The code cache is an area in JVM where JVM stores the compiled native methods
    (also referred to as `nmethod`). The code cache is set to a static size and it
    might become full after a while. Once the code cache is full, JVM cannot compile
    or store any more code. It is very important to tune the code cache for optimum
    performance. Four key parameters help us to fine-tune JVM performance, with the
    optimum code cache:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 代码缓存是 JVM 中存储编译后的本地方法（也称为 `nmethod`）的区域。代码缓存被设置为静态大小，经过一段时间后可能会满。一旦代码缓存满，JVM
    就无法编译或存储更多代码。对代码缓存进行优化调整对于最佳性能至关重要。四个关键参数帮助我们微调 JVM 性能，以获得最佳代码缓存：
- en: '`-XX:InitialCodeCacheSize`: The initial size of the code cache. The default
    size is 160 KB (varies based on the JVM version).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-XX:InitialCodeCacheSize`：代码缓存的初始大小。默认大小为 160 KB（根据 JVM 版本的不同而有所变化）。'
- en: '`-XX:ReservedCodeCacheSize`: The maximum size the code cache can grow to. The
    default size is 32/48 MB. When the code cache reaches this limit, JVM will throw
    a warning: `CodeCache is full. Compiler has been disabled.`. JVM offers the `UseCodeCacheFlushing`
    option to flush the code cache when the code cache is full. The code cache is
    also flushed when the compiled code is not hot enough (when the counter is less
    than the compiler threshold).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-XX:ReservedCodeCacheSize`：代码缓存可以增长到的最大大小。默认大小为 32/48 MB。当代码缓存达到这个限制时，JVM
    将抛出一个警告：“代码缓存已满。编译器已被禁用。” JVM 提供了 `UseCodeCacheFlushing` 选项，当代码缓存满时可以刷新代码缓存。当编译的代码不够热（计数器小于编译器阈值）时，代码缓存也会被刷新。'
- en: '`-XX:CodeCacheExpansionSize`: This is the expansion size when it scales up.
    Its default value is 32/64 KB.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-XX:CodeCacheExpansionSize`：这是扩展现有的值。其默认值是 32/64 KB。'
- en: '`-XX:+PrintCodeCache`: This option can be used to monitor the usage of the
    code cache.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-XX:+PrintCodeCache`：此选项可用于监控代码缓存的利用率。'
- en: 'Since Java 9, JVM segments the code cache into three segments:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 自 Java 9 以来，JVM 将代码缓存分为三个部分：
- en: '`-XX:NonNMethodCodeHeapSize` flag.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-XX:NonNMethodCodeHeapSize` 标志。'
- en: '`-XX:ProfiledCodeHeapSize` flag.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-XX:ProfiledCodeHeapSize` 标志。'
- en: '`-XX:NonProfiledCodeHeapSize` flag.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-XX:NonProfiledCodeHeapSize` 标志。'
- en: Compiler threshold
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编译器阈值
- en: The compilation threshold is a factor that helps JVM decide when to perform
    JIT compilations. When JVM detects that a method execution has reached a compilation
    threshold, JVM will instigate the appropriate compiler to perform the compilation
    (more on this later in this section, where we will walk through the various types
    of JIT compilers and tiered compilation).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 编译阈值是帮助 JVM 决定何时执行 JIT 编译的一个因素。当 JVM 检测到某个方法的执行达到编译阈值时，JVM 将启动适当的编译器进行编译（关于这一点，在本节的后面部分将详细介绍，我们将遍历各种类型的
    JIT 编译器和分层编译）。
- en: 'Deciding the compilation threshold is based on two key variables. These variables
    come with a default value for each JVM, but can also be changed with appropriate
    command-line arguments. These variables are very critical in tuning the performance
    of JVM and should be used carefully. These two variables are as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 决定编译阈值基于两个关键变量。每个 JVM 都为这两个变量提供了默认值，但也可以使用适当的命令行参数进行更改。这两个变量对于调整 JVM 性能至关重要，应谨慎使用。这两个变量如下：
- en: '**Method invocation counter**: This counts the number of times a particular
    method is invoked.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方法调用计数器**：这统计了特定方法被调用的次数。'
- en: '**Loop counter**: This refers to the number of times a particular loop has
    completed execution (what is referred to as branching back). Sometimes, this is
    also referred to as Backedge Threshold or Backedge Counter.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**循环计数器**：这指的是特定循环完成执行（即分支回退）的次数。有时，这也被称为回边阈值或回边计数器。'
- en: JVM profiles these two variables at runtime and, on this basis, decides whether
    that method/loop needs to be compiled. When a compilation threshold is reached,
    JVM spins off a compilation thread to compile that particular method/loop.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: JVM 在运行时对这些两个变量进行配置，并据此决定是否需要编译该方法/循环。当达到编译阈值时，JVM 将启动一个编译线程来编译该特定方法/循环。
- en: The compilation threshold can be changed using the `-XX:CompilationThreshold=N`
    flag as an argument while executing the code. The default value of `N` is `1500`
    for the client compiler and `10000` for the server compiler.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `-XX:CompilationThreshold=N` 标志作为执行代码时的参数，可以更改编译阈值。对于客户端编译器，`N` 的默认值是 `1500`，而对于服务器编译器，默认值是
    `10000`。
- en: On-stack replacement
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 栈上替换
- en: The methods that reach the compilation threshold are compiled by the JIT compilers,
    and the next time the method is called, the compiled machine code is called. This
    improves performance over time. However, in cases of long-running loops that reach
    the loop counter threshold (Backedge Threshold), the compilation thread initiates
    code compilation. Once the code that is in the loop is compiled, the execution
    is stopped and resumed with the compiled code frame. This process is called **On-Stack
    Replacement (OSR)**. Let's look at the following example.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet just discusses how OSR works. To keep it simple,
    the code simply shows a long-running loop where we are just calculating the total
    number of times the loop runs. In this case, the `main()` method is never entered,
    so even after the compilation threshold is reached and the code is compiled, the
    compiled code cannot be used as the interpreter continues to execute, unless the
    code is replaced. This is where OSR helps in optimizing such code:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following flowchart shows how the OSR works in this case:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – OSR flowchart'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_2.02.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.2 – OSR flowchart
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how this works:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: The interpreter starts executing the code.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the compiler threshold is reached, JVM spins off a compiler thread to compile
    the method. In the meantime, the interpreter continues to execute the statement.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the compilation thread comes back with the compiled code (compilation frame),
    JVM checks whether the interpreter is still executing the code. If the interpreter
    is still executing the code, it will pause and perform OSR, and execution starts
    with the compiled code.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'When we run this code with the `-XX:PrintCompilation` flag on, this is the
    output that shows that JVM performed OSR (the % attribute indicates that it performed
    OSR):'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – OSR log screenshot'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_2.03.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.3 – OSR log screenshot
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the next section to understand the log format in detail.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: XX:+PrintCompilation
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`XX:+PrintCompilation` is a very powerful argument that can be passed to understand
    how the JIT compilers are kicking in and optimizing the code. Before we run our
    code with this argument, let''s first understand the output format.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '`XX:+PrintCompilation` produces a log list of parameters separated by blank
    spaces in the following format:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here is an example snapshot of the output:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – Print compilation log format'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_2.04.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.4 – Print compilation log format
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at what these parameters mean:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '`Timestamp`: This is the time in milliseconds since JVM started.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CompilationID`: This is an internal identification number used by JVM in the
    compilation queue. This will not necessarily be in a sequence, as there are background
    compilation threads that might reserve some of the IDs.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Flags`: The compiler flags are very important parameters that are logged.
    This suggests what attributes are applied by the compiler. JVM prints a comma-separated
    string of five possible characters to indicate five different attributes that
    are applied to the compiler. If none of the attributes are applied, it is shown
    as a blank string. The five attributes are as follows:'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Flags`：编译器标志是非常重要的参数，会被记录下来。这表明编译器应用了哪些属性。JVM打印出五个可能的字符的逗号分隔字符串，以指示应用给编译器的五个不同属性。如果没有应用任何属性，则显示为空字符串。这五个属性如下：'
- en: a. `%` character. OSR is explained earlier in this section. This attribute suggests
    that an OSR compilation is triggered as the method is looping over a large loop.
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. `%` 字符。OSR在本节前面已解释。此属性表明，当方法在大循环中循环时，会触发OSR编译。
- en: b. `!` character. This indicates that the method has an exception handler.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. `!` 字符。这表示该方法有一个异常处理器。
- en: c. `s` character. This indicates that the method is synchronized.
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. `s` 字符。这表示该方法被同步。
- en: d. `b` character. This indicates that the compilation occurred in blocking mode.
    This means that the compilation did not happen in the background.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d. `b` 字符。这表示编译是在阻塞模式下进行的。这意味着编译没有在后台进行。
- en: e. `n` character. This indicates that the code is compiled to the native method.
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: e. `n` 字符。这表示代码被编译为本地方法。
- en: '`Tier`: This indicates which tier of compilation is performed. Refer to the
    *Tiered compilation* section for more details.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Tier`：这表示执行了哪个编译层。有关更多详细信息，请参阅*分层编译*部分。'
- en: '`MethodName`: This column lists the method that is being compiled.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MethodName`：此列列出正在编译的方法。'
- en: '`MethodSize`: This is the size of the method.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MethodSize`：这是方法的大小。'
- en: '`Deoptimization performed`: This shows any de-optimizations that may be performed.
    We will discuss this in detail in the next section.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Deoptimization performed`：这显示了可能执行的任何去优化。我们将在下一节中详细讨论。'
- en: Tiered compilation
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分层编译
- en: In the previous chapter, we briefly covered compilation tiers/levels. In this
    section, we will go into more details. Client compilers kick in early when the
    compiler threshold is reached. The server compiler kicks in based on the profiling.
    The recent versions of JVM use a combination of both compilers for optimum performance.
    However, the user can specifically use one of the compilers with the `-client`,
    `-server`, or `-d64` arguments. The default behavior of JVM is to use tiered compilation,
    which is the most optimum JIT compilation. With tiered compilation, the code is
    first compiled by the client compiler and, based on the profiling, if the code
    gets hotter (hence the name HotSpot), the server compiler kicks in and recompiles
    the code. This process was explained in the previous section by means of the flowchart.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们简要介绍了编译层/级别。在本节中，我们将更详细地介绍。当达到编译器阈值时，客户端编译器会提前启动。服务器编译器基于分析启动。JVM的最新版本使用两种编译器的组合来实现最佳性能。然而，用户可以使用
    `-client`、`-server` 或 `-d64` 参数专门使用其中一个编译器。JVM的默认行为是使用分层编译，这是最优化JIT编译。在分层编译中，代码首先由客户端编译器编译，然后根据分析，如果代码变得更热（因此得名HotSpot），服务器编译器启动并重新编译代码。这个过程在上一节中通过流程图进行了说明。
- en: Tiered compilation brings in more optimization as the code gets complicated
    and runs for longer. There are instances where JIT compilation runs more optimally
    and faster than AOT compilation. While AOT compilation brings in optimization,
    during the build phase, it does not have the intelligence to optimize/deoptimize
    itself based on runtime profiling. Runtime profiling, optimizing, and deoptimizing
    are the key advantages of JIT compilation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 分层编译随着代码的复杂化和运行时间的增加而引入了更多的优化。有些情况下，即时编译（JIT）比静态编译（AOT）运行得更优化且更快。虽然AOT编译引入了优化，但在构建阶段，它没有根据运行时分析来自动优化/去优化的智能。运行时分析、优化和去优化是JIT编译的关键优势。
- en: 'There are three versions of JIT compilers:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种JIT编译器的版本：
- en: '`-client` argument:'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-client` 参数：'
- en: '[PRE3]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`long` or `double` variables. This version of the compiler can be explicitly
    invoked using the `-server` argument.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`long` 或 `double` 变量。这种编译器版本可以使用 `-server` 参数显式调用。'
- en: '`-d64` argument.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-d64` 参数。'
- en: Server compilers are up to 4x slower in compiling than client compilers. However,
    they do generate a faster running application (up to 2x).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器编译器在编译速度上比客户端编译器慢4倍。然而，它们确实生成了运行速度更快的应用程序（高达2倍）。
- en: 'There are five tiers/levels of compilation levels as listed next. A compilation
    log can be used to find which method was compiled to what level, by means of compilation
    print:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如下列出的有五个编译层级/级别。可以通过编译日志使用编译打印来查找哪些方法被编译到哪个级别。
- en: '**Level 0 – Interpreted code**: This the standard interpreter mode, where the
    JIT is still not activated. The JIT gets activated based on the compilation threshold.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Level 0 – 解释代码**：这是标准的解释器模式，其中JIT尚未激活。JIT的激活基于编译阈值。'
- en: '**Level 1 – Simple C1 compiled code**: This is a basic no-profile compilation
    of the code. The compiled code will not have any instrumentation.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Level 1 – 简单C1编译代码**：这是代码的基本无配置编译。编译后的代码将没有任何配置。'
- en: '**Level 2 – Limited C1 compiled code**: In this level, basic counters are instrumented.
    The counter will help JVM decide to move to the next level, L2\. Sometimes, when
    the C2 compiler is busy, JVM will use this level as an intermediate before promotion
    to Level 3.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Level 2 – 有限C1编译代码**：在这个级别，基本的计数器被配置了。这个计数器将帮助JVM决定是否移动到下一个级别，即L2。有时，当C2编译器忙碌时，JVM会使用这个级别作为提升到Level
    3的中间步骤。'
- en: '**Level 3 – Full C1 compiled code**: In this level, the code is fully instrumented
    and profiled. This detailed profiling will help decide further optimization with
    L4\. This level adds up to 25-30% of overhead to the compiler and performance.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Level 3 – 完整C1编译代码**：在这个级别，代码被完全配置和配置。这种详细的配置将有助于决定L4的进一步优化。这个级别给编译器增加了25-30%的开销，并影响了性能。'
- en: '**Level 4 – C2 compiled code**: This is the most optimized compilation of the
    code, where all the optimization is applied. However, while profiling, if JVM
    finds that the context of optimization has changed, it will deoptimize and replace
    the code with L0 or L1 (for trivial methods).'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Level 4 – C2编译代码**：这是代码的最优化编译，其中应用了所有优化。然而，在配置时，如果JVM发现优化上下文已更改，它将取消优化，并用L0或L1（对于简单方法）替换代码。'
- en: 'Let''s now look at how the Java HotSpot compiler performs tiered compilation.
    The following diagram shows the various tiers and flow patterns of compilation:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看Java HotSpot编译器如何执行分层编译。以下图表显示了编译的各种层级和流程模式：
- en: '![Figure 2.5 – Tiered compilation patterns'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 2.5 – 分层编译模式'
- en: '](img/B16878_Figure_2.05.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16878_Figure_2.05.jpg]'
- en: Figure 2.5 – Tiered compilation patterns
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5 – 分层编译模式
- en: 'Let''s understand what each flow indicates:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解每个流程表示的含义：
- en: '**A**: This is the normal pattern of how JVM works. All the code starts with
    L0 and escalates to L3 when the compilation threshold is reached. At L3, the code
    is compiled with complete detailed profiling instrumentation. The code is then
    profiled at runtime, when it reaches the threshold, and then the code is re-compiled
    with the C2 compiler (L4), with maximum optimization. C2 compilers require detailed
    data regarding the control flow so as to take decisions concerning optimization.
    Later in this section, we will walk through all the optimizations that the C2
    compiler (JIT) performs. It is possible, however, that the optimizations are invalid,
    due to changes in the flows or the context of optimization. In this case, JVM
    will deoptimize and bring it back to L0.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**A**：这是JVM的正常工作模式。所有代码都从L0开始，当达到编译阈值时升级到L3。在L3，代码会进行完整的详细配置的配置。然后，当代码达到阈值时，在运行时进行配置，然后使用C2编译器（L4）重新编译代码，进行最大优化。C2编译器需要有关控制流的大量数据，以便做出优化决策。在本节的后面部分，我们将详细介绍C2编译器（JIT）执行的优化。然而，由于流程或优化上下文的变化，优化可能是无效的。在这种情况下，JVM将取消优化，并将其返回到L0。'
- en: '**B: C2 Busy**: C2 compilation is performed on a separate compilation thread
    and the compilation activities are queued. When the compilation threads are all
    busy, JVM will not follow the normal flow, as this may affect the overall performance
    of the application. Instead, JVM will escalate to L2, where at least the counters
    are instrumented, and at a later point, when the code reaches the higher threshold,
    it will escalate to L3 and L4\. At any point, JVM can deoptimize or invalidate
    the compiled code.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**B: C2忙碌**：C2编译是在单独的编译线程上执行的，编译活动被排队。当所有编译线程都忙碌时，JVM不会遵循正常流程，因为这可能会影响应用程序的整体性能。相反，JVM将升级到L2，至少计数器被配置了，稍后，当代码达到更高的阈值时，它将升级到L3和L4。在任何时候，JVM都可以取消优化或使编译代码无效。'
- en: '**C: Trivial Code**: Sometimes, JVM will compile the code to L3 and realize
    that the code does not require any optimization, as it is very straightforward/simple,
    based on the profiling. In this case, it will bring it down to L1\. That way,
    the execution of the code will be faster. The more we instrument the code, the
    more overhead we are putting on the execution. It is typically observed that L3
    adds anywhere between 20-30% overhead to execution, due to instrumentation code.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C: 简单代码**：有时，JVM 会将代码编译到 L3，并意识到代码不需要任何优化，因为它非常直接/简单，基于分析。在这种情况下，它会将其降低到
    L1。这样，代码的执行速度会更快。我们越是对代码进行仪器化，对执行就越多的开销。通常观察到 L3 会给执行增加 20-30% 的开销，这是由于仪器化代码造成的。'
- en: 'We can look at how JVM behaves using the `-XX:+PrintCompilation` option. Here
    is an example of a normal flow:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `-XX:+PrintCompilation` 选项来查看 JVM 的行为。以下是一个正常流程的示例：
- en: '[PRE4]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'For this code, when we execute `java` with `-XX:+PrintCompilation`, the following
    log is generated on the console. The log can be redirected to a log file using
    the `+LogCompilation` flag:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此代码，当我们使用 `-XX:+PrintCompilation` 执行 `java` 时，控制台会生成以下日志。日志可以通过使用 `+LogCompilation`
    标志重定向到日志文件：
- en: '![Figure 2.6 – Log showing tiered compilation'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.6 – 显示分层编译的日志'
- en: '](img/B16878_Figure_2.06.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16878_Figure_2.06.jpg)'
- en: Figure 2.6 – Log showing tiered compilation
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6 – 显示分层编译的日志
- en: 'In this screenshot, you can see how the `main()` method moves from L0->L3->L4,
    which is the normal flow (A). As JVM performs optimizations and de-optimizations,
    jumping between these various levels of compilation, it reaches the most optimum,
    stable point. This is one of the greatest advantages that JIT compilers have over
    AOT compilers. The JIT compiler uses the runtime behavior to optimize the code
    execution (not just the semantic/static code optimizations). If you run this with
    JITWatch, we can see a clearer representation. The following screenshot shows
    the JITWatch tool compile chain when we run it by the `Sample.java` snippet:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个屏幕截图中，你可以看到 `main()` 方法是如何从 L0->L3->L4 移动的，这是正常流程（A）。当 JVM 进行优化和去优化，在这些不同的编译级别之间跳跃时，它会达到最优化、最稳定的状态。这是
    JIT 编译器相对于 AOT 编译器的最大优势之一。JIT 编译器使用运行时行为来优化代码执行（不仅仅是语义/静态代码优化）。如果你使用 JITWatch
    运行它，我们可以看到更清晰的表示。以下屏幕截图显示了当我们通过 `Sample.java` 碎片运行 JITWatch 工具时的编译链：
- en: '![Figure 2.7 – JITWatch tiered compilation'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.7 – JITWatch 分层编译'
- en: '](img/B16878_Figure_2.07.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16878_Figure_2.07.jpg)'
- en: Figure 2.7 – JITWatch tiered compilation
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7 – JITWatch 分层编译
- en: 'The previous screenshot shows that `Sample::main()` is compiled with the C1-L3
    compiler. `Sample::Sample()` (default constructor) is inlined and `Sample::performOperation()`
    is also inlined into `Sample::main()`. `Sample::performAnotherOperation()` is
    also compiled. This is the first level of optimization:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 上一张屏幕截图显示 `Sample::main()` 是用 C1-L3 编译器编译的。`Sample::Sample()`（默认构造函数）被内联，`Sample::performOperation()`
    也被内联到 `Sample::main()` 中。`Sample::performAnotherOperation()` 也被编译。这是第一个优化级别：
- en: '[PRE5]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following screenshot shows how various compilers are run on each of the
    methods:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图显示了各种编译器是如何在每个方法上运行的：
- en: '![Figure 2.8 – JITWatch tiered compilation of main()'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.8 – JITWatch 对 main() 的分层编译'
- en: '](img/B16878_Figure_2.08.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16878_Figure_2.08.jpg)'
- en: Figure 2.8 – JITWatch tiered compilation of main()
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.8 – JITWatch 对 main() 的分层编译
- en: 'This screenshot shows how the `main()` method is optimized. Since the `main()`
    method has a long loop, OSR has occurred two times: once when the C1 compiled
    code is replaced, and the second time when the C2 compiled code is replaced. In
    each case, it has performed inlining. You can see what optimizations the C1 and
    C2 compilers performed in the following screenshot:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这张屏幕截图显示了 `main()` 方法的优化。由于 `main()` 方法有一个长循环，发生了两次 OSR：一次是在 C1 编译代码被替换时，第二次是在
    C2 编译代码被替换时。在每种情况下，它都进行了内联。你可以在以下屏幕截图中看到 C1 和 C2 编译器执行了哪些优化：
- en: '![Figure 2.9 – JITWatch tiered compilation of main() – OSR-L3'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.9 – JITWatch 对 main() 的分层编译 – OSR-L3'
- en: '](img/B16878_Figure_2.09.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16878_Figure_2.09.jpg)'
- en: Figure 2.9 – JITWatch tiered compilation of main() – OSR-L3
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.9 – JITWatch 对 main() 的分层编译 – OSR-L3
- en: 'In the previous screenshot, we can see that `Sample::performAnotherOperation()`
    is compiled and `Sample::performOperation()` is inlined into `Sample::main()`.
    The following screenshot shows further optimization that is performed by inlining
    `Sample:performAnotherOperation()` into `Sample::performOperation()`:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一张截图中，我们可以看到 `Sample::performAnotherOperation()` 被编译，而 `Sample::performOperation()`
    被内联到 `Sample::main()` 中。下一张截图显示了将 `Sample:performAnotherOperation()` 内联到 `Sample::performOperation()`
    中所执行的进一步优化。
- en: '![Figure 2.10 – JITWatch tiered compilation of main() – OSR-L4'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 2.10 – JITWatch 分层编译 main() – OSR-L4'
- en: '](img/B16878_Figure_2.10.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16878_Figure_2.10.jpg]'
- en: Figure 2.10 – JITWatch tiered compilation of main() – OSR-L4
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.10 – JITWatch 分层编译 main() – OSR-L4
- en: 'Let''s now look at how the JIT compiler optimizes the S`ample::performAnotherOperation()`
    method:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看 JIT 编译器是如何优化 `Sample::performAnotherOperation()` 方法的：
- en: '![Figure 2.11 – JITWatch tiered compilation of performAnotherOperation()'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 2.11 – JITWatch 分层编译 performAnotherOperation()'
- en: '](img/B16878_Figure_2.11.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16878_Figure_2.11.jpg]'
- en: Figure 2.11 – JITWatch tiered compilation of performAnotherOperation()
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11 – JITWatch 分层编译 performAnotherOperation()
- en: As we can see in the previous screenshot, `Sample::performAnotherOperation()`
    has gone through various optimizations and OSRs, as it runs a long loop. The code
    is inlined into `Sample::performOperation()` as it hits the compiler threshold.
    The following screenshots reveal how `Sample::performAnotherOperation()` is compiled
    and inlined into `Sample::performOperation()`.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一张截图所示，`Sample::performAnotherOperation()` 由于运行了长时间的循环，已经经历了各种优化和 OSR。当它达到编译器阈值时，代码被内联到
    `Sample::performOperation()` 中。以下截图揭示了 `Sample::performAnotherOperation()` 的编译和内联过程。
- en: 'Let''s now look at how the JIT compiler compiles the `Sample::performOperation()`
    method:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看 JIT 编译器是如何编译 `Sample::performOperation()` 方法的：
- en: '![Figure 2.12 – JITWatch tiered compilation of performOperation()'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 2.12 – JITWatch 分层编译 performOperation()'
- en: '](img/B16878_Figure_2.12.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16878_Figure_2.12.jpg]'
- en: Figure 2.12 – JITWatch tiered compilation of performOperation()
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.12 – JITWatch 分层编译 performOperation()
- en: 'The following screenshot shows the C1 compilation chain view for the `performOperation()`
    method:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了 `performOperation()` 方法的 C1 编译链视图：
- en: '![Figure 2.13 – JITWatch tiered compilation of performOperation() – C1 compilation
    chain view'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 2.13 – JITWatch 分层编译 performOperation() – C1 编译链视图'
- en: '](img/B16878_Figure_2.13.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16878_Figure_2.13.jpg]'
- en: Figure 2.13 – JITWatch tiered compilation of performOperation() – C1 compilation
    chain view
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.13 – JITWatch 分层编译 performOperation() – C1 编译链视图
- en: 'The previous screenshot shows that `Sample::performAnotherOperation()` is compiled
    as it hits the compiler threshold, and the following screenshot shows that the
    compiled code is inlined into `Sample::performOperation()`:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 上一张截图显示，当 `Sample::performAnotherOperation()` 达到编译器阈值时，它被编译，下一张截图显示编译后的代码被内联到
    `Sample::performOperation()` 中：
- en: '![Figure 2.14 – JITWatch tiered compilation of performOperation() – C2 compilation
    chain view'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 2.14 – JITWatch 分层编译 performOperation() – C2 编译链视图'
- en: '](img/B16878_Figure_2.14.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16878_Figure_2.14.jpg]'
- en: Figure 2.14 – JITWatch tiered compilation of performOperation() – C2 compilation
    chain view
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.14 – JITWatch 分层编译 performOperation() – C2 编译链视图
- en: JITWatch can be used to gain detailed understanding of how the C1 an C2 compilers
    behave, and how the optimizations are performed. This helps in reflecting on the
    application code, and proactively updating the source code for better runtime
    performance. To get a better understanding of how the C2 compiler optimizes the
    code, let's now look at the various types of code optimizations that JVM applies
    during compilation.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: JITWatch 可以用来深入了解 C1 和 C2 编译器的行为以及优化是如何进行的。这有助于反思应用程序代码，并主动更新源代码以获得更好的运行时性能。为了更好地理解
    C2 编译器如何优化代码，现在让我们看看 JVM 在编译过程中应用的各类代码优化。
- en: Understanding the optimizations performed by JIT
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 JIT 执行的优化
- en: This section will cover the various optimization techniques that the JIT compilers
    employ at the various levels of compilation.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍 JIT 编译器在编译的各个级别上采用的各类优化技术。
- en: Inlining
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内联
- en: Calling a method is an expensive operation for JVM. When the program calls a
    method, JVM has to create a new stack frame for that method, copy all the values
    into the stack frame, and execute the code. Once the method completes, the stack
    frame has to be managed post-execution. One of the best practices in object-oriented
    programming is to access the object members through access methods (getters and
    setters).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Inlining is one of the most effective optimizations performed by JVM. JVM replaces
    the method call with the actual content of the code.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'If we run our previous code with the following command, we can see how JVM
    performs inlining:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In this case, the call to the `performOperation()` method is replaced with
    the content of the inline `main()` method. After inlining effectively, the `main()`
    method will look like this:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Inlining can be disabled using the `-XX:-Inline` flag.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: JVM decides to inline the code, based on the number of calls made to the method
    and the size of the method, and if the method is frequently called (hot), and
    the size of the method is <325 bytes. Methods that are <35 bytes are inlined by
    default. These numbers can be changed with the `-XX:+MaxFreqInlineSize` and `-XX:+MaxInlineSize`
    flags from the command line, respectively.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Monomorphic, bimorphic, and megamorphic dispatch
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Polymorphism is one of the key object-oriented concepts that provides a way
    to dynamically load classes based on a context, and the behavior is decided dynamically.
    Interfaces and inheritance are two of the most widely used polymorphism implementations.
    However, this comes with a performance overhead, as JVM loads the class/interface
    implementations dynamically. Inlining the implementations becomes a challenge.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: One of the things that JVM profiles is the number of times a particular implementation
    is called and how many derived class/interface implementations really exist for
    a given base class or interface. If the profiler identifies only one implementation,
    then it's called monomorphic. If it finds two, then it's called bimorphic, and
    megamorphic means there are multiple implementations.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the profiling, the JIT compiler identifies which specific derived
    class object (or interface implementation) is used and takes the decision on inlining
    that specific implementation, to overcome the performance overheads of polymorphism.
    Monomorphic and bimorphic are easy to inline. The JIT profiler tracks the execution
    paths and identifies in which context which implementation is used and performs
    inlining. Megamorphic implementations are complex to inline. The following code
    snippet shows polymorphism. We will use this code to understand the performance
    overhead:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the previous code, we have defined an interface called `Shape`, and we have
    three implementations of the interface, namely, `Circle`, `Square`, and `Triangle`.
    And, we are using a switch to initialize the right class. There are two optimization
    scenarios here:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: If the JIT knows that a particular implementation is used, it optimizes the
    code and might perform an inline. This is called a monomorphic dispatch.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If, let's say, the decision is to be taken based on a particular variable or
    a configuration, JIT will profile, which is the most optimistic assumption it
    can take, and only those classes and inline them, and may also use an uncommon
    trap. In case the implementation class that is used is different from what is
    assumed, the JIT will deoptimize.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dead code elimination
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The JIT compiler identifies the code that is never executed or not required
    while profiling. This is called dead code, and the JIT compiler eliminates this
    from the execution. Modern IDEs identify dead code; this is purely based on the
    static code analysis performed. JIT compilers not only eliminate such trivial
    code, but also eliminate the code based on the control flow at runtime. Dead code
    elimination is one of the most effective ways to improve performance.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take the following code as an example:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In this code, the `calculateSomething()` method has some logic. Let's look at
    the previous code snippet. The `finalTotalValue` variable is initialized and later,
    the total is calculated by calling the `calculateValue()` method in a loop, but
    assuming that `finalTotalValue` is never used after calculation. The initialization
    code, the array heap allocation code, and the loop that calls the `calculateValue()`
    method, are all dead code. JIT understands this at runtime and removes it completely.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: JIT takes these decisions based on profiling and whether the code is reachable.
    It might remove unnecessary `if` statements (especially null checks; if the object
    is never seen to be null – this technique is sometimes referred to as Null Check
    Elimination). It will replace this with what is called "uncommon trap" code. If
    this execution ever reaches this trap code, it will then deoptimize.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Another case where "uncommon trap" code is placed by eliminating the code is
    by predicting branches. Based on the profiling, JIT assumes and predicts a branch
    code (`if`, `switch`, and so on) that may never be executed, and eliminates that
    code.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Common Subexpression Elimination is another effective technique that JIT uses
    to eliminate code. In this technique, an intermediate subexpression is removed
    to save the number of instructions.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Later, in the *Escape analysis* section, we will also see some code elimination
    techniques, based on the escape analysis that JIT performs.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Loop optimization – Loop unrolling
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Loop unrolling is another effective optimization technique. This is more effective
    in smaller loop body and large number of iterations. The technique involves looking
    to reduce the iterations in the loop by replacing the code. Here is a very simple
    example:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This can be rolled into the following:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In this example, the JIT compiler decides to reduce the iterations by 1/4, by
    calling `somefunction()` four times instead of once. This has a significant performance
    improvement, as the number of jump statements goes down by 1/4\. Of course, the
    decision on four is taken based on the size of the array so that the array reference
    does not go out of bounds.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Escape analysis
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Escape analysis is one of the most advanced optimizations that the JIT compiler
    performs. This is controlled with the `-XX:+DoEscapeAnalysis` flag from the command
    line. This is enabled by default.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, we went through the various memory areas in the *Memory
    subsystem* section. Heap and stack are two of the most important memory areas.
    The heap memory area is accessible across various threads in JVM. A heap is not
    thread-safe. When multiple threads access the data that is stored in the heap,
    it is recommended to write thread-safe code by obtaining synchronization locks.
    This blocks the other threads from accessing the same data. This has performance
    implications.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Stack memory is thread-safe, as it is allocated for that particular method call.
    Only the method thread has access to this area, hence there is no need to worry
    about obtaining synchronization locks or the absence of blocking threads.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: The JIT compiler performs a detailed analysis of the code to identify code where
    we are allocating variables in the heap, but only using them in a specific method
    thread, and takes decisions on allocating these variables to the "stack area"
    instead of the "heap area." This is one of the most complex optimizations that
    JIT compilers perform and has a huge impact on performance. JIT might decide to
    store the variables in PC registers for even faster access.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: JIT also looks for the use of `synchronized` and tracks. If it's called by a
    single thread, JIT decides to ignore `synchronized`. This has a significant impact
    on performance. `StringBuffer` is one of the objects that is thread-safe and has
    a lot of synchronized methods. If an instance of `StringBuffer` is not used outside
    a single method, JIT decides to ignore `synchronized`. This technique is sometimes
    referred to as "lock elision."
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'In cases where a synchronized lock cannot be ignored, the JIT compiler looks
    to combine the `synchronized` blocks. This technique is known as lock coarsening.
    This technique looks for subsequent `synchronized` blocks. Here is an example:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this example, two subsequent synchronized blocks are trying to obtain a lock
    on the same class. The JIT compiler will combine these two blocks into one.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: 'JIT performs a similar analysis for variables that are created with a loop
    and never used outside the loop. There is a very sophisticated technique called
    "scalar replacement," where the JIT profiles for objects that are created, but
    only a few member variables are used in the object that is not used. JIT will
    decide to stop creating the objects and replace them with the member variables
    directly. Here is a very simple example:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The `StateStoring` class is a simple class, where we are storing the state of
    an object with two members – `state_variable_1` and `state_variable_2`. JIT profiles
    this for various iterations and checks whether this object was created and never
    used outside the scope. It might decide not to even create the object, instead
    replacing the object getters and setters with actual scalars (local variables).
    That way, entire object creation and destruction (which is a very expensive process)
    can be avoided.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a more advanced example, and this time let''s see how JITWatch shows
    the escape analysis:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this code snippet, the `allocateObjects()` method is creating an array (on
    the heap) and adding that value to the array. The `dummyInt` variable's scope
    is limited to the `for` loop in the `allocateObjects()` method. There is no need
    to have these objects created in the heap. After performing the escape analysis,
    JIT identifies that these variables can be put in a stack frame instead.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: 'The following JITWatch screenshot demonstrates this:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.15 – JITWatch escape analysis – 1'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_2.15.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.15 – JITWatch escape analysis – 1
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: 'In this screenshot, the bytecode that allocates `dummyInt` is struck off to
    indicate that heap allocation for that variable is not required:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.16 – JITWatch escape analysis – 2'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_2.16.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.16 – JITWatch escape analysis – 2
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: The previous screenshot shows the optimization that is performed by C2/Level
    4, where it removes allocation of the variable.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Deoptimization
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we looked at various optimization techniques that the
    JIT compiler performs. The JIT compiler optimizes the code with some assumptions
    that it makes, based on the profiling. Sometimes, these assumptions may be not
    correct in a different context. When JIT stumbles upon these scenarios, it deoptimizes
    the code and goes back to using an interpreter to run the code. This is called
    Deoptimization and has an impact on performance.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two scenarios where Deoptimization occurs:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: When the code is "non-entrant"
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the code is "zombie"
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's understand these scenarios with the help of examples.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Non-entrant code
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two cases where the code becomes non-entrant:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '`-XX:+PrintCompilation` flag.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Sample.java`:'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 2.17 – Tiered compilation escalation'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16878_Figure_2.17.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.17 – Tiered compilation escalation
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding screenshot, we can see the tiered compilation in action (the
    third column shows the tier number) and the optimization that is done.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Zombie code
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In most cases, some objects are created in the heap of the code that is marked
    as non-entrant. Once the GC reclaims all these objects, then JVM will mark the
    methods of those classes as zombie code. JVM then removes this compiled zombie
    code from the code cache. As we discussed in the *Taking a deep dive into hotspot
    and the C2 JIT* section, it's very important to keep the code cache optimum, as
    this has a significant impact on performance.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: As we saw in tiered compilation, deoptimization is performed when any of the
    assumptions that the Java JIT made is challenged by the control flow at runtime.
    In the next section, we will briefly introduce the Graal JIT compiler, and how
    it plugs into JVM.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Graal JIT and the JVM Compiler Interface (JVMCI)
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous sections, as we walked through the various features and advancements
    that JIT compilers underwent, it is very clear that C2 is very sophisticated.
    However, C2 compiler implementation has its downsides. C2 is implemented in the
    C/C++ language. While C/C++ is fast, it is not type-safe and it does not have
    garbage collection. Hence, the code becomes very complex. C2 implementation is
    very complex, as it has become more and more complex to change the code for new
    enhancements and bug fixes.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: In the meantime, Java has matured to run as fast as C/C++ in many cases. Java
    is type-safe with garbage collection. Java is simpler and easier to manage than
    C/C++. The key advantages of Java are its exception handling capabilities, memory
    management, better IDE/profiling, and tooling support. The JIT compiler is nothing
    but a program that takes in a bytecode, `byte[]`, optimizes it, compiles it, and
    returns an array of machine code, `byte[]`. This can easily be implemented in
    Java. What we need is a JVM interface that can provide the protocol for implementing
    the custom compiler logic. This will help open up JVM for the new implementations
    of JIT compilers.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: JDK enhancement proposal JEP243 ([https://openjdk.java.net/jeps/243](https://openjdk.java.net/jeps/243))
    is a proposal to provide a compiler interface that will enable writing a compiler
    in Java and extending JVM to use it dynamically.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: 'JEP243 was added in Java 9\. This is one of the most significant enhancements
    to JVM. JVMCI is an implementation of JEP243\. JVMCI provides the required extensibility
    to write our own JIT compilers. JVMCI provides the API that is required to implement
    custom compilers and configure JVM to call these custom compiler implementations.
    The JVMCI API provides the following capabilities:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Access to VM data structures, which is required to optimize the code
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing the compiled code following optimization and deoptimization
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Callbacks from JVM to execute the compilation at runtime
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A JVMCI can be executed with the following command-line flags:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Graal is an implementation of JVMCI, which brings all the key features and
    optimizations that are required for a modern Java runtime. Graal is wholly implemented
    in Java. Graal is much more than just a JIT compiler. Here is a quick comparison
    between the Graal JIT and the JVM JIT (C2):'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16878_Table_2.1.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
- en: The next chapter will go into more detail on Graal architecture, and [*Chapter
    4*](B16878_04_Final_SK_ePub.xhtml#_idTextAnchor077), *Graal Just-In-Time Compiler*,
    will go deeper into how Graal JIT works, and how it builds on top of Java JIT
    and brings in more advanced optimizations and support for Polyglot.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we went into a lot of detail on how the JIT compiler works
    and discussed the tiered compilation patterns that JVM uses to optimize the code.
    We also walked through various optimization techniques with a number of sample
    code examples. This provided a good understanding of the internal workings of
    JVM.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: JVMCI provides the extensibility to build custom JIT compilers on JVM. Graal
    JIT is an implementation of JVMCI.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: This chapter provided the basis for understanding how JVM works, and how JIT
    compilation optimizes the code at runtime. This is key in understanding how the
    Graal JIT compiler works.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will understand how the Graal VM architecture is built
    on the JVM architecture, and how it extends it to support Polyglot.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is a code cache?
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the various flags that can be used to optimize a code cache?
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the compiler threshold?
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is on-stack replacement?
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is tiered compilation? What are the various patterns of tiered compilation?
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is inlining?
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is monomorphic dispatch?
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is loop unrolling?
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is escape analysis?
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is Deoptimization?
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is JVMCI?
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Introduction to JVM Languages* ([https://www.packtpub.com/product/introduction-to-jvm-languages/9781787127944](https://www.packtpub.com/product/introduction-to-jvm-languages/9781787127944))'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Java SDK documentation ([https://docs.oracle.com](https://docs.oracle.com))
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GraalVM documentation ([https://docs.oracle.com/en/graalvm/enterprise/19/guide/overview/compiler.html](https://docs.oracle.com/en/graalvm/enterprise/19/guide/overview/compiler.html))
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JITWatch documentation ([https://github.com/AdoptOpenJDK/jitwatch](https://github.com/AdoptOpenJDK/jitwatch))
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
