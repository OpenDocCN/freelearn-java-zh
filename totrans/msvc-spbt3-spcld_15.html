<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer358" class="Basic-Text-Frame">
    <h1 class="chapterNumber">15</h1>
    <h1 id="_idParaDest-376" class="chapterTitle">Introduction to Kubernetes</h1>
    <p class="normal">In this chapter, we will start to learn about Kubernetes, the most popular and widely used container orchestrator at the time of writing this book. Since the subjects on container orchestrators in general and Kubernetes itself are too big to be covered in one chapter, I will focus on introducing the areas that I have found to be the most important in my use of Kubernetes over the last few years.</p>
    <p class="normal">The following topics will be covered in this chapter:</p>
    <ul>
      <li class="bulletList">Introducing Kubernetes concepts</li>
      <li class="bulletList">Introducing Kubernetes API objects</li>
      <li class="bulletList">Introducing Kubernetes runtime components</li>
      <li class="bulletList">Creating a local Kubernetes cluster</li>
      <li class="bulletList">Trying out a sample Deployment and getting used to the <code class="inlineCode">kubectl</code> Kubernetes CLI tool</li>
      <li class="bulletList">Managing a local Kubernetes cluster</li>
    </ul>
    <h1 id="_idParaDest-377" class="heading-1">Technical requirements</h1>
    <p class="normal">For instructions on how to install the tools used in this book and how to access the source code for this book, see:</p>
    <ul>
      <li class="bulletList"><em class="chapterRef">Chapter 21</em>, <em class="italic">Installation Instructions for macOS</em></li>
      <li class="bulletList"><em class="chapterRef">Chapter 22</em>, <em class="italic">Installation Instructions for Microsoft Windows with WSL 2 and Ubuntu</em></li>
    </ul>
    <p class="normal">The code examples in this chapter all come from the source code in <code class="inlineCode">$BOOK_HOME/Chapter15</code>. The source code for the sample Deployment on Kubernetes that will be performed in this chapter can be found in the folder <code class="inlineCode">$BOOK_HOME/Chapter15/kubernetes/first-attempts</code>.</p>
    <h1 id="_idParaDest-378" class="heading-1">Introducing Kubernetes concepts</h1>
    <p class="normal">At a high level, as a container orchestrator, Kubernetes<a id="_idIndexMarker1008"/> makes a cluster of (physical or virtual) servers that runs containers appear to be one big logical server running containers. </p>
    <p class="normal">As an operator, we declare a <strong class="keyWord">desired state</strong> to the Kubernetes cluster<a id="_idIndexMarker1009"/> by creating objects using the Kubernetes API. Kubernetes continuously compares the desired state with the current state. If it detects differences, it takes action to ensure that the current state is the same as the desired state.</p>
    <p class="normal">One of the main purposes of a Kubernetes cluster is to deploy and run containers, but also to support zero-downtime rolling upgrades using techniques such as green/blue and canary Deployments. Kubernetes <a id="_idIndexMarker1010"/>can schedule containers, that is, <strong class="keyWord">Pods</strong> that contain one or more co-located containers, to the available nodes in the cluster. To be able to monitor the health of running containers, Kubernetes<a id="_idIndexMarker1011"/> assumes that containers implement a <strong class="keyWord">liveness probe</strong>. If a liveness probe reports an unhealthy container, Kubernetes will restart the container. Containers can be scaled in the cluster manually or automatically using a horizontal autoscaler. To optimize the use of the available hardware resources in a cluster, for example, memory and CPU, containers<a id="_idIndexMarker1012"/> can be configured with <strong class="keyWord">quotas</strong> that specify the amount of resources a container needs. On the other hand, limits regarding how much a container is allowed to consume can be specified on the Pod<a id="_idIndexMarker1013"/> or for a group of Pods at the <strong class="keyWord">namespace</strong> level. Namespaces will be introduced as we proceed through this chapter. This is of extra importance if several teams share a common Kubernetes cluster.</p>
    <p class="normal">Another main purpose of Kubernetes is to provide Service discovery of the running Pods and their containers. Kubernetes <strong class="keyWord">Service</strong> objects<a id="_idIndexMarker1014"/> can be defined for Service discovery and will also load-balance incoming requests over the available Pods. Service objects can be exposed to the outside of a Kubernetes cluster. However, as we<a id="_idIndexMarker1015"/> will see, an <strong class="keyWord">Ingress</strong> object is, in many cases, better suited to handling externally incoming traffic to a group of Services. To help Kubernetes find out whether a container is ready to accept incoming<a id="_idIndexMarker1016"/> requests, a container can implement a <strong class="keyWord">readiness probe</strong>.</p>
    <p class="normal">Internally, a Kubernetes cluster provides one big flat IP network where each Pod gets its own IP address and can reach all the other Pods, independent of which node they run on. To support multiple network vendors, Kubernetes<a id="_idIndexMarker1017"/> allows the use of network plugins that comply with the <strong class="keyWord">Container Network Interface </strong>(<strong class="keyWord">CNI</strong>) specification (<a href="https://github.com/containernetworking/cni"><span class="url">https://github.com/containernetworking/cni</span></a>). Pods are not isolated by default; they accept all incoming requests. CNI plugins that support the use of network policy definitions can be used to lock down access to Pods, for example, only allowing traffic from Pods in the same namespace.</p>
    <p class="normal">To allow multiple<a id="_idIndexMarker1018"/> teams to work on the same<a id="_idIndexMarker1019"/> Kubernetes cluster in a safe way, <strong class="keyWord">Role-Based Access Control</strong> (<strong class="keyWord">RBAC</strong>, <a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/"><span class="url">https://kubernetes.io/docs/reference/access-authn-authz/rbac/</span></a>) can be applied. For example, administrators can be authorized to access resources at the cluster level, while the access of team members can be locked down to resources that are created in a namespace owned by the teams.</p>
    <p class="normal">In total, these concepts provide a platform<a id="_idIndexMarker1020"/> for running containers that is scalable, secure, highly available, and resilient.</p>
    <p class="normal">Let’s look a bit further into the API objects that are available in Kubernetes and, after that, the runtime components that make up a Kubernetes cluster.</p>
    <h1 id="_idParaDest-379" class="heading-1">Introducing Kubernetes API objects</h1>
    <p class="normal">Kubernetes defines an API<a id="_idIndexMarker1021"/> that is used to manage different types of <em class="italic">objects</em> or <em class="italic">resources</em>, as they are also known. Some of the most commonly used types, or <em class="italic">kinds</em>, as referred to in the API, are as follows:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Node</strong>: A node<a id="_idIndexMarker1022"/> represents a server, virtual <a id="_idIndexMarker1023"/>or physical, in the cluster.</li>
      <li class="bulletList"><strong class="keyWord">Pod</strong>: A Pod represents<a id="_idIndexMarker1024"/> the smallest possible<a id="_idIndexMarker1025"/> deployable component in Kubernetes, consisting of one or more co-located containers. The containers share the same IP address and port range. This means that containers in the same Pod instance can talk to each other over localhost, but need to be aware of potential port collisions. Typically, a Pod consists of one container, but there are use cases for extending the functionality of the main container by running the second container in a Pod. In <em class="chapterRef">Chapter 18</em>, <em class="italic">Using a Service Mesh to Improve Observability and Management</em>, a second container will be used in the Pods, running a sidecar that makes the main container join the Service mesh.</li>
      <li class="bulletList"><strong class="keyWord">Deployment</strong>: A Deployment is used to deploy<a id="_idIndexMarker1026"/> and upgrade Pods. The Deployment<a id="_idIndexMarker1027"/> objects hand over the responsibility of creating and monitoring the Pods to a ReplicaSet. When creating a Deployment for the first time, the work performed by the Deployment object is not much more than creating the ReplicaSet object. When performing a rolling upgrade of a Deployment, the role of the Deployment object is more involved.</li>
      <li class="bulletList"><strong class="keyWord">ReplicaSet</strong>: A ReplicaSet is used to ensure<a id="_idIndexMarker1028"/> that a specified number of Pods is running<a id="_idIndexMarker1029"/> at all times. If a Pod is deleted, it will be replaced with a new Pod by the ReplicaSet.</li>
      <li class="bulletList"><strong class="keyWord">Service</strong>: A Service is a stable network endpoint<a id="_idIndexMarker1030"/> that you can use to connect to one<a id="_idIndexMarker1031"/> or multiple Pods. A Service is assigned an IP address and a DNS name in the internal network of the Kubernetes cluster. The IP address of the Service will stay the same for the lifetime of the Service. Requests that are sent to a Service will be forwarded to one of the available Pods using round-robin-based load balancing. By default, a Service is only exposed inside the cluster using a cluster IP address. It is also possible to expose a Service outside the cluster, either on a dedicated port on each node in the cluster or – even better – through an external load balancer that is aware of Kubernetes; that is, it can automatically provision a public IP address and/or DNS name for the Service. Cloud providers that offer Kubernetes as a Service, in general, support this type of load balancer.</li>
      <li class="bulletList"><strong class="keyWord">Ingress</strong>: Ingress can manage external access<a id="_idIndexMarker1032"/> to Services in a Kubernetes<a id="_idIndexMarker1033"/> cluster, typically using HTTP or HTTPS. For example, it can route traffic to the underlying Services based on URL paths or HTTP headers such as the hostname. Instead of exposing a number of Services externally, either using node ports or through load balancers, it is, in general, more convenient to set up an Ingress in front of the Services. To handle the actual communication defined by the Ingress objects, an Ingress controller must be running in the cluster. We<a id="_idIndexMarker1034"/> will see an example of an Ingress controller as we proceed.</li>
      <li class="bulletList"><strong class="keyWord">Namespace</strong>: A namespace is used to group<a id="_idIndexMarker1035"/> and, on some levels, isolate resources<a id="_idIndexMarker1036"/> in a Kubernetes cluster. The names of resources must be unique in their namespaces, but not between namespaces.</li>
      <li class="bulletList"><strong class="keyWord">ConfigMap</strong>: A ConfigMap is used to store configuration<a id="_idIndexMarker1037"/> that’s used<a id="_idIndexMarker1038"/> by containers. ConfigMaps can be mapped into a running container as environment variables or files.</li>
      <li class="bulletList"><strong class="keyWord">Secret</strong>: This is used to store sensitive<a id="_idIndexMarker1039"/> data used by containers, such as credentials. Secrets<a id="_idIndexMarker1040"/> can be made available to containers in the same way as ConfigMaps. Anyone with full read access to the API server can access the values of created Secrets, so they are not as safe as the name might imply.</li>
      <li class="bulletList"><strong class="keyWord">DaemonSet</strong>: This ensures that one Pod<a id="_idIndexMarker1041"/> is running on each node in a set of nodes<a id="_idIndexMarker1042"/> in the cluster. In <em class="chapterRef">Chapter 19</em>, <em class="italic">Centralized Logging with the EFK Stack</em>, we will see an example of a log collector, Fluentd, that will run on each worker node as a DaemonSet.</li>
    </ul>
    <p class="normal">For a full list of resource objects<a id="_idIndexMarker1043"/> that the Kubernetes API covers in v1.26, see <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.26/"><span class="url">https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.26/</span></a>.</p>
    <p class="normal">The following diagram summarizes<a id="_idIndexMarker1044"/> the Kubernetes resources that are involved in handling incoming requests:</p>
    <figure class="mediaobject"><img src="../Images/B19825_15_01.png" alt="Diagram  Description automatically generated" width="812" height="523"/></figure>
    <p class="packt_figref">Figure 15.1: Overview of Kubernetes resources</p>
    <p class="normal">In the preceding diagram, we can see the following:</p>
    <ul>
      <li class="bulletList">Two Deployments, <strong class="keyWord">Deployment A</strong> and <strong class="keyWord">Deployment B</strong>, have been deployed to a cluster with two nodes, <strong class="keyWord">Node 1</strong> and <strong class="keyWord">Node 2</strong></li>
      <li class="bulletList"><strong class="keyWord">Deployment A</strong> contains two Pods, <strong class="keyWord">Pod A1</strong> and <strong class="keyWord">Pod A2</strong></li>
      <li class="bulletList"><strong class="keyWord">Deployment B</strong> contains one Pod, <strong class="keyWord">Pod B1</strong></li>
      <li class="bulletList"><strong class="keyWord">Pod A1</strong> is scheduled to <strong class="keyWord">Node 1</strong></li>
      <li class="bulletList"><strong class="keyWord">Pod A2</strong> and <strong class="keyWord">Pod B1</strong> are scheduled to <strong class="keyWord">Node 2</strong></li>
      <li class="bulletList">Each Deployment has a corresponding Service deployed, <strong class="keyWord">Service A</strong> and <strong class="keyWord">Service B</strong>, and they are available on all nodes</li>
      <li class="bulletList">An <strong class="keyWord">Ingress</strong> is defined to route incoming requests to the two Services</li>
      <li class="bulletList">A client typically sends requests to the cluster via an <strong class="keyWord">external load balancer</strong></li>
    </ul>
    <p class="normal">These objects are not, by themselves, running components; instead, they are definitions of different types of desired states. To reflect the desired state in the cluster’s current state, Kubernetes comes<a id="_idIndexMarker1045"/> with an architecture consisting of a number of runtime components, as described in the next section.</p>
    <h1 id="_idParaDest-380" class="heading-1">Introducing Kubernetes runtime components</h1>
    <p class="normal">A Kubernetes cluster contains two types of nodes: <strong class="keyWord">master nodes</strong> and <strong class="keyWord">worker nodes</strong>. Master nodes<a id="_idIndexMarker1046"/> manage the cluster, while the main purpose<a id="_idIndexMarker1047"/> of worker nodes is to run the actual workload, for example, the containers we deploy in the cluster. Kubernetes is built up of a number<a id="_idIndexMarker1048"/> of runtime components. The most important components are as follows:</p>
    <ul>
      <li class="bulletList">There are components that run on master<a id="_idIndexMarker1049"/> nodes, constituting the <strong class="keyWord">control plane</strong>:<ul>
          <li class="bulletList">The<strong class="keyWord"> API server</strong>, the entry point to the<a id="_idIndexMarker1050"/> control plane. This exposes<a id="_idIndexMarker1051"/> a RESTful API, which, for<a id="_idIndexMarker1052"/> example, the Kubernetes CLI tool known as <strong class="keyWord">kubectl</strong> uses.</li>
          <li class="bulletList"><strong class="keyWord">etcd</strong>, a highly available and distributed<a id="_idIndexMarker1053"/> key-value<a id="_idIndexMarker1054"/> store, used as a database for all cluster data.</li>
          <li class="bulletList">A <strong class="keyWord">controller manager</strong>, which contains a number of controllers<a id="_idIndexMarker1055"/> that continuously evaluate<a id="_idIndexMarker1056"/> the desired state versus the current state for the objects defined in the etcd database. Whenever the desired or current state changes, a controller that’s responsible for that type of state takes action to move the current state to the desired state. For example, a replication controller that’s responsible for managing Pods will react if a new Pod is added through the API server or a running Pod is deleted and ensures that new Pods are started. Another example of a controller is the node controller. It is responsible for acting if a node becomes unavailable, ensuring that Pods running on a failing node are rescheduled on other nodes in the cluster.</li>
          <li class="bulletList">A <strong class="keyWord">scheduler</strong>, which is responsible for assigning<a id="_idIndexMarker1057"/> newly created<a id="_idIndexMarker1058"/> Pods to a node with available capacity, for example, in terms of memory and CPU. <strong class="keyWord">Affinity rules</strong> can be used to control<a id="_idIndexMarker1059"/> how Pods are assigned to nodes. For example, Pods that perform a lot of disk I/O operations can be assigned to a group of worker nodes that have fast SSD disks. Anti-affinity rules can be defined to separate Pods, for example, to avoid scheduling Pods from the same Deployment to the same worker node.</li>
        </ul>
      </li>
      <li class="bulletList">Components that run<a id="_idIndexMarker1060"/> on all the nodes, constituting the <strong class="keyWord">data plane</strong>:<ul>
          <li class="bulletList"><strong class="keyWord">kubelet</strong>, a node agent that executes<a id="_idIndexMarker1061"/> as a process directly in the nodes’ operating system and not as a container. A kubelet ensures that the Pods that are scheduled to its node have their containers up and running and that they are healthy. It acts as a conduit between the API server and the container runtime on its node.</li>
          <li class="bulletList"><strong class="keyWord">kube-proxy</strong>, a network proxy that enables the Service<a id="_idIndexMarker1062"/> concept in Kubernetes and is capable of forwarding requests to the appropriate Pods, typically in a round-robin fashion if more than one Pod is available for the specific Service. <code class="inlineCode">kube-proxy</code> is deployed as a DaemonSet.</li>
          <li class="bulletList"><strong class="keyWord">Container runtime</strong>, which is the software that runs<a id="_idIndexMarker1063"/> the containers on a node. Historically, Kubernetes used Docker<a id="_idIndexMarker1064"/> Engine, but today any implementation of the Kubernetes <strong class="keyWord">Container Runtime Interface</strong> (<strong class="keyWord">CRI</strong>) can be used, for example, <strong class="keyWord">cri-o</strong> (<a href="https://cri-o.io"><span class="url">https://cri-o.io</span></a>) and <strong class="keyWord">containerd</strong> (<a href="https://containerd.io/"><span class="url">https://containerd.io/</span></a>). Support for Docker<a id="_idIndexMarker1065"/> Engine<a id="_idIndexMarker1066"/> was removed<a id="_idIndexMarker1067"/> in Kubernetes v1.24.</li>
        </ul>
        <div class="note">
          <p class="normal"><code class="inlineCode">containerd</code> is actually the container engine of Docker. It was separated from Docker back in 2017 and is today a graduated CNCF project.</p>
        </div>
        <ul>
          <li class="bulletList"><strong class="keyWord">Kubernetes DNS</strong>, which is a DNS server that’s used in the cluster’s internal network. Services <a id="_idIndexMarker1068"/>and Pods are assigned a DNS name, and Pods are configured to use this DNS server to resolve the internal DNS names. The DNS server is deployed as a Deployment object and a Service object.</li>
        </ul>
      </li>
    </ul>
    <p class="normal">The following diagram summarizes the Kubernetes runtime components described above:</p>
    <figure class="mediaobject"><img src="../Images/B19825_15_02.png" alt="Diagram  Description automatically generated" width="878" height="485"/></figure>
    <p class="packt_figref">Figure 15.2: Overview of Kubernetes runtime components</p>
    <p class="normal">Based on the diagram, we can imagine the following<a id="_idIndexMarker1069"/> sequence of events:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">An operator uses <strong class="keyWord">kubectl</strong> to send in a new desired state to Kubernetes, containing manifests declaring a new <strong class="keyWord">Deployment</strong>, <strong class="keyWord">Service</strong>, and <strong class="keyWord">Ingress</strong> object. The Ingress defines a route to the Service object and the Service object is defined to select Pods that are configured by the Deployment object.</li>
      <li class="numberedList"><strong class="keyWord">kubectl</strong> talks to the <strong class="keyWord">API server</strong> and it stores the new desired state as objects in the <strong class="keyWord">etcd</strong> database.</li>
      <li class="numberedList">Various <strong class="keyWord">controllers</strong> will react to the creation of the new objects and take the following actions:<ol class="alphabeticList" style="list-style-type: lower-alpha;">
          <li class="alphabeticList" value="1">For the Deployment object:<ol class="romanList" style="list-style-type: lower-roman;">
              <li class="romanList" value="1">New <strong class="keyWord">ReplicaSet</strong> and <strong class="keyWord">Pod</strong> objects will be registered in the API server.</li>
              <li class="romanList">The <strong class="keyWord">scheduler</strong> will see the new Pod(s) and schedule them to the appropriate worker nodes.</li>
              <li class="romanList">On each worker node, the <strong class="keyWord">kubelet</strong> agent will launch containers as described by the Pods. The kubelet will use the <strong class="keyWord">container runtime</strong> on the worker node to manage the containers.</li>
            </ol>
          </li>
          <li class="alphabeticList">For the Service object:<ol class="romanList" style="list-style-type: lower-roman;">
              <li class="romanList" value="1">A DNS name will be registered in the internal DNS server for the Service object and the <strong class="keyWord">kube-proxy</strong> will be able to route requests that use the DNS name to one of the available Pods.</li>
            </ol>
          </li>
        </ol>
      </li>
    </ol>
    <div class="packt_tip">
      <p class="normal">Note that Pods are reachable from any node in the cluster, so the kube-proxy does not need to run on the same node as the Pod to be able to forward requests to it.</p>
    </div>
    <ol class="alphabeticList" style="list-style-type: lower-alpha;">
      <li class="alphabeticList" value="3">For the Ingress object:<ol class="romanList" style="list-style-type: lower-roman;">
          <li class="romanList" value="1">An <strong class="keyWord">Ingress controller</strong> will set up routes according to the Ingress object and be ready to accept requests from outside of the Kubernetes cluster. External requests that match the routes defined by the Ingress object will be forwarded by the Ingress controller to the Service object. These requests will be forwarded by the kube-proxy to a Pod as described above.</li>
        </ol>
      </li>
    </ol>
    <p class="normal">Now that we understand<a id="_idIndexMarker1070"/> the Kubernetes runtime components and what they support and run on, let’s move on to creating a Kubernetes cluster with Minikube.</p>
    <h1 id="_idParaDest-381" class="heading-1">Creating a Kubernetes cluster using Minikube</h1>
    <p class="normal">Now, we are ready to create a Kubernetes<a id="_idIndexMarker1071"/> cluster! We will use Minikube to create<a id="_idIndexMarker1072"/> a local single-node cluster. Minikube can be deployed in a VM, a container, or on bare metal using different drivers. We will use one of the preferred drivers, the Docker driver, where the Minikube instance runs in a container managed by Docker Desktop on macOS and Windows with <strong class="keyWord">Windows Subsystem for Linux, v2</strong> (WSL 2).</p>
    <div class="packt_tip">
      <p class="normal">For information<a id="_idIndexMarker1073"/> on the available drivers in Minikube, see <a href="https://minikube.sigs.k8s.io/docs/drivers/"><span class="url">https://minikube.sigs.k8s.io/docs/drivers/</span></a>.</p>
      <p class="normal">Docker and its containers are already running in a separate WSL 2 instance; see the <em class="italic">Installing Docker Desktop for Windows</em> section in <em class="chapterRef">Chapter 22</em>, <em class="italic">Installation Instructions for Microsoft Windows with WSL 2 and Ubuntu</em>.</p>
    </div>
    <p class="normal">One drawback of running Minikube as a container on Docker is that ports exposed by Minikube are only accessible on the host that runs Docker. To make the ports available to Docker clients, for example, macOS or the Linux server we will use on WSL 2, we can specify port mappings when creating the Minikube cluster.</p>
    <p class="normal">Before creating the Kubernetes cluster, we need to learn a bit about Minikube profiles, the Kubernetes CLI tool known as <code class="inlineCode">kubectl</code>, and its use of contexts.</p>
    <h2 id="_idParaDest-382" class="heading-2">Working with Minikube profiles</h2>
    <p class="normal">In order to run multiple Kubernetes<a id="_idIndexMarker1074"/> clusters locally, Minikube comes with the concept of <strong class="keyWord">profiles</strong>. For example, if you want to work with multiple versions of Kubernetes, you can create multiple Kubernetes clusters using Minikube. Each cluster will be assigned a separate Minikube profile. Most of the Minikube commands accept a <code class="inlineCode">--profile</code> flag (or <code class="inlineCode">-p</code> for short), which can be used to specify which of the Kubernetes clusters the command will be applied to. If you plan to work with one specific profile for a while, a more convenient alternative exists, where you specify the current profile with the following command:</p>
    <pre class="programlisting con"><code class="hljs-con">minikube profile my-profile
</code></pre>
    <p class="normal">This command will set the <code class="inlineCode">my-profile</code> profile as the current profile.</p>
    <p class="normal">To get the current profile, run the following command:</p>
    <pre class="programlisting con"><code class="hljs-con">minikube config get profile
</code></pre>
    <p class="normal">If no profile is specified, either using the <code class="inlineCode">minikube profile</code> command or the <code class="inlineCode">--profile</code> switch, a default profile named <code class="inlineCode">minikube</code> will be used.</p>
    <p class="normal">Information regarding existing <a id="_idIndexMarker1075"/>profiles can be found with the command <code class="inlineCode">minikube profile</code> <code class="inlineCode">list</code>.</p>
    <h2 id="_idParaDest-383" class="heading-2">Working with the Kubernetes CLI, kubectl</h2>
    <p class="normal"><code class="inlineCode">kubectl</code> is the Kubernetes CLI tool. Once a cluster<a id="_idIndexMarker1076"/> has been set up, this is usually the only tool you need to manage the cluster!</p>
    <p class="normal">For managing the API objects, as we described earlier in this chapter, the <code class="inlineCode">kubectl</code> <code class="inlineCode">apply</code> command<a id="_idIndexMarker1077"/> is the only command you need to know about. It is a <strong class="keyWord">declarative command</strong>; that is, as an operator, we ask Kubernetes to apply the object definition we give to the command. It is then up to Kubernetes to figure out what actually needs to be done.</p>
    <div class="packt_tip">
      <p class="normal">Another example of a declarative command that’s hopefully familiar to many readers of this book is a <code class="inlineCode">SQL SELECT</code> statement, which can join information from several database tables. We only declare the expected result in the SQL query, and it is up to the database query optimizer to figure out in what order the tables should be accessed and what indexes to use to retrieve the data in the most efficient way.</p>
    </div>
    <p class="normal">In some cases, <strong class="keyWord">imperative statements</strong> that explicitly tell Kubernetes what to do are<a id="_idIndexMarker1078"/> preferred. One example is the <code class="inlineCode">kubectl delete</code> command, where we explicitly tell Kubernetes to delete some API objects. Creating a namespace object can also be conveniently done with an explicit <code class="inlineCode">kubectl create namespace</code> command.</p>
    <p class="normal">Repetitive usage of the imperative statements will make them fail, for example, deleting the same API object twice using <code class="inlineCode">kubectl delete</code> or creating the same namespace twice using <code class="inlineCode">kubectl create</code>. A declarative command, that is, using <code class="inlineCode">kubectl apply</code>, will not fail with repetitive usage – it will simply state that there is no change and exit without taking any action.</p>
    <p class="normal">Some commonly used commands for retrieving information about a Kubernetes cluster are as follows:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">kubectl get</code> shows information about the specified API object</li>
      <li class="bulletList"><code class="inlineCode">kubectl describe</code> gives more detail about the specified API object</li>
      <li class="bulletList"><code class="inlineCode">kubectl logs</code> displays log output from containers</li>
    </ul>
    <p class="normal">We will see a lot of examples of these and other <code class="inlineCode">kubectl</code> commands in this and the upcoming chapters!</p>
    <p class="normal">If in doubt about how to use the <code class="inlineCode">kubectl</code> tool, the <code class="inlineCode">kubectl help</code> and <code class="inlineCode">kubectl</code> <code class="inlineCode">&lt;command&gt; --help</code> commands are always available and provide very useful information. Another helpful command is <code class="inlineCode">kubectl explain</code>, which can be used to show what fields are available when declaring a Kubernetes object. For example, run the following command if you need to look up the fields available to describe a container in the template<a id="_idIndexMarker1079"/> of a Deployment object:</p>
    <pre class="programlisting con"><code class="hljs-con">kubectl explain deployment.spec.template.spec.containers
</code></pre>
    <h2 id="_idParaDest-384" class="heading-2">Working with kubectl contexts</h2>
    <p class="normal">To be able to work<a id="_idIndexMarker1080"/> with more than one Kubernetes cluster, using either Minikube locally or Kubernetes clusters set up on on-premises servers or in the cloud, <code class="inlineCode">kubectl</code> comes with the concept of <strong class="keyWord">contexts</strong>. A context is a combination of the following:</p>
    <ul>
      <li class="bulletList">A Kubernetes cluster</li>
      <li class="bulletList">Authentication information for a user</li>
      <li class="bulletList">A default namespace</li>
    </ul>
    <p class="normal">By default, contexts are saved in the <code class="inlineCode">~/.kube/config</code> file, but the file can be changed using the <code class="inlineCode">KUBECONFIG</code> environment variable. In this book, we will use the default location, so we will unset <code class="inlineCode">KUBECONFIG</code> using the <code class="inlineCode">unset KUBECONFIG</code> command.</p>
    <p class="normal">When a Kubernetes cluster is created in Minikube, a context is created with the same name as the Minikube profile and is then set as the current context. So, <code class="inlineCode">kubectl</code> commands that are issued after the cluster is created in Minikube will be sent to that cluster.</p>
    <p class="normal">To list the available contexts, run the following command:</p>
    <pre class="programlisting con"><code class="hljs-con">kubectl config get-contexts
</code></pre>
    <p class="normal">The following is a sample response:</p>
    <figure class="mediaobject"><img src="../Images/B19825_15_03.png" alt="Graphical user interface, application  Description automatically generated" width="878" height="113"/></figure>
    <p class="packt_figref">Figure 15.3: List of kubectl contexts</p>
    <p class="normal">The wildcard, <strong class="keyWord">*</strong>, in the first column marks the current context.</p>
    <div class="packt_tip">
      <p class="normal">You will only see the <code class="inlineCode">handson-spring-boot-cloud</code> context in the preceding response once the cluster has been created, the process for which we will describe shortly.</p>
    </div>
    <p class="normal">If you want to switch the current context to another context, that is, work with another Kubernetes cluster, run the following command:</p>
    <pre class="programlisting con"><code class="hljs-con">kubectl config use-context my-cluster
</code></pre>
    <p class="normal">In this example, the current context will be changed to <code class="inlineCode">my-cluster</code>.</p>
    <p class="normal">To update a context, for example, switching the default namespace used by <code class="inlineCode">kubectl</code>, use the <code class="inlineCode">kubectl config set-context</code> command.</p>
    <p class="normal">For example, to change the default namespace of the current context to <code class="inlineCode">my-namespace</code>, use the following command:</p>
    <pre class="programlisting con"><code class="hljs-con">kubectl config set-context $(kubectl config current-context) --namespace my-namespace
</code></pre>
    <p class="normal">In this command, <code class="inlineCode">kubectl config current-context</code> is used to get the name<a id="_idIndexMarker1081"/> of the current context.</p>
    <h2 id="_idParaDest-385" class="heading-2">Creating a Kubernetes cluster</h2>
    <p class="normal">To create a Kubernetes cluster using Minikube, we need<a id="_idIndexMarker1082"/> to run a few<a id="_idIndexMarker1083"/> commands:</p>
    <ul>
      <li class="bulletList">Unset the <code class="inlineCode">KUBECONFIG</code> environment variable to ensure that the <code class="inlineCode">kubectl</code> context is created in the default config file, <code class="inlineCode">~/.kube/config</code>.</li>
      <li class="bulletList">Create the cluster using the <code class="inlineCode">minikube start</code> command, where we can also specify what version of Kubernetes to use and the amount of hardware resources we want to allocate to the cluster:<ul>
          <li class="bulletList">To be able to complete the examples in the remaining chapters of this book, allocate 10 GB of memory, that is, 10,240 MB, to the cluster. The samples should also work if only 6 GB (6,144 MB) is allocated to the Minikube cluster, albeit more slowly.</li>
          <li class="bulletList">Allocate the number of CPU cores and disk space you find suitable; 4 CPU cores and 30 GB of disk space are used in the following example.</li>
          <li class="bulletList">Specify what version of Kubernetes will be used. In this book, we will use v1.26.1.</li>
          <li class="bulletList">Specify that we will use the Docker driver as described above. </li>
          <li class="bulletList">Specify the required port mappings. The ports <code class="inlineCode">8080</code> and <code class="inlineCode">8443</code> will be used by the Ingress controller, and the ports <code class="inlineCode">30080</code> and <code class="inlineCode">30443</code> will be used by Services of type <code class="inlineCode">NodePort</code>. </li>
        </ul>
        <div class="note">
          <p class="normal">See <em class="chapterRef">Chapter 16</em><em class="italic">, Deploying Our Microservices to Kubernetes,</em> for information on how the Gateway server deploys a Service of type <code class="inlineCode">NodePort</code>.</p>
        </div>
      </li>
      <li class="bulletList">Specify the Minikube profile to be used for the coming <code class="inlineCode">minikube</code> commands. We will use <code class="inlineCode">handson-spring-boot-cloud</code> as the profile name.</li>
      <li class="bulletList">After the cluster has been created, we will use the add-on manager in Minikube to enable an Ingress controller and a metrics server that comes out of the box with Minikube. The Ingress controller and the metrics server will be used in the next chapters.</li>
    </ul>
    <p class="normal">Run the following<a id="_idIndexMarker1084"/> commands to create the Kubernetes<a id="_idIndexMarker1085"/> cluster:</p>
    <pre class="programlisting con"><code class="hljs-con">unset KUBECONFIG
minikube start \
 --profile=handson-spring-boot-cloud \
 --memory=10240 \
 --cpus=4 \
 --disk-size=30g \
 --kubernetes-version=v1.26.1 \
 --driver=docker \
 --ports=8080:80 --ports=8443:443 \
 --ports=30080:30080 --ports=30443:30443
minikube profile handson-spring-boot-cloud
minikube addons enable ingress
minikube addons enable metrics-server
</code></pre>
    <p class="normal">After the preceding commands complete, you should be able to communicate with the cluster. Try the <code class="inlineCode">kubectl get nodes</code> command. It should respond with something that looks similar to the following:</p>
    <figure class="mediaobject"><img src="../Images/B19825_15_04.png" alt="Graphical user interface  Description automatically generated" width="878" height="149"/></figure>
    <p class="packt_figref">Figure 15.4: List of nodes in the Kubernetes cluster</p>
    <p class="normal">Once created, the cluster will initialize itself in the background, starting up a number of system Pods in the <code class="inlineCode">kube-system</code> and the <code class="inlineCode">ingress-nginx</code> namespace. We can monitor its progress by issuing the following command:</p>
    <pre class="programlisting con"><code class="hljs-con">kubectl get pods --all-namespaces
</code></pre>
    <p class="normal">Once the startup is complete, the preceding command should report the status for all Pods as <strong class="keyWord">Running</strong> and the <strong class="keyWord">READY</strong> count should be <strong class="keyWord">1/1</strong>, meaning that a single container in each Pod is up and running:</p>
    <figure class="mediaobject"><img src="../Images/B19825_15_05.png" alt="Graphical user interface, text  Description automatically generated" width="878" height="283"/></figure>
    <p class="packt_figref">Figure 15.5: List of running system Pods</p>
    <p class="normal">Note that two Pods are reported as <strong class="keyWord">Completed</strong>, and not <strong class="keyWord">Running</strong>. They are Pods created by <strong class="keyWord">Job</strong> objects, used to execute a container<a id="_idIndexMarker1086"/> a fixed number of times like a batch<a id="_idIndexMarker1087"/> job. Run the command <code class="inlineCode">kubectl get jobs --namespace=ingress-nginx</code> to reveal the two Job objects.</p>
    <p class="normal">We are now ready for some action!</p>
    <h1 id="_idParaDest-386" class="heading-1">Trying out a sample Deployment</h1>
    <p class="normal">Let’s see how we can do the following:</p>
    <ul>
      <li class="bulletList">Deploy a simple web server<a id="_idIndexMarker1088"/> based on NGINX in our<a id="_idIndexMarker1089"/> Kubernetes cluster</li>
      <li class="bulletList">Apply some changes to the Deployment:<ul>
          <li class="bulletList">Change the current state by deleting the Pod and verify that the <code class="inlineCode">ReplicaSet</code> creates a new one</li>
          <li class="bulletList">Change the desired state by scaling the web server to three Pods and verify that the <code class="inlineCode">ReplicaSet</code> fills the gap by starting up two new Pods</li>
        </ul>
      </li>
      <li class="bulletList">Route external traffic to the web server using a Service with a node port</li>
    </ul>
    <p class="normal">First, create a namespace, <code class="inlineCode">first-attempts</code>, and update the <code class="inlineCode">kubectl</code> context to use this namespace by default:</p>
    <pre class="programlisting con"><code class="hljs-con">kubectl create namespace first-attempts
kubectl config set-context $(kubectl config current-context) --namespace=first-attempts
</code></pre>
    <p class="normal">We can now create a Deployment of NGINX<a id="_idIndexMarker1090"/> in the namespace<a id="_idIndexMarker1091"/> using the <code class="inlineCode">kubernetes/first-attempts/nginx-deployment.yaml</code> file. This file looks as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-deploy</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">replicas:</span> <span class="hljs-number">1</span>
  <span class="hljs-attr">selector:</span>
    <span class="hljs-attr">matchLabels:</span>
      <span class="hljs-attr">app:</span> <span class="hljs-string">nginx-app</span>
  <span class="hljs-attr">template:</span>
    <span class="hljs-attr">metadata:</span>
      <span class="hljs-attr">labels:</span>
        <span class="hljs-attr">app:</span> <span class="hljs-string">nginx-app</span>
    <span class="hljs-attr">spec:</span>
      <span class="hljs-attr">containers:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-container</span>
        <span class="hljs-attr">image:</span> <span class="hljs-string">nginx:latest</span>
        <span class="hljs-attr">ports:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">80</span>
</code></pre>
    <p class="normal">Let’s explain this source code in more detail:</p>
    <ul>
      <li class="bulletList">The <code class="inlineCode">kind</code> and <code class="inlineCode">apiVersion</code> attributes are used to specify that we are declaring a Deployment object.</li>
      <li class="bulletList">The <code class="inlineCode">metadata</code> section is used to describe the Deployment object. For example, we give it the name <code class="inlineCode">nginx-deploy</code>.</li>
    </ul>
    <div class="packt_tip">
      <p class="normal">Other commonly used metadata for a Kubernetes object includes the name of the <code class="inlineCode">namespace</code> it belongs to, <code class="inlineCode">label</code>s, and <code class="inlineCode">annotation</code>s. We will see them used in this chapter and the following chapters.</p>
    </div>
    <ul>
      <li class="bulletList">Next comes a <code class="inlineCode">spec</code> section that defines our desired state for the Deployment object:<ul>
          <li class="bulletList"><code class="inlineCode">replicas: 1</code> specifies we want to have one Pod up and running.</li>
          <li class="bulletList">A <code class="inlineCode">selector</code> section that specifies how the Deployment will find the Pods it manages. In this case, the Deployment will look for Pods that have the <code class="inlineCode">app</code> label set to <code class="inlineCode">nginx-app</code>.</li>
          <li class="bulletList">The <code class="inlineCode">template</code> section is used to specify how Pods will be created.<ul>
              <li class="bulletList">The <code class="inlineCode">metadata</code> section specifies the <code class="inlineCode">label</code>, <code class="inlineCode">app: nginx-app</code>, which is used to identify the Pods, thereby matching the selector.</li>
              <li class="bulletList">The <code class="inlineCode">spec</code> section specifies details for the creation of the single container in the Pod, that is, <code class="inlineCode">name</code>, <code class="inlineCode">image</code>, and what <code class="inlineCode">ports</code> it uses.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
    <p class="normal">Create the Deployment with the following commands:</p>
    <pre class="programlisting con"><code class="hljs-con">cd $BOOK_HOME/Chapter15
kubectl apply -f kubernetes/first-attempts/nginx-deployment.yaml
</code></pre>
    <p class="normal">Let’s see what<a id="_idIndexMarker1092"/> we got<a id="_idIndexMarker1093"/> with the <code class="inlineCode">kubectl get all</code> command:</p>
    <figure class="mediaobject"><img src="../Images/B19825_15_06.png" alt="Text  Description automatically generated" width="684" height="286"/></figure>
    <p class="packt_figref">Figure 15.6: Kubernetes objects created by the sample deployment</p>
    <p class="normal">As expected, we got a Deployment, ReplicaSet, and Pod object. After a short while, which mainly depends on the time it takes to download the NGINX Docker image, the Pod will be up and running, reported as <strong class="keyWord">1/1</strong> in the <strong class="keyWord">READY</strong> column, meaning that the desired state is equal to the current state!</p>
    <p class="normal">Now, we will change the current state by deleting the Pod. Before deleting the Pod, run the command <code class="inlineCode">kubectl get pod --watch</code> in another terminal. The use of the <code class="inlineCode">--watch</code> option makes the command hang, waiting for state changes of Pods in the current namespace. Delete the Pod using the following command:</p>
    <pre class="programlisting con"><code class="hljs-con">kubectl delete pod --selector app=nginx-app
</code></pre>
    <p class="normal">Since the Pod has a random name (<code class="inlineCode">nginx-deploy-59b8c5f7cd-mt6pg</code> in the preceding example), the Pod is selected based on the <code class="inlineCode">app</code> label, which is set to <code class="inlineCode">nginx-app</code> in the Pod.</p>
    <p class="normal">Note how <code class="inlineCode">kubectl get pod --watch</code> reports how the current Pod is terminated and at the same time a new Pod is started up. </p>
    <p class="normal">It is the ReplicaSet that detects the difference between the desired and current state and almost immediately starts up a new Pod to compensate for the deviation. The reported events should look like the following screenshot:</p>
    <figure class="mediaobject"><img src="../Images/B19825_15_07.png" alt="A screenshot of a computer  Description automatically generated with low confidence" width="649" height="255"/></figure>
    <p class="packt_figref">Figure 15.7: kubectl get pod --watch reporting changes to the Pods</p>
    <p class="normal">In the screenshot, we can see that the Pod with a name ending with <code class="inlineCode">d69ln</code> was stopped by the <code class="inlineCode">delete</code> command and that the ReplicaSet immediately started up a new Pod with a name ending with <code class="inlineCode">ptbkf</code>.</p>
    <p class="normal">Change the desired<a id="_idIndexMarker1094"/> state by setting the number of desired Pods to three<a id="_idIndexMarker1095"/> replicas in the <code class="inlineCode">kubernetes/first-attempts/nginx-deployment.yaml</code> Deployment file. Apply the change in the desired state by simply repeating the <code class="inlineCode">kubectl apply</code> command, as we mentioned previously.</p>
    <p class="normal">Again, note that the <code class="inlineCode">kubectl get pod --watch</code> command reports new Pods being launched by the ReplicaSet to get the current state equivalent to the new desired state, that is, three Pods. After a few seconds, two new NGINX Pods will be reported as up and running. Stop the command with <em class="keystroke">Ctrl + C</em>.</p>
    <p class="normal">Run the <code class="inlineCode">kubectl get all</code> command and expect a response that looks similar to the following:</p>
    <figure class="mediaobject"><img src="../Images/B19825_15_08.png" alt="Text  Description automatically generated" width="737" height="290"/></figure>
    <p class="packt_figref">Figure 15.8: New Pods started up by Kubernetes to meet the desired state</p>
    <p class="normal">Note the three Pods and that the Deployment object reports <strong class="keyWord">3/3</strong>. This is interpreted as 3 ready and 3 desired Pods, meaning that all desired Pods are ready to be used.</p>
    <p class="normal">To enable external communication<a id="_idIndexMarker1096"/> with the web servers, create a Service<a id="_idIndexMarker1097"/> using the <code class="inlineCode">kubernetes/first-attempts/nginx-service.yaml</code> file. It looks like the following:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-service</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">type:</span> <span class="hljs-string">NodePort</span>
  <span class="hljs-attr">selector:</span>
    <span class="hljs-attr">app:</span> <span class="hljs-string">nginx-app</span>
  <span class="hljs-attr">ports:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">targetPort:</span> <span class="hljs-number">80</span>
      <span class="hljs-attr">port:</span> <span class="hljs-number">80</span>
      <span class="hljs-attr">nodePort:</span> <span class="hljs-number">30080</span>
</code></pre>
    <p class="normal">The <code class="inlineCode">kind</code> and <code class="inlineCode">apiVersion</code> attributes are used to specify that we are declaring a <code class="inlineCode">Service</code> object.</p>
    <p class="normal">The <code class="inlineCode">metadata</code> section is used to describe the <code class="inlineCode">Service</code> object, for example, to give it a name: <code class="inlineCode">nginx-service</code>.</p>
    <p class="normal">Next comes a <code class="inlineCode">spec</code> section, which defines the desired state of the <code class="inlineCode">Service</code> object:</p>
    <ul>
      <li class="bulletList">With the <code class="inlineCode">type</code> field, we specify that we want <code class="inlineCode">NodePort</code>, that is, a Service that is accessible externally on a dedicated port on each node in the cluster. This means that an external caller can reach the Pods behind this Service using this port on any of the nodes in the cluster, independent of which nodes the Pods actually run on.</li>
      <li class="bulletList">The selector is used by the Service to find available Pods, which, in our case, are Pods labeled with <code class="inlineCode">app: nginx-app</code>.</li>
      <li class="bulletList">Finally, <code class="inlineCode">ports</code> are declared as follows:<ul>
          <li class="bulletList"><code class="inlineCode">port: 80</code> specifies which port the Service will be accessible on, that is, internally in the cluster.</li>
          <li class="bulletList"><code class="inlineCode">targetPort: 80</code> specifies the port in the Pod where the requests will be forwarded to.</li>
          <li class="bulletList"><code class="inlineCode">nodePort: 30080</code> specifies which port the Service will be externally accessible on using any of the nodes in the cluster. By default, a node port must be in the range of <code class="inlineCode">30000</code> to <code class="inlineCode">32767</code>.</li>
        </ul>
      </li>
    </ul>
    <div class="packt_tip">
      <p class="normal">This port range is used to minimize the risk of colliding with other ports in use. In a production system, a load balancer is typically placed in front of the Kubernetes cluster, shielding the external users both from the knowledge of these ports and the IP numbers of the nodes in the Kubernetes cluster. See <em class="chapterRef">Chapter 18</em>, <em class="italic">Using a Service Mesh to Improve Observability and Management</em>, specifically the <em class="italic">Setting up access to Istio Services</em> section, for more on the usage of a <code class="inlineCode">LoadBalanced</code> Kubernetes Service.</p>
    </div>
    <p class="normal">Create the Service with the following command:</p>
    <pre class="programlisting con"><code class="hljs-con">kubectl apply -f kubernetes/first-attempts/nginx-service.yaml
</code></pre>
    <p class="normal">To see what we got, run the <code class="inlineCode">kubectl get svc</code> command. Expect a response like the following:</p>
    <figure class="mediaobject"><img src="../Images/B19825_15_09.png" alt="Graphical user interface  Description automatically generated" width="878" height="134"/></figure>
    <p class="packt_figref">Figure 15.9: NodePort Service for our Deployment</p>
    <div class="packt_tip">
      <p class="normal"><code class="inlineCode">kubectl</code> supports short names for many of the API objects as an alternative to their full name. For example, <code class="inlineCode">svc</code> was used in the preceding command instead of the full name, <code class="inlineCode">service</code>. Run the command <code class="inlineCode">kubectl api-resources</code> to see all available short names.</p>
    </div>
    <p class="normal">To access the web server<a id="_idIndexMarker1098"/> through the Service’s node port, we need to know the IP address<a id="_idIndexMarker1099"/> or hostname of the single node in our cluster. When using the Docker driver, the hostname is always <code class="inlineCode">localhost</code>. </p>
    <p class="normal">The node port, <code class="inlineCode">30080</code>, is forwarded from Docker Engine by the <code class="inlineCode">–ports</code> option in the <code class="inlineCode">minikube start</code> command. See the <em class="italic">Creating a Kubernetes cluster</em> section above for details. This means that the <code class="inlineCode">Service</code> can be reached at the address <code class="inlineCode">localhost:30080</code>. </p>
    <div class="packt_tip">
      <p class="normal">Ports opened in a WSL 2 instance are accessible in Windows on <code class="inlineCode">localhost</code>.</p>
    </div>
    <p class="normal">With this information, we can direct a web browser on macOS and Windows to the deployed web server using the address <code class="inlineCode">http://localhost:30080</code>. Expect a response such as the following:</p>
    <figure class="mediaobject"><img src="../Images/B19825_15_10.png" alt="Graphical user interface, text, application, email  Description automatically generated" width="878" height="437"/></figure>
    <p class="packt_figref">Figure 15.10: NGINX default web page</p>
    <p class="normal">Great! But what about the internal cluster IP address and port?</p>
    <p class="normal">One way to verify that<a id="_idIndexMarker1100"/> the web server is also reachable internally in the cluster<a id="_idIndexMarker1101"/> is to launch a small Pod that we can use to run <code class="inlineCode">curl</code> from the inside. The <code class="inlineCode">curl</code> command will use the internal cluster IP address and port. We don’t need to use the internal IP address; instead, we can use a DNS name that is created for the Service in the internal DNS server. The short name of the DNS name is the same as the name of the Service, that is, <code class="inlineCode">nginx-service</code>.</p>
    <div class="packt_tip">
      <p class="normal">The full DNS name of a Service is <code class="inlineCode">&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local</code>. The full name for this Service is <code class="inlineCode">nginx-service.first-attempts.svc.cluster.local</code>. Since we will run the command below in the same namespace, we can use the short name. </p>
    </div>
    <p class="normal">Run the following command:</p>
    <pre class="programlisting con"><code class="hljs-con">kubectl run -i --rm --restart=Never curl-client --image=curlimages/curl --command -- curl -s 'http://nginx-service:80'
</code></pre>
    <p class="normal">The command looks a bit complex, but it will do the following:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">Create a Pod with a small container based on the Docker image <code class="inlineCode">curlimages/curl</code>, which contains the <code class="inlineCode">curl</code> command.</li>
      <li class="numberedList">Run the <code class="inlineCode">curl -s 'http://nginx-service:80'</code> command inside the container and redirect the output to the Terminal using the <code class="inlineCode">-i</code> option.</li>
      <li class="numberedList">Delete the Pod using the <code class="inlineCode">--rm</code> option.</li>
    </ol>
    <p class="normal">Expect the output from the preceding command to contain the following information (we are only showing parts of the response here):</p>
    <figure class="mediaobject"><img src="../Images/B19825_15_11.png" alt="Text  Description automatically generated" width="525" height="224"/></figure>
    <p class="packt_figref">Figure 15.11: Accessing NGINX inside the Kubernetes cluster</p>
    <p class="normal">This means that the web server is also accessible internally in the cluster!</p>
    <p class="normal">This is basically all we need to know to be able to deploy our system landscape.</p>
    <p class="normal">Wrap this up by removing the namespace containing the <code class="inlineCode">nginx</code> Deployment:</p>
    <pre class="programlisting con"><code class="hljs-con">kubectl delete namespace first-attempts
</code></pre>
    <p class="normal">Before we end this<a id="_idIndexMarker1102"/> introductory chapter on Kubernetes, we need<a id="_idIndexMarker1103"/> to learn how to manage our Kubernetes cluster.</p>
    <h1 id="_idParaDest-387" class="heading-1">Managing a local Kubernetes cluster</h1>
    <p class="normal">A running Kubernetes cluster<a id="_idIndexMarker1104"/> consumes a lot of resources, mostly memory. So, when we are done working with a Kubernetes cluster in Minikube, we must be able to hibernate it in order to release the resources allocated to it. We also need to know how to resume the cluster when we want to continue working with it. Eventually, we must also be able to permanently remove the cluster when we don’t want to keep it on disk anymore.</p>
    <p class="normal">Minikube comes with a <code class="inlineCode">stop</code> command that can be used to hibernate a Kubernetes cluster. The <code class="inlineCode">start</code> command we used to initially create the Kubernetes cluster can also be used to resume the cluster from its hibernated state. To permanently remove a cluster, we can use the <code class="inlineCode">delete</code> command from Minikube.</p>
    <h2 id="_idParaDest-388" class="heading-2">Hibernating and resuming a Kubernetes cluster</h2>
    <p class="normal">Run the following<a id="_idIndexMarker1105"/> command to hibernate (that is, <code class="inlineCode">stop</code>) the Kubernetes<a id="_idIndexMarker1106"/> cluster:</p>
    <pre class="programlisting con"><code class="hljs-con">minikube stop
</code></pre>
    <p class="normal">Run the following command to resume (that is, <code class="inlineCode">start</code>) the Kubernetes cluster again:</p>
    <pre class="programlisting con"><code class="hljs-con">minikube start
</code></pre>
    <p class="normal">Running <code class="inlineCode">kubectl</code> commands directly after restarting the cluster might result in error messages like:</p>
    <pre class="programlisting con"><code class="hljs-con">E0428 09:44:16.333361   79175 memcache.go:106] couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request
</code></pre>
    <p class="normal">This is due to the <code class="inlineCode">metrics-server</code> being a bit slow on starting up; the error message will disappear after a short while.</p>
    <div class="packt_tip">
      <p class="normal">When resuming an already existing cluster, the <code class="inlineCode">start</code> command ignores switches that were used when you were creating the cluster.</p>
    </div>
    <p class="normal">After resuming the Kubernetes cluster, the <code class="inlineCode">kubectl</code> context will be updated to use this cluster with the currently used namespace set to <code class="inlineCode">default</code>. If you are working with another namespace, for example, the <code class="inlineCode">hands-on</code> namespace that we will use in the upcoming chapter, <em class="chapterRef">Chapter 16</em>, <em class="italic">Deploying Our Microservices to Kubernetes</em>, you can update the <code class="inlineCode">kubectl</code> context with the following command:</p>
    <pre class="programlisting con"><code class="hljs-con">kubectl config set-context $(kubectl config current-context) --namespace=hands-on
</code></pre>
    <p class="normal">Subsequent <code class="inlineCode">kubectl</code> commands will be applied to the <code class="inlineCode">hands-on</code> namespace when applicable.</p>
    <div class="packt_tip">
      <p class="normal">Minikube also comes with a more lightweight and faster alternative to the <code class="inlineCode">stop</code> and <code class="inlineCode">start</code> commands: the <code class="inlineCode">pause</code> and <code class="inlineCode">unpause</code> commands. In this case, the components in the control plane are paused, not stopped, reducing the CPU consumption of the cluster to a minimum. I have, however, seen issues with these commands when used in the recent chapters, so I recommend using the <code class="inlineCode">start</code> and <code class="inlineCode">stop</code> commands.</p>
    </div>
    <h2 id="_idParaDest-389" class="heading-2">Terminating a Kubernetes cluster</h2>
    <p class="normal">If you later want to terminate<a id="_idIndexMarker1107"/> the Kubernetes cluster, you can run the following command:</p>
    <pre class="programlisting con"><code class="hljs-con">minikube delete --profile handson-spring-boot-cloud 
</code></pre>
    <p class="normal">You can actually run the <code class="inlineCode">delete</code> command without specifying the profile, but I find it safer to be explicit about the profile. Otherwise, you may accidentally delete the wrong Kubernetes cluster!</p>
    <p class="normal">We’ve successfully learned how to manage a Kubernetes cluster that runs in Minikube. We now know how to suspend and resume<a id="_idIndexMarker1108"/> a cluster and, when no longer needed, we know how to permanently remove it.</p>
    <h1 id="_idParaDest-390" class="heading-1">Summary</h1>
    <p class="normal">In this chapter, we were introduced to Kubernetes as a container orchestrator.</p>
    <p class="normal">Using Kubernetes, we can handle a cluster of servers as one big logical server that runs our containers. We declare a desired state for the Kubernetes cluster, and it ensures that the actual state is the same as the desired state at all times, provided that enough hardware resources are available in the cluster.</p>
    <p class="normal">The desired state is declared by creating resources using the Kubernetes API server. The controller manager in Kubernetes and its controllers react to the various resources that were created by the API server and take actions to ensure that the current state meets the new desired state. The scheduler assigns nodes to newly created containers, that is, Pods that contain one or more containers. On each node, an agent, a <code class="inlineCode">kubelet</code>, runs and ensures that the Pods that were scheduled to its node are up and running. The <code class="inlineCode">kube-proxy</code> acts as a network proxy, enabling a Service abstraction by forwarding requests that are sent to the Service to available Pods in the cluster. External requests can be handled either by a Kubernetes-aware load balancer that can provision a public IP address and/or DNS name for the Service, a node port that’s available on all of the nodes in the cluster, or through a dedicated Ingress resource.</p>
    <p class="normal">We have also tried out Kubernetes by creating a local single-node cluster using Minikube. The Minikube cluster runs as a Docker container using the Docker driver. To make ports accessible outside of Docker Engine, we can use the <code class="inlineCode">--ports</code> option on the <code class="inlineCode">minikube start</code> command. Using the Kubernetes CLI tool known as <code class="inlineCode">kubectl</code>, we deployed a simple web server based on NGINX. We tried out resilience capabilities by deleting the web server, and we observed it being recreated automatically. We learned how to manually scale it by requesting that three Pods run on the web server. We created a Service with a node port and verified that we could access it both externally and from the inside of the cluster.</p>
    <p class="normal">Finally, we learned how to manage a Kubernetes cluster running in Minikube in terms of how to hibernate, resume, and terminate the cluster.</p>
    <p class="normal">We are now ready to deploy our system landscape from the earlier chapters in Kubernetes. Head over to the next chapter to find out how to do this!</p>
    <h1 id="_idParaDest-391" class="heading-1">Questions</h1>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">What happens if you run the same <code class="inlineCode">kubectl create</code> command twice?</li>
      <li class="numberedList">What happens if you run the same <code class="inlineCode">kubectl apply</code> command twice?</li>
      <li class="numberedList">In terms of questions 1 and 2, why do they act differently the second time they are run?</li>
      <li class="numberedList">What is the purpose of a ReplicaSet, and what other resource creates a ReplicaSet?</li>
      <li class="numberedList">What is the purpose of <code class="inlineCode">etcd</code> in a Kubernetes cluster?</li>
      <li class="numberedList">How can a container find out the IP address of another container that runs in the same Pod?</li>
      <li class="numberedList">What happens if you create two Deployments with the same name but in different namespaces?</li>
      <li class="numberedList">What configuration of two Services with the same name can make them fail, even if they are created in two different namespaces?</li>
    </ol>
  </div>
  <div id="_idContainer360">
    <h1 id="_idParaDest-392" class="heading-1">Join our community on Discord</h1>
    <p class="normal">Join our community’s Discord space for discussion with the author and other readers:</p>
    <p class="normal"><a href="https://packt.link/SpringBoot3e"><span class="url">https://packt.link/SpringBoot3e</span></a></p>
    <p class="normal"><img src="../Images/QR_Code1849216352344398875.png" alt="" role="presentation" width="177" height="177"/></p>
  </div>
</div>
</div>
</body></html>