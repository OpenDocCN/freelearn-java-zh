- en: Chapter 1. Performance by Design
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一章. 设计性能
- en: Clojure is a safe, functional programming language that brings great power and
    simplicity to the user. Clojure is also dynamically and strongly typed, and has
    very good performance characteristics. Naturally, every activity performed on
    a computer has an associated cost. What constitutes acceptable performance varies
    from one use-case and workload to another. In today's world, performance is even
    the determining factor for several kinds of applications. We will discuss Clojure
    (which runs on the **JVM** (**Java Virtual Machine**)), and its runtime environment
    in the light of performance, which is the goal of this book.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure是一种安全、函数式编程语言，为用户带来了巨大的力量和简洁性。Clojure也是动态和强类型化的，并且具有非常好的性能特性。自然地，计算机上进行的每一项活动都有相关的成本。构成可接受性能的标准因用例和工作负载而异。在当今世界，性能甚至成为多种类型应用程序的决定性因素。我们将从性能的角度讨论Clojure（在**JVM**（**Java虚拟机**）上运行），以及其运行环境，这正是本书的目标。
- en: 'The performance of Clojure applications depend on various factors. For a given
    application, understanding its use cases, design and implementation, algorithms,
    resource requirements and alignment with the hardware, and the underlying software
    capabilities is essential. In this chapter, we will study the basics of performance
    analysis, including the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Clojure应用程序的性能取决于各种因素。对于一个特定的应用程序，理解其用例、设计实现、算法、资源需求和与硬件的匹配，以及底层软件能力是至关重要的。在本章中，我们将研究性能分析的基础，包括以下内容：
- en: Classifying the performance anticipations by the use cases types
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据用例类型对性能预期进行分类
- en: Outlining the structured approach to analyze performance
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概述分析性能的结构化方法
- en: A glossary of terms, commonly used to discuss performance aspects
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 术语表，通常用于讨论性能方面
- en: The performance numbers that every programmer should know
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个程序员都应该知道的性能数字
- en: Use case classification
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用例分类
- en: The performance requirements and priority vary across the different kinds of
    use cases. We need to determine what constitutes acceptable performance for the
    various kinds of use cases. Hence, we classify them to identify their performance
    model. When it comes to details, there is no sure shot performance recipe for
    any kind of use case, but it certainly helps to study their general nature. Note
    that in real life, the use cases listed in this section may overlap with each
    other.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型的用例的性能要求和优先级各不相同。我们需要确定各种用例可接受的性能标准。因此，我们将它们分类以识别其性能模型。在细节上，对于任何类型的用例，都没有一成不变的性能秘方，但研究它们的普遍性质肯定有帮助。请注意，在现实生活中，本节中列出的用例可能相互重叠。
- en: The user-facing software
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 面向用户的软件
- en: The performance of user-facing applications is strongly linked to the user's
    anticipation. Having a difference of a good number of milliseconds may not be
    perceptible for the user but at the same time, a wait of more than a few seconds
    may not be taken kindly. One important element in normalizing anticipation is
    to engage the user by providing duration-based feedback. A good idea to deal with
    such a scenario would be to start the task asynchronously in the background, and
    poll it from the UI layer to generate a duration-based feedback for the user.
    Another way could be to incrementally render the results to the user to even out
    the anticipation.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 面向用户的软件性能与用户的预期紧密相关。相差数十毫秒可能对用户来说并不明显，但与此同时，等待几秒钟以上可能不会受到欢迎。在正常化预期中的一个重要元素是通过提供基于持续时间的反馈来吸引用户。处理此类场景的一个好主意是在后台异步启动任务，并从UI层轮询它以生成基于持续时间的用户反馈。另一种方法是对用户逐步渲染结果，以平衡预期。
- en: Anticipation is not the only factor in user facing performance. Common techniques
    like staging or precomputation of data, and other general optimization techniques
    can go a long way to improve the user experience with respect to performance.
    Bear in mind that all kinds of user facing interfaces fall into this use case
    category—the Web, mobile web, GUI, command line, touch, voice-operated, gesture...you
    name it.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 预期并不是用户界面性能的唯一因素。常见的技巧，如数据分阶段或预计算，以及其他一般优化技术，可以在很大程度上提高用户体验的性能。请记住，所有类型的用户界面都落入此类用例类别——网页、移动网页、GUI、命令行、触摸、语音操作、手势……无论你叫它什么。
- en: Computational and data-processing tasks
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算和数据处理任务
- en: Non-trivial compute intensive tasks demand a proportional amount of computational
    resources. All of the CPU, cache, memory, efficiency and the parallelizability
    of the computation algorithms would be involved in determining the performance.
    When the computation is combined with distribution over a network or reading from/staging
    to disk, I/O bound factors come into play. This class of workloads can be further
    subclassified into more specific use cases.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 非平凡的密集型计算任务需要相应数量的计算资源。CPU、缓存、内存、计算算法的效率和并行性都会涉及到性能的确定。当计算结合网络分布或从磁盘读取/写入时，I/O限制因素就会发挥作用。这类工作负载可以进一步细分为更具体的用例。
- en: A CPU bound computation
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CPU密集型计算
- en: A CPU bound computation is limited by the CPU cycles spent on executing it.
    Arithmetic processing in a loop, small matrix multiplication, determining whether
    a number is a **Mersenne prime**, and so on, would be considered CPU bound jobs.
    If the algorithm complexity is linked to the number of iterations/operations *N*,
    such as *O(N)*, *O(N* *²)* and more, then the performance depends on how big *N*
    is, and how many CPU cycles each step takes. For parallelizable algorithms, performance
    of such tasks may be enhanced by assigning multiple CPU cores to the task. On
    virtual hardware, the performance may be impacted if the CPU cycles are available
    in bursts.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: CPU密集型计算受执行它所花费的CPU周期的限制。循环中的算术处理、小矩阵乘法、判断一个数是否是**梅森素数**等，都会被认为是CPU密集型任务。如果算法复杂度与迭代/操作数*N*相关，例如*O(N)*，*O(N²)*等，那么性能取决于*N*的大小以及每一步需要多少CPU周期。对于可并行化的算法，可以通过分配多个CPU核心给任务来提高这类任务的性能。在虚拟硬件上，如果CPU周期是突发性的，性能可能会受到影响。
- en: A memory bound task
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内存限制型任务
- en: A memory bound task is limited by the availability and bandwidth of the memory.
    Examples include large text processing, list processing, and more. For example,
    specifically in Clojure, the `(reduce f (pmap g coll))` operation would be memory
    bound if `coll` is a large sequence of big maps, even though we parallelize the
    operation using `pmap` here. Note that higher CPU resources cannot help when memory
    is the bottleneck, and vice versa. Lack of availability of memory may force you
    to process smaller chunks of data at a time, even if you have enough CPU resources
    at your disposal. If the maximum speed of your memory is *X* and your algorithm
    on single the core accesses the memory at speed *X/3*, the multicore performance
    of your algorithm cannot exceed three times the current performance, no matter
    how many CPU cores you assign to it. The memory architecture (for example, SMP
    and NUMA) contributes to the memory bandwidth in multicore computers. Performance
    with respect to memory is also subject to page faults.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 内存限制型任务受内存的可用性和带宽限制。例如，大文本处理、列表处理等。例如，在Clojure中，如果`coll`是一个由大映射组成的大序列，那么`(reduce
    f (pmap g coll))`操作将是内存限制型，即使我们在这里使用`pmap`来并行化操作。请注意，当内存是瓶颈时，更高的CPU资源无法帮助，反之亦然。内存不可用可能迫使你一次处理更小的数据块，即使你有足够的CPU资源可用。如果你的内存最大速度是*X*，而你的算法在单核上以速度*X/3*访问内存，那么你的算法的多核性能不能超过当前性能的三倍，无论你分配多少CPU核心给它。内存架构（例如，SMP和NUMA）对多核计算机的内存带宽有贡献。与内存相关的性能也受页面错误的影响。
- en: A cache bound task
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缓存限制型任务
- en: A task is cache bound when its speed is constrained by the amount of cache available.
    When a task retrieves values from a small number of repeated memory locations,
    for example a small matrix multiplication, the values may be cached and fetched
    from there. Note that CPUs (typically) have multiple layers of cache, and the
    performance will be at its best when the processed data fits in the cache, but
    the processing will still happen, more slowly, when the data does not fit into
    the cache. It is possible to make the most of the cache using **cache-oblivious**
    algorithms. A higher number of concurrent cache/memory bound threads than CPU
    cores is likely to flush the instruction pipeline, as well as the cache at the
    time of context switch, likely leading to a severely degraded performance.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当任务的速度受可用缓存量限制时，该任务就是缓存限制型。当一个任务从少量重复的内存位置检索值时，例如小矩阵乘法，这些值可能会被缓存并从那里检索。请注意，CPU（通常是）有多个缓存层，当处理的数据适合缓存时，性能将达到最佳，但如果数据不适合缓存，处理仍然会发生，但速度会慢一些。可以使用**缓存无关**算法最大限度地利用缓存。如果并发缓存/内存限制型线程的数量高于CPU核心数，很可能会在上下文切换时清空指令流水线和缓存，这可能导致性能严重下降。
- en: An input/output bound task
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个输入/输出（I/O）密集型任务
- en: An **input/output** (**I/O**) bound task would go faster if the I/O subsystem,
    that it depends on, goes faster. Disk/storage and network are the most commonly
    used I/O subsystems in data processing, but it can be serial port, a USB-connected
    card reader, or any I/O device. An I/O bound task may consume very few CPU cycles.
    Depending on the speed of the device, connection pooling, data compression, asynchronous
    handling, application caching, and more, may help in performance. One notable
    aspect of I/O bound tasks is that performance is usually dependent on the time
    spent waiting for connection/seek, and the amount of serialization that we do,
    and hardly on the other resources.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果依赖的I/O子系统运行得更快，一个输入/输出（I/O）密集型任务会运行得更快。磁盘/存储和网络是数据处理中最常用的I/O子系统，但也可以是串行端口、USB连接的卡片阅读器或任何I/O设备。一个I/O密集型任务可能消耗很少的CPU周期。根据设备速度、连接池、数据压缩、异步处理、应用程序缓存等，可能会有助于性能。I/O密集型任务的一个显著方面是，性能通常依赖于等待连接/查找的时间以及我们进行的序列化程度，而很少依赖于其他资源。
- en: In practice, many data processing workloads are usually a combination of CPU
    bound, memory bound, cache bound, and I/O bound tasks. The performance of such
    mixed workloads effectively depends on the even distribution of CPU, cache, memory,
    and I/O resources over the duration of the operation. A bottleneck situation arises
    only when one resource gets too busy to make way for another.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，许多数据处理工作负载通常是CPU密集型、内存密集型、缓存密集型和I/O密集型任务的组合。这类混合工作负载的性能实际上取决于在整个操作过程中CPU、缓存、内存和I/O资源的均匀分布。只有当某一资源过于繁忙而无法为其他资源让路时，才会出现瓶颈情况。
- en: Online transaction processing
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在线事务处理
- en: '**Online transaction processing** (**OLTP**) systems process the business transactions
    on demand. They can sit behind systems such as a user-facing ATM machine, point-of-sale
    terminal, a network-connected ticket counter, ERP systems, and more. The OLTP
    systems are characterized by low latency, availability, and data integrity. They
    run day-to-day business transactions. Any interruption or outage is likely to
    have a direct and immediate impact on sales or service. Such systems are expected
    to be designed for resiliency rather than delayed recovery from failures. When
    the performance objective is unspecified, you may like to consider graceful degradation
    as a strategy.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**在线事务处理**（**OLTP**）系统按需处理业务交易。它们可以位于用户界面ATM机、销售点终端、网络连接的票务柜台、ERP系统等系统之后。OLTP系统以低延迟、可用性和数据完整性为特点。它们运行日常业务交易。任何中断或故障都可能导致销售或服务直接且立即受到影响。这类系统应设计为具有弹性，而不是从故障中延迟恢复。当性能目标不明确时，您可能希望考虑优雅降级作为一种策略。'
- en: It is a common mistake to ask the OLTP systems to answer analytical queries,
    something that they are not optimized for. It is desirable for an informed programmer
    to know the capability of the system, and suggest design changes as per the requirements.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 请求OLTP系统回答分析查询是一个常见的错误，它们并不是为此优化的。一个有经验的程序员了解系统的能力，并根据需求提出设计更改是可取的。
- en: Online analytical processing
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在线分析处理
- en: '**Online analytical processing** (**OLAP**) systems are designed to answer
    analytical queries in a short time. They typically get data from the OLTP operations,
    and their data model is optimized for querying. They basically provide for consolidation
    (roll-up), drill-down and slicing and dicing of data for analytical purposes.
    They often use specialized data stores that can optimize ad-hoc analytical queries
    on the fly. It is important for such databases to provide pivot-table like capability.
    Often, the OLAP cube is used to get fast access to the analytical data.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**在线分析处理**（**OLAP**）系统旨在短时间内回答分析查询。它们通常从OLTP操作中获取数据，其数据模型针对查询进行了优化。它们基本上提供数据合并（汇总）、钻取和切片切块，以供分析使用。它们通常使用可以即时优化即席分析查询的特殊数据存储。对于这类数据库来说，提供类似数据透视表的功能非常重要。通常，OLAP立方体用于快速访问分析数据。'
- en: Feeding the OLTP data into the OLAP systems may entail workflows and multistage
    batch processing. The performance concern of such systems is to efficiently deal
    with large quantities of data while also dealing with inevitable failures and
    recovery.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 将OLTP数据输入到OLAP系统中可能涉及工作流程和多阶段批量处理。这类系统的性能关注点是高效处理大量数据的同时，还要处理不可避免的故障和恢复。
- en: Batch processing
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 批量处理
- en: '**Batch processing** is automated execution of predefined jobs. These are typically
    bulk jobs that are executed during off-peak hours. Batch processing may involve
    one or more stages of job processing. Often batch processing is clubbed with workflow
    automation, where some workflow steps are executed offline. Many of the batch
    processing jobs work on staging of data, and on preparing data for the next stage
    of processing to pick up.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**批处理**是指预定义作业的自动化执行。这些通常是批量作业，在非高峰时段执行。批处理可能涉及一个或多个作业处理阶段。通常批处理与工作流自动化结合使用，其中一些工作流步骤是在离线状态下执行的。许多批处理作业工作在数据准备阶段，为下一阶段的处理挑选数据。'
- en: Batch jobs are generally optimized for the best utilization of the computing
    resources. Since there is little to moderate the demand to lower the latencies
    of some particular subtasks, these systems tend to optimize for throughput. A
    lot of batch jobs involve largely I/O processing and are often distributed over
    a cluster. Due to distribution, the data locality is preferred when processing
    the jobs; that is, the data and processing should be local in order to avoid network
    latency in reading/writing data.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 批处理作业通常优化以最佳利用计算资源。由于几乎没有东西可以调节对降低某些特定子任务延迟的需求，这些系统倾向于优化吞吐量。许多批处理作业涉及大量的I/O处理，并且通常分布在集群上。由于分布，处理作业时优先考虑数据局部性；也就是说，数据和处理应该是本地的，以避免在读写数据时的网络延迟。
- en: A structured approach to the performance
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对性能的
- en: In practice, the performance of non-trivial applications is rarely a function
    of coincidence or prediction. For many projects, performance is not an option
    (it is rather a necessity), which is why this is even more important today. Capacity
    planning, determining performance objectives, performance modeling, measurement,
    and monitoring are key.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，非平凡应用程序的性能很少是巧合或预测的结果。对于许多项目来说，性能不是一种选择（而是一种必需品），这就是为什么这在今天尤为重要。容量规划、确定性能目标、性能建模、测量和监控是关键。
- en: Tuning a poorly designed system to perform is significantly harder, if not practically
    impossible, than having a system well-designed from the start. In order to meet
    a performance goal, performance objectives should be known before the application
    is designed. The performance objectives are stated in terms of latency, throughput,
    resource utilization, and workload. These terms are discussed in the following
    section in this chapter.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 调整一个设计不良的系统以实现性能，如果不说实际上是不可能的，那么比从一开始就设计一个良好的系统要困难得多。为了达到性能目标，在应用程序设计之前应该知道性能目标。性能目标用延迟、吞吐量、资源利用率和工作负载来表述。这些术语将在本章下一节中讨论。
- en: The resource cost can be identified in terms of application scenarios, such
    as browsing of products, adding products to shopping cart, checkout, and more.
    Creating workload profiles that represent users performing various operations
    is usually helpful.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 资源成本可以根据应用场景来识别，例如浏览产品、将产品添加到购物车、结账等。创建代表用户执行各种操作的工作负载配置文件通常是有帮助的。
- en: '**Performance modeling** is a reality check for whether the application design
    will support the performance objectives. It includes performance objectives, application
    scenarios, constraints, measurements (benchmark results), workload objectives
    and if available, the performance baseline. It is not a replacement for measurement
    and load testing, rather, the model is validated using these. The performance
    model may include the performance test cases to assert the performance characteristics
    of the application scenarios.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能建模**是检查应用程序设计是否支持性能目标的一种现实检查。它包括性能目标、应用程序场景、约束、测量（基准结果）、工作负载目标以及如果有的话，性能基线。它不是测量和负载测试的替代品，相反，模型是通过这些来验证的。性能模型可能包括性能测试用例，以断言应用程序场景的性能特征。'
- en: Deploying an application to production almost always needs some form of **capacity
    planning**. It has to take into account the performance objectives for today and
    for the foreseeable future. It requires an idea of the application architecture,
    and an understanding of how the external factors translate into the internal workload.
    It also requires informed expectations about the responsiveness and the level
    of service to be provided by the system. Often, capacity planning is done early
    in a project to mitigate the risk of provisioning delays.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 将应用程序部署到生产环境几乎总是需要某种形式的**容量规划**。它必须考虑今天的性能目标和可预见的未来的目标。它需要了解应用程序架构，以及外部因素如何转化为内部工作负载。它还需要对系统提供的响应性和服务水平有合理的预期。通常，容量规划在项目早期进行，以减轻配置延迟的风险。
- en: The performance vocabulary
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能词汇表
- en: There are several technical terms that are heavily used in performance engineering.
    It is important to understand these, as they form the cornerstone of the performance-related
    discussions. Collectively, these terms form a performance vocabulary. The performance
    is usually measured in terms of several parameters, where every parameter has
    roles to play—such parameters are a part of the vocabulary.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在性能工程中，有几个技术术语被广泛使用。理解这些术语很重要，因为它们是性能相关讨论的基础。这些术语共同构成了性能词汇表。性能通常以几个参数来衡量，每个参数都有其作用——这样的参数是词汇表的一部分。
- en: Latency
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 延迟
- en: '**Latency** is the time taken by an individual unit of work to complete the
    task. It does not imply successful completion of a task. Latency is not collective,
    it is linked to a particular task. If two similar jobs—`j1` and `j2` took 3 ms
    and 5 ms respectively, their latencies would be treated as such. If `j1` and `j2`
    were dissimilar tasks, it would have made no difference. In many cases the average
    latency of similar jobs is used in the performance objectives, measurement, and
    monitoring results.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**延迟** 是单个工作单元完成任务所需的时间。它并不表示任务的完成成功。延迟不是集体的，它与特定的任务相关。如果两个类似的工作任务——`j1` 和
    `j2` 分别耗时 3 毫秒和 5 毫秒，它们的延迟将被视为如此。如果 `j1` 和 `j2` 是不同的任务，那么这并没有区别。在许多情况下，类似工作的平均延迟被用于性能目标、测量和监控结果。'
- en: Latency is an important indicator of the health of a system. A high performance
    system often thrives on low latency. Higher than normal latency can be caused
    due to load or bottleneck. It helps to measure the latency distribution during
    a load test. For example, if more than 25 percent of similar jobs, under a similar
    load, have significantly higher latency than others, then it may be an indicator
    of a bottleneck scenario that is worth investigating.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟是衡量系统健康状况的重要指标。高性能系统通常依赖于低延迟。高于正常水平的延迟可能是由于负载或瓶颈造成的。在负载测试期间测量延迟分布有助于了解情况。例如，如果超过
    25% 的类似工作在类似负载下比其他工作有显著更高的延迟，那么这可能是值得调查的瓶颈场景的指标。
- en: When a task called `j1` consists of smaller tasks called `j2`, `j3`, and `j4`,
    the latency of `j1` is not necessarily the sum of the latencies of each of `j2`,
    `j3`, and `j4`. If any of the subtasks of `j1` are concurrent with another, the
    latency of `j1` will turn out to be less than the sum of the latencies of `j2`,
    `j3`, and `j4`. The I/O bound tasks are generally more prone to higher latency.
    In network systems, latency is commonly based on the round-trip to another host,
    including the latency from source to destination, and then back to source.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个名为 `j1` 的任务由名为 `j2`、`j3` 和 `j4` 的较小任务组成时，`j1` 的延迟不一定是 `j2`、`j3` 和 `j4` 各自延迟的总和。如果
    `j1` 的任何子任务与其他任务并发，`j1` 的延迟可能会小于 `j2`、`j3` 和 `j4` 延迟的总和。I/O 密集型任务通常更容易出现较高的延迟。在网络系统中，延迟通常基于往返另一个主机的总时间，包括从源到目的地的延迟，然后返回源。
- en: Throughput
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 吞吐量
- en: '**Throughput** is the number of successful tasks or operations performed in
    a unit of time. The top-level operations performed in a unit of time are usually
    of a similar kind, but with a potentially different from latencies. So, what does
    throughput tell us about the system? It is the rate at which the system is performing.
    When you perform load testing, you can determine the maximum rate at which a particular
    system can perform. However, this is not a guarantee of the conclusive, overall,
    and maximum rate of performance.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**吞吐量**是指在单位时间内完成的成功任务或操作的数量。在单位时间内执行的最顶层操作通常属于同一类，但延迟可能不同。那么，吞吐量告诉我们关于系统的什么信息呢？它是系统执行的速度。当你进行负载测试时，你可以确定特定系统可以执行的最大速率。然而，这并不能保证系统性能的最终、整体和最大速率。'
- en: Throughput is one of the factors that determine the scalability of a system.
    The throughput of a higher level task depends on the capacity to spawn multiple
    such tasks in parallel, and also on the average latency of those tasks. The throughput
    should be measured during load testing and performance monitoring to determine
    the peak-measured throughput, and the maximum-sustained throughput. These factors
    contribute to the scale and performance of a system.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 吞吐量是决定系统可扩展性的因素之一。较高层次任务的吞吐量取决于并行生成多个此类任务的能力，以及这些任务的平均延迟。吞吐量应在负载测试和性能监控期间进行测量，以确定峰值吞吐量和最大持续吞吐量。这些因素有助于决定系统的规模和性能。
- en: Bandwidth
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带宽
- en: '**Bandwidth** is the raw data rate over a communication channel, measured in
    a certain number of bits per second. This includes not only the payload, but also
    all the overhead necessary to carry out the communication. Some examples are:
    Kbits/sec, Mbits/sec, and more. An uppercase B such as KB/sec denotes Bytes, as
    in kilobytes per second. Bandwidth is often compared to throughput. While bandwidth
    is the raw capacity, throughput for the same system is the successful task completion
    rate, which usually involves a round-trip. Note that throughput is for an operation
    that involves latency. To achieve maximum throughput for a given bandwidth, the
    communication/protocol overhead and operational latency should be minimal.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**带宽**是指通信通道上的原始数据速率，以每秒一定数量的比特来衡量。这包括不仅包括有效载荷，还包括执行通信所需的所有开销。一些例子包括：Kbits/sec、Mbits/sec等。大写字母B，如KB/sec，表示字节，即每秒千字节。带宽通常与吞吐量进行比较。虽然带宽是原始容量，但对于同一系统，吞吐量是成功任务完成率，通常涉及往返。请注意，吞吐量涉及延迟的操作。为了在给定带宽下实现最大吞吐量，通信/协议开销和操作延迟应尽可能小。'
- en: For storage systems (such as hard disks, solid-state drives, and more) the predominant
    way to measure performance is **IOPS** (**Input-output per second**), which is
    multiplied by the transfer size and represented as bytes per second, or further
    into MB/sec, GB/sec, and more. IOPS is usually derived for sequential and random
    workloads for read/write operations.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于存储系统（如硬盘、固态硬盘等），衡量性能的主要方式是**IOPS**（每秒输入输出），它是通过传输大小乘以的，表示为每秒字节数，或者进一步表示为MB/sec、GB/sec等。IOPS通常用于顺序和随机工作负载的读写操作。
- en: 'Mapping the throughput of a system to the bandwidth of another may lead to
    dealing with an impedance mismatch between the two. For example, an order processing
    system may perform the following tasks:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 将系统的吞吐量映射到另一个带宽可能会导致处理两个系统之间的阻抗不匹配。例如，一个订单处理系统可能执行以下任务：
- en: Transact with the database on disk
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与磁盘上的数据库进行交易
- en: Post results over the network to an external system
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将结果通过网络发送到外部系统
- en: Depending on the bandwidth of the disk sub-system, the bandwidth of the network,
    and the execution model of order processing, the throughput may depend not only
    on the bandwidth of the disk sub-system and network, but also on how loaded they
    currently are. Parallelism and pipelining are common ways to increase the throughput
    over a given bandwidth.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 根据磁盘子系统、网络带宽以及订单处理执行模型的不同，吞吐量可能不仅取决于磁盘子系统和网络的带宽，还取决于它们当前的负载情况。并行化和流水线是提高给定带宽吞吐量的常见方法。
- en: Baseline and benchmark
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基准和基准测试
- en: The performance **baseline**, or simply baseline, is the reference point, including
    measurements of well-characterized and understood performance parameters for a
    known configuration. The baseline is used to collect performance measurements
    for the same parameters that we may benchmark later for another configuration.
    For example, collecting "throughput distribution over 10 minutes at a load of
    50 concurrent threads" is one such performance parameter that we can use for baseline
    and benchmarking. A baseline is recorded together with the hardware, network,
    OS and JVM configuration.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 性能**基准线**，或简称基准线，是参考点，包括对已知配置中良好定义和理解的性能参数的测量。基准线用于收集我们可能后来为另一个配置基准测试的相同参数的性能测量。例如，收集“在50个并发线程负载下10分钟内的吞吐量分布”是这样一种性能参数，我们可以用它作为基准和基准测试。基准线与硬件、网络、操作系统和JVM配置一起记录。
- en: The performance **benchmark**, or simply benchmark, is the recording of the
    performance parameter measurements under various test conditions. A benchmark
    can be composed of a performance test suite. A benchmark may collect small to
    large amounts of data, and may take varying durations depending on the use-cases,
    scenarios, and environment characteristics.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 性能**基准**，或简称基准，是在各种测试条件下记录性能参数测量的过程。一个基准可以由一个性能测试套件组成。基准可能收集从小到大的数据量，并且可能根据用例、场景和环境特性而持续不同时长。
- en: A baseline is a result of the benchmark that was conducted at one point in time.
    However, a benchmark is independent of the baseline.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 基准线是在某个时间点进行的基准测试的结果。然而，基准与基准线是独立的。
- en: Profiling
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能分析
- en: '**Performance** **profiling** , or simply profiling, is the analysis of the
    execution of a program at its runtime. A program can perform poorly for a variety
    of reasons. A **profiler** can analyze and find out the execution time of various
    parts of the program. It is possible to put statements in a program manually to
    print the execution time of the blocks of code, but it gets very cumbersome as
    you try to refine the code iteratively.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能** **分析**，或简称分析，是在程序运行时对其执行的分析。程序可能由于各种原因表现不佳。分析器可以分析和找出程序各部分的执行时间。手动在程序中放置语句以打印代码块的执行时间是可能的，但随着您尝试迭代地改进代码，这会变得非常繁琐。'
- en: A profiler is of great assistance to the developer. Going by how profilers work,
    there are three major kinds—instrumenting, sampling, and event-based.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 分析器对开发者非常有帮助。根据分析器的工作原理，主要有三种类型——仪器化、采样和基于事件。
- en: '**Event-based profilers**: These profilers work only for selected language
    platforms, and provide a good balance between the overhead and results; Java supports
    event-based profiling via the JVMTI interface.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于事件的分析器**：这些分析器仅适用于选定的语言平台，并在开销和结果之间提供了良好的平衡；Java通过JVMTI接口支持基于事件的性能分析。'
- en: '**The instrumenting profilers**: These profilers modify code at either compile
    time, or runtime to inject performance counters. They are intrusive by nature
    and add significant performance overhead. However, you can profile the regions
    of code very selectively using the instrumenting profilers.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仪器分析器**：这些分析器在编译时或运行时修改代码以注入性能计数器。它们本质上是侵入性的，并增加了显著的性能开销。然而，您可以使用仪器分析器非常选择性地分析代码区域。'
- en: '**The sampling profilers**: These profilers pause the runtime and collect its
    state at "sampling intervals". By collecting enough samples, they get to know
    where the program is spending most of its time. For example, at a sampling interval
    of 1 millisecond, the profiler would have collected 1000 samples in a second.
    A sampling profiler also works for code that executes faster than the sampling
    interval (as in, the code may perform several iterations of work between the two
    sampling events), as the frequency of pausing and sampling is proportional to
    the overall execution time of any code.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**采样分析器**：这些分析器在“采样间隔”暂停运行时并收集其状态。通过收集足够的样本，它们可以了解程序大部分时间花在了哪里。例如，在1毫秒的采样间隔下，分析器在一秒钟内会收集1000个样本。采样分析器也适用于执行速度超过采样间隔的代码（即，代码可能在两次采样事件之间执行几个工作迭代），因为暂停和采样的频率与任何代码的整体执行时间成比例。'
- en: Profiling is not meant only for measuring execution time. Capable profilers
    can provide a view of memory analysis, garbage collection, threads, and more.
    A combination of such tools is helpful to find memory leaks, garbage collection
    issues, and so on.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 分析并不仅限于测量执行时间。有能力的分析器可以提供内存分析、垃圾回收、线程等方面的视图。这些工具的组合有助于找到内存泄漏、垃圾回收问题等。
- en: Performance optimization
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能优化
- en: Simply put, **optimization** is enhancing a program's resource consumption after
    a performance analysis. The symptoms of a poorly performing program are observed
    in terms of high latency, low throughput, unresponsiveness, instability, high
    memory consumption, high CPU consumption, and more. During the performance analysis,
    one may profile the program in order to identify the bottlenecks and tune the
    performance incrementally by observing the performance parameters.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，**优化**是在性能分析之后增强程序的资源消耗。性能不佳的程序的症状可以从高延迟、低吞吐量、无响应、不稳定、高内存消耗、高CPU消耗等方面观察到。在性能分析期间，可以通过分析程序来识别瓶颈，并通过观察性能参数逐步调整性能。
- en: Better and suitable algorithms are an all-around good way to optimize code.
    The CPU bound code can be optimized with computationally cheaper operations. The
    cache bound code can try using less memory lookups to keep a good hit ratio. The
    memory bound code can use an adaptive memory usage and conservative data representation
    to store in memory for optimization. The I/O bound code can attempt to serialize
    as little data as possible, and batching of operations will make the operation
    less chatty for better performance. Parallelism and distribution are other, overall
    good ways to increase performance.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 选择更好和更合适的算法是优化代码的全面好方法。对于CPU密集型代码，可以通过计算成本更低的操作进行优化。对于缓存密集型代码，可以尝试使用更少的内存查找来保持良好的命中率。对于内存密集型代码，可以使用自适应内存使用和保守的数据表示来存储在内存中进行优化。对于I/O密集型代码，可以尝试尽可能少地序列化数据，并且操作批处理将使操作更少地聊天，从而提高性能。并行性和分布式是其他，整体上好的提高性能的方法。
- en: Concurrency and parallelism
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发与并行
- en: Most of the computer hardware and operating systems that we use today provide
    concurrency. On the x86 architecture, hardware support for concurrency can be
    traced as far back as the 80286 chip. **Concurrency** is the simultaneous execution
    of more than one process on the same computer. In older processors, concurrency
    was implemented using the context switch by the operating system kernel. When
    concurrent parts are executed in parallel by the hardware instead of merely the
    switching context, it is called **parallelism**. Parallelism is the property of
    the hardware, though the software stack must support it in order for you to leverage
    it in your programs. We must write your program in a concurrent way to exploit
    the parallelism features of the hardware.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们今天使用的绝大多数计算机硬件和操作系统都提供了并发功能。在x86架构上，对并发的硬件支持可以追溯到80286芯片。**并发**是在同一台计算机上同时执行多个进程。在较老的处理器中，并发是通过操作系统内核的上下文切换来实现的。当并发部分由硬件并行执行而不是仅仅切换上下文时，这被称为**并行性**。并行性是硬件的特性，尽管软件堆栈必须支持它，以便你在程序中利用它。我们必须以并发的方式编写程序，以利用硬件的并行性特性。
- en: While concurrency is a natural way to exploit hardware parallelism and speed
    up operations, it is worth bearing in mind that having significantly higher concurrency
    than the parallelism that your hardware can support is likely to schedule tasks
    to varying processor cores thereby, lowering the branch prediction and increasing
    cache misses.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然并发是利用硬件并行性和加快操作的自然方式，但值得记住的是，拥有比你的硬件支持的并行性显著更高的并发性可能会导致任务调度到不同的处理器核心，从而降低分支预测并增加缓存未命中。
- en: At a low level, spawning the processes/threads, mutexes, semaphores, locking,
    shared memory, and interprocess communication are used for concurrency. The JVM
    has an excellent support for these concurrency primitives and interthread communication.
    Clojure has both—the low and higher level concurrency primitives that we will
    discuss in the concurrency chapter.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在低级别上，用于并发的进程/线程、互斥锁、信号量、锁定、共享内存和进程间通信是通过创建进程/线程、互斥锁、信号量、锁定、共享内存和进程间通信来实现的。JVM对这些并发原语和线程间通信提供了出色的支持。Clojure既有低级也有高级并发原语，我们将在并发章节中讨论。
- en: Resource utilization
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源利用率
- en: R**esource utilization** is the measure of the server, network, and storage
    resources that is consumed by an application. Resources include CPU, memory, disk
    I/O, network I/O, and more. The application can be analyzed in terms of CPU bound,
    memory bound, cache bound, and I/O bound tasks. Resource utilization can be derived
    by means of benchmarking, by measuring the utilization at a given throughput.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源利用率**是衡量应用程序消耗的服务器、网络和存储资源的度量。资源包括 CPU、内存、磁盘 I/O、网络 I/O 等。可以从 CPU 密集型、内存密集型、缓存密集型和
    I/O 密集型任务的角度分析应用程序。资源利用率可以通过基准测试、在给定吞吐量下测量利用率来得出。'
- en: Workload
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作负载
- en: '**Workload** is the quantification of how much work is there in hand to be
    carried out by the application. It is measured in the total numbers of users,
    the concurrent active users, the transaction volume, the data volume, and more.
    Processing a workload should take in to account the load conditions, such as how
    much data the database currently holds, how filled up the message queues are,
    the backlog of I/O tasks after which the new load will be processed, and more.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**工作负载**是指应用程序需要完成的工作量。它通过总用户数、并发活跃用户、交易量、数据量等来衡量。处理工作负载时应考虑负载条件，例如数据库当前持有的数据量、消息队列的填充程度、I/O
    任务的积压情况以及更多。'
- en: The latency numbers that every programmer should know
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 每个程序员都应该知道的延迟数字
- en: 'Hardware and software have progressed over the years. Latencies for various
    operations put things in perspective. The latency numbers for the year 2015, reproduced
    with the permission of Aurojit Panda and Colin Scott of Berkeley University ([http://www.eecs.berkeley.edu/~rcs/research/interactive_latency.html](http://www.eecs.berkeley.edu/~rcs/research/interactive_latency.html)).
    Latency numbers that every programmer should know are as shown in the following
    table:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，硬件和软件都取得了进步。各种操作的延迟使事情有了新的视角。以下表格展示了 2015 年的延迟数字，经加州大学伯克利分校的 Aurojit
    Panda 和 Colin Scott 允许复制（[http://www.eecs.berkeley.edu/~rcs/research/interactive_latency.html](http://www.eecs.berkeley.edu/~rcs/research/interactive_latency.html)）。每个程序员都应该知道的延迟数字如下表所示：
- en: '| Operation | Time taken as of 2015 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | 2015 年所需时间 |'
- en: '| --- | --- |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| L1 cache reference | 1ns (nano second) |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| L1 缓存引用 | 1ns（纳秒）|'
- en: '| Branch mispredict | 3 ns |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 分支预测错误 | 3 ns |'
- en: '| L2 cache reference | 4 ns |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| L2 缓存引用 | 4 ns |'
- en: '| Mutex lock/unlock | 17 ns |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 互斥锁/解锁 | 17 ns |'
- en: '| Compress 1KB with Zippy(Zippy/Snappy: [http://code.google.com/p/snappy/](http://code.google.com/p/snappy/))
    | 2μs (1000 ns = 1μs: micro second) |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 使用 Zippy（Zippy/Snappy：[http://code.google.com/p/snappy/](http://code.google.com/p/snappy/))
    压缩 1KB | 2μs（1000 ns = 1μs：微秒）|'
- en: '| Send 2000 bytes over the commodity network | 200ns (that is, 0.2μs) |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 在商品网络上发送 2000 字节 | 200ns（即 0.2μs）|'
- en: '| SSD random read | 16 μs |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| SSD 随机读取 | 16 μs |'
- en: '| Round-trip in the same datacenter | 500 μs |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 同一数据中心内的往返 | 500 μs |'
- en: '| Read 1,000,000 bytes sequentially from SSD | 200 μs |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 从 SSD 顺序读取 1,000,000 字节 | 200 μs |'
- en: '| Disk seek | 4 ms (1000 μs = 1 ms) |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 磁盘寻道 | 4 ms（1000 μs = 1 ms）|'
- en: '| Read 1,000,000 bytes sequentially from disk | 2 ms |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 从磁盘顺序读取 1,000,000 字节 | 2 ms |'
- en: '| Packet roundtrip CA to Netherlands | 150 ms |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 从 CA 到荷兰的数据包往返 | 150 ms |'
- en: The preceding table shows the operations in a computer vis-a-vis the latency
    incurred due to the operation. When a CPU core processes some data in a CPU register,
    it may take a few CPU cycles (for reference, a 3 GHz CPU runs 3000 cycles per
    nanosecond), but the moment it has to fall back on L1 or L2 cache, the latency
    becomes thousands of times slower. The preceding table does not show main memory
    access latency, which is roughly 100 ns (it varies, based on the access pattern)—about
    25 times slower than the L2 cache.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的表格显示了计算机中的操作及其引起的延迟。当 CPU 核在 CPU 寄存器中处理一些数据时，它可能需要几个 CPU 循环（以 3 GHz CPU 为例，每纳秒运行
    3000 个循环），但一旦它必须回退到 L1 或 L2 缓存，延迟就会慢数千倍。前面的表格没有显示主内存访问延迟，这大约是 100 纳秒（根据访问模式而变化）——大约是
    L2 缓存的 25 倍慢。
- en: Summary
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: We learned about the basics of what it is like to think more deeply about performance.
    We saw the common performance vocabulary, and also the use cases by which performance
    aspects might vary. We concluded by looking at the performance numbers for the
    different hardware components, which is how performance benefits reach our applications.
    In the next chapter, we will dive into the performance aspects of the various
    Clojure abstractions.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了深入思考性能的基础知识。我们了解了常见的性能词汇，以及性能方面可能变化的用例。通过查看不同硬件组件的性能数据，我们得出了性能优势如何传递到我们的应用中的结论。在下一章中，我们将深入探讨各种Clojure抽象的性能方面。
