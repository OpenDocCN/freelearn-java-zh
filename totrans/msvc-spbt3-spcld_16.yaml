- en: '16'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '16'
- en: Deploying Our Microservices to Kubernetes
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将我们的微服务部署到 Kubernetes
- en: In this chapter, we will deploy the microservices in this book to Kubernetes.
    To bundle and configure the microservices for Deployments in different runtime
    environments, **Helm**, a package manager for Kubernetes, will be used. Before
    doing that, we need to review how Service discovery is used. Since Kubernetes
    comes with built-in support for Service discovery, it seems unnecessary to deploy
    Netflix Eureka for that purpose. Finally, we will also try out some Spring Boot
    features that facilitate the Deployment of microservices in Kubernetes.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将部署本书中的微服务到 Kubernetes。为了在不同运行环境中打包和配置微服务以进行部署，我们将使用 Kubernetes 的包管理器
    **Helm**。在这样做之前，我们需要回顾一下服务发现是如何使用的。由于 Kubernetes 内置了对服务发现的支持，因此似乎没有必要部署 Netflix
    Eureka 来实现这一目的。最后，我们还将尝试一些有助于在 Kubernetes 中部署微服务的 Spring Boot 功能。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Replacing Netflix Eureka with Kubernetes Service objects and `kube-proxy` for
    Service discovery
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用 Kubernetes 服务对象和 `kube-proxy` 替换 Netflix Eureka 进行服务发现
- en: Introducing how Kubernetes will be used
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 Kubernetes 的使用方法
- en: Using Spring Boot’s support for graceful shutdown and probes for liveness and
    readiness
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Spring Boot 对优雅关闭和存活性/就绪性探测的支持
- en: Using Helm to package, configure, and deploy the microservices in different
    environments
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Helm 打包、配置和在不同环境中部署微服务
- en: Verifying the Deployments with the test script, `test-em-all.bash`
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用测试脚本 `test-em-all.bash` 验证部署
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For instructions on how to install the tools used in this book and how to access
    the source code for this book, see:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何安装本书中使用的工具以及如何访问本书的源代码的说明，请参阅：
- en: '*Chapter 21*, *Installation Instructions for macOS*'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第 21 章*，*macOS 安装说明*'
- en: '*Chapter 22*, *Installation Instructions for Microsoft Windows with WSL 2 and
    Ubuntu*'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第 22 章*，*使用 WSL 2 和 Ubuntu 的 Microsoft Windows 安装说明*'
- en: The code examples in this chapter all come from the source code in `$BOOK_HOME/Chapter16`.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的代码示例均来自 `$BOOK_HOME/Chapter16` 的源代码。
- en: If you want to view the changes applied to the source code in this chapter,
    that is, see what it took to deploy the microservices on Kubernetes, you can compare
    this source code with that in *Chapter 15*, *Introduction to Kubernetes*. You
    can use your favorite `diff` tool and compare the two folders, `$BOOK_HOME/Chapter15`
    and `$BOOK_HOME/Chapter16`.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要查看本章源代码中应用的变化，即查看在 Kubernetes 上部署微服务所需的内容，你可以将此源代码与 *第 15 章*，*Kubernetes
    简介* 中的源代码进行比较。你可以使用你喜欢的 `diff` 工具比较两个文件夹，`$BOOK_HOME/Chapter15` 和 `$BOOK_HOME/Chapter16`。
- en: Replacing Netflix Eureka with Kubernetes Services
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用 Kubernetes 服务替换 Netflix Eureka
- en: As shown in the previous chapter, *Chapter 15*, *Introduction to Kubernetes*,
    Kubernetes comes with a built-in discovery **service** based on Kubernetes Service
    objects and the `kube-proxy` runtime component. This makes it unnecessary to deploy
    a separate discovery Service such as Netflix Eureka, which we used in the previous
    chapters.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章，*第 15 章*，*Kubernetes 简介* 所示，Kubernetes 内置了一个基于 Kubernetes 服务对象和 `kube-proxy`
    运行时组件的发现 **服务**。这使得部署像 Netflix Eureka 这样的单独发现服务变得不必要，我们在前几章中使用了它。
- en: An advantage of using the Kubernetes discovery Service is that it doesn’t require
    a client library such as Spring Cloud LoadBalancer, which we have used together
    with Netflix Eureka. This makes the Kubernetes discovery Service easy to use,
    independent of which language or framework a microservice is based on.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 发现服务的一个优点是它不需要像我们与 Netflix Eureka 一起使用的 Spring Cloud LoadBalancer
    这样的客户端库。这使得 Kubernetes 发现服务易于使用，与微服务基于哪种语言或框架无关。
- en: A drawback of using the Kubernetes discovery Service is that it only works in
    a Kubernetes environment. However, since the discovery Service is based on `kube-proxy`,
    which accepts requests to the DNS name or IP address of a Service object, it should
    be fairly simple to replace it with a similar discovery Service, for example,
    one that comes bundled with another container orchestrator.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 发现服务的缺点是它只能在 Kubernetes 环境中工作。然而，由于发现服务基于接受服务对象 DNS 名称或 IP 地址请求的
    `kube-proxy`，因此用类似的发现服务替换它应该相当简单，例如，另一个容器编排器捆绑的服务。
- en: 'To summarize this, we will remove the discovery server based on Netflix Eureka
    from our microservice landscape, as illustrated in the following diagram:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 总结这一点，我们将从我们的微服务架构中移除基于 Netflix Eureka 的发现服务器，如下面的图所示：
- en: '![Diagram  Description automatically generated](img/B19825_16_01.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图描述自动生成](img/B19825_16_01.png)'
- en: 'Figure 16.1: Replacing Netflix Eureka with the Kubernetes built-in discovery
    Service'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.1：用Kubernetes内置的发现服务替换Netflix Eureka
- en: 'To replace the discovery server based on Netflix Eureka with the built-in discovery
    Service in Kubernetes, we need to make some changes in our build and configuration
    files. We do not need to make any changes in the Java source code, except for
    some of the test classes, where a property is no longer required and, therefore,
    will be removed. The following changes have been applied to the source code:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要将基于Netflix Eureka的发现服务器替换为Kubernetes内置的发现服务，我们需要在我们的构建和配置文件中做一些修改。我们不需要对Java源代码进行任何修改，除了某些测试类，其中不再需要属性，因此将被删除。以下更改已应用于源代码：
- en: Netflix Eureka and the Spring Cloud LoadBalancer-specific configuration (client
    and server) have been removed from the configuration repository, `config-repo`.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Netflix Eureka和Spring Cloud LoadBalancer特定配置（客户端和服务器）已从配置存储库`config-repo`中移除。
- en: Routing rules in the gateway Service to the Eureka server have been removed
    from the `config-repo/gateway.yml` file.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已从`config-repo/gateway.yml`文件中移除了网关服务到Eureka服务器的路由规则。
- en: The Eureka server project, in the `spring-cloud/eureka-server` folder, has been
    removed.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spring-cloud/eureka-server`文件夹中的Eureka服务器项目已被移除。'
- en: The Eureka server has been removed from the Docker Compose files and the `settings.gradle`
    Gradle file.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已从Docker Compose文件和`settings.gradle` Gradle文件中移除了Eureka服务器。
- en: The dependency on `spring-cloud-starter-netflix-eureka-client` has been removed
    in all of Eureka’s client build files, `build.gradle`.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已从所有Eureka客户端构建文件`build.gradle`中移除了对`spring-cloud-starter-netflix-eureka-client`的依赖。
- en: The property setting `eureka.client.enabled=false` has been removed from all
    integration tests of former Eureka clients.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已从以前Eureka客户端的所有集成测试中移除了属性设置`eureka.client.enabled=false`。
- en: The gateway Service no longer uses routing based on the client-side load balancer
    in Spring Cloud LoadBalancer, using the `lb` protocol. For example, the `lb://product-composite`
    routing destination has been replaced with `http://product-composite` in the `config-repo/gateway.yml`
    file.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网关服务不再使用Spring Cloud LoadBalancer中的客户端负载均衡器的路由。例如，`lb://product-composite`路由目标在`config-repo/gateway.yml`文件中已被替换为`http://product-composite`。
- en: 'The HTTP port used by the microservices and the authorization server has been
    changed from port `8080` (`9999` in the case of the authorization server) to the
    default HTTP port, `80`. This has been configured in `config-repo` for each affected
    Service, like so:'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务和授权服务器使用的HTTP端口已从端口`8080`（在授权服务器的情况下为`9999`）更改为默认HTTP端口`80`。这已在`config-repo`中为每个受影响的Service进行配置，如下所示：
- en: '[PRE0]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'None of the HTTP addresses that we will use are affected by the replacement
    of Netflix Eureka with Kubernetes Services. For example, addresses used by the
    composite Service are unaffected:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的所有HTTP地址都不会受到用Kubernetes服务替换Netflix Eureka的影响。例如，复合服务使用的地址不受影响：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This is because we changed the HTTP port used by the microservices and the authorization
    server to the default HTTP port, `80`, as described previously.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为我们已将微服务和授权服务器使用的HTTP端口更改为默认HTTP端口`80`，如前所述。
- en: Using Docker Compose still works, even though Netflix Eureka has been removed.
    The main reason that this works is that the container names in the Docker Compose
    files are the same as the corresponding Service names used in Kubernetes, meaning
    that the microservices’ DNS names are the same in both environments. This can
    be used to run functional tests of the microservices without deploying them to
    Kubernetes, for example, running `test-em-all.bash` together with Docker Desktop
    in the same way we did in the previous chapters. Removing Netflix Eureka, however,
    means that we no longer have a discovery Service in place when using plain Docker
    and Docker Compose. Therefore, scaling microservices will only work when deploying
    to Kubernetes.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 即使移除了Netflix Eureka，使用Docker Compose仍然有效。这之所以可行，是因为Docker Compose文件中的容器名称与Kubernetes中使用的相应服务名称相同，这意味着微服务的DNS名称在两个环境中都是相同的。这可以用来在不部署到Kubernetes的情况下运行微服务的功能测试，例如，与Docker
    Desktop一起运行`test-em-all.bash`，就像我们在前面的章节中所做的那样。然而，移除Netflix Eureka意味着当我们使用纯Docker和Docker
    Compose时，不再有发现服务。因此，只有在部署到Kubernetes时，微服务的扩展才能工作。
- en: In *Chapter 17*, *Implementing Kubernetes Features to Simplify the System Landscape*,
    in the section *Verifying that microservices work without Kubernetes*, we will
    discuss the importance of avoiding the source code of the microservices being
    dependent on the Kubernetes platform, thus avoiding vendor lock-in. We will also
    use the test script `test-em-all.bash`, together with Docker Compose, to verify
    that the microservices don’t require Kubernetes from a functional perspective.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *第 17 章*，*通过实现 Kubernetes 功能简化系统景观*，在 *验证微服务无需 Kubernetes 也能工作* 的部分，我们将讨论避免微服务源代码依赖于
    Kubernetes 平台的重要性，从而避免供应商锁定。我们还将使用测试脚本 `test-em-all.bash` 以及 Docker Compose 来验证微服务在功能上不需要
    Kubernetes。
- en: Now that we’ve familiarized ourselves with how Netflix Eureka will be replaced
    with Kubernetes Services, let’s introduce the other Kubernetes objects we will
    use.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经熟悉了 Netflix Eureka 将如何被 Kubernetes 服务所取代，那么让我们介绍其他我们将使用的 Kubernetes 对象。
- en: Introducing how Kubernetes will be used
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 Kubernetes 的使用方法
- en: 'Later on in the chapter, we will see in detail how various Kubernetes objects
    are used to deploy the microservices and the resource managers they depend on,
    like databases and queue managers. Before delving into all the details, let’s
    get an overview of the Kubernetes objects that will be used:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的后面部分，我们将详细看到如何使用各种 Kubernetes 对象来部署微服务以及它们所依赖的资源管理器，如数据库和队列管理器。在深入所有细节之前，让我们先了解一下将要使用的
    Kubernetes 对象：
- en: For each microservice, database, and queue manager that will be deployed in
    Kubernetes, one Deployment object and one Service object will be created. For
    all components, except for the edge server named `gateway`, the Service object
    will be of type `ClusterIP`. For the gateway, the Service object will be of type
    `NodePort`, accepting external HTTPS requests on port `30433`.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于将在 Kubernetes 中部署的每个微服务、数据库和队列管理器，将创建一个 Deployment 对象和一个 Service 对象。对于所有组件，除了名为
    `gateway` 的边缘服务器外，Service 对象的类型将是 `ClusterIP`。对于网关，Service 对象的类型将是 `NodePort`，在端口
    `30433` 接受外部 HTTPS 请求。
- en: The config server will use a ConfigMap, containing the configuration files in
    the `config-repo`.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置服务器将使用 ConfigMap，其中包含 `config-repo` 中的配置文件。
- en: 'To hold credentials for the config server and its clients, two Secrets will
    be created: one for the config server and one for its clients.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了存储配置服务器及其客户端的凭证，将创建两个 Secrets：一个用于配置服务器，一个用于其客户端。
- en: Now that we’ve seen what Kubernetes objects will be created, let’s learn about
    the Spring Boot features that facilitate deployment to Kubernetes.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了将要创建的 Kubernetes 对象，让我们学习一下 Spring Boot 的功能，这些功能有助于简化 Kubernetes 的部署。
- en: Using Spring Boot’s support for graceful shutdown and probes for liveness and
    readiness
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Spring Boot 对优雅关闭和存活性/就绪性探测的支持
- en: 'Back in Spring Boot v2.3, a couple of useful features were added to support
    Deployments to Kubernetes:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Spring Boot v2.3 中，添加了一些有用的功能来支持将部署到 Kubernetes：
- en: '**Graceful shutdown:**'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优雅关闭：**'
- en: Whenever a microservice instance needs to be stopped, for example, in a rolling
    upgrade scenario, there is a risk that active requests are affected when the instance
    is stopped. To minimize this risk, Spring Boot has added support for graceful
    shutdown. When applying graceful shutdown, a microservice stops accepting new
    requests and waits for a configurable time for active requests to complete before
    it shuts down the application. Requests that take a longer time to complete than
    the shutdown wait period will be aborted. These requests will be seen as exceptional
    cases that a shutdown procedure can’t wait for before it stops the application.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当微服务实例需要停止时，例如在滚动升级场景中，当实例停止时可能会影响活动请求。为了最小化这种风险，Spring Boot 添加了对优雅关闭的支持。在应用优雅关闭时，微服务停止接受新的请求，并在关闭应用程序之前等待一个可配置的时间，以便完成活动请求。完成时间超过关闭等待期的请求将被终止。这些请求将被视为异常情况，关闭程序在停止应用程序之前不能等待。
- en: 'Graceful shutdown has been enabled with a waiting period of 10 seconds for
    all microservices by adding the following to the common file `application.yml`
    in the `config-repo` folder:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在 `config-repo` 文件夹中的公共文件 `application.yml` 中添加以下内容，为所有微服务启用了优雅关闭，等待期为 10
    秒：
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: For more information, see [https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#features.graceful-shutdown](https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#features.graceful-shutdown).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息，请参阅 [https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#features.graceful-shutdown](https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#features.graceful-shutdown)。
- en: '**Liveness and readiness probes:**'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存活性和就绪性探针：**'
- en: As described in *Chapter 15*, *Introduction to Kubernetes*, proper implementations
    of liveness and readiness probes are essential for Kubernetes to be able to manage
    our Pods.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如在第 15 章《Kubernetes 简介》中所述，正确实现存活性和就绪性探针对于 Kubernetes 能够管理我们的 Pods 至关重要。
- en: To briefly recap, a liveness probe tells Kubernetes if a Pod needs to be replaced,
    and a readiness probe tells Kubernetes if its Pod is ready to accept requests.
    To simplify this work, Spring Boot has added support to implement liveness and
    readiness probes. The probes are exposed on the URLs `/actuator/health/liveness`
    and `/actuator/health/readiness` respectively. They can either be declared by
    configuration or implementation in source code, if increased control is required
    compared to what configuration gives. When declaring the probes by configuration,
    a **health group** can be declared for each probe, specifying what existing health
    indicators it should include. For example, a readiness probe should report `DOWN`
    if a microservice can’t access its MongoDB database. In this case, the health
    group for the readiness probe should include the `mongo` health indicator. For
    available health indicators, see [https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#actuator.endpoints.health.auto-configured-health-indicators](https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#actuator.endpoints.health.auto-configured-health-indicators).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 简要回顾一下，存活性探针告诉 Kubernetes 是否需要替换 Pod，而就绪性探针告诉 Kubernetes 其 Pod 是否准备好接受请求。为了简化这项工作，Spring
    Boot 添加了对实现存活性和就绪性探针的支持。这些探针分别暴露在 `/actuator/health/liveness` 和 `/actuator/health/readiness`
    URL 上。如果需要比配置提供的更多控制，它们可以通过配置或源代码中的实现来声明。当通过配置声明探针时，可以为每个探针声明一个 **健康组**，指定它应包含哪些现有的健康指标。例如，如果微服务无法访问其
    MongoDB 数据库，就绪性探针应报告 `DOWN`。在这种情况下，就绪性探针的健康组应包括 `mongo` 健康指标。有关可用的健康指标，请参阅 [https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#actuator.endpoints.health.auto-configured-health-indicators](https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#actuator.endpoints.health.auto-configured-health-indicators)。
- en: 'In this chapter, we will declare the probes using the following configuration
    in the common file `application.yml` in the `config-repo` folder:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用以下配置在 `config-repo` 文件夹中的公共文件 `application.yml` 中声明探针：
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The first line of the configuration enables the liveness and readiness probes.
    The second line declares that readiness probes will include health indicators
    for RabbitMQ, MongoDB, and SQL databases, if available. For the liveness probe,
    we don’t need to add any extra health indicators. For the scope of this chapter,
    it is sufficient that the liveness probe reports `UP` given that the Spring Boot
    application is up and running.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 配置文件的第一行启用了存活性和就绪性探针。第二行声明，如果可用，就绪性探针将包括 RabbitMQ、MongoDB 和 SQL 数据库的健康指标。对于存活性探针，我们不需要添加任何额外的健康指标。在本章的范围内，只要
    Spring Boot 应用程序正在运行，存活性探针报告 `UP` 就足够了。
- en: For more information, see [https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#actuator.endpoints.kubernetes-probes](https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#actuator.endpoints.kubernetes-probes).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息，请参阅 [https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#actuator.endpoints.kubernetes-probes](https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#actuator.endpoints.kubernetes-probes)。
- en: We will try out these features once we have deployed our microservices in Kubernetes.
    Before we do that, we need to learn about Helm and see how it helps us bundle,
    configure, and deploy microservices to Kubernetes.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在将微服务部署到 Kubernetes 之后尝试这些功能。在我们这样做之前，我们需要了解 Helm 并看看它是如何帮助我们打包、配置和部署微服务到
    Kubernetes 的。
- en: Introducing Helm
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 Helm
- en: As described above, deploying a microservice to Kubernetes requires writing
    manifest files that declare the desired state of a Deployment object and a Service
    object. If we also need to add some configuration for the microservices, manifests
    for ConfigMaps and Secrets must be added. The approach of declaring a desired
    state and handing over the responsibility to Kubernetes to ensure that the actual
    state is always as close as possible to the desired state is very useful.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，将微服务部署到Kubernetes需要编写声明部署对象和服务对象所需状态的清单文件。如果我们还需要为微服务添加一些配置，就必须添加ConfigMaps和Secrets的清单。声明所需状态并将责任交给Kubernetes以确保实际状态始终尽可能接近所需状态的方法非常有用。
- en: However, writing and maintaining these manifest files can become a significant
    maintenance overhead. The files will contain a lot of boilerplate code, meaning
    duplicated manifests that will look the same for all microservices. It is also
    cumbersome to handle environment-specific settings without duplicating the whole
    set of manifest files, even though only a fraction of the content needs to be
    updated.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，编写和维护这些清单文件可能会变成一项重大的维护负担。这些文件将包含大量的样板代码，意味着所有微服务的清单看起来都相同。即使只需要更新内容的一小部分，处理特定环境的设置而不重复整个清单文件集也是一件麻烦事。
- en: In the case of a few microservices that will only be deployed to a few environments,
    like a test, QA, and production environment, this might not be a major issue to
    handle.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在只有少数微服务将被部署到少数环境（如测试、QA和生产环境）的情况下，这可能不是处理的主要问题。
- en: When the number of microservices grows to tens and hundreds and it must be possible
    to deploy different groups of microservices to different test, QA, and production
    environments, this quickly becomes an unmanageable maintenance problem.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当微服务的数量增长到数十甚至数百，并且必须能够将不同的微服务组部署到不同的测试、QA和生产环境中时，这很快就会变成一个难以管理的维护问题。
- en: To address these shortcomings, we will use Helm ([https://helm.sh](https://helm.sh)),
    an open source-based package manager for Kubernetes. With Helm comes a templating
    language that can be used to extract settings specific to a microservice or an
    environment from generic definitions of the various Kubernetes objects used.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些不足，我们将使用基于开源的包管理器Helm ([https://helm.sh](https://helm.sh))。Helm附带了一种模板语言，可以用来从各种Kubernetes对象的通用定义中提取特定于微服务或环境的设置。
- en: For smaller system landscapes with only a few Deployment objects, simpler templating
    tools can be sufficient. For example, if you are already familiar with **Ansible**
    and its **Jinja2** templates, they can be used instead. Also, `kubectl` itself
    comes with built-in support for **Kustomize**, offering a template-free alternative
    to customize Kubernetes manifest files.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于只有少数部署对象的较小系统景观，简单的模板工具可能就足够了。例如，如果你已经熟悉**Ansible**及其**Jinja2**模板，它们可以替代使用。此外，`kubectl`本身也内置了对**Kustomize**的支持，提供了一种无需模板即可自定义Kubernetes清单文件的替代方案。
- en: A package is known as a **chart** in Helm. A chart contains templates, default
    values for the templates, and optional dependencies on definitions in other charts.
    Each component that needs to be deployed, meaning the microservices and the resource
    managers they depend on like databases and queue managers, will have its own chart
    describing how to deploy it.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在Helm中，一个包被称为**chart**。一个chart包含模板、模板的默认值以及可选的依赖项，这些依赖项来自其他chart中的定义。每个需要部署的组件，即微服务和它们所依赖的资源管理器（如数据库和队列管理器），都将有自己的chart，描述如何部署它。
- en: To extract boilerplate definitions from the components’ charts, a special type
    of chart, a **library chart**, will be used. A library chart doesn’t contain any
    deployable definitions but only templates expected to be used by other charts
    for Kubernetes manifests – in our case, for Deployment, Service, ConfigMap, and
    Secret objects.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从组件的chart中提取样板定义，将使用一种特殊的chart，即**库chart**。库chart不包含任何可部署的定义，而只包含其他chart用于Kubernetes清单的模板——在我们的案例中，用于Deployment、Service、ConfigMap和Secret对象。
- en: Finally, to be able to describe how to deploy all components into different
    types of environments, for example, for development and testing or staging and
    production, the concept of **parent charts** and **subcharts** will be used. We
    will define two types of environments, `dev-env` and `prod-env`. Each environment
    will be implemented as a parent chart that depends on different sets of subcharts,
    for example, the microservice charts. The environment charts will also provide
    environment-specific default values, such as for the requested number of Pods,
    Docker image versions, credentials, and resource requests and limits.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了能够描述如何将所有组件部署到不同类型的环境中，例如，用于开发和测试或预生产和生产，我们将使用**父图表**和**子图表**的概念。我们将定义两种环境类型，`dev-env`和`prod-env`。每个环境都将实现为一个依赖于不同子图表集的父图表，例如，微服务图表。环境图表还将提供特定于环境的默认值，例如请求的
    Pod 数量、Docker 镜像版本、凭证以及资源请求和限制。
- en: 'In summary, we will have one reusable library chart, named `common`; a set
    of microservice- and resource manager-specific charts, placed in the `components`
    folder; and two environment-specific parent charts, placed in the `environments`
    folder. The file structure looks like this:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们将有一个可重用的库图表，命名为`common`；一组针对微服务和资源管理器的特定图表，放置在`components`文件夹中；以及两个环境特定的父图表，放置在`environments`文件夹中。文件结构如下：
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The files can be found in the folder `$BOOK_HOME/Chapter16/kubernetes/helm`.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这些文件可以在文件夹`$BOOK_HOME/Chapter16/kubernetes/helm`中找到。
- en: To share Helm charts with others, they can be published to a Helm **chart repository**.
    In this book we will not publish any charts, but in *Chapter 17*, *Implementing
    Kubernetes Features to Simplify the System Landscape*, we will install a component
    named **cert-manager** using a Helm chart from a chart repository.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 要与他人共享 Helm 图表，可以将它们发布到 Helm **图表仓库**。在这本书中，我们不会发布任何图表，但在第17章*实现 Kubernetes
    功能以简化系统景观*中，我们将使用来自图表仓库的 Helm 图表安装名为**cert-manager**的组件。
- en: Before we learn about how charts are constructed, let’s learn about the most
    frequently used Helm commands and how to run them.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们了解图表是如何构建之前，让我们了解最常用的 Helm 命令以及如何运行它们。
- en: Running Helm commands
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行 Helm 命令
- en: To make Helm do something for us, we will use its CLI tool, `helm`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 要让 Helm 为我们执行某些操作，我们将使用其 CLI 工具，`helm`。
- en: 'Some of the most frequently used Helm commands are:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的 Helm 命令包括：
- en: '`create`: Used to create new charts.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`create`：用于创建新的图表。'
- en: '`dependency update` (`dep up` for short): Resolves dependencies on other charts.
    Charts are placed in the `charts` folder and the file `Chart.lock` is updated.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dependency update`（简称`dep up`）：解决对其他图表的依赖。图表放置在`charts`文件夹中，并更新文件`Chart.lock`。'
- en: '`dependency build`: Rebuilds the dependencies based on the content in the file
    `Chart.lock`.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dependency build`：根据文件`Chart.lock`中的内容重建依赖。'
- en: '`template`: Renders the definition files created by the templates.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`template`：渲染由模板创建的定义文件。'
- en: '`install`: Installs a chart. This command can override the values supplied
    by a chart, either using the `--set` flag to override a single value or using
    the `--values` flag to supply its own `yaml` file with values.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`install`：安装一个图表。此命令可以覆盖图表提供的值，可以使用`--set`标志覆盖单个值，或使用`--values`标志提供自己的`yaml`文件，其中包含值。'
- en: '`install --Dry-run`: simulates a Deployment without performing it; it’s useful
    for verifying a Deployment before executing it.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`install --Dry-run`：模拟一个部署而不执行它；在执行之前验证部署很有用。'
- en: '`list`: Lists installations in the current n amespace.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`list`：列出当前命名空间中的安装。'
- en: '`upgrade`: Updates an existing installation.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upgrade`：更新现有安装。'
- en: '`uninstall`: Removes an installation.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`uninstall`：删除安装。'
- en: For full documentation of the commands that Helm provides, see [https://helm.sh/docs/helm/](https://helm.sh/docs/helm/).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看 Helm 提供的命令的完整文档，请参阅[https://helm.sh/docs/helm/](https://helm.sh/docs/helm/)。
- en: Let’s put these Helm commands in context and see what files a chart consists
    of.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把这些 Helm 命令放在上下文中，看看一个图表由哪些文件组成。
- en: Looking into a Helm chart
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查看 Helm 图表
- en: 'A Helm chart has a predefined structure of files. We will use the following
    files:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Helm 图表有一个预定义的文件结构。我们将使用以下文件：
- en: '`Chart.yaml`, which contains general information about the chart and a list
    of other charts it might depend on.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Chart.yaml`，其中包含有关图表的一般信息和可能依赖的其他图表列表。'
- en: '`templates`, a folder that contains the templates that will be used to deploy
    the chart.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`templates`，一个包含用于部署图表的模板的文件夹。'
- en: '`values.yaml`, which contains default values for the variables used by the
    templates.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`values.yaml`，它包含模板使用的变量的默认值。'
- en: '`Chart.lock`, a file created by Helm when resolving the dependencies described
    in the `Chart.yaml` file. This information describes in more detail what dependencies
    are actually used. It is used by Helm to track the entire dependency tree, making
    it possible to recreate the dependency tree exactly as it looked the last time
    the chart worked.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Chart.lock`，Helm在解决`Chart.yaml`文件中描述的依赖关系时创建的文件。该信息更详细地描述了实际使用的依赖关系。Helm使用它来跟踪整个依赖关系树，使得能够精确地重新创建上一次图表工作时的依赖关系树。'
- en: '`charts`, a folder that will contain the charts this chart depends on after
    Helm has resolved the dependencies.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`charts`，一个文件夹，在Helm解决依赖关系后，将包含此图表所依赖的图表。'
- en: '`.helmignore`, an ignore file similar to `.gitignore`. It can be used to list
    files that should be excluded when building the chart.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.helmignore`，一个类似于`.gitignore`的忽略文件。它可以用来列出在构建图表时应排除的文件。'
- en: 'Now that we understand the structure inside a Helm chart, let’s learn about
    one of the core features of Helm: its template mechanism, and how to pass values
    to it.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了Helm图表内部的架构，让我们来学习Helm的核心功能之一：其模板机制以及如何向其传递值。
- en: Helm templates and values
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Helm模板和值
- en: 'Helm templates are used to parameterize Kubernetes manifest files. Using templates,
    we no longer need to maintain long-winded Deployment manifests for each microservice.
    Instead, we can define a common template that contains placeholders for where
    microservice-specific values will be placed in the template, when a manifest is
    rendered for a specific microservice. Let’s see an example, extracted from `kubernetes/helm/common/templates/_deployment.yaml`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Helm模板用于参数化Kubernetes清单文件。使用模板，我们不再需要为每个微服务维护冗长的Deployment清单。相反，我们可以定义一个包含在模板中占位符的通用模板，当为特定微服务渲染清单时，这些占位符将放置微服务特定的值。让我们看一个例子，它来自`kubernetes/helm/common/templates/_deployment.yaml`：
- en: '[PRE5]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: It looks very similar to the Deployment manifest we saw in *Chapter 15*, *Introduction
    to Kubernetes*, with the exception of the use of the `{{ ... }}` constructs, used
    to insert microservice-specific values into the template. The construct `{{ include
    "common.fullname" . }}` is used to invoke other templates, as explained below.
    The other two constructs are used to insert values using one of the **built-in
    objects** in Helm.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 它看起来与我们在第15章“Kubernetes简介”中看到的Deployment清单非常相似，唯一的区别是使用了`{{ ... }}`构造，用于将微服务特定的值插入到模板中。构造`{{
    include "common.fullname" . }}`用于调用其他模板，如下所述。其他两个构造用于使用Helm中的**内置对象**之一插入值。
- en: 'The most frequently used parts of the built-in objects are:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 常用内置对象的以下部分：
- en: '`Values`: Used to refer to values in the chart’s `values.yaml` file or values
    supplied when running a Helm command like `install`.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Values`: 用于引用图表的`values.yaml`文件中的值或运行Helm命令（如`install`）时提供的值。'
- en: '`Release`: Used to provide metadata regarding the current release that is installed.
    It contains fields like:'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Release`: 用于提供有关当前已安装发布版本的元数据。它包含如下字段：'
- en: '`Name`: The name of the release'
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Name`: 发布版本的名称'
- en: '`Namespace`: The name of the namespace where the installation is performed'
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Namespace`: 执行安装的命名空间名称'
- en: '`Service`: The name of the installation Service, always returning `Helm`'
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Service`: 安装服务的名称，总是返回`Helm`'
- en: '`Chart`: Used to access information from the `Chart.yaml` file. Examples of
    fields that can be useful for providing metadata for a Deployment are:'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Chart`: 用于从`Chart.yaml`文件中访问信息。以下是一些可用于为部署提供元数据的字段示例：'
- en: '`Name`: The name of the chart'
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Name`: 图表的名称'
- en: '`Version`: The chart’s version number'
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Version`: 图表的版本号'
- en: '`Files`: Containing functions for accessing chart-specific files. In this chapter
    we will use the following two functions in the `Files` object:'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Files`: 包含访问特定图表文件的函数。在本章中，我们将使用`Files`对象中的以下两个函数：'
- en: '`Glob`: Returns files in a chart based on a **glob pattern**. For example,
    the pattern `"``config-repo/*"` will return all files found in the folder `config-repo`'
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Glob`: 根据glob模式返回图表中的文件。例如，模式`"config-repo/*"`将返回在`config-repo`文件夹中找到的所有文件'
- en: '`AsConfig`: Returns the content of files as a YAML map appropriate for declaring
    values in a `ConfigMap`'
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AsConfig`: 返回适合在`ConfigMap`中声明值的YAML映射文件内容'
- en: '`Capabilities`: Can be used to find information regarding the capabilities
    of the Kubernetes cluster that the installation is performed on. For example,
    a template can use information in this object to adopt a manifest based on what
    API versions the actual Kubernetes cluster supports. We will not use this object
    in this chapter, but I think it is in our interest to be aware of it for more
    advanced use cases.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Capabilities`：可用于查找有关在安装上执行的操作的Kubernetes集群的功能信息。例如，模板可以使用此对象中的信息根据实际Kubernetes集群支持的API版本采用清单。我们本章不会使用此对象，但我认为对于更高级的使用案例，了解它对我们是有益的。'
- en: For further details on built-in objects, see [https://helm.sh/docs/chart_template_guide/builtin_objects](https://helm.sh/docs/chart_template_guide/builtin_objects).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 有关内置对象的更多详细信息，请参阅[https://helm.sh/docs/chart_template_guide/builtin_objects](https://helm.sh/docs/chart_template_guide/builtin_objects)。
- en: All objects are accessible in a tree where the `root` context, in most cases,
    can be addressed using the current scope, represented by a period, `.`, also known
    as the **dot**. From the examples above we can see the use of the dot, for example,
    in `.Values.replicaCount` and `.Chart.Name`, where we can see that the built-in
    objects `Values` and `Chart` are accessible directly under the current scope.
    In the `include` directive above, we can also see the dot being used as a parameter
    sent to the template named `common.fullname`, meaning the whole tree is sent to
    the template. Instead of sending the whole tree to a template, a sub-tree can
    be passed.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 所有对象都可以在一个树结构中访问，其中`root`上下文，在大多数情况下，可以使用当前作用域来表示，用点`.`表示，也称为**点**。从上面的例子中我们可以看到点的使用，例如在`.Values.replicaCount`和`.Chart.Name`中，我们可以看到内置对象`Values`和`Chart`可以直接在当前作用域下访问。在上面的`include`指令中，我们也可以看到点被用作参数发送给名为`common.fullname`的模板，这意味着整个树被发送到模板。而不是将整个树发送到模板，可以传递一个子树。
- en: When using some of the Helm functions, the current scope will be changed and
    no longer point to the `root` context. We will, for example, meet the `range`
    function later on, which can be used to iterate through collections of values.
    If we need to access the `root` context inside the scope of a `range` function,
    we can use the predefined variable `$`.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用一些Helm函数时，当前作用域将发生变化，不再指向`root`上下文。例如，我们将在稍后遇到`range`函数，它可以用来遍历值集合。如果我们需要在`range`函数的作用域内访问`root`上下文，我们可以使用预定义变量`$`。
- en: 'Helm templates also support the declaration of variables to reference other
    objects. For example:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Helm模板还支持声明变量以引用其他对象。例如：
- en: '[PRE6]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this example, a variable, `name`, has been declared to hold the value of
    the Helm release that is currently being processed. We will see later on how variables
    are used in more advanced constructs.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，已声明一个变量`name`，用于存储当前正在处理的Helm发布版本值。我们将在稍后了解变量如何在更高级的结构中使用。
- en: If you recognize the format of using the `{{ ... }}` constructs from using `kubectl`,
    you are right. They are, in both cases, based on Go templates. For more information,
    see [https://golang.org/pkg/text/template/](https://golang.org/pkg/text/template/).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你认识从使用`kubectl`中使用的`{{ ... }}`构造的格式，你是正确的。在两种情况下，它们都是基于Go模板。有关更多信息，请参阅[https://golang.org/pkg/text/template/](https://golang.org/pkg/text/template/)。
- en: With the templating mechanism introduced, let’s learn about how the three types
    of charts are constructed. We will start with the most important chart, the `common`
    chart, explaining the `components` and `environments` charts after that.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在引入模板机制后，让我们了解三种图表类型是如何构建的。我们将从最重要的图表`common`图表开始，之后解释`components`和`environments`图表。
- en: The common library chart
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常用库图表
- en: 'This chart contains reusable templates, also known as **named templates**,
    for the four types of Kubernetes manifests we will use in this chapter: `Deployment`,
    Service, `ConfigMap`, and `Secret`. The structure and content of the common chart
    are based on the output from a `helm create` command. Specifically, the template
    file `_helpers.tpl` has been retained to reuse best practices for naming conventions.
    It declares the following templates that encapsulate naming conventions:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 此图表包含可重用的模板，也称为**命名模板**，用于本章中我们将使用的四种Kubernetes清单类型：`Deployment`、Service、`ConfigMap`和`Secret`。常用图表的结构和内容基于`helm
    create`命令的输出。具体来说，模板文件`_helpers.tpl`已被保留，以便重用命名约定的最佳实践。它声明以下模板，这些模板封装了命名约定：
- en: '`common.name`: Based on the chart name.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`common.name`：基于图表名称。'
- en: '`common.fullname`: Based on a combination of the name of the release and the
    chart. In this book, we will override this naming convention and simply using
    the name of the chart.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`common.fullname`：基于发布名称和图表名称的组合。在本书中，我们将覆盖这个命名约定，并简单地使用图表名称。'
- en: '`common.chart`: Based on the chart name and version.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`common.chart`：基于图表名称和版本。'
- en: For details, see the implementation in the `_helpers.tpl` file.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 有关详细信息，请参阅 `_helpers.tpl` 文件中的实现。
- en: Named templates, which will only be used by other templates and not used to
    create manifests themselves, must have a name that starts with an underscore,
    `_`. This is used to prevent Helm from trying to create manifests using them alone.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 命名模板，这些模板将仅被其他模板使用，而不会用于创建自己的清单，必须以下划线 `_` 开头。这是为了防止 Helm 尝试仅使用它们来创建清单。
- en: Since the named templates for the Kubernetes manifests mentioned previously
    contain the main part of the logic and, therefore, most of the complexity in the
    Helm charts, we will go through them one by one.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 由于之前提到的 Kubernetes 清单的命名模板包含 Helm 图表中的主要逻辑部分，因此包含大部分复杂性，我们将逐一介绍它们。
- en: The ConfigMap template
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ConfigMap 模板
- en: This template is designed to create ConfigMaps from files in the folder `config-repo`.
    Each ConfigMap will contain all non-sensitive configurations required by a specific
    Deployment. The Deployment manifest will map the content of the ConfigMap as a
    volume in its Pod template. This will result in Pods created by the Deployment
    being able to access the configuration as files in their local filesystem. See
    the section *The Deployment template* below for details. The `config-repo` folder
    needs to be placed in the charts that use the common chart.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模板旨在从 `config-repo` 文件夹中的文件创建 ConfigMap。每个 ConfigMap 将包含特定 Deployment 所需的所有非敏感配置。Deployment
    清单将把 ConfigMap 的内容映射到其 Pod 模板中的卷。这将导致由 Deployment 创建的 Pod 能够将其配置作为本地文件系统中的文件访问。有关详细信息，请参阅下面的
    *Deployment 模板* 部分。`config-repo` 文件夹需要放置在使用通用图表的图表中。
- en: In this chapter, this template will be used only by the config server chart
    in the `components` folder. In the next chapter, all other microservices will
    also use this template to define their own ConfigMaps, since the config server
    will be removed.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，这个模板将仅在 `components` 文件夹中的配置服务器图表中使用。在下一章中，所有其他微服务也将使用这个模板来定义它们自己的 ConfigMaps，因为配置服务器将被移除。
- en: 'The templates file is named `_configmap_from_file.yaml`, and it looks like
    this:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 模板文件命名为 `_configmap_from_file.yaml`，其内容如下：
- en: '[PRE7]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'An explanation of the template is as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 模板的解释如下：
- en: The first line, `{{- define "common.configmap_from_file " -}}`, is used to declare
    the name of the reusable template. The scope of the template ends with a matching
    `{{- end -}}`, the last line in this example.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一行，`{{- define "common.configmap_from_file " -}}`，用于声明可重用模板的名称。模板的作用域以匹配的 `{{-
    end -}}` 结束，本例中的最后一行。
- en: To set the name of the ConfigMap, the template `common.fullname` from the file
    `_helpers.tpl` is used.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了设置 ConfigMap 的名称，使用了来自 `_helpers.tpl` 文件的模板 `common.fullname`。
- en: Next, a number of labels are defined to make it easier to identify the ConfigMap
    later on. Again, templates from the `_helpers.tpl` file are used to set the `name`
    and specify the `chart` used. To mark that this Service has been created using
    Helm, the label `app.kubernetes.io/managed-by` is set to the value for the field
    `.Release.Service`. From the earlier description of the `Release` object, we know
    that it always returns the value `Helm`.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，定义了一系列标签以便于稍后更容易地识别 ConfigMap。同样，这里使用了 `_helpers.tpl` 文件中的模板来设置 `name` 并指定所使用的
    `chart`。为了标记这个服务是使用 Helm 创建的，将标签 `app.kubernetes.io/managed-by` 设置为字段 `.Release.Service`
    的值。根据对 `Release` 对象的早期描述，我们知道它总是返回值 `Helm`。
- en: Next comes the core part of the ConfigMap, its `data` section. To specify the
    actual configuration in the ConfigMap, the `Glob` function in the `Files` object
    is used to get all files in the folder `config-repo`. Next, the function `AsConfig`
    is applied to the content in the files to form a proper YAML map. The result is
    piped to the `indent` function, which ensures a proper indentation is rendered,
    in this case, using two characters.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来是 ConfigMap 的核心部分，其 `data` 部分。为了在 ConfigMap 中指定实际的配置，使用了 `Files` 对象中的 `Glob`
    函数来获取 `config-repo` 文件夹中的所有文件。然后，将 `AsConfig` 函数应用于文件中的内容，以形成一个正确的 YAML 映射。结果通过管道传递到
    `indent` 函数，该函数确保渲染出适当的缩进，在这种情况下，使用两个字符。
- en: The hyphens in `{{-` and `-}}` are used to remove preceding and trailing whitespace
    remaining after the processing of the directive inside the curly braces.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`{{-` 和 `-}}` 中的连字符用于删除大括号内指令处理后剩余的前导和尾随空白。'
- en: Example of using the ConfigMap template
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用 ConfigMap 模板的示例
- en: In this chapter, only the config server will use a ConfigMap. See the section
    on *The component charts* for a description of how this template is used.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，只有配置服务器将使用 ConfigMap。请参阅关于 *组件图表* 的部分，了解此模板的使用方法。
- en: 'To see the ConfigMap that will be created by Helm using this template, run
    the following commands:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看 Helm 使用此模板创建的 ConfigMap，请运行以下命令：
- en: '[PRE8]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Expect output from the `helm template` command like the following:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 期望从 `helm template` 命令得到如下输出：
- en: '[PRE9]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `data` field contains the content of all files in the `config-repo` folder.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`data` 字段包含 `config-repo` 文件夹中所有文件的内容。'
- en: The Secrets template
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Secrets 模板
- en: 'This template is designed to create Secrets defined by values like credentials
    provided by the environments `dev-env` and `prod-env`. The Secrets will be mapped
    as environment variables in the Pods. See the section *The Deployment template*
    below for details. Since an environment must be able to define multiple Secrets,
    this template is designed to create multiple Secret manifests using the `range`
    function in Helm. The template file is named `_secrets.yaml`, and it looks like
    this:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 此模板旨在创建由环境 `dev-env` 和 `prod-env` 提供的凭证等值定义的 Secrets。Secrets 将作为 Pod 中的环境变量映射。请参阅下面的
    *部署模板* 部分以获取详细信息。由于环境必须能够定义多个 Secrets，因此此模板设计为使用 Helm 中的 `range` 函数创建多个 Secret
    清单。模板文件命名为 `_secrets.yaml`，其外观如下：
- en: '[PRE10]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'An explanation of the template is as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如下解释模板：
- en: 'After the declaration of the template in line 1 comes the use of the `range`
    function in line 2\. The function assumes that the field `.Values.secrets` contains
    a map of Secret names and a map of the Secret’s key/value pairs. A declaration
    of the `Secrets` field in one of the environment’s `values.yaml` files will look
    like this:'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第 1 行声明模板之后，第 2 行使用了 `range` 函数。该函数假定 `.Values.secrets` 字段包含一个 Secret 名称映射和一个
    Secret 的键/值对映射。在某个环境的 `values.yaml` 文件中声明 `Secrets` 字段的示例如下：
- en: '[PRE11]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This definition will render two Secrets, named `a-secret` and `another-secret`.
    The `range` function assigns the current Secret name and its map to the variables
    `$secretName` and `$secretMap`.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 此定义将渲染两个 Secrets，分别命名为 `a-secret` 和 `another-secret`。`range` 函数将当前 Secret 名称及其映射分配给变量
    `$secretName` 和 `$secretMap`。
- en: Since the `range` function changes the current scope, we can no longer use the
    dot notation to pass the `root` context to the `common.chart` template. Instead,
    the variable `$` has to be used.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于 `range` 函数改变了当前作用域，我们不能再使用点符号将 `root` 上下文传递给 `common.chart` 模板。相反，必须使用变量
    `$`。
- en: In the `data` section of the manifest, a second `range` function is applied
    a second time to traverse the current Secret’s key/value pairs. Each key/value
    pair is assigned by the `range` function to the variables `$key` and `$val`.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在清单的 `data` 部分中，再次应用第二个 `range` 函数来遍历当前 Secret 的键/值对。每个键/值对由 `range` 函数分配给变量
    `$key` 和 `$val`。
- en: Finally, the Secret’s key/value pairs are defined as a map entry in the `data`
    section. The value in the `$val` variable is piped to the `b64enc` function to
    get it properly **Base64**-encoded as required by a Secret manifest.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，Secret 的键/值对在 `data` 部分定义为映射条目。`$val` 变量的值通过管道传递到 `b64enc` 函数，以获得符合 Secret
    清单要求的正确 **Base64** 编码。
- en: The `---` is used to separate the rendered Secret manifests from each other
    so that they are processed as separate YAML documents.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `---` 来分隔渲染的 Secret 清单，以便它们作为单独的 YAML 文档进行处理。
- en: Example of using the Secrets template
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用 Secrets 模板的示例
- en: Secrets are only defined by the environment charts `dev-env` and `prod-env`.
    They are used to create environment-specific credentials. See the section on *The
    environment charts* for a description of how this template is used.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 秘密仅由环境图表 `dev-env` 和 `prod-env` 定义。它们用于创建特定环境的凭证。请参阅关于 *环境图表* 的部分，了解此模板的使用方法。
- en: 'To see the Secrets that will be created for the `dev-env` by Helm using this
    template, run the following commands:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看 Helm 使用此模板为 `dev-env` 创建的 Secrets，请运行以下命令：
- en: '[PRE12]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Expect output from the `helm template` command like this:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 期望从 `helm template` 命令得到如下输出：
- en: '[PRE13]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The Service template
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务模板
- en: The Service template introduces support for overriding default values from the
    common chart, with values specific to the charts that use the common chart. The
    common chart will, for example, provide default values for the Service `type`
    and what `ports` the Service will expose. This will be useful for most of the
    microservices, but some of them need to be able to override these default values
    in their own `values.yaml` file.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 服务模板引入了对从通用图表覆盖默认值的支持，使用通用图表的特定图表的值。例如，通用图表将为服务的 `type` 和服务将暴露的 `ports` 提供默认值。这对于大多数微服务来说将很有用，但其中一些需要在它们自己的
    `values.yaml` 文件中覆盖这些默认值。
- en: 'The template file is named `_service.yaml` and starts like the other named
    templates, with the declaration of its name, followed by the implementation of
    the override mechanism. It looks like this:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 模板文件命名为 `_service.yaml`，其结构与其他命名模板类似，首先声明其名称，然后是实现覆盖机制。它看起来是这样的：
- en: '[PRE14]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This construct can be explained in the following way:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结构可以这样解释：
- en: When the `_service.yaml` template is used by a microservice to render its Service
    manifest, the values from the microservice `values.yaml` file will be available
    in the `.Values` object, and the common chart’s values will be available under
    the field `.Values.common`.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当微服务使用 `_service.yaml` 模板来渲染其服务清单时，微服务的 `values.yaml` 文件中的值将在 `.Values` 对象中可用，而通用图表的值将在
    `.Values.common` 字段下可用。
- en: So, the variable `$common` will refer to a dictionary, created by the `dict`
    function, with one key, `Values`, and its value will be the default values from
    the common chart. These values are taken from the `common` key in the `.Values`
    object.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，变量 `$common` 将引用一个由 `dict` 函数创建的字典，其中有一个键 `Values`，其值将是通用图表的默认值。这些值来自 `.Values`
    对象中的 `common` 键。
- en: The `$noCommon` variable will hold all values from the microservice except values
    under the `common` key, specified using the `omit` function.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`$noCommon` 变量将保留微服务中除 `common` 键下的值之外的所有值，该键使用 `omit` 函数指定。'
- en: The `$overrides` variable will refer to a dictionary, also with one key, `Values`,
    but its value will be the values from the microservice’s values, except the `common`
    values. It gets the values from the `$noCommon` variable declared on the previous
    line.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`$overrides` 变量将引用一个字典，同样只有一个键 `Values`，但其值将是微服务的值，除了 `common` 值。它从上一行声明的 `$noCommon`
    变量中获取值。'
- en: The `$noValues` variable will hold all other built-in objects, except for the
    `Values` object.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`$noValues` 变量将保留所有其他内置对象，除了 `Values` 对象。'
- en: Now, here is where the override will happen; the `merge` function will create
    one dictionary based on the dictionaries referred to by the variables `$noValues`,
    `$overrides`, and `$common`. In this case, values found in the `$overrides` dictionary
    will take precedence over values in the `$common` dictionary, thereby overriding
    its values.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在，覆盖将在这里发生；`merge` 函数将基于变量 `$noValues`、`$overrides` 和 `$common` 所引用的字典创建一个字典。在这种情况下，`$overrides`
    字典中找到的值将优先于 `$common` 字典中的值，从而覆盖其值。
- en: Finally, the `with` function will change the scope for the template code that
    follows until its `{{- end -}}` definition is reached. So, the current scope,
    `.`, will now refer to the merged dictionary.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，`with` 函数将改变后续模板代码的作用域，直到其 `{{- end -}}` 定义为止。因此，当前的作用域 `.` 现在将指向合并后的字典。
- en: 'Let’s take an example to see how this will work out. The `common` chart’s `values.yaml`
    file contains the following default settings for the Service type and exposed
    ports:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来看看这将如何工作。`common` 图表的 `values.yaml` 文件包含以下服务类型和暴露端口的默认设置：
- en: '[PRE15]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This setting will render Service objects that are of type `ClusterIP`. The Service
    objects will expose port `80` and forward requests to the Pods on their port,
    named `http`.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 此设置将渲染类型为 `ClusterIP` 的服务对象。服务对象将暴露端口 `80` 并将请求转发到其端口上名为 `http` 的 Pod。
- en: 'The gateway Service needs to expose a `NodePort` and use other port settings.
    To override the above default values, it declares the following in its chart’s
    `values.yaml` file:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 网关服务需要暴露 `NodePort` 并使用其他端口设置。为了覆盖上述默认值，它在图表的 `values.yaml` 文件中声明以下内容：
- en: '[PRE16]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The gateway’s `values.yaml` file can be found in the folder `$BOOK_HOME/Chapter16/kubernetes/helm/components/gateway/values.yaml`.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 网关的 `values.yaml` 文件位于文件夹 `$BOOK_HOME/Chapter16/kubernetes/helm/components/gateway/values.yaml`。
- en: 'The rest of the Service template file looks like this:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 服务模板文件的其余部分如下所示：
- en: '[PRE17]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'An explanation of the template is as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 模板解释如下：
- en: The metadata fields for `name` and `labels` are defined in the same way as already
    seen for the previous templates.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`和`labels`的元数据字段与之前看到的模板定义方式相同。'
- en: The `type` of the Service is set by the field `.Values.service.type`.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Service的`type`由字段`.Values.service.type`设置。
- en: The `ports` exposed by the Service are specified using the field `.Values.service.ports`.
    The built-in function `toYaml` is used to format its value as `yaml`, and the
    result is piped to the `indent` function, which ensures a proper indentation is
    rendered, in this case, `4` characters.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用字段`.Values.service.ports`指定Service暴露的端口。内置函数`toYaml`用于将值格式化为`yaml`，然后将结果传递给`indent`函数，以确保正确缩进，在这种情况下为`4`个字符。
- en: Finally, the Pod `selector` is defined. It is based on the label `app.kubernetes.io/name`
    and is given the name using the template `common.name`.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，定义了Pod的`选择器`。它基于标签`app.kubernetes.io/name`，并使用模板`common.name`来指定名称。
- en: Example of using the Service template
  id: totrans-190
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用Service模板的示例
- en: The Service template is used by each component to create its Service manifest.
    As described above, the core microservices reuse the configuration in the common
    chart’s `values.yaml` file, while the other components override these values in
    their own `values.yaml` file.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 每个组件使用Service模板来创建其Service清单。如上所述，核心微服务重用通用图表的`values.yaml`文件中的配置，而其他组件在其自己的`values.yaml`文件中覆盖这些值。
- en: 'To see the Service manifest generated for a core component, for the `product`
    microservice, run the following commands:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看为核心组件生成的Service清单，对于`product`微服务，运行以下命令：
- en: '[PRE18]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Expect output from the `helm template` command like this:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 预期`helm template`命令的输出如下：
- en: '[PRE19]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To see the Service manifest generated for a component that overrides the settings
    in the common chart, for the `gateway` component, run the following commands:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看为覆盖通用图表设置的组件生成的Service清单，对于`gateway`组件，运行以下命令：
- en: '[PRE20]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Expect output from the `helm template` command like this:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 预期`helm template`命令的输出如下：
- en: '[PRE21]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The Deployment template
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署模板
- en: 'Finally, we have the template for rendering Deployment manifests. This is the
    most complex template, since it must handle many parts of the Deployment manifest
    optionally. Different components will use different parts of a Deployment manifest.
    The common chart’s `values.yaml` file contains default values for these settings
    that are applicable to most of the components, minimizing the need to override
    these settings in each component’s own chart’s `values.yaml` file. The following
    parts of the Deployment manifest are optional for use by the components:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有用于渲染Deployment清单的模板。这是最复杂的模板，因为它必须处理清单中可选的许多部分。不同的组件将使用Deployment清单的不同部分。通用图表的`values.yaml`文件包含适用于大多数组件的默认设置值，最小化在每个组件自己的图表的`values.yaml`文件中覆盖这些设置的需求。以下Deployment清单的部分对于组件的使用是可选的：
- en: Arguments given to the container when it starts up
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器启动时传递给容器的参数
- en: Environment variables
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境变量
- en: Environment variables from Secrets
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自Secrets的环境变量
- en: The liveness probe
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 活跃探针
- en: The readiness probe
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 就绪探针
- en: A ConfigMap and a corresponding volume
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个ConfigMap和相应的卷
- en: 'The template file is named `_deployment.yaml`, and its first lines look very
    similar to the Service template, utilizing the same type of override mechanism:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 模板文件命名为`_deployment.yaml`，其开头几行看起来与Service模板非常相似，使用相同的覆盖机制：
- en: '[PRE22]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: For an explanation of this part of the template, see the description of the
    Service template above.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 对于模板的这一部分的解释，请参阅上面Service模板的描述。
- en: 'When it comes to the `spec` part of the manifest, it starts with:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到清单的`spec`部分时，它从以下内容开始：
- en: '[PRE23]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Here we can see how the core parts of the spec are defined: the requested number
    of `replicas`, the `selector` for the Pods, and the `template` used to create
    new Pods. The template defines `labels` that match the selector and the `name`,
    Docker `image`, and `imagePullPolicy` to use when starting a container.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们可以看到如何定义spec的核心部分：请求的`replicas`数量、Pod的`selector`以及用于创建新Pod的`template`。模板定义了与选择器匹配的`labels`、`name`、Docker`image`和启动容器时使用的`imagePullPolicy`。
- en: 'Next comes the various optional parts of the manifest, as described above:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是清单中描述的各个可选部分：
- en: '[PRE24]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: For the environment variables and Secrets that are mapped to environment variables,
    the `range` function is used in the same way the `secrets` template uses it. The
    environment variables can either be specified on a component or environment level,
    depending on their use case. Secrets are always specified by an environment chart.
    See the following sections regarding the component and environment charts.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 对于映射到环境变量的环境变量和机密信息，使用 `range` 函数的方式与 `secrets` 模板使用的方式相同。环境变量可以在组件或环境级别指定，具体取决于其用例。机密信息始终通过环境图表指定。有关组件和环境图表的更多信息，请参阅以下章节。
- en: 'The manifest is concluded by the declaration of the `ports` the container exposes,
    `resource` requests and limits, and finally, the optional declaration of a ConfigMap
    and a corresponding volume to map the files in the ConfigMap to:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 清单以声明容器暴露的 `ports`、`resource` 请求和限制以及最后可选地声明一个 ConfigMap 和相应的卷来映射 ConfigMap
    中的文件结束：
- en: '[PRE25]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'From the common chart’s `values.yaml` file we can find some default values
    of interest, for example, how default values for the liveness and readiness probes
    are defined:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 从公共图表的 `values.yaml` 文件中，我们可以找到一些有趣的默认值，例如，如何定义存活和就绪探针的默认值：
- en: '[PRE26]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'From these declarations, we can see that:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些声明中，我们可以看到：
- en: The probes are by default disabled, since not all Deployments use probes.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探针默认是禁用的，因为并非所有部署都使用探针。
- en: The probes are based on HTTP `GET` requests sent to the endpoints exposed by
    Spring Boot, as described in the section *Using Spring Boot’s support for graceful
    shutdown and probes for liveness and readiness* above.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探针基于发送到 Spring Boot 暴露的端点的 HTTP `GET` 请求，如上节所述的 *使用 Spring Boot 对优雅关闭和存活就绪探针的支持*。
- en: As long as the endpoint responds with a `2xx` or a `3xx` response code, the
    probe is considered to be successful.
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只要端点以 `2xx` 或 `3xx` 响应代码响应，探针就被认为是成功的。
- en: 'The probes can be configured using the following parameters:'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探针可以使用以下参数进行配置：
- en: '`initialDelaySeconds` specifies how long Kubernetes waits to probe a container
    after it’s started up.'
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initialDelaySeconds` 指定 Kubernetes 在容器启动后等待多长时间才对其进行探针。'
- en: '`periodSeconds` specifies the time between probe requests sent by Kubernetes.'
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`periodSeconds` 指定 Kubernetes 发送探针请求之间的时间间隔。'
- en: '`timeoutSeconds` specifies how long Kubernetes waits on a response before it
    treats the probe as failed.'
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timeoutSeconds` 指定 Kubernetes 在将探针视为失败之前等待响应的时间。'
- en: '`failureThreshold` specifies how many failed attempts Kubernetes makes before
    giving up. In the case of a liveness probe, this means restarting the Pod. In
    the case of a readiness probe, it means that Kubernetes will not send any more
    requests to the container until the readiness probes are successful again.'
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`failureThreshold` 指定 Kubernetes 在放弃之前尝试失败的次数。在存活探针的情况下，这意味着重新启动 Pod。在就绪探针的情况下，这意味着
    Kubernetes 将不会向容器发送更多请求，直到就绪探针再次成功。'
- en: '`successThreshold` specifies the number of successful attempts that are required
    for a probe to be considered successful again after a failure. This only applies
    to readiness probes, since it must be set to `1` if specified for liveness probes.'
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`successThreshold` 指定探针在失败后再次被视为成功所需的成功尝试次数。这仅适用于就绪探针，因为如果为存活探针指定，则必须设置为 `1`。'
- en: Finding optimal settings for the probes can be challenging, that is, finding
    a proper balance between getting a swift reaction from Kubernetes when the availability
    of a Pod changes and not overloading the Pods with probe requests.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找探针的最佳设置可能具有挑战性，也就是说，在当 Pod 的可用性发生变化时，从 Kubernetes 获得快速反应和不过度加载 Pod 以探针请求之间找到一个适当的平衡。
- en: Specifically, configuring a liveness probe with values that are too low can
    result in Kubernetes restarting Pods that don’t need to be restarted; they just
    need some extra time to start up. Starting a large number of Pods at the same
    time, also resulting in extra-long startup times, can similarly result in a lot
    of unnecessary restarts.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，配置一个存活探针，其值过低可能导致 Kubernetes 重新启动不需要重新启动的 Pod；它们只需要一些额外的时间来启动。同时启动大量 Pod，这也可能导致启动时间过长，同样可能导致大量不必要的重启。
- en: Setting the configuration values too high on the probes (except for the `successThreshold`
    value) makes Kubernetes react more slowly, which can be annoying in a development
    environment. Proper values also depend on the available hardware, which affects
    the startup times for the Pods. For the scope of this book, `failureThreshold`
    for the liveness probes is set to a high value, `20`, to avoid unnecessary restarts
    on computers with limited hardware resources.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在探针（除 `successThreshold` 值外）上设置配置值过高会使 Kubernetes 响应更慢，这在开发环境中可能会很烦人。适当的值还取决于可用的硬件，这会影响
    Pod 的启动时间。在本书的范围内，为了防止在硬件资源有限的计算机上不必要的重启，将 liveness 探针的 `failureThreshold` 设置为高值，`20`。
- en: Example of using the Deployment template
  id: totrans-234
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用 Deployment 模板的示例
- en: The Deployment template is used by each component to create its Deployment manifest.
    The core microservices reuse most of the configuration in the common chart’s `values.yaml`
    file, minimizing the need for component-specific configuration, while the other
    components override more of these values in their own `values.yaml` file.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 每个组件使用 Deployment 模板来创建其 Deployment 清单。核心微服务在通用图表的 `values.yaml` 文件中重用了大部分配置，最小化了组件特定配置的需求，而其他组件在其自己的
    `values.yaml` 文件中覆盖了这些值中的更多。
- en: 'To see the Deployment manifest generated for a core component, run the following
    commands for the `product` microservice:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看为核心组件生成的 Deployment 清单，请为 `product` 微服务运行以下命令：
- en: '[PRE27]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'To see the Deployment manifest generated for a component that overrides the
    settings in the common chart, run the following commands for the MongoDB component:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看为覆盖通用图表设置的组件生成的 Deployment 清单，请为 MongoDB 组件运行以下命令：
- en: '[PRE28]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Expect output from the `helm template` command like this:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 期望 `helm template` 命令的输出如下：
- en: '[PRE29]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This concludes the walkthrough of the reusable named templates in the common
    chart. The files can be found in the folder `$BOOK_HOME/Chapter16/kubernetes/helm/common`.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了对通用图表中可重用命名模板的浏览。文件可以在文件夹 `$BOOK_HOME/Chapter16/kubernetes/helm/common`
    中找到。
- en: Next, let’s see how the component-specific charts are defined.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看如何定义特定组件的图表。
- en: The component charts
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组件图表
- en: 'The charts for the microservices and the resource managers are stored in the
    `components` folder, and they all share the same file structure:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务图表和资源管理器图表存储在 `components` 文件夹中，它们都共享相同的文件结构：
- en: '`Chart.yaml` expresses a dependency on the `common` library chart.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Chart.yaml` 表达了对 `common` 库图表的依赖。'
- en: 'The `template` folder contains two templates, `deployment.yaml` and `Service.yaml`.
    Both templates apply the corresponding named template from the common chart. For
    example, the `Service.yaml` template looks like this:'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`template` 文件夹包含两个模板，`deployment.yaml` 和 `Service.yaml`。这两个模板都应用来自通用图表的相应命名模板。例如，`Service.yaml`
    模板看起来像这样：'
- en: '[PRE30]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The `values.yaml` file contains settings specific to the microservice. For
    example, the `values` file for the `auth-server` chart looks like this:'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`values.yaml` 文件包含特定于微服务的设置。例如，`auth-server` 图表的 `values` 文件看起来像这样：'
- en: '[PRE31]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The `auth-server` only needs to declare its name, Docker image, Spring profile,
    and that it wants to use the default configuration of the liveness and readiness
    probes.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '`auth-server` 只需要声明其名称、Docker 镜像、Spring 配置文件，以及它希望使用默认的 liveness 和 readiness
    探针配置。'
- en: 'The config server differs from the other charts in that it uses a ConfigMap
    to store the `config-repo` containing the configuration files for all the other
    microservices. In its `template` folder, it defines a template for a ConfigMap
    that is based on the named template in the common chart for ConfigMaps that we
    have already been introduced to:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 配置服务器与其他图表不同，因为它使用 ConfigMap 来存储包含所有其他微服务配置文件的 `config-repo`。在其 `template` 文件夹中，它定义了一个基于我们之前已介绍过的通用图表中
    ConfigMaps 命名模板的模板：
- en: '[PRE32]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The template expects to find the property files in the charts folder, `config-repo`.
    To avoid duplicating the `config-repo` from `$BOOK_HOME/Chapter16/config-repo`,
    a **soft link**, also known as a **symbolic link**, has been created with the
    command:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 模板期望在图表文件夹 `config-repo` 中找到属性文件。为了避免从 `$BOOK_HOME/Chapter16/config-repo` 复制
    `config-repo`，已使用命令创建了一个**软链接**，也称为**符号链接**：
- en: '[PRE33]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Since Git preserves soft links, you don’t need to recreate the soft link – the
    `git clone` command makes it for you!
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Git 保留软链接，您不需要重新创建软链接 - `git clone` 命令会为您创建它！
- en: As already mentioned in the walkthrough of the common chart, the gateway Service
    differs from the other microservices, since it needs to expose a Service of type
    `NodePort`.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 如在通用图表的说明中已提到的，网关服务与其他微服务不同，因为它需要暴露类型为 `NodePort` 的服务。
- en: 'Besides the charts for the microservices, the `components` folder also contains
    charts for the databases, message broker, and Zipkin server we use. They are structured
    in the same way as the microservices. Since the common templates have been designed
    to streamline the charts for the microservices, the other charts need to override
    more default values in `values.yaml` files compared to the microservices. For
    more details, look at the `values.yaml` files in the following folders: `mongodb`,
    `mysql`, `rabbitmq`, and `zipkin-server`.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 除了微服务的图表之外，`components` 文件夹还包含我们使用的数据库、消息代理和 Zipkin 服务器的图表。它们的结构方式与微服务相同。由于通用模板已被设计用于简化微服务的图表，因此与其他图表相比，其他图表需要在
    `values.yaml` 文件中覆盖更多的默认值。有关更多详细信息，请查看以下文件夹中的 `values.yaml` 文件：`mongodb`、`mysql`、`rabbitmq`
    和 `zipkin-server`。
- en: The environment charts
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 环境图表
- en: 'Finally, the `dev-env` and `prod-env` charts in the `environments` folder tie
    everything together to complete installation packages for a typical development/test
    or staging/production environment. Their `Charts.yaml` file contains dependencies
    on both the `common` chart and the charts in the `components` folder, and the
    `template` folder contains a `secrets.yaml` template to create environment-specific
    credentials as Secrets. It is based on the named template for Secrets from the
    common chart and looks like this:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`environments` 文件夹中的 `dev-env` 和 `prod-env` 图表将所有内容结合起来，以完成典型开发/测试或预发布/生产环境的安装包。它们的
    `Charts.yaml` 文件包含对 `common` 图表和 `components` 文件夹中图表的依赖，而 `template` 文件夹包含一个 `secrets.yaml`
    模板，用于创建特定环境的凭据作为密钥。它基于通用图表中密钥的命名模板，看起来如下：
- en: '[PRE34]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Looking at the `dev-env` chart’s `values.yaml` file, we can find the following
    Secret values defined for the Secret `config-server-secrets`:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 查看 `dev-env` 图表的 `values.yaml` 文件，我们可以找到为 `config-server-secrets` 密钥定义的以下密钥值：
- en: '[PRE35]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This will result in the Secret `config-server-secrets` containing three Secret
    values, all Base64-encoded. Its manifest will look like this:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致 `config-server-secrets` 密钥包含三个密钥值，全部为 Base64 编码。其清单看起来如下：
- en: '[PRE36]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Note that this `values.yaml` file contains sensitive information, for example,
    the encrypt key used by the config server and the password used to access the
    config server. This file must be stored securely. An alternative, if it is inappropriate
    to store this file securely, is to remove the sensitive information from this
    file and supply it when the `helm install` command is executed.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，此 `values.yaml` 文件包含敏感信息，例如配置服务器使用的加密密钥和访问配置服务器的密码。此文件必须安全存储。如果不适于安全存储此文件，则另一种选择是在执行
    `helm install` 命令时从该文件中删除敏感信息并提供。
- en: 'To use the Secret in the Deployment manifest for the config server, the following
    is defined in the `dev-env` chart’s `values.yaml` file:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 要在配置服务器的部署清单中使用密钥，`dev-env` 图表的 `values.yaml` 文件中定义了以下内容：
- en: '[PRE37]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This will be used by the Deployment template described above to add the Secret
    as environment variables in the Deployment manifest for the config server.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这将由上面描述的部署模板使用，以在配置服务器的部署清单中将密钥作为环境变量添加。
- en: 'The `prod-env` chart overrides more values than the `dev-env` chart. For example,
    the `values.yaml` file in the `prod-env` chart specifies that an extra Spring
    profile, `prod`, should be used and what version to use for the Docker images.
    This looks like the following for the `product` microservice:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '`prod-env` 图表覆盖的值比 `dev-env` 图表更多。例如，`prod-env` 图表中的 `values.yaml` 文件指定应使用额外的
    Spring 配置文件 `prod`，以及 Docker 镜像的版本。对于 `product` 微服务，这看起来如下：'
- en: '[PRE38]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: With this introduction to what the various types of charts contain, let’s move
    on and use them together with the Helm commands we learned about to deploy our
    microservices in Kubernetes!
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 通过介绍各种类型图表包含的内容，让我们继续前进，并使用我们学到的 Helm 命令将微服务部署到 Kubernetes 中！
- en: Deploying to Kubernetes for development and test
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将应用程序部署到 Kubernetes 进行开发和测试
- en: In this section, we will deploy the microservices in an environment to be used
    for development and test activities, for example, system integration tests. This
    type of environment is used primarily for functional tests and is, therefore,
    configured to use minimal system resources and the latest available versions of
    the microservices’ Docker images.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将部署用于开发和技术活动的微服务环境，例如，系统集成测试。此类环境主要用于功能测试，因此配置为使用最少的系统资源和微服务 Docker 镜像的最新版本。
- en: To be able to run functional tests, we will deploy the microservices together
    with the resource managers they require in the same Namespace, which we will call
    `hands-on`. This makes it easy to set up a test environment and also to remove
    it once we are done with it. We can simply delete the Namespace to get rid of
    all resources used by the test environment.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够运行功能测试，我们将部署微服务及其所需的资源管理器在同一命名空间中，我们将称之为 `hands-on`。这使得设置测试环境变得容易，一旦我们完成测试，也可以轻松删除。我们可以简单地删除命名空间来移除测试环境使用的所有资源。
- en: 'This Deployment scenario is illustrated by the following diagram:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了此部署场景：
- en: '![Diagram  Description automatically generated](img/B19825_16_02.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![图描述自动生成](img/B19825_16_02.png)'
- en: 'Figure 16.2: Resource managers deployed in the same Kubernetes namespace as
    the microservices in the dev environment'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.2：在开发环境中的微服务相同 Kubernetes 命名空间中部署的资源管理器
- en: Before we can deploy the system landscape, we need to build our Docker images
    and resolve the dependencies for our Helm charts.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以部署系统景观之前，我们需要构建我们的 Docker 镜像并解决 Helm 图表的依赖项。
- en: Building Docker images
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建 Docker 镜像
- en: Normally, we have to push images to a Docker registry and configure Kubernetes
    to pull images from the registry. In our case, where we have a local single node
    cluster, we can shortcut this process by pointing our Docker client to the Docker
    engine in Minikube and then running the `docker-compose build` command. This will
    result in the Docker images being immediately available to Kubernetes. For development,
    we will use `latest` as the Docker image version for the microservices.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们必须将镜像推送到 Docker 仓库并配置 Kubernetes 从仓库拉取镜像。在我们的案例中，由于我们有一个本地单节点集群，我们可以通过将
    Docker 客户端指向 Minikube 中的 Docker 引擎，然后运行 `docker-compose build` 命令来简化此过程。这将导致 Docker
    镜像立即对 Kubernetes 可用。对于开发，我们将使用 `latest` 作为微服务的 Docker 镜像版本。
- en: 'You can build Docker images from the source as follows:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从源构建 Docker 镜像，如下所示：
- en: '[PRE39]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The `eval $(minikube docker-env)` command directs the local Docker client to
    communicate with the Docker engine in Minikube.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '`eval $(minikube docker-env)` 命令将本地 Docker 客户端指向 Minikube 中的 Docker 引擎。'
- en: 'The `docker-compose.yml` file has been updated to specify a name for the Docker
    images it builds. For example, for the `product` Service, we have the following:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker-compose.yml` 文件已更新，以指定它构建的 Docker 镜像的名称。例如，对于 `product` 服务，我们有以下内容：'
- en: '[PRE40]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '`latest` is the default tag for a Docker image name, so it is not specified.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '`latest` 是 Docker 镜像名称的默认标签，因此无需指定。'
- en: With the Docker images built, it’s time to build the Helm charts.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 镜像构建完成后，是时候构建 Helm 图表了。
- en: Resolving Helm chart dependencies
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决 Helm 图表依赖项
- en: 'First, we update the dependencies in the `components` folder:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们更新 `components` 文件夹中的依赖项：
- en: '[PRE41]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Next, we update the dependencies in the `environments` folder:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们更新 `environments` 文件夹中的依赖项：
- en: '[PRE42]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Finally, we verify that the dependencies for the `dev-env` folder look good:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们验证 `dev-env` 文件夹的依赖项看起来良好：
- en: '[PRE43]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Expect the command to respond with:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 预期命令会响应如下：
- en: '![](img/B19825_16_03.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19825_16_03.png)'
- en: 'Figure 16.3: Helm chart dependencies resolved'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.3：已解决的 Helm 图表依赖项
- en: With both Docker images built and Helm dependencies resolved, we can start deploying
    to Kubernetes!
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建了 Docker 镜像并解决了 Helm 依赖项后，我们可以开始部署到 Kubernetes！
- en: Deploying to Kubernetes
  id: totrans-300
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署到 Kubernetes
- en: 'A deploy to Kubernetes means creating or updating Kubernetes objects. We will
    use Helm to perform the Deployment, per the following steps:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 将系统部署到 Kubernetes 意味着创建或更新 Kubernetes 对象。我们将按照以下步骤使用 Helm 进行部署：
- en: 'To avoid a slow Deployment process due to Kubernetes downloading Docker images
    (potentially causing the liveness probes we described previously to restart our
    Pods), run the following `docker pull` commands to download the images in advance:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了避免由于 Kubernetes 下载 Docker 镜像（可能引起我们之前描述的存活探针重启我们的 Pod）而导致的缓慢部署过程，请运行以下 `docker
    pull` 命令预先下载镜像：
- en: '[PRE44]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Before using the Helm charts, render the templates using the `helm template`
    command to see what the manifests will look like:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在使用Helm图表之前，使用`helm template`命令渲染模板，以查看清单将是什么样子：
- en: '[PRE45]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Note that no interaction was performed with the Kubernetes cluster, so cluster
    information will be faked, and no tests are run to verify whether the rendered
    manifest will be accepted by the cluster.
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，这里没有与Kubernetes集群进行交互，因此集群信息将被伪造，并且不会运行测试来验证渲染的清单是否会被集群接受。
- en: 'To also verify that the Kubernetes cluster will actually accept the rendered
    manifest, a **dry run** of the installation can be performed by passing `–-dry-run`
    to the `helm install` command. Passing the `--debug` flag will also show which
    user-supplied and calculated values Helm will use when rendering the manifests.
    Run the following command to perform a dry run:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要验证Kubernetes集群实际上会接受渲染的清单，可以通过将`–-dry-run`传递给`helm install`命令来执行安装的**dry run**。传递`--debug`标志也会显示Helm在渲染清单时将使用哪些用户提供的和计算出的值。运行以下命令以执行dry
    run：
- en: '[PRE46]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'To initiate the Deployment of the complete system landscape, including creating
    the Namespace, `hands-on`, run the following command:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要启动整个系统景观的部署，包括创建命名空间、`hands-on`，请运行以下命令：
- en: '[PRE47]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Note that here is where the Helm machinery kicks in. It will use the charts
    we walked through in the *Introducing Helm* section above to render and apply
    the Kubernetes manifests, resulting in the required Kubernetes objects for the
    Deployment being created.
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，这里是Helm机制开始发挥作用的地方。它将使用我们在上面*介绍Helm*部分中介绍的图表来渲染和应用Kubernetes清单，从而创建部署所需的Kubernetes对象。
- en: 'Set the newly created namespace as the default namespace for `kubectl`:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将新创建的命名空间设置为`kubectl`的默认命名空间：
- en: '[PRE48]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'To see the Pods starting up, run the command:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查看Pod启动，请运行以下命令：
- en: '[PRE49]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'This command will continuously report when new Pods are **Running**, and if
    something goes wrong it will report the status, for example, **Error** and **CrashLoopBackOff**.
    After a while, you might see that errors are reported for the **gateway**, **product-composite**,
    and **zipkin-server** Pods. The reason for this is that they all depend on external
    resources that they require to be accessible during the startup. If not, they
    will crash. The gateway and product composite Service depend on the auth server,
    and the Zipkin server depends on access to RabbitMQ. Typically, they start up
    faster than the resources they rely on, causing this situation. However, Kubernetes
    will detect the crashed Pods, and they will restart. Once the resources are up
    and running, all Pods will start up and be reported as ready, showing **1/1**
    in the **READY** column. A sample output from the command looks like this:'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此命令将连续报告新Pod的状态为**运行中**，如果出现问题，它将报告状态，例如**错误**和**CrashLoopBackOff**。过了一会儿，你可能会看到**网关**、**产品组合**和**zipkin-server**
    Pod报告了错误。这是因为它们都需要在启动时访问外部资源。如果没有，它们将会崩溃。网关和产品组合服务依赖于认证服务器，而Zipkin服务器依赖于对RabbitMQ的访问。通常，它们启动速度比它们依赖的资源快，导致这种情况。然而，Kubernetes会检测到崩溃的Pod，并将它们重启。一旦资源启动并运行，所有Pod都将启动并报告为就绪，**READY**列显示为**1/1**。命令的示例输出如下：
- en: '![A picture containing text  Description automatically generated](img/B19825_16_04.png)'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![包含文本的图片  自动生成的描述](img/B19825_16_04.png)'
- en: 'Figure 16.4: Pods restarted until external dependencies are ready'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图16.4：Pod在外部依赖就绪之前重启
- en: After seeing some output like the above, interrupt the command with *Ctrl*+*C*.
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在看到一些如上所示的输出后，使用*Ctrl*+*C*中断命令。
- en: 'Wait for all the Pods in the Namespace to be ready with the command:'
  id: totrans-320
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令等待命名空间中的所有Pod就绪：
- en: '[PRE50]'
  id: totrans-321
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Expect the command to respond with 11 log lines like `pod/... condition met`,
    where the three dots (`...`) are replaced with the name of the actual Pod that
    is reported to be ready.
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期命令将响应11行日志，如`pod/... condition met`，其中三个点（`...`）将被报告为就绪的实际Pod名称所替换。
- en: 'To see the Docker images that are used, run the following command:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查看使用的Docker镜像，请运行以下命令：
- en: '[PRE51]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The response should look like the following:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 响应应如下所示：
- en: '![Text, chat or text message  Description automatically generated](img/B19825_16_05.png)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![文本、聊天或文本消息  自动生成的描述](img/B19825_16_05.png)'
- en: 'Figure 16.5: Docker images used in a test environment'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.5：测试环境中使用的Docker镜像
- en: Note that the Docker images have the version tag set to **latest** for the microservices.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，微服务的Docker镜像的版本标签设置为**latest**。
- en: We are now ready to test our Deployment! However, before we can do that, we
    need to go through changes that are required in the test script for use with Kubernetes.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备测试我们的部署！然而，在我们能够这样做之前，我们需要通过测试脚本中所需的更改，以便与 Kubernetes 一起使用。
- en: Changes in the test script for use with Kubernetes
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于 Kubernetes 的测试脚本更改
- en: To verify the Deployment, we will, as usual, run the test script, `test-em-all.bash`.
    To work with Kubernetes, the circuit breaker tests have been slightly modified.
    The circuit breaker tests call the `actuator` endpoints on the `product-composite`
    Service to check their health state and get access to circuit breaker events.
    Since this endpoint isn’t exposed externally, the previous chapters used the `docker-compose
    exec` command to run a `curl` command inside of the `product-composite` Service
    to perform the tests.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证部署，我们将像往常一样运行测试脚本，`test-em-all.bash`。为了与 Kubernetes 一起工作，断路器测试已经略有修改。断路器测试在
    `product-composite` 服务上调用 `actuator` 端点来检查其健康状态并获取访问断路器事件的权限。由于此端点未对外暴露，前几章使用了
    `docker-compose exec` 命令在 `product-composite` 服务内部运行 `curl` 命令以执行测试。
- en: Starting with this chapter, the test script can either use the `docker-compose
    exec` command or the corresponding `kubectl` command, `kubectl exec`, depending
    on whether we run the microservices using Docker Compose or Kubernetes.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 从本章开始，测试脚本可以使用 `docker-compose exec` 命令或相应的 `kubectl` 命令，`kubectl exec`，这取决于我们是否使用
    Docker Compose 或 Kubernetes 运行微服务。
- en: To know which command to use, a new parameter has been added to the script,
    `USE_K8S`. It defaults to `false`. For details, see the `testCircuitBreaker()`
    function in the test script.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 要知道使用哪个命令，脚本中已添加了一个新参数，`USE_K8S`。它默认为 `false`。有关详细信息，请参阅测试脚本中的 `testCircuitBreaker()`
    函数。
- en: Testing the Deployment
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试部署
- en: When launching the test script, we have to give it the address of the host that
    runs Kubernetes, that is, our Minikube instance, and the `NodePort` where our
    gateway Service listens for external requests. The gateway is accessible using
    port `30443`. As mentioned in *Chapter 15*, since we use Minikube’s `docker` driver,
    the hostname is always `localhost`. Since the hostname is the same as when running
    tests with Docker Compose, we don’t have to specify it; only the port has to be
    specified, together with the `USE_K8S` parameter.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动测试脚本时，我们必须提供运行 Kubernetes 的主机地址，即我们的 Minikube 实例，以及我们的网关服务监听外部请求的 `NodePort`。网关可以通过端口
    `30443` 访问。如 *第 15 章* 中所述，由于我们使用 Minikube 的 `docker` 驱动程序，主机名始终是 `localhost`。由于主机名与使用
    Docker Compose 运行测试时相同，我们不需要指定它；只需指定端口，以及 `USE_K8S` 参数即可。
- en: 'Start the tests with the following command:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令开始测试：
- en: '[PRE52]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'In the output from the script, we can see how the `NodePort` is used, but besides
    that, everything looks the same as when we used Docker Compose in the previous
    chapters:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 在脚本的输出中，我们可以看到 `NodePort` 的使用情况，但除此之外，一切看起来都和我们在前几章中使用 Docker Compose 时的样子一样：
- en: '![Text  Description automatically generated](img/B19825_16_06.png)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![文本描述自动生成](img/B19825_16_06.png)'
- en: 'Figure 16.6: Output from the automated tests of the system landscape'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.6：系统景观自动化测试的输出
- en: With the system landscape validations performed, let’s see how we can test the
    new features in Spring Boot, graceful shutdown, and the probes for liveness and
    readiness.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 在系统景观验证完成后，让我们看看我们如何测试 Spring Boot 的新功能，优雅关闭以及存活性和就绪性探测。
- en: Testing Spring Boot’s support for graceful shutdown and probes for liveness
    and readiness
  id: totrans-342
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试 Spring Boot 对优雅关闭和存活性及就绪性探测的支持
- en: In this section, we will test out the new Spring Boot features and see how they
    interact with other components in Kubernetes.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将测试新的 Spring Boot 功能，并查看它们如何与其他 Kubernetes 组件交互。
- en: Let’s start by testing Spring Boot’s support for graceful shutdown, where the
    application during its shutdown phase will wait a configurable length of time
    for active requests to complete. Remember that no new requests are allowed during
    the shutdown phase.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先来测试 Spring Boot 对优雅关闭的支持，在这个阶段，应用程序将等待一个可配置的时间长度，以完成活跃请求。记住，在关闭阶段不允许新的请求。
- en: To test the graceful shutdown mechanism, we will run a client that continuously
    sends requests to the composite Service. First, we will use it to send requests
    that take 5 seconds, a shorter amount of time than the shutdown wait period. The
    waiting period is configured to be 10 seconds. Next, we will use it to send requests
    that take a longer time, 15 seconds, to see how they are handled. As the test
    client, we will use **Siege**, a command-line-based-load test tool.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试优雅关闭机制，我们将运行一个持续向复合服务发送请求的客户端。首先，我们将使用它发送需要 5 秒的请求，这比关闭等待期短。等待期配置为 10 秒。然后，我们将使用它发送需要更长时间的请求，15
    秒，以查看它们是如何处理的。作为测试客户端，我们将使用 **Siege**，这是一个基于命令行的负载测试工具。
- en: To be able to test run requests that take this long to complete, we need to
    temporarily increase the timeout in the `product-composite` Service. Otherwise,
    its circuit breaker will kick in and prevent us from running the long requests.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够测试运行这种长时间完成的请求，我们需要暂时增加 `product-composite` 服务的超时。否则，其断路器将启动并阻止我们运行长时间请求。
- en: 'To increase the timeout in the composite Service, perform the following steps:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 要在复合服务中增加超时，请执行以下步骤：
- en: 'Add the following under the `product-composite` section in the `values` file
    for the `dev-env`, `kubernetes/helm/environments/dev-env/values.yaml`:'
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `values` 文件中 `dev-env` 的 `product-composite` 部分添加以下内容，对于 `dev-env`，`kubernetes/helm/environments/dev-env/values.yaml`：
- en: '[PRE53]'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'After the change, the configuration file should look like this:'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更改后，配置文件应如下所示：
- en: '[PRE54]'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: As long as this setting is active, the circuit breaker tests in `test-em-all.bash`
    will no longer work, since they assume a timeout of 2 seconds.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 只要此设置处于活动状态，`test-em-all.bash` 中的断路器测试将不再工作，因为它们假设超时为 2 秒。
- en: 'Update the Helm installation with Helm’s `upgrade` command, using the `--wait`
    flag to ensure that the update is completed when the command terminates:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Helm 的 `upgrade` 命令更新 Helm 安装，使用 `--wait` 标志以确保在命令终止时更新完成：
- en: '[PRE55]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Now we can run the tests, proceeding with the following steps to test with
    requests that are shorter than the shutdown wait period:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以运行测试，按照以下步骤使用短于关闭等待期的请求进行测试：
- en: 'Get an access token:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取访问令牌：
- en: '[PRE56]'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Ensure you got an access token by issuing the command `echo $ACCESS_TOKEN`.
    If it’s empty, you have to check the `curl` command above and the logs from the
    gateway and the auth server.
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过运行命令 `echo $ACCESS_TOKEN` 确保你获得了访问令牌。如果它是空的，你必须检查上面的 `curl` 命令和网关以及身份验证服务器的日志。
- en: 'Make a test request and ask for a delay of 5 seconds using the `delay` query
    parameter:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送测试请求并使用 `delay` 查询参数请求 5 秒的延迟：
- en: '[PRE57]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: If you get a normal response and the `time` command reports a 5-second response
    time, the config changes of the increased timeout worked!
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你得到正常响应，并且 `time` 命令报告了 5 秒的响应时间，增加超时的配置更改已生效！
- en: 'Use Siege to start requests that take 5 seconds to complete, with five concurrent
    users sending requests with a random delay between 0 and 2 seconds to spread out
    the requests slightly:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Siege 启动需要 5 秒才能完成的请求，有五个并发用户发送请求，请求之间有 0 到 2 秒的随机延迟，以稍微分散请求：
- en: '[PRE58]'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Expect output from the tool for each completed request like this:'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于每个完成的请求，工具的输出应如下所示：
- en: '[PRE59]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Watch log output from the `product` Service in a separate terminal window with
    the command:'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在单独的终端窗口中监视 `product` 服务的日志输出：
- en: '[PRE60]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'We will now ask Kubernetes to restart the `product` Deployment. The restart
    will first start a new Pod before the old one is shut down, meaning that none
    of the requests sent by Siege should be affected by the restart. Of specific interest
    are the few requests that are processed by the old Pod when it starts to shut
    down. If the graceful shutdown works as expected, none of the active requests
    should fail. Perform the restart by running the following command in a separate
    window:'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将要求 Kubernetes 重新启动 `product` 部署。重启将首先启动一个新的 Pod，然后关闭旧的 Pod，这意味着 Siege
    发送的任何请求都不应受到重启的影响。特别关注的是，当旧 Pod 开始关闭时，它处理的少量请求。如果优雅关闭按预期工作，则不应有任何活跃请求失败。通过在单独的窗口中运行以下命令来执行重启：
- en: '[PRE61]'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Ensure that there are only successful requests reported in the output from the
    load-test tool, Siege, reporting **200** **(OK).**
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保从负载测试工具 Siege 的输出中只报告成功的请求，显示 **200** **(OK)**。
- en: 'In the log output from the now-stopped `product` Pod, you should see that all
    requests were allowed to terminate gracefully before the application was stopped.
    Expect log output like the following, at the end of the log output:'
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在已停止的`product` Pod的日志输出中，你应该看到在应用程序停止之前，所有请求都被允许优雅地终止。期望看到如下日志输出，在日志输出的末尾：
- en: '![Text  Description automatically generated](img/B19825_16_07.png)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![文本描述自动生成](img/B19825_16_07.png)'
- en: 'Figure 16.7: Graceful shutdown where all requests are allowed to complete'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.7：所有请求都允许完成的优雅关闭
- en: Specifically, note the time between the two log messages (4 seconds, in this
    case), indicating that the shutdown procedure actually waited for the last request
    to complete.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，注意两个日志消息之间的时间（在这种情况下为4秒），这表明关闭程序实际上等待最后一个请求完成。
- en: 'Now let’s run the second test, with requests taking a longer time to complete
    than the shutdown wait period:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们运行第二个测试，请求完成所需时间比关闭等待期更长：
- en: 'Restart Siege, requesting longer response times, above the wait limit of 10
    seconds. Start five concurrent users, asking for a 15-second response time and
    a random delay between the requests of 0–5 seconds. Stop Siege with *Ctrl*+*C*
    and run the following command:'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新启动Siege，请求更长的响应时间，超过10秒的等待限制。启动五个并发用户，请求15秒的响应时间和请求之间的0-5秒随机延迟。使用*Ctrl*+*C*停止Siege并运行以下命令：
- en: '[PRE62]'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Watch the log output from the `product` Pod with the command:'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令监视`product` Pod的日志输出：
- en: '[PRE63]'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Restart the `product` Deployment:'
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新启动`product`部署：
- en: '[PRE64]'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Follow the log output from the `product` Pod. Once it has shut down, you should
    be able to see that not all requests were allowed to terminate gracefully before
    the application was stopped. Expect log output like the following, at the end
    of the log output:![Text  Description automatically generated](img/B19825_16_08.png)
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 跟踪`product` Pod的日志输出。一旦它关闭，你应该能够看到在应用程序停止之前，并非所有请求都被允许优雅地终止。期望看到如下日志输出，在日志输出的末尾：![文本描述自动生成](img/B19825_16_08.png)
- en: 'Figure 16.8: Graceful shutdown where some long-running requests are aborted'
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图16.8：某些长时间运行的请求被终止的优雅关闭
- en: The log message **Graceful shutdown aborted with one or more requests still
    active** indicates that at least one request was not allowed to complete before
    the application was stopped.
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 日志消息**优雅关闭因一个或多个请求仍然活跃而被终止**表明在应用程序停止之前至少有一个请求没有被允许完成。
- en: 'In the output from the load-test tool, Siege, there should now appear one or
    a few failing requests reporting **500** **(Internal Server Error)** like this:'
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在负载测试工具Siege的输出中，现在应该出现一个或几个失败的请求报告**500**（内部服务器错误），如下所示：
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B19825_16_09.png)'
  id: totrans-386
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  描述自动生成，中等置信度](img/B19825_16_09.png)'
- en: 'Figure 16.9: Long-running requests fail during shutdown'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.9：在关闭期间长时间运行的请求失败
- en: This demonstrates how the shutdown procedure proceeds after the configured wait
    time and that the remaining long-running requests are aborted, as expected.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 这证明了关闭程序在配置的等待时间之后如何进行，以及剩余的长时间运行请求如预期的那样被终止。
- en: This completes the tests of Spring Boot’s graceful shutdown mechanism, which
    is clearly useful to avoid normal client requests being affected by Pods being
    stopped, for example, as a result of scaling down or a rolling upgrade being performed.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了Spring Boot优雅关闭机制的测试，这显然有助于避免正常客户端请求受到Pod停止的影响，例如，由于缩放或滚动升级执行的结果。
- en: 'Clean up after the tests:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 清理测试后的环境：
- en: Stop the Siege load-test tool with *Ctrl*+*C*.
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*Ctrl*+*C*停止Siege负载测试工具。
- en: 'Roll back the latest Helm release to get rid of the increased timeout:'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回滚最新的Helm发布以去除增加的超时：
- en: '[PRE65]'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: The `helm rollback` command is also useful to roll back a failed upgrade.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '`helm rollback`命令也很有用，可以回滚失败的升级。'
- en: Also remove the increased timeout setting in the file `kubernetes/helm/environments/dev-env/values.yaml`.
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还需要在文件`kubernetes/helm/environments/dev-env/values.yaml`中移除增加的超时设置。
- en: 'Run `test-em-all.bash` to verify that the configuration is rolled back:'
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`test-em-all.bash`以验证配置已回滚：
- en: '[PRE66]'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Finally, let’s see what information the Spring Boot liveness and readiness
    probes report. We will use the `product` Service, but feel free to also try out
    the probes for other Services:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看看Spring Boot的存活和就绪探针报告了什么信息。我们将使用`product`服务，但也可以尝试其他服务的探针：
- en: 'Run the following command to get output from the `product` Service’s liveness
    probe:'
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令以获取`product`服务的存活探针输出：
- en: '[PRE67]'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Expect it to respond with:'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期它会这样响应：
- en: '![Graphical user interface, text, application  Description automatically generated](img/B19825_16_10.png)'
  id: totrans-402
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，文本，应用程序，自动生成描述](img/B19825_16_10.png)'
- en: 'Figure 16.10: Response from a liveness probe'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.10：存活性探测的响应
- en: 'Run the following command to get output from the `product` Service’s readiness
    probe:'
  id: totrans-404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令以获取`product`服务就绪性探测的输出：
- en: '[PRE68]'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Expect its response to be a bit more extensive:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 预期其响应会更加详细：
- en: '![A screenshot of a computer screen  Description automatically generated with
    medium confidence](img/B19825_16_11.png)'
  id: totrans-407
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图，自动生成描述，中等置信度](img/B19825_16_11.png)'
- en: 'Figure 16.11: Response from a readiness probe'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.11：就绪性探测的响应
- en: From the output above, we can confirm that the readiness of the `product` now
    depends on its access to both MongoDB and RabbitMQ. This is expected, since we
    configured the readiness health group to include health indicators for RabbitMQ,
    MongoDB, and SQL databases, if available. See the section *Using Spring Boot’s
    support for graceful shutdown and probes for liveness and readiness* to recap,
    if required.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的输出中，我们可以确认现在`product`的可用性取决于其访问MongoDB和RabbitMQ。这是预期的，因为我们配置了就绪健康组以包括RabbitMQ、MongoDB和SQL数据库的健康指标，如果可用的话。如果需要，请参阅*使用Spring
    Boot对优雅关闭和存活性及就绪性探测的支持*部分进行回顾。
- en: Before we move on, let’s clean up what we have installed in the development
    environment. We can do this by simply deleting the namespace. Deleting the namespace
    will recursively delete the resources that exist in the namespace, including information
    regarding the Helm installation.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，让我们清理一下在开发环境中安装的内容。我们可以通过简单地删除命名空间来完成这项工作。删除命名空间将递归地删除命名空间中存在的资源，包括关于Helm安装的信息。
- en: 'Delete the namespace with the following command:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令删除命名空间：
- en: '[PRE69]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: If you just want to uninstall what the `helm install` command installed, you
    can run the command `helm uninstall hands-on-dev-env`.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只想卸载`helm install`命令安装的内容，你可以运行命令`helm uninstall hands-on-dev-env`。
- en: With the development environment removed, we can move on and set up an environment
    targeting staging and production.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 在移除开发环境后，我们可以继续前进，并设置一个针对预发布和生产的开发环境。
- en: Deploying to Kubernetes for staging and production
  id: totrans-415
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将应用程序部署到Kubernetes进行预发布和发布
- en: In this section, we will deploy the microservices in an environment for staging
    and production usage. A staging environment is used to perform **quality assurance**
    (**QA**) and **user acceptance tests** (**UATs**) as the last step before taking
    a new release into production. To be able to verify that a new release not only
    meets functional requirements but also non-functional requirements, for example,
    in terms of performance, robustness, scalability, and resilience, a staging environment
    is configured to be as similar as possible to the production environment.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将部署用于预发布和生产使用的微服务环境。预发布环境用于在将新版本投入生产之前执行**质量保证**（**QA**）和**用户验收测试**（**UATs**）。为了能够验证新版本不仅满足功能需求，还满足非功能需求，例如性能、健壮性、可扩展性和弹性，预发布环境被配置得尽可能接近生产环境。
- en: 'When deploying to an environment for staging or production, there are a number
    of changes required compared to when deploying for development or tests:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 将应用程序部署到预发布或生产环境时，与开发或测试部署相比，需要做出一些更改：
- en: '**Resource managers should run outside of the Kubernetes cluster**: It is technically
    feasible to run databases and queue managers for production use on Kubernetes
    as stateful containers, using `StatefulSets` and `PersistentVolumes`. At the time
    of writing, I recommend against it, mainly because the support for stateful containers
    is relatively new and unproven in Kubernetes. Instead, I recommend using the existing
    database and queue manager Services on-premises or as managed Services in the
    cloud, leaving Kubernetes to do what it is best at: running stateless containers.
    For the scope of this book, to simulate a production environment, we will run
    MySQL, MongoDB, and RabbitMQ as plain Docker containers outside of Kubernetes,
    using the already existing Docker Compose files.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源管理器应在Kubernetes集群外部运行**：从技术上讲，可以在Kubernetes上作为有状态容器运行数据库和队列管理器以供生产使用，使用`StatefulSets`和`PersistentVolumes`。在撰写本文时，我建议不要这样做，主要是因为Kubernetes中对有状态容器的支持相对较新且未经证实。相反，我建议使用现有的数据库和队列管理器本地或作为云中的托管服务，让Kubernetes做它最擅长的事情：运行无状态容器。就本书的范围而言，为了模拟生产环境，我们将在Kubernetes外部作为普通Docker容器运行MySQL、MongoDB和RabbitMQ，使用已存在的Docker
    Compose文件。'
- en: '**Lockdown**:'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**锁定**：'
- en: For security reasons, things like `actuator` endpoints and log levels need to
    be constrained in a production environment.
  id: totrans-420
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于安全原因，像`actuator`端点和日志级别这样的东西在生产环境中需要受到限制。
- en: Externally exposed endpoints should also be reviewed from a security perspective.
    For example, access to the configuration server should probably be locked down
    in a production environment, but we will keep it exposed in this book for convenience.
  id: totrans-421
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从安全角度也应该审查外部暴露的端点。例如，在生产环境中，可能需要锁定对配置服务器的访问，但为了方便，我们将在本书中保持其暴露。
- en: Docker image tags must be specified to be able to track which versions of the
    microservices have been deployed.
  id: totrans-422
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须指定Docker镜像标签，以便能够跟踪已部署的微服务的版本。
- en: '**Scale up available resources**: To meet the requirements of both high availability
    and higher load, we need to run at least two Pods per Deployment. We might also
    need to increase the amount of memory and CPU that are allowed to be used per
    Pod. To avoid running out of memory in the Minikube instance, we will keep one
    Pod per Deployment but increase the maximum memory allowed in the production environment.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩大可用资源**：为了满足高可用性和更高负载的需求，我们需要每个Deployment运行至少两个Pod。我们可能还需要增加每个Pod允许使用的内存和CPU的数量。为了避免在Minikube实例中内存不足，我们将每个Deployment运行一个Pod，但在生产环境中增加允许的最大内存。'
- en: '**Set up a production-ready Kubernetes cluster**: This is outside the scope
    of this book, but, if feasible, I recommend using one of the managed Kubernetes
    Services provided by the leading cloud providers. For the scope of this book,
    we will deploy to our local Minikube instance.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设置一个生产就绪的Kubernetes集群**：这超出了本书的范围，但如果可行，我建议使用主要云提供商提供的托管Kubernetes服务之一。就本书的范围而言，我们将部署到我们的本地Minikube实例。'
- en: This is not meant to be an exhaustive list of things that have to be considered
    when setting up an environment for production, but it’s a good start.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是在设置生产环境时必须考虑的所有事情的详尽列表，但这是一个良好的开始。
- en: 'Our simulated production environment will look as follows:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模拟生产环境将如下所示：
- en: '![Diagram  Description automatically generated](img/B19825_16_12.png)'
  id: totrans-427
  prefs: []
  type: TYPE_IMG
  zh: '![图描述自动生成](img/B19825_16_12.png)'
- en: 'Figure 16.12: Resource managers deployed outside of Kubernetes'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.12：部署在Kubernetes外部的资源管理器
- en: Changes in the source code
  id: totrans-429
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 源代码中的更改
- en: 'The following changes have been applied to the source code to prepare for Deployment
    in an environment that’s used for staging and production:'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 对源代码进行了以下更改，以准备在用于预演和生产的环境中进行部署：
- en: 'A Spring profile named `prod` has been added to the configuration files in
    the `config-repo` configuration repository:'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`config-repo`配置存储库中的配置文件中添加了一个名为`prod`的Spring配置文件：
- en: '[PRE70]'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'In the `prod` profiles, the following have been added:'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`prod`配置文件中，已添加以下内容：
- en: 'URLs to the resource managers that run as plain Docker containers:'
  id: totrans-434
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行作为普通Docker容器的资源管理器URL：
- en: '[PRE71]'
  id: totrans-435
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: We use the `172.17.0.1` IP address to address the Docker engine in the Minikube
    instance. This is the default IP address for the Docker engine when creating it
    with Minikube, at least for Minikube up to version 1.18.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`172.17.0.1` IP地址来在Minikube实例中定位Docker引擎。这是使用Minikube创建Docker引擎时的默认IP地址，至少对于版本1.18以下的Minikube来说是这样。
- en: There is work ongoing to establish a standard DNS name for containers to use
    if they need to access the Docker host they run on, but at the time of writing,
    this work effort hasn’t been completed.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 正在进行工作，以建立一个标准 DNS 名称，供容器在需要访问其运行的 Docker 主机时使用，但在撰写本文时，这项工作尚未完成。
- en: 'Log levels have been set to warning or higher, that is, error or fatal. For
    example:'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志级别已设置为警告或更高，即错误或致命。例如：
- en: '[PRE72]'
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The only `actuator` endpoints that are exposed over HTTP are the `info` and
    `health` endpoints that are used by the liveness and readiness probes in Kubernetes,
    as well as the `circuitbreakerevents` endpoint that’s used by the test script,
    `test-em-all.bash`:'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 HTTP 上公开的唯一 `actuator` 端点是 `info` 和 `health` 端点，这些端点用于 Kubernetes 中的存活和就绪探测，以及由测试脚本
    `test-em-all.bash` 使用的 `circuitbreakerevents` 端点：
- en: '[PRE73]'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'In a real-world production environment, we should also have changed the `imagePullPolicy:
    Never` setting to `IfNotPresent`, to download Docker images from a Docker registry.
    However, since we will deploy the production setup to the Minikube instance where
    we manually build and tag the Docker images, we will not update this setting.'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '在现实世界的生产环境中，我们还应该将 `imagePullPolicy: Never` 设置更改为 `IfNotPresent`，以便从 Docker
    仓库下载 Docker 镜像。然而，由于我们将部署生产设置到我们手动构建和标记 Docker 镜像的 Minikube 实例中，我们将不会更新此设置。'
- en: Deploying to Kubernetes
  id: totrans-443
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署到 Kubernetes
- en: 'To simulate the use of production-grade resource managers, MySQL, MongoDB,
    and RabbitMQ will run outside of Kubernetes using Docker Compose. We will start
    them up as we did in the previous chapters:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟使用生产级资源管理器，MySQL、MongoDB 和 RabbitMQ 将使用 Docker Compose 在 Kubernetes 外部运行。我们将像前几章那样启动它们：
- en: '[PRE74]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'We also need to tag the existing Docker images with `v1`, using the following
    commands:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要使用以下命令对现有的 Docker 镜像进行 `v1` 标记：
- en: '[PRE75]'
  id: totrans-447
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'From here, the commands are very similar to how we deployed to the development
    environment:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里开始，命令与我们在开发环境中部署的方式非常相似：
- en: 'Deploy using Helm:'
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Helm 部署：
- en: '[PRE76]'
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Wait for the Deployments to be up and running:'
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待部署正常运行：
- en: '[PRE77]'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'To see the Docker images that are currently used in the production environment,
    run the following command:'
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查看当前生产环境中使用的 Docker 镜像，请运行以下命令：
- en: '[PRE78]'
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The response should look something like the following:'
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 响应应该看起来像以下这样：
- en: '![Text  Description automatically generated](img/B19825_16_13.png)'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![文本描述自动生成](img/B19825_16_13.png)'
- en: 'Figure 16.13: Docker images used in a production environment'
  id: totrans-457
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 16.13：生产环境中使用的 Docker 镜像
- en: Note the `v1` version of the Docker images!
  id: totrans-458
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意 Docker 镜像的 `v1` 版本！
- en: Also note that the resource manager Pods for MySQL, MongoDB, and RabbitMQ are
    gone; these can be found with the `docker-compose ps` command.
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 还要注意，MySQL、MongoDB 和 RabbitMQ 的资源管理器 Pod 已消失；这些可以使用 `docker-compose ps` 命令找到。
- en: 'Run the test script, `test-em-all.bash`, to verify the simulated production
    environment:'
  id: totrans-460
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行测试脚本 `test-em-all.bash` 以验证模拟的生产环境：
- en: '[PRE79]'
  id: totrans-461
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: Expect the same type of output that we got when the test script was run against
    the development environment.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 预期与在开发环境中运行测试脚本时相同的输出类型。
- en: That completes the tests; let’s clean up so that the Kubernetes environment
    is ready for the next chapter.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了测试；让我们清理一下，以便 Kubernetes 环境为下一章做好准备。
- en: Cleaning up
  id: totrans-464
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 清理
- en: 'To delete the resources that we used, run the following commands:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除我们使用的资源，请运行以下命令：
- en: 'Delete the namespace:'
  id: totrans-466
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除命名空间：
- en: '[PRE80]'
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Shut down the resource managers that run outside of Kubernetes:'
  id: totrans-468
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭运行在 Kubernetes 外部的资源管理器：
- en: '[PRE81]'
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: The `eval $(minikube docker-env -u)` command directs the local Docker client
    to communicate with the local Docker engine and no longer communicate with the
    Docker engine in Minikube.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: '`eval $(minikube docker-env -u)` 命令指示本地 Docker 客户端与本地 Docker 引擎通信，而不再与 Minikube
    中的 Docker 引擎通信。'
- en: As already described earlier in this chapter, the `kubectl delete namespace`
    command will recursively delete all Kubernetes resources that existed in the namespace,
    and the `docker-compose down` command will stop MySQL, MongoDB, and RabbitMQ.
    With the production environment removed, we have reached the end of this chapter.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章前面所述，`kubectl delete namespace` 命令将递归删除命名空间中存在的所有 Kubernetes 资源，而 `docker-compose
    down` 命令将停止 MySQL、MongoDB 和 RabbitMQ。随着生产环境的移除，我们已到达本章的结尾。
- en: Summary
  id: totrans-472
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned how to deploy the microservices in this book on
    Kubernetes using Helm. We have seen how Helm can be used to create reusable templates,
    minimizing the boilerplate code required to create the Kubernetes manifests. Reusable
    templates are stored in a common chart, while microservice-specific charts provide
    values specific to each microservice. At the top level, we have parent charts
    that describe how a development/test and stage/production environment should be
    deployed using the microservice charts, optionally together with charts for resource
    managers such as databases and queue managers.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用Helm在Kubernetes上部署本书中的微服务。我们看到了如何使用Helm创建可重用的模板，从而最小化创建Kubernetes清单所需的样板代码。可重用模板存储在公共图表中，而特定于微服务的图表提供每个微服务特有的值。在顶层，我们有父图表，描述了如何使用微服务图表部署开发/测试和阶段/生产环境，可选地还可以与数据库和队列管理器等资源管理器的图表一起部署。
- en: We have also seen how we can benefit from using Spring Boot features to facilitate
    Deployments to Kubernetes. Spring Boot’s support for graceful shutdown can be
    used to allow active requests to complete before a Spring Boot-based microservice
    is stopped, for example, during a rolling upgrade. The support for liveness and
    readiness probes makes it easy to declare probes that are aware of the availability
    of external resources that a specific microservice depends on.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到了如何利用Spring Boot功能来简化部署到Kubernetes的过程。Spring Boot对优雅关闭的支持可以在停止基于Spring
    Boot的微服务之前允许活动请求完成，例如，在滚动升级期间。对存活性和就绪性探测的支持使得声明对特定微服务所依赖的外部资源可用性的探测变得容易。
- en: Finally, to be able to deploy our microservices in Kubernetes, we had to replace
    Netflix Eureka with the built-in discovery Service in Kubernetes. Changing the
    discovery Service was done without any changes in the Java source code – all we
    had to do was apply changes to the build dependencies and some of the configuration.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了能够在Kubernetes中部署我们的微服务，我们不得不将Netflix Eureka替换为Kubernetes内置的发现服务。更改发现服务没有对Java源代码进行任何更改——我们只需要对构建依赖项和一些配置进行更改。
- en: In the next chapter, we will see how we can further utilize Kubernetes to reduce
    the number of supporting Services we need to deploy in Kubernetes. Head over to
    the next chapter to see how we can eliminate the need for the configuration server
    and how our edge server can be replaced by a Kubernetes Ingress controller.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到如何进一步利用Kubernetes来减少在Kubernetes中需要部署的支持服务的数量。前往下一章，了解我们如何消除对配置服务器的需求，以及我们的边缘服务器如何可以被Kubernetes
    Ingress控制器所替代。
- en: Questions
  id: totrans-477
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Why did we remove the Eureka server from the microservice landscape when deploying
    it on Kubernetes?
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么我们在Kubernetes上部署时从微服务领域中移除了Eureka服务器？
- en: What did we replace the Eureka server with and how was the source code of the
    microservices affected by this change?
  id: totrans-479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们用什么替换了Eureka服务器，以及这个变化如何影响了微服务的源代码？
- en: What’s the purpose of liveness and readiness probes?
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存活性和就绪性探测的目的是什么？
- en: How is Spring Boot’s mechanism for graceful shutdown useful?
  id: totrans-481
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Spring Boot的优雅关闭机制有什么用？
- en: What is the purpose of the following Helm template directives?
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下Helm模板指令的目的是什么？
- en: '[PRE82]'
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Why would the following named Helm template fail?
  id: totrans-484
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么以下命名的Helm模板会失败？
- en: '[PRE83]'
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: Why would the following manifests not work together?
  id: totrans-486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么以下清单不能一起工作？
- en: '[PRE84]'
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
