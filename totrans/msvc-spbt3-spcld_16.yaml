- en: '16'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying Our Microservices to Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will deploy the microservices in this book to Kubernetes.
    To bundle and configure the microservices for Deployments in different runtime
    environments, **Helm**, a package manager for Kubernetes, will be used. Before
    doing that, we need to review how Service discovery is used. Since Kubernetes
    comes with built-in support for Service discovery, it seems unnecessary to deploy
    Netflix Eureka for that purpose. Finally, we will also try out some Spring Boot
    features that facilitate the Deployment of microservices in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Replacing Netflix Eureka with Kubernetes Service objects and `kube-proxy` for
    Service discovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing how Kubernetes will be used
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Spring Boot’s support for graceful shutdown and probes for liveness and
    readiness
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Helm to package, configure, and deploy the microservices in different
    environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Verifying the Deployments with the test script, `test-em-all.bash`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For instructions on how to install the tools used in this book and how to access
    the source code for this book, see:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 21*, *Installation Instructions for macOS*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 22*, *Installation Instructions for Microsoft Windows with WSL 2 and
    Ubuntu*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code examples in this chapter all come from the source code in `$BOOK_HOME/Chapter16`.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to view the changes applied to the source code in this chapter,
    that is, see what it took to deploy the microservices on Kubernetes, you can compare
    this source code with that in *Chapter 15*, *Introduction to Kubernetes*. You
    can use your favorite `diff` tool and compare the two folders, `$BOOK_HOME/Chapter15`
    and `$BOOK_HOME/Chapter16`.
  prefs: []
  type: TYPE_NORMAL
- en: Replacing Netflix Eureka with Kubernetes Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As shown in the previous chapter, *Chapter 15*, *Introduction to Kubernetes*,
    Kubernetes comes with a built-in discovery **service** based on Kubernetes Service
    objects and the `kube-proxy` runtime component. This makes it unnecessary to deploy
    a separate discovery Service such as Netflix Eureka, which we used in the previous
    chapters.
  prefs: []
  type: TYPE_NORMAL
- en: An advantage of using the Kubernetes discovery Service is that it doesn’t require
    a client library such as Spring Cloud LoadBalancer, which we have used together
    with Netflix Eureka. This makes the Kubernetes discovery Service easy to use,
    independent of which language or framework a microservice is based on.
  prefs: []
  type: TYPE_NORMAL
- en: A drawback of using the Kubernetes discovery Service is that it only works in
    a Kubernetes environment. However, since the discovery Service is based on `kube-proxy`,
    which accepts requests to the DNS name or IP address of a Service object, it should
    be fairly simple to replace it with a similar discovery Service, for example,
    one that comes bundled with another container orchestrator.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize this, we will remove the discovery server based on Netflix Eureka
    from our microservice landscape, as illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B19825_16_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.1: Replacing Netflix Eureka with the Kubernetes built-in discovery
    Service'
  prefs: []
  type: TYPE_NORMAL
- en: 'To replace the discovery server based on Netflix Eureka with the built-in discovery
    Service in Kubernetes, we need to make some changes in our build and configuration
    files. We do not need to make any changes in the Java source code, except for
    some of the test classes, where a property is no longer required and, therefore,
    will be removed. The following changes have been applied to the source code:'
  prefs: []
  type: TYPE_NORMAL
- en: Netflix Eureka and the Spring Cloud LoadBalancer-specific configuration (client
    and server) have been removed from the configuration repository, `config-repo`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Routing rules in the gateway Service to the Eureka server have been removed
    from the `config-repo/gateway.yml` file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Eureka server project, in the `spring-cloud/eureka-server` folder, has been
    removed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Eureka server has been removed from the Docker Compose files and the `settings.gradle`
    Gradle file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dependency on `spring-cloud-starter-netflix-eureka-client` has been removed
    in all of Eureka’s client build files, `build.gradle`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The property setting `eureka.client.enabled=false` has been removed from all
    integration tests of former Eureka clients.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The gateway Service no longer uses routing based on the client-side load balancer
    in Spring Cloud LoadBalancer, using the `lb` protocol. For example, the `lb://product-composite`
    routing destination has been replaced with `http://product-composite` in the `config-repo/gateway.yml`
    file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The HTTP port used by the microservices and the authorization server has been
    changed from port `8080` (`9999` in the case of the authorization server) to the
    default HTTP port, `80`. This has been configured in `config-repo` for each affected
    Service, like so:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'None of the HTTP addresses that we will use are affected by the replacement
    of Netflix Eureka with Kubernetes Services. For example, addresses used by the
    composite Service are unaffected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This is because we changed the HTTP port used by the microservices and the authorization
    server to the default HTTP port, `80`, as described previously.
  prefs: []
  type: TYPE_NORMAL
- en: Using Docker Compose still works, even though Netflix Eureka has been removed.
    The main reason that this works is that the container names in the Docker Compose
    files are the same as the corresponding Service names used in Kubernetes, meaning
    that the microservices’ DNS names are the same in both environments. This can
    be used to run functional tests of the microservices without deploying them to
    Kubernetes, for example, running `test-em-all.bash` together with Docker Desktop
    in the same way we did in the previous chapters. Removing Netflix Eureka, however,
    means that we no longer have a discovery Service in place when using plain Docker
    and Docker Compose. Therefore, scaling microservices will only work when deploying
    to Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: In *Chapter 17*, *Implementing Kubernetes Features to Simplify the System Landscape*,
    in the section *Verifying that microservices work without Kubernetes*, we will
    discuss the importance of avoiding the source code of the microservices being
    dependent on the Kubernetes platform, thus avoiding vendor lock-in. We will also
    use the test script `test-em-all.bash`, together with Docker Compose, to verify
    that the microservices don’t require Kubernetes from a functional perspective.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve familiarized ourselves with how Netflix Eureka will be replaced
    with Kubernetes Services, let’s introduce the other Kubernetes objects we will
    use.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing how Kubernetes will be used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Later on in the chapter, we will see in detail how various Kubernetes objects
    are used to deploy the microservices and the resource managers they depend on,
    like databases and queue managers. Before delving into all the details, let’s
    get an overview of the Kubernetes objects that will be used:'
  prefs: []
  type: TYPE_NORMAL
- en: For each microservice, database, and queue manager that will be deployed in
    Kubernetes, one Deployment object and one Service object will be created. For
    all components, except for the edge server named `gateway`, the Service object
    will be of type `ClusterIP`. For the gateway, the Service object will be of type
    `NodePort`, accepting external HTTPS requests on port `30433`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The config server will use a ConfigMap, containing the configuration files in
    the `config-repo`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To hold credentials for the config server and its clients, two Secrets will
    be created: one for the config server and one for its clients.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we’ve seen what Kubernetes objects will be created, let’s learn about
    the Spring Boot features that facilitate deployment to Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Using Spring Boot’s support for graceful shutdown and probes for liveness and
    readiness
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Back in Spring Boot v2.3, a couple of useful features were added to support
    Deployments to Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Graceful shutdown:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whenever a microservice instance needs to be stopped, for example, in a rolling
    upgrade scenario, there is a risk that active requests are affected when the instance
    is stopped. To minimize this risk, Spring Boot has added support for graceful
    shutdown. When applying graceful shutdown, a microservice stops accepting new
    requests and waits for a configurable time for active requests to complete before
    it shuts down the application. Requests that take a longer time to complete than
    the shutdown wait period will be aborted. These requests will be seen as exceptional
    cases that a shutdown procedure can’t wait for before it stops the application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Graceful shutdown has been enabled with a waiting period of 10 seconds for
    all microservices by adding the following to the common file `application.yml`
    in the `config-repo` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: For more information, see [https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#features.graceful-shutdown](https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#features.graceful-shutdown).
  prefs: []
  type: TYPE_NORMAL
- en: '**Liveness and readiness probes:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As described in *Chapter 15*, *Introduction to Kubernetes*, proper implementations
    of liveness and readiness probes are essential for Kubernetes to be able to manage
    our Pods.
  prefs: []
  type: TYPE_NORMAL
- en: To briefly recap, a liveness probe tells Kubernetes if a Pod needs to be replaced,
    and a readiness probe tells Kubernetes if its Pod is ready to accept requests.
    To simplify this work, Spring Boot has added support to implement liveness and
    readiness probes. The probes are exposed on the URLs `/actuator/health/liveness`
    and `/actuator/health/readiness` respectively. They can either be declared by
    configuration or implementation in source code, if increased control is required
    compared to what configuration gives. When declaring the probes by configuration,
    a **health group** can be declared for each probe, specifying what existing health
    indicators it should include. For example, a readiness probe should report `DOWN`
    if a microservice can’t access its MongoDB database. In this case, the health
    group for the readiness probe should include the `mongo` health indicator. For
    available health indicators, see [https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#actuator.endpoints.health.auto-configured-health-indicators](https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#actuator.endpoints.health.auto-configured-health-indicators).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will declare the probes using the following configuration
    in the common file `application.yml` in the `config-repo` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The first line of the configuration enables the liveness and readiness probes.
    The second line declares that readiness probes will include health indicators
    for RabbitMQ, MongoDB, and SQL databases, if available. For the liveness probe,
    we don’t need to add any extra health indicators. For the scope of this chapter,
    it is sufficient that the liveness probe reports `UP` given that the Spring Boot
    application is up and running.
  prefs: []
  type: TYPE_NORMAL
- en: For more information, see [https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#actuator.endpoints.kubernetes-probes](https://docs.spring.io/spring-boot/docs/3.0.4/reference/htmlsingle/#actuator.endpoints.kubernetes-probes).
  prefs: []
  type: TYPE_NORMAL
- en: We will try out these features once we have deployed our microservices in Kubernetes.
    Before we do that, we need to learn about Helm and see how it helps us bundle,
    configure, and deploy microservices to Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Helm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As described above, deploying a microservice to Kubernetes requires writing
    manifest files that declare the desired state of a Deployment object and a Service
    object. If we also need to add some configuration for the microservices, manifests
    for ConfigMaps and Secrets must be added. The approach of declaring a desired
    state and handing over the responsibility to Kubernetes to ensure that the actual
    state is always as close as possible to the desired state is very useful.
  prefs: []
  type: TYPE_NORMAL
- en: However, writing and maintaining these manifest files can become a significant
    maintenance overhead. The files will contain a lot of boilerplate code, meaning
    duplicated manifests that will look the same for all microservices. It is also
    cumbersome to handle environment-specific settings without duplicating the whole
    set of manifest files, even though only a fraction of the content needs to be
    updated.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of a few microservices that will only be deployed to a few environments,
    like a test, QA, and production environment, this might not be a major issue to
    handle.
  prefs: []
  type: TYPE_NORMAL
- en: When the number of microservices grows to tens and hundreds and it must be possible
    to deploy different groups of microservices to different test, QA, and production
    environments, this quickly becomes an unmanageable maintenance problem.
  prefs: []
  type: TYPE_NORMAL
- en: To address these shortcomings, we will use Helm ([https://helm.sh](https://helm.sh)),
    an open source-based package manager for Kubernetes. With Helm comes a templating
    language that can be used to extract settings specific to a microservice or an
    environment from generic definitions of the various Kubernetes objects used.
  prefs: []
  type: TYPE_NORMAL
- en: For smaller system landscapes with only a few Deployment objects, simpler templating
    tools can be sufficient. For example, if you are already familiar with **Ansible**
    and its **Jinja2** templates, they can be used instead. Also, `kubectl` itself
    comes with built-in support for **Kustomize**, offering a template-free alternative
    to customize Kubernetes manifest files.
  prefs: []
  type: TYPE_NORMAL
- en: A package is known as a **chart** in Helm. A chart contains templates, default
    values for the templates, and optional dependencies on definitions in other charts.
    Each component that needs to be deployed, meaning the microservices and the resource
    managers they depend on like databases and queue managers, will have its own chart
    describing how to deploy it.
  prefs: []
  type: TYPE_NORMAL
- en: To extract boilerplate definitions from the components’ charts, a special type
    of chart, a **library chart**, will be used. A library chart doesn’t contain any
    deployable definitions but only templates expected to be used by other charts
    for Kubernetes manifests – in our case, for Deployment, Service, ConfigMap, and
    Secret objects.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, to be able to describe how to deploy all components into different
    types of environments, for example, for development and testing or staging and
    production, the concept of **parent charts** and **subcharts** will be used. We
    will define two types of environments, `dev-env` and `prod-env`. Each environment
    will be implemented as a parent chart that depends on different sets of subcharts,
    for example, the microservice charts. The environment charts will also provide
    environment-specific default values, such as for the requested number of Pods,
    Docker image versions, credentials, and resource requests and limits.
  prefs: []
  type: TYPE_NORMAL
- en: 'In summary, we will have one reusable library chart, named `common`; a set
    of microservice- and resource manager-specific charts, placed in the `components`
    folder; and two environment-specific parent charts, placed in the `environments`
    folder. The file structure looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The files can be found in the folder `$BOOK_HOME/Chapter16/kubernetes/helm`.
  prefs: []
  type: TYPE_NORMAL
- en: To share Helm charts with others, they can be published to a Helm **chart repository**.
    In this book we will not publish any charts, but in *Chapter 17*, *Implementing
    Kubernetes Features to Simplify the System Landscape*, we will install a component
    named **cert-manager** using a Helm chart from a chart repository.
  prefs: []
  type: TYPE_NORMAL
- en: Before we learn about how charts are constructed, let’s learn about the most
    frequently used Helm commands and how to run them.
  prefs: []
  type: TYPE_NORMAL
- en: Running Helm commands
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To make Helm do something for us, we will use its CLI tool, `helm`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the most frequently used Helm commands are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`create`: Used to create new charts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dependency update` (`dep up` for short): Resolves dependencies on other charts.
    Charts are placed in the `charts` folder and the file `Chart.lock` is updated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dependency build`: Rebuilds the dependencies based on the content in the file
    `Chart.lock`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`template`: Renders the definition files created by the templates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`install`: Installs a chart. This command can override the values supplied
    by a chart, either using the `--set` flag to override a single value or using
    the `--values` flag to supply its own `yaml` file with values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`install --Dry-run`: simulates a Deployment without performing it; it’s useful
    for verifying a Deployment before executing it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`list`: Lists installations in the current n amespace.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`upgrade`: Updates an existing installation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`uninstall`: Removes an installation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For full documentation of the commands that Helm provides, see [https://helm.sh/docs/helm/](https://helm.sh/docs/helm/).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s put these Helm commands in context and see what files a chart consists
    of.
  prefs: []
  type: TYPE_NORMAL
- en: Looking into a Helm chart
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A Helm chart has a predefined structure of files. We will use the following
    files:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Chart.yaml`, which contains general information about the chart and a list
    of other charts it might depend on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`templates`, a folder that contains the templates that will be used to deploy
    the chart.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`values.yaml`, which contains default values for the variables used by the
    templates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Chart.lock`, a file created by Helm when resolving the dependencies described
    in the `Chart.yaml` file. This information describes in more detail what dependencies
    are actually used. It is used by Helm to track the entire dependency tree, making
    it possible to recreate the dependency tree exactly as it looked the last time
    the chart worked.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`charts`, a folder that will contain the charts this chart depends on after
    Helm has resolved the dependencies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.helmignore`, an ignore file similar to `.gitignore`. It can be used to list
    files that should be excluded when building the chart.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now that we understand the structure inside a Helm chart, let’s learn about
    one of the core features of Helm: its template mechanism, and how to pass values
    to it.'
  prefs: []
  type: TYPE_NORMAL
- en: Helm templates and values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Helm templates are used to parameterize Kubernetes manifest files. Using templates,
    we no longer need to maintain long-winded Deployment manifests for each microservice.
    Instead, we can define a common template that contains placeholders for where
    microservice-specific values will be placed in the template, when a manifest is
    rendered for a specific microservice. Let’s see an example, extracted from `kubernetes/helm/common/templates/_deployment.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: It looks very similar to the Deployment manifest we saw in *Chapter 15*, *Introduction
    to Kubernetes*, with the exception of the use of the `{{ ... }}` constructs, used
    to insert microservice-specific values into the template. The construct `{{ include
    "common.fullname" . }}` is used to invoke other templates, as explained below.
    The other two constructs are used to insert values using one of the **built-in
    objects** in Helm.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most frequently used parts of the built-in objects are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Values`: Used to refer to values in the chart’s `values.yaml` file or values
    supplied when running a Helm command like `install`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Release`: Used to provide metadata regarding the current release that is installed.
    It contains fields like:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Name`: The name of the release'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Namespace`: The name of the namespace where the installation is performed'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Service`: The name of the installation Service, always returning `Helm`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Chart`: Used to access information from the `Chart.yaml` file. Examples of
    fields that can be useful for providing metadata for a Deployment are:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Name`: The name of the chart'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Version`: The chart’s version number'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Files`: Containing functions for accessing chart-specific files. In this chapter
    we will use the following two functions in the `Files` object:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Glob`: Returns files in a chart based on a **glob pattern**. For example,
    the pattern `"``config-repo/*"` will return all files found in the folder `config-repo`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AsConfig`: Returns the content of files as a YAML map appropriate for declaring
    values in a `ConfigMap`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Capabilities`: Can be used to find information regarding the capabilities
    of the Kubernetes cluster that the installation is performed on. For example,
    a template can use information in this object to adopt a manifest based on what
    API versions the actual Kubernetes cluster supports. We will not use this object
    in this chapter, but I think it is in our interest to be aware of it for more
    advanced use cases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For further details on built-in objects, see [https://helm.sh/docs/chart_template_guide/builtin_objects](https://helm.sh/docs/chart_template_guide/builtin_objects).
  prefs: []
  type: TYPE_NORMAL
- en: All objects are accessible in a tree where the `root` context, in most cases,
    can be addressed using the current scope, represented by a period, `.`, also known
    as the **dot**. From the examples above we can see the use of the dot, for example,
    in `.Values.replicaCount` and `.Chart.Name`, where we can see that the built-in
    objects `Values` and `Chart` are accessible directly under the current scope.
    In the `include` directive above, we can also see the dot being used as a parameter
    sent to the template named `common.fullname`, meaning the whole tree is sent to
    the template. Instead of sending the whole tree to a template, a sub-tree can
    be passed.
  prefs: []
  type: TYPE_NORMAL
- en: When using some of the Helm functions, the current scope will be changed and
    no longer point to the `root` context. We will, for example, meet the `range`
    function later on, which can be used to iterate through collections of values.
    If we need to access the `root` context inside the scope of a `range` function,
    we can use the predefined variable `$`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Helm templates also support the declaration of variables to reference other
    objects. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In this example, a variable, `name`, has been declared to hold the value of
    the Helm release that is currently being processed. We will see later on how variables
    are used in more advanced constructs.
  prefs: []
  type: TYPE_NORMAL
- en: If you recognize the format of using the `{{ ... }}` constructs from using `kubectl`,
    you are right. They are, in both cases, based on Go templates. For more information,
    see [https://golang.org/pkg/text/template/](https://golang.org/pkg/text/template/).
  prefs: []
  type: TYPE_NORMAL
- en: With the templating mechanism introduced, let’s learn about how the three types
    of charts are constructed. We will start with the most important chart, the `common`
    chart, explaining the `components` and `environments` charts after that.
  prefs: []
  type: TYPE_NORMAL
- en: The common library chart
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This chart contains reusable templates, also known as **named templates**,
    for the four types of Kubernetes manifests we will use in this chapter: `Deployment`,
    Service, `ConfigMap`, and `Secret`. The structure and content of the common chart
    are based on the output from a `helm create` command. Specifically, the template
    file `_helpers.tpl` has been retained to reuse best practices for naming conventions.
    It declares the following templates that encapsulate naming conventions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`common.name`: Based on the chart name.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`common.fullname`: Based on a combination of the name of the release and the
    chart. In this book, we will override this naming convention and simply using
    the name of the chart.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`common.chart`: Based on the chart name and version.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For details, see the implementation in the `_helpers.tpl` file.
  prefs: []
  type: TYPE_NORMAL
- en: Named templates, which will only be used by other templates and not used to
    create manifests themselves, must have a name that starts with an underscore,
    `_`. This is used to prevent Helm from trying to create manifests using them alone.
  prefs: []
  type: TYPE_NORMAL
- en: Since the named templates for the Kubernetes manifests mentioned previously
    contain the main part of the logic and, therefore, most of the complexity in the
    Helm charts, we will go through them one by one.
  prefs: []
  type: TYPE_NORMAL
- en: The ConfigMap template
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This template is designed to create ConfigMaps from files in the folder `config-repo`.
    Each ConfigMap will contain all non-sensitive configurations required by a specific
    Deployment. The Deployment manifest will map the content of the ConfigMap as a
    volume in its Pod template. This will result in Pods created by the Deployment
    being able to access the configuration as files in their local filesystem. See
    the section *The Deployment template* below for details. The `config-repo` folder
    needs to be placed in the charts that use the common chart.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, this template will be used only by the config server chart
    in the `components` folder. In the next chapter, all other microservices will
    also use this template to define their own ConfigMaps, since the config server
    will be removed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The templates file is named `_configmap_from_file.yaml`, and it looks like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'An explanation of the template is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The first line, `{{- define "common.configmap_from_file " -}}`, is used to declare
    the name of the reusable template. The scope of the template ends with a matching
    `{{- end -}}`, the last line in this example.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To set the name of the ConfigMap, the template `common.fullname` from the file
    `_helpers.tpl` is used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, a number of labels are defined to make it easier to identify the ConfigMap
    later on. Again, templates from the `_helpers.tpl` file are used to set the `name`
    and specify the `chart` used. To mark that this Service has been created using
    Helm, the label `app.kubernetes.io/managed-by` is set to the value for the field
    `.Release.Service`. From the earlier description of the `Release` object, we know
    that it always returns the value `Helm`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next comes the core part of the ConfigMap, its `data` section. To specify the
    actual configuration in the ConfigMap, the `Glob` function in the `Files` object
    is used to get all files in the folder `config-repo`. Next, the function `AsConfig`
    is applied to the content in the files to form a proper YAML map. The result is
    piped to the `indent` function, which ensures a proper indentation is rendered,
    in this case, using two characters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The hyphens in `{{-` and `-}}` are used to remove preceding and trailing whitespace
    remaining after the processing of the directive inside the curly braces.
  prefs: []
  type: TYPE_NORMAL
- en: Example of using the ConfigMap template
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this chapter, only the config server will use a ConfigMap. See the section
    on *The component charts* for a description of how this template is used.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the ConfigMap that will be created by Helm using this template, run
    the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect output from the `helm template` command like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The `data` field contains the content of all files in the `config-repo` folder.
  prefs: []
  type: TYPE_NORMAL
- en: The Secrets template
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This template is designed to create Secrets defined by values like credentials
    provided by the environments `dev-env` and `prod-env`. The Secrets will be mapped
    as environment variables in the Pods. See the section *The Deployment template*
    below for details. Since an environment must be able to define multiple Secrets,
    this template is designed to create multiple Secret manifests using the `range`
    function in Helm. The template file is named `_secrets.yaml`, and it looks like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'An explanation of the template is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'After the declaration of the template in line 1 comes the use of the `range`
    function in line 2\. The function assumes that the field `.Values.secrets` contains
    a map of Secret names and a map of the Secret’s key/value pairs. A declaration
    of the `Secrets` field in one of the environment’s `values.yaml` files will look
    like this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This definition will render two Secrets, named `a-secret` and `another-secret`.
    The `range` function assigns the current Secret name and its map to the variables
    `$secretName` and `$secretMap`.
  prefs: []
  type: TYPE_NORMAL
- en: Since the `range` function changes the current scope, we can no longer use the
    dot notation to pass the `root` context to the `common.chart` template. Instead,
    the variable `$` has to be used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the `data` section of the manifest, a second `range` function is applied
    a second time to traverse the current Secret’s key/value pairs. Each key/value
    pair is assigned by the `range` function to the variables `$key` and `$val`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the Secret’s key/value pairs are defined as a map entry in the `data`
    section. The value in the `$val` variable is piped to the `b64enc` function to
    get it properly **Base64**-encoded as required by a Secret manifest.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `---` is used to separate the rendered Secret manifests from each other
    so that they are processed as separate YAML documents.
  prefs: []
  type: TYPE_NORMAL
- en: Example of using the Secrets template
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Secrets are only defined by the environment charts `dev-env` and `prod-env`.
    They are used to create environment-specific credentials. See the section on *The
    environment charts* for a description of how this template is used.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the Secrets that will be created for the `dev-env` by Helm using this
    template, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect output from the `helm template` command like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The Service template
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Service template introduces support for overriding default values from the
    common chart, with values specific to the charts that use the common chart. The
    common chart will, for example, provide default values for the Service `type`
    and what `ports` the Service will expose. This will be useful for most of the
    microservices, but some of them need to be able to override these default values
    in their own `values.yaml` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The template file is named `_service.yaml` and starts like the other named
    templates, with the declaration of its name, followed by the implementation of
    the override mechanism. It looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This construct can be explained in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: When the `_service.yaml` template is used by a microservice to render its Service
    manifest, the values from the microservice `values.yaml` file will be available
    in the `.Values` object, and the common chart’s values will be available under
    the field `.Values.common`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, the variable `$common` will refer to a dictionary, created by the `dict`
    function, with one key, `Values`, and its value will be the default values from
    the common chart. These values are taken from the `common` key in the `.Values`
    object.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `$noCommon` variable will hold all values from the microservice except values
    under the `common` key, specified using the `omit` function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `$overrides` variable will refer to a dictionary, also with one key, `Values`,
    but its value will be the values from the microservice’s values, except the `common`
    values. It gets the values from the `$noCommon` variable declared on the previous
    line.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `$noValues` variable will hold all other built-in objects, except for the
    `Values` object.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, here is where the override will happen; the `merge` function will create
    one dictionary based on the dictionaries referred to by the variables `$noValues`,
    `$overrides`, and `$common`. In this case, values found in the `$overrides` dictionary
    will take precedence over values in the `$common` dictionary, thereby overriding
    its values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the `with` function will change the scope for the template code that
    follows until its `{{- end -}}` definition is reached. So, the current scope,
    `.`, will now refer to the merged dictionary.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s take an example to see how this will work out. The `common` chart’s `values.yaml`
    file contains the following default settings for the Service type and exposed
    ports:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This setting will render Service objects that are of type `ClusterIP`. The Service
    objects will expose port `80` and forward requests to the Pods on their port,
    named `http`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The gateway Service needs to expose a `NodePort` and use other port settings.
    To override the above default values, it declares the following in its chart’s
    `values.yaml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The gateway’s `values.yaml` file can be found in the folder `$BOOK_HOME/Chapter16/kubernetes/helm/components/gateway/values.yaml`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of the Service template file looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'An explanation of the template is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The metadata fields for `name` and `labels` are defined in the same way as already
    seen for the previous templates.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `type` of the Service is set by the field `.Values.service.type`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `ports` exposed by the Service are specified using the field `.Values.service.ports`.
    The built-in function `toYaml` is used to format its value as `yaml`, and the
    result is piped to the `indent` function, which ensures a proper indentation is
    rendered, in this case, `4` characters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the Pod `selector` is defined. It is based on the label `app.kubernetes.io/name`
    and is given the name using the template `common.name`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Example of using the Service template
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Service template is used by each component to create its Service manifest.
    As described above, the core microservices reuse the configuration in the common
    chart’s `values.yaml` file, while the other components override these values in
    their own `values.yaml` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the Service manifest generated for a core component, for the `product`
    microservice, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect output from the `helm template` command like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'To see the Service manifest generated for a component that overrides the settings
    in the common chart, for the `gateway` component, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect output from the `helm template` command like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The Deployment template
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, we have the template for rendering Deployment manifests. This is the
    most complex template, since it must handle many parts of the Deployment manifest
    optionally. Different components will use different parts of a Deployment manifest.
    The common chart’s `values.yaml` file contains default values for these settings
    that are applicable to most of the components, minimizing the need to override
    these settings in each component’s own chart’s `values.yaml` file. The following
    parts of the Deployment manifest are optional for use by the components:'
  prefs: []
  type: TYPE_NORMAL
- en: Arguments given to the container when it starts up
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Environment variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Environment variables from Secrets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The liveness probe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The readiness probe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A ConfigMap and a corresponding volume
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The template file is named `_deployment.yaml`, and its first lines look very
    similar to the Service template, utilizing the same type of override mechanism:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: For an explanation of this part of the template, see the description of the
    Service template above.
  prefs: []
  type: TYPE_NORMAL
- en: 'When it comes to the `spec` part of the manifest, it starts with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we can see how the core parts of the spec are defined: the requested number
    of `replicas`, the `selector` for the Pods, and the `template` used to create
    new Pods. The template defines `labels` that match the selector and the `name`,
    Docker `image`, and `imagePullPolicy` to use when starting a container.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next comes the various optional parts of the manifest, as described above:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: For the environment variables and Secrets that are mapped to environment variables,
    the `range` function is used in the same way the `secrets` template uses it. The
    environment variables can either be specified on a component or environment level,
    depending on their use case. Secrets are always specified by an environment chart.
    See the following sections regarding the component and environment charts.
  prefs: []
  type: TYPE_NORMAL
- en: 'The manifest is concluded by the declaration of the `ports` the container exposes,
    `resource` requests and limits, and finally, the optional declaration of a ConfigMap
    and a corresponding volume to map the files in the ConfigMap to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'From the common chart’s `values.yaml` file we can find some default values
    of interest, for example, how default values for the liveness and readiness probes
    are defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'From these declarations, we can see that:'
  prefs: []
  type: TYPE_NORMAL
- en: The probes are by default disabled, since not all Deployments use probes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The probes are based on HTTP `GET` requests sent to the endpoints exposed by
    Spring Boot, as described in the section *Using Spring Boot’s support for graceful
    shutdown and probes for liveness and readiness* above.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As long as the endpoint responds with a `2xx` or a `3xx` response code, the
    probe is considered to be successful.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The probes can be configured using the following parameters:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`initialDelaySeconds` specifies how long Kubernetes waits to probe a container
    after it’s started up.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`periodSeconds` specifies the time between probe requests sent by Kubernetes.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeoutSeconds` specifies how long Kubernetes waits on a response before it
    treats the probe as failed.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`failureThreshold` specifies how many failed attempts Kubernetes makes before
    giving up. In the case of a liveness probe, this means restarting the Pod. In
    the case of a readiness probe, it means that Kubernetes will not send any more
    requests to the container until the readiness probes are successful again.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`successThreshold` specifies the number of successful attempts that are required
    for a probe to be considered successful again after a failure. This only applies
    to readiness probes, since it must be set to `1` if specified for liveness probes.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding optimal settings for the probes can be challenging, that is, finding
    a proper balance between getting a swift reaction from Kubernetes when the availability
    of a Pod changes and not overloading the Pods with probe requests.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, configuring a liveness probe with values that are too low can
    result in Kubernetes restarting Pods that don’t need to be restarted; they just
    need some extra time to start up. Starting a large number of Pods at the same
    time, also resulting in extra-long startup times, can similarly result in a lot
    of unnecessary restarts.
  prefs: []
  type: TYPE_NORMAL
- en: Setting the configuration values too high on the probes (except for the `successThreshold`
    value) makes Kubernetes react more slowly, which can be annoying in a development
    environment. Proper values also depend on the available hardware, which affects
    the startup times for the Pods. For the scope of this book, `failureThreshold`
    for the liveness probes is set to a high value, `20`, to avoid unnecessary restarts
    on computers with limited hardware resources.
  prefs: []
  type: TYPE_NORMAL
- en: Example of using the Deployment template
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Deployment template is used by each component to create its Deployment manifest.
    The core microservices reuse most of the configuration in the common chart’s `values.yaml`
    file, minimizing the need for component-specific configuration, while the other
    components override more of these values in their own `values.yaml` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the Deployment manifest generated for a core component, run the following
    commands for the `product` microservice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'To see the Deployment manifest generated for a component that overrides the
    settings in the common chart, run the following commands for the MongoDB component:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect output from the `helm template` command like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This concludes the walkthrough of the reusable named templates in the common
    chart. The files can be found in the folder `$BOOK_HOME/Chapter16/kubernetes/helm/common`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s see how the component-specific charts are defined.
  prefs: []
  type: TYPE_NORMAL
- en: The component charts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The charts for the microservices and the resource managers are stored in the
    `components` folder, and they all share the same file structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Chart.yaml` expresses a dependency on the `common` library chart.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `template` folder contains two templates, `deployment.yaml` and `Service.yaml`.
    Both templates apply the corresponding named template from the common chart. For
    example, the `Service.yaml` template looks like this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `values.yaml` file contains settings specific to the microservice. For
    example, the `values` file for the `auth-server` chart looks like this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `auth-server` only needs to declare its name, Docker image, Spring profile,
    and that it wants to use the default configuration of the liveness and readiness
    probes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The config server differs from the other charts in that it uses a ConfigMap
    to store the `config-repo` containing the configuration files for all the other
    microservices. In its `template` folder, it defines a template for a ConfigMap
    that is based on the named template in the common chart for ConfigMaps that we
    have already been introduced to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The template expects to find the property files in the charts folder, `config-repo`.
    To avoid duplicating the `config-repo` from `$BOOK_HOME/Chapter16/config-repo`,
    a **soft link**, also known as a **symbolic link**, has been created with the
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Since Git preserves soft links, you don’t need to recreate the soft link – the
    `git clone` command makes it for you!
  prefs: []
  type: TYPE_NORMAL
- en: As already mentioned in the walkthrough of the common chart, the gateway Service
    differs from the other microservices, since it needs to expose a Service of type
    `NodePort`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides the charts for the microservices, the `components` folder also contains
    charts for the databases, message broker, and Zipkin server we use. They are structured
    in the same way as the microservices. Since the common templates have been designed
    to streamline the charts for the microservices, the other charts need to override
    more default values in `values.yaml` files compared to the microservices. For
    more details, look at the `values.yaml` files in the following folders: `mongodb`,
    `mysql`, `rabbitmq`, and `zipkin-server`.'
  prefs: []
  type: TYPE_NORMAL
- en: The environment charts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, the `dev-env` and `prod-env` charts in the `environments` folder tie
    everything together to complete installation packages for a typical development/test
    or staging/production environment. Their `Charts.yaml` file contains dependencies
    on both the `common` chart and the charts in the `components` folder, and the
    `template` folder contains a `secrets.yaml` template to create environment-specific
    credentials as Secrets. It is based on the named template for Secrets from the
    common chart and looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Looking at the `dev-env` chart’s `values.yaml` file, we can find the following
    Secret values defined for the Secret `config-server-secrets`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the Secret `config-server-secrets` containing three Secret
    values, all Base64-encoded. Its manifest will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Note that this `values.yaml` file contains sensitive information, for example,
    the encrypt key used by the config server and the password used to access the
    config server. This file must be stored securely. An alternative, if it is inappropriate
    to store this file securely, is to remove the sensitive information from this
    file and supply it when the `helm install` command is executed.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use the Secret in the Deployment manifest for the config server, the following
    is defined in the `dev-env` chart’s `values.yaml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: This will be used by the Deployment template described above to add the Secret
    as environment variables in the Deployment manifest for the config server.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `prod-env` chart overrides more values than the `dev-env` chart. For example,
    the `values.yaml` file in the `prod-env` chart specifies that an extra Spring
    profile, `prod`, should be used and what version to use for the Docker images.
    This looks like the following for the `product` microservice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: With this introduction to what the various types of charts contain, let’s move
    on and use them together with the Helm commands we learned about to deploy our
    microservices in Kubernetes!
  prefs: []
  type: TYPE_NORMAL
- en: Deploying to Kubernetes for development and test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will deploy the microservices in an environment to be used
    for development and test activities, for example, system integration tests. This
    type of environment is used primarily for functional tests and is, therefore,
    configured to use minimal system resources and the latest available versions of
    the microservices’ Docker images.
  prefs: []
  type: TYPE_NORMAL
- en: To be able to run functional tests, we will deploy the microservices together
    with the resource managers they require in the same Namespace, which we will call
    `hands-on`. This makes it easy to set up a test environment and also to remove
    it once we are done with it. We can simply delete the Namespace to get rid of
    all resources used by the test environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'This Deployment scenario is illustrated by the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B19825_16_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.2: Resource managers deployed in the same Kubernetes namespace as
    the microservices in the dev environment'
  prefs: []
  type: TYPE_NORMAL
- en: Before we can deploy the system landscape, we need to build our Docker images
    and resolve the dependencies for our Helm charts.
  prefs: []
  type: TYPE_NORMAL
- en: Building Docker images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Normally, we have to push images to a Docker registry and configure Kubernetes
    to pull images from the registry. In our case, where we have a local single node
    cluster, we can shortcut this process by pointing our Docker client to the Docker
    engine in Minikube and then running the `docker-compose build` command. This will
    result in the Docker images being immediately available to Kubernetes. For development,
    we will use `latest` as the Docker image version for the microservices.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can build Docker images from the source as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: The `eval $(minikube docker-env)` command directs the local Docker client to
    communicate with the Docker engine in Minikube.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `docker-compose.yml` file has been updated to specify a name for the Docker
    images it builds. For example, for the `product` Service, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '`latest` is the default tag for a Docker image name, so it is not specified.'
  prefs: []
  type: TYPE_NORMAL
- en: With the Docker images built, it’s time to build the Helm charts.
  prefs: []
  type: TYPE_NORMAL
- en: Resolving Helm chart dependencies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we update the dependencies in the `components` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we update the dependencies in the `environments` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we verify that the dependencies for the `dev-env` folder look good:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect the command to respond with:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19825_16_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.3: Helm chart dependencies resolved'
  prefs: []
  type: TYPE_NORMAL
- en: With both Docker images built and Helm dependencies resolved, we can start deploying
    to Kubernetes!
  prefs: []
  type: TYPE_NORMAL
- en: Deploying to Kubernetes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A deploy to Kubernetes means creating or updating Kubernetes objects. We will
    use Helm to perform the Deployment, per the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To avoid a slow Deployment process due to Kubernetes downloading Docker images
    (potentially causing the liveness probes we described previously to restart our
    Pods), run the following `docker pull` commands to download the images in advance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Before using the Helm charts, render the templates using the `helm template`
    command to see what the manifests will look like:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that no interaction was performed with the Kubernetes cluster, so cluster
    information will be faked, and no tests are run to verify whether the rendered
    manifest will be accepted by the cluster.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To also verify that the Kubernetes cluster will actually accept the rendered
    manifest, a **dry run** of the installation can be performed by passing `–-dry-run`
    to the `helm install` command. Passing the `--debug` flag will also show which
    user-supplied and calculated values Helm will use when rendering the manifests.
    Run the following command to perform a dry run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To initiate the Deployment of the complete system landscape, including creating
    the Namespace, `hands-on`, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that here is where the Helm machinery kicks in. It will use the charts
    we walked through in the *Introducing Helm* section above to render and apply
    the Kubernetes manifests, resulting in the required Kubernetes objects for the
    Deployment being created.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set the newly created namespace as the default namespace for `kubectl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To see the Pods starting up, run the command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This command will continuously report when new Pods are **Running**, and if
    something goes wrong it will report the status, for example, **Error** and **CrashLoopBackOff**.
    After a while, you might see that errors are reported for the **gateway**, **product-composite**,
    and **zipkin-server** Pods. The reason for this is that they all depend on external
    resources that they require to be accessible during the startup. If not, they
    will crash. The gateway and product composite Service depend on the auth server,
    and the Zipkin server depends on access to RabbitMQ. Typically, they start up
    faster than the resources they rely on, causing this situation. However, Kubernetes
    will detect the crashed Pods, and they will restart. Once the resources are up
    and running, all Pods will start up and be reported as ready, showing **1/1**
    in the **READY** column. A sample output from the command looks like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![A picture containing text  Description automatically generated](img/B19825_16_04.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 16.4: Pods restarted until external dependencies are ready'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: After seeing some output like the above, interrupt the command with *Ctrl*+*C*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Wait for all the Pods in the Namespace to be ready with the command:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: Expect the command to respond with 11 log lines like `pod/... condition met`,
    where the three dots (`...`) are replaced with the name of the actual Pod that
    is reported to be ready.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To see the Docker images that are used, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The response should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Text, chat or text message  Description automatically generated](img/B19825_16_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.5: Docker images used in a test environment'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the Docker images have the version tag set to **latest** for the microservices.
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to test our Deployment! However, before we can do that, we
    need to go through changes that are required in the test script for use with Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the test script for use with Kubernetes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To verify the Deployment, we will, as usual, run the test script, `test-em-all.bash`.
    To work with Kubernetes, the circuit breaker tests have been slightly modified.
    The circuit breaker tests call the `actuator` endpoints on the `product-composite`
    Service to check their health state and get access to circuit breaker events.
    Since this endpoint isn’t exposed externally, the previous chapters used the `docker-compose
    exec` command to run a `curl` command inside of the `product-composite` Service
    to perform the tests.
  prefs: []
  type: TYPE_NORMAL
- en: Starting with this chapter, the test script can either use the `docker-compose
    exec` command or the corresponding `kubectl` command, `kubectl exec`, depending
    on whether we run the microservices using Docker Compose or Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: To know which command to use, a new parameter has been added to the script,
    `USE_K8S`. It defaults to `false`. For details, see the `testCircuitBreaker()`
    function in the test script.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the Deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When launching the test script, we have to give it the address of the host that
    runs Kubernetes, that is, our Minikube instance, and the `NodePort` where our
    gateway Service listens for external requests. The gateway is accessible using
    port `30443`. As mentioned in *Chapter 15*, since we use Minikube’s `docker` driver,
    the hostname is always `localhost`. Since the hostname is the same as when running
    tests with Docker Compose, we don’t have to specify it; only the port has to be
    specified, together with the `USE_K8S` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Start the tests with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'In the output from the script, we can see how the `NodePort` is used, but besides
    that, everything looks the same as when we used Docker Compose in the previous
    chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Text  Description automatically generated](img/B19825_16_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.6: Output from the automated tests of the system landscape'
  prefs: []
  type: TYPE_NORMAL
- en: With the system landscape validations performed, let’s see how we can test the
    new features in Spring Boot, graceful shutdown, and the probes for liveness and
    readiness.
  prefs: []
  type: TYPE_NORMAL
- en: Testing Spring Boot’s support for graceful shutdown and probes for liveness
    and readiness
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will test out the new Spring Boot features and see how they
    interact with other components in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by testing Spring Boot’s support for graceful shutdown, where the
    application during its shutdown phase will wait a configurable length of time
    for active requests to complete. Remember that no new requests are allowed during
    the shutdown phase.
  prefs: []
  type: TYPE_NORMAL
- en: To test the graceful shutdown mechanism, we will run a client that continuously
    sends requests to the composite Service. First, we will use it to send requests
    that take 5 seconds, a shorter amount of time than the shutdown wait period. The
    waiting period is configured to be 10 seconds. Next, we will use it to send requests
    that take a longer time, 15 seconds, to see how they are handled. As the test
    client, we will use **Siege**, a command-line-based-load test tool.
  prefs: []
  type: TYPE_NORMAL
- en: To be able to test run requests that take this long to complete, we need to
    temporarily increase the timeout in the `product-composite` Service. Otherwise,
    its circuit breaker will kick in and prevent us from running the long requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'To increase the timeout in the composite Service, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following under the `product-composite` section in the `values` file
    for the `dev-env`, `kubernetes/helm/environments/dev-env/values.yaml`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After the change, the configuration file should look like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As long as this setting is active, the circuit breaker tests in `test-em-all.bash`
    will no longer work, since they assume a timeout of 2 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: 'Update the Helm installation with Helm’s `upgrade` command, using the `--wait`
    flag to ensure that the update is completed when the command terminates:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now we can run the tests, proceeding with the following steps to test with
    requests that are shorter than the shutdown wait period:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Get an access token:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Ensure you got an access token by issuing the command `echo $ACCESS_TOKEN`.
    If it’s empty, you have to check the `curl` command above and the logs from the
    gateway and the auth server.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Make a test request and ask for a delay of 5 seconds using the `delay` query
    parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you get a normal response and the `time` command reports a 5-second response
    time, the config changes of the increased timeout worked!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use Siege to start requests that take 5 seconds to complete, with five concurrent
    users sending requests with a random delay between 0 and 2 seconds to spread out
    the requests slightly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Expect output from the tool for each completed request like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Watch log output from the `product` Service in a separate terminal window with
    the command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will now ask Kubernetes to restart the `product` Deployment. The restart
    will first start a new Pod before the old one is shut down, meaning that none
    of the requests sent by Siege should be affected by the restart. Of specific interest
    are the few requests that are processed by the old Pod when it starts to shut
    down. If the graceful shutdown works as expected, none of the active requests
    should fail. Perform the restart by running the following command in a separate
    window:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Ensure that there are only successful requests reported in the output from the
    load-test tool, Siege, reporting **200** **(OK).**
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the log output from the now-stopped `product` Pod, you should see that all
    requests were allowed to terminate gracefully before the application was stopped.
    Expect log output like the following, at the end of the log output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Text  Description automatically generated](img/B19825_16_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.7: Graceful shutdown where all requests are allowed to complete'
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, note the time between the two log messages (4 seconds, in this
    case), indicating that the shutdown procedure actually waited for the last request
    to complete.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s run the second test, with requests taking a longer time to complete
    than the shutdown wait period:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Restart Siege, requesting longer response times, above the wait limit of 10
    seconds. Start five concurrent users, asking for a 15-second response time and
    a random delay between the requests of 0–5 seconds. Stop Siege with *Ctrl*+*C*
    and run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Watch the log output from the `product` Pod with the command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Restart the `product` Deployment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Follow the log output from the `product` Pod. Once it has shut down, you should
    be able to see that not all requests were allowed to terminate gracefully before
    the application was stopped. Expect log output like the following, at the end
    of the log output:![Text  Description automatically generated](img/B19825_16_08.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 16.8: Graceful shutdown where some long-running requests are aborted'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The log message **Graceful shutdown aborted with one or more requests still
    active** indicates that at least one request was not allowed to complete before
    the application was stopped.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the output from the load-test tool, Siege, there should now appear one or
    a few failing requests reporting **500** **(Internal Server Error)** like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B19825_16_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.9: Long-running requests fail during shutdown'
  prefs: []
  type: TYPE_NORMAL
- en: This demonstrates how the shutdown procedure proceeds after the configured wait
    time and that the remaining long-running requests are aborted, as expected.
  prefs: []
  type: TYPE_NORMAL
- en: This completes the tests of Spring Boot’s graceful shutdown mechanism, which
    is clearly useful to avoid normal client requests being affected by Pods being
    stopped, for example, as a result of scaling down or a rolling upgrade being performed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Clean up after the tests:'
  prefs: []
  type: TYPE_NORMAL
- en: Stop the Siege load-test tool with *Ctrl*+*C*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Roll back the latest Helm release to get rid of the increased timeout:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `helm rollback` command is also useful to roll back a failed upgrade.
  prefs: []
  type: TYPE_NORMAL
- en: Also remove the increased timeout setting in the file `kubernetes/helm/environments/dev-env/values.yaml`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run `test-em-all.bash` to verify that the configuration is rolled back:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, let’s see what information the Spring Boot liveness and readiness
    probes report. We will use the `product` Service, but feel free to also try out
    the probes for other Services:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to get output from the `product` Service’s liveness
    probe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Expect it to respond with:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B19825_16_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.10: Response from a liveness probe'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to get output from the `product` Service’s readiness
    probe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Expect its response to be a bit more extensive:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer screen  Description automatically generated with
    medium confidence](img/B19825_16_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.11: Response from a readiness probe'
  prefs: []
  type: TYPE_NORMAL
- en: From the output above, we can confirm that the readiness of the `product` now
    depends on its access to both MongoDB and RabbitMQ. This is expected, since we
    configured the readiness health group to include health indicators for RabbitMQ,
    MongoDB, and SQL databases, if available. See the section *Using Spring Boot’s
    support for graceful shutdown and probes for liveness and readiness* to recap,
    if required.
  prefs: []
  type: TYPE_NORMAL
- en: Before we move on, let’s clean up what we have installed in the development
    environment. We can do this by simply deleting the namespace. Deleting the namespace
    will recursively delete the resources that exist in the namespace, including information
    regarding the Helm installation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Delete the namespace with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: If you just want to uninstall what the `helm install` command installed, you
    can run the command `helm uninstall hands-on-dev-env`.
  prefs: []
  type: TYPE_NORMAL
- en: With the development environment removed, we can move on and set up an environment
    targeting staging and production.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying to Kubernetes for staging and production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will deploy the microservices in an environment for staging
    and production usage. A staging environment is used to perform **quality assurance**
    (**QA**) and **user acceptance tests** (**UATs**) as the last step before taking
    a new release into production. To be able to verify that a new release not only
    meets functional requirements but also non-functional requirements, for example,
    in terms of performance, robustness, scalability, and resilience, a staging environment
    is configured to be as similar as possible to the production environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'When deploying to an environment for staging or production, there are a number
    of changes required compared to when deploying for development or tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resource managers should run outside of the Kubernetes cluster**: It is technically
    feasible to run databases and queue managers for production use on Kubernetes
    as stateful containers, using `StatefulSets` and `PersistentVolumes`. At the time
    of writing, I recommend against it, mainly because the support for stateful containers
    is relatively new and unproven in Kubernetes. Instead, I recommend using the existing
    database and queue manager Services on-premises or as managed Services in the
    cloud, leaving Kubernetes to do what it is best at: running stateless containers.
    For the scope of this book, to simulate a production environment, we will run
    MySQL, MongoDB, and RabbitMQ as plain Docker containers outside of Kubernetes,
    using the already existing Docker Compose files.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lockdown**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For security reasons, things like `actuator` endpoints and log levels need to
    be constrained in a production environment.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Externally exposed endpoints should also be reviewed from a security perspective.
    For example, access to the configuration server should probably be locked down
    in a production environment, but we will keep it exposed in this book for convenience.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker image tags must be specified to be able to track which versions of the
    microservices have been deployed.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scale up available resources**: To meet the requirements of both high availability
    and higher load, we need to run at least two Pods per Deployment. We might also
    need to increase the amount of memory and CPU that are allowed to be used per
    Pod. To avoid running out of memory in the Minikube instance, we will keep one
    Pod per Deployment but increase the maximum memory allowed in the production environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Set up a production-ready Kubernetes cluster**: This is outside the scope
    of this book, but, if feasible, I recommend using one of the managed Kubernetes
    Services provided by the leading cloud providers. For the scope of this book,
    we will deploy to our local Minikube instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is not meant to be an exhaustive list of things that have to be considered
    when setting up an environment for production, but it’s a good start.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our simulated production environment will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B19825_16_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.12: Resource managers deployed outside of Kubernetes'
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the source code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following changes have been applied to the source code to prepare for Deployment
    in an environment that’s used for staging and production:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A Spring profile named `prod` has been added to the configuration files in
    the `config-repo` configuration repository:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `prod` profiles, the following have been added:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'URLs to the resource managers that run as plain Docker containers:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: We use the `172.17.0.1` IP address to address the Docker engine in the Minikube
    instance. This is the default IP address for the Docker engine when creating it
    with Minikube, at least for Minikube up to version 1.18.
  prefs: []
  type: TYPE_NORMAL
- en: There is work ongoing to establish a standard DNS name for containers to use
    if they need to access the Docker host they run on, but at the time of writing,
    this work effort hasn’t been completed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Log levels have been set to warning or higher, that is, error or fatal. For
    example:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The only `actuator` endpoints that are exposed over HTTP are the `info` and
    `health` endpoints that are used by the liveness and readiness probes in Kubernetes,
    as well as the `circuitbreakerevents` endpoint that’s used by the test script,
    `test-em-all.bash`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In a real-world production environment, we should also have changed the `imagePullPolicy:
    Never` setting to `IfNotPresent`, to download Docker images from a Docker registry.
    However, since we will deploy the production setup to the Minikube instance where
    we manually build and tag the Docker images, we will not update this setting.'
  prefs: []
  type: TYPE_NORMAL
- en: Deploying to Kubernetes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To simulate the use of production-grade resource managers, MySQL, MongoDB,
    and RabbitMQ will run outside of Kubernetes using Docker Compose. We will start
    them up as we did in the previous chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need to tag the existing Docker images with `v1`, using the following
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'From here, the commands are very similar to how we deployed to the development
    environment:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Deploy using Helm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Wait for the Deployments to be up and running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To see the Docker images that are currently used in the production environment,
    run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The response should look something like the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Text  Description automatically generated](img/B19825_16_13.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 16.13: Docker images used in a production environment'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note the `v1` version of the Docker images!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Also note that the resource manager Pods for MySQL, MongoDB, and RabbitMQ are
    gone; these can be found with the `docker-compose ps` command.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the test script, `test-em-all.bash`, to verify the simulated production
    environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Expect the same type of output that we got when the test script was run against
    the development environment.
  prefs: []
  type: TYPE_NORMAL
- en: That completes the tests; let’s clean up so that the Kubernetes environment
    is ready for the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To delete the resources that we used, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Delete the namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Shut down the resource managers that run outside of Kubernetes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `eval $(minikube docker-env -u)` command directs the local Docker client
    to communicate with the local Docker engine and no longer communicate with the
    Docker engine in Minikube.
  prefs: []
  type: TYPE_NORMAL
- en: As already described earlier in this chapter, the `kubectl delete namespace`
    command will recursively delete all Kubernetes resources that existed in the namespace,
    and the `docker-compose down` command will stop MySQL, MongoDB, and RabbitMQ.
    With the production environment removed, we have reached the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to deploy the microservices in this book on
    Kubernetes using Helm. We have seen how Helm can be used to create reusable templates,
    minimizing the boilerplate code required to create the Kubernetes manifests. Reusable
    templates are stored in a common chart, while microservice-specific charts provide
    values specific to each microservice. At the top level, we have parent charts
    that describe how a development/test and stage/production environment should be
    deployed using the microservice charts, optionally together with charts for resource
    managers such as databases and queue managers.
  prefs: []
  type: TYPE_NORMAL
- en: We have also seen how we can benefit from using Spring Boot features to facilitate
    Deployments to Kubernetes. Spring Boot’s support for graceful shutdown can be
    used to allow active requests to complete before a Spring Boot-based microservice
    is stopped, for example, during a rolling upgrade. The support for liveness and
    readiness probes makes it easy to declare probes that are aware of the availability
    of external resources that a specific microservice depends on.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, to be able to deploy our microservices in Kubernetes, we had to replace
    Netflix Eureka with the built-in discovery Service in Kubernetes. Changing the
    discovery Service was done without any changes in the Java source code – all we
    had to do was apply changes to the build dependencies and some of the configuration.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see how we can further utilize Kubernetes to reduce
    the number of supporting Services we need to deploy in Kubernetes. Head over to
    the next chapter to see how we can eliminate the need for the configuration server
    and how our edge server can be replaced by a Kubernetes Ingress controller.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why did we remove the Eureka server from the microservice landscape when deploying
    it on Kubernetes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What did we replace the Eureka server with and how was the source code of the
    microservices affected by this change?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What’s the purpose of liveness and readiness probes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How is Spring Boot’s mechanism for graceful shutdown useful?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the purpose of the following Helm template directives?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Why would the following named Helm template fail?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Why would the following manifests not work together?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
