- en: Configuring Continuous Integration Using Jenkins
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will teach you how to integrate the pet store application
    with Jenkins, a **Continuous Integration** (**CI**) server. We will introduce
    CI concepts and how they can be implemented using Jenkins. We will configure a
    sample `pipeline` so that you can see how changes in application code are propagated
    to the deployed application.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start with the builds.
  prefs: []
  type: TYPE_NORMAL
- en: Learning OpenShift builds
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous chapters, we did some serious magic in order to build our application.
    To be able to run the builds, we executed the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In previous chapters, when we wanted to build our application, we invoked the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: After a lot of mysterious stuff had happened (as indicated by growing logs),
    we were able to see our application working. Now, it's time to explain what actually
    happened under the hood. Let's get to know OpenShift builds.
  prefs: []
  type: TYPE_NORMAL
- en: In general, an OpenShift build is an operation that transforms input parameters
    into a resulting object that is used to start an application. In most cases, the
    build will transform the source code into an image that will be later deployed
    on the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'The details of the build process operation depend on the build type (about
    which we will learn in a moment), but the general algorithm looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The build container starts from the build image
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sources from all the inputs are being injected into the container
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The build scripts are being run
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The output docker image is created
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The new concept that is being introduced here is the build container. Let's
    take a look at it a little bit closer. What actually is its purpose? The container
    in which you are building your application has to contain all the libraries, tools,
    and runtimes that are necessary to build and run your application. For example,
    if you use the WildFly AS builder image, it will contain Java, Maven, and WildFly
    runtimes among others. After the application is built, the same image is used
    as a base for the Docker image that will be deployed to OpenShift. Speaking precisely,
    your application will be added as another layer on top of the builder image, resulting
    in a runnable image with your application. The good news here is that although
    you can easily create an image yourself, in most cases those images will be created
    by the tool provider.
  prefs: []
  type: TYPE_NORMAL
- en: The input types can be provided from any resources, such as GitHub repositories,
    existing images, and Dockerfile config. All the sources that you provide are unpacked
    and merged together in the build directory, which will be processed by the builder
    image during the build. The option that we will use (and actually have used a
    few times already) in this book is GitHub repositories.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned previously, the precise way in which a build works depends on
    the build type. You will be able to define the type of build by specifying the
    build strategy. You can create images using Docker, Source-to-image of custom
    builds. The build type that is most interesting for us is the source-to-image
    build, which we will explain in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: There is also another type of build—`pipeline`. The `pipeline` build is connected
    to the Jenkins CI server and allows you to create a fully featured **Continuous
    Deployment** (**CD**) `pipeline`. We will describe this kind of build thoroughly
    in the second part of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Let's turn to the source-to-image build now.
  prefs: []
  type: TYPE_NORMAL
- en: Learning about the source-to-image build
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we mentioned, the source-to-image build needs a builder image and you have
    to provide it each time when you are configuring such a build. The builder images
    contain scripts that are responsible for assembling and running the application.
    The assembling scripts will be run in phase 3 of the build algorithm, and the
    run script will be used as the start command of the resulting Docker image. During
    the build, the layer that contains the runnable application will be added on top
    of the builder image, the run script will be set as the image starting command,
    and the resulting image will be committed.
  prefs: []
  type: TYPE_NORMAL
- en: 'We know the basics of source-to-image builds, so now we can explain what we
    did when deploying our application in the last chapters. Let''s start with the
    following command that we have invoked before running any builds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command is responsible for including a YAML object file into
    our cluster. The main object created by this script is the Docker build configuration.
    If we examine our cluster using command-line tools, we will find that the new
    build config is created:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/10100531-2072-4a6f-862c-8a199630347d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is the build config for our builder image. We may now examine builds in
    the Web Console. We will be able to see that the build based on `wildfyswarm-10-centos7`
    config has already been executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/27d3b465-578f-4500-8bfd-7f6939ed0253.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After the execution of the first command, the builder image was created and
    stored in the cluster. We can confirm this by navigating to Build | Images in
    the web console:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c4082b65-aeed-49d5-98c6-44dc07906834.png)'
  prefs: []
  type: TYPE_IMG
- en: As you will have noticed in the preceding screenshot, we have a new image, wildflyswarm-10-centos7,
    available in the cluster. An important thing to note here is that these images
    have been described as `ImageStreams`. What does that actually mean? `ImageStream`,
    as its name suggests, is an object that represents a stream of related objects.
    In our scenario, the `ImageStream` contains all images that are the result of
    the build of the builder image.
  prefs: []
  type: TYPE_NORMAL
- en: We created the BuildConfig for the builder image. The source for this image
    can change; if that happens, OpenShift will create a new version of this image
    and add it to the `ImageStream`.
  prefs: []
  type: TYPE_NORMAL
- en: The images in the stream can be tagged, and there is always the latest tag,
    which represents the latest image in the stream.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now examine the `new-app` command that we have used before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We are now ready to explain what the `new-app` syntax means. It has two parts
    separated by a tilde. The first one is the name of the builder-image stream. The
    second one is the GitHub repository from which the application will be built.
  prefs: []
  type: TYPE_NORMAL
- en: After we know the internals of the source-to-image build, we can run the build
    again and examine the build log.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we have to remove the `pricing-service` that we have deployed previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we are ready to execute the `new-app` command and use web console
    to inspect the log:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6d2191fd-ea40-40bd-8421-8d167f128521.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Oops! We have to download all the dependencies. This fact will result in build
    taking a substantial amount of time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ea37e902-8fa9-457e-b7e6-fcdaa2c0f279.png)'
  prefs: []
  type: TYPE_IMG
- en: This was just a first build. So, what will happen when we run the build for
    the second time?
  prefs: []
  type: TYPE_NORMAL
- en: You can use the web console to force the second build and inspect the log to
    verify that the dependencies are downloaded again.
  prefs: []
  type: TYPE_NORMAL
- en: This is a serious inconvenience, as it results in much longer build types. Can
    we do something about it? Yes, we can use incremental builds.
  prefs: []
  type: TYPE_NORMAL
- en: The incremental build is a feature of the source-to-image build, which extracts
    the build artifacts from the previously created image and uses them to build the
    next one.
  prefs: []
  type: TYPE_NORMAL
- en: Our builder image uses the Maven plugin to build a Swarm application, so the
    artifacts that are being downloaded are the Maven dependency JARs. Usually, different
    build tools and different types of the artifact will be used. As a result, the
    specific type of incremental build has to be implemented by the image provider.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of a Swarm builder image, the Maven artifacts are being extracted
    from the last image and placed in the Maven repo of the new one. As a result,
    artifacts that are being used many times have to be downloaded only once. Furthermore,
    in order to decrease the time spent downloading the JARs, you can use a Maven
    mirror.
  prefs: []
  type: TYPE_NORMAL
- en: OK. However, how can we turn the incremental build on? We have to edit the YAML
    of our build.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use the web console for that. We have to select the `pricing-service`
    build and navigate to Actions | Edit YAML in the top-right corner of the screen.
    The YAML has to be edited in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/42b76cfa-1eb5-4675-90ed-4105e381b73e.png)'
  prefs: []
  type: TYPE_IMG
- en: As you will have noticed in the preceding screenshot, we found the `sourceStrategy`
    section of the build config and added an incremental property with a value set
    to `true`. Let's run our build again to see what happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our new build log, we can see two optimistic lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6bc49bc1-f288-4f34-a5c4-08638921b56b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The first optimistic line is at the beginning where Maven informs us that the
    artifacts are being restored and the second one is at the end:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3aca6699-48da-44b9-92be-8621be134dbf.png)'
  prefs: []
  type: TYPE_IMG
- en: The build has taken only `16.347` seconds, not much longer than the standalone
    Maven build.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring environment variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we were deploying our services, we provided an environment variables script
    for catalog and `pricing-services` that needs to interact with our database. Processing
    this configuration file is also the responsibility of the source-to-image build.
    If a user wants to provide environment properties to the build, they have to create
    a `.s2i` directory in the root of the service's GitHub repository and create an
    environment file that will contain a list of key-value pairs.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let''s recall the configuration file for the `pricing-service`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Properties set in this file will be available as environment variables during
    the image build and during its execution.
  prefs: []
  type: TYPE_NORMAL
- en: The whole source-to-image algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After covering the specifics of the source-to-image build operation, let''s
    recap the steps in Swarm''s `s2i` build:'
  prefs: []
  type: TYPE_NORMAL
- en: The container on which the build will take place is created from the builder
    image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The sources of an application are injected into the container.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If incremental builds are enabled, the Maven artifacts will be restored from
    the previous build image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If provided, environment variables are set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The assembly script, provided by the image creator, is executed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The image is committed with the start command set to the run script provided
    by the image creator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A developer who will like to build their applications using the source-to-image
    build has to provide the name of the builder image and the source code of an application.
    A developer can enable the incremental build and provide environment variables.
  prefs: []
  type: TYPE_NORMAL
- en: Source-to-image summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have covered how the source-to-image build works internally, it's
    time to look at it from a wider perspective.
  prefs: []
  type: TYPE_NORMAL
- en: The source-to-image build is another tool provided by OpenShift that abstracts
    away the details of the Kubernetes cluster, providing a simple interface for the
    developer. The role of the developer is to provide the source code and the name
    of the image that will be used to build it. It is the responsibility of the image
    creator to assemble the Docker image that will be deployed on the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Again, this leads to the separation of concerns—the builder image provider is
    responsible for assembling source in an optimal way and the details of those optimizations
    don't have to be known by the developer.
  prefs: []
  type: TYPE_NORMAL
- en: The performance implications of builds resulting from the build architecture
    are as follows. The libraries that are needed to perform the build and create
    the runnable container are located in the builder image, which is created once
    (and later only updated) inside the cluster. The artifacts that are being downloaded
    during the build can be restored from previous builds if the incremental build
    is enabled. Owing to that, the dependencies of the application can be downloaded
    only once and later reused. This leads to a very fast build time. As you may remember,
    the build of our pricing service took only about 16 seconds, which is only a few
    seconds more than standalone Maven builds on a modern workstation.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, the reproducibility, which is one of the constant benefits of using
    Docker, holds for builder images also. All the builds are performed using exactly
    the same image. As a result, it is guaranteed that the build result will be the
    same on all of your environments.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, since builder images are just standard Docker containers and the
    explicit builder contract allows tool creators to write builder images easily,
    there is an wide variaty of Docker builder images that you can use. You, as a
    developer, already have access to a wide variety of builder images dedicated to
    number of development tools.
  prefs: []
  type: TYPE_NORMAL
- en: In the end, a source-to-image build tool is a tool that represents the core
    of the OpenShift philosophy. It provides a simple developer interface, which abstracts
    away the cluster internals, and under the hood it implements the an optimized
    build process.
  prefs: []
  type: TYPE_NORMAL
- en: The developer view
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Till now, we have explained in detail how the source-to-image build builds an
    image based on your code. The new-app command does not just create the build though.
    As you remember, after its execution, we were able to test the working application.
    Clearly, the build and image are not the only product of the command.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from the `BuildConfiguration`, the new-app command creates the `DeploymentConfiguration`
    (that we described in [Chapter 6](461aee71-984a-4158-addc-fc49341d3455.xhtml),
    *Deploying Applications on the Cloud with OpenShift*) and an `ImageStream` for
    our application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the created objects in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2bbdeae3-1b57-4028-979a-edb786780b6a.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, the objects related to the builder image are colored
    red, build-related objects are colored blue, and deployment-related objects are
    colored green. The build is triggered by a developer by pushing changes to GitHub.
    It results in the creation of the build objects. If the build is successful, the
    image is pushed to the image stream. This further triggers the deployment of the
    application, which, if successful, results in the creation of application services.
  prefs: []
  type: TYPE_NORMAL
- en: The important thing to note is that, in the simplest scenario, a developer may
    be responsible only for pushing the changes to the repository—in other words,
    programming and their changes will be propagated to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'That''s nice again, but, in some scenarios, we will like to have more than
    that: a full CD `pipeline` with integration tests, checking the deployed application,
    or staging the changes in different environments. As we hinted earlier, we can
    integrate an OpenShift cluster with Jenkins to use its full power to implement
    the CD `pipeline` for our services. Let''s learn how to do it.'
  prefs: []
  type: TYPE_NORMAL
- en: Pipeline build
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the first chapter, when we were explaining why you may be considering implementing
    the microservice architecture in your applications, we mentioned the challenges
    that are being currently faced by application developers and architects.
  prefs: []
  type: TYPE_NORMAL
- en: One of the key tools that may enable us to deal with providing software in a
    way that enables us to meet those challenges is automation. As we covered in the
    preceding chapter, OpenShift enables us to automate infrastructure provisioning.
    However, we need more than that.
  prefs: []
  type: TYPE_NORMAL
- en: We will also like to automate the process of deploying software into production.
    Ideally, we will like to have tools that will enable us to release software immediately.
    OpenShift provides such a tool in the form of the build `pipeline`. Let's introduce
    the rationale behind this concept.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start with CI.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a developer, you know too well what the development of projects looks like.
    There are many developers working on different functionalities, which they contribute
    to the same repository. Contributions from all the developers have to be integrated
    into the code repository so that stable code is created. After that, the code
    can be published into the production environment.
  prefs: []
  type: TYPE_NORMAL
- en: This sounds simple, but if you don't create an organized order according to
    which this process is executed, you will quickly end up with a huge mess. If the
    developers will integrate rarely, they are asking for problems. Their repositories
    will be highly diverged, and the application's functionality will be scattered
    between their repositories. As a result, during the development, there will be
    no *current state* source repository, and we will have no information about the
    state of an application. The new version of an application will emerge during
    the time people decide to push their contribution to the main code (which will
    presumably happen the day before the release). The process of integration at this
    point will be painful, where incompatible contributions are being discovered,
    and errors will emerge. Such a situation was described in the past as *integration
    hell*.
  prefs: []
  type: TYPE_NORMAL
- en: Owing to the preceding problems, it became clear that it will be a good idea
    to integrate code frequently. The methodology that advocates such a behavior and,
    more importantly, gives hints on how to do it, is called CI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Obviously, pushing the code frequently to the repository is not helping us
    much. At each commit, we need to make sure that the current version of the code
    at least compiles, and passes unit and integration tests. This is by no means
    a comprehensive list: to declare your code correctly, you may also need automatic
    code inspections or code reviews to name a few.'
  prefs: []
  type: TYPE_NORMAL
- en: In order for this process to be executed consistently, it has to be automated
    and executed each time the user wants to make the change to the code. Also, developers
    are supposed to integrate their code frequently, with each logical functionality
    developed, and are supposed to fix any errors that appear as soon as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'If this procedure is observed, this will lead to a number of benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: Problems are detected quickly. As the result, their source can be debugged and
    fixed quickly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The current version of the application is always present—it is the result of
    the last successful build. At each point, we can tell the status of the application,
    how it works, and what functionalities have been currently implemented.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The automated process works as a trigger for quality control. The build is guaranteed
    to be run and be reproducible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Continuous Integration ensures continuous builds of source code. It demands
    that fixes are pushed often and provides instant feedback to the developers. What
    if we extend this notion and configure our build infrastructure so that it will
    ensure that our services will be built and deployed automatically?
  prefs: []
  type: TYPE_NORMAL
- en: Such an approach, which is an extension of CI, is called Continuous Deployment.
    To implement it, we will need to automate the release process also. This means
    that we will have to keep all the resources that are needed to release the software
    to the given environment, such as environment properties or configuration scripts.
  prefs: []
  type: TYPE_NORMAL
- en: As a reward, we will be able to obtain reliable and repeatable releases. First
    of all, as the release process is no longer manual, all the magic is taken away
    from the release process. The release is executed by the release script using
    environment properties, which are both parts of the versioned build configuration.
    Those files are the one source-of-truth regarding the build process. As a result,
    if an error occurs during the build, those scripts have to be fixed. There is
    no place for manual patches or ad hoc fixes. Also, builds happen often, so configuration
    bugs will have an opportunity to occur and be fixed. On the other hand, after
    builds and releases start to work correctly, each next correct build adds more
    confidence in the release process. As a result, the release becomes a well-tested
    and an automated event.
  prefs: []
  type: TYPE_NORMAL
- en: Such an approach changes the way the team works by changing the speed at which
    features are developed. With CD, you are not releasing the software in large chunks
    to the client. Instead, small functionalities are released often and are immediately
    visible to the client.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the expected behavior for a number of reasons. First, customers will
    like to respond to client demand as quickly as possible. Having the tool that
    enables them to do that will be a big market advantage for the customer. However,
    there is more to it: because new functionalities are released often, they are
    visible to the customer immediately. As a result, a customer can immediately assess
    the actually implemented functionality. This creates an efficient feedback loop
    between the developers and the customers, which allow for faster convergence to
    the functionality actually expected by the client.'
  prefs: []
  type: TYPE_NORMAL
- en: Deployment pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The process of automatic delivery is implemented using a `pipeline`. A `pipeline`
    is a chain of steps that takes the source code as its input and provides a working
    application on it's output.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of the `pipeline` is to make sure that the source code is ready to
    be deployed in production. As a result, a `pipeline` should be able to catch errors
    as soon as possible and provide feedback to the developers immediately.
  prefs: []
  type: TYPE_NORMAL
- en: Also, because the final product is the released application, a `pipeline` should
    automate the release process so that it is run the same in all environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although a `pipeline` is a configurable script and its direct operation depends
    on your concrete environment, there are a number of common steps that are executed
    in the deployment `pipeline`: commit, build, automatic tests, manual tests, release,
    and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Continuous Deployment in OpenShift environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After this quick theory recap, now let's return to our cluster and configure
    CD for our application.
  prefs: []
  type: TYPE_NORMAL
- en: At the beginning of this chapter, we described the source-to-image build, which
    we have used in previous chapters. We also hinted that there is a `pipeline` build
    available. As you probably have guessed by now, this is the kind of build that
    we will use to implement CD of our services.
  prefs: []
  type: TYPE_NORMAL
- en: The `pipeline` build uses the Jenkins server to configure the `pipeline` configuration.
    Before moving further, let's introduce it quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Jenkins
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Jenkins is an open source software automation server. It allows for `pipeline`
    creation and provides the relevant syntax. So, how are we able to use Jenkins
    in OpenShift cluster and configure `pipeline` execution? Let's find out.
  prefs: []
  type: TYPE_NORMAL
- en: Our first pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start by creating our first `pipeline`. We have to log in to our web console
    and navigate to Add to project | Import YAML.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to do that, we have to go the web console''s main web page and navigate
    to Add to Project | Import YAML/Json and enter the following script there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'After the script is created, we can click on the Create button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/36d6de0a-fbfe-4258-90d7-67401a187b42.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Before we look further at the `pipeline` code, let''s note the other things
    that are happening. If we get to the main view of the web console, we will note
    that there is a new resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/55b9a649-623f-46d3-b307-cc79a79bd3ae.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s take a look at the currently available Pods too:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c055352a-525b-4747-a18a-617bbbc0ec87.png)'
  prefs: []
  type: TYPE_IMG
- en: Indeed, there is a new deployment of Jenkins server running, and the container
    for the Jenkins server is being created. OpenShift runs a `pipeline` build using
    the Jenkins server. Therefore, whenever you create a `pipeline`, OpenShift must
    check whether there is a Jenkins server present in the cluster. If not, OpenShift
    will start one automatically.
  prefs: []
  type: TYPE_NORMAL
- en: The creation of the Jenkins server takes some time, so we have to wait till
    it has been deployed. After we are able to see that the application is running
    in the Pods view, we are ready to start the build of our first `pipeline`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to do that, let''s navigate to Build | Pipelines. You will be able
    to see that there is a new `pipeline` present:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3d6f27c8-2cb8-46a8-a715-4e9def53639d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s click on the Start Pipeline button and see what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9994127a-285b-4024-8a8c-5b96cb1ec677.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Note in the preceding screenshot that the build has run. The dot with the tick
    described as Print means that one stage has been run and that it has been successful.
    We will be talking about the Jenkins `pipeline` structure in just a moment. Now,
    let''s take a look at more information about our current build by clicking on
    the View Log button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d7e6c34b-3b7c-4150-a09b-bf2e49a2921b.png)'
  prefs: []
  type: TYPE_IMG
- en: As you will have noticed in the preceding screenshot, we have been redirected
    to the Jenkins console. The build has been created, the Print stage has been executed,
    and the print message that we have echoed has indeed been written to a log.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the `pipeline` build configuration has been automatically turned
    into the Jenkins build and run in the Jenkins console. We will get more information
    about the build when we click on petstore/pricing-service-pipeline in the top-left
    corner of the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f82c848c-08f8-40bd-a744-5dac8d233a5f.png)'
  prefs: []
  type: TYPE_IMG
- en: From this window, we can trace the build history, view the logs and time of
    the latest execution, or edit the `pipeline`, among others. At this point, it
    is good to look again at the script that we have written in order to create the
    `pipeline`. You probably have noted immediately that the Jenkins `pipeline` was
    squashed into one line, making it hard to read and edit. Before we take any other
    steps, let's find a human way to edit our `pipeline`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to do that, let''s click on the Configure button on the left-hand
    side menu and scroll down:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/30400538-e076-458d-8030-156f5eb4ee70.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We have a good editor for our `pipeline` here. Let''s make our first edit of
    the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9e60e66a-3ad4-4f58-baf9-829871ab8bf2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We will then test it to check whether it works. In order to do that, we have
    to save the `pipeline` and click on the Build Now button in the build view. After
    that, we are ready to examine the log by clicking on the second build that has
    just been executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aad14228-9d6e-4506-b097-35c58f78752e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We will see the new log as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e4bec7ff-ce59-47e8-acda-b9fe45d04c66.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Also, let''s log in again to the web console and examine that `pipeline` there:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5e53124c-6629-4e92-bf37-c43f370dc39b.png)'
  prefs: []
  type: TYPE_IMG
- en: As you will have noticed, the `pipeline` build config was modified accordingly
    to the changes that we have made in Jenkins. We will perform our future changes
    using the Jenkins server.
  prefs: []
  type: TYPE_NORMAL
- en: The new message that we are printing in the build promises that our build will
    do something useful at some point. After all, we want to create a CD `pipeline`
    for our services and not print messages. Before we can do it though, we will need
    to learn a few more things. In the beginning, we will need to say a few more words
    about the language that we are using to define the `pipeline`.
  prefs: []
  type: TYPE_NORMAL
- en: Pipeline syntax language
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we wrote our first `pipeline`, we used the Jenkins declarative pipeline
    language. We will describe the essentials of the **Declarative Pipeline Language**
    (**DPL**) in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Core pipeline elements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to do that, let''s return to the `pipeline` that we executed in the
    preceding section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Each `pipeline` in DPL must be enclosed with the `pipeline` block (1).
  prefs: []
  type: TYPE_NORMAL
- en: The `pipeline` must begin with the `agent` directive (2). This directive specifies
    the Jenkins builder machines in which the build stages (more about them in a moment)
    can be executed. This setting can be overridden in each of the stages. In our
    examples, we will use any agent for all the stages.
  prefs: []
  type: TYPE_NORMAL
- en: The core `pipeline` build blocks are the stages. The stages are meant to map
    to the stages in the CD `pipeline`. They are defined in a serial order, and each
    stage can execute only if the stage before has succeeded.
  prefs: []
  type: TYPE_NORMAL
- en: The stages have to be enclosed with the `stages` (3) block. Each stage (there
    need to be at least one of them) has its own `stage` block with the name specified
    as a parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Each stage block can contain a bunch of directives followed by the steps block,
    which encloses one or more steps that will be executed in the `pipeline`.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we are getting to the key point. What are the available steps that we can
    execute? Jenkins provides a very large number of different steps provided by different
    plugins. We will concentrate on one specific plugin that makes it easy to develop
    and execute operations on OpenShift clusters—let's discuss OpenShift, the `pipeline`
    Jenkins plugin (Further reading, link 1).
  prefs: []
  type: TYPE_NORMAL
- en: Standard Maven operation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first stage that we will implement is the unit testing stage. In the beginning,
    we will add a simple unit test in the same way that we did in [Chapter 5](c1be724d-e5fd-4c33-bd27-c04887d5cc8e.xhtml),
    *Testing Your Services with Arquillian*. We have to extend `pom.xml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Recall that we had to add dependencies for JUnit (1), Arquillian (2), Swarm's
    Arquillian adapter (3), and the in-memory database that we will use (4).
  prefs: []
  type: TYPE_NORMAL
- en: 'Secondly, we have to provide test resources, namely `persistence.xml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'And the load script that we are going to use to test the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Ensure that we also add the `h2` driver module:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/17e1078e-59f2-4af1-b8f3-efa2582103ca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We are now ready to write a test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Now, we are finally ready to write the testing stage. We will like to make this
    stage run fast and fail immediately if there are some problems, without creating
    an image or changing anything in our OpenShift model. For this, we will use standard
    Maven and git from the command line.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to do this, we need to configure those tools. To do this, we will
    have to go to Jenkins configuration in the main menu, click on Manage Jenkins
    and select the tool configuration for JDK:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fe72f1b1-c6c4-4c95-b002-32250f3c9e9a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And Maven:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3c0d6bbc-025d-4dda-8e3b-ae8420bccb40.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We are finally ready to update our `pipeline`. Let''s take a look:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We have provided the mandatory agent any (1) and configured Maven, JDK, and
    git tools, providing the versions for all of them. We have replaced our print
    stage with the unit test stage (3), which consists of the following two steps:'
  prefs: []
  type: TYPE_NORMAL
- en: The first step clones the pricing-service's git repository (4)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The second step runs the Maven tests (5)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We have to provide the modules directory in order for the tests to work.
  prefs: []
  type: TYPE_NORMAL
- en: OK. So, we have our first stage. Now, what next? If the unit tests pass, we
    will like to build and deploy an image with our application. In order to do that,
    we will have to interact with our cluster object from within the `pipeline`. The
    tool that will help us do that with ease is the OpenShift Pipeline Plugin. Let's
    learn more about it.
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift Pipeline Plugin
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Jenkins has a pluggable architecture, which allows for plugin development. OpenShift
    provides its own plugin, which allows for straightforward operations on OpenShift
    cluster objects in a declarative manner. The plugin provides a number of commands.
    We will introduce them one by one during the `pipeline` development.
  prefs: []
  type: TYPE_NORMAL
- en: In the beginning, we will write a build stage, which will assemble the image
    and ensure that the application works correctly.
  prefs: []
  type: TYPE_NORMAL
- en: The first command that we will use is the `openShiftBuild` command. It allows
    running one of the builds defined in the OpenShift cluster. This command takes
    one mandatory parameter, `buildCfg`, which is the name of the build that will
    be executed.
  prefs: []
  type: TYPE_NORMAL
- en: The second command that we will use is verified as `Build`. This command also
    takes `buildCfg` and checks whether the last build of this type has finished successfully
    within a reasonable time period. To set the period, we will use the `waitTime`
    parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at our new `pipeline`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: We have introduced the `Build` stage (1) and added two steps to it, as mentioned
    in the preceding paragraph. The `Build` command runs the `pricing-service` `s2i`
    build that we configured at the beginning of this chapter (2). The verify command
    checks whether the build was executed successfully within 5 minutes.
  prefs: []
  type: TYPE_NORMAL
- en: We will like to only build the image here and not deploy it yet. So, we will
    need to modify our build and remove the image change as the trigger for the deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'After that, we are ready to start our `Build` in Jenkins. If you do it and
    click on console output, you will be able to see the execution log. Let''s take
    a look at it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8c9a2cb3-37e8-40a6-8bed-7eebc8a8fabf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Oops! If you look again at the test, you will note that there is an error,
    as the price of the test-pet is 5 none 7\. Before we fix it, let''s note how the
    `pipeline` works. Our first unit test stage failed immediately. As a result, no
    further stages were started. No images were built and no applications were deployed.
    Let''s also look at the `pipeline` view on the web console:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a83f88ec-9570-4368-a320-41fd7161fd8c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The console presents the `pipeline` execution in a graphic way, showing that
    the test stage failed. Let''s fix our tests and run the application again. If
    you do it and look at the console log, you will be able to see that the test has
    passed and the `Build` stage has been executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e93b5cfa-0a69-4adb-88fc-e5fde152b404.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When you take a look at the web console, you will be able to see that the `Build`
    has been finished and that the image has been created:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a5954008-32cf-4af6-975c-ce9979401a6d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s look at the currently available deployments:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7e93af2d-4331-425c-ab7a-2fa18207df4e.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, we only have the build image and have not triggered the deployment yet.
    Let's add another stage to our build. We will use `openshiftDeploy`, `openshiftScale`,
    `openShiftVerifyDeployment`, and `openShiftVerifyService`. Before doing that,
    let's introduce each of these commands.
  prefs: []
  type: TYPE_NORMAL
- en: The `openshiftDeploy` command takes a mandatory parameter—`dplCfg`—which is
    the name of the deployment. It runs the deployment of an application.
  prefs: []
  type: TYPE_NORMAL
- en: '`openshiftScale`, irrespective of a mandatory `dplCfg` parameter, takes the
    `replicaCount` parameter, which specifies the number of replicas of the application.
    Since we are using this command to scale the application, we will change the number
    of instance deployments in the `deploymentConfig` to zero. As a result, the pods
    will be started only after the `openshiftScale` operation has been executed without
    an unnecessary rescale.'
  prefs: []
  type: TYPE_NORMAL
- en: '`openShiftVerifyDeployment` has the same mandatory parameter as the two previous
    commands—`dplCfg`. This command has three optional parameters, and we will use
    all of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '`replicaCount`: This parameter specifies the expected number of replicas'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`verifyReplicaCount`: This is a Boolean parameter, which specifies whether
    the replica count should be checked'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`waitTime`: This indicates the time in milliseconds in which we should wait
    for the verification'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`openshiftVerifyService`: This command checks whether the service is available'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`openshiftVerifyService` has one mandatory parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '`svcName`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One optional parameter `retryCount` specifies how many times the connection
    is attempted before declaring the verification invalid
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before showing you the new script, we will introduce one more concept. As we
    mentioned in the theoretical section of this chapter, the build should give immediate
    feedback to its authors regarding its status. In order to react to the `Build`
    status, the DPL provides the ability to perform an action after the `pipeline`
    is finished based on the status of the build. The construct that allows doing
    that is post directive.
  prefs: []
  type: TYPE_NORMAL
- en: 'A post directive enables us to perform an action after the build has been finished.
    It can be placed at the end of the `pipeline` or at the end of each stage. The
    post directive provides a bunch of subdirectories: always, success, failure, unstable,
    (runs if the build is unstable—the result changes during the build) aborted, and
    changed.'
  prefs: []
  type: TYPE_NORMAL
- en: In our script, for the sake of simplicity, we will echo the build status to
    the console, but we can use the available Jenkins plugins0; to configure email,
    HipChat, or slack notification.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the build:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We have extended our `pipeline` in a way described previously:'
  prefs: []
  type: TYPE_NORMAL
- en: We have added the `Deploy` stage (1), which deploys the application (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, it scales the application (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It verifies that the deployment succeeded (4) and that the service is available
    (5)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After each build, the result of the test is echoed to the output, depending
    on whether the test succeeded (6) or failed (7)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you look at the console output, you will be able to see that all the steps
    that we have implemented have been executed successfully.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also verify this in the web console `pipeline` view:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/235d9bdc-5bae-453a-9d72-f950ae6a6935.png)'
  prefs: []
  type: TYPE_IMG
- en: Finally, you can verify in the web console that the service has indeed been
    created and that the corresponding pods are running.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned the build infrastructure provided by OpenShift.
    You then learned to use source-to-image build, which abstracts away the details
    of Kubernetes internals from the developer and lets them build the image based
    solely on code with minimal configuration.
  prefs: []
  type: TYPE_NORMAL
- en: In the second part of this chapter, you learned about the `pipeline` build,
    which, effectively, is a way to integrate Jenkins `pipelines` with OpenShift infrastructures.
    You also learned how to create the `pipeline` build and the basics of the DPL
    syntax. Hence, you were able to create a CD `pipeline` for your petstore's `pricing-service.`
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://jenkins.io/doc/book/pipeline/syntax/](https://jenkins.io/doc/book/pipeline/syntax/)'
  prefs: []
  type: TYPE_NORMAL
