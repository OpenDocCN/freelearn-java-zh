- en: Introduction to the Actor Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we the discussed patterns and techniques of advanced
    functional programming in modern programming languages. However, you may have
    noticed that we were always dealing with cases of sequential programming. The
    closest that we have ever gotten to real parallelism was when we discussed the
    Applicative type class.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will go deeper into the topic of modern functional solutions
    for parallelism. The following are the topics that we will be covering in this
    chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Overview of parallelism solutions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traditional model synchronization on monitors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The actor model as a replacement for the traditional model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overview of parallelism solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you remember, the Applicative type class gives us an abstraction to define
    parallel computations. It was set against the `Monad` class, which is an abstraction
    to define sequential computational.
  prefs: []
  type: TYPE_NORMAL
- en: In the *Type Classes* section in [Chapter 8](baec5eab-0c98-4407-8f73-9a1a2b9726c4.xhtml),
    *Basic Type Classes and Their Usage*, we reasoned that Applicatives are needed
    to provide you with a primitive to define independent computational. Parallelism
    can also be modeled by the Applicative. However, it is precisely the idea of independence
    for motivating force behind this type class.
  prefs: []
  type: TYPE_NORMAL
- en: Parallelism and concurrency require a different approach. They give rise to
    problems that are not normally encountered in sequential programming, and these
    problems have their own techniques so that they can be solved in object-oriented
    programming. However, these techniques are even more error-prone and hard to reason
    about than regular object-oriented and imperative programming. Hence, a bunch
    of other techniques were devised in order to simplify the process of developing
    concurrent software.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we still cannot say that we have an ideal approach to parallel and concurrent
    programming. Whenever concurrency is involved, programming gets much more difficult
    than in a single-threaded case, even in the case of the use of the most modern
    techniques and approaches. Modern systems tend to be distributed, and there is
    a high demand on the scalability of such systems. This means that in the modern
    world, it is often the case that a single application must run on several machines
    that can be located in different parts of the world. Also, there is a requirement
    on the scalability of such systems. Scalability means that whenever you add extra
    processing power, such as extra machines to the cluster, the existing program
    must run seamlessly on these new machines without you needing to write extra programming
    code. Basically, scalability means that software must run on any number of machines
    as well as it does on a single machine.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, in such scenarios, chaos is inevitable. So far, we do not have a
    single solution to the issues that arise in the context of distributed fault-tolerant
    and highly available systems. Attempts were made to create approaches and mathematical
    theories that address this issue in the 20^(th) century. Here, we are talking
    primarily about a class of mathematical theories called process calculi. Process
    calculi is a set of mathematical theories that are precisely aimed to describe
    processes that happen concurrently with the help of mathematical logic and mathematical
    laws. Some notable examples of process calculi include **Algebra of Communicating
    Processes** (**ACP**), which has an implementation in Scala called SubScript (see
    [subscript-lang.org](http://subscript-lang.org/)), pi-calculus, **Calculus of
    Communicating Systems** (**CCS**). Attempts were made to implement these theories
    in practice. However, today, we cannot say that any given theory addresses the
    entire range of problems faced by modern programmers in-depth and with convenience.
  prefs: []
  type: TYPE_NORMAL
- en: Also, in recent years, a range of engineering approaches have been developed
    specifically for the development of concurrent and parallel applications. One
    such approach is reactive programming. This approach is mostly based on engineering
    your application in terms of streams, data sources, and sinks. This kind of approach
    can be very useful in the context of an application that is heavy on data flow,
    which means that there is a large volume of data that is constantly moving from
    one part of an application to another.
  prefs: []
  type: TYPE_NORMAL
- en: A practical application of such reactive programming is applications that are
    heavy on events. For example, many mobile applications rely on event propagation
    and reacting to events. This means that a good strategy to describe this kind
    of application would be to reason about data streams and data sources, as well
    as reactions to data as first-class citizens of the application. Normally, these
    kinds of application would be described in terms of callbacks and reactions to
    events. However, reasoning in terms of streams gets you a toolset of proper abstractions.
    In the previous chapter, we saw that when we frequently encounter errors and side
    effects, then making them first-class citizens of your programs and reasoning
    about them explicitly can be very beneficial to troubleshoot your application
    and to reduce the chance of an error.
  prefs: []
  type: TYPE_NORMAL
- en: It's the same thing here—when we have an application that is heavy on data and
    events, then reasoning in terms of streams can be pretty beneficial. There is
    an entire range of implementations of this approach for a wide range of programming
    languages.
  prefs: []
  type: TYPE_NORMAL
- en: However, programming in terms of event streams and reactive programming is not
    always what you want. It's true that certain applications that are heavy on events
    and data processing may be reasonable to describe in terms of data streams. However,
    this is not always the case.
  prefs: []
  type: TYPE_NORMAL
- en: As we have discussed previously, a wide range of theories and approaches have
    been developed to address the difficulties of parallel programming. Some of them
    can be regarded as more functional. For example, some libraries for functional
    programming for Scala, such as `Cats` or `ScalaZ`, provide certain primitives
    to allow for concurrent and parallel programming. Some of these approaches have
    a more object-oriented flavor. For example, some of the process calculi mentioned
    previously tend to have a deal of object-oriented spirit in them, which means
    that they introduce certain kinds of primitives that are very much comparable
    to objects in object-oriented programming. Some theories and approaches reside
    on the edge between functional programming and object-oriented programming and
    cannot be clearly classified as members of any of these approaches. For example,
    this can be the reactive approach to programming. Although it is heavy on functions
    and uses Lambda calculus to compose these functions, the trade-off is often type
    safety.
  prefs: []
  type: TYPE_NORMAL
- en: The presence of the amount of theories and approaches for concurrent programming
    means that this topic is highly speculative. It is often the case that techniques
    and theories that work well for one application will not show themselves as being
    well for another. Therefore, it is necessary to remark this book's stance on the
    topic. In this book, we take a pragmatic approach to functional programming, which
    means that the aim of this book is to give you a toolset to solve practical problems
    in a functional manner. So far, one of the most pragmatic and best approaches
    toward parallel programming is the actors model. While it is possibly not the
    most elegant modal from a functional programming perspective, since it still lacks
    a satisfactory type safety, it is something that is highly scalable and works
    well in practice. In this chapter of this book, we will be studying the actor
    approach to the functional programming of parallel applications, and we will see
    how to use modern actor-based technology to write real-world parallel and scalable
    applications with the help of the actor model.
  prefs: []
  type: TYPE_NORMAL
- en: However, before we jump into discussing the actor model and its practical applications,
    it is necessary to understand all of the challenges that are faced by parallel
    programming, and how they are solved in the traditional model of object-oriented
    programming with the traditional approach. So, first of all, let's take a look
    at the traditional approach to parallel programming, that is, multi-threading
    with synchronization and monitors.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional model synchronization on monitors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Concurrency scenarios occur when you have two or more operations that are executed
    in parallel one with another. This parallelism can be either true parallelism
    or simulated parallelism. True parallelism is when your application is executed
    in parallel on two different CPU cores, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/30f64707-8d2c-486e-bacc-3e4c681c1c41.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Simulated parallelism is when all of your parallel tasks are executed on the
    same processor core, however the processor switches from one task to another from
    time to time. Every task is composed of so-called atomic actions—smallest tasks
    that cannot be interrupted until they complete. The processor can take a certain
    amount of atomic actions from one task, and then execute a certain number of atomic
    tasks from another task:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8fa70dc4-0ab7-4b51-9b64-5e79ff76ef13.png)'
  prefs: []
  type: TYPE_IMG
- en: When you are writing a parallel application, you will often come across a situation
    where your tasks need to communicate one with another. One such situation when
    this may happen is when your concurrent tasks need to access some kind of resource
    that can be external or internal to the application, which is not thread-safe.
    In this situation, they will need to coordinate their access to this resource.
    Here, we have stumbled upon a very important concept to parallel programming,
    that is thread safety. Thread-safe resources can be accessed from any number of
    threads in parallel without worrying about whether something can go wrong. However,
    resources that are not thread-safe must be accessed from one side at a time. A
    typical example of a thread-safe resource is an immutable data structure. A typical
    example of a non-thread-safe resource is a shared mutable state.
  prefs: []
  type: TYPE_NORMAL
- en: 'What can possibly go wrong if you access a resource that is not thread-safe
    from more than one thread? Consider the example of writing to a file. Consider
    that you are writing an application for an online shop that is intended to generate
    a list of goods in some format. Consider that you need to read from a file listing
    goods in CSV and then transform them in some way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Consider that you need to output the same goods in JSON using the `Circe` library
    that we have already learned about:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Also consider that you want to perform this operation in parallel. What you
    need to do here is take every row of the CSV file and convert it into some JSON
    output. Then, we need to write this output into the output file. Here, we have
    a bunch of operations that are not dependent one on another. Every transformation
    of every row is independent on any other transformation of any other row. So,
    what we might want to do is take these tasks in parallel from two threads. Therefore,
    one thread will process the first half of the list, and the other thread will
    process the second half of the list.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output to a file can be modeled as a certain transaction, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/08cc1a4b-4dde-481f-9cdb-451dea9a2075.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding diagram, you can see that we have the operation of opening
    the file for writing, then executing certain atomic actions that write the data
    into the file, and then closing the file. For simplicity, the process of writing
    a string called `Hello` into a file may not look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2492799d-0719-4cc3-b93f-f7eb9c1ca60f.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, we can see that the entire transaction is not atomic.
    It is composed of atomic operations, and is writing individual characters in our
    case. A note should be made here that the preceding example is only an example.
    Different implementations of writing logic might implement the transaction process
    differently so that the preceding atomic operations might not hold true for all
    environments. However, the preceding example illustrates this point very well,
    since most implementations still write to a file in a non-thread-safe manner using
    atomic actions. The entire writing transaction is not atomic.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider what happens if we try and write into the same file from two
    different threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3c384403-3929-4b1e-a4f3-ea767b24f61a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So, as you can see, we do not have any guarantee regarding the order in which
    the atomic tasks of every transaction get executed. So, as the preceding scenario
    comes through, you will end up with the following output to a file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'That is what we mean when we say that an operation or a resource is not thread-safe.
    This means that it is only permitted to work with the source from a single thread.
    Working from two threads with the same resource can be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5c7086ef-0671-44c5-a82f-bc1234e68670.png)'
  prefs: []
  type: TYPE_IMG
- en: So, obviously, the preceding two threads must be aware of one another and of
    the order in which they should be executed. More precisely, we should somehow
    impose a guarantee that only one thread at a time will have access to the shared
    resource. In other words, we need to synchronize the threads somehow.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The simplest approach that can be used to synchronize the threads is called
    synchronization. It is implemented on the language level and is a standard construct
    in most programming languages.
  prefs: []
  type: TYPE_NORMAL
- en: The idea is as follows. Certain chunks of your programming code can be made
    guarded, which means they cannot be executed by the thread unless a certain condition
    is true. The condition in question is ownership of a so-called monitor. Therefore,
    a thread can own certain monitors. In a JVM setting, a monitor can be any object.
    So, on the JVM level, we can declare that a thread owns a monitor. Threads can
    take ownership and release the ownership of monitors at their own discretion.
    Another rule is that a monitor can only be held by one thread at a time. When
    a thread wants to take a monitor that is already held by another thread, then
    this thread must wait until this monitor is released and becomes available to
    it once more.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding framework can be used in order to synchronize threads with one
    with another. You can do so as follows. Whenever we have a resource that is not
    thread-safe and needs to be accessed from more than one thread, we guard the code
    by accessing it with the `synchronized` keyword, that is, in the case of Java
    or Scala. This can be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code is executed in the context of some thread. Every instruction
    is executed in the thread in sequence. When the thread reaches the `synchronized`
    keyword, it attempts to take the object in question as a monitor. If this object
    is owned by some other thread, this thread goes into sleep mode. This means it
    does nothing until notified that the monitor is released and available for it
    to acquire. Once the monitor is available, it is acquired by this thread. This
    thread now has a guarantee that no other threat will take the same monitor until
    it is held by itself. Then, this thread executes the code in a `synchronized`
    block.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the code is executed, the monitor is released by the current thread.
    The semantics of the execution will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b1368add-9d93-4536-979d-1e26e759982a.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding approach might look good in theory. However, there are a bunch
    of serious problems that can be encountered in such a scenario. These problems
    are pretty hard to debug, and they cannot be spotted by modern compilers. The
    existence of such problems demands a better framework for reasoning and defining
    concurrent and parallel applications. Next, let's take a look at what these problems
    are.
  prefs: []
  type: TYPE_NORMAL
- en: Problems with the traditional model – race conditions and deadlocks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The problems start to appear when more than one resource gets involved. Consider,
    for example, a slightly modified version of the preceding program. In the previous
    example, we had to write the result of the computation into a file. Consider that,
    at the same time as doing the computations themselves, we need to keep track of
    what they're doing in a log file. This kind of practice can be useful in a real-world
    scenario for debugging purposes.
  prefs: []
  type: TYPE_NORMAL
- en: So, the plan is as follows. First, the entire input file is read into the program
    memory. In our current scenario, threads are heterogeneous, which means that they
    have different tasks to accomplish. Homogeneous threads are generally easier to
    work with because they behave similarly and are controlled from one place. However,
    this is not always the case in the real world. So, let's consider threads with
    the following tasks. The first thread will be tasked with the conversion from
    CSV to JSON, as in the previous example. Also, it must report about how the conversion
    goes into the log file. The other thread will perform a different task. Let it
    compute some statistics over the file in question, for example, an average price
    of all the goods that the online shop is trading.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how such a program might be implemented in a traditional synchronization
    scenario. Before diving into this example, let''s define some convenience methods
    and values that we will use in the example. You will need the following imports:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'For file operations, we will use the Apache Commons IO library. The dependency
    on it must be declared in `build.sbt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The convenience methods are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'With the stage set, let''s proceed to the example. First of all, let''s take
    a look at the first thread tasked with the conversion from CSV to JSON. The first
    thing you might want to do in this thread is open the file we''re going to work
    on and read it to a list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Since files are not thread-safe resources, the first thing that we need to
    do is take a monitor on the file. Immediately after reading this file, we might
    want to report to the log that the operation was performed successfully. So, we
    might want to take a monitor on the log file and report the operation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that the monitor of the log file is released immediately after we are
    done with that reporting. So, `inputListcode` looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we are done with reading the file, we perform the operation of conversion
    on every row of the input file, and then we write the result into the output file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'So, the entire code for the first thread looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s take a look at the other thread. It is tasked by the objective
    of computing certain statistics to our input file. More precisely, what we can
    do is compute some sort of aggregate function on all of the prices of the goods.
    For example, we might consider computing the average, the maximum value, and the
    minimum value of the set. However, we might also want to configure this thread
    with the exact metrics we want to compute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, we were able to specify which exact metrics we need to compute.
    A reasonable step would be to report this information to a log file before doing
    anything else:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The first thing that we do here is take a monitor on the log file and report
    the metrics. The next thing we need to do is actually read the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Since we also need to report the fact that the file was read successfully to
    the log, we decide to release the log monitor, but only after the file is successfully
    read. Notice how the snippet that reports the metrics gets incorporated into the `inputList` code,
    so that both the statistics and the `Read the input file` reporting can be done
    under the same `synchronized` code block.
  prefs: []
  type: TYPE_NORMAL
- en: 'After reading the input file, we are able to compute the required metrics on
    this input file based on the parameters specified by the user as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Therefore, the entire code for the `statistics` thread will look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: What happens if you run this thread in parallel with the first thread?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: You may notice that, sometimes, the program hangs and becomes non-responsive.
    This situation is called a **deadlock**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Basically, the problem here is that the two threads are racing for the resources.
    It is a race condition of who takes which monitor first. The first thread takes
    the monitor on the input file, and then it takes the monitor on the log. Then,
    it releases the monitor on the lock, and then it releases the monitor on the input
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b26dab53-8f3e-485f-890a-3b94cb6a6a30.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, the orange bar represents the code that is executed
    under the input monitor. The blue bar is the code under the log monitor. In this
    particular case, the blue code also owns the input monitor, since it has not been
    released from the time of its execution yet.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second thread, in contrast, does these operations in a different order.
    First, it takes a lock on the log file. Then, it takes the lock on the input file,
    and then it releases the lock on the input file, before releasing the lock on
    the log file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/442b21f4-7289-4e13-9845-4448e6ae9a2b.png)'
  prefs: []
  type: TYPE_IMG
- en: The two threads depend on the same set of resources, and the order in which
    they acquire them is not defined. This means that they will be competing for these
    resources, and when you run the program several times, the order of resources
    in acquisition will be different from run to run.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at a case where an application works well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2880eb78-a06a-4b26-ad8a-767350d766b7.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, the first thread takes the monitor on input and then
    it takes a monitor on the log, but after that, the second thread attempts to take
    the lock on the log, but it is late to do that. Therefore, it is forced to wait
    until the other thread finishes. The first thread has acquired all of the locks
    it is dependent on, and so it finishes successfully. After it finishes, it releases
    all of monitors it owns, and the second thread is capable of taking them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at how and why exactly the application gets a deadlock:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c0787699-8448-43c1-b377-9070fe798a24.png)'
  prefs: []
  type: TYPE_IMG
- en: So, in the example above, the first thread takes the monitor on the input file.
    Together with it, the second thread takes the monitor on the log file. After that,
    in order to proceed, the first thread needs a monitor on the log file, but it
    cannot take it because the second thread has already taken it, and so it is forced
    to wait.
  prefs: []
  type: TYPE_NORMAL
- en: The second thread needs the monitor on the input file in order to proceed. However,
    it cannot take it because it is owned by the first thread, and so it is also forced
    to wait. This means we have ended up in a situation where neither of the threads
    can proceed until the other thread finishes, and so neither of the threads ever
    finishes. This kind of situation is called a deadlock.
  prefs: []
  type: TYPE_NORMAL
- en: 'A quick fix may be to make the threads and take the monitor in the same order.
    For example, if the first thread takes the monitor on the input file and then
    a monitor on the log file, we might want to enforce the same order on the second
    thread as well. So, the second thread will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The preceding chunk of code in bold is what was changed compared to the `statistics` thread
    definition. Now, whoever takes the monitor on the input file first is guaranteed
    to finish the execution. This is because, in the preceding application, it is
    impossible to take the monitor on the log file unless you already own the monitor
    on the input file. So, whoever takes the monitor on the input file is guaranteed
    to be able to take the same monitor on the log file.
  prefs: []
  type: TYPE_NORMAL
- en: The fix might work in the short term. However, you might have already noticed
    that it is suboptimal. In the previous example, we had a pretty simple situation.
    We only had two threads and two resources they depend on. That kind of simple
    setting is not likely to happen in the real world. Real-world applications are
    likely to have dozens of threads in them and depend on dozens of resources. Also,
    debugging the preceding complexity was tricky. If only two threats were capable
    of producing such complexity and required a lot of our brain power to do the analysis
    and find the problem, imagine how this complexity can grow in magnitude in a real-world
    setting.
  prefs: []
  type: TYPE_NORMAL
- en: This is precisely why the standard synchronization approach to parallel programming
    is not practical in the long run. It's fine as a low-level model of programming
    so that people build some high-level primitives on top of it. However, we cannot
    use it in practice efficiently. These kinds of problems with threads and concurrent
    applications provided a motivation to create newer, more robust approaches to
    reasoning about concurrent programming. We already discussed some of them briefly
    at the beginning of this chapter. Now, let's talk about the actor model in more
    detail.
  prefs: []
  type: TYPE_NORMAL
- en: The actor model as a replacement for the traditional model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most popular approaches to dealing with the complexity discussed
    previously is the actor approach to concurrent programming. If you look at the
    preceding examples in detail, you will notice one thing about them, that is, global
    reasoning. Whenever we have several threads that need to communicate in one with
    another, we are forced to reason about them together. So, we cannot take one thread
    and reason about it independently from other threads.
  prefs: []
  type: TYPE_NORMAL
- en: As we saw previously, the solution to the deadlock problem was to change the
    order in which the monitors were taken in the second thread so that the order
    matched the one in the first thread. Basically, when we are working in the scope
    of the second thread, we are forced to take into account the operations done in
    the first thread.
  prefs: []
  type: TYPE_NORMAL
- en: Global reasoning produces mental load on the programmer's mind. One of the central
    points of this book is that purely functional programming aims to reduce the mental
    load on the programmer's mind by reducing the scope of reasoning about the programs.
  prefs: []
  type: TYPE_NORMAL
- en: How can we tackle the problem of the global scope and shared mutable state as
    the means of communication between threads in the context of concurrent programming?
    The response of the actors model would be to provide a set of abstractions to
    ensure that whenever you are programming a parallel application, you are able
    to forget that you are working in a concurrent environment. The central point
    behind the actors model, the central idea of why it is created, and why it exists,
    is to make your program within a concurrent environment as if you were dealing
    with a single threaded application, which means you no longer need to think about
    taking monitors or accessing resources in a thread-safe manner.
  prefs: []
  type: TYPE_NORMAL
- en: The actor model does this by providing you with a set of abstractions and a
    set of conventions that you must follow as part of the model. A central abstraction
    of the actor model is, not surprisingly, an actor. An actor can be roughly thought
    of as a thread. It is not necessarily mapped one-to-one on threads; in fact, it
    is a more lightweight primitive, and you might have thousands upon thousands of
    actors. The way their concurrency is managed is in abstracted away. However, the
    right way to think about actors is that they are the concurrency primitives of
    the actor model.
  prefs: []
  type: TYPE_NORMAL
- en: An actor can own certain resources, and if it does, it is guaranteed that no
    other actor owns or has access to these sources. For example, if an actor has
    a reference to a file, it is guaranteed that no other actor has the same reference
    to the same file, so it is not able to write or read from the file. If it does
    need to access a resource owned by another actor, it needs to ask the owner actor
    to perform the required operation on behalf of this actor. Since all of the operations
    over a non-thread-safe or resource are done by one and only one actor, and actors
    are sequential and single threaded entities, there is no danger that some non-thread-safe
    behavior will emerge in this context.
  prefs: []
  type: TYPE_NORMAL
- en: How exactly does one actor ask another actor to perform an action? This is done
    by messaging. Every actor has a so-called **mailbox**. A mailbox is a place where
    all of the incoming communications to this actor are stored. A single unit of
    communication in the actor model is a message. A message can be anything as long
    as it complies with the constraints of the actor model, which we will be discussing
    later. A mailbox is a queue. Therefore, the messages from many actors that run
    and send messages in parallel may arrive to the single actor, and they will get
    sorted into a single sequential queue. An actor is guaranteed to process only
    one message at a time. So, the way it works is that the actor waits on its mailbox
    for mail. Then, it takes one letter at a time and processes it sequentially.
  prefs: []
  type: TYPE_NORMAL
- en: One way regarding how exactly to process the incoming mail is defined in the
    body of an actor in terms of reactions to different kinds of incoming mail. So,
    for every type of mail the actor is capable of handling, it defines a certain
    function that is supposed to be executed whenever this letter arrives to the actor.
  prefs: []
  type: TYPE_NORMAL
- en: Deadlock example revisited
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have looked at the actors model at a glance. We have not learned
    any practical implementations of the actor model just yet. However, it can be
    instructive to take a look at how our previous example can be implemented so that
    we are rid of the complexity that we have faced with it.
  prefs: []
  type: TYPE_NORMAL
- en: First of all, we have discussed that actors are primitives of concurrency of
    the actors model. In the preceding example, the primitives of concurrency were
    two threads that performed some operations. So, it is reasonable to map the operations
    that we need to perform from the two threads onto two actors of the actor model.
    So now, instead of two threads, we have two actors. One actor is supposed to generate
    JSON from CSV, and the other actor is supposed to compute some statistics on the
    CSV file.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, we had two files that we were supposed to work with
    and two threads that needed to get access to both of the files. The actors model
    requires that only one actor must own a given resource. So, if the first actor
    needs a resource, the second actor cannot have it. In our situation, the first
    and second actors need to work with the input file and the log file. How should
    we tackle this situation? How should we make it compliant with the actor model?
  prefs: []
  type: TYPE_NORMAL
- en: The solution is that none of the two actors should own this resource. Instead,
    we should create a third actor that is responsible for running operations that
    involve these resources. Then, whenever we need to do something with a result,
    we send a message to that actor asking to perform the required operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since our actor, let''s call it process manager, controls access to the input
    file and the log file, we must expect the request from other actors to perform
    operations relevant to this resource. In other words, we also need to define the
    reactions to all the possible messages that it might receive. Hence, we need to
    think about what kind of operations request we might get from other actors. We
    can consider the following requests:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we get the input file. This message is a request to read the input file
    and send it back to the requesting actor as an immutable collection. Sharing an
    immutable resource between two actors is perfectly fine since immutable resources
    are thread-safe.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secondly, we may be expecting a request to write into the log file. Upon receiving
    this request, the resource manager actor will perform a write operation into the
    log file with the message that was sent to it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once we have the resource manager actor, we can express the example like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6ae66c87-28e7-47de-9a01-74a53ebd18d0.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, the first two actors that do the actual job are defined in terms of messages
    and communication with the resource manager. The first actor asks the process
    manager to send it an input file. Upon receiving a response from the resource
    manager, it starts its operations, and whenever it performs a significant action
    that requires logging, it sends the log message to the resource manager. No monitors
    are taken in this situation since all of the resources are owned by a single actor.
    All of the other actors are not calling them directly—they are just asking the
    resource actor to perform the operations on their behalf.
  prefs: []
  type: TYPE_NORMAL
- en: The second actor has a similar situation to itself. First of all, it sends a
    log message to the resource manager with the statistics it is going to compute.
    Secondly, it requests the input file from the resource manager. Finally, upon
    receiving the input file as a separate message, it performs the computation and
    also contacts our resource manager whenever it needs logging.
  prefs: []
  type: TYPE_NORMAL
- en: None of the actors need to take monitors or synchronize one with another in
    order to ensure that the non-thread-safe resources are safe to work with. They
    are all owned by a single actor, and this single actor works with them sequentially
    from its own single thread. The messages that the other actors send to it may
    arrive in parallel, but they will be aggregated in a single mailbox, and they
    will not be processed right away. The resource actor processes messages at its
    own pace, at its own time, whenever it has the resources and the processing time
    allocated to the underlying system. It is guaranteed that this actor will process
    the messages one at a time, and no two messages will be processed in parallel.
    Hence, we have a greatly increased level of thread safety.
  prefs: []
  type: TYPE_NORMAL
- en: Also, noticed that in the preceding diagram, we have a scenario that would cause
    a deadlock in the standard synchronization model. The first actor needs to access
    the file, and then it needs to access the log, and the second actor needs to access
    the log and then the file. Previously in this chapter, we discussed how this kind
    of situation yields the possibility of a deadlock. Here, the deadlock is no longer
    possible, since the resources are controlled by a single actor.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we had a brief overview of the motivation and the idea behind
    the actor model. We saw how the architecture of applications can be expressed
    in terms of what the actor model might look like. In the next chapter, we will
    dive deeper into the model and see how to use it in practice. We will learn some
    practical implementations and frameworks of the models that we can use in our
    projects right away.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How does the synchronization model work in synchronizing parallel computations?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does a deadlock occur? Describe a scenario in which a deadlock can occur.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the main abstractions and constraints of the actor model?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does the actor model help prevent the problems that usually arise under
    the synchronization model?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
