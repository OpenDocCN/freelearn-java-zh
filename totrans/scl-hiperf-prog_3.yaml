- en: Chapter 3. Unleashing Scala Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will look at Scala-specific constructs and language features,
    and examine how they can help or hurt performance. Equipped with our newly-acquired
    performance measurement knowledge, we will analyze how to use the rich language
    features that are provided by the Scala programming language better. For each
    feature, we will introduce it, show you how it compiles to bytecode, and then
    identify caveats and other considerations when using this feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout the chapter, we will show the Scala source code and generated bytecode
    that are emitted by the Scala compiler. It is necessary to inspect these artifacts
    to enrich your understanding of how Scala interacts with the JVM so that you can
    develop an intuition for the runtime performance of your software. We will inspect
    the bytecode by invoking the  `javap` Java disassembler after compiling the command,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The minus `c` switch prints the disassembled code. Another useful option is `-private`,
    which prints the bytecode of privately defined methods. For more information on `javap`,
    refer to the manual page. The examples that we will cover do not require in-depth
    JVM bytecode knowledge, but if you wish to learn more about bytecode operations,
    refer to Oracle's JVM specification at [http://docs.oracle.com/javase/specs/jvms/se7/html/jvms-3.html#jvms-3.4](http://docs.oracle.com/javase/specs/jvms/se7/html/jvms-3.html#jvms-3.4).
  prefs: []
  type: TYPE_NORMAL
- en: 'Periodically, we will also inspect a version of the Scala source code with
    Scala-specific features removed by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a useful way to see how the Scala compiler desugars convenient syntax
    into constructs that the JVM can execute. In this chapter, we will explore the
    following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Value classes and tagged types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specialization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tuples
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pattern matching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tail recursion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Option` data type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An alternative to `Option`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Value classes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 2](ch02.html "Chapter 2.  Measuring Performance on the JVM"), *Measuring
    Performance on the JVM*, we introduced the domain model of the order book application.
    This domain model included two classes, `Price` and `OrderId`. We pointed out
    that we created domain classes for `Price` and `OrderId` to provide contextual
    meanings to the wrapped `BigDecimal` and `Long`. While providing us with readable
    code and compilation time safety, this practice also increases the number of instances
    that are created by our application. Allocating memory and generating class instances
    create more work for the garbage collector by increasing the frequency of collections
    and by potentially introducing additional long-lived objects. The garbage collector
    will have to work harder to collect them, and this process may severely impact
    our latency.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, as of Scala 2.10, the `AnyVal` abstract class is available for developers
    to define their own value classes to solve this problem. The `AnyVal` class is
    defined in the Scala doc ([http://www.scala-lang.org/api/current/#scala.AnyVal](http://www.scala-lang.org/api/current/#scala.AnyVal))
    as, "the root class of all value types, which describe values not implemented
    as objects in the underlying host system." The `AnyVal` class can be used to define
    a value class, which receives special treatment from the compiler. Value classes
    are optimized at compile time to avoid the allocation of an instance, and instead
    they use the wrapped type.
  prefs: []
  type: TYPE_NORMAL
- en: Bytecode representation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As an example, to improve the performance of our order book, we can define
    `Price` and `OrderId` as value classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To illustrate the special treatment of value classes, we define a dummy method taking
    a `Price` value class and an `OrderId` value class as arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'From this definition, the compiler produces the following method signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We see that the generated signature takes a `BigDecimal` object and a `long`
    object, even though the Scala code allows us to take advantage of the types defined
    in our model. This means that we cannot use an instance of `BigDecimal` or `Long`
    when calling `printInfo` because the compiler will throw an error.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An interesting thing to notice is that the second parameter of `printInfo` is
    not compiled as `Long` (an object), but `long` (a primitive type, note the lower
    case 'l').  `Long` and other objects matching to primitive types, such as `Int`, `Float`
    or `Short`, are specially handled by the compiler to be represented by their primitive
    type at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: 'Value classes can also define methods. Let''s enrich our `Price` class, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Our new method allows us to compare two instances of `Price`. At compile time,
    a companion object is created for `Price`. This companion object defines a `lowerThan`
    method that takes two `BigDecimal` objects as parameters. In reality, when we
    call `lowerThan` on an instance of `Price`, the code is transformed by the compiler
    from an instance method call to a static method call that is defined in the companion
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'If we were to write the pseudo-code equivalent to the preceding Scala code,
    it would look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Performance considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Value classes are a great addition to our developer toolbox. They help us reduce
    the count of instances and spare some work for the garbage collector, while allowing
    us to rely on meaningful types that reflect our business abstractions. However,
    extending `AnyVal` comes with a certain set of conditions that the class must
    fulfill. For example, a value class may only have one primary constructor that
    takes one public `val` as a single parameter. Furthermore, this parameter cannot
    be a value class. We saw that value classes can define methods via `def`. Neither `val`
    nor `var` is allowed inside a value class. A nested class or object definitions
    are also impossible. Another limitation prevents value classes from extending
    anything other than a universal trait, that is, a trait that extends `Any`, only
    has `defs` as members, and performs no initialization. If any of these conditions
    are not fulfilled, the compiler generates an error. In addition to the preceding
    constraints that are listed, there are special cases in which a value class has
    to be instantiated by the JVM. Such cases include performing a pattern matching
    or runtime type test, or assigning a value class to an array. An example of the
    latter looks like the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The generated bytecode is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Notice how `mcVI$sp` is invoked from `newPriceArray`, and this creates a new
    instance of `ValueClasses$Price` at the `5` instruction.
  prefs: []
  type: TYPE_NORMAL
- en: As turning a single field case class into a value class is as trivial as extending
    the `AnyVal` trait, we recommend that you always use `AnyVal` wherever possible.
    The overhead is quite low, and it generate high benefits in terms of garbage collection's
    performance. To learn more about value classes, their limitations, and use cases,
    you can find detailed descriptions at [http://docs.scala-lang.org/overviews/core/value-classes.html](http://docs.scala-lang.org/overviews/core/value-classes.html).
  prefs: []
  type: TYPE_NORMAL
- en: Tagged types - an alternative to value classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Value classes are an easy to use tool, and they can yield great improvements
    in terms of performance. However, they come with a constraining set of conditions,
    which can make them impossible to use in certain cases. We will conclude this
    section with a glance at an interesting alternative by leveraging the tagged type
    feature that is implemented by the `Scalaz` library ([https://github.com/scalaz/scalaz](https://github.com/scalaz/scalaz)).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `Scalaz` implementation of tagged types is inspired by another Scala library,
    named `shapeless`. The `shapeless` library provides tools to write type-safe,
    generic code with minimal boilerplate. While we will not explore `shapeless`,
    we encourage you to learn more about the project at [https://github.com/milessabin/shapeless](https://github.com/milessabin/shapeless).
  prefs: []
  type: TYPE_NORMAL
- en: 'Tagged types are another way to enforce compile-type checking without incurring
    the cost of instance instantiation. They rely on the `Tagged` structural type
    and the `@@` type alias that are defined in the `Scalaz` library, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s rewrite part of our code to leverage tagged types with our `Price` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Let's perform a short walkthrough of the code snippet. We will define a `PriceTag`
    sealed trait that we will use to tag our instances, a `Price` type alias is created
    and defined as a `BigDecimal` object tagged with `PriceTag`. The `Price` object
    defines useful methods, including the `newPrice` factory function that is used
    to tag a given `BigDecimal` object and return a `Price` object (that is, a tagged `BigDecimal `object).
    We will also implement an equivalent to the `lowerThan` method. This function
    takes two `Price` objects (that is, two tagged `BigDecimal` objects), extracts
    the content of the tags that are two `BigDecimal` objects, and compares them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using our new `Price` type, we rewrite the same `newPriceArray` method that
    we previously looked at (the code is omitted for brevity, but you can refer to
    it in the attached source code), and print the following generated bytecode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'In this version, we no longer see an instantiation of `Price`, even though
    we are assigning it to an array. The tagged `Price` implementation involves a
    runtime cast, but we anticipate that the cost of this cast will be less than the
    instance allocations (and garbage collection) observed in the previous value class `Price` strategy.
    We will look  at tagged types again later in this chapter, and use them to replace
    a well-known tool of the standard library: the `Option`.'
  prefs: []
  type: TYPE_NORMAL
- en: Specialization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To understand the significance of specialization, it is important to first
    grasp the concept of object boxing. The JVM defines primitive types (`boolean`,
    `byte`, `char`, `float`, `int`, `long`, `short`, and `double`) that are stack-allocated
    rather than heap-allocated. When a generic type is introduced, for example, `scala.collection.immutable.List`,
    the JVM references an object equivalent, instead of a primitive type. In this
    example, an instantiated list of integers would be heap-allocated objects rather
    than integer primitives. The process of converting a primitive to its object equivalent
    is called boxing, and the reverse process is called unboxing. Boxing is a relevant
    concern for performance-sensitive programming because boxing involves heap allocation.
    In performance-sensitive code that performs numerical computations, the cost of
    boxing and unboxing can can create significant performance slowdowns. Consider
    the following example to illustrate boxing overhead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Creating the list via `fill` yields 10,000 heap allocations of the integer object.
    Performing the multiplication in `map` requires 10,000 unboxings to perform multiplication
    and then 10,000 boxings to add the multiplication result into the new list. From
    this simple example, you can imagine how critical section arithmetic will be slowed
    down due to boxing or unboxing operations.
  prefs: []
  type: TYPE_NORMAL
- en: As shown in Oracle's tutorial on boxing at [https://docs.oracle.com/javase/tutorial/java/data/autoboxing.html](https://docs.oracle.com/javase/tutorial/java/data/autoboxing.html),
    boxing in Java and also in Scala happens transparently. This means that, without
    careful profiling or bytecode analysis, it is difficult to discern where you are
    paying the cost for object boxing. To ameliorate this problem, Scala provides
    a feature named specialization. Specialization refers to the compile-time process
    of generating duplicate versions of a generic trait or class that refer directly
    to a primitive type instead of the associated object wrapper. At runtime, the
    compiler-generated version of the generic class (or, as it is commonly referred
    to, the specialized version of the class) is instantiated. This process eliminates
    the runtime cost of boxing primitives, which means that you can define generic
    abstractions while retaining the performance of a handwritten, specialized implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Bytecode representation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s look at a concrete example to better understand how the specialization
    process works. Consider a naive, generic representation of the number of shares
    purchased, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'For this example, let''s assume that the intended usage is to swap between
    an integer or long representation of `ShareCount`. With this definition, instantiating
    a long-based `ShareCount` instance incurs the cost of boxing, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This definition translates to the following bytecode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding bytecode, it is clear at instruction `5` that the primitive
    long value is boxed before instantiating the `ShareCount` instance. By introducing
    the `@specialized` annotation, we are able to eliminate the boxing by having the
    compiler provide an implementation of `ShareCount` that works with primitive long
    values. It is possible to specify which types you wish to specialize by supplying
    a set of types. As defined in the `Specializables` trait ([http://www.scala-lang.org/api/current/index.html#scala.Specializable"](http://www.scala-lang.org/api/current/index.html#scala.Specializable)),
    you are able to specialize for all JVM primitives, as well as, `Unit` and `AnyRef`.
    For our example, let''s specialize `ShareCount` for integers and longs, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'With this definition, the bytecode now becomes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The boxing disappears and is curiously replaced with a different class name,
    `ShareCount $mcJ$sp`. This is because we are invoking the compiler-generated version
    of `ShareCount` that is specialized for long values. By inspecting the output
    of `javap`, we see that the specialized class generated by the compiler is a subclass
    of `ShareCount`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Bear this specialization implementation detail in mind as we turn to the *Performance
    considerations* section. The use of inheritance forces tradeoffs to be made in
    more complex use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Performance considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At first glance, specialization appears to be a simple panacea for JVM boxing.
    However, there are several caveats to consider when using specialization. A liberal
    use of specialization leads to significant increases in compile time and resulting
    code size. Consider specializing `Function3`, which accepts three arguments as
    input and produces one result. To specialize four arguments across all types (that
    is, `Byte`, `Short`, `Int`, `Long`, `Char`, `Float`, `Double`, `Boolean`, `Unit`,
    and `AnyRef`) yields 10^4 or 10,000 possible permutations. For this reason, the
    standard library conserves the application of specialization. In your own use
    cases, consider carefully which types you wish to specialize. If we specialize `Function3` only
    for `Int` and `Long`, the number of generated classes shrinks to 2^4 or 16\. Specialization
    involving inheritance requires extra attention because it is trivial to lose specialization
    when extending a generic class. Consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In this scenario, you likely expect that `ChildFoo` is defined with a primitive
    integer. However, as `ChildFoo` does not mark its type with the `@specialized`
    annotation, zero specialized classes are created. Here is the bytecode to prove
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The next logical step is to add the `@specialized` annotation to the definition
    of `ChildFoo`. In doing so, we stumble across a scenario where the compiler warns
    about the use of specialization, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The compiler indicates that you have created a diamond inheritance problem,
    where the specialized versions of `ChildFoo` extend both `ChildFoo` and the associated
    specialized version of `ParentFoo`. This issue can be resolved by modeling the
    problem with a trait, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This definition compiles using a specialized version of `ChildBar`, as we originally
    were hoping for, as seen in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'An analogous and equally error-prone scenario is when a generic method is defined
    around a specialized type. Consider the following definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the definition of `create` is analogous to the child class from the inheritance
    example. Instances of `Foo` wrapping a primitive that are instantiated from the `create`
    method will be boxed. The following bytecode demonstrates how `boxed` leads to
    heap allocations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The solution is to apply the `@specialized` annotation at the call site, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'One final interesting scenario is when specialization is used with multiple
    types and one of the types extends `AnyRef` or is a value class. To illustrate
    this scenario, consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: In this example, which methods do you expect to box the second argument to `Container2`?
    For brevity, we omit the bytecode, but you can easily inspect it yourself. As
    it turns out, `shareCount` and `executionCount` box the integer. The compiler
    does not generate a specialized version of `Container2` that accepts a primitive
    integer and a value extending `AnyVal` (for example, `ExecutionCount`). The `shareCount` method also
    causes boxing due to the order in which the compiler removes the value class type
    information from the source code. In both scenarios, the workaround is to define
    a case class that is specific to a set of types (for example, `ShareCount` and `Int`).
    Removing the generics allows the compiler to select the primitive types.
  prefs: []
  type: TYPE_NORMAL
- en: The conclusion to draw from these examples is that specialization requires extra
    focus to be used throughout an application without boxing. As the compiler is
    unable to infer scenarios where you accidentally forgot to apply the `@specialized`
    annotation, it fails to raise a warning. This places the onus on you to be vigilant
    about profiling and inspecting bytecode to detect scenarios where specialization
    is incidentally dropped.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To combat some of the shortcomings that specialization brings, there is a compiler
    plugin under active development, named miniboxing, at [http://scala-miniboxing.org/](http://scala-miniboxing.org/).
    This compiler plugin applies a different strategy that involves encoding all primitive
    types into a long value and carrying metadata to recall the original type. For
    example, `boolean` can be represented in a `long` using a single bit to signal
    true or false. With this approach, performance is qualitatively similar to specialization
    while producing orders of magnitude fewer classes for large permutations. Additionally,
    miniboxing is able to more robustly handle inheritance scenarios and can warn
    when boxing will occur. While the implementations of specialization and miniboxing
    differ, the end user usage is quite similar. Like specialization, you must add
    appropriate annotations to activate the miniboxing plugin. To learn more about
    the plugin, you can view the tutorials on the miniboxing project site.
  prefs: []
  type: TYPE_NORMAL
- en: 'The extra focus to ensure specialization produces heap allocation free code
    is worthwhile because of the performance wins in performance-sensitive code. To
    drive home the value of specialization, consider the following microbenchmark
    that computes the cost of a trade by multiplying share count with execution price.
    For simplicity, primitive types are used directly instead of value classes. Of
    course, in production code this would never happen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'In this benchmark, two versions of a generic execution class are defined. `SpecializedExecution`
    incurs zero boxing when computing the total cost because of specialization, while `BoxingExecution`
    requires object boxing and unboxing to perform the arithmetic. The microbenchmark
    is invoked with the following parameterization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We configure this JMH benchmark via annotations that are placed at the class
    level in the code. This is different from what we saw in [Chapter 2](ch02.html
    "Chapter 2.  Measuring Performance on the JVM"), *Measuring Performance on the
    JVM,* where we used command-line arguments. Annotations have the advantage of
    setting proper defaults for your benchmark, and simplifying the command-line invocation.
    It is still possible to override the values in the annotation with command-line
    arguments. We use the  `-foe` command-line argument to enable failure on error
    because there is no annotation to control this behavior. In the rest of this book,
    we will parameterize JMH with annotations and omit the annotations in the code
    samples because we always use the same values.
  prefs: []
  type: TYPE_NORMAL
- en: 'The results are summarized in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Benchmark** | **Throughput (ops per second)** | **Error as percentage of
    throughput** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `boxed` | 251,534,293.11 | ±2.23 |'
  prefs: []
  type: TYPE_TB
- en: '| `specialized` | 302,371,879.84 | ±0.87 |'
  prefs: []
  type: TYPE_TB
- en: This microbenchmark indicates that the specialized implementation yields approximately
    17% higher throughput. By eliminating boxing in a critical section of the code,
    there is an order of magnitude performance improvement available through the judicious
    usage of specialization. For performance-sensitive arithmetic, this benchmark
    provides justification for the extra effort that is required to ensure that specialization
    is applied properly.
  prefs: []
  type: TYPE_NORMAL
- en: Tuples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First-class tuple support in Scala simplifies use cases where multiple values
    need to be grouped together. With tuples, you can elegantly return multiple values
    using a concise syntax without defining a case class. The following section shows
    how the compiler translates Scala tuples.
  prefs: []
  type: TYPE_NORMAL
- en: Bytecode representation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s look at how the JVM handles creating a tuple to understand how the JVM
    supports tuples better. To develop our intuition, consider creating a tuple with
    an arity of two, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The corresponding bytecode for this method is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This bytecode shows that the compiler desugared the parenthesis tuple definition
    syntax into the allocation of a class named `Tuple2`. There is a tuple class that
    is defined for each supported arity (for example, `Tuple5` supports five members)
    up to `Tuple22`. The bytecode also shows at the  `4` and `5` instructions that
    the primitive versions of `Int` and `Double` are used to allocate this `tuple`
    instance.
  prefs: []
  type: TYPE_NORMAL
- en: Performance considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the preceding example, `Tuple2` avoids the boxing of primitives due to specialization
    on the two generic types. It is often convenient to tuple multiple values together
    because of Scala''s expressive tupling syntax. However, this leads to excessive
    memory allocation because tuples with an arity larger than two are not specialized.
    Here is an example to illustrate this concern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This definition is analogous to the first tuple definition that we reviewed,
    except that there is now an arity of three. This definition produces the following
    bytecode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: In this bytecode, the absence of specialization is clear because of the presence
    of integer and double boxing. If you are working on a performance-sensitive region
    of your application and find occurrences of tuples with an arity of three or larger,
    you should consider defining a case class to avoid the boxing overhead. The definition
    of your case class will not have any generics. This enables the JVM to use primitives
    instead of allocating objects on the heap for the primitive tuple members.
  prefs: []
  type: TYPE_NORMAL
- en: 'Even when using `Tuple2`, it is still possible that you are incurring the cost
    of boxing. Consider the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Given what we know about the bytecode representation of Tuple2 and value classes,
    we expect the bytecode for this method to be two stack-allocated integers. Unfortunately,
    in this case, the resulting bytecode is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding bytecode, we see that the integer is boxed and an instance
    of Bar is instantiated. This example is analogous to the final specialization
    example that we investigated involving `Container2`. Looking back at that example,
    it should be evident that `Container2` is a close analog to Tuple2\. As before,
    due to how specialization is implemented by the compiler, the compiler is unable
    to avoid boxing in this scenario. If you are faced with performance-sensitive
    code, the workaround remains defining a case class. Here is proof that defining
    a case class erases the undesired value class instantiation and primitive boxing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'This definition produces the following bytecode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Note that `IntBar` is not defined as a value class because it has two parameters.
    In contrast to the tuple definition, there is neither boxing nor any reference
    to the `Bar` value class. In this scenario, defining a case class is a performance
    win for performance-sensitive code.
  prefs: []
  type: TYPE_NORMAL
- en: Pattern matching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For programmers who are new to Scala, pattern matching is often one of the language
    features that is the simplest to understand, but it also unlocks new ways to think
    about writing software. This powerful mechanism enables you to match on disparate
    types with compile-time safety using an elegant syntax. Given how central this
    technique is to writing Scala in the functional paradigm, it is important to consider
    its runtime overhead.
  prefs: []
  type: TYPE_NORMAL
- en: Bytecode representation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s consider an example that involves order processing with an algebraic
    data type representing the possible sides of an order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The terminology **algebraic data type** (**ADT**) is a more formal way of referring
    to a sealed trait and its cases. For example, `Side`, `Buy`, and `Sell` form an
    ADT. For our purposes, an ADT defines a closed set of cases. For `Side`, the enclosed
    cases are `Buy` and `Sell`. The sealed modifier provides closed set semantics
    because it disallows the extension of `Side` in separate source files. The closed
    set semantics implied by an ADT is what allows the compiler to infer whether or
    not a pattern match statement is exhaustive. If you are interested in studying
    another example of an ADT, view the order book commands defined in [Chapter](ch02.html
    "Chapter 2.  Measuring Performance on the JVM") [2](ch02.html "Chapter 2.  Measuring
    Performance on the JVM"), *Measuring Performance on the JVM*.
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the following bytecode, pattern matching is desugared into a set
    of if statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Inspecting the bytecode shows how the Scala compiler is able to desugar pattern
    match expressions into a set of efficient if statements with the `ifeq` instructions
    at the `9` and `24` indexes. This an illustrative example of how Scala is able
    to provide expressive and elegant first-class language features that retain efficient
    bytecode equivalents.
  prefs: []
  type: TYPE_NORMAL
- en: Performance considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Pattern matching against values that contain state (for example, a case class)
    imposes additional runtime costs that are not immediately clear when looking at
    the Scala source code. Consider the following extension to the previous example
    that introduces state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the example is more complicated because the instance type must be identified
    for all three cases with the added complexity of a predicate on the `BuyOrder`
    price in the first case. In the following, we look at a snippet of the `scalac`
    output with all Scala-specific features removed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This desugaring illustrates several interesting points about the Scala compiler.
    Identifying the type of `Order` utilizes `isInstanceOf` from `java.lang.Object`,
    which maps to the `instanceOf` bytecode instruction. Casting, by way of `asInstanceOf`,
    coerces the `Order` into either a `BuyOrder` price or a `SellOrder`.  The first
    takeaway is that pattern matching types carrying state incurs the runtime cost
    of type-checking and casting.
  prefs: []
  type: TYPE_NORMAL
- en: A second insight is that the Scala compiler is able to optimize away the instance
    checking for the second pattern match by creating a Boolean variable named `rc8`
    to determine whether a `BuyOrder` was discovered. This neat optimization is simple
    to handwrite, but it removes the elegance and simplicity of pattern matching.
    This is another example of how the compiler is able to produce efficient bytecode
    from expressive, high-level code.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the preceding examples, it is now clear that pattern matches are compiled
    to if statements. One performance consideration for critical path code is the
    ordering of pattern match statements. If your code has five pattern match statements
    and the fifth pattern is the most frequently accessed, then your code is paying
    the price of always evaluating four other branches. Let''s devise a JMH microbenchmark
    that estimates the linear access cost of pattern matching. Each benchmark defines
    ten pattern matches using different values (for example, the value class, the
    integer literal, the case class, and so on). For each benchmark, the matched index
    is swept to show the cost of accessing the first, the fifth, and the the tenth
    pattern match statement. Here is the benchmark definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Performance was evaluated by running 30 trials, each lasting 10 seconds with
    three warm-up trials, each lasting 5 seconds. Here is the benchmark invocation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are summarized in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Benchmark** | **Index to match** | **Throughput (ops per second)** | **Error
    as percentage of throughput** | **Throughput change as percentage of base run**
    |'
  prefs: []
  type: TYPE_TB
- en: '| `matchAnyVal` | 1 | 350,568,900.12 | ±3.02 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| `matchAnyVal` | 5 | 291,126,287.45 | ±2.63 | -17 |'
  prefs: []
  type: TYPE_TB
- en: '| `matchAnyVal` | 10 | 238,326,567.59 | ±2.95 | -32 |'
  prefs: []
  type: TYPE_TB
- en: '| `matchCaseClass` | 1 | 356,567,498.69 | ±3.66 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| `matchCaseClass` | 5 | 287,597,483.22 | ±3.50 | -19 |'
  prefs: []
  type: TYPE_TB
- en: '| `matchCaseClass` | 10 | 234,989,504.60 | ±2.60 | -34 |'
  prefs: []
  type: TYPE_TB
- en: '| `matchIntLiterals` | 1 | 304,242,630.15 | ±2.95 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| `matchIntLiterals` | 5 | 314,588,776.07 | ±3.70 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| `matchIntLiterals` | 10 | 285,227,574.79 | ±4.33 | -6 |'
  prefs: []
  type: TYPE_TB
- en: '| `matchIntVariables` | 1 | 332,377,617.36 | ±3.28 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| `matchIntVariables` | 5 | 263,835,356.53 | ±6.53 | -21 |'
  prefs: []
  type: TYPE_TB
- en: '| `matchIntVariables` | 10 | 170,460,049.63 | ±4.20 | -49 |'
  prefs: []
  type: TYPE_TB
- en: 'The last column takes the first trial of each benchmark when matching the first
    index as the base case. For trials matching the fifth and tenth indexes, the relative
    performance drop is displayed. In every case, except matching the fifth index
    of literal integers, throughput degrades nearly linearly as deeper indexes are
    matched. The one trial that defies this pattern is the trial matching literal
    integers. In this trial, performance improves relative to the first index when
    accessing the fifth index. Upon inspection of the bytecode, we discover that this
    scenario produces a jump table instead of a set of if statements. Here is a snippet
    from the generated bytecode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: This bytecode snippet demonstrates that the JVM converts a pattern match on
    integer literals to a jump table using the `tableswitch` instruction. This is
    a constant time operation rather than a linear traversal of if statements. Given
    that the observed error is several percentage points and the observed differences
    across the three trials are roughly several percentage points, we can deduce that
    the linear access cost does not apply to this scenario. Instead, matching literal
    integers at the N^(th) index has a constant access cost due to the generated jump
    table. In contrast, matching an integer variable proves to be nearly twice as
    expensive at the tenth index. The clear takeaway from this experiment is that,
    for any pattern match that is generating a series of if statements, there is a
    linear cost to access the N^(th) pattern match statement. If you pattern match
    at least three cases in performance-sensitive code, consider reviewing the code
    to determine whether the statement order matches the access frequency.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Do you have examples of pattern matching containing only two patterns? In scenarios
    involving only two pattern match statements that directly match a value, the compiler
    is able to generate an efficient jump table. When matching primitive literals
    (for example, string literals or integer literals), the compiler is able to generate
    jump tables for larger pattern matches. Analogous to the `@tailrec` annotation,
    Scala defines a `@switch` annotation for you to indicate to the compiler that
    you expect this pattern match statement to be compiled to a jump table. If the
    compiler is unable to generate a jump table, and instead it produces a series
    of if statements, then a warning will be issued. Like the `@tailrec` annotation,
    the compiler will apply the jump table heuristic whether you provide the `@switch`
    annotation or not. In practice, we do not often use this annotation because of
    its limited applicability, but it is worthwhile to be aware of its existence.
    The following is an example of an annotated pattern match that compiles to a jump table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Tail recursion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A function is said to be recursive when it calls itself. Recursion is a powerful
    tool, and it is often used in functional programming. It allows you to break complex
    problems into smaller subproblems, making them easier to reason through and solve.
    Recursion also works well with the idea of immutability. Recursive functions provide
    us with a good way to manage changing state without using mutable structures or
    reassignable variables. In this section, we focus on the different shortcomings
    of using recursion on the JVM, and especially in Scala.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at a simple example of a recursive method. The following
    snippet shows a `sum` method that is used to calculate the sum of a list of integers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The `sum` method presented in the preceding code snippet performs what is called
    head-recursion. The `sum(xs)` recursive call is not the last instruction in the
    function. This method needs the result of the recursive call to compute its own
    result. Consider the following call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'It can be represented as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Note how each time we perform a recursive call, our function is left hanging,
    waiting for the right side of the computation to finish to be able to return.
    As the calling function needs to complete its own computation after receiving
    the result of the recursive call, a new entry is added to the stack for each call.
    The stack has a limited size, and nothing prevents us from calling `sum` with
    a very long list. With a sufficiently long list, a call to `sum` would result
    in a `StackOverflowError`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: The stack trace shows all the recursive calls piling up on the stack, waiting
    for the result from the following step. This proves that none of the calls to
    sum were able to complete without first completing the recursive call. Our stack
    ran out of space before the last call could be performed.
  prefs: []
  type: TYPE_NORMAL
- en: 'To avoid this problem, we need to refactor our method to make it tail-recursive.
    A recursive method is said to be tail-recursive if the recursive call is the last
    instruction performed. A tail-recursive method can be optimized to turn the series
    of recursive calls into something similar to a `while` loop. This means that only
    the first call is added to the stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'This new version of `sum` is tail-recursive. Note that we create an internal
    `loop` method, which takes the list to sum, as well as an accumulator to compute
    the current state of the result. The `loop` method is tail-recursive because the
    recursive `loop(xs, acc+x)` call is the last instruction. By calculating the accumulator
    as we iterate, we avoid stacking recursive calls. The initial accumulator value
    is `0`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We mentioned that recursion is an important aspect of functional programming.
    However, in practice, you should only rarely have to write your own recursive
    method, especially when dealing with collections such as `List`. The standard
    API provides already optimized methods that should be preferred. For example,
    calculating the sum of a list of integers can be written, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`list.foldLeft(0)((acc, x) => acc + x)` Or when taking advantage of Scala sugar,
    we can use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`list.foldLeft(0)(+)` The `foldLeft` function is internally implemented with
    a `while` loop and will not cause a `aStackOverflowError` exception.'
  prefs: []
  type: TYPE_NORMAL
- en: Actually, `List` has a `sum` method, which makes calculating the sum of a list
    of integers even easier. The `sum` method is implemented with `foldLeft` and is
    similar to the preceding code.
  prefs: []
  type: TYPE_NORMAL
- en: Bytecode representation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As a matter of fact, the JVM does not support tail-recursion optimization. To
    make this work, the Scala compiler optimizes tail-recursive methods at compile
    time and turns them into a `while` loop. Let's compare the bytecode that was generated
    for each implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our original, head-recursive `sum` method compiled into the following bytecode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'While the tail recursive `loop` method produced the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Note how the `sum` method calls itself with the `invokevirtual` instruction
    at the `52` index and still has to perform some instructions with the returned
    value. On the contrary, the `loop` method uses a `goto` instruction at the `60`
    index to jump back to the beginning of its block, thus avoiding stacking several
    recursive calls to itself.
  prefs: []
  type: TYPE_NORMAL
- en: Performance considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The compiler can only optimize simple tail-recursion cases. Specifically, only
    self-calling functions where the recursive call is the last instruction. There
    are many edge cases that could be described as tail-recursive, but they are too
    complex for the compiler to optimize. To avoid unknowingly writing a nonoptimizable
    recursive method, you should always annotate your tail-recursive methods with
    `@tailrec`. The `@tailrec` annotation is a way to tell the compiler, "I believe
    you will be able to optimize this recursive method; however, if you cannot, please
    give me an error at compile time." One thing to keep in mind is that `@tailrec`
    is not asking the compiler to optimize the method, it will do so anyway if it
    is possible. The annotation is for the developer to make sure the compiler can
    optimize the recursion.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At this point, you should realize that all `while` loops can be replaced by
    a tail-recursive method without any loss in performance. If you have been using
    while loop constructs in Scala, you can reflect on how to replace them with a
    tail-recursive implementation. Tail recursion eliminates the use of mutable variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the same `tailrecSum` method with the `@tailrec` annotation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'If we attempted to annotate our first, head-recursive, implementation, we would
    see the following error at compile time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'We recommend always using `@tailrec` to ensure that your methods can be optimized
    by the compiler. As the compiler is only able to optimize simple cases of tail-recursion,
    it is important to ensure at compile time that you did not inadvertently write
    a nonoptimizable function that may cause a `StackOverflowError` exception. We
    now look at a few cases where the compiler is not able to optimize a recursive
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The `loop` method in `sum2` cannot be optimized because the recursion involves
    two different methods calling each other. If we were to replace the call to `info`
    by its actual implementation, then the optimization would be possible, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'A somewhat similar use case involves the compiler''s inability to take into
    account by-name parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The `read` method cannot  be optimized by the compiler because it is unable
    to use the definition of `Option.fold` to understand that the recursive call is
    effectively in the tail position. If we replace the call to fold by its exact
    implementation, we can annotate the method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The compiler will also refuse to optimize a nonfinal public method. This is
    to prevent the risk of a subclass overriding the method with a non-tail-recursive
    version. A recursive call from the super class may go through the subclass''s
    implementation and break the tail-recursion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Attempting to flag the `printMessageNTimes` method as tail-recursive yields
    the following error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Another case of recursive methods that cannot be optimized is when the recursive
    call is part of a try/catch block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'In contrast to the prior examples, in this example the compiler is not to blame.
    The recursive call is not in the tail position. As it is surrounded by a try/catch,
    the method needs to be ready to receive a potential exception and perform more
    computations to address it. As proof, we can look at the generated bytecode and
    observe that the last instructions are related to the try/catch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: We hope that these few examples have convinced you that writing a non-tail-recursive
    method is an easy mistake to make. Your best defense against this is to always
    use the `@tailrec` annotation to verify your intuition that your method can be
    optimized.
  prefs: []
  type: TYPE_NORMAL
- en: The Option data type
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `Option` data type is used pervasively throughout the Scala standard library.
    Like pattern matching, it is a language feature often adopted early by Scala beginners.
    The `Option` data type provides an elegant way to transform and handle values
    that are not required, doing away with null checks often found in Java code. We
    assume you understand and appreciate the value that `Option` brings to writing
    Scala in the functional paradigm, so we will not reiterate its benefits further.
    Instead, we focus on analyzing its bytecode representation to drive performance
    insights.
  prefs: []
  type: TYPE_NORMAL
- en: Bytecode representation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Inspecting the Scala source code, we see that `Option` is implemented as an
    abstract class with the possible outcomes, `Some` and `None`, extending `Option`
    to encode this relationship. The class definitions with implementations removed
    are shown for convenience in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Studying the definitions, we can infer several points about the bytecode representation.
    Focusing on `Some`, we note the absence of extending `AnyVal`. As `Option` is
    implemented using inheritance, `Some` cannot be a value class due to limitations
    that we covered in the Value class section. This limitation implies that there
    is an allocation for each value wrapped as a `Some` instance. Furthermore, we
    observe that `Some` is not specialized. From our examination of specialization,
    we realize that primitives wrapped as `Some` instances will be boxed. Here is
    a simple example to illustrate both concerns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'In this trivial example, an integer is encoded as a `Some` instance to be used
    as an `Option` data type. The following bytecode is produced:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: As we expected, there is an object allocation to create a `Some` instance, followed
    by the boxing of the provided integer to construct the `Some` instance.
  prefs: []
  type: TYPE_NORMAL
- en: The `None` instance is a simpler case to understand from the bytecode perspective.
    As `None` is defined as a Scala object, there is no instantiation cost to create
    a `None` instance. This makes sense because `None` represents a scenario where
    there is no state to maintain.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Have you ever considered how the single value, `None`, represents no value for
    all the types? The answer lies in understanding the `Nothing` type. The `Nothing`
    type extends all other types, which allows `None` to be a subtype of any  `A`
    type. For more insight into the Scala type hierarchy, view this useful Scala language
    tutorial at [http://docs.scala-lang.org/tutorials/tour/unified-types.html](http://docs.scala-lang.org/tutorials/tour/unified-types.html).
  prefs: []
  type: TYPE_NORMAL
- en: Performance considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In any non-performance-sensitive environments, it is sensible to default to
    using `Option` to represent values that are not required. In a performance-sensitive
    area of the code, the choice becomes more challenging and less clear-cut. Particularly
    in performance-sensitive code, you must first optimize for correctness and then
    performance. We suggest always implementing the first version of the problem that
    you are modeling in the most idiomatic style, which is to say, using `Option`.
    Using the awareness gained from the bytecode representation of `Some`, the logical
    next step is to profile in order to determine whether or not `Option` use is the
    bottleneck. In particular, you are focusing on memory allocation patterns and
    garbage collection costs. In our experience, there are often other overhead sources
    present in the code that are more costly than `Option` use. Examples include inefficient
    algorithm implementation, a poorly constructed domain model, or inefficient use
    of system resources. If, in your case, you have eliminated other sources of inefficiency
    and are positive that `Option` is the source of your performance woes, then you
    need to take further steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'An incremental step towards improved performance might include removing use
    of the `Option` higher-order functions. On the critical path, there can be significant
    cost savings by replacing higher-order functions with inlined equivalents. Consider
    the following trivial example that transforms an `Option` data type into a `String` data
    type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'On the critical path, the following change may yield substantive improvements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Replacing the `fold` operation with an if statement saves the cost of creating
    an anonymous function. It bears repeating that this type of change should only
    ever be considered after extensive profiling reveals `Option` usage to be the
    bottleneck. While this type of code change is likely to improve your performance,
    it is verbose and unsafe due to usage of `o.get`. When this technique is used
    judiciously, you may be able to retain use of the `Option` data type in critical
    path code.
  prefs: []
  type: TYPE_NORMAL
- en: If replacing higher-order `Option` function use with inlined and unsafe equivalents
    fails to sufficiently improve performance, then you need to consider more drastic
    measures. At this point, profiling should reveal that `Option` memory allocation
    is the bottleneck, preventing you from reaching your performance goals. Faced
    with this scenario, you have two options (pun intended!) to explore, both of which
    involve a high cost in terms of time to implement.
  prefs: []
  type: TYPE_NORMAL
- en: One way to proceed is to admit that, for the critical path, `Option` is unsuitable
    and must be removed from the type signatures and replaced with null checks. This
    is the most performant approach, but it brings significant maintenance costs because
    you and all other team members working on the critical path must be cognizant
    of this modeling decision. If you choose to proceed this way, define clear boundaries
    for the critical path to isolate null checks to the smallest possible region of
    the code. In the next section, we explore a second approach that involves building
    a new data type that leverages the knowledge that we gained in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Case study – a more performant option
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you are not yet ready to lose information that is encoded by the `Option`
    data type, then you may wish to explore alternative implementations of `Option`
    that are more garbage-collection-friendly. In this section, we present an alternative
    approach that also provides type-safety while avoiding boxing and instantiation
    of the `Some` instances. We leverage tagged types and specialization, and disallow
    null as a valid value for `Some` to come up with the following implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: This implementation defines factory methods to construct optional types (that
    is, `some`, `nullCheckingSome`, and `none`). In contrast to Scala's `Option`,
    this implementation uses tagged types to add type information to a value rather
    than creating a new value to encode optionality. The implementation of `none`
    takes advantage of `null` being a value in Scala rather than a language in keyword
    as is the case in Java. Remember, unless performance requirements required such
    extreme measures, we would not default to these more esoteric approaches. The
    tagged type returned by each factory method preserves type-safety, and it requires
    an explicit unwrapping to access the underlying type.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you would like to learn more about Scala's representation of the `null` value,
    we encourage you to check out these two StackOverflow posts at [http://stackoverflow.com/questions/8285916/why-doesnt-null-asinstanceofint-throw-a-nullpointerexception](http://stackoverflow.com/questions/8285916/why-doesnt-null-asinstanceofint-throw-a-nullpointerexception) and
    [http://stackoverflow.com/questions/10749010/if-an-int-cant-be-null-what-does-null-asinstanceofint-mean](http://stackoverflow.com/questions/10749010/if-an-int-cant-be-null-what-does-null-asinstanceofint-mean). In
    both posts, multiple responders provide excellent responses that will help you
    deepen your understanding.
  prefs: []
  type: TYPE_NORMAL
- en: The remaining methods in `OptOps` define methods that you would find in the
    implementation of Scala's `Option`. Rather than instance methods, we see that
    the methods are static because there are no new instances that are allocated by
    the factory methods. It is possible to define an implicit class that would provide
    a syntax emulating instance method invocation, but we avoid doing this because
    we are operating under the assumption of extreme performance sensitivity. Semantically,
    the operations that are defined in `OptOps` are equivalent to the Scala `Option`
    analogs. Instead of matching against a value representing no value (that is, `None`),
    we again take advantage of the ability to reference `null` as a value.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this implementation, the runtime overhead consists of instance checking
    and invocations of `scalaz.Tag`. We lose the ability to pattern match, and instead
    we must either fold or, in extreme cases, use `isSome` and `unsafeGet`. To get
    a better understanding of runtime differences, we microbenchmarked `Option` creation
    using Scala''s `Option` and the preceding tagged type implementation. The microbenchmark
    gives you a taste for the change in syntax. We encourage you to run `javap` to
    disassemble the bytecode in order to prove to yourself that this implementation
    avoids boxing and object creation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'We run the test with the following familiar parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are summarized in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Benchmark** | **Throughput (ops per second)** | **Error as percentage of
    throughput** |'
  prefs: []
  type: TYPE_TB
- en: '| `optNone` | 351,536,523.84 | ±0.75 |'
  prefs: []
  type: TYPE_TB
- en: '| `optNoneReuse` | 344,201,145.90 | ±0.23 |'
  prefs: []
  type: TYPE_TB
- en: '| `optSome` | 232,684,849.83 | ±0.37 |'
  prefs: []
  type: TYPE_TB
- en: '| `optSomeWithNullChecking` | 233,432,224.39 | ±0.28 |'
  prefs: []
  type: TYPE_TB
- en: '| `scalaNone` | 345,826,731.05 | ±0.35 |'
  prefs: []
  type: TYPE_TB
- en: '| `scalaSome` | 133,583,718.28 | ±0.24 |'
  prefs: []
  type: TYPE_TB
- en: 'Perhaps the most impressive result here is that throughput increases approximately
    57% when using the tagged type implementation of `Some` over the Scala-provided
    implementation. This is likely due to reduced memory allocation pressure. We see
    that `None` creation throughput is qualitatively similar. We also observe that
    there appears to be zero cost to add a null check in the construction of a tagged `Some`
    option. If you trust your team to avoid passing around null values, then the check
    is superfluous. We also created a set of benchmarks to evaluate fold performance
    to get a sense of the relative cost of using this alternative `Option` implementation.
    Here is the source code for a simple fold benchmark:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'This benchmark was run using the same set of parameters as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'The results of this test are summarized in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Benchmark** | **Throughput (ops per second)** | **Error as percentage of
    throughput** |'
  prefs: []
  type: TYPE_TB
- en: '| `optOption` | 346,208,759.51 | ±1.07 |'
  prefs: []
  type: TYPE_TB
- en: '| `scalaOption` | 306,325,098.74 | ±0.41 |'
  prefs: []
  type: TYPE_TB
- en: In this benchmark we are hoping to prove that there is no significant throughput
    degradation when using the alternative tagged type-inspired implementation over
    the Scala `Option`. A significant degradation in performance would jeopardize
    the performance wins that we found in the creation benchmark. Fortunately, this
    benchmark suggests fold throughput actually increases approximately 13% over the
    Scala `Option` fold implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is a relief to see benchmarking yield results that confirm your hypothesis.
    However, it is equally important to understand why favorable results were produced,
    and to be able to explain this. Without an understanding of how these results
    happened, you are unlikely to be able to reproduce the results. How would you
    explain fold throughput improvement of the tagged type-inspired implementation
    over the Scala `Option` implementation? Consider the implementation and memory
    allocation differences that we covered.
  prefs: []
  type: TYPE_NORMAL
- en: The benchmarks suggest that the tagged type-inspired `Option` implementation
    yields qualitative performance improvements over the Scala `Option` implementation.
    If you are faced with a performance issue and profiling reveals the Scala `Option`
    to be the bottleneck, it may make sense to explore this alternative implementation.
    While the performance improves, realize that a tradeoff exists. When using the
    alternative implementation, you lose the ability to pattern match. This seems
    like a small price to pay because you are able to instead use the fold operation.
    The higher price to pay is integration with the standard library and third-party
    libraries. If your critical path code interacts heavily with the Scala standard
    library or a third-party library, you will be forced to rewrite significant chunks
    of code to use the alternative `Option` implementation. In this scenario, if you
    are under time pressure, it may make sense to reconsider whether or not modeling
    parts of the domain with `null` is sensible. If your critical path code avoids
    significant interaction with the Scala standard library or third-party libraries,
    then using the alternative `Option` implementation might be an easier decision.
  prefs: []
  type: TYPE_NORMAL
- en: Our case study is inspired by a novel approach Alexandre Bertails explores in
    his blog post at [https://bertails.org/2015/02/15/abstract-algebraic-data-type/](https://bertails.org/2015/02/15/abstract-algebraic-data-type/).
    He solves the same performance issues that we addressed by defining an approach
    that he refers to as abstract algebraic data types. Both approaches rely on using
    type constraints to model `Option` without instance allocation. By abstracting
    over the `Option` algebraic data type and its operations, he is able to devise
    an implementation free of allocations and boxing. We encourage you to explore
    this approach because it is another great example of how to achieve safety while
    still providing excellent performance.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we dived into the bytecode representation and performance considerations
    of commonly-used Scala language features. In our case study, you saw first-hand
    how you can combine several areas of knowledge about Scala language features in
    combination with the excellent Scalaz library to produce an `Option` implementation
    that is better suited for high-performance needs.
  prefs: []
  type: TYPE_NORMAL
- en: A consistent theme across all our examples is to promote type-safety and correctness
    while taking into account performance tradeoffs. As functional programmers, we
    value compile time correctness and referential transparency. Even with the usage
    of `null` in the tagged type `Option` implementation, we preserved correctness
    because the `null` value is an internal implementation detail. When you reflect
    on the strategies that we covered, consider how each one preserves referentially
    transparent (that is, side-effect-free) code while still enabling you to reach
    your performance goals.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you should feel more confident about the tradeoffs that are introduced
    by Scala's elegant language features. Through our analysis, you learned how to
    translate from concise Scala syntax to JVM bytecode. This is an invaluable skill
    to debug performance issues. As you practice your awareness by studying more examples,
    you will develop a stronger intuition for where potential problems lie. Over time,
    you can refer back to this chapter in order to review common remediation strategies
    to balance the tradeoff between elegance and safety with performance. In the next
    chapter, we will continue to grow our ability to leverage Scala to write performant,
    functional code by diving into collections.
  prefs: []
  type: TYPE_NORMAL
