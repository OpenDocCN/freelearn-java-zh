- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Architecting Distributed Systems – Challenges and Anti-Patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In today’s digital landscape, the demand for scalable and reliable systems has
    led to the widespread adoption of distributed systems. These complex networks
    of interconnected components are designed to handle large-scale data processing,
    storage, and communication across multiple machines or nodes. However, architecting
    distributed systems comes with a unique set of challenges and pitfalls.
  prefs: []
  type: TYPE_NORMAL
- en: Building distributed systems aims to achieve high availability, fault tolerance,
    and better performance and scalability while distributing the workload across
    multiple nodes. However, the complexity of these systems often gives rise to various
    challenges that architects and developers must overcome. From ensuring data consistency
    and synchronization to managing network latency and optimizing performance, numerous
    factors should be considered when designing a distributed system.
  prefs: []
  type: TYPE_NORMAL
- en: One of the critical challenges in architecting distributed systems is achieving
    proper data consistency. Maintaining the integrity and coherence of data across
    different nodes is crucial, but it becomes increasingly challenging as the system
    scales. Ensuring that all replicas of a given piece of data are updated correctly
    and simultaneously poses a significant challenge and often requires implementing
    complex synchronization mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: Another challenge lies in managing network latency and communication overhead.
    In a distributed system, nodes communicate with each other over a network, and
    the time taken for messages to traverse the network can introduce delays and bottlenecks.
    Architects must carefully design communication protocols and choose appropriate
    network technologies to minimize latency and maximize system performance.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability is a critical consideration when architecting distributed systems.
    As the demand for resources and processing power grows, the system should scale
    horizontally by adding more nodes seamlessly. Achieving this scalability while
    maintaining performance and avoiding bottlenecks is a complex task that requires
    careful planning and architectural decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Despite these challenges, architects must also be aware of common anti-patterns
    that can undermine the effectiveness and reliability of distributed systems. Anti-patterns
    are recurring design or implementation practices that are considered suboptimal
    or counterproductive. These can include network congestion, single points of failure,
    improper load balancing, or overreliance on a central coordinator. Recognizing
    and avoiding these anti-patterns is crucial to ensuring the successful operation
    of distributed systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will explore the pitfalls of modern architecture when we
    talk about distributed systems:'
  prefs: []
  type: TYPE_NORMAL
- en: Data integration scales and distributed transactions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dual-write anti-pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservices and shared databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eventual consistency problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will delve into the challenges architects face when designing distributed
    systems and explore common anti-patterns that can arise during the process. By
    understanding these challenges and avoiding the pitfalls, architects and developers
    can create robust and efficient distributed systems that meet the demands of modern
    applications. Through best practices and practical insights, we aim to equip you
    with the knowledge and tools to architect distributed systems and mitigate potential
    risks effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Data integration scales and distributed transactions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data integration is critical to building distributed systems, where disparate
    data sources must be harmonized and accessible to various system components. As
    the scale of data and the number of distributed nodes increase, the challenges
    associated with data integration becomes more challenging. One key consideration
    in this context is the coordination of distributed transactions.
  prefs: []
  type: TYPE_NORMAL
- en: Maintaining data integrity is crucial for distributed transactions and ensuring
    that the system behaves as if it’s executing a single transaction on a centralized
    database. Distributed transactions refer to related database operations that must
    be executed atomically across multiple nodes. In a distributed system, where data
    is spread across different nodes, ensuring consistency and isolation across these
    operations becomes complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows data being integrated into two services, each with
    a database. At this point, orchestration is required to guarantee data consistency
    and security:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1: Transaction workflow in a distributed system](img/Figure_10.01_B19375.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.1: Transaction workflow in a distributed system'
  prefs: []
  type: TYPE_NORMAL
- en: However, achieving distributed transactional consistency at scale poses significant
    challenges. Traditional **atomicity, consistency, isolation, and durability**
    (**ACID**) properties, typically guaranteed in a centralized database, become
    harder to enforce across distributed nodes due to network latency, node failures,
    and concurrency issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'One approach to addressing these challenges is to use distributed transaction
    protocols such as **two-phase commit** (**2PC**) or **three-phase commit** (**3PC**).
    These protocols coordinate the commit or rollback decisions across multiple nodes
    in a distributed transaction. However, these protocols have limitations, including
    increased latency and failure vulnerability if a coordinator node becomes unavailable.
    The following diagram shows a sequence of 2PCs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2: 2PC illustration](img/Figure_10.02_B19375.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.2: 2PC illustration'
  prefs: []
  type: TYPE_NORMAL
- en: Another approach is to adopt a more relaxed consistency model, such as eventual
    consistency or optimistic concurrency control. These models trade off strict consistency
    guarantees for increased scalability and availability. These models can perform
    better when real-time consistency is not strictly required by allowing temporary
    inconsistencies and resolving conflicts asynchronously.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, distributed data integration often involves dealing with heterogeneous
    data sources with varying schemas and formats. Data transformation and mapping
    become crucial to ensure that data from different sources can be effectively combined
    and processed and often come with a performance cost. To create a consistent view
    of a distributed system, you can use methods such as **extract**, **transform**,
    and **load** (**ETL**) or data virtualization to combine data from various sources.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed transactional systems require careful design decisions to balance
    the trade-offs between consistency, scalability, and performance. When designing
    and architecting data integration at scale, it is essential to consider data consistency
    requirements, latency, fault tolerance, and performance factors. Understanding
    the characteristics and limitations of different transactional models and adopting
    appropriate data integration techniques can help architects and developers tackle
    the complexities associated with distributed data integration and ensure the reliability
    and efficiency of their systems.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, data integration at scale in distributed systems requires addressing
    the challenges of distributed transactions and maintaining consistency across
    multiple nodes. Architects and developers must consider the trade-offs between
    consistency guarantees, scalability, and performance when designing distributed
    transactional systems. Organizations can effectively manage and integrate large-scale
    data into their distributed systems by employing appropriate transactional protocols,
    consistency models, and data integration techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed databases are challenging, so we should leverage the best architecture
    to minimize pitfalls. Next, we’ll discuss an error that’s recorded when managing
    a distrusted system that’s specifically related to the dual-write process and
    why it should be avoided.
  prefs: []
  type: TYPE_NORMAL
- en: The dual-write anti-pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Dual-write is a pattern or approach in software development where data is simultaneously
    written to two or more separate systems or databases in real time. Dual-write
    aims to ensure data consistency and synchronization across multiple systems that
    serve different purposes or require additional data. The following diagram shows
    this operation, where a single web app writes multiple times to a database, a
    cache, and a second application.
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 10.3: Dua\uFEFFl-write operation](img/Figure_10.03_B19375.jpg)"
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.3: Dual-write operation'
  prefs: []
  type: TYPE_NORMAL
- en: 'While dual-write may seem convenient for data integration and synchronization,
    it is generally considered an anti-pattern. But what happens if one update succeeds
    and the other fails? Here are a few reasons why dual-write can be problematic:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Complexity and coupling**: Implementing dual-write introduces complexity
    and tight coupling between different systems. It increases the maintenance overhead
    and makes the system more fragile and prone to errors. Any change or update in
    one system may require corresponding changes in all the other systems involved
    in the dual-write process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance overhead**: Dual-write can have a significant performance impact
    on the system. Writing data to multiple systems synchronously in real time can
    introduce latency and decrease the overall system performance. As the number of
    systems involved increases, the impact on performance becomes more pronounced,
    potentially leading to a degraded user experience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inconsistencies and failures**: Dual-write does not guarantee perfect consistency
    across all systems. Failures during writing, such as network issues or system
    failures, can lead to inconsistent data states across different systems. Handling
    these failures and resolving inconsistencies can be challenging and time-consuming.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data integrity challenges**: Maintaining data integrity becomes more complex
    with dual-write. Ensuring that all the systems involved are updated correctly
    and simultaneously, without any data loss or corruption, requires implementing
    sophisticated mechanisms such as distributed transactions. These mechanisms add
    complexity and can further impact performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability limitations**: Dual-write becomes increasingly challenging to
    scale as the system grows. As the number of designs and the volume of data increase,
    the overhead of synchronizing writes across all systems becomes more challenging
    to manage effectively. Scaling dual-write to handle high-throughput scenarios
    may require additional infrastructure and optimization efforts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Instead of depending solely on dual-write, let’s explore other options for
    integrating and synchronizing data. Some recommended alternatives include the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**ETL**: Using ETL processes, data can be extracted from the source system,
    transformed into the appropriate format, and then loaded into the target system.
    This approach allows for more flexibility and decoupling between systems, enabling
    data transformations and mappings as necessary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Event-driven architecture**: Employing an event-driven architecture can help
    propagate data changes or events across systems asynchronously. It decouples systems
    and allows for more flexible and scalable data integration. Events are published
    when data changes occur, and interested systems that are subscribed, can react
    to these events accordingly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Message queues**: Leveraging message queues can provide reliable and scalable
    data integration and synchronization mechanisms. Systems can publish messages
    to the queue, and subscribing systems can consume them at their own pace, ensuring
    asynchronous and decoupled communication.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Organizations can achieve data integration and synchronization by adopting these
    alternative approaches while avoiding dual-write pitfalls. These approaches provide
    more flexibility, scalability, and maintainability, enabling better-distributed
    data system management.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, dual-write is the most popular anti-pattern we face as distributed
    architects and is a mistake. Now, let’s move to the second topic: microservices
    and shared databases.'
  prefs: []
  type: TYPE_NORMAL
- en: Microservices and shared databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The use of microservices architecture has become increasingly popular because
    it allows you to create scalable and flexible systems. This approach involves
    breaking down applications into smaller, independent services that can be developed,
    deployed, and scaled individually. However, despite its many advantages, sharing
    databases across multiple services can pose challenges and disadvantages.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure illustrates a sample where three applications share the
    same database. In the short term, we can imagine that this will save us some power
    resources, but in the long term, we start wondering about the price. If we create
    an inconsistent data event, how do we know which application contains the bug?
    We may also have security issues, such as unauthorized data access:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4: Shared database in a microservice](img/Figure_10.04_B19375.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.4: Shared database in a microservice'
  prefs: []
  type: TYPE_NORMAL
- en: Multiple microservices sharing a database can introduce several challenges and
    drawbacks. These include data coupling and dependencies, performance bottlenecks,
    lack of autonomy and ownership, data integrity and consistency issues, and scalability
    and deployment flexibility limitations. The tight coupling between services due
    to shared data can slow development and hinder individual service flexibility.
    Contentions for database resources can lead to degraded performance, especially
    when multiple services concurrently access the same database. Shared databases
    also blur the lines of ownership and make it harder to identify responsible services
    for data-related issues. Ensuring data integrity and consistency becomes complex
    with multiple services writing to the same database, and conflicts and inconsistencies
    may arise. Scaling the database to accommodate the load from numerous services
    becomes challenging, and deploying new services or making changes can be complicated
    due to necessary schema changes and migrations affecting other services.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data coupling and dependencies**: Sharing a database between multiple microservices
    introduces tight coupling between services. Database schema or data model changes
    can impact multiple services, requiring coordination and synchronization efforts.
    It can slow development and hinder individual services’ flexibility and autonomy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance bottlenecks**: When multiple services access the same shared
    database, contention for database resources can become a bottleneck. Increased
    traffic and simultaneous requests from various services can lead to degraded performance
    since the database becomes a single point of contention. Scaling the database
    becomes more challenging as the load from multiple services must be accommodated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lack of autonomy and ownership**: Microservices architecture emphasizes the
    autonomy and ownership of individual services. Sharing a database blurs the lines
    of ownership as multiple services have access to and can modify the same data.
    It can create confusion and make identifying the responsible service for data-related
    issues or errors easier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data integrity and consistency**: Maintaining data integrity becomes more
    complex when multiple services are written to the same database. Coordinating
    transactions and managing concurrency becomes more complex when multiple services
    are involved. Ensuring consistency and enforcing business rules across services
    can be challenging as conflicts and data inconsistencies may arise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability and deployment flexibility**: Shared databases can limit microservices’
    scalability and deployment flexibility. As the system grows, scaling the database
    becomes more challenging due to the increased load from multiple services. Additionally,
    deploying new services or changing existing services becomes more complicated
    as they may require database schema changes or data migrations that affect other
    services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows the isolation between several services, where each
    service has a dedicated database and is responsible for it. All communication
    between applications will happen through an API; no application communicates directly
    with another application’s database:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5: A microservice with each database](img/Figure_10.05_B19375.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.5: A microservice with each microservice has its own database'
  prefs: []
  type: TYPE_NORMAL
- en: 'To tackle these obstacles, utilizing one database for each microservice is
    advisable. This approach offers numerous advantages, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Service autonomy and isolation**: Each microservice has a dedicated database,
    providing independence and isolation. Each service can choose the database technology
    or schema that best suits its needs. Services can evolve independently without
    them impacting others, allowing faster development, deployment, and scalability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Simplified data management**: Data management becomes more straightforward
    with a single database per microservice. It reduces coordination efforts and allows
    services to choose the most suitable data storage technology or approach. Services
    fully control their data, including schema changes, migrations, and optimizations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improved performance and scalability**: Dedicated databases enable services
    to scale horizontally and independently. Services can choose databases optimized
    for their specific workload, ensuring efficient data access and processing. Each
    service can handle its database load, improving performance and scalability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clear ownership and responsibility**: Having single databases per microservice
    ensures a clear sense of ownership and responsibility. Each service is responsible
    for its data, making troubleshooting and resolving issues easier. Additionally,
    it enhances the system’s maintainability and supportability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Simplified data consistency and integrity**: Maintaining data consistency
    and integrity becomes more manageable with dedicated databases. Services can enforce
    their own business rules and transactional boundaries within their databases.
    It reduces the complexity of managing distributed transactions and mitigates data
    consistency issues.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration between services in a microservices architecture should ideally
    go through events, and it is generally considered a security best practice to
    avoid directly accessing or modifying another service’s database. By relying on
    events for communication and maintaining strict boundaries around each service’s
    database, you can enhance security and protect sensitive data within the system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s why events and avoiding direct database access promote security:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Limited attack surface area**: Accessing another service’s database increases
    the attack surface area. Exposing the database context of a service to other services
    introduces potential vulnerabilities, such as injection attacks or unauthorized
    access to sensitive data. Using events as a communication mechanism, you can limit
    the exposure of a service’s data and reduce the risk of unauthorized access.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data isolation**: Each service in a microservices architecture has its specific
    context and boundaries. By avoiding direct access to another service’s database,
    you maintain data isolation and prevent unauthorized read or write operations
    on the database. This isolation ensures that only the service responsible for
    a specific data context can manipulate or access that data, enhancing security
    and data privacy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Separation of concerns**: Microservices architecture emphasizes separation
    of concerns, where each service focuses on its specific domain. Allowing services
    to access each other’s databases can blur these boundaries and introduce potential
    data inconsistencies or unauthorized modifications. By relying on events, services
    can communicate and exchange relevant data without breaking the encapsulation
    and ownership of their respective databases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Auditing and compliance**: Maintaining separate database contexts for each
    service simplifies auditing and compliance requirements. With dedicated databases,
    tracking and monitoring data access and modifications within a specific service’s
    context becomes easier. It supports compliance with regulatory standards and simplifies
    identifying and investigating security-related issues or breaches.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Saga design pattern** is used for long-running and distributed transactions.
    It allows a sequence of local transactions, each within the context of a specific
    service, to participate in a coordinated and consistent operation across multiple
    services. The Saga pattern enables communication and maintains data consistency
    across services without direct database access.
  prefs: []
  type: TYPE_NORMAL
- en: With the Saga pattern, each service involved in a transaction executes its part
    and emits an event to indicate the completion or progress of its task. Other services
    interested in the transaction listen to these events and continue their tasks
    accordingly. The Saga pattern ensures data consistency without directly exposing
    or modifying another service’s database by relying on events and a coordinated
    sequence of local transactions.
  prefs: []
  type: TYPE_NORMAL
- en: By adopting the event-driven architecture and leveraging the Saga pattern, microservices
    can securely communicate and maintain data consistency while upholding the principles
    of isolation, limited surface area, and separation of concerns. This approach
    enhances security and minimizes the risks associated with direct access to other
    service databases, enabling a more robust and secure microservices ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using several good practices in distributed architecture can reduce the number
    of pitfalls and challenges but not eliminate them. It is a perennial challenge
    to get consistency across persistent systems. However, there is one point that
    we need to understand and live with: **eventual consistency**. In the next section,
    we’ll discuss this in more detail.'
  prefs: []
  type: TYPE_NORMAL
- en: Eventual consistency problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In distributed systems, eventual consistency is a model where data updates are
    not instantly synchronized across all nodes. Instead, temporary inconsistencies
    are allowed, and the updates are gradually propagated until the system converges
    to a consistent state.
  prefs: []
  type: TYPE_NORMAL
- en: In eventual consistency, different nodes in the system may have different views
    of the data at any given point in time. This is primarily due to network latency,
    communication delays, and concurrent updates. However, eventual consistency ensures
    the system reaches a consistent state where all nodes converge on the same data.
  prefs: []
  type: TYPE_NORMAL
- en: 'To address the challenges and potential problems associated with eventual consistency,
    several techniques and mechanisms can be employed:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Conflicts** can occur when multiple updates are made to the same data simultaneously.
    To ensure consistency, conflict resolution mechanisms are used to determine how
    these conflicts should be resolved. Different techniques, including last-write-wins
    and application-defined conflict resolution strategies, can reconcile conflicting
    updates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Read repair**: Read repair is a technique that’s used to repair inconsistencies
    by updating or synchronizing data during read operations. When a read operation
    encounters inconsistent or outdated data, it triggers a repair process that retrieves
    the latest version of the data from other nodes and updates the local copy, ensuring
    eventual consistency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Anti-entropy mechanisms**: Anti-entropy mechanisms actively detect and reconcile
    inconsistencies in distributed systems. These mechanisms periodically compare
    data across nodes and initiate synchronization processes to ensure consistency.
    Examples of anti-entropy tools include Merkle trees, gossip protocols, and vector
    clocks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quorum systems**: Quorum systems determine the level of agreement required
    to achieve consistency in a distributed system. By defining quorums and quorum
    sizes, systems can ensure that a certain number of nodes must agree on an update
    or operation before it is considered consistent. This helps prevent inconsistencies
    due to partial updates or failures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compensating actions**: In cases where conflicts or inconsistent updates
    cannot be resolved automatically, compensating actions can be employed. Compensating
    actions are operations or processes that reverse or pay for incorrect or conflicting
    updates. These actions help restore consistency in the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Idempotency**: Designing operations to be idempotent can help mitigate inconsistencies.
    Idempotence, in programming and mathematics, is a property of some operations
    such that no matter how many times you execute them, you achieve the same result.
    It ensures that even if an operation is used numerous times due to communication
    delays or retries, the outcome remains the same, preventing inconsistencies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you’re familiar with NoSQL databases, you’ll remember **BASE** means **basically
    available**, where data values may change over time but will achieve eventual
    consistency. This eventual consistency is the data modeling concept we must consider
    to meet several horizontal scalabilities, and we can take advantage of the knowledge
    we learn from the NoSQL database. We could see several previously mentioned techniques
    being used on this database engine, such as Cassandra as read-repair.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that eventual consistency is unsuitable for all scenarios.
    Systems that require strict real-time consistency or those dealing with critical
    data may require more vital consistency models. However, for many distributed
    systems, eventual consistency strikes a balance between availability, performance,
    and data integrity.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing and managing eventual consistency requires carefully considering
    the system’s requirements, using appropriate conflict resolution strategies, and
    choosing anti-entropy mechanisms. By employing these techniques, distributed systems
    can effectively handle temporary inconsistencies and converge toward a consistent
    state over time.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In conclusion, architecting distributed systems presents unique challenges that
    must be carefully addressed to ensure the success and effectiveness of the system.
    Throughout this chapter, we explored some challenges, such as dual-write and microservices
    with shared databases, and discussed why they could be problematic.
  prefs: []
  type: TYPE_NORMAL
- en: Although initially appealing for data consistency, dual-write can introduce
    complexity, performance overhead, and data integrity challenges. Similarly, sharing
    databases between microservices can lead to data coupling, performance bottlenecks,
    and compromised autonomy. These pitfalls emphasize the importance of carefully
    considering alternatives, such as event-driven architectures and single databases
    per microservice, to promote scalability, independence, and maintainability.
  prefs: []
  type: TYPE_NORMAL
- en: We also highlighted the significance of eventual consistency as a model for
    distributed systems. While it allows temporary data inconsistencies, eventual
    consistency balances availability, performance, and data integrity. Techniques
    such as conflict resolution, read repair, anti-entropy mechanisms, quorum systems,
    compensating actions, and idempotency help address any challenges and ensure eventual
    consistency.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, documentation emerges as a critical aspect of distributed architecture.
    Good documentation provides a comprehensive overview of the system, its components,
    and their interactions. It enables better understanding, collaboration, and decision-making
    throughout development, maintenance, and modernization.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will delve into modernization strategies and data integration.
    We will explore approaches to modernizing existing systems, leverage data integration
    techniques, and delve into the various patterns and technologies that facilitate
    smooth transitions and effective utilization of distributed architectures.
  prefs: []
  type: TYPE_NORMAL
