- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Advanced API Concepts and Implementations
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级API概念和实现
- en: Creating robust and high-performance RESTful APIs involves more than just setting
    up endpoints and handling CRUD operations. As applications grow and user demands
    increase, incorporating advanced strategies that keep your APIs efficient, reliable,
    and resilient under various conditions becomes essential. This chapter explores
    these strategies, focusing on data-handling techniques such as pagination, filtering,
    and file uploads and downloads, as well as resilience mechanisms crucial for modern
    API development.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 创建健壮且高性能的RESTful API不仅仅是设置端点和处理CRUD操作。随着应用程序的增长和用户需求的增加，在API中融入先进的策略，以保持API在各种条件下的效率、可靠性和弹性变得至关重要。本章探讨了这些策略，重点关注数据处理技术，如分页、过滤和文件的上传和下载，以及对于现代API开发至关重要的弹性机制。
- en: On the data management front, we will examine key practices such as pagination,
    filtering, and the efficient uploading and downloading of files through REST APIs.
    These methods are designed to boost the responsiveness and scalability of your
    APIs, ensuring they can seamlessly manage higher loads and more complex data interactions.
    Some of these topics are related to performance, but we will cover performance
    optimization in greater detail in [*Chapter 10*](B21843_10.xhtml#_idTextAnchor284)
    .
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据管理方面，我们将检查分页、过滤以及通过REST API高效上传和下载文件等关键实践。这些方法旨在提高API的响应性和可伸缩性，确保它们能够无缝地管理更高的负载和更复杂的数据交互。其中一些主题与性能相关，但我们将更详细地介绍性能优化在[*第10章*](B21843_10.xhtml#_idTextAnchor284)。
- en: The chapter will explore critical resilience mechanisms, including timeouts,
    retry strategies, rate limiting, throttling, idempotency keys, circuit breakers,
    and bulkheads. These approaches help safeguard your APIs against failures, manage
    traffic effectively, and maintain stability even under unpredictable or adverse
    conditions.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将探讨关键的弹性机制，包括超时、重试策略、速率限制、节流、幂等键、断路器和防波堤。这些方法有助于保护您的API免受故障的影响，有效管理流量，并在不可预测或不利条件下保持稳定性。
- en: 'From a developer’s perspective, anticipating how systems will behave in real-world
    scenarios can be challenging. During development, we often operate in ideal settings:
    running the API locally, being the sole user, and conducting tests with minimal
    variables that might cause failures. This controlled environment can obscure the
    complexities and potential issues that emerge in production, where the API must
    support multiple users, handle varying loads, and respond to unexpected events.
    By incorporating the advanced concepts and implementations discussed in this chapter,
    you will be better equipped to build APIs that perform reliably and efficiently
    in any environment.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 从开发者的角度来看，预测系统在实际场景中的行为可能具有挑战性。在开发过程中，我们通常在理想的环境下操作：在本地运行API、作为唯一用户，以及使用可能导致失败的变量最少的测试。这种受控环境可能会掩盖生产中出现的复杂性和潜在问题，在那里API必须支持多个用户、处理不同的负载并响应意外事件。通过结合本章讨论的先进概念和实现，您将更好地装备自己，以构建在任何环境中都能可靠且高效运行的API。
- en: 'We are going to cover the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Data handling
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据处理
- en: Resilience
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弹性
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, you will find several different approaches that will help
    you to improve your API depending on your requirements. For this chapter, we recommend
    you catch up with the code from the previous chapter; some small enhancements
    for this chapter are available at the following link: [https://github.com/PacktPublishing/Mastering-RESTful-Web-Services-with-Java/tree/main/chapter6](https://github.com/PacktPublishing/Mastering-RESTful-Web-Services-with-Java/tree/main/chapter6)
    . We use the `curl` command-line tool as a client to test the APIs.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将找到几种不同的方法，这些方法将帮助您根据您的需求改进您的API。对于本章，我们建议您复习上一章的代码；本章的一些小改进可在以下链接找到：[https://github.com/PacktPublishing/Mastering-RESTful-Web-Services-with-Java/tree/main/chapter6](https://github.com/PacktPublishing/Mastering-RESTful-Web-Services-with-Java/tree/main/chapter6)。我们使用`curl`命令行工具作为客户端来测试API。
- en: Data handling
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据处理
- en: '**Data handling** is the cornerstone of building robust and user-friendly APIs.
    In this section, we will explore advanced data-handling techniques that address
    common challenges faced in real-world API development.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据处理**是构建健壮且用户友好的API的基石。在本节中，我们将探讨高级数据处理技术，这些技术针对现实世界API开发中面临的常见挑战。'
- en: Ensuring that an API delivers reliable performance is crucial for several interconnected
    reasons, including enhancing user experience, enabling system scalability, optimizing
    resource efficiency, and influencing the success of the business behind API development.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 确保API提供可靠的性能对于多个相互关联的原因至关重要，包括提升用户体验、实现系统可扩展性、优化资源效率以及影响API开发背后业务的成功。
- en: A high-performing API must respond quickly and communicate clearly with clients.
    This means returning appropriate HTTP status codes (such as 200 for success or
    404 for not found) along with descriptive messages that explain what happened.
    Low latency is crucial because users expect fast responses, and slow APIs can
    create system bottlenecks that frustrate users.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一个高性能的API必须快速响应并与客户端进行清晰的沟通。这意味着返回适当的HTTP状态码（例如，200表示成功或404表示未找到）以及描述性消息，说明发生了什么。低延迟至关重要，因为用户期望快速响应，而缓慢的API可能会创建系统瓶颈，让用户感到沮丧。
- en: When APIs take too long to respond, they cause delays throughout the entire
    application. Modern systems often need real-time data updates, so APIs must handle
    frequent requests efficiently while maintaining consistent response times. Clear
    communication is equally important—when errors occur, clients need informative
    messages that explain the problem and suggest solutions.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当API响应时间过长时，会导致整个应用程序出现延迟。现代系统通常需要实时数据更新，因此API必须高效地处理频繁的请求，同时保持一致的响应时间。清晰的沟通同样重要——当出现错误时，客户端需要提供解释问题的信息性消息并建议解决方案。
- en: Effective APIs balance speed with clarity. They process requests quickly while
    providing meaningful feedback through proper status codes and helpful messages.
    This approach ensures both end users and developers can work with the API effectively,
    reducing confusion and debugging time.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的API在速度和清晰度之间取得平衡。它们快速处理请求，同时通过适当的状态码和有用的消息提供有意义的反馈。这种方法确保了最终用户和开发者都能有效地使用API，减少了困惑和调试时间。
- en: Optimizing response speed and message quality helps APIs handle increased traffic
    without compromising performance or raising operational costs. These improvements
    support both user satisfaction and business growth.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 优化响应速度和消息质量有助于API在不降低性能或增加运营成本的情况下处理增加的流量。这些改进既支持用户满意度，也支持业务增长。
- en: In the following sections, we will explore data-handling techniques that improve
    API performance. We will start with pagination for managing large datasets, then
    cover filtering and efficient file operations through REST APIs.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将探讨提高API性能的数据处理技术。我们将从管理大数据集的分页开始，然后介绍通过REST API进行过滤和高效的文件操作。
- en: Paginatio n
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分页
- en: Retrieving a large number of records from one or multiple database tables and
    converting them into a data structure compatible with your language/framework,
    such as in Java with Spring Boot, consumes resources, including memory and CPU
    processing power. This process continues until the data is transformed into a
    standard format such as JSON for communication and is ready to be sent to the
    client. Additionally, even after the data is prepared, resources are still used
    to transmit it over the network to the client.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 从一个或多个数据库表中检索大量记录并将它们转换为与您的语言/框架兼容的数据结构，例如在Java中使用Spring Boot，会消耗资源，包括内存和CPU处理能力。这个过程会一直持续到数据被转换为标准格式，如JSON，用于通信并准备好发送给客户端。此外，即使在数据准备完毕后，仍然会使用资源通过网络将其传输到客户端。
- en: Often, it is unnecessary to send all the data represented by a resource in a
    single, large payload to the client. Doing so consumes more resources, degrades
    the system performance, and causes a poor user experience. These may be accompanied
    by the increased costs associated with cloud computing, which are billed based
    on usage. Processing and transferring larger amounts of data also takes more time.
    Instead, the data can be divided into smaller chunks, which require less time
    and fewer resources, thereby making the API more reliable and cost-effective to
    maintain. This approach is known as **pagination** , which enhances API responsiveness
    and conserves resources.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，没有必要将资源表示的所有数据在一个大型的单一负载中发送给客户端。这样做会消耗更多资源，降低系统性能，并导致糟糕的用户体验。这可能会伴随着与云计算相关的增加成本，这些成本基于使用量来计费。处理和传输大量数据也需要更多时间。相反，可以将数据分成更小的块，这需要更少的时间和资源，从而使API更可靠且维护成本效益更高。这种方法被称为**分页**，它提高了API的响应速度并节省了资源。
- en: 'Consider the following example: our API contains 100,000 products, and we have
    a **single-page application** ( **SPA** ) that consumes this API to display products
    in a data table on the **Products** page. Imagine that every time a user opens
    this page, the API is called to access the database, load these records into memory,
    convert them to JSON, and then transfer this large amount of data via an internet
    request each time a user accesses the page. Now, imagine that this system is used
    by numerous users daily. Without pagination, each user action would trigger resource-intensive
    processes, leading to increased costs, slower response times, and a diminished
    user experience. By implementing pagination, the API can deliver smaller, more
    manageable datasets, improving performance and scalability while reducing operational
    expenses. All of that can be done without limiting the user interface view of
    the application, because the user will never see all the products displayed at
    the same time.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下示例：我们的API包含100,000个产品，我们有一个**单页应用程序**（**SPA**），它消费此API以在**产品**页面上显示产品数据表。想象一下，每次用户打开这个页面时，API都会被调用以访问数据库，将这些记录加载到内存中，将它们转换为JSON，然后在用户每次访问页面时通过互联网请求传输大量数据。现在，想象一下，这个系统每天被众多用户使用。如果没有分页，每个用户操作都会触发资源密集型过程，导致成本增加、响应时间变慢，以及用户体验下降。通过实现分页，API可以提供更小、更易于管理的数据集，从而提高性能和可扩展性，同时降低运营成本。所有这些都可以在不限制应用程序用户界面视图的情况下完成，因为用户永远不会同时看到所有产品。
- en: Different pagination approaches
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不同的分页方法
- en: 'The following are some common approaches to REST API pagination:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些常见的REST API分页方法：
- en: Offset-based pagination
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于偏移量的分页
- en: Page-based pagination
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于页面的分页
- en: Cursor-based pagination
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于游标的分页
- en: Keyset pagination
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关键集分页
- en: Let’s take a look at each of them
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一看看它们
- en: Offset-based pagination
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基于偏移量的分页
- en: '**Offset-based pagination** is a straightforward and widely adopted technique.
    It works by defining an offset (the starting position) and a limit (the number
    of records to retrieve per page) to navigate through the dataset. This is the
    approach that we can find in the APIs of several different companies, such as
    OpenWeatherMap, Stripe, Adidas, and Mailchimp.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于偏移量的分页**是一种简单且广泛采用的技术。它通过定义一个偏移量（起始位置）和一个限制（每页要检索的记录数）来在数据集中导航。这种做法可以在多个不同公司的API中找到，例如OpenWeatherMap、Stripe、Adidas和Mailchimp。'
- en: 'The following are the advantages of offset-based pagination:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是基于偏移量分页的优点：
- en: '**Simplicity** : The method is straightforward to implement and easy to understand'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简单性**：该方法易于实现和理解'
- en: '**Flexibility** : By adjusting the offset, you can directly jump to any position
    that you may want'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活性**：通过调整偏移量，您可以直接跳转到您可能想要的位置'
- en: 'The following are the disadvantages of offset-based pagination:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是基于偏移量分页的缺点：
- en: '**Performance issues** : As the offset increases, query performance declines
    because the database must scan and skip over a growing number of records.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能问题**：随着偏移量的增加，查询性能会下降，因为数据库必须扫描并跳过越来越多的记录。'
- en: '**Data consistency** : Data changes such as inserts or deletes between requests
    can lead to inconsistent results, causing duplicate or missing records across
    pages.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据一致性**：请求之间的数据更改，如插入或删除，可能导致结果不一致，导致页面之间出现重复或缺失的记录。'
- en: Clients can manipulate the business logic, which does not guarantee a single
    experience for all clients. It can be considered a benefit, though, if the API
    is meant to be very flexible.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 客户可以操作业务逻辑，但这并不能保证所有客户都能获得相同的体验。然而，如果API旨在非常灵活，这也可以被视为一种优势。
- en: Most likely, this will be passed to a database query such as SQL, which, without
    proper input sanitization and parameterization, can cause SQL injection.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能，这将被传递到数据库查询，如SQL，如果没有适当的输入清理和参数化，可能会导致SQL注入。
- en: 'The following is an example of an API call:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个API调用的示例：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Page-based pagination
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基于页面的分页
- en: '**Page-based pagination** divides a dataset into pages, allowing clients to
    navigate the data by specifying a page number. This approach is simple and hence
    widely adopted by companies in the API market, for example, Salesforce and Microsoft.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于页面的分页**将数据集分为页面，允许客户通过指定页码来导航数据。这种方法很简单，因此被API市场的公司广泛采用，例如Salesforce和Microsoft。'
- en: To use it, you need to specify the page you want to retrieve ( `page` ) and
    the number of records per page ( `page_size` ).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用它，您需要指定要检索的页面（`page`）和每页的记录数（`page_size`）。
- en: 'The following are the advantages of page-based pagination:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是基于页面分页的优点：
- en: '**User-friendliness** : Intuitive for users to navigate to specific pages'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户友好性**：用户可以直观地导航到特定页面'
- en: '**Simplicity** : Easy to implement and understand'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简单性**：易于实现和理解'
- en: 'The following are the disadvantages of page-based pagination:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是基于页面分页的缺点：
- en: '**Performance issues** : Like offset-based pagination, large page numbers can
    cause performance degradation.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能问题**：与基于偏移量的分页类似，大页码可能导致性能下降。'
- en: '**Less flexibility** : The returned list of records must start at a page boundary.
    This may not be convenient for user interfaces using scrollbars instead of the
    classical pagination.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活性较低**：返回的记录列表必须从页面边界开始。这可能不适合使用滚动条而不是传统分页的用户界面。'
- en: 'The following is an example of an API call:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个API调用的示例：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Page-based pagination for the `GET /products` endpoint of our example Product
    API was implemented while demonstrating API evolution in [*Chapter 5*](B21843_05.xhtml#_idTextAnchor116)
    .
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在演示API演变时，实现了示例产品API的`GET /products`端点的基于页面的分页，见[*第5章*](B21843_05.xhtml#_idTextAnchor116)。
- en: Cursor-based pagination
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基于光标分页
- en: '**Cursor-based pagination** uses a pointer (cursor) to keep track of the current
    position in the dataset. Instead of specifying an offset, clients use a cursor
    to request the next set of records and a limit that represents the number of records
    we want to return per chunk of data. That is the approach implemented by the X
    (formerly Twitter) API to paginate the data of tweets, followers, and other resources.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于光标分页**使用一个指针（光标）来跟踪数据集中的当前位置。客户端不是指定偏移量，而是使用光标请求下一组记录，并指定一个表示我们希望每块数据返回的记录数的限制。这正是X（前身为Twitter）API实现分页数据的方法，包括推文、关注者和其他资源。'
- en: 'The following are the advantages of cursor-based pagination:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是基于光标分页的优点：
- en: '**Performance efficiency** : Maintains reliable performance regardless of dataset
    size since it does not require skipping records'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能效率**：由于不需要跳过记录，因此无论数据集大小如何，都能保持可靠的性能'
- en: '**Data consistency** : Less susceptible to data inconsistencies between requests,
    ensuring more reliable results'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据一致性**：相较于请求之间的数据不一致性，这种分页方式能确保更可靠的结果'
- en: 'The following are the disadvantages of cursor-based pagination:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是基于光标分页的缺点：
- en: '**Complexity** : The implementation is more complex when compared to offset-based
    pagination'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂性**：与基于偏移量的分页相比，实现更为复杂'
- en: '**Less flexibility** : It is suited for sequential navigation and may not be
    a good option if you need to jump to arbitrary pages'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活性较低**：适用于顺序导航，如果需要跳转到任意页面可能不是最佳选择'
- en: 'The following is an example of an API call:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个API调用的示例：
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Keyset pagination
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 键集分页
- en: '**Keyset pagination** is a variation of cursor-based pagination; it leverages
    a unique key—typically a timestamp or a **universally unique identifier** ( **UUID**
    )—to navigate through records. Unlike offset-based pagination, which relies on
    numerical offsets that can become increasingly inefficient with larger datasets,
    keyset pagination uses the unique key to mark the position in the dataset. This
    approach ensures faster query performance and more consistent response times,
    making it particularly well suited for applications that require real-time data
    access and scalability.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**键集分页**是基于光标分页的一种变体；它利用一个唯一键——通常是时间戳或**通用唯一标识符**（**UUID**）——来导航记录。与依赖于数值偏移量（在数据集较大时可能越来越低效）的基于偏移量的分页不同，键集分页使用唯一键来标记数据集中的位置。这种方法确保了更快的查询性能和更一致的响应时间，特别适合需要实时数据访问和可扩展性的应用。'
- en: 'The following are the advantages of keyset pagination:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是基于键集分页的优点：
- en: '**Performance** : Keyset pagination offers better performance for large datasets
    by eliminating the need for the database to count or skip over large numbers of
    records, as is necessary with offset-based pagination'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能**：键集分页通过消除数据库计数或跳过大量记录的需求（这在基于偏移量的分页中是必要的），为大数据集提供了更好的性能'
- en: '**Scalability** : As datasets grow, keyset pagination maintains consistent
    response times, making it a scalable solution for high-traffic applications'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：随着数据集的增长，键集分页能保持一致的响应时间，使其成为高流量应用的可扩展解决方案'
- en: '**Reliability** : By relying on a unique key for navigation, keyset pagination
    reduces the risk of encountering missing or duplicate records, ensuring data integrity
    across paginated results'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可靠性**：通过依赖唯一的键进行导航，键集分页降低了遇到缺失或重复记录的风险，确保分页结果中的数据完整性'
- en: 'The following are the disadvantages of keyset pagination:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些键集分页的缺点：
- en: '**Sequential navigation only** : Keyset pagination requires sequential data
    access. Unlike offset-based pagination, which allows users to jump directly to
    any page by specifying an offset, keyset pagination requires navigating through
    records in a linear order. This limitation can be restrictive for applications
    where users need to access non-sequential pages or perform random access within
    the dataset.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仅顺序导航**：键集分页需要顺序数据访问。与基于偏移量的分页不同，后者允许用户通过指定偏移量直接跳转到任何页面，键集分页需要按线性顺序遍历记录。这种限制对于需要访问非顺序页面或在数据集中进行随机访问的应用程序可能具有约束性。'
- en: '**Bookmark dependency** : To access a specific page, the client must retain
    the unique key (cursor) from the preceding pages. This dependency can complicate
    client-side logic, especially in scenarios where users might want to revisit or
    share specific pages without maintaining a history of cursors.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**书签依赖**：要访问特定页面，客户端必须保留前几页的唯一键（游标）。这种依赖关系可能会使客户端逻辑复杂化，尤其是在用户可能希望重新访问或共享特定页面而不维护游标历史的情况下。'
- en: 'The following is an example of an API call:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个API调用的示例：
- en: '[PRE3]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: After selecting the pagination strategy to apply to all our endpoints and APIs,
    we should also return the information about the pagination. Providing information
    such as total items, pages, and the current page helps clients better navigate
    large datasets.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在为所有端点和API选择要应用的分页策略后，我们还应该返回有关分页的信息。提供有关总项数、页数和当前页的信息可以帮助客户端更好地导航大型数据集。
- en: Different approaches to return pagination information
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 返回分页信息的不同方法
- en: 'There are many ways to return pagination information to the client. The most
    common are as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以将分页信息返回给客户端。最常见的方法如下：
- en: Using response headers
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用响应头
- en: Including pagination information in the response body
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在响应体中包含分页信息
- en: Using hypermedia (HATEOAS)
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用超媒体（HATEOAS）
- en: Using response headers
  id: totrans-81
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用响应头
- en: 'This strategy involves embedding pagination information directly within the
    HTTP headers, such as details about the total number of pages, the current page,
    and other relevant information. This approach is not commonly used in isolation,
    and it is often combined with other strategies to enhance API functionality. For
    instance, GitLab employs this method alongside hypermedia strategies to provide
    a more comprehensive user experience. We can combine filtering with pagination
    to retrieve specific data, allowing us to manage large datasets by breaking them
    into paginated sections:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这种策略涉及将分页信息直接嵌入到HTTP头中，例如关于总页数、当前页和其他相关信息。这种方法通常不单独使用，而是经常与其他策略结合使用以增强API功能。例如，GitLab就采用这种方法与超媒体策略结合，以提供更全面的用户体验。我们可以将过滤与分页结合使用，以检索特定数据，通过将数据分成分页部分来管理大型数据集：
- en: '[PRE4]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the preceding example, we can see four custom headers to inform the client
    about how to navigate through the API effectively.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们可以看到四个自定义头，用于告知客户端如何有效地导航API。
- en: Including pagination information in the response body
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在响应体中包含分页信息
- en: In this approach, the API includes paginated data within the response body alongside
    relevant pagination metadata, such as total pages and the current page. For example,
    the Stripe API employs this strategy by returning both the data and a `has_more`
    flag that indicates whether additional results are available. This method offers
    clarity by directly integrating pagination details with the response, letting
    clients understand their data context.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，API将分页数据与相关的分页元数据（如总页数和当前页）一起包含在响应体中。例如，Stripe API通过返回数据和`has_more`标志（指示是否有更多结果可用）来采用这种策略。这种方法通过直接将分页细节与响应集成，使客户端能够理解其数据上下文。
- en: 'Some APIs separate the response data from the metadata, which can also be effective.
    An examp le structure is shown here:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一些API将响应数据与元数据分开，这也可以是有效的。以下是一个示例结构：
- en: '[PRE5]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this structure, the `data` field contains the actual results from the API,
    while the `pagination` section provides essential metadata about the paginated
    response. This approach enhances usability by clearly organizing both the data
    and its associated pagination information, making it easier for clients to navigate
    and process the results.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种结构中，`data`字段包含API的实际结果，而`pagination`部分提供了关于分页响应的必要元数据。这种方法通过清晰地组织数据和相关的分页信息来提高可用性，使客户端更容易导航和处理结果。
- en: Using hypermedia (HATEOAS)
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用超媒体（HATEOAS）
- en: HATEOAS enhances API responses by embedding navigational links that guide clients
    on how to navigate and perform actions based on the server’s response. As we discussed
    in [*Chapter 1*](B21843_01.xhtml#_idTextAnchor015) , HATEOAS represents the fourth
    level of maturity in REST architecture, helping to decouple the client from the
    server. We will dive deep into this subject in the *HATEOAS* subsection later
    in this chapter.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: HATEOAS通过嵌入导航链接增强了API响应，引导客户端根据服务器的响应进行导航和执行操作。正如我们在[*第一章*](B21843_01.xhtml#_idTextAnchor015)中讨论的那样，HATEOAS代表了REST架构的第四个成熟度级别，有助于将客户端与服务器解耦。我们将在本章后面的*HATEOAS*子节中深入探讨这个主题。
- en: 'This strategy empowers clients to interact with the API dynamically, without
    requiring prior knowledge of the structure or additional documentation. For example,
    APIs such as GitHub incorporate HATEOAS to make navigation through resources,
    such as paginated data, straightforward and intuitive. In the following code block,
    we can see an example of using this strategy to help the client move through the
    data:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这种策略使客户端能够动态地与API交互，无需事先了解结构或额外的文档。例如，GitHub等API通过采用HATEOAS使导航资源，如分页数据，变得简单直观。在下面的代码块中，我们可以看到使用这种策略帮助客户端通过数据的示例：
- en: '[PRE6]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As shown in the preceding code, the `_links` attribute provides key navigational
    details, including information about the current request and links to the previous
    and next pages, as well as the first and last pages. With these comprehensive
    links, clients can effortlessly navigate through the API without needing to construct
    additional requests manually.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述代码所示，`_links`属性提供了关键的导航细节，包括关于当前请求的信息以及到上一页和下一页的链接，以及第一页和最后一页的链接。有了这些综合链接，客户端可以轻松地导航API，无需手动构造额外的请求。
- en: This structure streamlines the client’s interaction with the data, embedding
    the necessary navigation information within each response. By supplying these
    links, the API enables developers to create more intuitive and seamless user experiences.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这种结构简化了客户端与数据的交互，将必要的导航信息嵌入到每个响应中。通过提供这些链接，API使开发者能够创建更直观和无缝的用户体验。
- en: In API development, efficient data handling and robust pagination strategies
    are not merely supplementary features—they are essential points that underpin
    the efficacy, scalability, and overall user experience of your applications. We
    have outlined some different pagination approaches with their details, to ensure
    that your APIs deliver reliable and high-performing services. Regardless of your
    chosen approach, the key is maintaining consistency across all endpoints. Ensuring
    that every API follows the same pagination standard helps simplify integration
    for clients and promotes a more cohesive experience.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在API开发中，高效的数据处理和强大的分页策略不仅仅是辅助功能——它们是支撑应用程序效能、可扩展性和整体用户体验的基本要点。我们已经概述了一些不同的分页方法及其细节，以确保您的API提供可靠且高性能的服务。无论您选择哪种方法，关键在于在整个端点之间保持一致性。确保每个API遵循相同的分页标准有助于简化客户端的集成，并促进更一致的用户体验。
- en: In the next section, we will explore how to filter data returned by the API
    by applying some strategies that allow us to combine pagination and filtering.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨如何通过应用一些允许我们结合分页和过滤的策略来过滤API返回的数据。
- en: While pagination alone enables us to manage large datasets by breaking them
    into manageable pages, it may not fully address the client’s needs when specific
    subsets of data are required. To improve data handling further, we can incorporate
    filtering, which will allow clients to retrieve only the data they need within
    each page. By combining pagination with filtering, we offer a more flexible and
    efficient approach to data retrieval.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然分页本身可以通过将数据分成可管理的页面来管理大量数据集，但它可能无法完全满足客户端在需要特定数据子集时的需求。为了进一步提高数据处理能力，我们可以引入过滤功能，这将允许客户端在每一页中仅检索他们所需的数据。通过结合分页和过滤，我们提供了一种更灵活和高效的数据检索方法。
- en: Filtering
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 过滤
- en: '**Filtering** allows API clients to inform our API that we need some specific
    subset of the data on that resource, which means that it will not waste resources
    processing data that we are not interested in at that moment; we can concentrate
    exclusively on the data that we need. We can combine filtering with pagination
    to retrieve specific data, allowing us to manage large datasets by breaking them
    into paginated sections.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**过滤**允许API客户端通知我们的API我们需要在该资源上的一些特定数据子集，这意味着它将不会浪费资源处理我们此时不感兴趣的数据；我们可以专注于我们所需的数据。我们可以将过滤与分页结合使用来检索特定数据，从而通过将数据集分成分页部分来管理大量数据。'
- en: 'The following are some principles for filtering:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些过滤原则：
- en: '**Statelessness** : The REST API should be stateless, meaning that every request
    from a client must contain all the necessary information that will give the server
    the capability to fulfill the request. Filtering is achieved by including filter
    parameters in the query string of the request URL, without the need to save this
    state on the API server side.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无状态**：REST API应该是无状态的，这意味着客户端的每个请求都必须包含所有必要的信息，以便服务器能够满足请求。过滤是通过在请求URL的查询字符串中包含过滤参数来实现的，无需在API服务器端保存此状态。'
- en: '**Consistency and predictability** : The filtering syntax should be consistent
    across all API endpoints. This ensures predictability across different endpoints
    and makes it easy for clients to understand the filtering by looking at the request.
    For example, if we are filtering by a first name parameter using `` `?firstName=Peter`
    `` in one endpoint, it should work similarly across other endpoints where such
    filtering is relevant.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性和可预测性**：过滤语法应在所有API端点保持一致。这确保了不同端点之间的可预测性，并使得客户端通过查看请求就能轻松理解过滤操作。例如，如果我们在一个端点通过`?firstName=Peter`参数进行按名字过滤，那么在其他相关端点进行此类过滤时，其操作应类似。'
- en: '**Granularity and flexibility** : An effective filtering mechanism allows clients
    to precisely define their requirements while being adaptable enough to handle
    different scenarios. For instance, filters should accommodate different data types
    (such as strings, numbers, and dates) and a range of operators (such as equals,
    not equals, greater than, less than, in, etc.).'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**粒度和灵活性**：有效的过滤机制允许客户端精确定义他们的需求，同时足够灵活以应对不同场景。例如，过滤器应适应不同的数据类型（如字符串、数字和日期）以及一系列运算符（如等于、不等于、大于、小于、在等）。'
- en: Different filtering approaches
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不同的过滤方法
- en: 'Filtering can be implemented via several different approaches. It can be implemented
    using the following:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤可以通过多种不同的方法实现。它可以采用以下方式实现：
- en: '**Basic field filtering** : This is the most straightforward approach, where
    you can pass the field name to the resource and the value that you want to filter
    by, which is usually done by passing these values as a query parameter on the
    URL:'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基本字段过滤**：这是最直接的方法，您可以传递字段名称和您想要过滤的值到资源中，这通常通过在URL上传递这些值作为查询参数来完成：'
- en: '[PRE7]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Multiple field filtering** : This is the same as the previous one, with the
    only difference being that we will pass multiple field filters and their respective
    values for filtering the data. To separate the `field=value` set, we will use
    the `''&''` character:'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多字段过滤**：这与上一个例子相同，唯一的区别是我们将传递多个字段过滤器及其相应的值来过滤数据。为了分隔`field=value`集合，我们将使用`''&''`字符：'
- en: '[PRE8]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'It is possible to achieve filtering by a range of values, combining the same
    field name preceded by the `min` and `max` prefixes, as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一系列值进行过滤是可能的，通过将`min`和`max`前缀与相同的字段名称结合，如下所示：
- en: '[PRE9]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**Filtering with comparison operators** : Some APIs also provide the capability
    of handling comparison operators; this gives a chance to build a more sophisticated
    set of filtering combinations than a simple field equals value:'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用比较运算符进行过滤**：一些API还提供了处理比较运算符的能力；这为构建比简单的字段等于值更复杂的过滤组合提供了机会：'
- en: '[PRE10]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**List filtering (inclusion/exclusion)** : Using this approach, we can use
    an operator of `in` or `nin` (not in) on a list:'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**列表过滤（包含/排除）**：使用这种方法，我们可以在列表上使用`in`或`nin`（不在）运算符：'
- en: '[PRE11]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'As you will realize by now, pagination and filtering are two concepts that
    you cannot miss in your API implementation. Furthermore, they need to be combined
    to exploit their advantages on the endpoints of our APIs that are candidates to
    return lists of data. These are some best practices:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你应该已经意识到，分页和过滤是你在API实现中不能错过的两个概念。此外，它们需要结合起来，以充分利用我们API端点的优势，这些端点是返回数据列表的候选者。以下是一些最佳实践：
- en: Use significant, clear, and intuitive parameter names that guide the user to
    avoid errors
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用显著、清晰、直观的参数名称，以引导用户避免错误
- en: Validate and sanitize the inputs to avoid attacks and typos
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证和清理输入以避免攻击和错误
- en: Validate and implement default limits to avoid the user requesting large values
    and the server having to pass excessive volumes of data
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证并实施默认限制，以避免用户请求大值，使服务器不得不传递大量数据
- en: Keep consistent naming, response metadata, and approaches across the system
    to provide a good user/developer experience, making the structure and parametrization
    standardized and easy to consume
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在整个系统中保持一致的命名、响应元数据和方法，以提供良好的用户/开发者体验，使结构和参数化标准化且易于消费
- en: Filtering is a critical aspect of robust API design, enabling clients to retrieve
    the data they need without overburdening the server or the network. By implementing
    well-structured filtering mechanisms, APIs can achieve higher performance, scalability,
    and user satisfaction.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤是稳健API设计的关键方面，它使客户端能够获取所需数据，而不会过度负担服务器或网络。通过实施结构良好的过滤机制，API可以实现更高的性能、可扩展性和用户满意度。
- en: Employing various filtering approaches—from basic field filters to advanced
    comparison operators and list-based criteria—allows APIs to cater to diverse client
    requirements and complex querying needs. Moreover, integrating filtering with
    pagination not only enhances data management but also ensures that responses remain
    swift and manageable, even when dealing with extensive datasets.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 采用各种过滤方法——从基本的字段过滤器到高级的比较运算符和基于列表的标准——使API能够满足多样化的客户端需求和复杂的查询需求。此外，将过滤与分页集成不仅增强了数据管理，还确保了即使在处理大量数据集时，响应也能保持快速且易于管理。
- en: Let us explore a practical example that builds upon our paginated endpoint.
    Here, we add filtering capabilities to allow clients to specify criteria such
    as categories or price ranges. Combining pagination and filtering not only enhances
    data management but also is a best practice that provides a streamlined experience
    for clients, keeping responses fast and relevant even as datasets grow.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索一个基于我们分页端点的实际例子。在这里，我们添加了过滤功能，允许客户端指定如类别或价格范围等标准。结合分页和过滤不仅增强了数据管理，而且是一种最佳实践，为客户端提供流畅的体验，即使在数据集增长的情况下，也能保持响应快速且相关。
- en: Consider an e-commerce API endpoint that returns a list of products. This endpoint
    allows clients to request specific pages of data and apply filters to retrieve
    only the products they need, reducing data load on both the client and server.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个电子商务API端点，该端点返回产品列表。此端点允许客户端请求特定页面的数据并应用过滤器，仅检索他们需要的商品，从而减少客户端和服务器上的数据负载。
- en: 'The following is an example of an API call using pagination and filtering:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个使用分页和过滤的API调用示例：
- en: '[PRE12]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'It should return something like the following:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 它应该返回如下内容：
- en: '[PRE13]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Best practices when paginating and filtering
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分页和过滤的最佳实践
- en: 'Let’s take a look at some of the best practices to follow when paginating and
    filtering:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看在分页和过滤时应该遵循的一些最佳实践：
- en: '**Use clear and intuitive parameter names** : The parameter names, such as
    `page` , `limit` , `category` , `priceMin` , and `priceMax` , should be simple,
    self-explanatory, and aligned with common API design conventions, making the endpoint
    easy to use and understand.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用清晰直观的参数名称**：参数名称，如`page`、`limit`、`category`、`priceMin`和`priceMax`，应该是简单、一目了然且符合常见的API设计惯例，使端点易于使用和理解。'
- en: '**Apply input validation and sanitization** : The API validates all parameters
    to ensure they are correctly formatted. For instance, `page` and `limit` must
    be integers, while `priceMin` and `priceMax` must be decimal numbers. Additionally,
    the `sort` parameter only accepts specific values, preventing injection attacks
    and typos.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用输入验证和清理**：API 验证所有参数以确保它们格式正确。例如，`page`和`limit`必须是整数，而`priceMin`和`priceMax`必须是十进制数。此外，`sort`参数仅接受特定值，防止注入攻击和错误。'
- en: '**Apply default limits and constraints** : In our example, a default limit
    of 10 items per page is applied, and the `limit` parameter cannot exceed `100`
    . These measures protect the server from handling overly large requests, enhancing
    performance and preventing abuse.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用默认限制和约束**：在我们的示例中，每页默认限制为 10 项，且`limit`参数不能超过`100`。这些措施可以保护服务器免受处理过大请求的影响，提高性能并防止滥用。'
- en: '**Employ consistent naming and metadata** : The response includes metadata—
    `page` , `limit` , `totalPages` , and `totalItems` —that provides clients with
    essential information about the pagination state, ensuring a standardized and
    predictable experience.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**采用一致的命名和元数据**：响应包括元数据——`page`、`limit`、`totalPages` 和 `totalItems`——这些元数据向客户端提供有关分页状态的必要信息，确保标准化和可预测的体验。'
- en: '**Combine pagination and filtering** : This example demonstrates how pagination
    and filtering work together. The client can specify page numbers and filters simultaneously,
    allowing them to retrieve exactly the data they need without overloading the server
    or client with unnecessary information.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结合分页和过滤**：本例演示了分页和过滤如何协同工作。客户端可以同时指定页码和过滤器，允许他们检索所需的确切数据，而不会过载服务器或客户端，避免提供不必要的信息。'
- en: By applying these best practices, the API achieves a balance of flexibility,
    performance, and user-friendliness, ensuring that clients can access data efficiently
    while maintaining robust, scalable API design.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 通过应用这些最佳实践，API 实现了灵活性、性能和用户友好性的平衡，确保客户端可以高效地访问数据，同时保持强大、可扩展的 API 设计。
- en: With pagination and filtering, we have seen how to manage large datasets efficiently
    by selectively retrieving information. However, in many applications, handling
    data is not limited to managing structured information alone. Often, APIs need
    to support the uploading and downloading of files, allowing clients to transfer
    data in formats such as images, documents, and reports.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分页和过滤，我们已经看到如何通过选择性检索信息来有效地管理大量数据。然而，在许多应用程序中，处理数据并不仅限于管理结构化信息。通常，API 需要支持上传和下载文件，允许客户端以图像、文档和报告等格式传输数据。
- en: In the next section, we will dive into best practices and techniques for handling
    file uploads and downloads via REST APIs. These strategies will help ensure secure,
    reliable file transfers that integrate smoothly with the rest of the API.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将深入探讨通过 REST API 处理文件上传和下载的最佳实践和技术。这些策略将有助于确保安全、可靠的文件传输，并与 API 的其余部分顺利集成。
- en: Uploading and downloading files via the REST API
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过 REST API 上传和下载文件
- en: Web applications often need to support file uploads and downloads. This functionality
    is usually accompanied by additional requirements, such as validating file types,
    names, and maximum sizes, determining optimal storage solutions, providing meaningful
    responses, and handling large files efficiently through streaming. In this section,
    we will discuss these common topics in detail.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Web 应用通常需要支持文件上传和下载。此功能通常伴随着额外的要求，例如验证文件类型、名称和最大大小，确定最佳存储解决方案，提供有意义的响应，以及通过流式传输有效地处理大文件。在本节中，我们将详细讨论这些常见主题。
- en: When designing controllers to handle file uploads, it is essential to ensure
    that the parameter for the uploaded file is defined using the Spring Web interface,
    that is, the Spring Boot interface that represents an uploaded file in a multi-part
    request— `org.springframework.web.multipart.MultipartFile` . Additionally, the
    request must have its `Content-Type` set to `multipart/form-data` , the standard
    format used by web browsers for uploading files, so this format is also expected
    by an API service using `MultipartFile` .
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 当设计用于处理文件上传的控制器时，确保使用 Spring Web 接口定义上传文件的参数至关重要，即表示多部分请求中上传文件的 Spring Boot
    接口——`org.springframework.web.multipart.MultipartFile`。此外，请求必须将其`Content-Type`设置为`multipart/form-data`，这是网络浏览器用于上传文件的常用格式，因此使用`MultipartFile`的
    API 服务也期望这种格式。
- en: We can demonstrate the upload and download functionality by adding a subresource,
    `/products/{productId}/photo` , to our example Product API, which will represent
    a photo image of the product.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过向我们的示例产品API添加一个子资源 `/products/{productId}/photo` 来演示上传和下载功能，这将代表产品的照片图像。
- en: 'The following is an example HTTP request and method to upload a single file:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个上传单个文件的示例HTTP请求和方法：
- en: '[PRE14]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `multipart/form-data` format represents a form that can contain multiple
    fields. It is also possible to use it to upload multiple files in one request.
    This is why the `"file"` parameter name in the preceding example is important
    for identifying the file our code wants to work with.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`multipart/form-data` 格式表示一个可以包含多个字段的表单。它也可以用于在单个请求中上传多个文件。这就是为什么在先前的示例中，“file”参数名称对于识别代码想要处理的文件非常重要。'
- en: 'The following is an example HTTP request:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例HTTP请求：
- en: '[PRE15]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'And the following is the method to upload multiple files:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是多文件上传的方法：
- en: '[PRE16]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Our example code stores the uploaded file content as a **large object** ( **LOB**
    ) in the relational database for simplicity. Relational databases are not optimized
    for this kind of data, so in large-scale systems, other types of storage are commonly
    used.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例代码为了简单起见，将上传的文件内容作为关系数据库中的**大型对象**（**LOB**）存储。关系数据库没有针对这类数据进行优化，所以在大规模系统中，通常使用其他类型的存储。
- en: The file could be saved in an external storage provider, such as AWS S3. This
    cloud-based storage solution efficiently manages files, providing a link for accessing
    the stored content. This approach is increasingly popular in the industry as it
    optimizes resource management and leverages the scalability of cloud infrastructure.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 文件可以保存在外部存储提供者，如AWS S3。这种基于云的存储解决方案有效地管理文件，提供访问存储内容的链接。这种方法在行业中越来越受欢迎，因为它优化了资源管理并利用了云基础设施的可扩展性。
- en: By saving files in cloud data storage and exposing only the link through the
    API, developers can avoid loading large resources directly. This not only enhances
    performance but also improves response times for clients, allowing them to retrieve
    files as needed without overloading the API.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在云数据存储中保存文件并通过API仅暴露链接，开发者可以避免直接加载大量资源。这不仅提高了性能，还改善了客户端的响应时间，使他们能够按需检索文件，而不会过载API。
- en: In the preceding examples, the API returns a string in the response, so the
    returned string could be used to pass the cloud storage URL.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在先前的示例中，API在响应中返回一个字符串，因此返回的字符串可以用来传递云存储URL。
- en: It is advisable to validate uploaded files to ensure security, data integrity,
    and performance. Some of the possible validations are described in the following
    section.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 建议验证上传的文件以确保安全性、数据完整性和性能。以下部分描述了一些可能的验证。
- en: Validating the uploaded files
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 验证上传的文件
- en: The validation step is critical not only for RESTful APIs but also for any system
    that you may be developing, to maintain the integrity and security of your application.
    The inputs you receive can make the application vulnerable to several distinct
    kinds of attacks. Let us see some examples of important validations to be performed
    when uploading files.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 验证步骤对于RESTful API至关重要，对于您可能正在开发的任何系统也是如此，以维护应用程序的完整性和安全性。您接收到的输入可以使应用程序容易受到多种不同类型的攻击。让我们看看在上传文件时需要执行的一些重要验证示例。
- en: Validating the file content type
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 验证文件内容类型
- en: 'Accepting files of only a certain type would be a good measure to avoid receiving
    malicious files or even data that does not comply with the data you need to store.
    In the following example, you ensure that you will only receive PNG and JPEG files:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 仅接受特定类型的文件是一个很好的措施，可以避免接收恶意文件或不符合您需要存储的数据的数据。在以下示例中，您确保只会收到PNG和JPEG文件：
- en: '[PRE17]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Please note that the content type of the whole HTTP request body will be `multipart/form-data`
    , but each of the files it contains also has its own content type. This is why
    we need to check the content type using the `getContentType` method of the particular
    `MultipartFile` object we are going to process.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，整个HTTP请求体的内容类型将是 `multipart/form-data`，但其中包含的每个文件也有其自己的内容类型。这就是为什么我们需要使用我们即将处理的特定
    `MultipartFile` 对象的 `getContentType` 方法来检查内容类型。
- en: Besides the content of the file, our example Product API stores the content
    type of the uploaded file. The same content type is returned by the `GET` endpoint
    when the file is downloaded. Without the correct `Content-Type` header, opening
    the URL in a web browser would display gibberish because the browser would not
    know how to interpret the downloaded file bytes.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Validating the file size
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Validating the size of a file is a measure to avoid processing files that are
    bigger than expected, which can cause denial of service by exhaustion of memory
    due to the overloading of the system with excessively large files, irrespective
    of whether the upload is intentional or not.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'We can check the file size programmatically using the respective method of
    the `MultipartFile` class:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'File uploads are also limited for the whole application by Spring configuration
    properties specifying the maximum acceptable multipart request size and the maximum
    size of one file within such a request. You can set the properties in the `application.yml`
    or `application.properties` file:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Validating filenames
  id: totrans-169
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To improve file upload security on your server, validating filenames is essential
    to prevent attacks such as path traversal, where attackers attempt to access restricted
    areas on your server’s filesystem. For example, an attacker might use a filename
    such as `../../etc/passwd` to try to access sensitive files outside the intended
    upload directory.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Path traversal attacks can be particularly dangerous in file uploads. By manipulating
    the file path, an attacker may exploit weak validation to save files in unintended
    locations on the server, potentially leading to the exposure of sensitive data
    or even overwriting critical files. For example, if the server directly appends
    a user-provided filename to an upload path, an attacker could use `../` sequences
    to navigate up the directory structure, allowing them to access or modify restricted
    files. This is why validation is crucial when handling file paths, especially
    in upload scenarios.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: 'While there are several ways to prevent path traversal attacks, here are some
    effective strategies:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '**Set user and file permissions carefully** : Restrict permissions to limit
    access only to necessary users and directories.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Store files separately** : Consider storing uploaded files on a different
    server or in a secure storage service such as AWS S3. By keeping files off the
    main server, you reduce the risk of unauthorized access to your system’s file
    structure.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Validate the file path** : Ensure that the file path points to a specific
    folder that is expected for the files to be sent.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use secure file upload resolvers** : In Spring, classes such as `CommonsMultipartResolver`
    and `StandardServletMultipartResolver` , as resolvers, are responsible for resolving
    or interpreting multipart data within a request and help manage file uploads securely.
    They separate file parts from other form data and make them accessible as `MultipartFile`
    objects within Spring’s request-handling framework. Both of these classes are
    responsible for parsing multipart file requests, which are commonly used in file
    uploads. They handle the file data separately from user input, which helps prevent
    injection attacks:'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用安全的文件上传解析器**：在Spring中，如`CommonsMultipartResolver`和`StandardServletMultipartResolver`之类的类作为解析器，负责解析或解释请求中的多部分数据，并帮助安全地管理文件上传。它们将文件部分与其他表单数据分开，并在Spring的请求处理框架中将它们作为`MultipartFile`对象提供。这两个类都负责解析常见的多部分文件请求，这些请求通常用于文件上传。它们将文件数据与用户输入分开处理，这有助于防止注入攻击：'
- en: '**CommonsMultipartResolver** : This class, part of the Apache Commons `FileUpload`
    library, allows you to configure file size limits and temporary storage directories.
    It offers flexibility for applications that require strict control over file storage
    and performance. By setting up limits and constraints through `CommonsMultipartResolver`
    , you can mitigate risks such as excessive file uploads or unauthorized access
    to temporary storage.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CommonsMultipartResolver**：这个类是Apache Commons `FileUpload`库的一部分，允许您配置文件大小限制和临时存储目录。它为需要严格控制文件存储和性能的应用程序提供了灵活性。通过通过`CommonsMultipartResolver`设置限制和约束，您可以减轻过度文件上传或未经授权访问临时存储等风险。'
- en: '**StandardServletMultipartResolver** : This is a resolver in Spring that leverages
    the built-in multipart support provided by Servlet 3.0, making it a reliable and
    efficient choice for handling file uploads in Spring applications. By relying
    on the servlet container’s native multipart processing, this resolver avoids the
    need for additional libraries, simplifying setup and maintenance.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**StandardServletMultipartResolver**：这是一个Spring框架中的解析器，它利用Servlet 3.0提供的内置多部分支持，使其成为处理Spring应用程序中文件上传的可靠且高效的选项。通过依赖Servlet容器本地的多部分处理，这个解析器避免了需要额外的库，简化了设置和维护。'
- en: These resolvers not only simplify file handling but also help mitigate potential
    security vulnerabilities by handling multipart file requests in a standardized
    way. This ensures that files are processed according to predefined rules, which
    reduces the risk of path traversal and other injection attacks.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这些解析器不仅简化了文件处理，而且通过以标准化的方式处理多部分文件请求，有助于减轻潜在的安全漏洞。这确保了文件将根据预定义的规则进行处理，从而降低了路径遍历和其他注入攻击的风险。
- en: When working with files stored on your application’s server, remember not to
    rely solely on methods such as `StringUtils.cleanPath` . Although commonly used,
    it should not be the only security measure because it does not fully protect against
    path traversal. As noted in the Spring documentation (v6.1.12), “ `cleanPath`
    *should not be depended upon in a security context* .”
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理存储在应用程序服务器上的文件时，请记住不要仅依赖`StringUtils.cleanPath`等方法。尽管这些方法被广泛使用，但它们不应是唯一的安全措施，因为它们不能完全防止路径遍历。正如Spring文档（v6.1.12）中所述，“`cleanPath`
    *不应在安全环境中依赖*。”
- en: To enhance filename sanitization, you can use the `FilenameUtils` class from
    the Apache Commons IO library. This utility class provides methods to manipulate
    and sanitize filenames safely.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增强文件名的消毒，您可以使用Apache Commons IO库中的`FilenameUtils`类。这个实用工具类提供了安全地操作和消毒文件名的各种方法。
- en: 'Here are some examples of codes that would help to cover some file upload validations:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些有助于覆盖一些文件上传验证的代码示例：
- en: '[PRE20]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This approach provides a thorough sanitization and validation of filenames,
    ensuring that they do the following:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法提供了对文件名的彻底消毒和验证，确保它们执行以下操作：
- en: Conform to expected characters and formats
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 符合预期的字符和格式
- en: Have reasonable length limits
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有合理的长度限制
- en: Are restricted to allowed file types
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制在允许的文件类型范围内
- en: Are stored only within the intended directory
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅存储在预期的目录中
- en: Are optionally assigned a unique name to prevent conflicts
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可选地分配一个唯一名称以防止冲突
- en: By combining these security measures and utilizing `FilenameUtils` for safe
    file name manipulation, you can ensure that file uploads remain secure. This reduces
    the chance of path traversal attacks and protects your application from unauthorized
    access. Even if your application stores files on a service such as AWS S3, validating
    filenames contributes to a consistent, secure, and user-friendly experience.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合这些安全措施并利用`FilenameUtils`进行安全的文件名操作，您可以确保文件上传保持安全。这减少了路径遍历攻击的机会，并保护您的应用程序免受未经授权的访问。即使您的应用程序在AWS
    S3等服务上存储文件，验证文件名也有助于保持一致、安全且用户友好的体验。
- en: Using storage services such as AWS S3 can simplify file upload handling by offloading
    certain security concerns from your application server. Since S3 and similar services
    store files in a managed environment separate from your server’s filesystem, they
    reduce the risk of path traversal attacks, where an attacker might attempt to
    save or access files in unauthorized locations. By isolating storage, these services
    protect your core infrastructure from direct interaction with uploaded files,
    reducing the potential impact of improperly validated file paths or names.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AWS S3等存储服务可以通过将某些安全关注点从您的应用程序服务器卸载来简化文件上传处理。由于S3和类似服务在与管理您的服务器文件系统分离的管理环境中存储文件，它们减少了路径遍历攻击的风险，攻击者可能会尝试在未经授权的位置保存或访问文件。通过隔离存储，这些服务保护了您的核心基础设施免受与上传文件的直接交互，减少了不正确验证的文件路径或名称可能带来的潜在影响。
- en: Additionally, AWS S3 automatically generates unique URLs or identifiers for
    uploaded files, which minimizes the need for name conflict resolution and additional
    filename validation. S3 enforces secure naming conventions and ensures that uploaded
    files are stored safely without affecting other areas of your application. This
    means your application can focus on verifying basic attributes, such as file type
    or size, without worrying as much about path traversal or directory restrictions,
    streamlining the file upload process and enhancing overall security.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，AWS S3自动为上传的文件生成唯一的URL或标识符，这最大限度地减少了名称冲突解决和额外文件名验证的需求。S3强制执行安全的命名约定，并确保上传的文件安全存储，不影响应用程序的其他区域。这意味着您的应用程序可以专注于验证基本属性，如文件类型或大小，而不必过多担心路径遍历或目录限制，从而简化文件上传过程并增强整体安全性。
- en: After implementing thorough validation to secure filenames and mitigate risks
    such as path traversal attacks, it is crucial to consider how our API communicates
    the outcome of the file upload process. Providing clear, meaningful responses
    ensures that clients are informed about the status of their upload attempts, whether
    successful or not. Effective responses do more than acknowledge success—they also
    guide users when an error occurs, helping them understand what went wrong and
    how to correct it. By returning specific HTTP status codes and relevant metadata,
    we can make the file upload process more transparent, reliable, and user-friendly.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施彻底的验证以确保文件名安全并减轻如路径遍历攻击等风险之后，考虑我们的API如何传达文件上传过程的结果至关重要。提供清晰、有意义的响应确保客户了解其上传尝试的状态，无论成功与否。有效的响应不仅承认成功——当发生错误时，它们还指导用户了解出了什么问题以及如何纠正它。通过返回特定的HTTP状态码和相关的元数据，我们可以使文件上传过程更加透明、可靠和用户友好。
- en: Providing meaningful responses on our API service for file upload
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在我们的API服务上提供文件上传的有意义响应
- en: 'Provide clear feedback to the client regarding the result of the upload by
    using appropriate HTTP status codes:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用适当的HTTP状态码，向客户端提供有关上传结果的明确反馈：
- en: '`201 Created` : When a file is successfully uploaded'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`201 Created`：当文件成功上传时'
- en: '`415 Unsupported Media Type` : For invalid file types'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`415 Unsupported Media Type`：对于无效的文件类型'
- en: '`413 Payload Too Large` : If the file size exceeds the allowed limit'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`413 Payload Too Large`：如果文件大小超过允许的限制'
- en: '`400 Bad Request` : For other validation errors'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`400 Bad Request`：对于其他验证错误'
- en: Include metadata in the response, such as the file URL or identifier for future
    downloads.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在响应中包含元数据，例如文件URL或标识符，以便将来下载。
- en: After covering these fundamental yet essential details and highlighting specific
    precautions for handling files within your API, it becomes clear that even seemingly
    minor implementations can lead to potential vulnerabilities. Such weaknesses may
    act as critical points of failure, potentially destabilizing the entire API. For
    instance, a single malformed file could disrupt API operations, or an attack exploiting
    file-naming conventions might provide an entry point for malicious actors. The
    intention of covering this topic was to call your attention to these scenarios
    that you may encounter when dealing with files on your API.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Earlier in this chapter, we introduced HATEOAS while discussing pagination to
    demonstrate how hypermedia links can enhance navigation through large datasets.
    Now, we’ll explore HATEOAS in greater detail as it represents a broader architectural
    pattern that goes beyond pagination, offering a more sophisticated approach to
    API interaction and resource discovery.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: HATEOAS
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: HATEOAS, as mentioned in the *Pagination* section, is a key principle of RESTful
    APIs that improves the client’s interaction by including navigational links within
    the response. These hyperlinks guide the client on how to access related resources
    without needing prior knowledge of the API structure. As we saw before, in a paginated
    response, HATEOAS can provide links to the next and previous pages, enabling smooth
    navigation through data without requiring hardcoded logic.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: By using HATEOAS, APIs become more self-explanatory and adaptable to changes.
    Clients can discover available actions, such as editing or deleting, directly
    from the response, based on the provided links. This simplifies API usage and
    ensures flexibility, as clients do not have to rely on external documentation
    to understand the API’s behavior, reducing the chance of errors when updates occur.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us see an example of using HATEOAS to expose available operations on a
    resource:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In the preceding example, the response contains three elements in the `links`
    section. The first element, `"rel": "self"` , indicates the link to the current
    resource itself. This allows the client to retrieve or interact with a specific
    user using the `GET` method at the URL provided in the `href` (which stands for
    hypermedia reference) attribute. The second element, `"rel": "edit"` , provides
    a link for updating the user’s details with the `PUT` method. Lastly, the `"rel":
    "delete"` element allows the client to remove the user with the `DELETE` method.
    Each of these links guides the client through interactions with the resource,
    making the API self-explanatory and easier to use.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: HATEOAS, as outlined in RFC 8288, formalizes the use of web links in APIs, ensuring
    consistency and clarity in how these links are structured and interpreted. This
    RFC defines key components such as the `rel` attribute, which specifies the relation
    type of a link (e.g., `"self"` or `"edit"` ), and `href` , which defines the target
    URL for the interaction. By adhering to this standard, APIs become more robust,
    with clients able to navigate resources and perform actions without needing to
    hardcode endpoint paths or refer to external documentation. This approach enhances
    flexibility and future-proofs API interactions, as the server can evolve while
    still maintaining compatibility with existing clients.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: HATEOAS，如RFC 8288所述，正式化了在API中使用Web链接，确保了这些链接的结构和解释的一致性和清晰性。此RFC定义了关键组件，如`rel`属性，它指定了链接的关系类型（例如，`"self"`或`"edit"`），以及`href`，它定义了交互的目标URL。通过遵循此标准，API变得更加健壮，客户端能够导航资源并执行操作，而无需硬编码端点路径或参考外部文档。这种方法增强了灵活性并确保API交互的未来兼容性，因为服务器可以进化，同时仍然与现有客户端保持兼容性。
- en: 'The same example we saw before can also have a different response, where certain
    actions—such as deleting the element—are not available. For instance, in the following
    example, the response for the user `"Jane Smith"` does not include a `"delete"`
    link in the `links` section:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前看到的相同示例也可以有不同的响应，其中某些操作（如删除元素）不可用。例如，在以下示例中，对用户`"Jane Smith"`的响应在`links`部分不包括`"delete"`链接：
- en: '[PRE22]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In this case, the absence of the `delete` link indicates that the `delete` operation
    is not available for this resource, due to permission restrictions or business
    rules. HATEOAS helps make these limitations clear to the client, ensuring that
    the client does not attempt unsupported actions. This allows the API to dynamically
    control which actions are allowed, preventing misuse and guiding the client’s
    behavior based on the current state of the resource.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`delete`链接的缺失表明由于权限限制或业务规则，此资源不支持`delete`操作。HATEOAS有助于向客户端清晰地展示这些限制，确保客户端不会尝试执行不支持的操作。这允许API动态控制哪些操作是允许的，防止滥用并根据资源当前状态引导客户端的行为。
- en: 'To simplify the implementation of HATEOAS, modern API frameworks offer built-in
    tools to support this pattern. For example, in Spring Boot, you can leverage the
    `spring-boot-starter-hateoas` dependency to easily incorporate HATEOAS into your
    API:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化HATEOAS的实现，现代API框架提供了内置工具来支持此模式。例如，在Spring Boot中，你可以利用`spring-boot-starter-hateoas`依赖项轻松地将HATEOAS集成到你的API中：
- en: '[PRE23]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: HATEOAS enhances the dynamism of the API, advancing it to a higher level of
    maturity by incorporating all the benefits we have mentioned so far. However,
    it is important to evaluate whether this resource is necessary for your use case,
    as HATEOAS is not a mandatory component for every API. It requires another dependency,
    additional development, and maintenance, and then requires attention to understand
    whether it makes sense to have it.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: HATEOAS增强了API的动态性，通过结合我们之前提到的所有好处，将API提升到一个更高的成熟水平。然而，评估此资源是否适用于你的用例是很重要的，因为HATEOAS不是每个API的强制组件。它需要另一个依赖项、额外的开发和维护，并且需要关注是否值得拥有它。
- en: We have covered essential practices for building a reliable and user-friendly
    API by employing efficient data-handling techniques. Now, as we transition to
    resilience patterns, we will explore strategies that help APIs maintain stability
    and robustness, even in the face of unexpected challenges. Resilience is crucial
    for ensuring that an API continues to function reliably under various adverse
    conditions, from network issues to system overloads. In the upcoming section,
    we will dive into patterns that enable APIs to handle such scenarios gracefully,
    enhancing their dependability and user experience.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经通过采用高效的数据处理技术，介绍了构建可靠且用户友好的API的基本实践。现在，随着我们转向弹性模式，我们将探讨帮助API在面临意外挑战时保持稳定和健壮性的策略。弹性对于确保API在各种不利条件下继续可靠地运行至关重要，从网络问题到系统过载。在接下来的部分中，我们将深入研究使API能够优雅地处理此类场景的模式，从而增强其可靠性和用户体验。
- en: Resilience
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 弹性
- en: 'Before discussing how to make an API resilient, let’s look at the Oxford English
    dictionary’s definition for resilience: “ *(of a person or animal) able to withstand
    or recover quickly from difficult conditions.* ” If we try to apply the same definition
    to our RESTful APIs or systems in general, we could say that a resilient API is
    an API that can withstand failures and disruptions while maintaining its functionality
    and performance, recovering from situations that could shut it down or cause a
    degradation in performance.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: To ensure that an API serves as a reliable component of a larger, robust system,
    it must handle excess spikes, performance degradation of services it depends on,
    and infrastructure failures effectively. For that, we need to observe several
    aspects of the API design that we are going to approach. We will explore strategies
    and techniques to achieve these capabilities, ensuring your APIs can deliver consistent
    value.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: 'Regarding API design, the key principles that we need to observe are the following:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '**Redundancy** : Have multiple instances of our components/services to avoid
    a single point of failure.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decoupling** : Minimize dependencies in the design, aiming to limit impact
    during any system part failure.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimize direct dependencies within a system’s design by reducing the interconnections
    between its components, which helps limit the impact of any single component’s
    failure. When an API is tightly coupled to other services or components, an issue
    in one part can cascade throughout the system, leading to widespread failures
    or degraded performance. By contrast, a decoupled system allows components to
    operate more independently, isolating faults and preventing them from affecting
    other parts.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fault isolation** : Use techniques such as bulkheads and circuit breakers
    to confine failures to isolated parts of the system, preventing error states from
    propagating throughout the entire system, as would occur with a “poison pill.”'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Graceful degradation** : Keep limited functionality even when parts of the
    system fail or are underperforming. This way prioritizes the main functionalities,
    preventing the entire system from stopping.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let us list some concepts and patterns that we will talk about and the problems
    that each one of them can help us to solve:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Timeouts
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retry mechanisms
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rate limiting and throttling
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Idempotency key
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Circuit breaker
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bulkhead
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Timeouts
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Establishing appropriate timeout settings is critical when designing APIs to
    ensure system resilience. API interactions often involve synchronous remote calls
    between services, whether they reside on the same network or across different
    networks. This synchronous communication means that the client remains unaware
    of the server’s processing status, maintains the network connection, and waits
    until the call either succeeds or fails. Without well-defined timeouts, clients
    might experience prolonged wait times for responses, which can degrade user experience,
    introduce security vulnerabilities, and cause system instability or downtime.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: 'The timeout can be set from two perspectives:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Client configuration
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Server configuration
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Client configuration
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Configuring timeouts on the client side is essential to prevent clients from
    waiting indefinitely for a server response. By setting a specific timeout duration,
    the client ensures that it does not become unresponsive due to delayed server
    replies. When the server fails to respond within the designated timeout period,
    the client should do the following:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '**Alert users** : Inform users about the delay to maintain transparency and
    manage expectations'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Log the event** : Record the timeout occurrence in logs for monitoring and
    troubleshooting purposes'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Initiate retry mechanisms** : Depending on the application requirements,
    the client may attempt to resend the request to recover from transient issues'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s implement the timeout for the API client using Spring Boot’s `RestClient`
    . In our example, we will configure a timeout of six seconds, striking a balance
    between allowing sufficient time for normal operations and preventing excessive
    waiting periods. Here is how to configure `RestClient` with the appropriate timeout
    settings:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This example demonstrated how to configure `RestClient` with appropriate timeout
    settings to establish connections and receive data. Let us set up these timeouts
    to ensure our client avoids waiting too long for server responses.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: Server configuration
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When a server receives a request, it begins processing the necessary information,
    which may involve interacting with other servers, executing database queries,
    and performing various computational tasks. If these operations exceed the predefined
    timeout threshold, the server should do the following:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '**Terminate processing** : Stop any ongoing operations related to the request
    to free up resources'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Release allocated resources** : Ensure that resources such as memory, threads,
    and database connections are properly released to prevent leaks and bottlenecks'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Notify the client** : Inform the client that a timeout has occurred using
    the appropriate HTTP error code, `408 Request Timeout` , allowing the client to
    handle the situation appropriately (e.g., by retrying the request or notifying
    the user)'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before setting a timeout, it is important to observe the typical responses of
    your service and network conditions; this will allow you to have a proper notion
    of what is a “normal” expected time to respond, because setting a very short timeout
    can cause unnecessary failures, whereas a very long timeout can lead to poor user
    experience. The best application of this practice requires constant monitoring
    of the timeout metrics and adjusting configurations, both client and server, to
    maintain a healthy, resilient, and sustainable API.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate client timeout settings in a Spring Boot application, you can
    configure the connection timeout and read timeout within `ClientHttpRequestFactorySettings`
    . This class is responsible for setting up the HTTP request factory with specific
    timeout parameters. These settings are then used to create a `RestClient` instance,
    which is a component for executing HTTP requests to other services. For more detailed
    information on this configuration, please refer to the `ProductsApiConfiguration`
    class in the `chapter6` folder of the book’s source code repository.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: While the last example focuses on client-side configuration, it’s worth noting
    that server-side timeout configuration in Spring Boot typically involves setting
    properties in your `application.properties` or `application.yml` file.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: 'Take the following example:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This sets the server’s connection timeout to five seconds. The specific properties
    and their effects can vary depending on the server you’re using (e.g., Tomcat
    or Jetty).
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: The previous examples show basic client-side and server-side timeout configurations.
    However, in more complex applications, you might need more advanced timeout management.
    The example in this book is intentionally simple to focus on key concepts. For
    real-world applications, especially those with complex database operations or
    microservices, you might find more sophisticated libraries, such as Resilience4j,
    useful.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: 'Resilience4j offers a `TimeLimiter` module that provides detailed control over
    timeouts and works well with Spring Boot applications. While this level of complexity
    is not necessary for our basic example, understanding these advanced techniques
    can be valuable as your applications become more complex. Here’s an example using
    Resilience4j version 2.2.0 to manage timeouts in a more advanced scenario:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the Resilience4j dependency to your project:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Configure `TimeLimiter` in your `application.yml` :'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Implement the service with `TimeLimiter` :'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Use the service in a controller:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'In this example, note the following:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: We have an instance of `TimeLimiter` that is built by a named `TimeLimiterRegistry`
    using the configuration named `productServiceGetById` , which has a configuration
    for a five-second timeout.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `ProductsQueryUseCaseImpl.getProductById()` method uses the `timeLimiter.executeCompetionStage()`
    method, which wraps the repository call in a `CompletableFuture` to make it asynchronous.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a real scenario, if a complex database query or high server load causes a
    delay, it will be detected by this `timeLimiter` call, throwing one exception.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That will be detected by the controller’s `try/catch` and return a timeout HTTP
    code.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: This example shows how to apply timeouts to specific service methods, such as
    those involving database operations. Although it is more complex than the book’s
    main example, it demonstrates how you can improve your timeout strategies as your
    application’s needs grow.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: In practice, you would choose the appropriate level of timeout management based
    on your specific requirements. You might start with simpler approaches and move
    to more advanced solutions, such as Resilience4j, as your system becomes more
    complex.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: 'While timeouts are crucial for maintaining system responsiveness, they often
    work hand in hand with another important resilience pattern: retry mechanisms.
    When a timeout occurs, it may be due to temporary issues that could be resolved
    quickly. In such cases, automatically retrying the operation can help maintain
    service continuity without user intervention. Let’s explore how retry mechanisms
    complement timeout strategies and enhance overall system resilience.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: Retry mechanism
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Implementing a retry mechanism is an effective strategy to prevent the temporary
    unavailability of a system component from disrupting the entire chain of dependent
    processes. While retries can mitigate temporary failures, excessive or inappropriate
    retries can exacerbate issues, leading to resource exhaustion and degraded performance.
    We will present how to properly deal with this here.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: 'There are countless reasons why an API might fail to complete a process cycle,
    affecting various tasks within a request. Here are some cases that you can handle
    with retries:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: Timeouts
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 5xx server errors (e.g., `500 Internal Server Error` or `503 Service Unavailable`
    )
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rate limiting (e.g., `429 Too Many Requests` )
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Consider an e-commerce platform where verifying the stock count of a product
    is a critical step in finalizing a sale. Suppose the product stock verification
    API typically responds within 2 to 5 seconds. If this API experiences a temporary
    delay or failure, implement a retry mechanism to ensure that the transaction can
    still proceed without unnecessary abandonment. Take the following example:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '**Initial request** : The system requests the stock count'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**First failure** : The API does not respond within the expected period'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Retry attempt** : The system retries the request after a brief delay'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Successful response** : On the second attempt, the API responds successfully,
    allowing the sale to proceed'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This approach minimizes the risk of losing transactions due to temporary API
    unavailability. However, retries can become problematic if the product stock API
    is down and recovery takes longer. Continuous retries without communicating with
    other systems involved in the transaction can lead to a poor customer experience
    and cause considerable damage and loss to the company.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: 'To not get trapped in the pitfalls that we mentioned, you need to consider
    some best practices when implementing your retry policy:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: Set a maximum retry limit
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use exponential backoff with jitter
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have idempotent requests
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement timeout mechanisms
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log retry attempts
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set a maximum retry limit
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Without a maximum retry limit, your system could enter an endless loop of trying
    to resend a failed request. Imagine a scenario where a server is down for an extended
    period. If there is no limit on retries, the system will keep trying to resend
    the request forever, wasting resources and potentially causing other issues.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Use exponential backoff with jitter
  id: totrans-295
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Exponential backoff is a method used to manage the timing of retry attempts
    after a failure. Instead of trying to resend the message at regular intervals,
    the system waits longer each time it fails to resend. The wait time increases
    exponentially, meaning it increases quickly.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us look at an example:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '**First attempt** : If sending the message fails, wait for a brief period of
    time (e.g., one second) before trying again.'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Second attempt** : If it fails again, wait twice as long (e.g., two seconds).'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Third attempt** : Double the wait time, that is, four seconds.'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Continue depending on the limit of tries** : At every new retry, the wait
    time doubles (8 seconds, 16 seconds, etc.).'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This approach helps prevent the system from repeatedly trying to send messages
    too quickly, which can cause more problems, such as overloading the server or
    network.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Jitter
  id: totrans-303
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '**Jitter** is a random time used as a time interval for retrying failed requests.
    Instead of having the retry mechanism make all the calls at a fixed time or even
    with exponential progress, we have a random time for each new retry. Instead of
    waiting exactly 2 seconds, for example, it might wait between 1 and 3 seconds.'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: Combining exponential backoff and jitter
  id: totrans-305
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using only exponential backoff can still cause issues. If many devices or systems
    are trying to resend messages at the same time, they might all wait the same amount
    and then retry together, creating a sudden peak of traffic. This can make the
    network or server even more overwhelming, which is why it is best practice to
    combine exponential backoff and jitter.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: Adding jitter helps by spreading out the retry attempts. Each device waits for
    a slightly different time, reducing the chance that they all send requests at
    the same time. This makes the system more stable and increases the chances that
    messages will be successfully sent.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: Have idempotent requests
  id: totrans-308
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Having idempotent requests when retrying API calls is vital for building resilient
    and reliable systems. It ensures that multiple attempts to perform the same operation
    do not lead to unintended consequences, such as duplicate actions or inconsistent
    data.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: Implement timeout mechanisms
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You are already aware of the importance of timeouts from the previous topic.
    A retry involves sending a new request to the service, and it is essential to
    manage how long we wait before taking the next action.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: Log retry attempts
  id: totrans-312
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Logging each failure during retry attempts will help us understand recurring
    patterns or frequent issues causing the retries, and it will ease system troubleshooting.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: A well-implemented retry mechanism significantly enhances the resilience of
    APIs by gracefully handling transient failures. By adhering to best practices—such
    as limiting retry attempts, employing exponential backoff, guaranteeing idempotent
    retries, and distinguishing error types—developers can ensure that retries contribute
    to system stability without introducing new vulnerabilities. Thoughtful retry
    strategies lead to improved user experiences, higher system reliability, and sustained
    operational efficiency.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: 'Although retry mechanisms help handle temporary failures, unrestricted retries
    could overwhelm your system. This brings us to another crucial resilience pattern:
    rate limiting. By controlling the frequency and volume of requests, rate limiting
    helps maintain system stability even during high-load situations.'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: Rate limiting
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Rate limiting is a critical strategy used to protect APIs from abuse and excessive
    resource access. It ensures the stability, reliability, and security of API systems
    by restricting the number of requests an API can handle from a user (user, IP,
    application, token, etc.) within a specified period. This approach helps to prevent
    **denial of service** ( **DoS** ) attacks and ensures the fair distribution of
    services among clients, preventing exhaustion of resources.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: 'We can apply rate limiting on distinct levels of context; it can be based on
    the following:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '**Global level** : In this context, we can limit the total number of requests
    the API can handle by period'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**IP level** : By IP, we limit the number of requests based on the IP address
    of the client'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User level** : Limits requests based on individual users or clients'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application level** : Limits based on a specific application using the API'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following sections, we will explore some of the aspects of implementing
    rate limiting, such as quota management, time windows, and rate-limiting headers.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: Rate limiting key aspects
  id: totrans-324
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To effectively manage rate limiting, it is essential to understand its core
    components and how they contribute to overall API resilience. Rate limiting is
    not just about restricting requests; it is about controlling access fairly, transparently,
    and scalably, ensuring a stable experience for all users while protecting resources.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will explore three critical aspects of rate limiting:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: '**Quota management** : Defines the maximum number of requests allowed per client
    within a given period (e.g., 1,500 requests per hour).'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time windows** : The period during which the request count is measured. Common
    intervals include per second, minute, hour, or day.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rate limit headers** : APIs often include headers in responses to inform
    clients about their current usage and remaining quota. Examples include the following:'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`X-Rate-Limit-Limit` : The maximum number of requests allowed'
  id: totrans-330
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`X-Rate-Limit-Remaining` : The number of requests left in the current window'
  id: totrans-331
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`X-Rate-Limit-Reset` : The time when the rate limit will reset'
  id: totrans-332
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Provide the proper response HTTP code when it reaches the rating limit**
    : A `429 Too Many Requests` error is advised by RFC 6585.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you know what these aspects are and understand what they mean, let
    us talk about different implementations of rate limiting on your API.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: Rate limiting implementation strategies
  id: totrans-335
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Implementing rate limiting requires careful consideration of various strategies,
    each with its advantages and trade-offs:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: '**Fixed window** : This strategy has the time split into fixed intervals (windows),
    such as one minute. The count of requests is reset at the start of each new window.
    This is the simplest implementation, although it might be susceptible to bursts
    at window boundaries (e.g., a client could send double the allowed requests in
    a brief period and have multiple requests rejected). Depending on the application,
    it may be acceptable to employ this simple strategy to implement and have occasional
    failures.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sliding window** : Unlike fixed windows, sliding windows move continuously.
    For each request, the system checks the number of requests in the past defined
    period for readjusting itself. It will result in a smoother distribution of allowed
    requests over time, reducing the chance of overloaded periods and periods without
    any requests. It has a more complex implementation but shows precise control over
    request rates.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Token bucket** : A bucket holds tokens representing the number of allowed
    requests. Tokens are added, refilling the bucket based on the number of allowed
    requests per configured time. Each request consumes a token. If no tokens are
    available, the request is rejected. It has a slightly more complex logic, but
    will support the APIs that need to handle occasional spikes without compromising
    overall rate limits.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Leaky bucket** : This strategy is like a token bucket but processes requests
    at a fixed rate, queuing requests where the bucket limit is the mark that determines
    whether we accept new requests. If the queue/bucket is full, additional requests
    are rejected. Every time a request is processed from the queue, it opens space
    for a new, incoming request. It can cause an increase in latency due to the queuing.
    However, it will ensure a steady processing rate. This is advantageous for systems
    where maintaining a consistent processing rate is critical.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rate limiting implementation will protect the API against abuse by malicious
    actors overwhelming the API, support resource management, ensure a fair distribution
    of resources among the clients, and maintain the API’s responsiveness by controlling
    the traffic flow.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: While rate limiting focuses on restricting the total number of requests, a related
    but distinct concept is throttling. Understanding the difference between these
    two approaches is crucial for implementing effective request management strategies.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: Gateway-level rate limiting
  id: totrans-343
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: While rate limiting inside individual API services provides good protection,
    implementing rate limiting at the gateway level offers important benefits that
    experienced developers should consider for production systems.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: Single point of control
  id: totrans-345
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: API gateways act as the main entry point for all client requests. This makes
    them perfect places to set up rate-limiting rules. Instead of adding rate-limiting
    code to each service separately, you can manage all policies from one central
    location. This approach reduces complexity and makes maintenance easier across
    your entire system.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: Stopping requests early
  id: totrans-347
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Gateway-level rate limiting blocks excessive requests before they reach your
    application services. When clients send too many requests, the gateway immediately
    returns a 429 error code without using any backend resources, such as database
    connections or server processing power. This early blocking protects your system
    during traffic spikes and saves computing resources.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: System-wide rate limiting
  id: totrans-349
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In complex systems where clients use multiple services, gateway rate limiting
    lets you set limits across your entire API. For example, you can limit a user
    to 5,000 requests per hour across all services, not just individual ones. This
    prevents clients from avoiding limits by spreading requests across different endpoints.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: Implementation options
  id: totrans-351
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Popular gateway tools such as Kong, AWS API Gateway, and Nginx offer built-in
    rate-limiting features. These tools support different strategies, such as the
    token bucket and sliding window methods. When using multiple gateway servers,
    consider using shared storage such as Redis to track request counts accurately
    across all servers.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: Gateway-level rate limiting works best when combined with service-level rate
    limiting. Use gateways for general limits and overall system protection, while
    keeping specific business rules and detailed limits within individual services.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: Throttling
  id: totrans-354
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Throttling** , on the other hand, manages the rate at which requests are
    handled. Instead of limiting the total number of requests, throttling makes sure
    that requests are processed at a steady pace. This is often done by queuing or
    delaying requests to keep the system stable.'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: For real-time data, the API limits how frequently each user can make requests
    to prevent server overload. In this case, each user can make only one request
    per second. If a user sends requests faster than this, throttling will slow down
    their requests, but will not block them completely.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how it works:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: User X sends three requests in one second.
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The API processes the first request immediately.
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The API delays the second and third requests, ensuring each request is spaced
    one second apart.
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Throttling controls the pace of requests, allowing the server to handle high-frequency
    requests without being overwhelmed.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: What is the difference between rate limiting and throttling, then?
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: '**Rate limiting** : Controls the total number of requests over a period (e.g.,
    500 requests per hour)'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Throttling** : Controls the speed of requests, slowing them down if they
    come in too quickly (e.g., one request per second)'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using both together ensures that the API remains responsive and fair, even with
    high demand.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: Throttling implementation strategies
  id: totrans-366
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following are some of the throttling implementation strategies:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: '**Dynamic throttling** : Adjusts limits based on real-time system performance
    and load. This implementation is more responsive to changing conditions, although
    it requires sophisticated monitoring and adjustment mechanisms.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Priority-based throttling** : Assigns priorities to different types of requests
    or clients. In this way, it ensures critical operations have access to necessary
    resources; however, this approach is complex to manage.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Graceful degradation** : Reduces functionality or performance in a controlled
    manner when under high load. During peak usage, this strategy maintains some level
    of service. This strategy may come at the cost of some periods of bad user experience.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Circuit breaker pattern** : Temporarily stop requests flowing to some specific
    route, to prevent system overload and allow recovery. It will protect the system
    against cascading failures. As a side effect, it may require careful configuration
    to avoid unnecessary shutdowns.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Throttling helps ensure the reliability of APIs, maintaining stability under
    varying conditions. It allocates resources efficiently based on current demands,
    preventing slowdowns and outages, and maintaining the consistency of the service.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: This strategy is used by many large API providers, such as Microsoft’s GitHub
    API, which has a detailed rate-limiting system based on distinct levels. The level
    is determined by the number of simultaneous requests you make.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: To simplify things, let us assume we are at the most basic level. In this case,
    rate limits depend on our authentication. For example, unauthenticated requests
    that can access public data have their specific limits. Authenticated requests,
    on the other hand, have different rate limits (bigger) depending on the type of
    authentication, such as using a token or OAuth.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: This does not mean you need to implement something that complex. This is an
    example of how rate limits can help manage the demand on your API, depending on
    the level of implementation. It depends only on your needs and creativity.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: A quite simple example where you can find rate limits widely used on the market
    of API providers is the limiting of the usage for the free user plan, as you can
    see on different Google APIs, for example.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: Rate limiting and throttling are essential mechanisms for API management, helping
    to maintain the integrity and reliability of services. Rate limiting focuses on
    controlling the number of requests per client within a specific time, while throttling
    employs strategies to manage overall traffic flow and system performance.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: For API providers, implementing effective rate limiting and throttling ensures
    fair usage, protects against abuse, and maintains optimal performance. For API
    consumers, understanding these mechanisms allows for the design of resilient applications
    that interact smoothly with APIs, handle limitations gracefully, and provide a
    seamless user experience.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: Managing the request flow through throttling is important, but ensuring request
    consistency is equally crucial. This is where idempotency comes into play, particularly
    when dealing with retried requests that might have succeeded but failed to communicate
    their success.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: Idempotency key
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To understand why an idempotency key is necessary, it is essential to first
    understand the concept of idempotency. If you do not recall this from the second
    chapter, now is a good time to revisit that section. In simple terms, idempotency
    means calling the API multiple times with the same parameters while ensuring that
    the state remains unchanged and no unintended side effects occur.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: According to the idempotency key RFC (there is no defined number yet) about
    the idempotency key header, “The HTTP Idempotency-Key request header field can
    be used to carry an idempotency key in order to make non-idempotent HTTP methods
    such as `POST` or `PATCH` fault-tolerant.”
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine the following scenario: we have a frontend that sends an order to our
    management order API, and this happens when the user clicks on the **Save Order**
    button; this will trigger the code that will make a `POST` call with all the data
    required to create a new order. Let us imagine that due to internet instability,
    the user does not see the result on the screen as fast as usual and hits this
    button multiple times. This means we will receive multiple `POST` calls with the
    same data. As an undesirable side effect, we would have the same order repeated
    multiple times, which causes an inconsistency in our system.'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: If our frontend added on each call a header item `"Idempotency-Key"` , a key
    that satisfies the requirement that its value is the same if and only if it is
    the same request (order) from a business perspective, it would prevent this undesirable
    side effect of having multiple wrong records stored on the management API because
    `"Idempotency-Key"` would serve as a unique key to avoid these repetitions.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of one call to an API that requires the usage of an idempotency
    key:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: In the preceding example, we have the `"Idempotency-Key"` header, and this header
    is sent by the request client. The Stripe documentation recommends generating
    a key with V4 UUIDs, or another random string with enough entropy to avoid collisions.
    By doing so, we can guarantee idempotency even for methods that are not idempotent.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: In summary, using an idempotency key is crucial for maintaining the reliability
    and consistency of APIs, especially when handling non-idempotent requests such
    as `POST` or `PATCH` . By assigning a unique key to each request, developers can
    prevent duplicate actions, such as multiple orders being created unintentionally.
    This approach ensures that even if a user sends the same request multiple times
    due to network issues or repeated clicks, the system remains stable and accurate.
    Implementing idempotency keys not only safeguards the integrity of the data but
    also enhances the user experience by avoiding errors and inconsistencies. Adhering
    to best practices, such as generating unique and secure keys, further strengthens
    the API’s resilience and fault tolerance.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: '![img](img/Information_Box_Icon.png)'
  id: totrans-389
  prefs: []
  type: TYPE_IMG
- en: '**UUID V4**'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: A UUID V4 is a 128-bit value used to uniquely identify information in computer
    systems. It is randomly generated and follows a specific format to ensure uniqueness.
    Unlike other versions, a V4 UUID relies on random numbers, which makes it highly
    unlikely to generate duplicates. This type of identifier is often used when a
    unique reference is needed, such as in database entries or API requests, to ensure
    data consistency and prevent collisions.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: While idempotency ensures request consistency, it does not address the broader
    challenge of handling failing downstream services. The circuit breaker pattern
    offers a solution by preventing cascading failures in distributed systems.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: Circuit breaker
  id: totrans-393
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Inspired by electrical circuit breakers, which protect electrical systems from
    damage caused by overloads or short circuits, the circuit breaker pattern in software
    works analogously. It helps prevent system failures by stopping repeated attempts
    at unsuccessful operations until the system recovers. Just like in an electrical
    circuit, when the switch is closed, energy flows through, but opening the switch
    disrupts the flow.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: When a certain number or percentage of failures is detected, the pattern opens
    the faulty circuit or component and redirects all requests to a fallback routine.
    After some time, it tries again, and if not all but some requests succeed, then
    it assumes the state of half open. Then, depending on the stability of the subsequent
    requests, it can open or close, and so on.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: Some frameworks also allow you to ignore certain types of failures (Java exceptions)
    and only count specific ones, offering more control over how the system responds
    to avoid issues. Depending on the library or framework you choose, the circuit
    breaker configuration can have an extensive list of parameters to customize how
    the circuit breaker needs to behave. In the following figure, we have an illustration
    of the workflow and an example of the Resilience4j configuration for our circuit
    breaker.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Circuit breaker flow](img/B21843_06_1.png)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – Circuit breaker flow
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of implementation using Resilience4j:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This code sets up a Resilience4j circuit breaker to monitor a downstream service
    call. It does the following:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: Opens after the service fails more than 50% of the time
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remains open for 10 seconds before allowing test requests
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Treats calls taking longer than five seconds as failures
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By using the circuit breaker pattern, the API becomes more resilient, as it
    limits repeated calls to failing services and recovers once the service stabilizes.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: In the previous example, we saw how a circuit breaker can help manage failures
    in downstream services, protecting the API by isolating and handling service disruptions.
    However, implementing circuit breakers within each API service can lead to duplicated
    code and maintenance challenges, especially in larger systems with multiple services.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: Let us explore this further by understanding a different way of implementing
    a circuit breaker that is implemented at the level of the system gateway.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: Circuit breaker implemented in the gateway
  id: totrans-408
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A gateway functions as a central control point for managing communication between
    various services or systems. This makes it an optimal location for implementing
    patterns such as circuit breakers, rate limiting, and file upload validation.
    By incorporating these mechanisms at the gateway level, operational concerns are
    separated from business logic, allowing for isolation and promoting the standardization
    of system configurations, all managed through the gateway.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some benefits of implementing a circuit breaker on a gateway:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: '**Centralized control** : A single circuit breaker can protect multiple downstream
    services, simplifying management and monitoring'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improved resilience** : By isolating failing services, a circuit breaker
    can prevent cascading failures and maintain overall system stability'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reduced latency** : When a service is deemed unhealthy, the circuit breaker
    can quickly return a fallback response, reducing latency for clients'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enhanced reliability** : A circuit breaker can help ensure that critical
    services remain available even in the face of temporary failures'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The circuit breaker pattern is a crucial tool for building reliable and stable
    APIs, especially those that rely on multiple services or external APIs. You should
    consider using this pattern in several key situations to enhance resilience and
    stability.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, when building distributed systems or microservices, distinct parts
    of your application communicate with each other through APIs. In such setups,
    if one service becomes slow or fails, it can negatively impact the entire system.
    By implementing a circuit breaker, you can monitor these API calls and stop attempts
    to communicate with the failing service temporarily. This prevents one service’s
    issues from causing a domino effect, ensuring that other parts of the system continue
    to function smoothly.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: Another important scenario is when your application relies on external services.
    Many applications depend on third-party APIs, such as payment gateways, social
    media platforms, or data providers. These external services can sometimes experience
    downtime or slow responses due to several reasons, such as maintenance or high
    traffic. A circuit breaker helps by detecting these failures early and avoiding
    long waits for responses that may never come. Instead, your application can provide
    fallback options, such as default messages or alternative actions, maintaining
    a good user experience even when external services are unreliable.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: To prevent transaction failures, systems often cache frequently calculated values
    such as delivery tax, which may depend on external services. In situations where
    a quick response is crucial, a cached value can serve as a fallback option, avoiding
    lost transactions. A circuit breaker pattern can be effectively used to manage
    these scenarios. Promote a fallback solution until the part of the circuit that
    is opened gets to a normal state again.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: Circuit breakers help prevent system failures by stopping repeated attempts
    at unsuccessful operations. However, sometimes we need to isolate different parts
    of our system to prevent resource exhaustion. This is where the bulkhead pattern
    becomes valuable.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: Bulkhead
  id: totrans-420
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine you have a system where one small part fails, but you do not want the
    entire system to go down because of it. This is where the bulkhead pattern comes
    in. Let us explore how this pattern helps improve fault tolerance and keeps your
    system running smoothly.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: The bulkhead pattern is inspired by ships. Ships have bulkheads, which are walls
    that divide the ship into separate sections. If one section takes on water, the
    bulkheads prevent the water from spreading to other parts of the ship. This keeps
    the ship from sinking entirely.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: In software, the bulkhead pattern works similarly by dividing an application
    into various parts or services that operate independently. If one part fails or
    slows down, the other parts continue to function without any issues. This isolation
    ensures that a problem in one area does not affect the entire system.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned, the bulkhead pattern is a structural design pattern used to partition
    a system into isolated units or modules. Each module can handle its own load and
    failures independently, ensuring that an issue in one does not cascade to others.
    This isolation can be applied at various levels, such as the following:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: '**Service level** : Separating different microservices within an architecture'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource level** : Allocating separate thread pools, memory, or database
    connections to different components'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Functional level** : Dividing functionalities within a service to prevent
    one failing feature from affecting others'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The key characteristics of this pattern include the following:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: '**Isolation** : Ensures that failures in one compartment do not impact others'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource allocation** : Allocates separate resources to each compartment
    to prevent resource exhaustion from affecting the entire system'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fault tolerance** : Enhances the system’s ability to handle partial failures
    gracefully'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A common example of using the bulkhead pattern is managing “hot paths” in your
    system. Hot paths are parts of your system that receive more traffic than others.
    If a hot path gets too many requests, it can overload that part of the system,
    causing it to slow down or crash. This can make the entire system unresponsive,
    affecting users who are not using the hot path.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: To understand how the bulkhead pattern enhances resilience, we will dive into
    different areas where this approach can be applied effectively. By isolating components,
    we can prevent failures in one part of the system from affecting the entire application.
    This flexibility allows us to apply the bulkhead pattern across various levels,
    such as services, resources, and functionalities, making it a versatile solution
    for fault tolerance.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: Let’s explore some practical ways to implement bulkheads in different system
    architectures and at different levels, from monolithic systems to microservices,
    as well as through database and queue management.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: Implementing bulkhead in different architectures
  id: totrans-435
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can apply the bulkhead pattern whether you are using a monolithic architecture
    or microservices:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: '**Monolithic systems** : Even if your system is a single application, you can
    create isolation by directing heavy traffic to specific instances. For example,
    you can have certain instances handle the hot paths while other instances manage
    different parts of the system. This way, if the hot path gets overloaded, the
    rest of the system remains unaffected.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Microservices** : In a microservices architecture, each service can act as
    a separate bulkhead. If one service fails, the others continue to operate normally.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the bulkhead pattern through database isolation
  id: totrans-439
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another way to implement the bulkhead pattern is by isolating your databases.
    Instead of using a single database that handles all requests, you can create separate
    database instances for different parts of your system. For example, a high-traffic
    feature can have its own database, preventing it from overwhelming the main database
    and affecting other features.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the bulkhead pattern through queue management
  id: totrans-441
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can also apply isolation to message queues by creating different queues
    with varying priorities. High-priority queues can be monitored and scaled independently
    to ensure they process messages quickly, while standard queues operate normally.
    This prevents a surge in one queue from impacting others.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: External services and throttling
  id: totrans-443
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When your system makes calls to external services, latency and timeouts can
    cause problems. By using the bulkhead pattern, you can limit the number of external
    requests, ensuring that slow responses from third-party services do not overwhelm
    your system. Implementing throttling in your code can help manage the flow of
    these requests effectively.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
- en: Using the bulkhead pattern increases your system’s resilience and availability.
    It makes your system easier to manage by isolating different parts. However, adding
    bulkheads also introduces some complexity. You need to carefully design your system
    to ensure that the added complexity is justified by the improved fault tolerance.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: The bulkhead resilience pattern is a powerful technique for building robust
    and reliable systems. By creating isolation between different parts of your architecture,
    you can prevent small failures from cascading and affecting the entire system.
    Whether you are working with monolithic applications or microservices, the bulkhead
    pattern can enhance your system’s stability and performance.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: The bulkhead pattern is a strong architectural method used for designing and
    building APIs. It helps make systems more resilient, scalable, and able to handle
    faults. Separating distinct parts of the system keeps failures limited, uses resources
    efficiently, and ensures the system stays strong even if some parts go down. However,
    it is important to weigh these benefits against the extra complexity and resource
    use it can bring. Careful planning, managing resources well, and continuous monitoring
    are key to successfully using the bulkhead pattern in your API design.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-448
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter covered two important areas for building strong RESTful APIs:
    data handling and resilience.'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: The *Data handling* section focused on managing large amounts of data efficiently.
    Key techniques include pagination, which splits data into smaller pages to improve
    performance, and filtering, which allows clients to request only the data they
    need. The chapter also explained how to handle file uploads and downloads securely,
    ensuring that APIs can manage large files without slowing down. Additionally,
    we introduced HATEOAS, which adds navigational links to API responses, making
    it easier for clients to interact with the API.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: The *Resilience* section showed us how we can keep APIs stable and reliable
    under various conditions. Important strategies included setting timeouts to avoid
    long wait times, using retry mechanisms to handle temporary failures, and implementing
    rate limiting to prevent abuse and manage traffic. Throttling helps control the
    flow of requests, while idempotency keys ensure that repeated requests do not
    cause errors. Advanced patterns, such as circuit breakers, stop failing requests
    to protect the system, and bulkheads isolate different parts of the API to prevent
    failures from spreading. By applying these resilience techniques, APIs can maintain
    high performance and reliability even during unexpected challenges.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: Overall, by focusing on effective data handling and robust resilience strategies,
    developers can create APIs that are both efficient and dependable, capable of
    supporting growing applications and delivering a consistent user experience.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have mastered advanced API concepts and implementations, the journey
    ahead will focus on securing, testing, and deploying your APIs in production environments.
    [*Chapter 7*](B21843_07.xhtml#_idTextAnchor176) will guide you through securing
    your RESTful APIs against common vulnerabilities and attacks, teaching you to
    implement HTTPS encryption, proper authentication and authorization mechanisms,
    JWT tokens, and protection against OWASP vulnerabilities and CORS issues. [*Chapter
    8*](B21843_08.xhtml#_idTextAnchor223) shifts focus to comprehensive testing strategies,
    covering everything from Spring MVC unit testing to integration testing, GenAI-assisted
    test creation, and contract testing to ensure API reliability.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
- en: These upcoming chapters will transform your APIs from functional prototypes
    into secure, well-tested services ready for production deployment. By the end
    of *Part 2* , you will have the knowledge to build APIs that not only perform
    well but also protect user data and maintain reliability under various conditions,
    preparing you for the final part of the book, which covers deployment and performance
    optimization.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
