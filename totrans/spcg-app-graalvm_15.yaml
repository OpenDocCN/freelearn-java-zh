- en: Assessments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section contains answers to the questions from all chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 1 – Evolution of Java Virtual Machine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Java code is compiled to bytecode. JVM uses interpreters to convert the bytecode
    to machine language and uses JIT compilers to compile the most commonly used code
    snippets (hotspots). This approach helps Java to achieve "write-once run-anywhere,"
    as a result of which programmers don't have to write machine-specific code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A class loader subsystem is responsible for loading the classes. It not only
    finds the classes, but also verifies and resolves the classes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'JVM has five memory areas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'a. Method: A shared area, where all the class-level data is stored at the JVM
    level'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b. Heap: All instance variables and objects stored at the JVM level (shared
    across threads)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'c. Stack: A runtime stack per thread to store the local variables at the method
    scope, as well as operands and frame data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'd. Registries: PC registers with the addresses of current executing instructions
    (for each thread)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'e. Native method stack: Native method information for each thread that is used
    to invoke native methods'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Chapter 2 – JIT, Hotspot, and GraalJIT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A code cache is a special memory area within JVM that is used by JVM to store
    the compiled code. The code is compiled by JIT compilers and stored in the code
    cache. If a method is compiled and is found in the code cache, JVM will use that
    code to run, instead of interpreting the method code. Refer to the *Code cache*
    section for more details
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The code cache size can be changed using the following flags for fine-tuning.
    Refer to the *Code cache* section for more details:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. `-XX:InitialCodeCacheSize` – The initial size of the code cache. The default
    size is 160 KB (the size varies based on the JVM version)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. `-XX:ReservedCodeCacheSize` – This is the maximum size the code cache can
    grow to. The default size is 32/48 MB. When the code cache reaches this limit,
    JVM will throw a warning, `CodeCache is full. Compiler has been disabled.` JVM
    offers the `UseCodeCacheFlushing` option to flush the code cache when the code
    cache is full. The code cache is also flushed when the compiled code is not hot
    enough (when the counter is less than the compiler threshold).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. `-XX:CodeCacheExpansionSize` – This is the expansion size. When it scales
    up, its default value is 32/64 KB.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The compiler threshold is the factor that is used to decide when the code is
    "hot." When the code reaches the compiler threshold, JVM will spin off the JIT
    compilation (C1 or C2) on a compilation thread. Refer to the *Compiler threshold*
    section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sometimes, the code can become hot while it is running a long-running loop.
    In such cases, JVM will compile that code and perform OSR. Refer to the *On-stack
    replacement* section for more details and a detailed flow chart regarding how
    JVM performs OSR.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In JVM, there is an interpreter and two types of compiler – C1 and C2\. Users
    can specify any specific compiler to be used to optimize the code. By default,
    JVM performs tiered compilation, which is a combination of C1 and C2, based on
    various compiler thresholds. There are five tiers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Interpreted code (level 0)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Simple C1 compiled code (level 1)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Limited C1 compiled code (level 2)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Full C1 compiled code (level 3)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: e. C2 compiled code (level 4)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'There are three main patterns that JVM follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a. Normal Flow
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. C2 Busy
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Trivial Code
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Refer to the *Tiered compilation* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Inlining is one of the key optimization techniques that JIT compilers use. Based
    on the profiling of the code, JIT identifies the methods that can be inlined in
    order to avoid method calls. Method calls are expensive, as it performs jumps
    and stack frames are created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Monomorphic dispatch is another optimization technique used to identify the
    specific implementations of a polymorphic implementation. JIT profiles the code,
    identifies the specific implementation, and optimizes the code around that. Please
    refer to the *Monomorphic, bimorphic, and megamorphic dispatch* section for more
    details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Loop unrolling is one of the most effective optimizations that JIT performs,
    by inlining code in the loop body, with additional code, and reducing the number
    of iterations a loop has to iterate through. Please refer to the *Loop optimization
    – loop unrolling* section for more details and examples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Escape analysis is an optimization technique that the JIT profiler performs
    to identify the allocation and scope of the variables, and takes decisions in
    avoiding heap allocation, and replaces that with stack allocation, based on the
    scope of the variable. This is one of the most advanced analyses performed by
    JIT profilers. Please refer to the *Escape analysis* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: JIT performs deoptimization when any of the optimistic assumptions that were
    made to optimize and compile the code are invalid. JIT will make the compiled
    code non-entrant and fall back to the interpreter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: JVMCI stands for *Java Virtual Machine Compiler Interface*. This interface was
    added to the JDK in Java 9\. JVMCI provides an API to extend JVM and build custom
    compilers. Graal JIT is an implementation of JVMCI. Please refer to the *Graal
    JIT and the JVM Compiler Interface (JVMCI)* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 3 – Graal VM Architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GraalVM comes in two versions – Community Edition and Enterprise Edition. Refer
    to *Reviewing the GraalVM editions* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: JVMCI stands for *Java Virtual Machine Compiler Interface*. Java 9 and above
    provide a way to implement custom JIT compilers. JVMCI provides an API to implement
    these custom compilers and provides access to JVM objects and the code cache.
    Graal JIT is an implementation of JVMCI. Refer to the *Java Virtual Machine Compiler
    Interface (JVMCI)* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Graal JIT replaces the C2 JIT compiler. Graal JIT is completely written in Java
    from the ground up but uses the hardened logic and best practices of the C2 compiler.
    Graal JIT implements better optimization strategies than C2 JIT, making it the
    best JIT compiler for Java. Graal JIT can also be used to compile other languages
    that are converted into intermediate representations in order to use the advanced
    optimization strategies. Refer to the *Graal compiler and tooling* section for
    more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Graal JIT requires a considerable amount of time to warm up, profile, and optimize
    the code. In certain use cases, this may not be suitable (such as serverless or
    containers). For such cases, Graal provides AOT compilation to compile the code
    directly to the native image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Graal AOT optimization is more related to static code analysis, but it does
    now have the runtime profile of the code to apply any advanced optimization**.
    Profile Guided Optimization** (**PGO**) provides a way to compile the code with
    instrumentation, generate a profile of the runtime, and use that profile to recompile
    the code to the most optimum native image. Refer to the *SubstrateVM (Graal AOT,
    Native Image)* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Truffle framework is built on top of Graal to support non-JVM languages
    to run on Graal JVM. Truffle provides the Truffle Language Implementation API
    and various other polyglot APIs to provide a very sophisticated environment where
    code in multiple languages can be embedded and interact. Refer to the *Truffle*
    section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: SubstrateVM is an embeddable VM that can be packaged along with the native images
    that are compiled by the Graal AOT compiler. Refer to the *SubstrateVM (Graal
    AOT and Native Image)* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Guest Access Context is an object that is used by the host language (such as
    Java) to provide access to the guest language (such as JavaScript) to various
    OS resources, such as the filesystem, I/O, and thread. Refer to the *Security*
    section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: GraalVM provides the most advanced JIT compilation, ideal for long-running processes
    involving high throughput. The GraalVM AOT compiler, along with SubstrateVM, provides
    the smallest and fastest runtime for cloud-native microservices implementations.
    Combined with PGO, it generates the optimum code to run on the cloud. Refer to
    the *GraalVM microservices architecture overview* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 4 – Graal Just-In-Time Compiler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Graal JIT compilation can be divided into two phases: frontend and backend.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The frontend phase is platform-independent compilation, where the code is converted
    to a platform-independent intermediate representation called **High-Level Intermediate
    Representation** (**HIR**), represented via Graal Graphs. This HIR is optimized
    in three tiers: High, Medium, and Low.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The backend phase is more platform-dependent compilation, where a **Low-Level
    Intermediate Representation** (**LIR**) is created and optimized at the machine
    code level. These optimizations are platform dependent.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Refer to the *Graal JIT compilation pipeline and Tiered Optimization* section
    for more details.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Intermediate Representations** (**IRs**) are among the most important data
    structures for compiler design. IRs provide a graph that helps the compiler understand
    the structure of the code, identify opportunities, and perform optimizations.
    Refer to the *Graal Intermediate Representation* section for more details.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Static Single Assignment** (**SSA**) is a form used in IRs where each variable
    is assigned once, and any time there is a change in the value, a new variable
    is used. Every variable is declared before it is used. This helps us to keep track
    of variables and values and helps optimize the code better using graphs. Refer
    to the *Graal intermediate representation* section for more details.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Speculative optimization is a compiler optimization technique of performing
    various code optimizations with speculation. Speculations are assumptions that
    are made based on profiling the code. The optimizations are performed on the code
    based on these assumptions. When these assumptions are proven wrong, at runtime,
    a deoptimization is performed. This helps to optimize focused parts of the code,
    instead of the whole code, which might slow down the runtime. Refer to the *Graal
    compiler optimizations* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Escape analysis is an optimization technique that identifies the scope and usage
    of the objects and decides the allocation of the objects either on the heap or
    the stack or the register. This has a significant impact on memory usage and performance.
    Escape analysis is performed at the method level, while partial escape analysis
    performs a deeper analysis of the code to track the objects not just at the method-level
    scope, but also at the control block level. This helps further optimize the code.
    Refer to the *Partial escape analysis* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 5 – Graal Ahead-of-Time Compiler and Native Image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GraalVM comes with a tool called the Native Image builder, `native-image`. This
    can be used to compile ahead of time and create a native image. Please refer to
    the *Building native images* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Native Image builder, when it compiles the code ahead of time, performs
    points-to analysis to understand all the dependent classes and methods that are
    accessed by the application code. It uses this information to optimize the native
    image, by only building the required code into the image. This provides faster
    execution and smaller images. Please refer to the *Building native images* section
    for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Native Image builder performs region analysis to initialize classes ahead
    of time into the heap so that the startup of the native image is faster. Please
    refer to the *Building native images* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Native Image builder packages the **Garbage Collector** (**GC**) code along
    with the native image. There are two types of GC that can be enabled in the native
    image. The Serial GC is a default GC and is available both in the Community and
    Enterprise editions. G1 performs more advanced garbage collection and is only
    available in the Enterprise edition. Please refer to the *Native Image memory
    management configurations* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Native Image builder can only perform static code analysis, unlike the JIT
    compiler, which can perform the runtime profiling of the code and optimize the
    code at runtime. PGO brings the runtime profiling information to a native image
    for further optimization. Please refer to the *Profile-guided optimization (PGO)*
    section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since native images are built ahead of time, the Native Image builder needs
    to have all the classes loaded at build time. Hence, native images have limitations
    in supporting dynamic features such as reflection and JNI. However, GraalVM's
    Native Image builder provides ways to pass dynamic resource information at build
    time. Please refer to the *Native image configuration* and *Limitations of Graal
    AOT (Native Image)* sections for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 6 – Truffle – An Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Specialization is a key optimization that helps identify the specific type of
    a variable. In dynamically typed languages, the type of a variable is not declared
    in the code. The interpreter starts assuming generic types and, based on the runtime
    profiling, will speculate on the type of the variable. Please refer to the *Truffle
    interpreter/compiler pipeline* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When Truffle speculates on a specialized type of a node, the node is rewritten
    dynamically, and the Truffle AST provides a way to rewrite the nodes to optimize
    the AST before submitting it to Graal for further optimized execution. Please
    refer to the *Truffle interpreter/compiler pipeline* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When Truffle finds that the AST has not been rewritten, it assumes that the
    AST has stabilized. The code is then compiled to machine code for the guest language
    after aggressive constant folding, inlining, and escape analysis. This is called
    Partial Evaluation. Please refer to *Partial Evaluation* in the *Truffle interpreter/compiler
    pipeline* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Truffle provides a Domain-Specific Language implemented as annotation generators.
    This helps guest language developers write smaller code and focus on the logic,
    rather than the boilerplate code. Please refer to the *Truffle DSL* section for
    more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A frame is a Truffle class that provides the interface to read and store data
    in the current namespace. Refer to *Frame management and local variables* in the
    *Truffle interoperability* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Truffle defines a Dynamic Object Model to provide a standard interface and framework
    for various guest language implementations to have a standard way of defining
    and exchanging data. Refer to *Dynamic Object Model* in the *Truffle interoperability*
    section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 7 – GraalVM Polyglot – JavaScript and Node.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`Polyglot` is the object that is used in JavaScript to run other language code.
    We use the method `eval()` to run the code. Please refer to the *JavaScript interoperability*
    section for more details on how to use this object to run the code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `Context` object provides the polyglot context to allow the guest language
    code to run in the host language. A polyglot context represents the global runtime
    state of all installed and permitted languages. Please refer to the *JavaScript
    embedded code in Java* section for more details on how to use this object to run
    the code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `Context` object helps provide fine-grained access control. The access control
    can be controlled with `ContextBuilder`. Please refer to the *JavaScript embedded
    code in Java* section for more details on how to use this object to run the code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: GraalVM provides a Native Image builder option to build native images of applications
    that have multiple languages embedded. A language flag is used to let the Native
    Image builder know which languages are used in the application. This flag can
    also be specified in `native-image` property files. Refer to the *Polyglot native
    images* section in this chapter to understand more. Refer to *Chapter 5* , *Graal
    Ahead-of-Time Compiler and Native Image* for more details about the native image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `binding` object acts as an intermediate layer between Java and JavaScript
    to access methods, variables, and objects between the languages. Please refer
    to the *Bindings* section to find out more about the binding object and how it
    is used as an intermediate layer between languages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 8 – GraalVM Polyglot – Java on Truffle, Python, and R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Java on Truffle is the new way to run Java programs on top of the Truffle framework.
    Java on Truffle provides an interpreter that is completely built on Java and runs
    in the same memory space as other Truffle languages. This was introduced in GraalVM
    version 21\. For more details refer to the *Understanding Espresso (Java on Truffle)*
    section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Java on Truffle provides an isolationist layer, which helps to run untrusted
    code and code written in an older version of JDK, and provides hot-swap and other
    advanced features. To learn more about the advantages of using Java on Truffle,
    refer to the *Why do we need Java on Java?* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `Polyglot.cast()` method is used in Java on Truffle to typecast the data
    that is exported or returned by dynamic languages. Refer to the *Exploring Espresso
    interoperability with other Truffle languages* section for more details and code
    examples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**SST** stands for **Simple Syntax Tree** and **ST** stands for **Scope Tree**.
    Python generates these intermediate representations before converting them into
    an AST intermediate representation. Python does this using the ANTLR parser and
    the cache, and speeds up parsing. Refer to the *Understanding Graalpython compilation
    and interpreter pipeline* section for more details.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A `.pyc` file is a cache Python creates after parsing Python code and generating
    SST and ST representations. This helps speed up parsing the next time the Python
    module is loaded. Python automatically keeps this cache validated. Refer to the
    *Understanding Graalpython compilation and interpreter pipeline* section for more
    details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`polyglot.import_value()` is used to import definitions from other dynamic
    languages, and `polyglot.export_value()` is used to export Python definitions
    to other languages. `polyglot.eval()` is used to execute other language code.
    Refer to the *Exploring interoperability between Python and other dynamic languages*
    section for more detailed explanations and sample code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In R, we use the `import()` function to import the definitions from other languages.
    Refer to the *Exploring interoperability of R* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We use `java.type('classname')` to load a Java class and interoperate with it.
    This function provides the class, and we can use the `new()` function to create
    an instance of the object. Refer to the *Exploring the interoperability of R*
    section for more details and sample code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 9 – GraalVM Polyglot – LLVM, Ruby, and WASM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sulong is an LLVM interpreter that is written in Java and internally uses the
    Truffle language implementation framework. This enables all language compilers
    that can generate LLVM IR to directly run on GraalVM. Refer to the *Understanding
    LLVM – the (Sulong) Truffle interface* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: GraalVM Enterprise Edition provides a managed environment of LLVM. The managed
    mode of execution provides a safe runtime, which, with additional safety, guarantees
    to catch illegal pointer accesses and access arrays outside of the bounds.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The TruffleRuby interpreter interoperates with the LLVM interpreter to implement
    the C extensions. This also extends the possibility to use other LLVM languages,
    such as Rust and Swift, to run as Ruby extensions. Refer to the *Understanding
    the TruffleRuby interpreter/compiler pipeline* section for more details.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: WASM is binary code that can run on modern web browsers. It has a very small
    footprint and performs much faster than JavaScript. Refer to the *Understanding
    WASM* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Emscripten or `emcc` is the compiler that generates the WASM binary image (`.wasm`)
    files. Refer to the *Installing and running GraalWasm* section for more details.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Chapter 10 – Microservices Architecture with GraalVM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices is an architectural pattern that decomposes a large application
    into smaller, manageable, and self-contained components that expose the functionality
    through a standard interface called services. Please refer to the *Microservices
    architecture overview* section for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The microservices architecture pattern helps us build an application that is
    scalable, manageable, and loosely coupled. This is very important for building
    cloud-native applications in order to get the most out of the cloud infrastructure
    and services. Please refer to the *Microservices architecture overview* section
    for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: GraalVM provides a high-performance runtime for JVM and non-JVM languages with
    a small footprint, which is critical for building scalable cloud-native applications.
    Refer to the *Reviewing modern architectural requirements* section in *Chapter
    3*, *Graal VM Architecture,* and the *Understanding how GraalVM helps build a
    microservice architecture* section in this chapter for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
