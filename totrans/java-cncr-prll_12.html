<html><head></head><body>
		<div id="_idContainer044">
			<h1 class="chapter-number" id="_idParaDest-260"><a id="_idTextAnchor295"/>12</h1>
			<h1 id="_idParaDest-261"><a id="_idTextAnchor296"/>The Horizon Ahead</h1>
			<p>As cloud technologies continue to evolve at a rapid pace, it is crucial for developers and organizations to stay ahead of the curve and prepare for the next wave of innovations. This chapter will explore the emerging trends and advancements in the cloud computing landscape, with a particular focus on Java’s role in shaping these <span class="No-Break">future developments.</span></p>
			<p>We<a id="_idIndexMarker1166"/> will begin by examining the evolution of serverless Java, where frameworks such as Quarkus<a id="_idIndexMarker1167"/> and Micronaut<a id="_idIndexMarker1168"/> are redefining the boundaries of <strong class="bold">functions as a service</strong>. These tools leverage innovative techniques, such as native image compilation, to deliver unprecedented performance and efficiency in serverless environments. Additionally, we will delve into the concept of serverless containers, which allow for the deployment of entire Java applications in a serverless fashion, harnessing the benefits of container orchestration platforms such as <a id="_idIndexMarker1169"/>Kubernetes<a id="_idIndexMarker1170"/> and <strong class="bold">Amazon Web Services</strong> (<span class="No-Break"><strong class="bold">AWS</strong></span><span class="No-Break">) Fargate.</span></p>
			<p>Next, we will explore the role of Java in the emerging paradigm of edge computing. As data processing and decision-making move closer to the source, Java’s platform independence, performance, and extensive ecosystem make it an ideal candidate for building edge applications. We will discuss the key frameworks and tools that enable Java developers to leverage the power of edge <span class="No-Break">computing architectures.</span></p>
			<p>Furthermore, we will <a id="_idIndexMarker1171"/>investigate Java’s evolving position in the integration of <strong class="bold">artificial intelligence</strong> (<strong class="bold">AI</strong>) and <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) within cloud-based ecosystems. From serverless AI/ML<a id="_idIndexMarker1172"/> workflows to the seamless integration of Java with cloud-based AI services, we will explore the opportunities and challenges that this <span class="No-Break">convergence presents.</span></p>
			<p>Finally, we will delve into the captivating realm<a id="_idIndexMarker1173"/> of <strong class="bold">quantum computing</strong>, a field that promises to revolutionize various industries. While still in its early stages, understanding the fundamental principles of quantum computing, such as qubits, quantum gates, and algorithms, can prepare developers for future advancements and their potential integration with <span class="No-Break">Java-based applications.</span></p>
			<p>By the end of this chapter, you will have a comprehensive understanding of the emerging trends in cloud computing and Java’s pivotal role in shaping these innovations. You will be equipped with the knowledge and practical examples to position your applications and infrastructure for success in the rapidly evolving <span class="No-Break">cloud landscape.</span></p>
			<p>The following are the key topics that will be covered in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>Future trends in cloud computing and <span class="No-Break">Java’s role</span></li>
				<li>Edge computing <span class="No-Break">and Java</span></li>
				<li>AI and <span class="No-Break">ML integration</span></li>
				<li>Emerging concurrency and parallel processing tools <span class="No-Break">in Java</span></li>
				<li>Preparing for the next wave of <span class="No-Break">cloud innovations</span></li>
			</ul>
			<p>So, let’s <span class="No-Break">get started!</span></p>
			<h1 id="_idParaDest-262"><a id="_idTextAnchor297"/>Technical requirements</h1>
			<p>To fully engage with <a href="B20937_12.xhtml#_idTextAnchor295"><span class="No-Break"><em class="italic">Chapter 12</em></span></a>’s content and examples, ensure the following are installed <span class="No-Break">and configured:</span></p>
			<ul>
				<li><strong class="bold">Java Development Kit </strong><span class="No-Break"><strong class="bold">or JDK</strong></span><span class="No-Break">:</span><ul><li>Quarkus requires a JDK to run. If you don’t have one, download and install a recent version (JDK 17 or newer is recommended) from the <span class="No-Break">official source:</span><ul><li><span class="No-Break"><strong class="bold">AdoptOpenJDK</strong></span><span class="No-Break">: </span><a href="https://adoptium.net/"><span class="No-Break">https://adoptium.net/</span></a></li><li><span class="No-Break"><strong class="bold">OpenJDK</strong></span><span class="No-Break">: </span><a href="https://openjdk.org/"><span class="No-Break">https://openjdk.org/</span></a></li></ul></li></ul></li>
				<li><strong class="bold">Quarkus Command Line </strong><span class="No-Break"><strong class="bold">Interface (CLI)</strong></span><span class="No-Break">:</span><ul><li>Use package managers such as Chocolatey (<strong class="source-inline">choco install quarkus</strong>) or Scoop (<strong class="source-inline">scoop </strong><span class="No-Break"><strong class="source-inline">install quarkus</strong></span><span class="No-Break">)</span></li><li>Alternatively, use JBang (<strong class="source-inline">jbang app install --</strong><span class="No-Break"><strong class="source-inline">fresh quarkus@quarkusio</strong></span><span class="No-Break">)</span></li><li><strong class="bold">Quarkus CLI installation </strong><span class="No-Break"><strong class="bold">guide</strong></span><span class="No-Break">: </span><a href="https://quarkus.io/guides/cli-tooling"><span class="No-Break">https://quarkus.io/guides/cli-tooling</span></a></li></ul></li>
				<li><span class="No-Break"><strong class="bold">GraalVM</strong></span><span class="No-Break">:</span><ol><li class="upper-roman">Download the GraalVM Community Edition for Windows <span class="No-Break">from </span><a href="https://www.graalvm.org/downloads/"><span class="No-Break">https://www.graalvm.org/downloads/</span></a><span class="No-Break">.</span></li><li class="upper-roman">Follow the installation <span class="No-Break">instructions provided.</span></li><li class="upper-roman">Set the <strong class="source-inline">GRAALVM_HOME</strong> environment variable to the GraalVM <span class="No-Break">installation directory.</span></li><li class="upper-roman">Add <strong class="source-inline">%GRAALVM_HOME%\bin</strong> to your PATH <span class="No-Break">environment variable.</span></li></ol></li>
				<li><span class="No-Break"><strong class="bold">Docker Desktop</strong></span><span class="No-Break">:</span><ol><li class="upper-roman" value="1">Download and install Docker Desktop for Windows <span class="No-Break">from </span><a href="https://www.docker.com/products/docker-desktop/"><span class="No-Break">https://www.docker.com/products/docker-desktop/</span></a><span class="No-Break">.</span></li><li class="upper-roman">Follow the installation wizard and configure Docker <span class="No-Break">as needed.</span></li></ol></li>
			</ul>
			<p>The code in this chapter can be found <span class="No-Break">on GitHub:</span></p>
			<p><a href="https://github.com/PacktPublishing/Java-Concurrency-and-Parallelism"><span class="No-Break">https://github.com/PacktPublishing/Java-Concurrency-and-Parallelism</span></a></p>
			<h1 id="_idParaDest-263"><a id="_idTextAnchor298"/>Future trends in cloud computing and Java’s role</h1>
			<p>As cloud computing continues to evolve, several emerging trends are shaping the future of this technology landscape. Innovations such as edge computing, AI and ML integration, and serverless architectures are at the forefront, driving new possibilities and efficiencies. Java, with its robust ecosystem and continuous advancements, is playing a pivotal role in these developments. This section will explore the latest trends in cloud computing, how Java is adapting to and facilitating these changes, and provide real-world examples of Java’s adoption in cutting-edge <span class="No-Break">cloud technologies.</span></p>
			<h2 id="_idParaDest-264"><a id="_idTextAnchor299"/>Emerging trends in cloud computing – serverless Java beyond function as a service</h2>
			<p>Emerging trends in cloud computing are reshaping the landscape of serverless Java, extending beyond the traditional functions-as-a-service model. Innovations in serverless Java frameworks such as Quarkus and Micronaut are driving <span class="No-Break">this evolution.</span></p>
			<h3>Quarkus</h3>
			<p><strong class="bold">Quarkus</strong>, recognized for <a id="_idIndexMarker1174"/>its strengths in microservices, is now making a substantial impact in serverless environments. It empowers developers to build serverless functions that adhere to microservice principles, seamlessly merging these two architectural approaches. A standout feature is Quarkus’ native integration with GraalVM, enabling the compilation of Java applications into native executables. This is a game-changer for serverless computing, as it tackles the long-standing issue of cold start latency. By harnessing GraalVM, Quarkus dramatically reduces startup times for Java applications, often from seconds to mere milliseconds, compared to traditional <strong class="bold">Java virtual machine</strong> (<strong class="bold">JVM</strong>) based alternatives. Moreover, the resulting native binaries are more memory efficient, facilitating optimized scaling and resource utilization in the dynamic world of serverless environments. These advancements are revolutionizing serverless Java, providing developers with a powerful toolkit to create high-performance, cloud-native applications that are both efficient <span class="No-Break">and responsive.</span></p>
			<h3>Micronaut</h3>
			<p><strong class="bold">Micronaut</strong> is another innovative framework<a id="_idIndexMarker1175"/> making significant progress in the serverless Java space. It is designed to optimize the performance of microservices and serverless applications through<a id="_idIndexMarker1176"/> several <span class="No-Break">key features:</span></p>
			<ul>
				<li><strong class="bold">Compile-time dependency injection</strong>: Unlike<a id="_idIndexMarker1177"/> traditional frameworks that resolve dependencies at runtime, Micronaut performs this task during compilation. This approach eliminates the need for runtime reflection, resulting in faster startup times and reduced <span class="No-Break">memory consumption.</span></li>
				<li><strong class="bold">Aspect-oriented programming (AOP)</strong>: AOP<a id="_idIndexMarker1178"/> is a programming paradigm that increases modularity by allowing the separation of cross-cutting concerns. In Micronaut, AOP is implemented at compile time rather than runtime. This means that features such as transaction management, security, and caching are woven into the bytecode during compilation, eliminating the need for runtime proxies and further reducing memory usage and <span class="No-Break">startup time.</span></li>
			</ul>
			<p>These compile-time techniques make Micronaut an ideal choice for building lightweight, fast, and efficient serverless applications. The framework’s design is particularly well suited to environments where rapid startup and low resource consumption <span class="No-Break">are crucial.</span></p>
			<p>Additionally, Micronaut <a id="_idIndexMarker1179"/>supports the creation of GraalVM native images. This feature further enhances its suitability for serverless environments by minimizing cold start times and resource usage, as native images can start almost instantaneously and consume less memory compared to traditional <span class="No-Break">JVM-based applications.</span></p>
			<h3>Serverless containers and Java applications</h3>
			<p>Serverless containers<a id="_idIndexMarker1180"/> represent another dimension of serverless computing, enabling the deployment of entire Java applications rather than individual functions. This approach leverages container orchestration platforms such as Kubernetes<a id="_idIndexMarker1181"/> and AWS Fargate<a id="_idIndexMarker1182"/> to run containers in a serverless fashion. Java applications packaged as containers benefit from the same serverless advantages of automatic scaling and pay-per-use pricing, but with more control over the runtime environment compared to traditional serverless functions. Developers can ensure consistency across different environments by packaging the application with its dependencies. Full control over the runtime environment allows for the inclusion of necessary libraries and tools, providing flexibility that is sometimes lacking in traditional serverless functions. Additionally, serverless containers can scale automatically based on demand, offering the benefits of serverless computing while maintaining the robustness of <span class="No-Break">containerized applications.</span></p>
			<p>By combining the innovations in serverless <a id="_idIndexMarker1183"/>Java frameworks such as Quarkus<a id="_idIndexMarker1184"/> and Micronaut<a id="_idIndexMarker1185"/> with the flexibility of serverless containers, developers can create highly scalable, efficient, and responsive Java applications that meet the demands of modern cloud-native environments. These advancements are paving the way for the next generation of serverless Java, moving beyond simple functions to encompass full-fledged applications <span class="No-Break">and services.</span></p>
			<h4>Example use-case – building a serverless REST API with Quarkus and GraalVM</h4>
			<p><strong class="bold">Objective</strong>: Create a <a id="_idIndexMarker1186"/>serverless REST API for product management and deploy it on AWS Lambda using Quarkus, demonstrating key Quarkus features and integration with <span class="No-Break">AWS services.</span></p>
			<p>This example covers key concepts and elements of Quarkus. The full application will be available in the <span class="No-Break">GitHub repository.</span></p>
			<ol>
				<li><strong class="bold">Set up the project</strong>: Use Quarkus CLI or Maven to bootstrap a new project. For this example, we’ll use Maven. Run the following Maven command to create the <span class="No-Break">Quarkus project:</span><pre class="source-code">
<strong class="bold">mvn io.quarkus:quarkus-maven-plugin:2.7.5.Final:create \</strong>
<strong class="bold">    -DprojectGroupId=com.example \</strong>
<strong class="bold">    -DprojectArtifactId=quarkus-serverless \</strong>
<strong class="bold">    -DclassName="com.example.ProductResource" \</strong>
<strong class="bold">    -Dpath="/api/products"</strong></pre></li>				<li><span class="No-Break"><strong class="bold">Key components</strong></span><span class="No-Break">:</span><ul><li><strong class="bold">Product resource (REST API)</strong>: The <strong class="source-inline">ProductResource</strong> class is a RESTful resource that defines the endpoints for managing products within the application. Using JAX-RS annotations, it provides methods for retrieving all products, fetching the count of products, and getting details of individual products by ID. This class serves as the primary interface for client interactions with the product-related data in the application. It demonstrates Quarkus features such as dependency injection, metrics, and <span class="No-Break">OpenAPI documentation:</span><pre class="source-code">
@Path("/api/products")
@Produces(MediaType.APPLICATION_JSON)
@Consumes(MediaType.APPLICATION_JSON)
@Tag(name = "Product",
    description = "Product management operations")
public class ProductResource {
    @Inject
    ProductRepository productRepository;
    @GET
    @Counted(name = "getAllProductsCount",
        description = "How many times getAllProducts has been         invoked")
    @Timed(name = "getAllProductsTimer",
        description = "A measure of how long it takes to perform         getAllProducts",
        unit = MetricUnits.MILLISECONDS)
    @Operation(summary = "Get all products",
        description = "Returns a list of all products with         pagination and sorting")
    public Response getAllProducts(@QueryParam(
        "page") @DefaultValue("0") int page,
            @QueryParam("size") @DefaultValue("20") int size,
            @QueryParam("sort") @DefaultValue("name") String             sort) {
        // Implementation omitted for brevity
    }
    @POST
    @Operation(summary = "Create a new product",
        description = "Creates a new product and returns the         created product")
    public Response createProduct(Product product) {
        // Implementation omitted for brevity
    }
    // Additional CRUD methods omitted for brevity
}</pre></li><li><strong class="source-inline">ProductRepository</strong>: The <strong class="source-inline">ProductRepository</strong> class acts as the data access layer, managing interactions with <em class="italic">AWS DynamoDB</em> for product<a id="_idIndexMarker1187"/> data persistence. It demonstrates Quarkus’ seamless integration with AWS <strong class="bold">Software Development Kit</strong> (<strong class="bold">SDK</strong>) v2, specifically for DynamoDB operations. The class uses dependency injection to obtain <strong class="source-inline">DynamoDbClient</strong>, showcasing how Quarkus simplifies cloud service integration. It implements methods for <strong class="bold">create, read, update, and delete</strong> (<strong class="bold">CRUD</strong>) operations, translating <a id="_idIndexMarker1188"/>between Java objects and DynamoDB item representations, thus demonstrating how Quarkus applications can efficiently work with NoSQL databases in a <span class="No-Break">cloud environment:</span><pre class="source-code">@ApplicationScoped
public class ProductRepository {
    @Inject
    DynamoDbClient dynamoDbClient;
    private static final String TABLE_NAME = "Products";
    public void persist(Product product) {
        Map&lt;String, AttributeValue&gt; item = new HashMap&lt;&gt;();
        item.put("id", AttributeValue.builder().s(
            product.getId()).build());
        item.put("name", AttributeValue.builder().s(
            product.getName()).build());
        // Add other attributes
        PutItemRequest request = PutItemRequest.builder()
                .tableName(TABLE_NAME)
                .item(item)
                .build();
        dynamoDbClient.putItem(request);
    }
    // Additional methods omitted for brevity
}</pre></li><li><strong class="source-inline">ImageAnalysisCoordinator</strong>: The <strong class="source-inline">ImageAnalysisCoordinator</strong> class <a id="_idIndexMarker1189"/>showcases Quarkus’ ability to create AWS Lambda functions that interact with multiple AWS services. It demonstrates <a id="_idIndexMarker1190"/>handling <strong class="bold">Simple Storage Service</strong> (<strong class="bold">S3</strong>) events and <a id="_idIndexMarker1191"/>triggering <strong class="bold">Elastic Container Service</strong> (<strong class="bold">ECS</strong>) tasks, illustrating how Quarkus can be used to build complex, event-driven architectures. This class uses dependency injection for AWS clients (ECS and S3), showing how Quarkus simplifies working with multiple cloud services in a single component. It’s an excellent example of using Quarkus for<a id="_idIndexMarker1192"/> serverless applications that orchestrate other <span class="No-Break">AWS services:</span><pre class="source-code">@ApplicationScoped
public class ImageAnalysisCoordinator implements RequestHandler&lt;S3Event, String&gt; {
    @Inject
    EcsClient ecsClient;
    @Inject
    S3Client s3Client;
    @Override
    public String handleRequest(S3Event s3Event,
        Context context) {
            String bucket = s3Event.getRecords().get(
                0).getS3().getBucket().getName();
            String key = s3Event.getRecords().get(
                0).getS3().getObject().getKey();
        RunTaskRequest runTaskRequest = RunTaskRequest.builder()
            .cluster("your-fargate-cluster")
            .taskDefinition("your-task-definition")
            .launchType("FARGATE")
            .overrides(TaskOverride.builder()
                .containerOverrides(
                    ContainerOverride.builder()
                        .name("your-container-name")
                        .environment(
                            KeyValuePair.builder()
                                .name("BUCKET")
                                .value(bucket)
                                .build(),
                            KeyValuePair.builder()
                                .name("KEY")
                                .value(key)
                                .build())
                            .build())
                        .build())
                .build();
        // Implementation omitted for brevity
    }
}</pre></li><li><strong class="source-inline">ProductHealthCheck</strong>: The <strong class="source-inline">ProductHealthCheck</strong> class implements Quarkus’ health check <a id="_idIndexMarker1193"/>mechanism, which is crucial for maintaining application reliability in cloud environments. It demonstrates the use of Microprofile Health, allowing the application to report its status to orchestration systems such as Kubernetes. The class checks the accessibility of the DynamoDB table, showcasing how Quarkus applications can provide meaningful health information about external dependencies. This component is essential for implementing robust microservices that can self-report their <span class="No-Break">operational status:</span><pre class="source-code">@Readiness
@ApplicationScoped
public class ProductHealthCheck implements HealthCheck {
    @Inject
    DynamoDbClient dynamoDbClient;
    private static final String TABLE_NAME = "Products";
    @Override
    public HealthCheckResponse call() {
        HealthCheckResponseBuilder responseBuilder =         HealthCheckResponse.named(
            "Product service health check");
        try {
            dynamoDbClient.describeTable(DescribeTableRequest.            builder()
                    .tableName(TABLE_NAME)
                    .build());
            return responseBuilder.up()
                    .withData("table", TABLE_NAME)
                    .withData("status", "accessible")
                    .build();
        } catch (DynamoDbException e) {
            return responseBuilder.down()
                    .withData("table", TABLE_NAME)
                    .withData("status",
                        "inaccessible")
                    .withData("error", e.getMessage())
                    .build();
        }
    }
}</pre></li></ul></li>				<li><strong class="bold">Configure a </strong><span class="No-Break"><strong class="bold">native build</strong></span><span class="No-Break">:</span><ul><li><strong class="bold">Maven profile</strong>: Ensure <a id="_idIndexMarker1194"/>your <strong class="source-inline">pom.xml</strong> file includes a profile for native builds. This will specify the necessary dependencies and plugins <span class="No-Break">for GraalVM:</span><pre class="source-code">
&lt;profiles&gt;
    &lt;profile&gt;
        &lt;id&gt;native&lt;/id&gt;
        &lt;activation&gt;
            &lt;property&gt;
                &lt;name&gt;native&lt;/name&gt;
            &lt;/property&gt;
        &lt;/activation&gt;
            &lt;properties&gt;
                &lt;skipITs&gt;false&lt;/skipITs&gt;
                &lt;quarkus.package.type&gt;native&lt;/quarkus.package.type&gt;
                &lt;quarkus.native.enabled&gt;true&lt;/quarkus.native.enabled&gt;
            &lt;/properties&gt;
        &lt;/profile&gt;
    &lt;/profiles&gt;</pre></li><li><strong class="source-inline">Dockerfile.native</strong>: The <a id="_idIndexMarker1195"/>provided Dockerfile is essential for building and packaging a Quarkus application with GraalVM for deployment on AWS Lambda. It starts by using a GraalVM image to compile the application into a native executable, ensuring optimal performance and minimal startup time. The build stage includes copying the project files and running the Maven build process. Subsequently, the runtime stage uses a minimal base image to keep the final image lightweight. The compiled native executable is copied from the build stage to the runtime stage, where it is set as the entry point for the container. This setup guarantees a streamlined and efficient deployment process for <span class="No-Break">serverless environments:</span><pre class="source-code"># Start with a GraalVM image for native building
FROM quay.io/quarkus/ubi-quarkus-native-image:21.0.0-java17 AS build
COPY src /usr/src/app/src
COPY pom.xml /usr/src/app
USER root
RUN chown -R quarkus /usr/src/app
USER quarkus
RUN mvn -f /usr/src/app/pom.xml -Pnative clean package
FROM registry.access.redhat.com/ubi8/ubi-minimal
WORKDIR /work/
COPY --from=build /usr/src/app/target/*-runner /work/application
RUN chmod 775 /work/application
EXPOSE 8080
CMD ["./application", "-Dquarkus.http.host=0.0.0.0"]</pre></li></ul></li>			</ol>
			<p>This Dockerfile describes a two-stage build process for a Quarkus <span class="No-Break">native application:</span></p>
			<ol>
				<li><span class="No-Break"><strong class="bold">Build stage</strong></span><span class="No-Break">:</span><ul><li>Uses a GraalVM-based image to compile <span class="No-Break">the application</span></li><li>Copies project files and builds a <span class="No-Break">native executable</span></li></ul></li>
				<li><span class="No-Break"><strong class="bold">Runtime stage</strong></span><span class="No-Break">:</span><ul><li>Uses a<a id="_idIndexMarker1196"/> minimal Red Hat UBI as the <span class="No-Break">base image</span></li><li>Copies the native executable from the <span class="No-Break">build stage</span></li><li>Sets the executable as the <span class="No-Break">entry point</span></li></ul></li>
			</ol>
			<p>Multi-stage builds have the <span class="No-Break">following benefits:</span></p>
			<ul>
				<li><strong class="bold">Smaller image size</strong>: The final image is lean, containing only the necessary <span class="No-Break">runtime dependencies</span></li>
				<li><strong class="bold">Improved security</strong>: Reduces the attack surface by including fewer tools <span class="No-Break">and packages</span></li>
				<li><strong class="bold">Clear separation</strong>: Simplifies maintenance by separating the build environment from the<a id="_idIndexMarker1197"/> <span class="No-Break">runtime environment</span></li>
			</ul>
			<p class="callout-heading">Note for Apple Silicon Users</p>
			<p class="callout">When building Docker images on Apple Silicon (M1 or M2) devices, you might encounter compatibility issues due to the <a id="_idIndexMarker1198"/>default <strong class="bold">Advance RISC Machine</strong> (<strong class="bold">ARM</strong>) architecture. Most cloud environments, including AWS, Azure, and Google Cloud, use AMD64 (x86_64) architecture. To avoid these issues, specify the target platform when building Docker images to <span class="No-Break">ensure compatibility.</span></p>
			<p class="callout">Specify the <strong class="source-inline">--platform</strong> argument when building Docker images on Apple Silicon devices to ensure compatibility with <span class="No-Break">cloud environments.</span></p>
			<p>For example, use the following command to build an image compatible with <span class="No-Break">AMD64 architecture:</span></p>
			<pre class="console">
docker build --platform linux/amd64 -t myapp:latest .</pre>			<p>While the <strong class="source-inline">application.properties</strong> file is not directly used for enabling native builds, you can include properties to optimize the application for running as a native image. Here is a sample <span class="No-Break"><strong class="source-inline">application.properties</strong></span><span class="No-Break"> file:</span></p>
			<pre class="source-code">
# you can include properties to optimize the application for running as a native image:
# Disable reflection if not needed
quarkus.native.enable-http-url-handler=true
# Native image optimization
quarkus.native.additional-build-args=-H:+ReportExceptionStackTraces
# Example logging configuration for production
%prod.quarkus.log.console.level=INFO</pre>			<p><strong class="bold">Deploy to </strong><span class="No-Break"><strong class="bold">AWS Lambda:</strong></span></p>
			<p><strong class="source-inline">Template.yaml</strong>: An AWS <strong class="bold">Serverless Application Model</strong> (<strong class="bold">SAM</strong>) template<a id="_idIndexMarker1199"/> that defines the infrastructure<a id="_idIndexMarker1200"/> for our Quarkus-based Lambda function, specifying its runtime environment, handler, resource allocations, and <span class="No-Break">necessary permissions:</span></p>
			<pre class="source-code">
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Description: &gt;
    quarkus-serverless
Resources:
    QuarkusFunction:
        Type: AWS::Serverless::Function
        Properties:
            Handler: com.example.LambdaHandler
            Runtime: provided.al2
            CodeUri: s3://your-s3-bucket-name/your-code.zip
            MemorySize: 128
            Timeout: 15
            Policies:
                - AWSLambdaBasicExecutionRole</pre>			<p><strong class="bold">Build and package</strong>: Run this Maven command to create a native <strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">jar</strong></span><span class="No-Break"> file:</span></p>
			<pre class="console">
mvn clean package -Pnative -Dquarkus.native.container-build=true</pre>			<p><strong class="bold">Deploy with SAM CLI</strong>: Use the AWS SAM CLI to package and deploy our Quarkus-based Lambda function: the first command packages the application and uploads it to an Amazon S3 bucket, while the second command deploys the packaged application to AWS, creating or <a id="_idIndexMarker1201"/>updating a CloudFormation stack with the necessary resources <span class="No-Break">and permissions:</span></p>
			<pre class="console">
sam package --output-template-file packaged.yaml --s3-bucket your-s3-bucket-name
sam deploy --template-file packaged.yaml --stack-name quarkus-serverless --capabilities CAPABILITY_IAM</pre>			<p>By following these steps, you will have successfully built a serverless REST API using Quarkus, packaged it as a native image with GraalVM, and deployed it to AWS Lambda. This setup ensures optimal performance and reduces cold start times for your <span class="No-Break">serverless application.</span></p>
			<p>The serverless paradigm continues to evolve, with Java frameworks such as Quarkus leading the charge in optimizing for cloud-native, serverless environments. As we’ve seen, modern serverless Java applications can leverage advanced features such as rapid startup times, low memory footprints, and seamless integration with cloud services. This enables developers to build complex, scalable applications that go far beyond simple function executions, encompassing full-fledged <span class="No-Break">microservices architectures.</span></p>
			<p>As the cloud computing landscape continues to evolve, another emerging trend is gaining significant traction: edge computing. Let’s explore how Java is adapting to meet the unique challenges and opportunities presented by edge <span class="No-Break">computing environments.</span></p>
			<h1 id="_idParaDest-265"><a id="_idTextAnchor300"/>Edge computing and Java</h1>
			<p>Edge computing<a id="_idIndexMarker1202"/> represents a paradigm shift in how data is processed, with computation occurring at or near the data source instead of relying solely on centralized cloud data centers. This approach reduces latency, optimizes bandwidth usage, and improves response times for <span class="No-Break">critical applications.</span></p>
			<h2 id="_idParaDest-266"><a id="_idTextAnchor301"/>Java’s role in edge computing architectures</h2>
			<p>Java, with its mature<a id="_idIndexMarker1203"/> ecosystem and robust performance, is increasingly becoming a pivotal player in edge <span class="No-Break">computing architectures.</span></p>
			<p>Java’s versatility and platform independence make it an ideal candidate for edge computing environments, which often consist of heterogeneous <a id="_idIndexMarker1204"/>hardware and <strong class="bold">operating systems</strong> (<strong class="bold">OSs</strong>). Java’s ability to run on various devices, from powerful servers to <a id="_idIndexMarker1205"/>constrained <strong class="bold">internet of things</strong> (<strong class="bold">IoT</strong>) devices, ensures that developers can leverage a consistent programming model across the entire edge-to-cloud continuum. Additionally, the extensive set of libraries and frameworks available in the Java ecosystem enables rapid development and deployment of <span class="No-Break">edge applications.</span></p>
			<p>Key benefits<a id="_idIndexMarker1206"/> of using Java in edge computing include <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Cross-platform compatibility</strong>: Java’s “write once, run anywhere” philosophy allows edge applications to be deployed across diverse hardware platforms <span class="No-Break">without modification</span></li>
				<li><strong class="bold">Performance and scalability</strong>: Java’s robust performance and efficient memory management are critical for handling the resource-constrained environments often found in <span class="No-Break">edge devices</span></li>
				<li><strong class="bold">Security</strong>: Java provides a strong security model, which is essential for safeguarding sensitive data processed at <span class="No-Break">the edge</span></li>
			</ul>
			<p>These advantages make Java a compelling choice for edge computing. To further empower developers, several frameworks and tools have been developed to streamline Java-based edge application development <span class="No-Break">and deployment.</span></p>
			<h2 id="_idParaDest-267"><a id="_idTextAnchor302"/>Frameworks and tools for Java-based edge applications</h2>
			<p>To effectively leverage Java in edge computing, developers can utilize a variety of frameworks and tools specifically designed for building and managing edge applications. Some of the prominent frameworks and tools include <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Eclipse Foundation’s </strong><span class="No-Break"><strong class="bold">IoT initiative</strong></span><span class="No-Break">:</span><ul><li><strong class="bold">Eclipse Kura</strong>: An open-source<a id="_idIndexMarker1207"/> framework for building IoT gateways. It provides <a id="_idIndexMarker1208"/>a set of Java APIs for accessing hardware interfaces, managing network configurations, and interacting with <span class="No-Break">cloud services.</span></li><li><strong class="bold">Eclipse Kapua</strong>: A<a id="_idIndexMarker1209"/> modular IoT cloud platform that works in conjunction <a id="_idIndexMarker1210"/>with Eclipse Kura to provide end-to-end IoT solutions. It offers features such as device management, data management, and <span class="No-Break">application integration.</span></li></ul></li>
				<li><strong class="bold">Apache Edgent</strong>: Apache Edgent (formerly known as Quarks) is a lightweight, embeddable programming <a id="_idIndexMarker1211"/>model and runtime for edge devices. It allows <a id="_idIndexMarker1212"/>developers to create analytics applications that can run on small-footprint devices and integrate with central <span class="No-Break">data systems.</span></li>
				<li><strong class="bold">Vert.x</strong>: Vert.x<a id="_idIndexMarker1213"/> is a toolkit for building reactive applications on the JVM. Its event-driven<a id="_idIndexMarker1214"/> architecture and lightweight nature make it well suited for edge-computing scenarios where low latency and high concurrency <span class="No-Break">are essential.</span></li>
				<li><strong class="bold">AWS IoT Greengrass</strong>: AWS IoT Greengrass<a id="_idIndexMarker1215"/> extends AWS capabilities to <a id="_idIndexMarker1216"/>edge devices, enabling them to act locally on the data they generate while still using the cloud for management, analytics, and durable storage. Java developers can create Greengrass Lambda functions to process and respond to <span class="No-Break">local events.</span></li>
				<li><strong class="bold">Azure IoT Edge</strong>: Azure IoT Edge<a id="_idIndexMarker1217"/> allows developers to deploy and run containerized <a id="_idIndexMarker1218"/>applications at the edge. Java applications can be packaged in Docker containers and deployed using Azure IoT Edge runtime, enabling seamless integration with Azure <span class="No-Break">cloud services.</span></li>
				<li><strong class="bold">Google Cloud IoT Edge</strong>: Google Cloud IoT Edge<a id="_idIndexMarker1219"/> brings Google Cloud’s ML and data<a id="_idIndexMarker1220"/> processing capabilities to edge devices. Java developers can utilize TensorFlow Lite and other Google Cloud services to create intelligent <span class="No-Break">edge applications.</span></li>
			</ul>
			<p>Java’s robust ecosystem, platform independence, and extensive library support make it a strong contender for edge computing. By leveraging frameworks and tools designed for edge environments, Java developers can build efficient, scalable, and secure edge applications that harness the full potential of edge computing architectures. As edge computing continues to evolve, Java is well positioned to play a critical role in shaping the future of distributed and decentralized <span class="No-Break">data processing.</span></p>
			<h1 id="_idParaDest-268"><a id="_idTextAnchor303"/>AI and ML integration</h1>
			<p>As we look toward the future of Java in cloud computing, the integration of AI and ML presents exciting opportunities and challenges. While <a href="B20937_07.xhtml#_idTextAnchor187"><span class="No-Break"><em class="italic">Chapter 7</em></span></a> focused on Java’s concurrency mechanisms for ML workflows, this section explores Java’s evolving role in cloud-based AI/ML ecosystems and its integration with advanced cloud <span class="No-Break">AI services.</span></p>
			<h2 id="_idParaDest-269"><a id="_idTextAnchor304"/>Java’s position in cloud-based AI/ML workflows</h2>
			<p>Here are some of Java’s evolving roles in cloud-based <span class="No-Break">AI/ML ecosystems:</span></p>
			<ul>
				<li><strong class="bold">Serverless AI/ML with Java</strong>: The<a id="_idIndexMarker1221"/> future of Java in cloud-based AI/ML workflows is increasingly serverless. Frameworks such as AWS Lambda and Google Cloud Functions allow developers to deploy AI/ML models as serverless functions. This trend is expected to grow, enabling more efficient and scalable AI/ML operations without the need for <span class="No-Break">managing infrastructure.</span></li>
				<li><strong class="bold">Java as an orchestrator</strong>: Java <a id="_idIndexMarker1222"/>is positioning itself as a powerful orchestrator for complex AI/ML pipelines in the cloud. Its robustness and extensive ecosystem make it ideal for managing workflows that involve multiple AI/ML services, data sources, and processing steps. Expect to see more Java-based tools and frameworks designed specifically for AI/ML <a id="_idIndexMarker1223"/>pipeline orchestration in <span class="No-Break">cloud environments.</span></li>
				<li><strong class="bold">Edge AI with Java</strong>: As edge computing gains prominence, Java’s <em class="italic">write once, run anywhere</em> philosophy<a id="_idIndexMarker1224"/> becomes increasingly valuable. Java is being adapted for edge AI applications, allowing models trained in the cloud to be deployed and run on edge devices. This trend will likely accelerate, with Java serving as a bridge between cloud-based training and <span class="No-Break">edge-based inference.</span></li>
			</ul>
			<p>Next, let’s explore Java’s integration with advanced cloud-based <span class="No-Break">AI services.</span></p>
			<h2 id="_idParaDest-270"><a id="_idTextAnchor305"/>Integration of Java with cloud AI services</h2>
			<p>Integrating Java applications with cloud-based AI services opens up a world of possibilities for developers, enabling the creation of intelligent and adaptive software solutions. Cloud AI services offer pre-trained models, scalable infrastructure, and APIs that make it easier to implement advanced ML and AI capabilities without the need for extensive in-house expertise. The following is a list of popular cloud AI services that can be integrated with <span class="No-Break">Java applications:</span></p>
			<ul>
				<li><strong class="bold">Native Java SDKs for cloud AI services</strong>: Major cloud providers are investing in developing a<a id="_idIndexMarker1225"/> robust <strong class="bold">Java Development Kit</strong> (<strong class="bold">JDK</strong>) for <a id="_idIndexMarker1226"/>their AI services. For example, AWS has released the AWS SDK for Java 2.0, which provides streamlined access to services such as Amazon SageMaker. Google Cloud has also enhanced its Java client libraries for AI and ML services. This trend is expected to continue, making it easier for Java developers to integrate cloud AI services into <span class="No-Break">their applications.</span></li>
				<li><strong class="bold">Java-friendly AutoML platforms</strong>: Cloud<a id="_idIndexMarker1227"/> providers are developing AutoML platforms that are increasingly Java friendly. For instance, Google Cloud AutoML now offers Java client libraries, allowing Java applications to easily train and deploy custom ML models without extensive ML expertise. This trend is likely to expand, making advanced AI capabilities more accessible to <span class="No-Break">Java developers.</span></li>
				<li><strong class="bold">Containerized Java AI/ML deployments</strong>: The future of Java in cloud AI/ML workflows is closely tied to <a id="_idIndexMarker1228"/>containerization. Platforms such as Kubernetes are becoming the de facto standard for deploying and managing AI/ML workloads in the cloud. Java’s compatibility with containerization technologies positions it well for this trend. Expect to see more tools and best practices emerge for deploying Java-based AI/ML applications in <span class="No-Break">containerized environments.</span></li>
				<li><strong class="bold">Java in federated learning</strong>: Federated learning<a id="_idIndexMarker1229"/> is an ML technique that trains algorithms across multiple decentralized edge devices or servers holding local data samples, without exchanging them. This approach addresses growing privacy concerns by allowing model training on distributed datasets without centrally pooling <span class="No-Break">the data.</span><p class="list-inset">As privacy concerns grow, federated learning is gaining traction. Java’s robust security features and its wide adoption in enterprise environments make it a strong candidate for implementing federated learning systems. Cloud providers are likely to offer more support for Java in their federated learning offerings, enabling models to be trained across decentralized data sources without <span class="No-Break">compromising privacy.</span></p></li>
				<li><strong class="bold">Java for Machine Learning Operations (MLOps)</strong>: The emerging field of MLOps is seeing increased adoption of Java. Its stability and extensive tooling make Java well suited for building robust<a id="_idIndexMarker1230"/> MLOps pipelines in the cloud. Expect to see more Java-based MLOps tools and integrations with cloud CI/CD services specifically designed for <span class="No-Break">AI/ML workflows.</span></li>
			</ul>
			<p>In conclusion, Java’s role in cloud-based AI/ML is evolving beyond just a language for implementing algorithms. It’s becoming a crucial part of the broader AI/ML ecosystem in the cloud, from serverless deployments to edge computing, and from AutoML to MLOps. As cloud AI services continue to mature, Java’s integration with these services will deepen, offering developers powerful new ways to build intelligent, scalable applications in <span class="No-Break">the cloud.</span></p>
			<h2 id="_idParaDest-271"><a id="_idTextAnchor306"/>Use case – serverless AI image analysis with AWS Lambda and Fargate</h2>
			<p>This use case <a id="_idIndexMarker1231"/>demonstrates a scalable, serverless architecture for AI-powered image analysis using AWS Lambda and Fargate. AWS Fargate is AWS’s implementation of serverless containers. This technology allows for the deployment of entire Java applications in a serverless fashion, leveraging container orchestration platforms such as Kubernetes and AWS Fargate. By packaging Java applications as containers, developers can enjoy the benefits of serverless computing – such as automatic scaling and pay-per-use pricing – while maintaining control over the runtime environment. This approach ensures consistency across different environments, provides flexibility with the inclusion of necessary libraries and tools, and offers <span class="No-Break">robust scalability.</span></p>
			<p>The system consists of two main components, each built as a separate <span class="No-Break">Quarkus project:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="source-inline">ImageAnalysisCoordinator</strong></span><span class="No-Break">:</span><ul><li>Built as a native executable for optimal performance in a <span class="No-Break">serverless environment</span></li><li>Triggered when an image is uploaded to an <span class="No-Break">S3 bucket</span></li><li>Performs quick analysis using <span class="No-Break">Amazon Rekognition</span></li><li>Initiates a more detailed analysis by launching an AWS <span class="No-Break">Fargate task</span></li></ul></li>
				<li><span class="No-Break"><strong class="source-inline">FargateImageAnalyzer</strong></span><span class="No-Break">:</span><ul><li>Built as a JVM-based application and containerized <span class="No-Break">using Docker</span></li><li>Runs as a task in AWS Fargate when triggered by the <span class="No-Break">Lambda function</span></li><li>Performs in-depth image processing using advanced <span class="No-Break">AI techniques</span></li><li>Stores detailed analysis results back <span class="No-Break">in S3</span></li></ul></li>
			</ul>
			<p>This<a id="_idIndexMarker1232"/> two-component architecture allows for efficient resource utilization: the lightweight Lambda function handles the initial processing and orchestration, while the Fargate container manages the more intensive computational tasks. Together, they form a r<a id="_idTextAnchor307"/>obust, scalable solution for serverless AI-powered <span class="No-Break">image analysis.</span></p>
			<p><strong class="bold">Step 1: Create a </strong><span class="No-Break"><strong class="bold">Fargate container</strong></span><span class="No-Break">:</span></p>
			<p><strong class="source-inline">Dockerfile.jvm</strong>: The <strong class="source-inline">Dockerfile.jvm</strong> is used to build the Docker image for the Fargate container component of the serverless AI image analysis architecture. Unlike the Lambda function, which is built as a native executable, the Fargate container runs the <strong class="source-inline">FargateImageAnalyzer</strong> application as a JVM-based Quarkus application. This choice is due to the Fargate container being responsible for the more computationally intensive image processing tasks, where the benefits of the Quarkus framework can outweigh the potential performance advantages of a <span class="No-Break">native executable.</span></p>
			<p>This Dockerfile defines the steps to build a Docker image for a Quarkus application. The image is designed to run within a Red<a id="_idIndexMarker1233"/> Hat <strong class="bold">Universal Base Image</strong> (<strong class="bold">UBI</strong>) environment with <span class="No-Break">OpenJDK 17:</span></p>
			<pre class="source-code">
FROM registry.access.redhat.com/ubi8/openjdk-17:1.14
ENV LANGUAGE='en_US:en'
# We make four distinct layers so if there are application changes the library layers can be re-used
COPY --chown=185 target/quarkus-app/lib/ /deployments/lib/
COPY --chown=185 target/quarkus-app/*.jar /deployments/
COPY --chown=185 target/quarkus-app/app/ /deployments/app/
COPY --chown=185 target/quarkus-app/quarkus/ /deployments/quarkus/
EXPOSE 8080
USER 185
ENV JAVA_OPTS="-Dquarkus.http.host=0.0.0.0 -Djava.util.logging.manager=org.jboss.logmanager.LogManager"
ENV JAVA_APP_JAR="/deployments/quarkus-run.jar"
ENTRYPOINT [ "/opt/jboss/container/java/run/run-java.sh" ]</pre>			<p><strong class="source-inline">FargateImageAnalyzer.java</strong> performs<a id="_idIndexMarker1234"/> in-depth <span class="No-Break">image processing:</span></p>
			<pre class="source-code">
@QuarkusMain
@ApplicationScoped
public class FargateImageAnalyzer implements QuarkusApplication {
    @Inject
    S3Client s3Client;
    @Inject
    RekognitionClient rekognitionClient;
    @Override
    public int run(String... args) throws Exception {
        String bucket = System.getenv("IMAGE_BUCKET");
        String key = System.getenv("IMAGE_KEY");
        try {
            DetectLabelsRequest labelsRequest = DetectLabelsRequest.            builder()
                    .image(Image.builder().s3Object(
                        S3Object.builder().bucket(
                            bucket).name(key).build()
                            ).build())
                    .maxLabels(10)
                    .minConfidence(75F)
                    .build();
            DetectLabelsResponse labelsResult = rekognitionClient.            detectLabels(labelsRequest);
            DetectFacesRequest facesRequest = DetectFacesRequest.            builder()
                    .image(Image.builder().s3Object(
                        S3Object.builder().bucket(
                            bucket).name(key).build()
                            ).build())
                    .attributes(Attribute.ALL)
                    .build();
            DetectFacesResponse facesResult = rekognitionClient.            detectFaces(facesRequest);
            String analysisResult =             generateAnalysisResult(labelsResult, facesResult);
            s3Client.putObject(builder -&gt; builder
                    .bucket(bucket)
                    .key(key + "_detailed_analysis.json")
                    .build(),
                    RequestBody.fromString(analysisResult));
        } catch (Exception e) {
            System.err.println("Error processing image: " +             e.getMessage());
            return 1;
        }
        return 0;
    }
    private String generateAnalysisResult(
        DetectLabelsResponse labelsResult, DetectFacesResponse         facesResult) {
            // Implement result generation logic
            return "Analysis result";
    }
}</pre>			<p>The <strong class="source-inline">FargateImageAnalyzer</strong> class is the<a id="_idIndexMarker1235"/> main application that runs inside the Fargate container as part of the serverless AI image analysis architecture. It is designed as a Quarkus application and implements the <strong class="source-inline">QuarkusApplication</strong> interface. The class is responsible for extracting the S3 bucket and object key information, using the AWS Rekognition client to perform image analysis, generating a detailed analysis result, and storing it back in the same S3 bucket. It is designed to run as a standalone Quarkus application within the Fargate task, leveraging the benefits of running in a containerized environment and the ease of deployment and scaling that <span class="No-Break">Fargate provides.</span></p>
			<p><strong class="bold">Step 2: Create a </strong><span class="No-Break"><strong class="bold">Lambda function</strong></span><span class="No-Break">:</span></p>
			<p><strong class="source-inline">Dockerfile.native</strong>: This Dockerfile is used to build the Docker image for the native executable of the Lambda function component in the serverless AI image analysis architecture. This Dockerfile follows the Quarkus convention for building native executables by using the <strong class="source-inline">quay.io/quarkus/ubi-quarkus-native-image</strong> base image and performing the necessary build steps. By using <strong class="source-inline">Dockerfile.native</strong>, the Lambda function can be packaged as a native executable, which provides improved performance and reduced cold start times compared to a JVM-based deployment. This is<a id="_idIndexMarker1236"/> particularly beneficial for serverless applications where rapid response times <span class="No-Break">are crucial:</span></p>
			<pre class="source-code">
FROM quay.io/quarkus/ubi-quarkus-native-image:21.0.0-java17 AS build
COPY src /usr/src/app/src
COPY pom.xml /usr/src/app
USER root
RUN chown -R quarkus /usr/src/app
USER quarkus
RUN mvn -f /usr/src/app/pom.xml -Pnative clean package
FROM registry.access.redhat.com/ubi8/ubi-minimal
WORKDIR /work/
COPY --from=build /usr/src/app/target/*-runner /work/application
RUN chmod 775 /work/application
EXPOSE 8080
CMD ["./application", "-Dquarkus.http.host=0.0.0.0"]</pre>			<p><strong class="source-inline">ImageAnalysisCoordinator.java</strong>: This is an AWS Lambda function that gets triggered when a new image is uploaded to an <span class="No-Break">S3 bucket:</span></p>
			<pre class="source-code">
@ApplicationScoped
public class ImageAnalysisCoordinator implements RequestHandler&lt;S3Event, String&gt; {
    @Inject
    EcsClient ecsClient;
    @Inject
    S3Client s3Client;
    @Override
    public String handleRequest(S3Event s3Event,
        Context context) {
            String bucket = s3Event.getRecords().get(
                0).getS3().getBucket().getName();
            String key = s3Event.getRecords().get(
                0).getS3().getObject().getKey();
            RunTaskRequest runTaskRequest = RunTaskRequest.builder()
                .cluster("your-fargate-cluster")
                .taskDefinition("your-task-definition")
                .launchType("FARGATE")
                .overrides(TaskOverride.builder()
                    .containerOverrides(
                        ContainerOverride.builder()
                        .name("your-container-name")
             // Replace with your actual container name
                        .environment(KeyValuePair.builder()
                            .name("BUCKET")
                            .value(bucket)
                            .build(),
                        KeyValuePair.builder()
                            .name("KEY")
                            .value(key)
                            .build())
                        .build())
                    .build())
                .build();
                try {
                    ecsClient.runTask(runTaskRequest);
                    return "Fargate task launched for image analysis:                     " + bucket + "/" + key;
                } catch (Exception e) {
                     context.getLogger().log(
                         "Error launching Fargate task: " +                          e.getMessage());
                        return "Error launching Fargate task";
                }
        }
}</pre>			<p>The <strong class="source-inline">ImageAnalysisCoordinator</strong> class is an AWS Lambda function that serves as the entry point for the serverless AI image analysis architecture. Its primary responsibilities are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Extracting the S3 bucket and object key information from the incoming S3 event that triggers the <span class="No-Break">Lambda function</span></li>
				<li>Initiating a Fargate task to perform the computationally intensive image analysis by launching an ECS task and passing the necessary environment variables (bucket <span class="No-Break">and key)</span></li>
				<li>Handling any errors that occur during the Fargate task launch process and returning appropriate <span class="No-Break">status messages</span></li>
			</ul>
			<p>This Lambda<a id="_idIndexMarker1237"/> function acts as a lightweight coordinator, responsible for orchestrating the overall image analysis workflow. It triggers the more resource-intensive processing to be performed by the Fargate container, which runs the <strong class="source-inline">FargateImageAnalyzer</strong> application. By separating the responsibilities in this way, t<a id="_idTextAnchor308"/>he architecture achieves efficient resource utilization <span class="No-Break">and scalability.</span></p>
			<p><strong class="bold">Step 3: Build </strong><span class="No-Break"><strong class="bold">the projects</strong></span><span class="No-Break">:</span></p>
			<p>For the Lambda function, run the following command to package <span class="No-Break">the function:</span></p>
			<pre class="console">
mvn package -Pnative -Dquarkus.native.container-build=true</pre>			<p>For the Fargate container, run the following command to build the <span class="No-Break">Docker image:</span></p>
			<pre class="console">
docker build -f src/main/docker/Dockerfile.jvm -t quarkus-ai-image-analysis .</pre>			<p><strong class="bold">Step </strong><span class="No-Break"><strong class="bold">4: Deploy</strong></span><span class="No-Break">:</span></p>
			<p>To streamline the deployment of the serverless AI infrastructure, an AWS CloudFormation template has been prepared. This template automates the entire deployment process, including the <span class="No-Break">following steps:</span></p>
			<ol>
				<li>Create the necessary AWS resources, such as <span class="No-Break">the following:</span><ul><li>S3 bucket for storing the images and <span class="No-Break">analysis results</span></li><li>ECS cluster and task definition for the <span class="No-Break">Fargate container</span></li><li>Lambda function for the <span class="No-Break"><strong class="source-inline">ImageAnalysisCoordinator</strong></span><span class="No-Break"> class</span></li></ul></li>
				<li>Upload the built artifacts (Lambda function <strong class="source-inline">.jar</strong> file and Docker image) to the <span class="No-Break">appropriate locations.</span></li>
				<li>Configure the necessary permissions and triggers for the Lambda function to be invoked when an image is uploaded to the <span class="No-Break">S3 bucket.</span></li>
				<li>Deploy the<a id="_idIndexMarker1238"/> Fargate task definition and set up the necessary <span class="No-Break">network configurations.</span></li>
			</ol>
			<p>To use the CloudFormation template, you can find it in the book’s accompanying GitHub repository alongside the source code. Simply download the template, fill in any necessary parameters, and deploy it using the AWS CloudFormation service. This will set up the entire serverless AI infrastructure for you, streamlining the de<a id="_idTextAnchor309"/>ployment process and ensuring consistency across <span class="No-Break">different environments.</span></p>
			<h1 id="_idParaDest-272"><a id="_idTextAnchor310"/>Emerging concurrency and parallel processing tools in Java</h1>
			<p>As Java continues to evolve, new tools and frameworks are being developed to address the growing demands of concurrent and parallel programming. These advancements aim to simplify development, improve performance, and enhance scalability in <span class="No-Break">modern applications.</span></p>
			<h2 id="_idParaDest-273"><a id="_idTextAnchor311"/>Introduction to Project Loom – virtual threads for efficient concurrency</h2>
			<p><strong class="bold">Project Loom</strong> is an<a id="_idIndexMarker1239"/> ambitious initiative by the OpenJDK community to enhance Java’s concurrency model. The primary goal is to simplify writing, maintaining, and observing high-throughput concurrent applications by introducing virtual threads (also known <span class="No-Break">as </span><span class="No-Break"><strong class="bold">fibers</strong></span><span class="No-Break">).</span></p>
			<p>Virtual threads<a id="_idIndexMarker1240"/> are lightweight and are managed by the Java runtime rather than the OS. Unlike traditional threads, which are limited by the number of OS threads, virtual threads can scale to handle millions of concurrent operations without overwhelming system resources. They allow developers to write code in a synchronous style while achieving the scalability of <span class="No-Break">asynchronous models.</span></p>
			<p>Its key features<a id="_idIndexMarker1241"/> include <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Lightweight nature</strong>: Virtual threads are much lighter than traditional OS threads, reducing memory and <span class="No-Break">context-switching overhead</span></li>
				<li><strong class="bold">Blocking calls</strong>: They handle blocking calls efficiently, suspending only the virtual thread while keeping the underlying OS thread available for <span class="No-Break">other tasks</span></li>
				<li><strong class="bold">Simplicity</strong>: Developers can write straightforward, readable code using familiar constructs such as loops and conditionals without resorting to complex <span class="No-Break">asynchronous paradigms</span></li>
			</ul>
			<p>To illustrate the practical application of Project Loom and virtual threads, let’s explore a code example that demonstrates implementing a high-concurrency microservice using Project Loom and Akka within an AWS <span class="No-Break">cloud environment.</span></p>
			<h2 id="_idParaDest-274"><a id="_idTextAnchor312"/>Code example – implementing a high-concurrency microservice using Project Loom and Akka for the AWS cloud environment</h2>
			<p>In this section, we will <a id="_idIndexMarker1242"/>demonstrate how to implement a high-concurrency microservice using Project Loom and Akka, designed to run in an AWS cloud environment. This example will showcase how to leverage virtual threads from Project Loom and the actor model provided by Akka to build a scalable and <span class="No-Break">efficient microservice:</span></p>
			<p><strong class="bold">Step 1: Project setup</strong>: Enter <span class="No-Break"><strong class="source-inline">pom.xml</strong></span><span class="No-Break"> dependencies:</span></p>
			<pre class="source-code">
&lt;!-- Akka Dependencies --&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.typesafe.akka&lt;/groupId&gt;
        &lt;artifactId&gt;akka-actor-typed_${
            scala.binary.version}&lt;/artifactId&gt;
        &lt;version&gt;${akka.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.typesafe.akka&lt;/groupId&gt;
        &lt;artifactId&gt;akka-stream_${scala.binary.version}&lt;/artifactId&gt;
        &lt;version&gt;${akka.version}&lt;/version&gt;
    &lt;/dependency&gt;
&lt;!-- AWS SDK --&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;software.amazon.awssdk&lt;/groupId&gt;
        &lt;artifactId&gt;s3&lt;/artifactId&gt;
        &lt;version&gt;2.17.100&lt;/version&gt;
    &lt;/dependency&gt;</pre>			<p><strong class="bold">Step 2: </strong><span class="No-Break"><strong class="bold">Code implementation</strong></span><span class="No-Break">:</span></p>
			<p><strong class="source-inline">HighConcurrencyService.java</strong>: The <a id="_idIndexMarker1243"/>main entry point for the service, which sets up <strong class="source-inline">ActorSystem</strong> and uses <strong class="source-inline">ExecutorService</strong> to manage <span class="No-Break">virtual threads:</span></p>
			<pre class="source-code">
public class HighConcurrencyService {
    public static void main(String[] args) {
        ActorSystem&lt;Void&gt; actorSystem = ActorSystem.create(
            Behaviors.empty(), "high-concurrency-system");
        S3Client s3Client = S3Client.create();
        ExecutorService executorService = Executors.        newCachedThreadPool();
// Use a compatible thread pool
        for (int i = 0; i &lt; 1000; i++) {
            final int index = i;
            executorService.submit(() -&gt; {
                // Create and start the actor
                Behavior&lt;RequestHandlerActor.HandleRequest&gt; behavior =                 RequestHandlerActor.create(s3Client);
                var requestHandlerActor = actorSystem.systemActorOf(
                    behavior, "request-handler-" + index,
                    Props.empty());
                // Send a request to the actor
                requestHandlerActor.tell(
                    new RequestHandlerActor.HandleRequest(
                        "example-bucket",
                        "example-key-" + index,
                        "example-content"));
            });
        }
        // Clean up
        executorService.shutdown();
        actorSystem.terminate();
    }
}</pre>			<p>The <strong class="source-inline">HighConcurrencyService</strong> class serves as the entry point for a high-concurrency microservice application designed to handle numerous requests efficiently. Utilizing Akka’s actor model and Java’s concurrency features, this class demonstrates how to manage thousands of concurrent tasks effectively. The main function initializes <strong class="source-inline">ActorSystem</strong> for creating and managing actors, sets up an S3 client for interacting with AWS S3 services, and employs an executor service to submit multiple tasks. Each task involves creating a new actor instance to handle a specific request, showcasing how to leverage virtual<a id="_idIndexMarker1244"/> threads and actors for scalable and concurrent processing in a <span class="No-Break">cloud environment.</span></p>
			<p><strong class="source-inline">RequestHandlerActor.java</strong>: This actor handles individual requests to process data and interact with <span class="No-Break">AWS S3:</span></p>
			<pre class="source-code">
public class RequestHandlerActor {
    public static Behavior&lt;HandleRequest&gt; create(
        S3Client s3Client) {
            return Behaviors.setup(context -&gt;
                Behaviors.receiveMessage(message -&gt; {
            processRequest(s3Client, message.bucket,
                message.key, message.content);
            return Behaviors.same();
        }));
    }
    private static void processRequest(S3Client s3Client,
        String bucket, String key, String content) {
            PutObjectRequest putObjectRequest = PutObjectRequest.            builder()
                .bucket(bucket)
                .key(key)
                .build();
        PutObjectResponse response = s3Client.putObject(
            putObjectRequest,
            RequestBody.fromString(content));
        System.out.println(
            "PutObjectResponse: " + response);
    }
    public static class HandleRequest {
        public final String bucket;
        public final String key;
        public final String content;
        public HandleRequest(String bucket, String key,
            String content) {
                this.bucket = bucket;
                this.key = key;
                this.content = content;
        }
    }
}</pre>			<p>The <strong class="source-inline">RequestHandlerActor</strong> class defines the behavior of an actor responsible for handling individual <a id="_idIndexMarker1245"/>requests in the high-concurrency microservice. It processes requests to store data in AWS S3 by utilizing the S3 client. The <strong class="source-inline">HandleRequest</strong> inner class encapsulates the details of a request, including the S3 bucket name, key, and content to be stored. The actor’s behavior is defined as receiving these <strong class="source-inline">HandleRequest</strong> messages, processing the request by interacting with the S3 service, and logging the result. This class exemplifies the use of Akka’s actor model to manage and process concurrent tasks efficiently, ensuring scalability and robustness in <span class="No-Break">cloud-based applications.</span></p>
			<p><strong class="bold">Step 3: Deployment </strong><span class="No-Break"><strong class="bold">to AWS</strong></span><span class="No-Break">:</span></p>
			<p><strong class="bold">Dockerfile</strong>: The <a id="_idIndexMarker1246"/>Dockerfile should be created and saved in the root directory of your application project. This is the standard location for the Dockerfile, as it allows the Docker build process to access all the necessary files and resources without requiring additional <span class="No-Break">context switches:</span></p>
			<pre class="console">
FROM amazoncorretto:17-alpine as builder
WORKDIR /workspace
COPY pom.xml .
COPY src ./src
RUN ./mvnw package -DskipTests
FROM amazoncorretto:17-alpine
WORKDIR /app
COPY --from=builder /workspace/target/high-concurrency-microservice-1.0.0-SNAPSHOT.jar /app/app.jar
ENTRYPOINT ["java", "-jar", "/app/app.jar"]</pre>			<p>The key points about this Dockerfile are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>It uses the <strong class="source-inline">amazoncorretto: 17-alpine</strong> base image, which provides the Java 17 runtime environment based on the Alpine <span class="No-Break">Linux distribution</span></li>
				<li>It follows a two-stage <span class="No-Break">build process:</span><ul><li>The <em class="italic">builder</em> stage compiles the application and packages it into a <span class="No-Break">JAR file</span></li><li>The final stage copies the packaged JAR file and sets the entry point to run <span class="No-Break">the application</span></li></ul></li>
			</ul>
			<p><strong class="bold">Deploy using </strong><span class="No-Break"><strong class="bold">AWS ECS/Fargate</strong></span><span class="No-Break">:</span></p>
			<p>We have also prepared a<a id="_idIndexMarker1247"/> CloudFormation template for these processes, which can be found in the code repository. Follow these steps <span class="No-Break">to deploy:</span></p>
			<ol>
				<li><strong class="bold">Create an ECS cluster and task definition in AWS</strong>: Set up your ECS cluster and define the task that will run your <span class="No-Break">Docker container.</span></li>
				<li><strong class="bold">Upload the Docker image to Amazon Elastic Container Registry (ECR)</strong>: Push the Docker image to Amazon ECR for <span class="No-Break">easy deployment.</span></li>
				<li><strong class="bold">Configure ECS service to use Fargate and run the container</strong>: Configure your ECS service to use AWS Fargate, a serverless compute engine, to run the <span class="No-Break">containerized application.</span></li>
			</ol>
			<p>This streamlined process ensures that your high-concurrency microservice is efficiently deployed in a scalable <span class="No-Break">cloud environment.</span></p>
			<p>This high-concurrency microservice example demonstrates the power of leveraging Project Loom’s virtual threads and Akka’s actor model to build scalable, efficient, and cloud-ready applications. By harnessing these advanced concurrency tools, developers can simplify their code, improve resource utilization, and enhance the overall performance and responsiveness of their services, particularly in the context of the AWS cloud environment. This lays the foundation for exploring the next wave of cloud innovations, where emerging technologies such as AWS Graviton processors and Google Cloud Spanner can further enhance the scalability and capabilities of <span class="No-Break">cloud-based applications.</span></p>
			<h1 id="_idParaDest-275"><a id="_idTextAnchor313"/>Preparing for the next wave of cloud innovations</h1>
			<p>As cloud technologies continue to evolve rapidly, developers and organizations must stay ahead of the curve. Anticipating advancements in cloud services, here’s how you can prepare for upcoming advancements in <span class="No-Break">cloud services:</span></p>
			<ul>
				<li><strong class="bold">AWS Graviton</strong>: AWS Graviton<a id="_idIndexMarker1248"/> is a family of ARM-based processors designed by AWS to offer improved price performance compared to traditional x86-based processors, particularly for workloads that can take advantage of the parallel processing capabilities of ARM architecture. The latest <strong class="bold">Graviton3</strong> iteration<a id="_idIndexMarker1249"/> can provide up to 25% better performance and 60% better price performance than previous-generation Intel-based <span class="No-Break">EC2 instances.</span></li>
				<li><strong class="bold">Amazon Corretto</strong>: On the other hand, Amazon Corretto<a id="_idIndexMarker1250"/> is a no-cost, multiplatform, production-ready distribution of the OpenJDK, a free and open-source implementation of the Java platform. Corretto is available for both x86-based and ARM-based (including Graviton) architectures, providing a certified, tested, and supported version of the JDK for AWS customers. The ARM-based Corretto JDK is optimized to run on AWS <span class="No-Break">Graviton-powered instances.</span></li>
			</ul>
			<p>Consider using the Amazon Corretto JDK. Here is a code snippet to build a <span class="No-Break">Docker image:</span></p>
			<pre class="console">
FROM --platform=$BUILDPLATFORM amazoncorretto:17
COPY . /app
WORKDIR /app
RUN ./gradlew build
CMD ["java", "-jar", "app.jar"]</pre>			<p>Build and push run the <span class="No-Break">following command:</span></p>
			<pre class="console">
docker buildx build --platform linux/amd64,linux/arm64 -t myapp:latest --push .</pre>			<p><strong class="bold">Google Cloud Spanner</strong>: Cloud Spanner is a fully managed, scalable, relational database service offering strong<a id="_idIndexMarker1251"/> consistency and <span class="No-Break">high availability:</span></p>
			<ul>
				<li><strong class="bold">Global distribution</strong>: Spanner supports multi-regional and global deployment, providing high availability and low-latency access <span class="No-Break">to data</span></li>
				<li><strong class="bold">Strong consistency</strong>: Unlike many NoSQL databases, Spanner maintains strong consistency, making it suitable for applications that require <span class="No-Break">transactional integrity</span></li>
				<li><strong class="bold">Seamless scaling</strong>: Spanner automatically handles horizontal scaling, allowing applications to grow without compromising performance <span class="No-Break">or availability</span></li>
			</ul>
			<p><strong class="bold">Example</strong>: Using Java <a id="_idIndexMarker1252"/>with <span class="No-Break">Cloud Spanner:</span></p>
			<pre class="source-code">
import com.google.cloud.spanner.*;
try (Spanner spanner = SpannerOptions.newBuilder(
    ).build().getService()) {
    DatabaseClient dbClient = spanner.getDatabaseClient(
        DatabaseId.of(projectId, instanceId, databaseId));
    try (ResultSet resultSet = dbClient
        .singleUse() // Create a single-use read-only //transaction
        .executeQuery(Statement.of("SELECT * FROM Users"))){
    while (resultSet.next()) {
        System.out.printf("User ID: %d, Name: %s\n",
            resultSet.getLong("UserId"),
            resultSet.getString("Name"));
        }
    }}</pre>			<p>This code snippet demonstrates the use of the Java client library to interact with Google Cloud Spanner. The code first creates a Spanner client using the <strong class="source-inline">SpannerOptions</strong> builder and retrieves the service instance. It then gets a <strong class="source-inline">DatabaseClient</strong> instance, which is used to interact with a specific Spanner database identified by the <strong class="source-inline">projectId</strong>, <strong class="source-inline">instanceId</strong>, and <span class="No-Break"><strong class="source-inline">databaseId</strong></span><span class="No-Break"> parameters.</span></p>
			<p>Within a try-with-resources block, the code creates a single-use, read-only transaction using the <strong class="source-inline">singleUse()</strong> method and executes a <strong class="source-inline">SQL SELECT</strong> query to retrieve all records from the <strong class="source-inline">Users</strong> table. The results are then iterated through, and the <strong class="source-inline">UserId</strong> and <strong class="source-inline">Name</strong> columns are printed for each <span class="No-Break">user record.</span></p>
			<p>This example showcases the basic usage of the Google Cloud Spanner Java client library, including establishing a connection to the database, executing a query, and processing the results, while ensuring proper resource management <span class="No-Break">and cleanup.</span></p>
			<h2 id="_idParaDest-276"><a id="_idTextAnchor314"/>Quantum computing</h2>
			<p><strong class="bold">Quantum computing</strong>, though <a id="_idIndexMarker1253"/>still in its early stages, promises to revolutionize various industries by solving complex problems that are infeasible for classical computers. Quantum computers leverage the principles of quantum mechanics, such as superposition and entanglement, to perform computations <span class="No-Break">in parallel.</span></p>
			<p>While not immediately practical for most applications, it’s beneficial to start learning about quantum computing principles and how they might apply to your domain. Key concepts to explore include qubits, quantum gates, and quantum algorithms such as Shor’s algorithm for factoring large numbers and Grover’s algorithm for <span class="No-Break">search problems.</span></p>
			<p>Understanding these principles will prepare you for future advancements and potential integration of quantum computing into your workflows. By familiarizing yourself with the foundational concepts now, you’ll be better positioned to take advantage of quantum computing as it becomes more accessible and applicable to <span class="No-Break">real-world problems.</span></p>
			<p>Staying informed and exploring these technologies, even at an introductory level, will help ensure your organization is ready to adapt and thrive in the rapidly evolving <span class="No-Break">cloud landscape.</span></p>
			<h1 id="_idParaDest-277"><a id="_idTextAnchor315"/>Summary</h1>
			<p>As the final chapter of this book, we now stand at the precipice of the future, where cloud technologies continue to evolve at a breathtaking pace. In this concluding section, we explored the emerging trends and advancements that are poised to reshape the way we develop and deploy applications in the cloud, with a particular emphasis on Java’s pivotal role in shaping <span class="No-Break">these innovations.</span></p>
			<p>We began by delving into the evolution of serverless Java, where we saw how frameworks such as Quarkus and Micronaut are redefining the boundaries of function as a service. These cutting-edge tools leverage techniques such as native image compilation to deliver unprecedented performance and efficiency in serverless environments, while also enabling the deployment of full-fledged Java applications as serverless containers. This represents a significant shift, empowering developers to create highly scalable, responsive, and cloud-native applications that go beyond simple <span class="No-Break">function executions.</span></p>
			<p>Next, we turned our attention to the edge computing landscape, where data processing and decision-making are moving closer to the source. Java’s platform independence, performance, and extensive ecosystem make it an ideal choice for building edge applications. We introduced the key frameworks and tools that enable Java developers to leverage the power of edge computing, ensuring their applications can seamlessly integrate with this rapidly <span class="No-Break">advancing paradigm.</span></p>
			<p>Furthermore, we explored Java’s evolving role in the integration of AI and ML within cloud-based ecosystems. From serverless AI/ML workflows to the seamless integration of Java with cloud-based AI services, we uncovered the opportunities and challenges that this convergence presents, equipping you with the knowledge to harness the power of these technologies in your <span class="No-Break">Java-based applications.</span></p>
			<p>Finally, we ventured into the captivating realm of quantum computing, a field that promises to revolutionize various industries. While still in its early stages, understanding the fundamental principles of quantum computing, such as qubits, quantum gates, and algorithms, can prepare developers for future advancements and their potential integration with <span class="No-Break">Java-based applications.</span></p>
			<p>As we conclude this book, you now possess a comprehensive understanding of the emerging trends in cloud computing and Java’s pivotal role in shaping these innovations. Armed with this knowledge, you are poised to position your applications and infrastructure for success in the rapidly evolving cloud landscape, ensuring your organization can adapt and thrive in the years <span class="No-Break">to come.</span></p>
			<h1 id="_idParaDest-278"><a id="_idTextAnchor316"/>Questions</h1>
			<ol>
				<li>What i<a id="_idTextAnchor317"/>s a key benefit of using Quarkus and GraalVM for building serverless <span class="No-Break">Java applications?</span><ol><li class="Alphabets">Improved startup time and reduced <span class="No-Break">memory usage</span></li><li class="Alphabets">Easier integration with cloud-based <span class="No-Break">AI/ML services</span></li><li class="Alphabets">Seamless deployment across multiple <span class="No-Break">cloud providers</span></li><li class="Alphabets">All of <span class="No-Break">the above</span></li></ol></li>
				<li>Which of the following is a key advantage of using Java in edge <span class="No-Break">comput<a id="_idTextAnchor318"/>ing environments?</span><ol><li class="Alphabets"><span class="No-Break">Platform independence</span></li><li class="Alphabets">Extensive <span class="No-Break">library support</span></li><li class="Alphabets">Robust <span class="No-Break">security model</span></li><li class="Alphabets">All of <span class="No-Break">the above</span></li></ol></li>
				<li>Which cloud AI service allows Java developers to easily train and deploy custom ML models without extensive <span class="No-Break">ML expertise?</span><ol><li class="Alphabets"><span class="No-Break">AWS SageMaker</span></li><li class="Alphabets">Google <span class="No-Break">Cloud AutoML</span></li><li class="Alphabets">Microsoft Azure <span class="No-Break">Cognitive Services</span></li><li class="Alphabets">IBM <span class="No-Break">Watson Studio</span></li></ol></li>
				<li>Which quantum computing concept is demonstrated in the provided code example that puts a qubit <a id="_idTextAnchor319"/>into superposition and measures <span class="No-Break">the outcome?</span><ol><li class="Alphabets"><span class="No-Break">Quantum entanglement</span></li><li class="Alphabets"><span class="No-Break">Quantum teleportation</span></li><li class="Alphabets"><span class="No-Break">Quantum superposition</span></li><li class="Alphabets"><span class="No-Break">Quantum tunneling</span></li></ol></li>
				<li>W<a id="_idTextAnchor320"/>hat is a key benefit of using serverless containers for Java applications in <span class="No-Break">the cloud?</span><ol><li class="Alphabets">Reduced operational overhead for <span class="No-Break">managing infrastructure</span></li><li class="Alphabets">Increased cold start times for <span class="No-Break">serverless functions</span></li><li class="Alphabets">Inability to include custom libraries <span class="No-Break">and dependencies</span></li><li class="Alphabets">Limited control over the <span class="No-Break">runtime environment</span></li></ol></li>
			</ol>
		</div>
	

		<div id="_idContainer045">
			<h1 class="chapter-number" id="_idParaDest-279"><a id="_idTextAnchor321"/>Appendix A: Setting up a Cloud-Native Java Environment</h1>
			<h1 id="_idParaDest-280"><a id="_idTextAnchor322"/></h1>
			<p>In <a href="B20937_AppA.xhtml#_idTextAnchor321"><em class="italic">Appendix A</em></a>, you will learn how to set up a cloud-native environment for Java applications. This comprehensive guide covers everything from building and packaging Java applications to deploying them on popular cloud platforms like <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>), <strong class="bold">Microsoft Azure</strong>, and <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>). Key <span class="No-Break">topics include:</span></p>
			<ul>
				<li><strong class="bold">Building and packaging</strong>: Step-by-step instructions on using build tools like Maven and Gradle to create and manage <span class="No-Break">Java projects.</span></li>
				<li><strong class="bold">Ensuring cloud-readiness</strong>: Best practices for making your Java applications stateless and configurable to thrive in <span class="No-Break">cloud environments.</span></li>
				<li><strong class="bold">Containerization</strong>: How to create Docker images for your Java applications and deploy them <span class="No-Break">using Docker.</span></li>
				<li><strong class="bold">Cloud deployments</strong>: Detailed procedures for deploying Java applications on AWS, Azure, and GCP, including setting up the necessary cloud environments, creating and managing cloud resources, and using specific cloud services like Elastic Beanstalk, Kubernetes, and <span class="No-Break">serverless functions.</span></li>
			</ul>
			<p>By the end of this appendix, you will have a solid understanding of how to effectively build, package, containerize, and deploy Java applications in a <span class="No-Break">cloud-native environment.</span></p>
			<h1 id="_idParaDest-281"><a id="_idTextAnchor323"/>General approach – build and package Java applications</h1>
			<p>This section <a id="_idIndexMarker1254"/>provides a detailed guide on the essential steps required to<a id="_idIndexMarker1255"/> build and package your Java applications, ensuring they are ready for deployment in a <span class="No-Break">cloud environment.</span></p>
			<ol>
				<li>Ensure your app <span class="No-Break">is cloud-ready</span><ol><li class="upper-roman"><strong class="bold">Stateless:</strong> Design your application to be stateless. This means that each request should be independent and not rely on previous requests. Store session data in a distributed cache like Redis instead of <span class="No-Break">in memory.</span></li><li class="upper-roman"><strong class="bold">Configurable:</strong> Use external configuration files or environment variables to manage configuration. This <a id="_idIndexMarker1256"/>can be done using Spring Boot’s <strong class="source-inline">application.properties</strong> or <strong class="source-inline">application.yaml</strong> files, or by using a configuration<a id="_idIndexMarker1257"/> management tool. Here is <span class="No-Break">an example:</span></li></ol></li>
			</ol>
			<pre class="console">
server.port=8080
spring.datasource.url=jdbc:mysql://localhost:3306/mydb
spring.datasource.username=root
spring.datasource.password=password</pre>			<ol>
				<li value="2">Use a Build tool like Maven <span class="No-Break">or Gradle</span><ul><li><strong class="bold">Maven:</strong> Create a <strong class="source-inline">pom.xml</strong> file in your project root directory if it doesn’t already exist. Add the necessary dependencies. Here is an example <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">pom.xml</strong></span><span class="No-Break">:</span><pre class="source-code">
&lt;project  
    xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;groupId&gt;com.example&lt;/groupId&gt;
    &lt;artifactId&gt;myapp&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!-- Add other dependencies here --&gt;
    &lt;/dependencies&gt;
    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;</pre></li><li><strong class="bold">Gradle</strong>: Create a <strong class="source-inline">build.gradle</strong> file in your project root directory if it doesn’t already <a id="_idIndexMarker1258"/>exist. Add the necessary dependencies, here is an <a id="_idIndexMarker1259"/>example <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">build.gradle</strong></span><span class="No-Break">:</span><pre class="source-code">plugins {
    id 'org.springframework.boot' version '2.5.4'
    id 'io.spring.dependency-management' version '1.0.11.RELEASE'
    id 'java'
}
group = 'com.example'
version = '1.0-SNAPSHOT'
sourceCompatibility = '11'
repositories {
    mavenCentral()
}
dependencies {
    implementation 'org.springframework.boot:spring-boot-starter-web'
    // Add other dependencies here
}
test {
    useJUnitPlatform()
}</pre></li></ul></li>				<li><strong class="bold">Build the JAR file</strong>: Build the JAR file using Maven <span class="No-Break">or Gradle.</span><ul><li><strong class="bold">M<a id="_idTextAnchor324"/>aven</strong>: Run <a id="_idIndexMarker1260"/>the <span class="No-Break">following command:</span></li></ul></li>
			</ol>
			<pre class="console">
mvn clean package</pre>			<p class="list-inset">This command <a id="_idIndexMarker1261"/>will generate a JAR file in the target directory, typically <span class="No-Break">named </span><span class="No-Break"><strong class="source-inline">myapp-1.0-SNAPSHOT.jar</strong></span><span class="No-Break">.</span></p>
			<ul>
				<li><strong class="bold">Gradle</strong>: Run the <span class="No-Break">following command:</span></li>
			</ul>
			<pre class="console">
gradle clean build</pre>			<p class="list-inset">This command will generate a JAR file in the build/libs directory, typically <span class="No-Break">named </span><span class="No-Break"><strong class="source-inline">myapp-1.0-SNAPSHOT.jar</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Note:</p>
			<p class="callout">If you are not using containers, you can stop here. The JAR file located in the target or build/libs directory can now be used to run your <span class="No-Break">application directly.</span></p>
			<ol>
				<li value="4">Containerize your application <span class="No-Break">using Docker</span><ol><li class="upper-roman"><strong class="bold">Create a Dockerfile</strong>: Create a Dockerfile in your project root directory with the <span class="No-Break">following content:</span></li></ol><pre class="source-code">
# Use an official OpenJDK runtime as a parent image (Java 21)
FROM openjdk:21-jre-slim
# Set the working directory
WORKDIR /app
# Copy the executable JAR file to the container
COPY target/myapp-1.0-SNAPSHOT.jar /app/myapp.jar
# Expose the port the app runs on
EXPOSE 8080
# Run the JAR file
ENTRYPOINT ["java", "-jar", "myapp.jar"]</pre><p class="list-inset">Make sure to <a id="_idIndexMarker1262"/>adjust the COPY instruction if your JAR file is <a id="_idIndexMarker1263"/>located in a different directory or has a <span class="No-Break">different name.</span></p><ol><li class="upper-roman" value="2"><strong class="bold">Build the </strong><span class="No-Break"><strong class="bold">Docker Image</strong></span><span class="No-Break">:</span></li></ol><p class="list-inset">Build the Docker image using the Docker build command. Run this command in the directory where your Dockerfile <span class="No-Break">is located:</span></p></li>			</ol>
			<pre class="console">
docker build -t myapp:1.0 .</pre>			<p class="list-inset">This command will create a Docker image named <strong class="source-inline">myapp</strong> with the <span class="No-Break">tag </span><span class="No-Break"><strong class="source-inline">1.0</strong></span><span class="No-Break">.</span></p>
			<ol>
				<li class="upper-roman" value="3"><strong class="bold">Run the Docker Container</strong>: Run the Docker container using the docker <span class="No-Break">run command:</span></li>
			</ol>
			<pre class="console">
docker run -p 8080:8080 myapp:1.0</pre>			<p class="list-inset">This command will start a container from the <strong class="source-inline">myapp:1.0</strong> image and map port <strong class="source-inline">8080</strong> of the container to port 8080 on your <span class="No-Break">host machine.</span></p>
			<p>This <a id="_idIndexMarker1264"/>section <a id="_idIndexMarker1265"/>provides a detailed guide on the essential steps required to build and package your Java applications, ensuring they are ready for deployment in a <span class="No-Break">cloud environment.</span></p>
			<p>After learning how to build and package your Java applications, the next step is to explore the specific procedures for deploying these applications on popular <span class="No-Break">cloud<a id="_idTextAnchor325"/> platforms.</span></p>
			<p><strong class="bold">Step-by-step guides for deploying Java applications on popular </strong><span class="No-Break"><strong class="bold">cloud<a id="_idTextAnchor326"/> platforms:</strong></span></p>
			<ol>
				<li>Setting Up the <span class="No-Break">AWS environment</span><ol><li class="upper-roman"><strong class="bold">Create an AWS Account</strong>: Sign up for an AWS account if you don’t already <span class="No-Break">have one.</span></li><li class="upper-roman"><strong class="bold">Install AWS CLI</strong>: Download and install the AWS <strong class="bold">Command Line Interface</strong> (<strong class="bold">CLI</strong>) to <a id="_idIndexMarker1266"/>manage your <span class="No-Break">AWS services.</span></li><li class="upper-roman"><strong class="bold">Configure AWS CLI</strong>: Run <strong class="source-inline">aws configure</strong> and enter your AWS Access Key, Secret Key, region, and <span class="No-Break">output format.</span></li><li class="upper-roman"><strong class="bold">Create an IAM role </strong><span class="No-Break"><strong class="bold">policy</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">trust-policy.json</strong></span></li></ol><pre class="source-code">
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Service": "ec2.amazonaws.com"
            },
            "Action": "sts:AssumeRole"
    <a id="_idTextAnchor327"/>    }
    ]</pre></li>				<li>Deploy <a id="_idIndexMarker1267"/>your Java <a id="_idIndexMarker1268"/>application to AWS using WAS CLI: Elastic <span class="No-Break">Beanstalk (PaaS)</span><ol><li class="upper-roman">Create the <span class="No-Break">IAM role:</span></li></ol></li>
			</ol>
			<pre class="console">
aws iam create-role --role-name aws-elasticbeanstalk-ec2-role --assume-role-policy-document file://trust-policy.json</pre>			<ol>
				<li class="upper-roman" value="2">Attach the required policies to <span class="No-Break">the role:</span></li>
			</ol>
			<pre class="console">
aws iam attach-role-policy --role-name aws-elasticbeanstalk-ec2-role-java --policy-arn arn:aws:iam::aws:policy/AWSElasticBeanstalkWebTier
aws iam attach-role-policy --role-name aws-elasticbeanstalk-ec2-role-javaa --policy-arn arn:aws:iam::aws:policy/AWSElasticBeanstalkMulticontainerDocker
aws iam attach-role-policy --role-name aws-elasticbeanstalk-ec2-role-java --policy-arn arn:aws:iam::aws:policy/AWSElasticBeanstalkWorkerTier</pre>			<ol>
				<li class="upper-roman" value="3">Create the <span class="No-Break">instance profile:</span></li>
			</ol>
			<pre class="console">
aws iam create-instance-profile --instance-profile-name aws-elasticbeanstalk-ec2-role-java</pre>			<ol>
				<li class="upper-roman" value="4">Add the role to the <span class="No-Break">instance profile:</span></li>
			</ol>
			<pre class="console">
aws iam add-role-to-instance-profile --instance-profile-name aws-elasticbeanstalk-ec2-role-java --role-name aws-elasticbeanstalk-ec2-role-java</pre>			<ol>
				<li value="3">Deploying to <span class="No-Break">Elastic Beanstalk</span><ol><li class="upper-roman">Create an Elastic <span class="No-Break">Beanstalk Application:</span></li></ol></li>
			</ol>
			<pre class="console">
aws elasticbeanstalk create-application --application-name MyJavaApp</pre>			<ol>
				<li class="upper-roman" value="2">Create <a id="_idIndexMarker1269"/>a new Elastic Beanstalk environment using the latest Corretto 21 version on Amazon <span class="No-Break">Linux 2023.</span></li>
			</ol>
			<pre class="console">
aws elasticbeanstalk create-environment --application-name MyJavaApp --environment-name my-env --solution-stack-name "64bit Amazon Linux 2023 v4.2.6 running Corretto 21"</pre>			<ol>
				<li class="upper-roman" value="3">Uploads <strong class="source-inline">my-application.jar</strong> to the deployments folder in the my-bucket S3 bucket. Adjust<a id="_idIndexMarker1270"/> the parameters as needed for your specific <span class="No-Break">use case.</span></li>
			</ol>
			<pre class="console">
aws s3 cp target/my-application.jar s3://my-bucket/my-application.jar</pre>			<ol>
				<li class="upper-roman" value="4">Create a new application version in <span class="No-Break">Elastic Beanstalk</span></li>
			</ol>
			<pre class="console">
aws elasticbeanstalk create-application-version --application-name MyJavaApp --version-label my-app-v1 --description "First version" --source-bundle S3Bucket= <a id="_idTextAnchor328"/>my-bucket,S3Key= my-application.jar</pre>			<ol>
				<li class="upper-roman" value="5">Update the Elastic Beanstalk environment to use the new <span class="No-Break">application version</span></li>
			</ol>
			<pre class="console">
aws elasticbeanstalk update-environment --environment-name my-env --version-label my-app-v1</pre>			<ol>
				<li class="upper-roman" value="6">Check the <span class="No-Break">environment health</span></li>
			</ol>
			<pre class="console">
aws elasticbeanstalk describe-environment-health --environment-name my-env --att<a id="_idTextAnchor329"/><a id="_idTextAnchor330"/>ribute-names All</pre>			<ol>
				<li value="4">Deploy your Java application: <span class="No-Break">ECS (Containers)</span><ol><li class="upper-roman">Push the <a id="_idIndexMarker1271"/>Docker image to Amazon <strong class="bold">Elastic Container Registry</strong> (<strong class="bold">ECR</strong>): First, create an <span class="No-Break">ECR repository:</span></li></ol></li>
			</ol>
			<pre class="console">
aws ecr create-repository --repository-name my-application</pre>			<ol>
				<li class="upper-roman" value="2">Authenticate <a id="_idIndexMarker1272"/>Docker to <span class="No-Break">your ECR:</span></li>
			</ol>
			<pre class="console">
aws ecr get-login-password --region &lt;your-region&gt; | docker login --username AWS --password-stdin &lt;account-id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com</pre>			<ol>
				<li class="upper-roman" value="3">Tag your <a id="_idIndexMarker1273"/><span class="No-Break">Docker image:</span></li>
			</ol>
			<pre class="console">
docker tag my-application:1.0                                                                                         &lt;account-id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/my-application:1.0</pre>			<ol>
				<li class="upper-roman" value="4">Push your Docker image <span class="No-Break">to ECR:</span></li>
			</ol>
			<pre class="console">
docker push &lt;account-id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/ my-application:1.0</pre>			<ol>
				<li value="5">Set <a id="_idIndexMarker1274"/>up <strong class="bold">Elastic Container Service</strong> or <strong class="bold">ECS</strong> using <span class="No-Break">AWS CLI</span><ol><li class="upper-roman"><strong class="bold">Create a task definition</strong>: Create a JSON file named <strong class="source-inline">task-definition.json </strong>with the task <span class="No-Break">definition configuration:</span></li></ol><pre class="source-code">
{
    "family": "my-application-task",
    "networkMode": "awsvpc",
    "requiresCompatibilities": [
        "FARGATE"
    ],
    "cpu": "256",
    "memory": "512",
    "containerDefinitions": [
        {
            "name": "my-application",
            "image": "&lt;account-id&gt;.dkr.ecr.&lt;
            region&gt;.amazonaws.com/my-application:1.0",
            "portMappings": [
            {
                "containerPort": 8080,
                "protocol": "tcp"
            }
            ],
            "essential": true
        }
    ]
}</pre><ol><li class="upper-roman" value="2">Register<a id="_idIndexMarker1275"/> the <span class="No-Break">task definition:</span></li></ol></li>			</ol>
			<pre class="console">
aws ecs register-task-definition --cli-input-json file://task-definition.json</pre>			<ol>
				<li class="upper-roman" value="3">Create <span class="No-Break">a</span><span class="No-Break"><a id="_idIndexMarker1276"/></span><span class="No-Break"> Cluster:</span></li>
			</ol>
			<pre class="console">
aws ecs create-cluster --cluster-name cloudapp-cluster</pre>			<ol>
				<li class="upper-roman" value="4"><strong class="bold">Create a Service</strong>: Create a service using the <span class="No-Break">following command:</span></li>
			</ol>
			<pre class="console">
aws ecs create-service \
    --cluster cloudapp-cluster \
    --service-name cloudapp-service \
    --task-definition cloudapp-task \
    --desired-count 1 \
    --launch-type FARGATE \
    --network-configuration "awsvpcConfiguration={
        subnets=[subnet-XXXXXXXXXXXXXXXXX],securityGroups=[
            sg-XXXXXXXXXXXXXXXXX],assignPublicIp=ENABLED}"</pre>			<p class="callout-heading">Important notes</p>
			<p class="callout">Replace subnet-XXXXXXXXXXXXXXXXX with the actual ID of the subnet where you want to run <span class="No-Break">your tasks.</span></p>
			<p class="callout">Replace sg-XXXXXXXXXXXXXXXXX with the actual ID of the security group you want to associate with <span class="No-Break">your tasks.</span></p>
			<p class="callout">This command uses forward slashes (\) for line continuation, which is appropriate for Unix-like environments (Linux, macOS, Git Bash <span class="No-Break">on Windows).</span></p>
			<p class="callout">For Windows Command Prompt, replace the backslashes (\) with caret symbols (^) for <span class="No-Break">line continuation.</span></p>
			<p class="callout">For PowerShell, use backticks (`) at the end of each line instead of backslashes for <span class="No-Break">line continuation.</span></p>
			<p class="callout">The --desired-count 1 parameter specifies that you want one task running at <span class="No-Break">all times.</span></p>
			<p class="callout">The --launch-type FARGATE parameter specifies that this service will use AWS Fargate, which means you don’t need to manage the underlying <span class="No-Break">EC2 instances.</span></p>
			<ol>
				<li value="6">Deploy<a id="_idIndexMarker1277"/> your<a id="_idIndexMarker1278"/> Java serverless <span class="No-Break">Lambda function</span><ol><li class="upper-roman">Create an AWS Lambda <span class="No-Break">function role:</span></li></ol></li>
			</ol>
			<pre class="console">
aws iam create-role --role-name lambda-role --assume-role-policy-document file://trust-policy.json</pre>			<ol>
				<li class="upper-roman" value="2">Attach the <strong class="source-inline">AWSLambdaBasicExecutionRole</strong> policy to <span class="No-Break">the role:</span></li>
			</ol>
			<pre class="console">
aws iam attach-role-policy --role-name lambda-role --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole</pre>			<ol>
				<li class="upper-roman" value="3">Create the <span class="No-Break">Lambda function:</span></li>
			</ol>
			<pre class="console">
aws lambda create-function \
    --function-name java-lambda-example \
    --runtime java17 \
    --role arn:aws:iam::&lt;account-id&gt;:role/lambda-role \
    --handler com.example.LambdaHandler::handleRequest \
    --zip-file fileb://target/lambda-example-1.0-SNAPSHOT.jar</pre>			<ol>
				<li class="upper-roman" value="4"><strong class="bold">Invoke the Lambda function</strong>: When using the aws lambda invoke command <a id="_idIndexMarker1279"/>to test your AWS Lambda function, it’s <a id="_idIndexMarker1280"/>important to update the --payload parameter to match the expected input format of your specific <span class="No-Break">Lambda function.</span></li>
			</ol>
			<pre class="console">
aws lambda invoke --function-name java-lambda-example --payload '{"name": "World"}' response.json</pre>			<ol>
				<li class="upper-roman" value="5">Check <span class="No-Break">the response:</span></li>
			</ol>
			<pre class="console">
cat response.json</pre>			<p>Now that you have an understanding of how to set up a cloud-native Java environment and deploy your applications on various cloud platforms, you may want to dive deeper into specific cloud services. The following links provide additional resources and documentation to help you further your knowledge and skills in deploying and managing Java <a id="_idTextAnchor331"/>applications in <span class="No-Break">the cloud.</span></p>
			<h2 id="_idParaDest-282"><a id="_idTextAnchor332"/>Useful links for further information on AWS</h2>
			<ul>
				<li><strong class="bold">Amazon EC2</strong>: Getting <a id="_idIndexMarker1281"/>Started with Amazon <span class="No-Break">EC2 (</span><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html"><span class="No-Break">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html</span></a><span class="No-Break">)</span></li>
				<li><strong class="bold">AWS Elastic Beanstalk</strong>: Getting Started with AWS Elastic <span class="No-Break">Beanstalk (</span><a href="https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/GettingStarted.html"><span class="No-Break">https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/GettingStarted.html</span></a><span class="No-Break">)</span></li>
				<li><strong class="bold">Amazon ECS</strong>: Getting Started with Amazon <span class="No-Break">ECS (</span><a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_GetStarted.html"><span class="No-Break">https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_GetStarted.html</span></a><span class="No-Break">)</span></li>
				<li><strong class="bold">AWS Lambda</strong>: Getting Started with AWS <span class="No-Break">Lambda (</span><a href="https://docs.aws.amazon.com/lambda/latest/dg/getting-started.html"><span class="No-Break">https://docs.aws.amazon.com/lambda/latest/dg/getting-started.html</span></a><span class="No-Break">)</span></li>
				<li><strong class="bold">Managing environment variables</strong>: Best practices for managing environment variables in AWS <span class="No-Break">Lambda (</span><a href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars.html"><span class="No-Break">https://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars.html</span></a><span class="No-Break">)</span></li>
			</ul>
			<h1 id="_idParaDest-283"><a id="_idTextAnchor333"/>Microsoft Azure</h1>
			<p>In this section, you <a id="_idIndexMarker1282"/>will learn the steps required to deploy Java applications on Microsoft Azure. This <a id="_idIndexMarker1283"/>includes setting up the Azure environment, deploying applications on virtual machines and containers, and utilizing <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>) for <a id="_idIndexMarker1284"/>containerized applications. Additionally, you will explore how to deploy Java functions on Azure Functions, enabling you to leverage serverless computing <a id="_idIndexMarker1285"/>for your <span class="No-Break">Java applications.</span></p>
			<ol>
				<li>Set up the <span class="No-Break">Azure environment:</span><ol><li class="upper-roman"><strong class="bold">Download and install Azure CLI</strong>: Follow the official installation instructions for your operating system from the Azure CLI installation <span class="No-Break">guide (</span><a href="https://learn.microsoft.com/en-us/cli/azure/install-azure-cli"><span class="No-Break">https://learn.microsoft.com/en-us/cli/azure/install-azure-cli</span></a><span class="No-Break">).</span></li><li class="upper-roman"><strong class="bold">Configure Azure CLI</strong>: Open your terminal or command prompt and run the following command to log in to your <span class="No-Break">Azure account:</span></li></ol></li>
			</ol>
			<pre class="console">
az login</pre>			<ol>
				<li value="2">Follow the instructions to log in to your <span class="No-Break">Azure account.</span></li>
			</ol>
			<p>Next, you will learn how to deploy a regular Java application on Azure <span class="No-Break">Virtual Machines.</span></p>
			<p><strong class="bold">Deploying a Regular Java Application on Azure </strong><span class="No-Break"><strong class="bold">Virtual Machines</strong></span></p>
			<ol>
				<li>Create a <a id="_idIndexMarker1286"/><span class="No-Break">Resource Group:</span></li>
			</ol>
			<pre class="console">
az group create --name myResourceGroup --location eastus</pre>			<ol>
				<li value="2">Create a <span class="No-Break">Virtual Machine:</span></li>
			</ol>
			<pre class="console">
az vm create --resource-group myResourceGroup --name myVM --image UbuntuLTS --admin-username azureuser --generate-ssh-keys</pre>			<ol>
				<li value="3">Open <span class="No-Break">port 8080:</span></li>
			</ol>
			<pre class="console">
az vm open-port --port 8080 --resource-group myResourceGroup --name myVM</pre>			<ol>
				<li value="4">SSH into <span class="No-Break">the VM:</span></li>
			</ol>
			<pre class="console">
ssh azureuser@&lt;vm-ip-address&gt;</pre>			<ol>
				<li value="5">Install Java on <span class="No-Break">the VM:</span></li>
			</ol>
			<pre class="console">
sudo apt update
sudo apt install openjdk-21-jre -y</pre>			<ol>
				<li value="6">Transfer and Run the <span class="No-Break">JAR File:</span></li>
			</ol>
			<pre class="console">
scp target/myapp-1.0-SNAPSHOT.jar azureuser@&lt;vm-ip-address&gt;:/home/azureuser
ssh azureuser@&lt;vm-ip-address&gt;
java -jar myapp-1.0-SNAPSHOT.jar</pre>			<p>Once you <a id="_idIndexMarker1287"/>have successfully deployed your Java application on an Azure Virtual Machine, you can manage and scale your application as needed using the Azure portal and CLI tools. This approach provides a solid foundation for running traditional Java applications in a <span class="No-Break">cloud environment.</span></p>
			<p>Next, you will learn how to deploy a Java application in containers using AKS, which offers a more flexible and<a id="_idIndexMarker1288"/> scalable solution for <span class="No-Break">containerized applications.</span></p>
			<p><strong class="bold">Deploying a Java Application in Containers </strong><span class="No-Break"><strong class="bold">on AKS</strong></span></p>
			<ol>
				<li>Create <a id="_idIndexMarker1289"/>an <strong class="bold">Azure Container </strong><span class="No-Break"><strong class="bold">Registry</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">ACR</strong></span><span class="No-Break">):</span></li>
			</ol>
			<pre class="console">
az acr create --resource-group myResourceGroup --name myACR --sku Basic</pre>			<ol>
				<li value="2">Login <span class="No-Break">to ACR:</span></li>
			</ol>
			<pre class="console">
az acr login --name myACR</pre>			<ol>
				<li value="3">Tag and push Docker image <span class="No-Break">to ACR:</span></li>
			</ol>
			<pre class="console">
docker tag myapp:1.0 myacr.azurecr.io/myapp:1.0
docker push myacr.azurecr.io/myapp:1.0</pre>			<ol>
				<li value="4">Create <span class="No-Break">AKS Cluster:</span></li>
			</ol>
			<pre class="console">
az aks create --resource-group myResourceGroup --name myAKSCluster --node-count 1 --enable-addons monitoring --generate-ssh-keys</pre>			<ol>
				<li value="5">Get <span class="No-Break">AKS Credentials:</span></li>
			</ol>
			<pre class="console">
az aks get-credentials --resource-group myResourceGroup --name myAKSCluster</pre>			<ol>
				<li value="6">Deploy <a id="_idIndexMarker1290"/>the application <span class="No-Break">to AKS:</span><ol><li class="upper-roman">Create a Deployment YAML <span class="No-Break">file (</span><span class="No-Break"><strong class="source-inline">deployment.yaml</strong></span><span class="No-Break">):</span></li></ol><pre class="source-code">
apiVersion: apps/v1
kind: Deployment
metadata:
    name: myapp-deployment
spec:
    replicas: 1
    selector:
        matchLabels:
            app: myapp
    template:
        metadata:
            labels:
                app: myapp
        spec:
            containers:
                - name: myapp
            image: myacr.azurecr.io/myapp:1.0
            ports:
                - containerPort: 8080</pre><ol><li class="upper-roman" value="2">Apply <span class="No-Break">the deployment:</span></li></ol></li>			</ol>
			<pre class="console">
kubectl apply -f deployment.yaml</pre>			<ol>
				<li class="upper-roman" value="3">Expose <span class="No-Break">the deployment:</span></li>
			</ol>
			<pre class="console">
kubectl expose deployment myapp-deployment--type=LoadBalancer --port=8080</pre>			<p>This completes <a id="_idIndexMarker1291"/>the process of deploying a containerized Java application to AKS. However, for scenarios where you need more granular control over your application’s execution or want to build serverless microservices, Azure Functions provides an excellent alternative. Next, you will learn how to deploy Java functions on Azure Functions, enabling you to take advantage of serverless computing for event-driven applications <span class="No-Break">and microservices.</span></p>
			<p><strong class="bold">Deploying Java Functions on </strong><span class="No-Break"><strong class="bold">Azure Functions</strong></span></p>
			<ol>
				<li>Install <a id="_idIndexMarker1292"/>Azure functions <span class="No-Break">core tools:</span><ul><li><strong class="bold">Windows</strong>: Use MSI <span class="No-Break">installer (</span><a href="https://learn.microsoft.com/en-us/azure/azure-functions/functions-run-local?tabs=windows%2Cisolated-process%2Cnode-v4%2Cpython-v2%2Chttp-trigger%2Ccontainer-apps&amp;pivots=programming-language-csharp#v2"><span class="No-Break">https://learn.microsoft.com/en-us/azure/azure-functions/functions-run-local?tabs=windows%2Cisolated-process%2Cnode-v4%2Cpython-v2%2Chttp-trigger%2Ccontainer-apps&amp;pivots=programming-language-csharp#v2</span></a><span class="No-Break">)</span></li><li><span class="No-Break"><strong class="bold">macOS</strong></span><span class="No-Break">:</span></li></ul></li>
			</ol>
			<pre class="console">
brew tap azure/functions
brew install azure-functions-core-tools@4</pre>			<ol>
				<li value="2">Create a new <span class="No-Break">function app:</span></li>
			</ol>
			<pre class="console">
func init MyFunctionApp --java
cd MyFunctionApp
func new</pre>			<ol>
				<li value="3">Build <span class="No-Break">the function:</span></li>
			</ol>
			<pre class="console">
mvn clean package</pre>			<ol>
				<li value="4">Deploy <a id="_idIndexMarker1293"/><span class="No-Break">to Azure:</span></li>
			</ol>
			<pre class="console">
func azure functionapp publish &lt;FunctionAppName&gt;</pre>			<p class="callout-heading">Notes</p>
			<p class="callout">Replace placeholders like &lt;vm-ip-address&gt;, &lt;your-region&gt;, &lt;FunctionAppName&gt;, etc., with your <span class="No-Break">actual values.</span></p>
			<p>For detailed information on configuring environment variables and managing configurations specifically for Azure environments, you can refer to the official <span class="No-Break">Azure documentation:</span></p>
			<ul>
				<li><strong class="bold">Azure App Service configuration</strong>: Configure apps in Azure App <span class="No-Break">Service (</span><a href="https://learn.microsoft.com/en-us/azure/app-service/configure-common?tabs=portal"><span class="No-Break">https://learn.microsoft.com/en-us/azure/app-service/configure-common?tabs=portal</span></a><span class="No-Break">)</span></li>
				<li><strong class="bold">AKS configuration</strong>: Best practices for cluster and node pool configuration in <span class="No-Break">AKS (</span><a href="https://learn.microsoft.com/en-us/azure/aks/operator-best-practices-scheduler"><span class="No-Break">https://learn.microsoft.com/en-us/azure/aks/operator-best-practices-scheduler</span></a><span class="No-Break">)</span></li>
				<li><strong class="bold">Azure functions configuration</strong>: Configure function app settings in Azure <span class="No-Break">functions (</span><a href="https://learn.microsoft.com/en-us/azure/azure-functions/functions-how-to-use-azure-function-app-settings?tabs=azure-portal%2Cto-premium"><span class="No-Break">https://learn.microsoft.com/en-us/azure/azure-functions/functions-how-to-use-azure-function-app-settings?tabs=azure-portal%2Cto-premium</span></a><span class="No-Break">)</span></li>
			</ul>
			<p>Now that you’ve learned how to deploy Java applications on various Azure services, including virtual machines, AKS, and Azure Functions, let’s explore another major cloud provider. The following section will guide you through similar deployment processes on GCP, allowing you to broaden your cloud deployment skills across <span class="No-Break">different environments.</span></p>
			<h1 id="_idParaDest-284"><a id="_idTextAnchor334"/>Google Cloud Platform</h1>
			<p>In this section, you’ll learn how to deploy Java applications on <strong class="bold">Google Cloud Platform</strong> or <strong class="bold">GCP</strong>, one <a id="_idIndexMarker1294"/>of the leading cloud service providers. GCP offers a wide range of services that cater to various deployment needs, from virtual machines to containerized environments and serverless functions. We’ll cover the setup process for GCP and guide you through deploying Java applications using different <a id="_idIndexMarker1295"/>GCP services, including <strong class="bold">Google Compute Engine</strong> (<strong class="bold">GCE</strong>), <strong class="bold">Google Kubernetes Engine</strong> (<strong class="bold">GKE</strong>), and <a id="_idIndexMarker1296"/>Google Cloud Functions. This knowledge will empower you to leverage GCP’s robust infrastructure and services for your <span class="No-Break">Java applications.</span></p>
			<h2 id="_idParaDest-285"><a id="_idTextAnchor335"/>Setting up the Google Cloud Environment</h2>
			<ol>
				<li>Create<a id="_idIndexMarker1297"/> a Google Cloud account if you don’t <span class="No-Break">have one.</span></li>
				<li>Install the Google Cloud SDK. Follow the instructions for your operating system from the official Google Cloud SDK <span class="No-Break">documentation (</span><a href="https://cloud.google.com/sdk/docs/install"><span class="No-Break">https://cloud.google.com/sdk/docs/install</span></a><span class="No-Break">)</span></li>
				<li>Initialize the Google <span class="No-Break">Cloud SDK:</span></li>
			</ol>
			<pre class="console">
gcloud init</pre>			<ol>
				<li value="4">Follow the prompts to log in and select <span class="No-Break">your project.</span></li>
				<li>Set your <span class="No-Break">project ID:</span></li>
			</ol>
			<pre class="console">
gcloud config set project YOUR_PROJECT_ID</pre>			<p>With your Google Cloud environment successfully set up, you are now prepared to deploy and manage Java applications using GCP’s robust infrastructure. In the next sections, you will explore specific methods for deploying Java applications on GCE, GKE, and Google <span class="No-Break">Cloud Functions.</span></p>
			<h2 id="_idParaDest-286"><a id="_idTextAnchor336"/>Deploy your Java application to Google Cloud</h2>
			<p><strong class="bold">GCE for regular </strong><span class="No-Break"><strong class="bold">Java Applications</strong></span><span class="No-Break">:</span></p>
			<ol>
				<li>Create a <a id="_idIndexMarker1298"/><span class="No-Break">VM instance:</span></li>
			</ol>
			<pre class="console">
gcloud compute instances create my-java-vm --zone=us-central1-a --machine-type=e2-medium --image-family=ubuntu-2004-lts --image-project=ubuntu-os-cloud</pre>			<ol>
				<li value="2">SSH into <span class="No-Break">the VM:</span></li>
			</ol>
			<pre class="console">
gcloud compute ssh my-java-vm --zone=us-central1-a</pre>			<ol>
				<li value="3">Install Java on <span class="No-Break">the VM:</span></li>
			</ol>
			<pre class="console">
sudo apt update
sudo apt install openjdk-17-jdk -y</pre>			<ol>
				<li value="4">Transfer your JAR file to <span class="No-Break">the VM:</span></li>
			</ol>
			<pre class="console">
gcloud compute scp your-app.jar my-java-vm:~ --zone=us-central1-a</pre>			<ol>
				<li value="5">Run your <span class="No-Break">Java application:</span></li>
			</ol>
			<pre class="console">
java -jar your-app.jar</pre>			<p>By following<a id="_idIndexMarker1299"/> these steps, you can efficiently deploy and manage your Java applications on Google Cloud, leveraging the various services and tools provided by GCP. With your Java application successfully deployed to Google Cloud, you are now ready to explore containerized deployments using GKE, which offers powerful orchestration capabilities for managing containers <span class="No-Break">at scale.</span></p>
			<h2 id="_idParaDest-287"><a id="_idTextAnchor337"/>GKE for containerized applications</h2>
			<p>In this section, you<a id="_idIndexMarker1300"/> will learn how to deploy Java applications in containers using GKE. GKE provides a managed environment for deploying, managing, and scaling containerized applications using Kubernetes. You will be guided through setting up a GKE cluster, deploying your Docker images, and managing your containerized <span class="No-Break">applications efficiently.</span></p>
			<ol>
				<li>Create a <span class="No-Break">GKE cluster:</span></li>
			</ol>
			<pre class="console">
gcloud container clusters create my-cluster --num-nodes=3 --zone=us-central1-a</pre>			<ol>
				<li value="2">Get credentials for <span class="No-Break">the cluster:</span></li>
			</ol>
			<pre class="console">
gcloud container clusters get-credentials my-cluster --zone=us-central1-a</pre>			<ol>
				<li value="3">Push your Docker<a id="_idIndexMarker1301"/> image to <strong class="bold">Google Container </strong><span class="No-Break"><strong class="bold">Registry</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">GCR</strong></span><span class="No-Break">):</span></li>
			</ol>
			<pre class="console">
docker tag your-app:latest gcr.io/YOUR_PROJECT_ID/your-app:latest
docker push gcr.io/YOUR_PROJECT_ID/your-app:latest</pre>			<ol>
				<li value="4">Create a Kubernetes deployment: Create a file <span class="No-Break">named deployment.yaml:</span><pre class="source-code">
apiVersion: apps/v1
kind: Deployment
metadata:
    name: your-app
spec:
    replicas: 3
    selector:
        matchLabels:
            app: your-app
    template:
        metadata:
            labels:
                app: your-app
    spec:
        containers:
            - name: your-app
        image: gcr.io/YOUR_PROJECT_ID/your-app:latest
        ports:
        - containerPort: 8080</pre></li>				<li>Apply <span class="No-Break">the </span><span class="No-Break"><a id="_idIndexMarker1302"/></span><span class="No-Break">deployment:</span></li>
			</ol>
			<pre class="console">
kubectl apply -f deployment.yaml</pre>			<ol>
				<li value="6">Expose <span class="No-Break">the deployment:</span></li>
			</ol>
			<pre class="console">
kubectl expose deployment your-app --type=LoadBalancer --port 80 --target-port 8080</pre>			<p>By leveraging GKE, you<a id="_idIndexMarker1303"/> can take full advantage of Kubernetes’ robust features to ensure your containerized Java applications are highly available, scalable, and easy <span class="No-Break">to maintain.</span></p>
			<h2 id="_idParaDest-288"><a id="_idTextAnchor338"/>Google Cloud Functions for serverless Java functions</h2>
			<p>In this<a id="_idIndexMarker1304"/> section, you will learn how to deploy Java functions using Google Cloud Functions, enabling you to run event-driven code in a fully managed serverless environment. You will be guided through setting up your development environment, creating and deploying your Java functions, and managing them effectively using Google Cloud’s powerful <span class="No-Break">serverless tools.</span></p>
			<ol>
				<li>Create a new directory for <span class="No-Break">your function:</span></li>
			</ol>
			<pre class="console">
mkdir my-java-function
cd my-java-function</pre>			<ol>
				<li value="2">Initialize a new <span class="No-Break">Maven project:</span></li>
			</ol>
			<pre class="console">
mvn archetype:generate -DgroupId=com.example -DartifactId=my-java-function -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false</pre>			<ol>
				<li value="3">Add the necessary dependencies to <span class="No-Break">your </span><span class="No-Break"><strong class="source-inline">pom.xml</strong></span><span class="No-Break">:</span><pre class="source-code">
&lt;dependency&gt;
  &lt;groupId&gt;com.google.cloud.functions&lt;/groupId&gt;
  &lt;artifactId&gt;functions-framework-api&lt;/artifactId&gt;
  &lt;version&gt;1.0.4&lt;/version&gt;
  &lt;scope&gt;provided&lt;/scope&gt;
&lt;/dependency&gt;</pre></li>				<li>Create your <span class="No-Break">function class:</span><pre class="source-code">
package com.example;
import com.google.cloud.functions.HttpFunction;
import com.google.cloud.functions.HttpRequest;
import com.google.cloud.functions.HttpResponse;
import java.io.BufferedWriter;
public class Function implements HttpFunction {
    @Override
    public void service(HttpRequest request,
        HttpResponse response) throws Exception {
        BufferedWriter writer = response.getWriter();
        writer.write("Hello, World!");
        }
    }</pre></li>				<li>Deploy <span class="No-Break">the function:</span></li>
			</ol>
			<pre class="console">
gcloud functions deploy my-java-function --entry-point com.example.Function --runtime java17 --trigger-http --allow-unauthenticated</pre>			<p>These<a id="_idIndexMarker1305"/> instructions provide a basic setup for deploying Java applications to Google Cloud using different services. Remember to adjust the commands and configurations based on your specific application requirements and Google Cloud <span class="No-Break">project settings.</span></p>
			<h1 id="_idParaDest-289"><a id="_idTextAnchor339"/>Useful links for further information</h1>
			<ul>
				<li><strong class="bold">Google Compute Engine</strong>: Get <a id="_idIndexMarker1306"/>started creating and managing virtual machines in GCP with the Compute Engine quickstart <span class="No-Break">guide: </span><a href="https://cloud.google.com/compute/docs/quickstart"><span class="No-Break">https://cloud.google.com/compute/docs/quickstart</span></a></li>
				<li><strong class="bold">Google Kubernetes Engine</strong>: Dive into container orchestration with GKE and deploy your first Kubernetes cluster using the GKE <span class="No-Break">quickstart: </span><a href="https://cloud.google.com/kubernetes-engine/docs/quickstart"><span class="No-Break">https://cloud.google.com/kubernetes-engine/docs/quickstart</span></a></li>
				<li><strong class="bold">Google Cloud Functions</strong>: Develop and deploy serverless functions that respond to events with the Cloud Functions deployment <span class="No-Break">guide: </span><a href="https://cloud.google.com/functions/docs/deploying"><span class="No-Break">https://cloud.google.com/functions/docs/deploying</span></a></li>
				<li><strong class="bold">Managing environment </strong><span class="No-Break"><strong class="bold">variables</strong></span><span class="No-Break">: </span><a href="https://cloud.google.com/run/docs/configuring/services/environment-variables"><span class="No-Break">https://cloud.google.com/run/docs/configuring/services/environment-variables</span></a></li>
			</ul>
		</div>
	

		<div id="_idContainer046">
			<h1 class="chapter-number" id="_idParaDest-290"><a id="_idTextAnchor340"/>Appendix B: Resources and Further Reading</h1>
			<h1 id="_idParaDest-291"><a id="_idTextAnchor341"/></h1>
			<h1 id="_idParaDest-292"><a id="_idTextAnchor342"/>Recommended books, articles, and online courses</h1>
			<h2 id="_idParaDest-293"><a id="_idTextAnchor343"/>Chapters 1–3</h2>
			<h3>Books</h3>
			<ul>
				<li><em class="italic">Cloud Native Java: Designing Resilient Systems with Spring Boot, Spring Cloud, and Cloud Foundry</em> by Josh Long and Kenny Bastani. This comprehensive guide offers practical insights into building scalable, resilient Java applications for cloud environments, covering Spring Boot, Spring Cloud, and Cloud Foundry technologies. <span class="No-Break">Link: </span><a href="https://www.amazon.com/Cloud-Native-Java-Designing-Resilient/dp/1449374646"><span class="No-Break">https://www.amazon.com/Cloud-Native-Java-Designing-Resilient/dp/1449374646</span></a></li>
				<li><em class="italic">Java Concurrency in Practice</em> by Brian Goetz et al. A seminal work on Java concurrency, this book provides in-depth coverage of concurrent programming techniques, best practices, and pitfalls to avoid when developing <span class="No-Break">multi-threaded applications.</span></li>
				<li><em class="italic">Parallel and Concurrent Programming in Haskell</em> by Simon Marlow. While focused on Haskell, this book offers valuable insights into parallel programming concepts that can be applied to Java, providing a broader perspective on concurrent and parallel application design. <span class="No-Break">Link: </span><a href="https://www.oreilly.com/library/view/parallel-and-concurrent/9781449335939/"><span class="No-Break">https://www.oreilly.com/library/view/parallel-and-concurrent/9781449335939/</span></a></li>
				<li><em class="italic">Designing Distributed Systems: Patterns and Paradigms for Scalable, Reliable Services</em> by Brendan Burns (Microsoft Azure). This explores essential patterns for building scalable and reliable distributed systems, offering insights from Microsoft Azure’s experience in cloud computing. <span class="No-Break">Link: </span><a href="https://www.amazon.com/Designing-Distributed-Systems-Patterns-Paradigms/dp/1491983647"><span class="No-Break">https://www.amazon.com/Designing-Distributed-Systems-Patterns-Paradigms/dp/1491983647</span></a></li>
			</ul>
			<h3>Articles</h3>
			<ul>
				<li><em class="italic">Microservices Patterns</em> by Chris Richardson (microservices.io). A comprehensive guide to microservices architecture patterns, this article helps developers understand and implement effective microservices-based systems. <span class="No-Break">Link: </span><a href="https://microservices.io/patterns/index.html"><span class="No-Break">https://microservices.io/patterns/index.html</span></a></li>
				<li><em class="italic">A Java Fork/Join Framework</em> by Doug Lea. An in-depth look at the Fork/Join framework by its creator, providing valuable insights into its design and implementation for parallel processing in Java. <span class="No-Break">Link: </span><a href="http://gee.cs.oswego.edu/dl/papers/fj.pdf"><span class="No-Break">http://gee.cs.oswego.edu/dl/papers/fj.pdf</span></a></li>
				<li><em class="italic">Amdahl’s Law in the Multicore Era</em> by Mark D. Hill and Michael R. Marty. This article offers a modern perspective on Amdahl’s Law and its implications for parallel computing, helping developers understand the limits and potential of parallel processing in contemporary systems. <span class="No-Break">Link: </span><a href="https://research.cs.wisc.edu/multifacet/papers/ieeecomputer08_amdahl_multicore.pdf"><span class="No-Break">https://research.cs.wisc.edu/multifacet/papers/ieeecomputer08_amdahl_multicore.pdf</span></a></li>
			</ul>
			<h3>Online courses</h3>
			<ul>
				<li><em class="italic">Java Multithreading, Concurrency &amp; Performance Optimization</em> by Udemy. This comprehensive course covers Java multithreading, concurrency, and performance optimization techniques, providing practical examples and hands-on exercises to master advanced Java programming <span class="No-Break">concepts. Link:</span><a href="https://www.udemy.com/course/java-multithreading-concurrency-performance-optimization/"><span class="No-Break">https://www.udemy.com/course/java-multithreading-concurrency-performance-optimization/</span></a></li>
				<li><em class="italic">Concurrency in Java</em> by Coursera (offered by Rice University). Focusing on the foundational principles of concurrency in Java, this course offers practical exercises to solidify understanding of concurrent programming concepts and techniques. <span class="No-Break">Link: </span><a href="https://www.coursera.org/learn/concurrent-programming-in-java"><span class="No-Break">https://www.coursera.org/learn/concurrent-programming-in-java</span></a></li>
				<li><em class="italic">Reactive Programming in Modern Java using Project Reactor</em> by Udemy. A comprehensive course on reactive programming in Java using Project Reactor, teaching developers how to build reactive applications for better scalability and resilience in modern software architectures. <span class="No-Break">Link: </span><a href="https://www.udemy.com/course/reactive-programming-in-modern-java-using-project-reactor/"><span class="No-Break">https://www.udemy.com/course/reactive-programming-in-modern-java-using-project-reactor/</span></a></li>
				<li><em class="italic">Parallel, Concurrent, and Distributed Programming in Java Specialization</em> on Coursera by Rice University. This specialization offers a comprehensive coverage of advanced concurrency topics in Java, including parallel, concurrent, and distributed programming techniques for developing high-performance applications. <span class="No-Break">Link: </span><a href="https://www.coursera.org/specializations/pcdp"><span class="No-Break">https://www.coursera.org/specializations/pcdp</span></a></li>
			</ul>
			<h3>Key blogs and websites</h3>
			<ul>
				<li><em class="italic">Baeldung</em> offers comprehensive tutorials and articles on Java, Spring, and related technologies, including in-depth content on concurrency and parallelism. Their concurrency section is particularly valuable for learning advanced Java threading concepts. <span class="No-Break">Link: </span><a href="https://www.baeldung.com/java-concurrency"><span class="No-Break">https://www.baeldung.com/java-concurrency</span></a></li>
				<li><em class="italic">DZone Java Zone</em> is a community-driven platform, offering a wealth of articles, tutorials, and guides on Java and cloud-native development. The Java Zone is an excellent resource for staying up-to-date with the latest trends and best practices in Java development. <span class="No-Break">Link: </span><a href="https://dzone.com/java-jdk-development-tutorials-tools-news"><span class="No-Break">https://dzone.com/java-jdk-development-tutorials-tools-news</span></a></li>
				<li><em class="italic">InfoQ Java</em> provides news, articles, and interviews on software development, with a strong focus on Java, concurrency, and cloud-native technologies. InfoQ is particularly useful for gaining insights into industry trends and emerging technologies in the Java ecosystem. <span class="No-Break">Link: </span><a href="https://www.infoq.com/java/"><span class="No-Break">https://www.infoq.com/java/</span></a></li>
			</ul>
			<h2 id="_idParaDest-294"><a id="_idTextAnchor344"/>Chapters 4–6</h2>
			<h3>Books</h3>
			<ul>
				<li><em class="italic">Patterns for Distributed Systems</em> by Unmesh <span class="No-Break">Joshi (InfoQ)</span></li>
				<li>This book provides an overview of common patterns used in distributed systems, offering practical advice for designing robust and scalable architectures. <span class="No-Break">Link: </span><a href="https://www.amazon.com/Patterns-Distributed-Systems-Addison-Wesley-Signature/dp/0138221987"><span class="No-Break">https://www.amazon.com/Patterns-Distributed-Systems-Addison-Wesley-Signature/dp/0138221987</span></a></li>
			</ul>
			<h3>Articles and blogs</h3>
			<ul>
				<li>Martin Fowler’s blog on microservices and distributed systems. This blog is a treasure trove of information on microservices and distributed systems, offering in-depth articles and thought leadership on modern software architecture. <span class="No-Break">Link: </span><a href="https://martinfowler.com/articles/microservices.html"><span class="No-Break">https://martinfowler.com/articles/microservices.html</span></a></li>
				<li><em class="italic">LMAX Disruptor documentation and performance guide</em> is a high-performance inter-thread messaging library for Java. This resource provides documentation and performance guides for implementing low-latency, high-throughput systems. <span class="No-Break">Link: </span><a href="https://lmax-exchange.github.io/disruptor/"><span class="No-Break">https://lmax-exchange.github.io/disruptor/</span></a></li>
			</ul>
			<h3>Online courses</h3>
			<ul>
				<li><em class="italic">Microservices Architecture</em> by the University of Alberta. This course provides a comprehensive introduction to microservices architecture, covering design principles, implementation strategies, and best practices for building scalable and maintainable systems. <span class="No-Break">Link: </span><a href="https://www.coursera.org/specializations/software-design-architecture"><span class="No-Break">https://www.coursera.org/specializations/software-design-architecture</span></a></li>
				<li><em class="italic">Building Scalable Java Microservices with Spring Boot and Spring Cloud</em> on Coursera by Google Cloud Offered by Google Cloud, this course teaches how to build scalable Java microservices using Spring Boot and Spring Cloud, with a focus on cloud-native development practices. <span class="No-Break">Link: </span><a href="https://www.coursera.org/learn/google-cloud-java-spring"><span class="No-Break">https://www.coursera.org/learn/google-cloud-java-spring</span></a></li>
			</ul>
			<h2 id="_idParaDest-295"><a id="_idTextAnchor345"/>Chapters 7–9</h2>
			<h3>Books</h3>
			<ul>
				<li><em class="italic">Serverless Architectures on AWS</em> by Peter Sbarski This book provides comprehensive coverage of serverless concepts and practical implementations on AWS, offering valuable insights for developers looking to build scalable and cost-effective applications. <span class="No-Break">Link: </span><a href="https://www.amazon.com/Serverless-Architectures-AWS-Peter-Sbarski/dp/1617295426"><span class="No-Break">https://www.amazon.com/Serverless-Architectures-AWS-Peter-Sbarski/dp/1617295426</span></a></li>
			</ul>
			<h3>Articles</h3>
			<ul>
				<li><em class="italic">Serverless Computing: One Step Forward, Two Steps Back</em> by Joseph M. Hellerstein et al. This article provides a critical analysis of serverless computing, discussing its advantages and limitations, and offering a balanced perspective on its place in modern architecture. <span class="No-Break">Link: </span><a href="https://arxiv.org/abs/1812.03651"><span class="No-Break">https://arxiv.org/abs/1812.03651</span></a></li>
				<li><em class="italic">Serverless Architecture Patterns and Best Practices</em> <span class="No-Break">by freeCodeCamp</span></li>
				<li>This article provides an overview of key serverless patterns like messaging, function focus, and event-driven architecture, emphasizing the benefits of decoupling and scalability. <span class="No-Break">Link: </span><a href="https://www.freecodecamp.org/news/serverless-architecture-patterns-and-best-practices/"><span class="No-Break">https://www.freecodecamp.org/news/serverless-architecture-patterns-and-best-practices/</span></a></li>
			</ul>
			<h3>Online courses</h3>
			<ul>
				<li><em class="italic">Developing Serverless Solutions on AWS</em> by the AWS training team. This includes comprehensive coverage of AWS Lambda, best practices, frameworks, and hands-on labs. <span class="No-Break">Link: </span><a href="https://aws.amazon.com/training/classroom/developing-serverless-solutions-on-aws/"><span class="No-Break">https://aws.amazon.com/training/classroom/developing-serverless-solutions-on-aws/</span></a></li>
			</ul>
			<h3>Technical papers</h3>
			<ul>
				<li><em class="italic">Serverless Computing: Current Trends and Open Problems </em>by Ioana Baldini et al. This academic paper provides a thorough examination of serverless computing, discussing current trends, challenges, and future directions in this rapidly evolving field. <span class="No-Break">Link</span><span class="No-Break"><span class="P---URL">: </span></span><a href="https://arxiv.org/abs/1706.03178"><span class="No-Break">https://arxiv.org/abs/1706.03178</span></a></li>
			</ul>
			<h3>Online resources</h3>
			<ul>
				<li>AWS Lambda Developer <span class="No-Break">Guide: </span><a href="https://docs.aws.amazon.com/lambda/latest/dg/welcome.html"><span class="No-Break">https://docs.aws.amazon.com/lambda/latest/dg/welcome.html</span></a></li>
				<li>Azure Functions Java developer <span class="No-Break">guide: </span><a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-reference-java"><span class="No-Break">https://docs.microsoft.com/en-us/azure/azure-functions/functions-reference-java</span></a></li>
				<li>Google Cloud Functions Java <span class="No-Break">Tutorials: </span><a href="https://codelabs.developers.google.com/codelabs/cloud-starting-cloudfunctions#"><span class="No-Break">https://codelabs.developers.google.com/codelabs/cloud-starting-cloudfunctions#</span></a></li>
			</ul>
			<h1 id="_idParaDest-296"><a id="_idTextAnchor346"/>Chapters 10–12</h1>
			<h3>Books</h3>
			<ul>
				<li><em class="italic">Quantum Computing for Developers</em> by Johan Vos. This groundbreaking book offers a developer-friendly introduction to quantum computing, bridging the gap between theoretical concepts and practical implementation. It provides clear explanations of quantum principles and includes hands-on examples using Java-based frameworks, preparing software developers for the emerging quantum computing landscape. The author, Johan Vos, expertly guides readers through quantum algorithms, quantum gates, and quantum circuits, demonstrating how to leverage existing programming skills in this cutting-edge field. <span class="No-Break">Link: </span><a href="https://www.manning.com/books/quantum-computing-for-developers"><span class="No-Break">https://www.manning.com/books/quantum-computing-for-developers</span></a></li>
			</ul>
			<h3>Articles</h3>
			<ul>
				<li><em class="italic">Transitioning your service or application</em> by Amazon <span class="No-Break">Web Services</span></li>
				<li>This article explores optimizing Java applications to provide more details regarding the individual steps involved in transitioning an application to Graviton2. <span class="No-Break">Link: </span><a href="https://docs.aws.amazon.com/whitepapers/latest/aws-graviton2-for-isv/transitioning-your-service-or-application.html"><span class="No-Break">https://docs.aws.amazon.com/whitepapers/latest/aws-graviton2-for-isv/transitioning-your-service-or-application.html</span></a></li>
				<li><em class="italic">Java in the Era of Cloud Computing</em> by Cogent University. This article focuses on the cloud-native advancements in Java, with frameworks like Spring Boot and Quarkus facilitating cloud-based development. It also mentions tools like Maven, Gradle, and JUnit for enhancing productivity and ensuring code quality. <span class="No-Break">Link: </span><a href="https://www.cogentuniversity.com/post/java-in-the-era-of-cloud-computing"><span class="No-Break">https://www.cogentuniversity.com/post/java-in-the-era-of-cloud-computing</span></a></li>
			</ul>
			<h3>Online courses</h3>
			<ul>
				<li><em class="italic">Parallel, Concurrent, and Distributed Programming in Java Specialization</em> by Rice University on Coursera. This specialization covers advanced concurrency topics in Java, which apply to cloud computing environments and auto-scaling scenarios. <span class="No-Break">Link: </span><a href="https://www.coursera.org/specializations/pcdp"><span class="No-Break">https://www.coursera.org/specializations/pcdp</span></a></li>
				<li><em class="italic">Serverless Machine Learning with Tensorflow on Google Cloud Platform</em> by Google Cloud on Coursera. This course explores the intersection of serverless computing and machine learning, aligning with discussions on AI/ML integration in cloud environments and future trends in cloud computing. <span class="No-Break">Link: </span><a href="https://www.coursera.org/learn/serverless-machine-learning-gcp-br"><span class="No-Break">https://www.coursera.org/learn/serverless-machine-learning-gcp-br</span></a></li>
			</ul>
			<p>This appendix provides a curated selection of resources, including books, articles, and online courses, to deepen your understanding of concurrency, parallelism, and cloud-native development in Java. Leveraging these materials will enhance your knowledge and skills, enabling you to build robust, scalable, and efficient cloud-native <span class="No-Break">Java applications.</span></p>
			<h1 id="_idParaDest-297"><a id="_idTextAnchor347"/>Answers to the end-of-chapter multiple-choice questions</h1>
			<h2 id="_idParaDest-298"><a id="_idTextAnchor348"/>Chapter 1: Concurrency, Parallelism, and the Cloud: Navigating the Cloud-Native Landscape</h2>
			<ol>
				<li>B) Easier to scale and maintain <span class="No-Break">individual services</span></li>
				<li><span class="No-Break">B) Synchronization</span></li>
				<li>D) <span class="No-Break">Stream API</span></li>
				<li>C) Automatic scaling and management <span class="No-Break">of resources</span></li>
				<li>B) Data consistency <span class="No-Break">and synchronization</span></li>
			</ol>
			<h2 id="_idParaDest-299"><a id="_idTextAnchor349"/>Chapter 2: Introduction to Java’s Concurrency Foundations: Threads, Processes, and Beyond</h2>
			<ol>
				<li value="1">C) Threads share a memory space, while processes are independent and have their <span class="No-Break">own memory.</span></li>
				<li>B) It offers a set of classes and interfaces for managing threads and <span class="No-Break">processes efficiently.</span></li>
				<li>B) Allowing multiple threads to read a resource concurrently but requiring exclusive access <span class="No-Break">for writing.</span></li>
				<li>B) It allows a set of threads to wait for a series of events <span class="No-Break">to occur.</span></li>
				<li>B) It allows for lock-free thread-safe operations on a single <span class="No-Break">integer value.</span></li>
			</ol>
			<h2 id="_idParaDest-300"><a id="_idTextAnchor350"/>Chapter 3: Mastering Parallelism in Java</h2>
			<ol>
				<li value="1">B) To enhance parallel processing by recursively splitting and <span class="No-Break">executing tasks</span></li>
				<li>A) <strong class="source-inline">RecursiveTask</strong> returns a value, while <strong class="source-inline">RecursiveAction</strong> <span class="No-Break">does not</span></li>
				<li>B) It allows idle threads to take over tasks from <span class="No-Break">busy threads</span></li>
				<li>B) Balancing task granularity and <span class="No-Break">parallelism level</span></li>
				<li>B) The task’s nature, resource availability, and <span class="No-Break">team expertise</span></li>
			</ol>
			<h2 id="_idParaDest-301"><a id="_idTextAnchor351"/>Chapter 4: Java Concurrency Utilities and Testing in the Cloud Era</h2>
			<ol>
				<li value="1">C) To efficiently manage thread execution and <span class="No-Break">resource allocation</span></li>
				<li><span class="No-Break">B) </span><span class="No-Break"><strong class="source-inline">CopyOnWriteArrayList</strong></span></li>
				<li>B) Enables asynchronous programming and <span class="No-Break">non-blocking operations</span></li>
				<li>B) They enable efficient data handling and reduce locking overhead in concurrent <span class="No-Break">access scenarios</span></li>
				<li>C) By offering more control over lock management and reducing <span class="No-Break">lock contention</span></li>
			</ol>
			<h2 id="_idParaDest-302"><a id="_idTextAnchor352"/>Chapter 5: Mastering Concurrency Patterns in Cloud Computing</h2>
			<ol>
				<li value="1">C) To prevent failures in one service from affecting <span class="No-Break">other services</span></li>
				<li>B) Employing a lock-free ring buffer to <span class="No-Break">minimize contention</span></li>
				<li>C) It isolates services to prevent failures in one from cascading <span class="No-Break">to others.</span></li>
				<li>B) <span class="No-Break">Scatter-Gather pattern</span></li>
				<li>D) Resilience and data <span class="No-Break">flow management</span></li>
			</ol>
			<h2 id="_idParaDest-303"><a id="_idTextAnchor353"/>Chapter 6: Java and Big Data – a Collaborative Odyssey</h2>
			<ol>
				<li value="1">B) Volume, velocity, <span class="No-Break">and variety</span></li>
				<li>A) <strong class="bold">Hadoop Distributed File </strong><span class="No-Break"><strong class="bold">System</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">HDFS</strong></span><span class="No-Break">)</span></li>
				<li>C) Spark offers faster in-memory data <span class="No-Break">processing capabilities.</span></li>
				<li>A) Spark can only process <span class="No-Break">structured data.</span></li>
				<li>C) It helps to break down large datasets into smaller, manageable chunks <span class="No-Break">for processing.</span></li>
			</ol>
			<h2 id="_idParaDest-304"><a id="_idTextAnchor354"/>Chapter 7: Concurrency in Java for Machine Learning</h2>
			<ol>
				<li value="1">C) To optimize <span class="No-Break">computational efficiency</span></li>
				<li>C) <span class="No-Break">Parallel Streams</span></li>
				<li>C) They improve scalability and manage <span class="No-Break">large-scale computations.</span></li>
				<li>B) To perform data preprocessing and model training <span class="No-Break">more efficiently</span></li>
				<li>B) Combining Java concurrency with <span class="No-Break">generative AI</span></li>
			</ol>
			<h2 id="_idParaDest-305"><a id="_idTextAnchor355"/>Chapter 8: Microservices in the Cloud and Java’s Concurrency</h2>
			<ol>
				<li value="1">C) Independent deployment <span class="No-Break">and scalability</span></li>
				<li><span class="No-Break">C) CompletableFuture</span></li>
				<li>B) Distributing incoming network traffic across <span class="No-Break">multiple instances</span></li>
				<li>C) Circuit <span class="No-Break">breaker pattern.</span></li>
				<li>C) Assigning a separate managed database instance for <span class="No-Break">each microservice</span></li>
			</ol>
			<h2 id="_idParaDest-306"><a id="_idTextAnchor356"/>Chapter 9: Serverless Computing and Java’s Concurrent Capabilities</h2>
			<ol>
				<li value="1">C) Automatic scaling and reduced <span class="No-Break">operational overhead.</span></li>
				<li><span class="No-Break">B) CompletableFuture.</span></li>
				<li>C) Managing recursive tasks by dividing them into <span class="No-Break">smaller subtasks.</span></li>
				<li>B) Optimize function size and use <span class="No-Break">provisioned concurrency.</span></li>
				<li>B) Improved performance through concurrent <span class="No-Break">data processing.</span></li>
			</ol>
			<h2 id="_idParaDest-307"><a id="_idTextAnchor357"/>Chapter 10: Synchronizing Java’s Concurrency with Cloud Auto-Scaling Dynamics</h2>
			<ol>
				<li value="1">C) Dynamic resource allocation based <span class="No-Break">on demand</span></li>
				<li><span class="No-Break">B) </span><span class="No-Break"><strong class="source-inline">CompletableFuture</strong></span></li>
				<li>A) Managing a fixed number <span class="No-Break">of threads</span></li>
				<li>C) Implementing <span class="No-Break">stateless services</span></li>
				<li>C) Improving performance through concurrent <span class="No-Break">data processing</span></li>
			</ol>
			<h2 id="_idParaDest-308"><a id="_idTextAnchor358"/>Chapter 11: Advanced Java Concurrency Practices in Cloud Computing</h2>
			<ol>
				<li value="1">D) User <span class="No-Break">interface design</span></li>
				<li>C) Improved performance for <span class="No-Break">parallel tasks</span></li>
				<li><span class="No-Break">B) VisualVM</span></li>
				<li>B) Minimize data loss and <span class="No-Break">improve availability</span></li>
				<li>C) Difficulty in obtaining a cohesive view of <span class="No-Break">distributed operations</span></li>
			</ol>
			<h2 id="_idParaDest-309"><a id="_idTextAnchor359"/>Chapter 12: The Horizon Ahead</h2>
			<ol>
				<li value="1">A) Improved startup time and reduced <span class="No-Break">memory usage</span></li>
				<li>D) All of <span class="No-Break">the above</span></li>
				<li>B) Google <span class="No-Break">Cloud AutoML</span></li>
				<li>C) <span class="No-Break">Quantum superposition</span></li>
				<li>A) Reduced operational overhead for <span class="No-Break">managing infrastructure</span></li>
			</ol>
		</div>
	</body></html>