- en: Execution Control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this book, we have been working with Reactor operators. This has
    included performing various tasks, such as filtering, transforming, and collecting.
    Most operators do not create additional threads and just work on the main thread.
    However, we can configure multithreading and concurrency in Reactor by using a
    set of schedulers.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Schedulers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallel processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Broadcasting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Java Standard Edition, JDK 8 or above
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IntelliJ IDEA IDE, 2018.1 or above
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The GitHub link for this chapter is [https://github.com/PacktPublishing/Hands-On-Reactive-Programming-with-Reactor/tree/master/Chapter09](https://github.com/PacktPublishing/Hands-On-Reactive-Programming-with-Reactor/tree/master/Chapter09).
  prefs: []
  type: TYPE_NORMAL
- en: Scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reactor executes all operations using one of the schedulers. A Reactor scheduler
    does not belong to the `java.util.concurrent` API. The Java concurrent API is
    quite low-level, where we can initiate and control task execution. On the other
    hand, all tasks in a Reactor chain are executed by the Reactor engine. Consequently,
    we do not need a low-level API to manage task execution. Instead, Reactor offers
    a declarative model, which we can use to configure a `Scheduler` and alter the
    behavior of the chain execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we start to configure Reactor, let''s first determine the default execution
    model. By default, Reactor is mostly single-threaded. The publisher and subscriber
    do not create additional threads for their execution. All life cycle hooks, and
    most operators, perform single-threaded execution. Before we jump ahead, let''s
    build some code to validate this, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: We built a simple Fibonacci chain, using the `filter` operator and life cycle
    hooks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each operation prints to a console using the `print` function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `print` function prints the current thread name, along with the text.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following screenshot shows a simple debugging code snippet, which allows
    us to see how Reactor does stream execution. Let''s run this and see how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5110c466-7ed1-4abe-84fd-70c48f9d8126.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding screenshot, we can see that all of the text is prefixed with
    `[main]`. Consequently, all operations are executed on the main thread, and no
    additional threads are used by Reactor. This output validates the idea that Reactor
    is single-threaded, by default. Due to the single-threaded execution, we did not
    pause the test execution using `Thread.sleep` or `latch.wait`.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the preceding concept is only partially true; Reactor operators do
    alter the behavior of chain execution. Previously, we used `latch` and `Thread.sleep`
    in our test cases, for the delay and timeout operator. Let''s add the operator
    to our test case and analyze the output, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: We added the `delayElements` operator to our chain, after the `filter` operator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The test now terminates quickly, so we need to add `Thread.sleep` to pause the
    execution of the main thread. The pause ensures that the complete chain is executed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s run this and analyze the output, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/36366260-ab46-4522-b2e3-04fce9cbfb8f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can deduce the following by looking at the preceding output:'
  prefs: []
  type: TYPE_NORMAL
- en: The publisher does not create a thread; it executes in the main thread.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `filter` operation does not create a thread; it executes in the main thread.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `delayElements` operations add a thread pool of two threads, denoted by
    `parallel-1` and `parallel-2`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rest of the chain now executes in the thread pool, rather than the main
    thread.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you have gained some understanding of the threading model of Reactor,
    let's discuss the ways in which we can configure it.
  prefs: []
  type: TYPE_NORMAL
- en: Reactor schedulers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed in the previous section, Reactor operators configure reactive chain
    execution behavior. However, the behavior can be altered by using a different
    scheduler. Most of the operators have overloaded methods, which take a scheduler
    as an argument. In this section, we will look at the various schedulers available
    in Reactor. Reactor also provides a `schedulers` utility class, to build instances
    of the available implementations.
  prefs: []
  type: TYPE_NORMAL
- en: The immediate scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Schedulers.immediate` scheduler executes work on the currently executing
    thread. All tasks are executed on the caller thread, and no task is performed
    in parallel. This is the default execution model for most Reactor tasks. Consider
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, the following has occurred:'
  prefs: []
  type: TYPE_NORMAL
- en: We added the `delayElements` operator to our chain.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The test tries to schedule the delay on the main thread.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can execute the code, but the task will fail, because the main thread lacks
    the time-based scheduling capability. The following screenshot shows this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d1152db0-c2a5-4ca0-91c7-afd42343bfeb.png)'
  prefs: []
  type: TYPE_IMG
- en: The single scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Schedulers.single` scheduler executes work on a single-worker thread pool.
    Since this is a single worker, all tasks are executed one by one, and no task
    is performed in a concurrent manner. The scheduler is quite useful for isolating
    the execution of non-threadsafe operations to a single thread. Consider the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, the following has occurred:'
  prefs: []
  type: TYPE_NORMAL
- en: We added the `delayElements` operator to our chain.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The test tries to schedule the delay on a single thread, and not on the main
    thread of test execution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From the output, we can validate that all of the tasks in the chain are executed
    on a `single-1` thread. Consider the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8eb38d32-4333-4ba7-9041-3ca1254d13c1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, the `single` scheduler is meant to execute non-blocking, computation-intensive
    operations. This can be treated as an event loop, executing non-blocking tasks
    in its queue. If we invoke any reactive blocking APIs, the scheduler throws back
    the following error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to the chain discussed previously, the following has occurred in
    the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: We invoked the `window` operator to generate batches of `10` elements each.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The subscriber invoked the `blockFirst` API to get back the first element.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Executing the preceding code leads to the following exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/53dbda69-8667-48a3-80b6-622dfff298f1.png)'
  prefs: []
  type: TYPE_IMG
- en: The parallel scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Schedulers.parallel` scheduler executes work on a multiple-worker thread
    pool. It creates workers based on the number of available processors. This is
    the default scheduler used in various Reactor operators. Consider the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'From the output, we can validate that all of the tasks in the chain are executed
    on `paralle-1` and `parallel-2` threads. Go through the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/89563f6d-82a3-41b1-9ae3-c32573a5f199.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similar to the `single` scheduler, the `parallel` scheduler is aimed at executing
    non-blocking tasks. If an operation invokes any of the reactive blocking APIs,
    the scheduler will throw back the following exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The elastic scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Schedulers.elastic` scheduler executes work on a multiple-worker thread
    pool. Each of the executed workers can execute long-lived tasks that ask for a
    blocking operation. Each worker is returned to the pool when the task finishes.
    There is also an idle time associated with the worker, after which the worked
    is disposed. The scheduler tries to consume an existing idle worker, but if there
    aren''t any, the scheduler dynamically generates one and schedules the task on
    it. The following code shows this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Unlike the previous worker, a blocking reactive call executes on an elastic
    scheduler successfully. Consider the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/26525eb6-bb91-4dfa-838b-1f526af5eb51.png)'
  prefs: []
  type: TYPE_IMG
- en: The ExecutorService scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Schedulers.fromExecutor` enables us to build a scheduler over the Java
    `ExecutorService`. The scheduler does not own thread generation, but instead,
    it is controlled by the underlying `ExecutorService`. The scheduler should not
    be favored over other schedulers, as the life cycle of the `ExecutorService` must
    be managed by the developer. Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following output, we can validate that the service is still running
    after the execution of our reactive chain:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6929c62c-c5ac-4ec0-81c6-d8f7f6d07cf2.png)'
  prefs: []
  type: TYPE_IMG
- en: Parallel processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reactor publishers and subscribers do not create threads. However, as seen in
    the previous section, there are operators that can alter this behavior. In the
    last section, we saw that the `delay` operator moved the execution of the Reactor
    chain from the main thread to the scheduler thread. However, we do not need delay/timeout
    operators for the purpose of switching execution. Reactor offers the `publishOn`
    and `subscribeOn` operators for the purpose of switching the chain execution.
    Both of these operators change the execution context of the reactive chain to
    the configured scheduler.
  prefs: []
  type: TYPE_NORMAL
- en: PublishOn operator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `publishOn` operator intercepts events from a publisher at a configured
    point in the execution chain, and sends them to a different scheduler for the
    rest of the chain. As a result, the operator changes the threading context of
    the downstream reactive chain. It is important to note that the operator only
    influences the downstream event chain. It does not alter the upstream chain, and
    leaves the upstream execution to the default execution model. The following code
    shows this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: We configured the `publishOn` operator before the `filter` operator. This should
    leave the generation on the main thread, and execute the rest of the chain on
    the scheduler.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We configured the `single` scheduler for the chain execution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since we are not executing the chain on the main thread, we have to pause the
    test execution for some time. This is accomplished by using `Thread.sleep`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s execute the test case and determine the output. The publisher generates
    events on the `main` thread, which are then passed over to a `single-1` thread,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/53503a77-3911-41b3-856d-520025c25adc.png)'
  prefs: []
  type: TYPE_IMG
- en: SubscribeOn operator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `subscribeOn` operator intercepts events from a publisher in the execution
    chain and sends them to a different scheduler for the complete chain. It is important
    to note that the operator changes the execution context for the complete chain,
    unlike the `publishOn` operator, which only alters the execution of a downstream
    chain:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we did the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Configured the `subscribeOn` operator, prior to subscribing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configured the `single` scheduler for the chain execution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since we are not executing the chain on the main thread, we have to pause the
    test execution for some time. This is accomplished by using `Thread.sleep`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s execute the test case and validate the output. All of the events are
    generated on the single thread configured by the `subscribeOn` operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e40c33e3-47ea-431d-b0e4-fc1ebe2ae80a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We have the `subscribeOn` and `publishOn` operators in the same chain. The
    `subscribeOn` operator will execute the complete reactive chain on the configured
    scheduler. However, the `publishOn` operator will change the downstream chain
    to the specified scheduler. It leaves back the upstream chain on the scheduler
    configured by the `subscribeOn` scheduler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code will generate events on a `single-1` scheduler, configured
    by the `subscribeOn` operator. The rest of the chain is executed on a parallel
    scheduler, configured by the `publishOn` operator.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the output after running the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aecb7263-b72b-4e21-95f6-2a4e3599127b.png)'
  prefs: []
  type: TYPE_IMG
- en: ParallelFlux
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reactor offers `ParallelFlux`, which is capable of splitting an existing stream
    into multiple streams in a round-robin manner. `ParallelFlux` is created from
    an existing `Flux`, using the `parallel` operator. By default, this splits the
    stream into the total number of CPU cores that are available. `ParallelFlux` only
    divides the stream, and does not change the execution model. Instead, it executes
    the streams on the default thread—the main thread. The divided stream can be configured
    for parallel processing by using the `runOn` operator. Similar to the `publishOn`
    operator, the `runOn` takes a scheduler and executes the downstream on the specified
    scheduler.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important to note that `ParallelFlux` does not offer the `doFinally`
    life cycle hook. It can be converted back to a `Flux` by using the `sequential`
    operator, which can then be configured by using the `doFinally` hook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: The `parallel` operator is configured to generate `ParallelFlux` from `fibonacciGenerator`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `runOn` operator is used to configure `ParallelFlux` on the parallel scheduler.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `sequential` operator is used to convert `ParallelFlux` to Flux.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`doFinally` is configured on the `sequential` Flux.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`subscribeOn` is configured to execute Flux generation on a single thread.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s run the code and validate the output, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7f82c6be-7615-42fb-954c-013baeb7e9d9.png)'
  prefs: []
  type: TYPE_IMG
- en: So far, we have discussed how to perform stream operations in parallel. In the
    next section, we will deliver events to all subscribers simultaneously, and then
    configure parallel processing for all of them.
  prefs: []
  type: TYPE_NORMAL
- en: Broadcasting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In networking, **broadcasting** is defined as simultaneous event publishing
    to multiple receivers. In terms of Reactive Streams, this means simultaneous event
    publishing to multiple subscribers. Until now, we have subscribed to cold publishers,
    where each subscription generates a new series of events. We have even subscribed
    to hot publishers, where the publisher keeps pushing events without waiting for
    a subscriber. Each subscriber gets the same event as soon as it is generated.
    A hot publisher may look like a broadcasting event, but there is a key difference
    with regard to the start of the event generation stream. Reactor allows us to
    create a `ConnecatableFlux`, capable of waiting for *n* subscribers before starting
    event generation. It then keeps publishing each event to all of its subscribers.
  prefs: []
  type: TYPE_NORMAL
- en: The replay operator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reactor provides the `replay` operator to convert a Flux to a `ConnectableFlux`.
    The resulting `ConnectableFlux` keeps buffering events published to the first
    subscriber. The buffer can be configured to keep the last *n* entries, or it can
    be configured to be based on the time duration. Only the buffered events are replayed
    back to the subscribers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Refer to the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9415c581-8d26-468e-af00-a8ed25743872.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A `ConnectableFlux` must be subscribed by *n* subscribers before it starts
    to publish events. `ConnectableFlux` provides the following operators to manage
    subscribers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Connect**: The `connect` operator must be invoked after enough subscriptions
    have been made. We must manage the subscription count ourselves. Subscription
    cancellation must also be tracked by developers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Auto-Connect**: The `autoConnect` operator configures a subscription count.
    This keeps track of subscriptions made to the publisher dynamically. It is best
    to use the `autoConnect` operator, and leave the subscription management to Reactor.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, you can see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The `broadcastGenerator` is generated from `fibonacciGenerator`, using the `replay`
    operator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `broadcastGenerator` waits for two subscribers before starting event publishing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`fibonacciGenerator` is subscribed twice.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`broadcastGenerator` is also subscribed twice.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the preceding code, we have subscribed twice, to both the `fibonacciGenerator`
    and `broadcastGenerator` publishers. Let''s run the test case and validate the
    output, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ed5f9ff8-5b15-46da-8f3e-6a48ba58103b.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding screenshot (output), we can see that the `fibonacciGenerator`
    publisher is called every time the next value is requested by the respective publisher.
    However, the `broadcastGenerator` publisher is invoked once, and the same value
    is published to both subscribers before generating the next value.
  prefs: []
  type: TYPE_NORMAL
- en: The `connect` and `autoConnect` operators, discussed in the preceding section,
    only keep track of subscription events. These start to process events when the
    configured count is reached. They keep publishing them until the publisher sends
    a terminating event. These operators do not keep track of a subscriber cancelling
    the subscription; once event generation has started, it keeps generating events,
    even when the subscribers have cancelled their subscription.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reactor provides a `refCount` operator for the previously discussed situation.
    The `refCount` operator also keeps track of the subscription. It stops generating
    new events if all subscribers have cancelled their subscription, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: The `fibonacciGenerator` is configured for two subscribers, before starting
    event publishing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each subscriber requests one event.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each subscriber cancels its subscription while processing the generated event.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s run the following test case to get the output, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/684e01be-2524-4778-9d07-50cead22f0b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding output, we can see that the complete Fibonacci series is generated
    before the stream is closed. The subscribers did not ask for more than one event.
    Now, let''s replace `autoConnect` with `refCount`, and compare the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/658f0cfe-4d09-4339-aa64-53737ae41973.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding output, you can see that the stream is closed as soon as all
    subscribers have cancelled their subscription. Now, if new subscribers arrive
    at `ConnectedFlux`, the series is generated from the first event.
  prefs: []
  type: TYPE_NORMAL
- en: The publish operator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Reactor provides the `publish` operator to generate a `ConnectedFlux`. Unlike
    the `replay` operator, which buffers events received by the first subscriber,
    the `publish` operator gets events from the source stream. The operator keeps
    track of the demands raised by its subscribers. If any subscriber does not raise
    a demand, it pauses the event generation until a new demand is raised by all of
    its subscribers. Consider the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bb8f3485-b6fc-493d-b584-788333cd970e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Just like the `replay` operator, the `ConnectedFlux` generated by the publisher
    also needs subscriber management. Here, we can configure this by using any of
    the following three options—`connect`, `autoConnect`, or `refCount`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: The `fibonacciGenerator` is configured for two subscribers, before starting
    event publishing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The first subscriber requests only one event.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The second subscriber does not put a constraint on the event count.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s run the test case to analyze the output, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eb239031-d37e-4604-89ec-6b9c155a5f6e.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding output, you can see that only the first event is generated.
    There is no closing event either, because the stream was waiting for the next
    event request from subscriber one. Consequently, the stream did not terminate.
    The test finished after waiting for 500 ms.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored Reactor execution models. We discovered that publisher
    and subscriber Reactive Streams are concurrency agnostic. Most of the operators
    in Reactor are also concurrency agnostic. Some operators, such as `delayElements`
    and `timeout`, do alter the concurrency behavior of a stream's execution. Reactor
    provides various schedulers, which can be used to control the execution behavior
    of the stream. We found out that these schedulers can be configured for various
    operators, such as `publishOn` and `subscribeOn`. Next, we discussed `ParallelFlux`,
    which can be configured, along with the available schedulers, to perform parallel
    processing. Finally, we discussed event broadcasting by using `ConnectedFlux`.
    Reactor presents `replay` and `publishOn` operators, to generate a `ConnectedFlux`
    from an existing Flux.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are the different types of schedulers that are available in Reactor?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What scheduler should be used for blocking operations?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What scheduler should be used for computation-intensive operations?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How are `PublishOn` and `SubscriberOn` different from each other?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the limitation of `ParallelFlux`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which operators are available for generating a `ConnectedFlux`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
