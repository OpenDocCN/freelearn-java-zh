<html><head></head><body>
		<div id="_idContainer132">
			<h1 id="_idParaDest-323"><a id="_idTextAnchor325"/>Chapter 14: Monitoring and Tracing Techniques</h1>
			<p>There is a risk, as developers and architects, of overlooking what happens to our applications and services after production release. We may be tempted to think that it's just a problem for sysadmins and whoever oversees service operations. As is easy to understand, this is the wrong point of view.</p>
			<p>Understanding how our application behaves in production gives us a lot of insight into what is and is not working—from both a code and an architecture perspective. As we learned in the previous chapter, maintenance of our application is crucial for the success of each software project, and looking closely at how the application is going in production is the perfect way to understand whether there is something that can be improved.</p>
			<p>Moreover, in modern DevOps teams, as we learned in <a href="B16354_05_Final_JM_ePUB.xhtml#_idTextAnchor109"><em class="italic">Chapter 5</em></a>, <em class="italic">Exploring the Most Common Development Models</em>, the separation of concerns must be overcome, and the development and architectural teams are responsible for operating services as well. In this chapter, we will have an overview of the common topics regarding the visibility of what happens to our application during production.</p>
			<p>We will look at the following topics in this chapter:</p>
			<ul>
				<li>Log management</li>
				<li>Collecting application metrics</li>
				<li>Defining application health checks</li>
				<li>Application Performance Management</li>
				<li>Service monitoring</li>
			</ul>
			<p>The idea is not only to have an overview of these topics and what they are useful for, but also to understand the impact that a correct design and implementation may have on these topics. With that said, let's start discussing log management.</p>
			<h1 id="_idParaDest-324"><a id="_idTextAnchor326"/>Technical requirements</h1>
			<p>You can find the source code used in this chapter here: <a href="https://github.com/PacktPublishing/Hands-On-Software-Architecture-with-Java/tree/master/Chapter14">https://github.com/PacktPublishing/Hands-On-Software-Architecture-with-Java/tree/master/Chapter14</a>.</p>
			<h1 id="_idParaDest-325"><a id="_idTextAnchor327"/>Log management</h1>
			<p><strong class="bold">Log management</strong> has been <a id="_idIndexMarker1824"/>taken for granted so far in the book. Let's just take a quick glance over some basic concepts related to producing logs in our Java applications.</p>
			<p>Logging in Java has had a troubled history. At the very beginning, no standard was provided as part of the Java platform. When a<a id="_idIndexMarker1825"/> standard (such as <strong class="bold">Java Util Logging</strong> (<strong class="bold">JUL</strong>)) was added to the platform (in release <strong class="bold">1.4</strong>), other alternative frameworks<a id="_idIndexMarker1826"/> were available, such<a id="_idIndexMarker1827"/> as <strong class="bold">Apache Commons Logging</strong> and <strong class="bold">Log4j</strong>.</p>
			<p>At the time of writing, Log4j has been<a id="_idIndexMarker1828"/> deprecated and <a id="_idIndexMarker1829"/>replaced by <strong class="bold">Log4j2</strong> and <strong class="bold">logback</strong>.</p>
			<p>Even though the JUL standard has been a part of the platform for many years now, the usage of alternative frameworks such as logback and Log4j2 is still very widespread, due to their features and performance. Regardless of which implementation we choose, there are some common concepts to consider.</p>
			<h2 id="_idParaDest-326"><a id="_idTextAnchor328"/>Common concepts in logging frameworks</h2>
			<p>As described previously, no matter what kind of preferred log implementation is used in your projects, there are two main concepts that are common to every one of them:</p>
			<ul>
				<li><strong class="bold">Levels</strong>: Each <a id="_idIndexMarker1830"/>framework defines its own levels. Logging levels are used to configure the verbosity of the logs at runtime, with a hierarchy defining which level of logs must be produced. Here, the hierarchy means that if a certain level of logging is enabled, all the log entries from that level and above are reported in the logs. The <strong class="source-inline">INFO</strong> level is commonly present, and defines the <em class="italic">average</em> level of verbosity, reporting log entries that record basic information useful to understand what's going on, but that can be discarded if you want to reduce the amount of logging or if you are familiar and confident enough with your app's behavior.</li>
			</ul>
			<p>Above<a id="_idIndexMarker1831"/> the <strong class="source-inline">INFO</strong> level, there are <strong class="source-inline">WARNING</strong> and other similar levels (such as <strong class="source-inline">ERROR</strong> and <strong class="source-inline">FATAL</strong>) that are used for reporting unusual or incorrect behavior. For this reason, these levels are almost always kept active. Finally, below <strong class="source-inline">INFO</strong> there are other levels, such as <strong class="source-inline">DEBUG</strong> and <strong class="source-inline">TRACE</strong>, which are used for getting details on what is happening in our application and are usually reported only for a limited amount of time. They are also used to gather data on whether there is something wrong in our application that needs troubleshooting, as well as collect data in non-production environments for development purposes. These levels of logging are discouraged in production as they will produce a lot of entries and may impact performance, which leads to our next point.</p>
			<ul>
				<li><strong class="bold">Appenders</strong> define<a id="_idIndexMarker1832"/> the<a id="_idIndexMarker1833"/> technology used for reporting log entries. As with the log levels, the appenders are also different in each logging implementation. <strong class="source-inline">CONSOLE</strong> and <strong class="source-inline">FILE</strong> are two common ones used to report log entries in the console or in a file. Other alternatives may include appenders to a database and to other external systems (such as logging to a socket).</li>
			</ul>
			<p>As described in the previous point, appenders may impact the overall performance. Writing to a file may be slower than writing to the console. For this reason, appenders often offer asynchronous alternatives that buffer the log entries in memory before writing them to the target system. However, this of course increases the risk of losing data should our application crash before the entries are forwarded to the relevant system (such as the file or the database).</p>
			<p>These are some very basic concepts of logging in Java (similar concepts can be found in other languages). But there are also some recommendations about logging that I can provide, from personal <a id="_idIndexMarker1834"/>experience:</p>
			<ul>
				<li>It's a good practice to avoid string concatenation (such as <strong class="source-inline">"My log is " + variable + " ! "</strong>). Other than being ugly, it can have a performance impact since string concatenation operations happen even if the log is not used (because it's related to a disabled level). Most logging frameworks offer alternatives based on placeholders (such as <strong class="source-inline">"My log is {} !", variable</strong>). Most recent Java versions automatically mitigate string concatenation by replacing it at compilation time with more efficient alternatives (such as <strong class="source-inline">StringBuilder</strong>), but it's still a good idea to avoid it.</li>
				<li>Consider <a id="_idIndexMarker1835"/>differentiating log destinations by content type. You may want to have different appenders (almost every framework allows it) to log different information. So, business information (related to how our application is performing from a business perspective) such as user information or the products used can go to a specific database table (and maybe then can be aggregated and reported), while logs containing technical information (useful for troubleshooting or checking the application's health) may go in a file to be easily accessed by SysOps.</li>
			</ul>
			<p>This can also be done by log severity by sending the <strong class="source-inline">INFO</strong> level on a certain appender, and other levels on other appenders. This may also allow for different <em class="italic">quality of service</em> for logs: you could log business information that is logged on an asynchronous appender (because you may lose some data in the event of an application issue—this is not a problem), while technical logs should go on synchronous appenders (because you cannot afford to lose anything if you intend to understand the issues behind a misbehaving application).</p>
			<ul>
				<li><strong class="bold">Log rotation</strong> is an<a id="_idIndexMarker1836"/> essential concept, but it's still sometimes forgotten, especially in older applications. Log rotation can be implemented using the logging framework itself or by external scripts and utilities. It's basically related to file appenders, and defines the way logs are archived by renaming them, moving them, and optionally compressing them. A log rotation policy allows the current logs to be small enough (for easy reading and searching) and makes it easier to find information from previous dates and save space on disk. This will help SysOps, who sometimes have to deal with misconfigured applications that fill the disk because of a misconfigured log rotation policy. Hopefully, this should be less common nowadays.</li>
				<li>Every message should provide meaningful information. As trivial as it may sound, it's very easy to write just basic things in logs, assuming that whoever reads the log will have enough context. <em class="italic">I highly recommend not doing this!</em> Log messages could be read by people not knowing much about the application (such as first-line support staff) in emergency situations (such as production troubleshooting). When in doubt, be as clear as possible. This doesn't necessarily mean being verbose, but make sure to provide a decent amount of content.</li>
				<li>Logging levels should be defined in a standard way. Especially in big projects composed of many microservices or applications, it should be well documented what is supposed to be logged as INFO, what should be higher, and what should be lower. In this way, logging levels can be set in a uniform way, expecting the same kind of information across all modules.</li>
				<li>The same <a id="_idIndexMarker1837"/>is true for log format. Almost every logging library supports defining a pattern, which means setting which information (apart from the log message itself) should be written, including date, time, the log level, and more. It's better if this kind of format is uniform across all the components to be easy to read and parse using tools (such as the very basic <strong class="source-inline">grep</strong> utility). Also, I strongly suggest configuring the logging library to provide information about the class that is generating the log. It's usually a bit expensive from a computational perspective (often negligible) but is worth it for sure.</li>
				<li>You should have a discussion with security and legal advisors as soon as possible (if present) about what can, must, and should not be present in logs. This varies from application to application, but there may be information (such as personal information or credit card data) that is prohibited from being present in logs (or needs to be anonymized), and other information that is required to be present by law (such as audit information). You need to know about this and implement the requirements accordingly.</li>
				<li>As a follow-up<a id="_idIndexMarker1838"/> from the previous point, most applications have legal (or other kinds of) requirements for log storage and archiving. You may need to store logs for many years, sometimes in an immutable way. Hence, log rotation and specialized hardware and software may be needed.</li>
			</ul>
			<p>As a final consideration about logging, we cannot avoid having a chat about log aggregation.</p>
			<h2 id="_idParaDest-327"><a id="_idTextAnchor329"/>Log aggregation</h2>
			<p>In <a href="B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230"><em class="italic">Chapter 9</em></a>, <em class="italic">Designing Cloud-Native Architectures</em>, when<a id="_idIndexMarker1839"/> discussing <strong class="bold">Twelve-Factor Applications</strong>, we saw how logs can be seen as an event stream and must be handled by a supporting platform, capable of capturing the event stream, storing it, and making it usable and searchable across different applications. We even <a id="_idIndexMarker1840"/>mentioned <strong class="bold">Fluentd</strong> as a commonly used solution for this. This is exactly what log aggregation is about. A typical log aggregation architecture features the following:</p>
			<ul>
				<li>An agent for collecting logs from the console (or a file) in the form of event streams. Fluentd is a common choice (even though it has some known limitations in terms<a id="_idIndexMarker1841"/> of performance<a id="_idIndexMarker1842"/> and logs that can potentially be lost in corner cases). <strong class="bold">Filebeat</strong> and <strong class="bold">collectd</strong> are some alternatives to this.</li>
				<li>Persistence for log entries. <strong class="bold">Elasticsearch</strong> is <a id="_idIndexMarker1843"/>practically the standard in this area, providing storing, indexing, and searching capabilities.</li>
				<li>A frontend for navigating and monitoring log entries. Software commonly used for this goal <a id="_idIndexMarker1844"/>are <strong class="bold">Kibana</strong> and <strong class="bold">Grafana</strong>. Here is a screenshot<a id="_idIndexMarker1845"/> of the Kibana UI:</li>
			</ul>
			<div>
				<div id="_idContainer129" class="IMG---Figure">
					<img src="image/Figure_14.1_B16354_new.jpg" alt="Figure 14.1 – Kibana UI home&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 14.1 – Kibana UI home</p>
			<p>Log aggregation<a id="_idIndexMarker1846"/> should be considered a must in cloud-native architecture, because having a heavily distributed application based on microservices will <a id="_idIndexMarker1847"/>mean having a lot of systems to monitor and troubleshoot in the event of issues. </p>
			<p>With a log aggregation strategy, you will have a centralized way to access logs, hence everything will become a bit easier.</p>
			<p>In this section, we had a quick overview of logging in Java, and then we highlighted the characteristics and the advantages of log aggregation. In the next section, we are going to have a look at another key topic about monitoring, which is metrics collection.</p>
			<h1 id="_idParaDest-328"><a id="_idTextAnchor330"/>Collecting application metrics</h1>
			<p><strong class="bold">Metrics</strong> are<a id="_idIndexMarker1848"/> a way<a id="_idIndexMarker1849"/> to instrument your source code to provide real-time insights into what's happening. Metrics are also known as <strong class="bold">telemetry</strong>. Instead<a id="_idIndexMarker1850"/> of logs, which represent information pushed into a file, a console, or another appender, metrics are values exposed by the application and are supposed to be pulled by whoever is interested in them. </p>
			<p>Moreover, while a log contains what's happening in our application, collected in a sequential way, metrics expose a snapshot of how the application was behaving in that instant, summarized into some well-known values (such as the number of threads, the memory allocated, and so on). It's also possible to define some custom metrics, which can be useful to define figures that are specific to our particular use case (such as the number of payments, transactions, and so on). </p>
			<p>There are <a id="_idIndexMarker1851"/>many widespread frameworks useful for exposing metrics in Java. <strong class="source-inline">Micrometer</strong> is an open source façade implementation, while other commercial solutions exist, such <a id="_idIndexMarker1852"/>as <strong class="bold">New Relic</strong> and <strong class="bold">Datadog</strong>. However, I think <a id="_idIndexMarker1853"/>that one of the most interesting efforts in this area is one part of the MicroProfile standard. We looked at MicroProfile in <a href="B16354_07_Final_JM_ePUB.xhtml#_idTextAnchor164"><em class="italic">Chapter 7</em></a>, <em class="italic">Exploring Middleware and Frameworks</em>, when discussing Quarkus as an implementation of it.</p>
			<p>I think that a quick example (MicroProfile compliant) will be useful here to better explain what metrics look like. Let's see a simple hello world REST API:</p>
			<p class="source-code">@GET</p>
			<p class="source-code">    @Path("/hello")</p>
			<p class="source-code">    @Produces(MediaType.TEXT_PLAIN)</p>
			<p class="source-code">    @Counted(name = "callsNumber", description = "How many </p>
			<p class="source-code">      calls received.")</p>
			<p class="source-code">    @Timed(name = "callsTimer", description = "Time for </p>
			<p class="source-code">      each call", unit = MetricUnits.MILLISECONDS)</p>
			<p class="source-code">    public String hello() throws InterruptedException {</p>
			<p class="source-code">        int rand = (int)(Math.random() * 30);</p>
			<p class="source-code">        Thread.sleep(rand*100);</p>
			<p class="source-code">        return "Hello RESTEasy";</p>
			<p class="source-code">    }</p>
			<p>As you can see, the <strong class="source-inline">hello</strong> method is annotated with two metric-related annotations (<strong class="source-inline">Counted</strong> and <strong class="source-inline">Timed</strong>), which declare the kind of metrics we want to collect. The annotations also provide some documentation (the <strong class="source-inline">name</strong> and <strong class="source-inline">description</strong> of the metric). Now, if we query the application via REST, we can see all the metrics values exposed:</p>
			<p class="source-code"># HELP application_it_test_MetricsTest_callsNumber_total </p>
			<p class="source-code">  How many calls received.</p>
			<p class="source-code"># TYPE application_it_test_MetricsTest_callsNumber_total </p>
			<p class="source-code">  counter</p>
			<p class="source-code">application_it_test_MetricsTest_callsNumber_total 4.0</p>
			<p class="source-code">...</p>
			<p class="source-code"># HELP application_it_test_MetricsTest_callsTimer_seconds </p>
			<p class="source-code">  Time for each call</p>
			<p class="source-code"># TYPE application_it_test_MetricsTest_callsTimer_seconds </p>
			<p class="source-code">  summary</p>
			<p class="source-code">application_it_test_MetricsTest_callsTimer_seconds_count </p>
			<p class="source-code">  4.0</p>
			<p class="source-code">...</p>
			<p>A<a id="_idIndexMarker1854"/> number of other metrics (such as minimum, maximum, and average) are omitted in the preceding output and calculated automatically by the framework.</p>
			<p>These kinds of metrics are exposed under the <strong class="source-inline">/metrics/application</strong> endpoint (<strong class="source-inline">/q/metrics/application</strong>, in the case of the Quarkus framework).</p>
			<p>The MicroProfile specification also defines the <strong class="source-inline">/metrics/vendor</strong> (vendor-specific), <strong class="source-inline">/metrics/base</strong> (a meaningful predefined subset), and <strong class="source-inline">/metrics</strong> (all the metrics available) endpoints. In these endpoints, you may find a lot of useful insights into the application, such as virtual machine stats and similar things. This is a small subset of what can be retrieved from such endpoints:</p>
			<p class="source-code">...</p>
			<p class="source-code"># HELP base_memory_usedHeap_bytes Displays the amount of </p>
			<p class="source-code">  used heap memory in bytes.</p>
			<p class="source-code"># TYPE base_memory_usedHeap_bytes gauge</p>
			<p class="source-code">base_memory_usedHeap_bytes 9.4322688E7</p>
			<p class="source-code"># HELP base_thread_count Displays the current number of </p>
			<p class="source-code">  live threads including both daemon and non-daemon threads</p>
			<p class="source-code"># TYPE base_thread_count gauge</p>
			<p class="source-code">base_thread_count 33.0</p>
			<p class="source-code">...</p>
			<p>The <a id="_idIndexMarker1855"/>metrics exposed in this way can then be collected by external systems, which can store them and provide alerts in the event of something going wrong. A widely used framework<a id="_idIndexMarker1856"/> to do so is <strong class="bold">Prometheus</strong>. </p>
			<p>Being a part of <a id="_idIndexMarker1857"/>the <strong class="bold">Cloud-Native Computing Foundation</strong> (<strong class="bold">CNCF</strong>) effort, Prometheus is able to collect the metrics from various systems (including OpenMetrics-compliant endpoints, similar to the ones exposed by the <a id="_idIndexMarker1858"/>example we saw previously), store them in a so-called <strong class="bold">Time Series Database</strong> (<strong class="bold">TSDB</strong>) (which is basically a database optimized for storing events on a temporal scale), and provide capabilities for querying the metrics and providing alerts. It also offers a built-in graphical interface and integration with Grafana. </p>
			<p>But metrics are just one of the aspects of application monitoring. Another similar and important one is health checks.</p>
			<h2 id="_idParaDest-329"><a id="_idTextAnchor331"/>Defining application health checks</h2>
			<p><strong class="bold">Health checks</strong> are a<a id="_idIndexMarker1859"/> kind of special case for metrics collection. Instead of exposing figures useful for evaluating the trends of application performance, health checks <a id="_idIndexMarker1860"/>provide simple <em class="italic">on/off</em> information about the application being healthy or not. </p>
			<p>Such information is particularly useful in cloud and PaaS environments (such as Kubernetes) because it can allow self-healing (such as a restart) in the event of an application not working.</p>
			<p>OpenMetrics currently defines three kinds of health checks: <strong class="bold">live</strong>, <strong class="bold">ready</strong>, and <strong class="bold">started</strong>. These checks come from concepts in the Kubernetes world:</p>
			<ul>
				<li>By using<a id="_idIndexMarker1861"/> a live (health) check, Kubernetes knows whether an application is up and running, and restarts it if it's not healthy.</li>
				<li>By using a<a id="_idIndexMarker1862"/> readiness check, Kubernetes will be aware of whether the application is ready to take requests and will forward connections to it.</li>
				<li>Startup checks<a id="_idIndexMarker1863"/> identify the successful completion of the startup phase.</li>
			</ul>
			<p>Note that <strong class="bold">ready</strong> and <strong class="bold">started</strong> are very similar but <strong class="bold">started</strong> has to do with the first startup of the application (which may be slow), while <strong class="bold">ready</strong> may involve a temporary inability to process requests (as an example, a traffic spike or other temporary slowdowns).</p>
			<p>Quarkus provides such checks with the <strong class="source-inline">smallrye-health</strong> extension. The probes are exposed, by default, at the <strong class="source-inline">/q/health/live</strong>, <strong class="source-inline">/q/health/ready</strong>, and <strong class="source-inline">/q/health/started</strong> endpoints and the results are formatted as JSON.</p>
			<p>In order to implement the checks, Quarkus provides an infrastructure based on annotations. This is<a id="_idIndexMarker1864"/> how a basic <strong class="source-inline">Liveness</strong> probe is implemented:</p>
			<p class="source-code">@Liveness</p>
			<p class="source-code">public class MyLiveHealthCheck implements HealthCheck {</p>
			<p class="source-code">    @Override</p>
			<p class="source-code">    public HealthCheckResponse call() {</p>
			<p class="source-code">        // do some checks</p>
			<p class="source-code">        return HealthCheckResponse.up("Everything works");</p>
			<p class="source-code">    }</p>
			<p class="source-code">}</p>
			<p>As you can see, the preceding method is annotated with <strong class="source-inline">@Liveness</strong> and returns a message using the <strong class="source-inline">up</strong> method of the <strong class="source-inline">HealthCheckResponse</strong> object.</p>
			<p>Similarly, a <strong class="source-inline">Readiness</strong> check <a id="_idIndexMarker1865"/>will look like this:</p>
			<p class="source-code">@Readiness</p>
			<p class="source-code">public class MyReadyHealthCheck implements HealthCheck {</p>
			<p class="source-code">    @Override</p>
			<p class="source-code">    public HealthCheckResponse call() {</p>
			<p class="source-code">        // do some checks</p>
			<p class="source-code">        return HealthCheckResponse.up("Ready to take </p>
			<p class="source-code">          calls");</p>
			<p class="source-code">    }</p>
			<p class="source-code">}</p>
			<p>Also, in this<a id="_idIndexMarker1866"/> case, the preceding method is annotated (in this case, with <strong class="source-inline">@Readiness</strong>) and returns a message using the <strong class="source-inline">up</strong> method of the <strong class="source-inline">HealthCheckResponse</strong> object.</p>
			<p>Finally, a <strong class="source-inline">Startup</strong> check <a id="_idIndexMarker1867"/>will look like this:</p>
			<p class="source-code">@Startup</p>
			<p class="source-code">public class MyStartedHealthCheck implements HealthCheck {</p>
			<p class="source-code">    @Override</p>
			<p class="source-code">    public HealthCheckResponse call() {</p>
			<p class="source-code">        // do some checks</p>
			<p class="source-code">return HealthCheckResponse.up("Startup completed");</p>
			<p class="source-code">    }</p>
			<p class="source-code">}</p>
			<p>For startup checks, the preceding method is annotated (with <strong class="source-inline">@Startup</strong>) and returns a message using the <strong class="source-inline">up</strong> method of the <strong class="source-inline">HealthCheckResponse</strong> object.</p>
			<p>As you can see, the API is pretty simple. The objects providing the functionalities are singletons by default. Of course, in a real-world application, you may want to do some complex checks such as testing the database connection or something similar.</p>
			<p>You can of course return a negative response (such as with the <strong class="source-inline">down()</strong> method) if you detect any failure. Other useful features include the chaining of multiple checks (where the cumulative answer is <strong class="source-inline">up</strong>, only if every check is up) and the ability to include some metadata in the response.</p>
			<h3>Implementing OpenTracing</h3>
			<p>Tracing is a<a id="_idIndexMarker1868"/> crucial monitoring technique when you have a long chain of calls (for example, a microservice calling other microservices, and so on), as you compose your answer by calling a huge number of internal or external services. </p>
			<p>Indeed, it's a very common use case in microservices applications: you have a call coming into your application (such as from a REST web service or an operation on a web user interface, which in turn translates into one or more REST calls). This kind of call will then be served by a number of different microservices, ultimately being assembled into a unique answer.</p>
			<p>The issue with this is that you may end up losing trace of whatever happened. It becomes very hard to correlate the incoming call with every specific sub-call. And that may be a big problem, in terms of troubleshooting issues and even simply understanding what's happening.</p>
			<p>Tracing allows a way<a id="_idIndexMarker1869"/> to identify the path made by each request by propagating an identifier code used in each subsystem, hence helping to document and reconstruct the tree of calls used to implement our use case, both for troubleshooting and for other purposes, such as audit logging. </p>
			<p><strong class="bold">OpenTracing</strong> is a <a id="_idIndexMarker1870"/>standard and part of the CNCF family, which implements this kind of functionality. In Quarkus, as an example, this feature is provided by a library that's part of the SmallRye project, which is called <strong class="source-inline">smallrye-opentracing</strong>.</p>
			<p>An interesting feature is that OpenTracing also supports computing the time spent on each sub-call.</p>
			<p>Let's see a very <a id="_idIndexMarker1871"/>simple example to understand how tracing works in Quarkus.</p>
			<p>We will start with a simple REST resource, as we have seen many other times in this book:</p>
			<p class="source-code">@Path("/trace")</p>
			<p class="source-code">public class TracingTest {</p>
			<p class="source-code">     @Inject</p>
			<p class="source-code">    NameGuessService service;</p>
			<p class="source-code">     @GET</p>
			<p class="source-code">    @Produces(MediaType.TEXT_PLAIN)</p>
			<p class="source-code">    public String hello() {</p>
			<p class="source-code">        String name = service.guess();</p>
			<p class="source-code">        return "Hello "+name;</p>
			<p class="source-code">    }</p>
			<p class="source-code">}</p>
			<p>As you can see, it's a simple <a id="_idIndexMarker1872"/>REST method listening on the <strong class="source-inline">/trace</strong> endpoint. It uses a service (<strong class="source-inline">NameGuessService</strong>) that has been injected.</p>
			<p>It's worth <a id="_idIndexMarker1873"/>noticing that there is no specific code related to tracing: indeed, tracing in REST endpoints is basically automatically provided by the framework. It's enough to have the <strong class="source-inline">smallrye-opentracing</strong> extension in the project itself.</p>
			<p>Now, let's have a look at the <strong class="source-inline">NameGuessService</strong> class:</p>
			<p class="source-code">@ApplicationScoped</p>
			<p class="source-code">@Traced</p>
			<p class="source-code">public class NameGuessService {</p>
			<p class="source-code">    public String guess()</p>
			<p class="source-code">    {</p>
			<p class="source-code">        Random random = new Random();</p>
			<p class="source-code">        String[] names = {"Giuseppe","Stefano",</p>
			<p class="source-code">          "Filippo","Luca","Antonello"};</p>
			<p class="source-code">        return names[random.nextInt(names.length)];</p>
			<p class="source-code">    }</p>
			<p class="source-code">}</p>
			<p>As you can see, there is nothing special here: there's just a simple mocked service returning a string, which is chosen randomly. The only notable thing is that the method is annotated with <strong class="source-inline">@Traced</strong>, because<a id="_idIndexMarker1874"/> the framework needs to know explicitly whether the method must be traced.</p>
			<p><em class="italic">Where do we go from here?</em> The most common and useful way to use tracing is with a Jaeger <a id="_idIndexMarker1875"/>server. Jaeger basically exposes some services that collect and graphically display what's happening in our application. The basic<a id="_idIndexMarker1876"/> concept is a <strong class="bold">span</strong>, which is an end-to-end method call. In our case, one <strong class="bold">span</strong> is made out of our REST call, and another one is the sub-call in our injected service.</p>
			<p>A quick way to test our service locally is to use a ready-made Jaeger server containerized.</p>
			<p>On a laptop with a container engine (such as Docker) installed, it's enough to run the following command:</p>
			<p class="source-code">sudo docker run -p 5775:5775/udp -p 6831:6831/udp -p </p>
			<p class="source-code">6832:6832/udp -p 5778:5778 -p 16686:16686 -p 14268:14268 </p>
			<p class="source-code">jaegertracing/all-in-one:latest</p>
			<p>This will run a <strong class="source-inline">jaegertracing</strong> <em class="italic">all-in-one</em> image, specifying the ports used.</p>
			<p>We can then run our application, hooking it into a Jaeger server:</p>
			<p class="source-code">./mvnw compile quarkus:dev -Djvm.args="-</p>
			<p class="source-code">DJAEGER_SERVICE_NAME=testservice -</p>
			<p class="source-code">DJAEGER_SAMPLER_TYPE=const -DJAEGER_SAMPLER_PARAM=1"</p>
			<p>These parameters are provided as command-line arguments but could also be provided as part of the properties file. In this case, we are specifying how this service is called and which kind of sampling should be done (it's okay to use the default parameters for the purposes of this test).</p>
			<p>Now, we can invoke our REST service a couple of times at <strong class="source-inline">http://127.0.0.1:8080/trace</strong>, just to generate some traffic to display. If we then navigate to the Jaeger UI, available by default at <strong class="source-inline">http://localhost:16686/</strong>, we will see something<a id="_idIndexMarker1877"/> similar (click on the <strong class="bold">Find Traces</strong> button and select the <strong class="bold">test-opentracing</strong> service, if necessary):</p>
			<div>
				<div id="_idContainer130" class="IMG---Figure">
					<img src="image/Figure_14.2_B16354_new.jpg" alt="Figure 14.2 – Jaeger UI home&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 14.2 – Jaeger UI home</p>
			<p>As you can<a id="_idIndexMarker1878"/> see, each of the calls made to our service is displayed with the overall time to respond (a couple of milliseconds, in our example).</p>
			<p>If we click on one of those calls, we can see the two spans:</p>
			<div>
				<div id="_idContainer131" class="IMG---Figure">
					<img src="image/Figure_14.3_B16354_new.jpg" alt="Figure 14.3 – Jaeger UI spans&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 14.3 – Jaeger UI spans</p>
			<p>As you can see, the main span concerns the REST call with a smaller span on the sub-call of the injected service. It's easy to imagine how useful it is to have this kind of information on an application running in production.</p>
			<p>As you can see, in this <a id="_idIndexMarker1879"/>example, we have just one microservice with two methods. However, the<a id="_idIndexMarker1880"/> same concept can be easily extended to more than one microservice talking to each other.</p>
			<p>Tracing and metrics are part of a bigger concept called <strong class="bold">Application Performance Management</strong> (<strong class="bold">APM</strong>).</p>
			<h1 id="_idParaDest-330"><a id="_idTextAnchor332"/>Application Performance Management </h1>
			<p>APM is a <a id="_idIndexMarker1881"/>broad and very important aspect of running an application in production. It involves a lot of different technologies, and sometimes it has some unknowns around log aggregation, metrics collection, and overall monitoring, among other things.</p>
			<p>Each vendor or stack of monitoring technologies has slightly different comprehensions of what APM is about, and somewhat different implementations of it as a result.</p>
			<p>I think that it's good to start from the goal: the goal of APM is to have insights into how a set of applications is performing, and what impact the underlying parameters (such as memory usage, database metrics, and more) have on the end user experience (such as user interface responsiveness, response times, and so on).</p>
			<p>It is easy to understand that to implement such a useful (and broad) goal, you may need to stack a number of different tools and frameworks.</p>
			<p>We have seen some of this in the previous section: you may want to have information coming from logs (to understand what the application is doing), together with metrics (to understand the resource consumption and collect other KPIs such as the number of calls), with health checks (to have a quick view over which service is up), and with tracing (to understand how each specific call is performed, including all the sub-calls).</p>
			<p>And there are a number of other tools that you can use. As an example, JVM provides some useful parameters (we saw some when discussing metrics) such as memory and CPU consumption.</p>
			<p>Last but not least, for code that is not natively instrumented (such as legacy code that is not providing metrics using frameworks similar to the one seen previously), it is possible to collect some metrics using some more invasive approaches, such as Java agents, which are low-level configurations that act on the JVM to understand how and when each method of our code is called.</p>
			<p>With that said, you<a id="_idIndexMarker1882"/> can imagine how hard it can be to provide a unified, easy-to-read, overall vision of what's happening with our application. You will need to install and maintain a lot of different tools and glue them together in order to display meaningful and uniform information.</p>
			<p>For this reason, aside<a id="_idIndexMarker1883"/> from open<a id="_idIndexMarker1884"/> source standards and tools, commercial solutions have emerged (such as <strong class="bold">Dynatrace</strong>, <strong class="bold">Datadog</strong>, and <strong class="bold">Splunk</strong>), which <a id="_idIndexMarker1885"/>allow us to use ready-made stacks to provide such information.</p>
			<p>But now that it is clear how important and useful it is to have this kind of information, let's look at some<a id="_idIndexMarker1886"/> topics to be aware of when talking about APM:</p>
			<ul>
				<li><strong class="bold">It may impact performance</strong>: Many of the approaches seen so far have been designed to have as little impact as possible by using asynchronous and non-blocking techniques. However, especially if we use older approaches such as Java agents, the impact can be significant. And if you think that an APM system might be useful when your application is slow, it's easy to understand that APM must be as lightweight as possible, to avoid putting any further pressure on systems that are already requested.</li>
				<li><strong class="bold">It requires nontrivial maintenance</strong>: The data collected can simply be huge in quantity. Think about every transaction generating a bunch of metrics (timing, error codes, resources consumed), plus a number of lines of logs and tracing information. When all these metrics are multiplied by hundreds or thousands of transactions, it may become difficult to maintain them. Plus, as said, each specific type of information you might want to look for (logs, metrics, and checks) is managed by a different stack, hence we may end up using different servers, storage, and configurations.</li>
				<li><strong class="bold">The information collected may be hard to correlate</strong>: Especially in the event of an issue, you may want to understand whether a specific transaction caused the issue and how the system behaved. While tracing makes it easy to correlate a transaction with each sub-call and subsystem, correlating tracing information with logging information plus metrics and health checks will still be trouble. Moreover, comparing<a id="_idIndexMarker1887"/> different kinds of data (such as timespans with KPIs and messages) can be hard, especially in user interfaces.</li>
			</ul>
			<p>Last but not least, it's crucial to correlate the platform information with the related features implemented. In the next section, we are going to look a bit more into what kind of information is worth collecting, and how to categorize it.</p>
			<h1 id="_idParaDest-331"><a id="_idTextAnchor333"/>Service monitoring</h1>
			<p>A very <a id="_idIndexMarker1888"/>important consideration is what to monitor.</p>
			<p>Indeed, it's very important to collect as much data as possible, in terms of metrics and KPIs, as they may reveal interesting trends, and can be very useful if something unpredicted happens. But at the same time, business users are mostly interested in different kinds of metrics and information, such as the number of transactions per second (or per hour, or per day), the amount of money that passes through the platform, the number of concurrent users, and so on.</p>
			<p>Hence, there are two different <a id="_idIndexMarker1889"/>kinds of KPIs to look for, sometimes with a blurred boundary between them:</p>
			<ul>
				<li><strong class="bold">Technical information</strong>: Things<a id="_idIndexMarker1890"/> such as the memory used, the number of threads, the number of connections, and so on. These things are useful for sizing and scaling systems and trying to forecast whether our system will perform well or some interventions are needed.</li>
				<li><strong class="bold">Business information</strong>: Defining <a id="_idIndexMarker1891"/>what information is business information heavily depends on the application realm, but usually includes the average transaction time, the number of concurrent users, the number of new users, and so on.</li>
			</ul>
			<p>From a technical standpoint, you can use the same frameworks (especially ones for collecting metrics) in order to collect both technical and business information.</p>
			<p>But it's very important (and not so easy to do) to try to correlate one kind of metric with another.</p>
			<p>In other words, it <a id="_idIndexMarker1892"/>could be useful to have a map (even simple documentation such as a web page can be enough) that documents where each feature is hosted, and how specific business information is related to a set of technical information.</p>
			<p>Let's look at an example: if we have a business KPI about the transaction time of a specific functionality, it is important to understand which servers provide that functionality, and which specific set of microservices (or applications) implements it.</p>
			<p>In this way, you can link a<a id="_idIndexMarker1893"/> business metric (such as the transaction time) to a set of technical metrics (such as the memory used by a number of JVMs, used threads, CPU consumption on the servers that are running such JVMs, and more).</p>
			<p>By doing<a id="_idIndexMarker1894"/> that, you can better correlate a change in performance in that particular feature (in our case, transactions going slower) to a specific subset of technical information (such as an increase in CPU usage on one particular server). </p>
			<p>This will help in troubleshooting and quickly fixing production issues (by scaling the resources on impacted systems).</p>
			<p>Other than this, business metrics are simply valuable for some users: they may be used for forecasting the economic performance of the platform, the expected growth, and similar parameters. For this reason, it's common to store such information on specific data stores (such as big data or data lakes), where they can be correlated with other information, which is analyzed and further studied. </p>
			<p>This completes the topics that were planned for this chapter. </p>
			<h1 id="_idParaDest-332"><a id="_idTextAnchor334"/>Summary</h1>
			<p>In this chapter, we have looked at some interesting considerations about monitoring and tracing our applications. </p>
			<p>We started by reviewing some basic concepts about logging in Java, and why log aggregation is a good thing to do in microservices and cloud-native applications. We then moved on to the concept of metrics and health checks, and how applications can provide data in real time on the performance and health of our modules. </p>
			<p>We then discussed tracing, which is very important when it comes to troubleshooting and managing distributed applications (such as microservices applications). APM was the next topic and is about putting all the information together (such as metrics, health checks, and logs) to create an overview of the application insights.</p>
			<p>Last but not least, we saw how service monitoring involves linking business information with the technical KPIs behind it, to support troubleshooting and draw more insights from the collected data.</p>
			<p>In the next chapter, we are going to see what's new in the latest version of the Java technology.</p>
			<h1 id="_idParaDest-333"><a id="_idTextAnchor335"/>Further reading</h1>
			<ul>
				<li>Hanif Jetha, <em class="italic">How To Set Up an Elasticsearch, Fluentd and Kibana (EFK) Logging Stack on Kubernetes </em>(<a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-an-elasticsearch-fluentd-and-kibana-efk-logging-stack-on-kubernetes">https://www.digitalocean.com/community/tutorials/how-to-set-up-an-elasticsearch-fluentd-and-kibana-efk-logging-stack-on-kubernetes</a>)</li>
				<li>Himanshu Shukla, <em class="italic">#Microservices : Observability Patterns</em> (<a href="mailto:https://medium.com/@greekykhs/microservices-observability-patterns-eff92365e2a8">https://medium.com/@greekykhs/microservices-observability-patterns-eff92365e2a8</a>)</li>
				<li><em class="italic">MicroProfile Metrics</em> (<a href="https://download.eclipse.org/microprofile/microprofile-metrics-2.3/microprofile-metrics-spec-2.3.html">https://download.eclipse.org/microprofile/microprofile-metrics-2.3/microprofile-metrics-spec-2.3.html</a>)</li>
				<li><em class="italic">The OpenTracing project </em>(<a href="https://opentracing.io/">https://opentracing.io/</a>)</li>
			</ul>
		</div>
	</body></html>