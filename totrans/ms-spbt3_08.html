<html><head></head><body>
<div id="_idContainer060">
<h1 class="chapter-number" id="_idParaDest-171"><a id="_idTextAnchor233"/><span class="koboSpan" id="kobo.1.1">8</span></h1>
<h1 id="_idParaDest-172"><a id="_idTextAnchor234"/><span class="koboSpan" id="kobo.2.1">Exploring Event-Driven Systems with Kafka</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In this chapter, we will delve into the mechanics of creating an event-driven system using Kafka and Spring Boot. </span><span class="koboSpan" id="kobo.3.2">Here, we’ll discover how to configure Kafka and ZooKeeper on your computer using Docker, laying the foundation for developing microservices that can seamlessly communicate through events. </span><span class="koboSpan" id="kobo.3.3">You’ll get hands-on experience with building two Spring Boot applications: one for generating events and the other for consuming them, simulating the functions of a sender and receiver in a </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">messaging framework.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">The ultimate aim of this chapter is to equip you with the skills to design, deploy, and monitor an </span><strong class="bold"><span class="koboSpan" id="kobo.6.1">event-driven architecture</span></strong><span class="koboSpan" id="kobo.7.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.8.1">EDA</span></strong><span class="koboSpan" id="kobo.9.1">) that harnesses the capabilities of Kafka</span><a id="_idIndexMarker571"/><span class="koboSpan" id="kobo.10.1"> combined with the simplicity of Spring Boot. </span><span class="koboSpan" id="kobo.10.2">This knowledge is not crucial for your progress in this book’s journey but invaluable in real-world scenarios where scalable and responsive systems are not just preferred </span><span class="No-Break"><span class="koboSpan" id="kobo.11.1">but expected.</span></span></p>
<p><span class="koboSpan" id="kobo.12.1">Mastering these principles and tools is essential for creating applications that are adaptable, scalable, and capable of meeting the evolving demands of contemporary software environments. </span><span class="koboSpan" id="kobo.12.2">By the conclusion of this chapter, you will have an event-driven setup on your local machine, boosting your confidence to tackle more </span><span class="No-Break"><span class="koboSpan" id="kobo.13.1">complex systems.</span></span></p>
<p><span class="koboSpan" id="kobo.14.1">The following are the main topics of this chapter that </span><span class="No-Break"><span class="koboSpan" id="kobo.15.1">you’ll explore:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.16.1">Introduction to </span><span class="No-Break"><span class="koboSpan" id="kobo.17.1">event-driven architecture</span></span></li>
<li><span class="koboSpan" id="kobo.18.1">Setting up Kafka and ZooKeeper for </span><span class="No-Break"><span class="koboSpan" id="kobo.19.1">local development</span></span></li>
<li><span class="koboSpan" id="kobo.20.1">Building an event-driven application with Spring </span><span class="No-Break"><span class="koboSpan" id="kobo.21.1">Boot messaging</span></span></li>
<li><span class="koboSpan" id="kobo.22.1">Monitoring </span><span class="No-Break"><span class="koboSpan" id="kobo.23.1">event-driven systems</span></span></li>
</ul>
<h1 id="_idParaDest-173"><a id="_idTextAnchor235"/><span class="koboSpan" id="kobo.24.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.25.1">For this chapter, we are going to need to configure some settings on our </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">local machines:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.27.1">Java Development Kit 17</span></strong><span class="koboSpan" id="kobo.28.1"> (</span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.29.1">JDK 17</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">)</span></span></li>
<li><span class="koboSpan" id="kobo.31.1">A modern </span><strong class="bold"><span class="koboSpan" id="kobo.32.1">integrated development environment</span></strong><span class="koboSpan" id="kobo.33.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.34.1">IDE</span></strong><span class="koboSpan" id="kobo.35.1">); I recommend </span><span class="No-Break"><span class="koboSpan" id="kobo.36.1">IntelliJ IDEA</span></span></li>
<li><span class="koboSpan" id="kobo.37.1">You can clone all repositories related to </span><a href="B18400_08.xhtml#_idTextAnchor233"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.38.1">Chapter 8</span></em></span></a><span class="koboSpan" id="kobo.39.1"> from the GitHub repository </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">here: </span></span><a href="https://github.com/PacktPublishing/Mastering-Spring-Boot-3.0/"><span class="No-Break"><span class="koboSpan" id="kobo.41.1">https://github.com/PacktPublishing/Mastering-Spring-Boot-3.0/</span></span></a></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.42.1">Docker Desktop</span></span></li>
</ul>
<h1 id="_idParaDest-174"><a id="_idTextAnchor236"/><span class="koboSpan" id="kobo.43.1">Introduction to event-driven architecture</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.44.1">Event-driven architecture</span></strong><span class="koboSpan" id="kobo.45.1">, also known as </span><strong class="bold"><span class="koboSpan" id="kobo.46.1">EDA</span></strong><span class="koboSpan" id="kobo.47.1">, is a design approach</span><a id="_idIndexMarker572"/><span class="koboSpan" id="kobo.48.1"> widely used in software development. </span><span class="koboSpan" id="kobo.48.2">It focuses more on triggering actions based on events than following a strict step-by-step process. </span><span class="koboSpan" id="kobo.48.3">In EDA, when a specific event occurs, the system reacts promptly by carrying out the action or series of actions. </span><span class="koboSpan" id="kobo.48.4">This method differs from models that rely on request-response patterns and offers a more dynamic and real-time </span><span class="No-Break"><span class="koboSpan" id="kobo.49.1">system behavior.</span></span></p>
<p><span class="koboSpan" id="kobo.50.1">EDA is significant in the era we’re living in where data is constantly being generated and updated. </span><span class="koboSpan" id="kobo.50.2">The ability to promptly respond to changes is invaluable in such a fast-paced environment. </span><span class="koboSpan" id="kobo.50.3">EDA empowers businesses to seize opportunities and address challenges swiftly compared to conventional systems. </span><span class="koboSpan" id="kobo.50.4">This agility</span><a id="_idIndexMarker573"/><span class="koboSpan" id="kobo.51.1"> is particularly crucial in industries such as finance, real-time analytics, the </span><strong class="bold"><span class="koboSpan" id="kobo.52.1">Internet of Things</span></strong><span class="koboSpan" id="kobo.53.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.54.1">IoT</span></strong><span class="koboSpan" id="kobo.55.1">), and other areas where rapid changes occur frequently and the timeliness of information </span><span class="No-Break"><span class="koboSpan" id="kobo.56.1">holds importance.</span></span></p>
<p><span class="koboSpan" id="kobo.57.1">Moving to EDA can significantly change</span><a id="_idIndexMarker574"/><span class="koboSpan" id="kobo.58.1"> how a company functions, offering the </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">following benefits:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.60.1">Responsiveness</span></strong><span class="koboSpan" id="kobo.61.1">: By handling events in real time, event-driven systems offer immediate feedback or action, which is crucial for </span><span class="No-Break"><span class="koboSpan" id="kobo.62.1">time-sensitive tasks.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.63.1">Scalability</span></strong><span class="koboSpan" id="kobo.64.1">: Event-driven setups can manage a number of events without causing delays in processing. </span><span class="koboSpan" id="kobo.64.2">This scalability is important for businesses dealing with increasing data volume </span><span class="No-Break"><span class="koboSpan" id="kobo.65.1">and complexity.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.66.1">Flexibility</span></strong><span class="koboSpan" id="kobo.67.1">: As components in EDA are loosely connected, they can be updated or replaced independently without impacting the system. </span><span class="koboSpan" id="kobo.67.2">This flexibility makes upgrades and the integration of </span><span class="No-Break"><span class="koboSpan" id="kobo.68.1">features simpler.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.69.1">Efficiency</span></strong><span class="koboSpan" id="kobo.70.1">: Minimizing the need for checking for new data through polling or querying reduces resource consumption, improving overall </span><span class="No-Break"><span class="koboSpan" id="kobo.71.1">system efficiency.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.72.1">Enhanced user experience</span></strong><span class="koboSpan" id="kobo.73.1">: In applications requiring real-time information, such as gaming and live updates, EDA contributes</span><a id="_idIndexMarker575"/><span class="koboSpan" id="kobo.74.1"> to providing a dynamic </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">user experience.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.76.1">These benefits highlight why many organizations are moving toward EDA to meet the demands of modern </span><span class="No-Break"><span class="koboSpan" id="kobo.77.1">technological challenges.</span></span></p>
<p><span class="koboSpan" id="kobo.78.1">In EDA, we need a </span><strong class="bold"><span class="koboSpan" id="kobo.79.1">message broker</span></strong><span class="koboSpan" id="kobo.80.1">. </span><span class="koboSpan" id="kobo.80.2">A message broker helps us to distribute</span><a id="_idIndexMarker576"/><span class="koboSpan" id="kobo.81.1"> the message between the components. </span><span class="koboSpan" id="kobo.81.2">In this chapter, we will use Apache Kafka as a message broker. </span><span class="koboSpan" id="kobo.81.3">Kafka is an open source stream-processing platform. </span><span class="koboSpan" id="kobo.81.4">It was initially developed by LinkedIn and later donated to the Apache Software Foundation. </span><span class="koboSpan" id="kobo.81.5">Kafka primarily functions as a message broker adept at handling substantial data </span><span class="No-Break"><span class="koboSpan" id="kobo.82.1">volumes efficiently.</span></span></p>
<p><span class="koboSpan" id="kobo.83.1">Its design features facilitate durable</span><a id="_idIndexMarker577"/><span class="koboSpan" id="kobo.84.1"> message storage and high-throughput event processing for effective EDA implementations. </span><span class="koboSpan" id="kobo.84.2">This platform allows distributed data streams to be consumed in time, making it an optimal solution for applications requiring extensive data-processing and </span><span class="No-Break"><span class="koboSpan" id="kobo.85.1">transfer capabilities.</span></span></p>
<p><span class="koboSpan" id="kobo.86.1">With Kafka, developers can seamlessly transfer data between components of an event-driven system, ensuring the preservation of event integrity and order even in complex transaction scenarios. </span><span class="koboSpan" id="kobo.86.2">This feature positions Kafka as a component in the architecture of many modern high-performance applications that rely on real-time </span><span class="No-Break"><span class="koboSpan" id="kobo.87.1">data processing.</span></span></p>
<p><span class="koboSpan" id="kobo.88.1">Now that we have a grasp of what EDA entails and the benefits it brings, along with understanding Kafka’s role in such systems, we will go through the process of setting up Kafka on Docker. </span><span class="koboSpan" id="kobo.88.2">This setup creates a controlled and reproducible environment for the exploration of Kafka’s capabilities within EDA. </span><span class="koboSpan" id="kobo.88.3">Our aim is to equip you with the tools and knowledge to deploy Kafka efficiently, enabling you to harness the potential of real-time data processing in </span><span class="No-Break"><span class="koboSpan" id="kobo.89.1">your projects.</span></span></p>
<p><span class="koboSpan" id="kobo.90.1">By mastering the deployment</span><a id="_idIndexMarker578"/><span class="koboSpan" id="kobo.91.1"> of Kafka using Docker, you will acquire the experience essential for comprehending and managing the intricacies of event-driven systems. </span><span class="koboSpan" id="kobo.91.2">This hands-on approach not only reinforces theoretical concepts but also readies you to effectively handle </span><span class="No-Break"><span class="koboSpan" id="kobo.92.1">real-world applications.</span></span></p>
<h1 id="_idParaDest-175"><a id="_idTextAnchor237"/><span class="koboSpan" id="kobo.93.1">Setting up Kafka and ZooKeeper for local development</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.94.1">Kafka</span></strong><span class="koboSpan" id="kobo.95.1"> plays a role in an event-driven system, facilitating</span><a id="_idIndexMarker579"/><span class="koboSpan" id="kobo.96.1"> smooth communication among different components. </span><span class="koboSpan" id="kobo.96.2">It enables services to communicate through message exchange, like how people use messaging apps to stay connected. </span><span class="koboSpan" id="kobo.96.3">This architecture promotes the development of scalable applications by allowing various parts of the system to function autonomously and respond promptly to events. </span><span class="koboSpan" id="kobo.96.4">We will also mention Kafka and its role in the </span><em class="italic"><span class="koboSpan" id="kobo.97.1">Understanding Kafka brokers and their role in event-driven systems</span></em><span class="koboSpan" id="kobo.98.1"> section in </span><span class="No-Break"><span class="koboSpan" id="kobo.99.1">more detail.</span></span></p>
<p><span class="koboSpan" id="kobo.100.1">However, Kafka</span><a id="_idIndexMarker580"/><span class="koboSpan" id="kobo.101.1"> doesn’t work alone; it collaborates with </span><strong class="bold"><span class="koboSpan" id="kobo.102.1">ZooKeeper</span></strong><span class="koboSpan" id="kobo.103.1">, which serves as its overseer. </span><span class="koboSpan" id="kobo.103.2">ZooKeeper monitors Kafka’s brokers to ensure they’re functioning. </span><span class="koboSpan" id="kobo.103.3">Think of it as having a coordinator who assigns tasks and ensures operations. </span><span class="koboSpan" id="kobo.103.4">ZooKeeper is essential for managing the background processes that uphold Kafka’s stability and reliability during </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">peak loads.</span></span></p>
<p><span class="koboSpan" id="kobo.105.1">After talking about the components we need, I will also mention the installation. </span><span class="koboSpan" id="kobo.105.2">We will use Docker as we did in previous chapters. </span><span class="koboSpan" id="kobo.105.3">Docker simplifies the setup of Kafka and ZooKeeper on your machine. </span><span class="koboSpan" id="kobo.105.4">It provides a portable version of the entire configuration that you can easily launch whenever </span><span class="No-Break"><span class="koboSpan" id="kobo.106.1">needed, hassle-free.</span></span></p>
<p><span class="koboSpan" id="kobo.107.1">This method of setting up Kafka and ZooKeeper isn’t just for convenience; it’s also about ensuring that you can explore, create, and test your event-driven systems without having to worry about intricate installation procedures or variations between setups. </span><span class="koboSpan" id="kobo.107.2">As we delve into the steps of setting up Kafka and ZooKeeper using Docker, remember that this forms the groundwork. </span><span class="koboSpan" id="kobo.107.3">You’re establishing an adaptable infrastructure for your applications—one that will facilitate effective communication and seamless scalability. </span><span class="koboSpan" id="kobo.107.4">Let’s proceed and get your local development environment ready </span><span class="No-Break"><span class="koboSpan" id="kobo.108.1">for EDA.</span></span></p>
<h2 id="_idParaDest-176"><a id="_idTextAnchor238"/><span class="koboSpan" id="kobo.109.1">Understanding Kafka brokers and their role in event-driven systems</span></h2>
<p><span class="koboSpan" id="kobo.110.1">In the changing world of EDA, </span><strong class="bold"><span class="koboSpan" id="kobo.111.1">Kafka brokers</span></strong><span class="koboSpan" id="kobo.112.1"> serve as efficient hubs carefully</span><a id="_idIndexMarker581"/><span class="koboSpan" id="kobo.113.1"> managing the reception</span><a id="_idIndexMarker582"/><span class="koboSpan" id="kobo.114.1"> routing and delivery of messages to their designated destinations. </span><span class="koboSpan" id="kobo.114.2">Within the Kafka ecosystem, a Kafka broker plays a role as part of a group of brokers that work together to oversee message traffic. </span><span class="koboSpan" id="kobo.114.3">In simple terms, imagine these brokers as diligent postal workers handling the messages from producers and organizing them into topics similar to specific mailboxes or addresses. </span><span class="koboSpan" id="kobo.114.4">These topics can be divided into sections to facilitate scalable </span><span class="No-Break"><span class="koboSpan" id="kobo.115.1">message processing.</span></span></p>
<p><span class="koboSpan" id="kobo.116.1">Let’s see how a Kafka cluster</span><a id="_idIndexMarker583"/><span class="koboSpan" id="kobo.117.1"> works in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.118.1">Figure 8</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.119.1">.1</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.120.1">.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer055">
<span class="koboSpan" id="kobo.121.1"><img alt="Figure 8.1: Kafka cluster architecture" src="image/B18400_08_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.122.1">Figure 8.1: Kafka cluster architecture</span></p>
<p><span class="koboSpan" id="kobo.123.1">In this diagram, you can see how Kafka organizes its workflow. </span><span class="koboSpan" id="kobo.123.2">Producers are the sources that send data to the Kafka system. </span><span class="koboSpan" id="kobo.123.3">They push messages into the Kafka cluster, which consists of multiple brokers (</span><strong class="bold"><span class="koboSpan" id="kobo.124.1">Broker 1</span></strong><span class="koboSpan" id="kobo.125.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.126.1">Broker 2</span></strong><span class="koboSpan" id="kobo.127.1">, and </span><strong class="bold"><span class="koboSpan" id="kobo.128.1">Broker 3</span></strong><span class="koboSpan" id="kobo.129.1">). </span><span class="koboSpan" id="kobo.129.2">These brokers store the messages and make them available for consumption. </span><span class="koboSpan" id="kobo.129.3">ZooKeeper acts as the manager of this cluster, keeping track of the state of brokers and performing other coordination tasks. </span><span class="koboSpan" id="kobo.129.4">Consumer groups, labeled </span><strong class="bold"><span class="koboSpan" id="kobo.130.1">Group-A</span></strong><span class="koboSpan" id="kobo.131.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.132.1">Group-B</span></strong><span class="koboSpan" id="kobo.133.1">, pull messages from the brokers depending on </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">their needs.</span></span></p>
<p><span class="koboSpan" id="kobo.135.1">The true magic of Kafka brokers lies in their adeptness at managing these topic sections. </span><span class="koboSpan" id="kobo.135.2">When a message arrives, the broker determines where to place it within a section based on criteria such as its importance level. </span><span class="koboSpan" id="kobo.135.3">This method ensures a distribution of messages and groups similar ones (those sharing common attributes) in one section. </span><span class="koboSpan" id="kobo.135.4">This partitioning process is essential for distributing workloads and enables consumer applications to process messages concurrently for more streamlined </span><span class="No-Break"><span class="koboSpan" id="kobo.136.1">data handling.</span></span></p>
<p><span class="koboSpan" id="kobo.137.1">Furthermore, another critical function of Kafka brokers is ensuring message duplication across the Kafka system, safeguarding against data loss in case of broker malfunctions. </span><span class="koboSpan" id="kobo.137.2">This duplication process acts as a safety measure by creating copies of sections across different brokers. </span><span class="koboSpan" id="kobo.137.3">If a broker goes offline, another can step in, smoothly keeping the system strong </span><span class="No-Break"><span class="koboSpan" id="kobo.138.1">and flexible.</span></span></p>
<p><span class="koboSpan" id="kobo.139.1">Brokers are skilled at storing and providing messages for consumers. </span><span class="koboSpan" id="kobo.139.2">They use offsets to track which messages consumers have read, allowing consumers to resume right where they left off in the message stream. </span><span class="koboSpan" id="kobo.139.3">This ensures that every message is handled and gives consumers the flexibility to manage messages at their </span><span class="No-Break"><span class="koboSpan" id="kobo.140.1">own pace.</span></span></p>
<p><span class="koboSpan" id="kobo.141.1">The orchestration of messages in a Kafka cluster, overseen by brokers, is a process that combines efficiency with reliability. </span><span class="koboSpan" id="kobo.141.2">This intricate coordination carried out by brokers enables event-driven systems to function efficiently, managing large amounts of data with precision. </span><span class="koboSpan" id="kobo.141.3">By utilizing the features of Kafka brokers, developers can create systems that are not only scalable and resilient but also capable of processing messages swiftly and accurately to meet the demands of today’s fast-paced </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">digital landscape.</span></span></p>
<p><span class="koboSpan" id="kobo.143.1">As we further explore the aspects of setting up and using Kafka, the role of brokers as the foundation for reliable and efficient message distribution becomes increasingly clear. </span><span class="koboSpan" id="kobo.143.2">Their ability to handle and direct</span><a id="_idIndexMarker584"/><span class="koboSpan" id="kobo.144.1"> messages serves as the core</span><a id="_idIndexMarker585"/><span class="koboSpan" id="kobo.145.1"> of any EDA, ensuring that information is delivered accurately to its intended destination </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">on time.</span></span></p>
<h2 id="_idParaDest-177"><a id="_idTextAnchor239"/><span class="koboSpan" id="kobo.147.1">Running Kafka and ZooKeeper with Docker</span></h2>
<p><span class="koboSpan" id="kobo.148.1">Running Kafka</span><a id="_idIndexMarker586"/><span class="koboSpan" id="kobo.149.1"> and ZooKeeper </span><a id="_idIndexMarker587"/><span class="koboSpan" id="kobo.150.1">on your computer</span><a id="_idIndexMarker588"/><span class="koboSpan" id="kobo.151.1"> through Docker</span><a id="_idIndexMarker589"/><span class="koboSpan" id="kobo.152.1"> can be a game-changer for developers. </span><span class="koboSpan" id="kobo.152.2">It streamlines what was once a setup process into something simple and easy to handle. </span><span class="koboSpan" id="kobo.152.3">Docker containers serve as transportable spaces that can be swiftly initiated, halted, and deleted, making them ideal for development and testing purposes. </span><span class="koboSpan" id="kobo.152.4">This arrangement enables you to recreate a production-level environment on your machine without the need for setup or </span><span class="No-Break"><span class="koboSpan" id="kobo.153.1">specialized hardware.</span></span></p>
<p><span class="koboSpan" id="kobo.154.1">You will be familiar with Docker Compose</span><a id="_idIndexMarker590"/><span class="koboSpan" id="kobo.155.1"> since we have used it in almost</span><a id="_idIndexMarker591"/><span class="koboSpan" id="kobo.156.1"> all the previous</span><a id="_idIndexMarker592"/><span class="koboSpan" id="kobo.157.1"> chapters. </span><span class="koboSpan" id="kobo.157.2">We will use Docker Compose </span><a id="_idIndexMarker593"/><span class="koboSpan" id="kobo.158.1">to run both services with a single command. </span><span class="koboSpan" id="kobo.158.2">Here’s a simple </span><strong class="source-inline"><span class="koboSpan" id="kobo.159.1">docker-compose.yml</span></strong><span class="koboSpan" id="kobo.160.1"> file example that sets up Kafka </span><span class="No-Break"><span class="koboSpan" id="kobo.161.1">and ZooKeeper:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.162.1">
version: '2'
services:
  zookeeper:
    image: zookeeper
    ports:
      - "2181:2181"
    networks:
      - kafka-network
  kafka:
    image: confluentinc/cp-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - kafka-network
networks:
  kafka-network:
    driver: bridge</span></pre> <p><span class="koboSpan" id="kobo.163.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.164.1">docker-compose.yml</span></strong><span class="koboSpan" id="kobo.165.1"> file is like a recipe</span><a id="_idIndexMarker594"/><span class="koboSpan" id="kobo.166.1"> that tells Docker</span><a id="_idIndexMarker595"/><span class="koboSpan" id="kobo.167.1"> exactly how to run</span><a id="_idIndexMarker596"/><span class="koboSpan" id="kobo.168.1"> your Kafka</span><a id="_idIndexMarker597"/><span class="koboSpan" id="kobo.169.1"> and ZooKeeper containers. </span><span class="koboSpan" id="kobo.169.2">It tells Docker which images to use, how the containers should talk to each other on a network, which ports to open, and what environment variables to set. </span><span class="koboSpan" id="kobo.169.3">In this file, we have told Docker to run ZooKeeper on port </span><strong class="source-inline"><span class="koboSpan" id="kobo.170.1">2181</span></strong><span class="koboSpan" id="kobo.171.1"> and Kafka on port </span><strong class="source-inline"><span class="koboSpan" id="kobo.172.1">9092</span></strong><span class="koboSpan" id="kobo.173.1">. </span><span class="koboSpan" id="kobo.173.2">Using this file, we streamline the whole process, making it as easy as pressing a button to get your setup running. </span><span class="koboSpan" id="kobo.173.3">It’s a brilliant tool for developers, cutting down on the manual steps and letting you focus on the fun part—building and experimenting with your </span><span class="No-Break"><span class="koboSpan" id="kobo.174.1">event-driven applications.</span></span></p>
<p><span class="koboSpan" id="kobo.175.1">Save this file as </span><strong class="source-inline"><span class="koboSpan" id="kobo.176.1">docker-compose.yml</span></strong><span class="koboSpan" id="kobo.177.1"> and run it using </span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">this command:</span></span></p>
<pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.179.1">docker-compose up -d</span></strong></pre> <p><span class="koboSpan" id="kobo.180.1">This command pulls the necessary Docker images, creates the containers, and starts Kafka and ZooKeeper in detached mode, leaving them running in </span><span class="No-Break"><span class="koboSpan" id="kobo.181.1">the background.</span></span></p>
<p><span class="koboSpan" id="kobo.182.1">By following these steps, you’ve just set up a robust, scalable messaging backbone for your applications to build upon. </span><span class="koboSpan" id="kobo.182.2">This foundation not only supports the development of event-driven systems but also paves the way for experimenting with Kafka’s powerful features in a controlled </span><span class="No-Break"><span class="koboSpan" id="kobo.183.1">local environment.</span></span></p>
<p><span class="koboSpan" id="kobo.184.1">Finishing our exploration of configuring Kafka using Docker, it’s evident how this pairing removes the obstacles in running Kafka on your computer. </span><span class="koboSpan" id="kobo.184.2">Docker’s container magic has turned what might have been a laborious task into a straightforward process, allowing you to concentrate more on the creative aspects of developing applications rather than getting caught up in setup intricacies. </span><span class="koboSpan" id="kobo.184.3">This simplified setup isn’t only about convenience; it’s also about democratizing technology and simplifying its management, empowering developers to experiment and innovate with EDA without dealing with overly </span><span class="No-Break"><span class="koboSpan" id="kobo.185.1">complicated configurations.</span></span></p>
<p><span class="koboSpan" id="kobo.186.1">As we shift from the aspects</span><a id="_idIndexMarker598"/><span class="koboSpan" id="kobo.187.1"> of setting up Kafka and ZooKeeper to delving into the exciting realm</span><a id="_idIndexMarker599"/><span class="koboSpan" id="kobo.188.1"> of constructing an event-driven application</span><a id="_idIndexMarker600"/><span class="koboSpan" id="kobo.189.1"> using Spring Boot</span><a id="_idIndexMarker601"/><span class="koboSpan" id="kobo.190.1"> messaging, we’re transitioning from laying the groundwork for infrastructure to engaging in the artistry of application design. </span><span class="koboSpan" id="kobo.190.2">In this section, you’ll witness firsthand how your Kafka setup empowers you as we walk you through the creation of applications that generate and consume messages with Spring Boot. </span><span class="koboSpan" id="kobo.190.3">This is where abstract concepts materialize into creations allowing you to fully leverage the capabilities of </span><span class="No-Break"><span class="koboSpan" id="kobo.191.1">event-driven systems.</span></span></p>
<h1 id="_idParaDest-178"><a id="_idTextAnchor240"/><span class="koboSpan" id="kobo.192.1">Building an event-driven application with Spring Boot messaging</span></h1>
<p><span class="koboSpan" id="kobo.193.1">Crafting an event-driven application</span><a id="_idIndexMarker602"/><span class="koboSpan" id="kobo.194.1"> using Spring Boot</span><a id="_idIndexMarker603"/><span class="koboSpan" id="kobo.195.1"> involves building a system that’s responsive, scalable, and equipped to handle the complexities of modern software requirements. </span><span class="koboSpan" id="kobo.195.2">Essentially, an event-driven application responds to events, ranging from user interactions to messages from external systems. </span><span class="koboSpan" id="kobo.195.3">This methodology enables components of your application to interact and operate independently, enhancing flexibility and efficiency. </span><span class="koboSpan" id="kobo.195.4">With Spring Boot, setting up such an application is made easier due to its philosophy of convention over configuration and the array of tools it provides from </span><span class="No-Break"><span class="koboSpan" id="kobo.196.1">the start.</span></span></p>
<p><span class="koboSpan" id="kobo.197.1">Throughout this journey, we will take a hands-on approach by introducing two Spring Boot projects—one will focus on generating events while the other will concentrate on consuming them. </span><span class="koboSpan" id="kobo.197.2">This segregation mirrors real-life scenarios where producers and consumers are often located in systems or microservices highlighting the decentralized nature of contemporary applications. </span><span class="koboSpan" id="kobo.197.3">By working on these projects, you will gain experience in configuring a producer for sending messages and a consumer for reacting to those messages, within the context of Spring Boot and Kafka. </span><span class="koboSpan" id="kobo.197.4">This method not only strengthens your comprehension of event-driven systems but also equips you with the resources needed to create and enhance your own </span><span class="No-Break"><span class="koboSpan" id="kobo.198.1">scalable applications.</span></span></p>
<p><span class="koboSpan" id="kobo.199.1">As we move forward, we’ll dive into the details of creating a Spring Boot project for Kafka integration. </span><span class="koboSpan" id="kobo.199.2">This will establish the foundation</span><a id="_idIndexMarker604"/><span class="koboSpan" id="kobo.200.1"> for our event-based applications, walking you through the process of configuring </span><a id="_idIndexMarker605"/><span class="koboSpan" id="kobo.201.1">a Spring Boot project to send and receive messages using Kafka. </span><span class="koboSpan" id="kobo.201.2">You’ll gain insights into the settings, libraries, and initial code structures required to kick start the implementation. </span><span class="koboSpan" id="kobo.201.3">Here is where our theoretical ideas transform into executable code. </span><span class="koboSpan" id="kobo.201.4">So, let’s get started and embark on this journey of developing robust interactive applications with Spring Boot </span><span class="No-Break"><span class="koboSpan" id="kobo.202.1">and Kafka.</span></span></p>
<h2 id="_idParaDest-179"><a id="_idTextAnchor241"/><span class="koboSpan" id="kobo.203.1">Creating a Spring Boot project for Kafka integration</span></h2>
<p><span class="koboSpan" id="kobo.204.1">Starting a project in Spring Boot</span><a id="_idIndexMarker606"/><span class="koboSpan" id="kobo.205.1"> that is specifically tailored for integrating</span><a id="_idIndexMarker607"/><span class="koboSpan" id="kobo.206.1"> with Kafka is the practical step toward unlocking the capabilities of event-driven applications. </span><span class="koboSpan" id="kobo.206.2">This step combines the ease and adaptability of Spring Boot with the messaging features of Kafka, allowing developers to create scalable and agile applications. </span><span class="koboSpan" id="kobo.206.3">Through this integration, we are establishing a base that facilitates communication and the management of large data volumes and operations in a distributed setting. </span><span class="koboSpan" id="kobo.206.4">The objective is to establish a framework that addresses message production and consumption requirements while also seamlessly expanding as the </span><span class="No-Break"><span class="koboSpan" id="kobo.207.1">application evolves.</span></span></p>
<p><span class="koboSpan" id="kobo.208.1">We will need two different projects to demonstrate the consumer and producer. </span><span class="koboSpan" id="kobo.208.2">So, you will need to follow the same steps twice to create the two projects. </span><span class="koboSpan" id="kobo.208.3">But it would be better to choose a different name when entering the project metadata in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.209.1">step 2</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.210.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.211.1">In </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.212.1">Figure 8</span></em></span><em class="italic"><span class="koboSpan" id="kobo.213.1">.2</span></em><span class="koboSpan" id="kobo.214.1">, we can see how our applications will communicate with </span><span class="No-Break"><span class="koboSpan" id="kobo.215.1">each other.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer056">
<span class="koboSpan" id="kobo.216.1"><img alt="Figure 8.2: How our apps communicate with each other" src="image/B18400_08_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.217.1">Figure 8.2: How our apps communicate with each other</span></p>
<p><span class="koboSpan" id="kobo.218.1">As you can see in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.219.1">Figure 8</span></em></span><em class="italic"><span class="koboSpan" id="kobo.220.1">.2</span></em><span class="koboSpan" id="kobo.221.1">, there is no direct call between the producer application and the consumer application. </span><span class="koboSpan" id="kobo.221.2">The producer application sends a message</span><a id="_idIndexMarker608"/><span class="koboSpan" id="kobo.222.1"> to Kafka and Kafka publishes this message</span><a id="_idIndexMarker609"/><span class="koboSpan" id="kobo.223.1"> to the </span><span class="No-Break"><span class="koboSpan" id="kobo.224.1">consumer application.</span></span></p>
<p><span class="koboSpan" id="kobo.225.1">Here is a step-by-step guide to creating a Spring </span><span class="No-Break"><span class="koboSpan" id="kobo.226.1">Boot project:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.227.1">Navigate to Spring Initializr (</span><a href="https://start.spring.io/"><span class="koboSpan" id="kobo.228.1">https://start.spring.io/</span></a><span class="koboSpan" id="kobo.229.1">) to bootstrap your</span><a id="_idIndexMarker610"/><span class="koboSpan" id="kobo.230.1"> project. </span><span class="koboSpan" id="kobo.230.2">It’s an online tool that lets you generate a Spring Boot project with your chosen </span><span class="No-Break"><span class="koboSpan" id="kobo.231.1">dependencies quickly.</span></span></li>
<li><span class="koboSpan" id="kobo.232.1">Enter your project’s metadata, such as </span><strong class="bold"><span class="koboSpan" id="kobo.233.1">Group</span></strong><span class="koboSpan" id="kobo.234.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.235.1">Artifact</span></strong><span class="koboSpan" id="kobo.236.1">, and </span><strong class="bold"><span class="koboSpan" id="kobo.237.1">Description</span></strong><span class="koboSpan" id="kobo.238.1">. </span><span class="koboSpan" id="kobo.238.2">Give different names for consumer and producer projects. </span><span class="koboSpan" id="kobo.238.3">Choose either </span><strong class="bold"><span class="koboSpan" id="kobo.239.1">Maven</span></strong><span class="koboSpan" id="kobo.240.1"> or </span><strong class="bold"><span class="koboSpan" id="kobo.241.1">Gradle</span></strong><span class="koboSpan" id="kobo.242.1"> as your build tool according to your preference. </span><span class="koboSpan" id="kobo.242.2">In our example, we will </span><span class="No-Break"><span class="koboSpan" id="kobo.243.1">use </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.244.1">Gradle</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.245.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.246.1">Select your dependencies. </span><span class="koboSpan" id="kobo.246.2">For a Kafka project, you need to add </span><strong class="bold"><span class="koboSpan" id="kobo.247.1">Spring for Apache Kafka</span></strong><span class="koboSpan" id="kobo.248.1"> under the </span><strong class="bold"><span class="koboSpan" id="kobo.249.1">Messaging</span></strong><span class="koboSpan" id="kobo.250.1"> category. </span><span class="koboSpan" id="kobo.250.2">We need to add </span><strong class="source-inline"><span class="koboSpan" id="kobo.251.1">Spring Web </span></strong><span class="koboSpan" id="kobo.252.1">for the producer project. </span><span class="koboSpan" id="kobo.252.2">This dependency includes the necessary libraries to integrate Kafka with </span><span class="No-Break"><span class="koboSpan" id="kobo.253.1">Spring Boot.</span></span></li>
<li><span class="koboSpan" id="kobo.254.1">Generate the project. </span><span class="koboSpan" id="kobo.254.2">Once you’ve filled</span><a id="_idIndexMarker611"/><span class="koboSpan" id="kobo.255.1"> in all the details and selected</span><a id="_idIndexMarker612"/><span class="koboSpan" id="kobo.256.1"> your dependencies, click on </span><strong class="bold"><span class="koboSpan" id="kobo.257.1">Generate</span></strong><span class="koboSpan" id="kobo.258.1"> to download your </span><span class="No-Break"><span class="koboSpan" id="kobo.259.1">project template.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.260.1">In </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.261.1">Figure 8</span></em></span><em class="italic"><span class="koboSpan" id="kobo.262.1">.3</span></em><span class="koboSpan" id="kobo.263.1">, we can see which dependencies we need and how to configure </span><span class="No-Break"><span class="koboSpan" id="kobo.264.1">Spring Initializr.</span></span></p></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer057">
<span class="koboSpan" id="kobo.265.1"><img alt="Figure 8.3: Screenshot of Spring Initialzr" src="image/B18400_08_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.266.1">Figure 8.3: Screenshot of Spring Initialzr</span></p>
<ol>
<li value="5"><span class="koboSpan" id="kobo.267.1">Extract the downloaded ZIP file and open the project in your favorite IDE, such as IntelliJ IDEA, Eclipse, or </span><span class="No-Break"><span class="koboSpan" id="kobo.268.1">VS Code.</span></span></li>
<li><span class="koboSpan" id="kobo.269.1">Update the </span><strong class="source-inline"><span class="koboSpan" id="kobo.270.1">application.properties</span></strong><span class="koboSpan" id="kobo.271.1"> file using the following line. </span><span class="koboSpan" id="kobo.271.2">Use different ports for consumer and </span><span class="No-Break"><span class="koboSpan" id="kobo.272.1">publisher projects:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.273.1">
server.port:8181</span></pre></li> </ol>
<p><span class="koboSpan" id="kobo.274.1">When integrating Kafka</span><a id="_idIndexMarker613"/><span class="koboSpan" id="kobo.275.1"> with a Spring Boot project, a key component is </span><strong class="bold"><span class="koboSpan" id="kobo.276.1">Spring Kafka</span></strong><span class="koboSpan" id="kobo.277.1">, which is added by Spring Initializr as Spring for Apache Kafka. </span><span class="koboSpan" id="kobo.277.2">This library simplifies the handling of messaging solutions based on Kafka by providing a user abstraction. </span><span class="koboSpan" id="kobo.277.3">It streamlines the process of sending and receiving messages between your Spring Boot application and Kafka brokers. </span><span class="koboSpan" id="kobo.277.4">By abstracting the complexities of producer and consumer configurations, it enables you to focus on implementing business logic rather than dealing with repetitive code for </span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">message handling.</span></span></p>
<p><span class="koboSpan" id="kobo.279.1">With your Spring Boot project configured and essential Kafka integration dependencies in place, you are now ready to delve into the details of producing and consuming messages. </span><span class="koboSpan" id="kobo.279.2">This setup serves as a starting point for exploring communication and EDAs, offering an effective approach to managing data flow in </span><span class="No-Break"><span class="koboSpan" id="kobo.280.1">your applications.</span></span></p>
<p><span class="koboSpan" id="kobo.281.1">Moving on to building the producer application</span><a id="_idIndexMarker614"/><span class="koboSpan" id="kobo.282.1"> in the next subsection marks</span><a id="_idIndexMarker615"/><span class="koboSpan" id="kobo.283.1"> a shift from setup to implementation. </span><span class="koboSpan" id="kobo.283.2">Here, we will guide you through setting up a Kafka producer within your Spring Boot project. </span><span class="koboSpan" id="kobo.283.3">This is where all your foundational work begins to take shape, allowing you to send messages to Kafka topics and kickstart the communication process for any event-driven system. </span><span class="koboSpan" id="kobo.283.4">Get ready to translate theory into action and witness how your application can engage </span><span class="No-Break"><span class="koboSpan" id="kobo.284.1">with Kafka.</span></span></p>
<h2 id="_idParaDest-180"><a id="_idTextAnchor242"/><span class="koboSpan" id="kobo.285.1">Building the producer application</span></h2>
<p><span class="koboSpan" id="kobo.286.1">Creating the producer application</span><a id="_idIndexMarker616"/><span class="koboSpan" id="kobo.287.1"> is like establishing a broadcasting hub within your event-based framework, where your Spring Boot setup is all set to dispatch messages out to the world—or, precisely, to a Kafka topic. </span><span class="koboSpan" id="kobo.287.2">This stage holds importance as it marks the beginning of information flow within your system, ensuring that data reaches its intended destination at the </span><span class="No-Break"><span class="koboSpan" id="kobo.288.1">right moment.</span></span></p>
<p><span class="koboSpan" id="kobo.289.1">Creating a Kafka producer in Spring Boot involves a few straightforward steps. </span><span class="koboSpan" id="kobo.289.2">First, you need to configure your application to connect to Kafka. </span><span class="koboSpan" id="kobo.289.3">This is done in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.290.1">application.properties</span></strong><span class="koboSpan" id="kobo.291.1"> file in your producer Spring Boot project. </span><span class="koboSpan" id="kobo.291.2">You’ll specify details such as the Kafka server’s address and the default topic to which you want to </span><span class="No-Break"><span class="koboSpan" id="kobo.292.1">send messages.</span></span></p>
<p><span class="koboSpan" id="kobo.293.1">Here’s how we will implement a Kafka producer in a Spring </span><span class="No-Break"><span class="koboSpan" id="kobo.294.1">Boot application:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.295.1">
@RestController
public class EventProducerController {
    private final KafkaTemplate&lt;String, String&gt; kafkaTemplate;
    @Autowired
    public EventProducerController(KafkaTemplate&lt;String, String&gt; kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }
    @GetMapping("/message/{message}")
    public String trigger(@PathVariable String message) {
        kafkaTemplate.send("messageTopic", message);
        return "Hello, Your message has been published: " + message;
    }
}</span></pre> <p><span class="koboSpan" id="kobo.296.1">In this code, </span><strong class="source-inline"><span class="koboSpan" id="kobo.297.1">KafkaTemplate</span></strong><span class="koboSpan" id="kobo.298.1"> is a Spring-provided</span><a id="_idIndexMarker617"/><span class="koboSpan" id="kobo.299.1"> class that simplifies sending messages to a Kafka topic. </span><span class="koboSpan" id="kobo.299.2">We inject this template into our </span><strong class="source-inline"><span class="koboSpan" id="kobo.300.1">MessageProducer</span></strong><span class="koboSpan" id="kobo.301.1"> service and use its </span><strong class="source-inline"><span class="koboSpan" id="kobo.302.1">send</span></strong><span class="koboSpan" id="kobo.303.1"> method to publish messages. </span><span class="koboSpan" id="kobo.303.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.304.1">send</span></strong><span class="koboSpan" id="kobo.305.1"> method takes two parameters—the name of the topic and the </span><span class="No-Break"><span class="koboSpan" id="kobo.306.1">message itself.</span></span></p>
<p><span class="koboSpan" id="kobo.307.1">To ensure your producer application can successfully send messages to Kafka, you’ll need to add some configurations to your </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.308.1">application.properties</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.309.1"> file:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.310.1">
spring.kafka.bootstrap-servers=localhost:9092
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer</span></pre> <p><span class="koboSpan" id="kobo.311.1">These configurations help Spring Boot identify the location of your Kafka server (Bootstrap servers) and how to convert the messages into a format for transmission over the network (key serializer and value serializer). </span><span class="koboSpan" id="kobo.311.2">Serialization involves converting your message, in this case, a string, into a format that can be transmitted over </span><span class="No-Break"><span class="koboSpan" id="kobo.312.1">the network.</span></span></p>
<p><span class="koboSpan" id="kobo.313.1">By setting up and configuring your Kafka producer, you have taken a step toward developing an event-driven application. </span><span class="koboSpan" id="kobo.313.2">This configuration allows your application to initiate conversations within your distributed system by sending out messages that other parts of your system can respond to </span><span class="No-Break"><span class="koboSpan" id="kobo.314.1">and handle.</span></span></p>
<p><span class="koboSpan" id="kobo.315.1">Moving forward, let’s shift our focus to the counterpart of this interaction: building the consumer application. </span><span class="koboSpan" id="kobo.315.2">This involves creating listeners that anticipate and react to messages dispatched by our producer. </span><span class="koboSpan" id="kobo.315.3">It plays a role in closing the communication loop within our EDA, transforming our system into a dynamic network of services capable of responding to real-time data. </span><span class="koboSpan" id="kobo.315.4">Let’s proceed with our exploration and uncover how we can unleash the potential</span><a id="_idIndexMarker618"/><span class="koboSpan" id="kobo.316.1"> of </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">event-driven applications.</span></span></p>
<h2 id="_idParaDest-181"><a id="_idTextAnchor243"/><span class="koboSpan" id="kobo.318.1">Building the consumer application</span></h2>
<p><span class="koboSpan" id="kobo.319.1">Once we’ve got our broadcasting station</span><a id="_idIndexMarker619"/><span class="koboSpan" id="kobo.320.1"> set up using our producer application, it’s time to tune to the correct frequency by developing the consumer application. </span><span class="koboSpan" id="kobo.320.2">This step ensures that the messages sent out by the producer aren’t just lost in space but are actually received, understood, and put into action. </span><span class="koboSpan" id="kobo.320.3">In our event-driven structure, the consumer application acts like a listener in a crowd catching signals meant for it and handling them accordingly. </span><span class="koboSpan" id="kobo.320.4">By incorporating a Kafka consumer into a Spring Boot application, we establish an element that eagerly waits for messages and is prepared to process them as soon as they come through. </span><span class="koboSpan" id="kobo.320.5">This ability plays a role in creating systems that are truly interactive and can respond promptly to changes and events in </span><span class="No-Break"><span class="koboSpan" id="kobo.321.1">real time.</span></span></p>
<p><span class="koboSpan" id="kobo.322.1">To set up a Kafka consumer in Spring Boot, you first need</span><a id="_idIndexMarker620"/><span class="koboSpan" id="kobo.323.1"> to configure your application to listen to the Kafka topics of interest. </span><span class="koboSpan" id="kobo.323.2">This involves specifying in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.324.1">application.properties</span></strong><span class="koboSpan" id="kobo.325.1"> file where your Kafka server is located and which topics your application should </span><span class="No-Break"><span class="koboSpan" id="kobo.326.1">subscribe to.</span></span></p>
<p><span class="koboSpan" id="kobo.327.1">Here’s how we will implement a Kafka consumer in our Spring </span><span class="No-Break"><span class="koboSpan" id="kobo.328.1">Boot application:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.329.1">
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;
@Component
public class MessageConsumer {
    @KafkaListener(topics = "messageTopic", groupId = "consumer_1_id")
    public void listen(String message) {
        System.out.println("Received message: " + message);
    }
}</span></pre> <p><span class="koboSpan" id="kobo.330.1">In this snippet, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.331.1">@KafkaListener</span></strong><span class="koboSpan" id="kobo.332.1"> annotation marks the </span><strong class="source-inline"><span class="koboSpan" id="kobo.333.1">listen</span></strong><span class="koboSpan" id="kobo.334.1"> method as a listener for messages on </span><strong class="source-inline"><span class="koboSpan" id="kobo.335.1">messageTopic</span></strong><span class="koboSpan" id="kobo.336.1">. </span><span class="koboSpan" id="kobo.336.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.337.1">groupId</span></strong><span class="koboSpan" id="kobo.338.1"> is used by Kafka to group consumers that should be considered as a single unit. </span><span class="koboSpan" id="kobo.338.2">This setup allows your application to automatically pick up and process messages from the </span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">specified topic.</span></span></p>
<p><span class="koboSpan" id="kobo.340.1">To make sure your consumer application consumes messages efficiently, add the following configurations to your </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.341.1">application.properties</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.342.1"> file:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.343.1">
spring.kafka.bootstrap-servers=localhost:9092
spring.kafka.consumer.group-id= consumer_1_id
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer</span></pre> <p><span class="koboSpan" id="kobo.344.1">These configurations make sure your user connects to the Kafka server (Bootstrap servers) and properly decodes the messages it receives (key deserializer and value deserializer). </span><span class="koboSpan" id="kobo.344.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.345.1">auto-offset-reset</span></strong><span class="koboSpan" id="kobo.346.1"> option guides Kafka on where to begin reading messages if there’s no offset for your users group; by setting it to </span><strong class="source-inline"><span class="koboSpan" id="kobo.347.1">earliest</span></strong><span class="koboSpan" id="kobo.348.1">, our application will start to consume from the beginning of the </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">event topic.</span></span></p>
<p><span class="koboSpan" id="kobo.350.1">Once your consumer application is active, your event-driven system is now fully operational, capable of both sending and receiving messages through the Kafka messaging pipeline. </span><span class="koboSpan" id="kobo.350.2">This two-way communication framework lays the foundation for scalable applications that can handle real-time data streams and respond promptly to events as </span><span class="No-Break"><span class="koboSpan" id="kobo.351.1">they occur.</span></span></p>
<p><span class="koboSpan" id="kobo.352.1">Looking forward, the next critical step involves testing</span><a id="_idIndexMarker621"/><span class="koboSpan" id="kobo.353.1"> both the producer and consumer applications to ensure their integration. </span><span class="koboSpan" id="kobo.353.2">This phase bridges theory with practice, allowing you to witness the outcomes of your efforts. </span><span class="koboSpan" id="kobo.353.3">Testing serves not only to verify individual component functionalities but also to validate the overall responsiveness and efficiency of the system. </span><span class="koboSpan" id="kobo.353.4">Let’s progress by initiating tests on our event-driven applications, ensuring they’re primed to manage any challenges that </span><span class="No-Break"><span class="koboSpan" id="kobo.354.1">may arise.</span></span></p>
<h2 id="_idParaDest-182"><a id="_idTextAnchor244"/><span class="koboSpan" id="kobo.355.1">Testing the whole stack – bringing your event-driven architecture to life</span></h2>
<p><span class="koboSpan" id="kobo.356.1">After configuring our event-based system</span><a id="_idIndexMarker622"/><span class="koboSpan" id="kobo.357.1"> using Kafka, Spring Boot, and Docker, we reach a pivotal moment as we test the entire setup to witness our system in operation. </span><span class="koboSpan" id="kobo.357.2">This critical stage confirms that our separate elements, the producer and consumer applications, are properly set up and communicating as intended while also ensuring that Kafka, managed by Docker, effectively transmits messages between them. </span><span class="koboSpan" id="kobo.357.3">This testing phase represents the culmination of our work, allowing us to directly observe the dynamic exchange of messages that serves as the core of any </span><span class="No-Break"><span class="koboSpan" id="kobo.358.1">event-driven system.</span></span></p>
<p><span class="koboSpan" id="kobo.359.1">Here are the instructions to run the </span><span class="No-Break"><span class="koboSpan" id="kobo.360.1">whole stack:</span></span></p>
<ol>
<li><strong class="bold"><span class="koboSpan" id="kobo.361.1">Docker Compose for Kafka and ZooKeeper</span></strong><span class="koboSpan" id="kobo.362.1">: Begin by starting Kafka and ZooKeeper using Docker Compose. </span><span class="koboSpan" id="kobo.362.2">Navigate to the directory containing your </span><strong class="source-inline"><span class="koboSpan" id="kobo.363.1">docker-compose.yml</span></strong><span class="koboSpan" id="kobo.364.1"> file that defines the Kafka and ZooKeeper services and run </span><span class="No-Break"><span class="koboSpan" id="kobo.365.1">the following:</span></span><pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.366.1">docker-compose up -d</span></strong></pre><p class="list-inset"><span class="koboSpan" id="kobo.367.1">This command starts Kafka and ZooKeeper in detached mode, setting the stage for </span><span class="No-Break"><span class="koboSpan" id="kobo.368.1">message brokering.</span></span></p></li> <li><strong class="bold"><span class="koboSpan" id="kobo.369.1">Running the producer application</span></strong><span class="koboSpan" id="kobo.370.1">: Launch your producer Spring Boot</span><a id="_idIndexMarker623"/><span class="koboSpan" id="kobo.371.1"> application, ensuring it runs on port </span><strong class="source-inline"><span class="koboSpan" id="kobo.372.1">8282</span></strong><span class="koboSpan" id="kobo.373.1">. </span><span class="koboSpan" id="kobo.373.2">This can be configured in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.374.1">application.properties</span></strong><span class="koboSpan" id="kobo.375.1"> file with the </span><span class="No-Break"><span class="koboSpan" id="kobo.376.1">following line:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.377.1">
server.port=8282</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.378.1">Start the application through your IDE or by running </span><strong class="source-inline"><span class="koboSpan" id="kobo.379.1">./gradlew bootRun</span></strong><span class="koboSpan" id="kobo.380.1"> in the terminal within the </span><span class="No-Break"><span class="koboSpan" id="kobo.381.1">project directory.</span></span></p></li> <li><strong class="bold"><span class="koboSpan" id="kobo.382.1">Running the consumer Spring Boot application</span></strong><span class="koboSpan" id="kobo.383.1">: Similarly, launch the consumer application, configured to run on port </span><strong class="source-inline"><span class="koboSpan" id="kobo.384.1">8181</span></strong><span class="koboSpan" id="kobo.385.1">, by setting this in its </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.386.1">application.properties</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.387.1"> file:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.388.1">
server.port=8181</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.389.1">Use your IDE or the </span><strong class="source-inline"><span class="koboSpan" id="kobo.390.1">Gradle</span></strong><span class="koboSpan" id="kobo.391.1"> command as with the producer to start the </span><span class="No-Break"><span class="koboSpan" id="kobo.392.1">consumer application.</span></span></p></li> <li><strong class="bold"><span class="koboSpan" id="kobo.393.1">Trigger message publishing</span></strong><span class="koboSpan" id="kobo.394.1">: With both applications running, it’s time to send messages. </span><span class="koboSpan" id="kobo.394.2">Use your web browser or a tool such as cURL to make </span><strong class="source-inline"><span class="koboSpan" id="kobo.395.1">GET</span></strong><span class="koboSpan" id="kobo.396.1"> requests to the producer’s </span><span class="No-Break"><span class="koboSpan" id="kobo.397.1">message-triggering endpoint:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.398.1">
http://localhost:8282/message/hello-world</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.399.1">Replace </span><strong class="source-inline"><span class="koboSpan" id="kobo.400.1">hello-world</span></strong><span class="koboSpan" id="kobo.401.1"> with any string you wish to send as a message. </span><span class="koboSpan" id="kobo.401.2">Trigger a few different messages to test </span><span class="No-Break"><span class="koboSpan" id="kobo.402.1">various scenarios.</span></span></p></li> <li><strong class="bold"><span class="koboSpan" id="kobo.403.1">Observe the consumer’s log</span></strong><span class="koboSpan" id="kobo.404.1">: Switch to the console or log output of your consumer application. </span><span class="koboSpan" id="kobo.404.2">You should see the messages logged as they are consumed, indicating successful communication from the producer, through Kafka, to the consumer. </span><span class="koboSpan" id="kobo.404.3">The output will be </span><span class="No-Break"><span class="koboSpan" id="kobo.405.1">as follows:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.406.1">
Received message: hello-world
Received message: hello-world-2
Received message: hello-world-3</span></pre></li> </ol>
<p><span class="koboSpan" id="kobo.407.1">Successfully running the test stack and observing the flow of messages from the producer to the consumer via Kafka is an invaluable experience because it showcases the power and flexibility of EDAs. </span><span class="koboSpan" id="kobo.407.2">This hands-on testing not only increases your understanding of integrating Kafka with Spring Boot applications but also highlights the importance of seamless communication in distributed systems. </span><span class="koboSpan" id="kobo.407.3">As you’ve seen, Docker plays a pivotal role in simplifying the setup for development and testing environments. </span><span class="koboSpan" id="kobo.407.4">After this practical experience, you are ready to delve into sophisticated and scalable event-driven applications, which are requested in modern </span><span class="No-Break"><span class="koboSpan" id="kobo.408.1">software developments.</span></span></p>
<p><span class="koboSpan" id="kobo.409.1">Now, with a fully functional event-driven application</span><a id="_idIndexMarker624"/><span class="koboSpan" id="kobo.410.1"> in hand, it’s time to look ahead. </span><span class="koboSpan" id="kobo.410.2">The next step is ensuring our application not only runs but succeeds under various conditions. </span><span class="koboSpan" id="kobo.410.3">This means diving into monitoring—a vital component of any application’s life cycle. </span><span class="koboSpan" id="kobo.410.4">In the upcoming section, we’ll explore how to keep a keen eye on our application’s performance and how to swiftly address any issues that arise. </span><span class="koboSpan" id="kobo.410.5">This knowledge will help not only in maintaining the health of our application but also in optimizing its efficiency and reliability. </span><span class="koboSpan" id="kobo.410.6">So, let’s move forward, ready to tackle these new challenges </span><span class="No-Break"><span class="koboSpan" id="kobo.411.1">with confidence.</span></span></p>
<h1 id="_idParaDest-183"><a id="_idTextAnchor245"/><span class="koboSpan" id="kobo.412.1">Monitoring event-driven systems</span></h1>
<p><span class="koboSpan" id="kobo.413.1">In the dynamic world of event-driven systems, where applications</span><a id="_idIndexMarker625"/><span class="koboSpan" id="kobo.414.1"> communicate through a constant flow of messages, monitoring plays a crucial role in ensuring everything runs smoothly. </span><span class="koboSpan" id="kobo.414.2">Just as a busy airport needs air traffic control to keep planes moving safely and efficiently, an EDA relies on monitoring to maintain the health and performance of its components. </span><span class="koboSpan" id="kobo.414.3">This oversight is vital for spotting when things go wrong and understanding the overall system behavior under various loads and conditions. </span><span class="koboSpan" id="kobo.414.4">It enables developers and operations teams to make informed decisions, optimize performance, and prevent issues before they </span><span class="No-Break"><span class="koboSpan" id="kobo.415.1">impact users.</span></span></p>
<p><span class="koboSpan" id="kobo.416.1">For applications built with Kafka and Spring Boot, a robust set of monitoring tools and techniques is essential for keeping an eye on the system’s pulse. </span><span class="koboSpan" id="kobo.416.2">At its core, Kafka is designed to handle high volumes of data, making monitoring aspects such as message throughput, broker health, and consumer lag imperative. </span><span class="koboSpan" id="kobo.416.3">Tools such as Apache Kafka’s JMX metrics and external utilities such as Prometheus and Grafana offer deep insights into Kafka’s performance. </span><span class="koboSpan" id="kobo.416.4">These tools can track everything from the number of messages being processed to the time it takes to travel through </span><span class="No-Break"><span class="koboSpan" id="kobo.417.1">the system.</span></span></p>
<p><span class="koboSpan" id="kobo.418.1">As monitoring the Spring Boot application was covered in the </span><em class="italic"><span class="koboSpan" id="kobo.419.1">Spring Boot Actuator with Prometheus and Grafana</span></em><span class="koboSpan" id="kobo.420.1"> section of </span><a href="B18400_07.xhtml#_idTextAnchor213"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.421.1">Chapter 7</span></em></span></a><span class="koboSpan" id="kobo.422.1">, it won’t be covered here. </span><span class="koboSpan" id="kobo.422.2">We will only focus on monitoring</span><a id="_idIndexMarker626"/><span class="koboSpan" id="kobo.423.1"> Kafka in </span><span class="No-Break"><span class="koboSpan" id="kobo.424.1">this section.</span></span></p>
<h2 id="_idParaDest-184"><a id="_idTextAnchor246"/><span class="koboSpan" id="kobo.425.1">Monitoring your Kafka infrastructure</span></h2>
<p><span class="koboSpan" id="kobo.426.1">Monitoring your Kafka setup</span><a id="_idIndexMarker627"/><span class="koboSpan" id="kobo.427.1"> is like using a tool to closely examine the core functions of your event-driven system. </span><span class="koboSpan" id="kobo.427.2">It’s all about getting a view of how well your Kafka environment is running, which is crucial for identifying problems, optimizing resource usage, and ensuring messages are delivered on time and reliably. </span><span class="koboSpan" id="kobo.427.3">Given Kafka’s role in managing data streams and event processing, any issues or inefficiencies can impact the entire system. </span><span class="koboSpan" id="kobo.427.4">Therefore, establishing a monitoring system isn’t just helpful; it’s necessary for maintaining a strong and </span><span class="No-Break"><span class="koboSpan" id="kobo.428.1">efficient architecture.</span></span></p>
<p><span class="koboSpan" id="kobo.429.1">Here are the key</span><a id="_idIndexMarker628"/><span class="koboSpan" id="kobo.430.1"> metrics to monitor </span><span class="No-Break"><span class="koboSpan" id="kobo.431.1">in Kafka:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.432.1">Broker metrics</span></strong><span class="koboSpan" id="kobo.433.1">: These include the number of active brokers in your cluster and their health status. </span><span class="koboSpan" id="kobo.433.2">Monitoring the CPU, memory usage, and disk I/O of each broker helps in identifying </span><span class="No-Break"><span class="koboSpan" id="kobo.434.1">resource bottlenecks.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.435.1">Topic metrics</span></strong><span class="koboSpan" id="kobo.436.1">: Important metrics here include message in-rate, message out-rate, and the size of topics. </span><span class="koboSpan" id="kobo.436.2">Keeping an eye on these can help in understanding the flow of data and spotting any </span><span class="No-Break"><span class="koboSpan" id="kobo.437.1">unusual patterns.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.438.1">Consumer metrics</span></strong><span class="koboSpan" id="kobo.439.1">: Consumer lag, which indicates how far behind a consumer group is in processing messages, is critical for ensuring data is processed in a timely manner. </span><span class="koboSpan" id="kobo.439.2">Additionally, monitoring the number of active consumers can help with detecting issues with consumer scalability </span><span class="No-Break"><span class="koboSpan" id="kobo.440.1">and performance.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.441.1">Producer metrics</span></strong><span class="koboSpan" id="kobo.442.1">: Monitoring the rate of produced messages, along with error rates, can highlight issues</span><a id="_idIndexMarker629"/><span class="koboSpan" id="kobo.443.1"> in data generation or submission to </span><span class="No-Break"><span class="koboSpan" id="kobo.444.1">Kafka topics.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.445.1">We will use Kafka Manager (now known as </span><strong class="bold"><span class="koboSpan" id="kobo.446.1">CMAK</span></strong><span class="koboSpan" id="kobo.447.1">, or </span><strong class="bold"><span class="koboSpan" id="kobo.448.1">Cluster Manager for Apache Kafka</span></strong><span class="koboSpan" id="kobo.449.1">) to monitor our Kafka </span><a id="_idIndexMarker630"/><span class="koboSpan" id="kobo.450.1">server. </span><span class="koboSpan" id="kobo.450.2">Running CMAK in the same Docker Compose file as your Kafka and ZooKeeper setup is convenient for managing and monitoring your Kafka </span><span class="No-Break"><span class="koboSpan" id="kobo.451.1">cluster locally.</span></span></p>
<h2 id="_idParaDest-185"><a id="_idTextAnchor247"/><span class="koboSpan" id="kobo.452.1">Using CMAK to monitor the Kafka server</span></h2>
<p><span class="koboSpan" id="kobo.453.1">Here’s how you can include</span><a id="_idIndexMarker631"/><span class="koboSpan" id="kobo.454.1"> CMAK in your Docker Compose</span><a id="_idIndexMarker632"/><span class="koboSpan" id="kobo.455.1"> setup and get it running on your </span><span class="No-Break"><span class="koboSpan" id="kobo.456.1">local machine:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.457.1">To include CMAK in your existing Docker Compose setup, you’ll need to add a new service definition for it. </span><span class="koboSpan" id="kobo.457.2">Open your </span><strong class="source-inline"><span class="koboSpan" id="kobo.458.1">docker-compose.yml</span></strong><span class="koboSpan" id="kobo.459.1"> file and append the following </span><span class="No-Break"><span class="koboSpan" id="kobo.460.1">service definition:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.461.1">
  kafka-manager:
    image: hlebalbau/kafka-manager:latest
    depends_on:
      - zookeeper
      - kafka
    ports:
      - "9000:9000"
    environment:
      ZK_HOSTS: zookeeper:2181
    networks:
      - kafka-network</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.462.1">We have simply introduced the </span><strong class="source-inline"><span class="koboSpan" id="kobo.463.1">kafka-manager</span></strong><span class="koboSpan" id="kobo.464.1"> image in our </span><strong class="source-inline"><span class="koboSpan" id="kobo.465.1">docker-compose.yml</span></strong><span class="koboSpan" id="kobo.466.1"> file—CMAK depends on ZooKeeper and Kafka since it needs to monitor their performance, and it will serve on </span><span class="No-Break"><span class="koboSpan" id="kobo.467.1">port </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.468.1">9000</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.469.1">.</span></span></p></li> <li><span class="koboSpan" id="kobo.470.1">With your </span><strong class="source-inline"><span class="koboSpan" id="kobo.471.1">docker-compose.yml</span></strong><span class="koboSpan" id="kobo.472.1"> file updated, launch</span><a id="_idIndexMarker633"/><span class="koboSpan" id="kobo.473.1"> the services by running the following command</span><a id="_idIndexMarker634"/><span class="koboSpan" id="kobo.474.1"> in the terminal, in the directory containing your Docker </span><span class="No-Break"><span class="koboSpan" id="kobo.475.1">Compose file:</span></span><pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.476.1">docker compose up -d</span></strong></pre><p class="list-inset"><span class="koboSpan" id="kobo.477.1">This command pulls the necessary images and starts the ZooKeeper, Kafka, and Kafka Manager containers. </span><span class="koboSpan" id="kobo.477.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.478.1">-d</span></strong><span class="koboSpan" id="kobo.479.1"> flag runs them in detached mode, so they’ll run in </span><span class="No-Break"><span class="koboSpan" id="kobo.480.1">the background.</span></span></p></li> <li><span class="koboSpan" id="kobo.481.1">Once all the services are up and running, open a web browser and go to </span><strong class="source-inline"><span class="koboSpan" id="kobo.482.1">http://localhost:9000</span></strong><span class="koboSpan" id="kobo.483.1">. </span><span class="koboSpan" id="kobo.483.2">You should be greeted with the Kafka Manager (</span><span class="No-Break"><span class="koboSpan" id="kobo.484.1">CMAK) interface.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.485.1">To start monitoring your Kafka cluster with Kafka Manager, you’ll need to add your cluster to the Kafka </span><span class="No-Break"><span class="koboSpan" id="kobo.486.1">Manager UI.</span></span></p></li>
<li><span class="koboSpan" id="kobo.487.1">Click on the </span><strong class="bold"><span class="koboSpan" id="kobo.488.1">Add </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.489.1">Cluster</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.490.1"> button.</span></span></li>
<li><span class="koboSpan" id="kobo.491.1">Fill in the cluster information. </span><span class="koboSpan" id="kobo.491.2">For </span><strong class="bold"><span class="koboSpan" id="kobo.492.1">Cluster Zookeeper Hosts</span></strong><span class="koboSpan" id="kobo.493.1">, you can use </span><strong class="source-inline"><span class="koboSpan" id="kobo.494.1">zookeeper:2181</span></strong><span class="koboSpan" id="kobo.495.1"> if you’re running everything locally, and use the default ZooKeeper setup from your Docker Compose file. </span><span class="koboSpan" id="kobo.495.2">Note that since Kafka Manager is running in the same Docker network created by Docker Compose, it can resolve the ZooKeeper </span><span class="No-Break"><span class="koboSpan" id="kobo.496.1">hostname directly.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.497.1">In </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.498.1">Figure 8</span></em></span><em class="italic"><span class="koboSpan" id="kobo.499.1">.4</span></em><span class="koboSpan" id="kobo.500.1">, we can see how we can fill the form in by using the </span><strong class="bold"><span class="koboSpan" id="kobo.501.1">Add Cluster</span></strong><span class="koboSpan" id="kobo.502.1"> screen of </span><span class="No-Break"><span class="koboSpan" id="kobo.503.1">Kafka Manager.</span></span></p></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer058">
<span class="koboSpan" id="kobo.504.1"><img alt="Figure 8.4: Screenshot of the Add Cluster screen in the Kafka Manager application" src="image/B18400_08_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.505.1">Figure 8.4: Screenshot of the Add Cluster screen in the Kafka Manager application</span></p>
<ol>
<li value="6"><span class="koboSpan" id="kobo.506.1">Save your </span><span class="No-Break"><span class="koboSpan" id="kobo.507.1">cluster configuration.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.508.1">Now that your Kafka cluster </span><a id="_idIndexMarker635"/><span class="koboSpan" id="kobo.509.1">is added to Kafka</span><a id="_idIndexMarker636"/><span class="koboSpan" id="kobo.510.1"> Manager, you can explore various metrics and configurations, such as topic creation, topic listing, and </span><span class="No-Break"><span class="koboSpan" id="kobo.511.1">consumer groups.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer059">
<span class="koboSpan" id="kobo.512.1"><img alt="Figure 8.5: Kafka Manager screen for our topic" src="image/B18400_08_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.513.1">Figure 8.5: Kafka Manager screen for our topic</span></p>
<p><span class="koboSpan" id="kobo.514.1">In </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.515.1">Figure 8</span></em></span><em class="italic"><span class="koboSpan" id="kobo.516.1">.5</span></em><span class="koboSpan" id="kobo.517.1">, you can see a screenshot of the CMAK dashboard, which gives information about a specific Kafka topic called </span><strong class="source-inline"><span class="koboSpan" id="kobo.518.1">messageTopic</span></strong><span class="koboSpan" id="kobo.519.1">. </span><span class="koboSpan" id="kobo.519.2">The dashboard provides an overview including details on the topic’s replication factor, the number of partitions, and the total sum of partition offsets representing the total message count in the topic. </span><span class="koboSpan" id="kobo.519.3">Additionally, it offers controls to manage the topic, such as options to delete the topic, add partitions, or modify the topic’s configuration. </span><span class="koboSpan" id="kobo.519.4">The dashboard also presents insights into how partitions are distributed across brokers with metrics such as </span><strong class="bold"><span class="koboSpan" id="kobo.520.1">Preferred Replicas %</span></strong><span class="koboSpan" id="kobo.521.1"> and flags any skewed or under-replicated partitions, which are crucial for diagnosing and maintaining optimal health and balance within the </span><span class="No-Break"><span class="koboSpan" id="kobo.522.1">Kafka cluster.</span></span></p>
<p><span class="koboSpan" id="kobo.523.1">This setup allows you to manage and monitor your Kafka cluster locally with ease, providing a powerful interface for handling Kafka configurations and observing </span><span class="No-Break"><span class="koboSpan" id="kobo.524.1">cluster performance.</span></span></p>
<p><span class="koboSpan" id="kobo.525.1">Implementing a monitoring</span><a id="_idIndexMarker637"/><span class="koboSpan" id="kobo.526.1"> strategy that covers these key metrics</span><a id="_idIndexMarker638"/><span class="koboSpan" id="kobo.527.1"> and leveraging tools such as Kafka Manager can help you better understand your Kafka infrastructure. </span><span class="koboSpan" id="kobo.527.2">This not only aids in proactive maintenance and optimization but also prepares you to react swiftly and effectively to any issues </span><span class="No-Break"><span class="koboSpan" id="kobo.528.1">that arise.</span></span></p>
<p><span class="koboSpan" id="kobo.529.1">In a nutshell, effectively monitoring Kafka is essential for an event-driven system. </span><span class="koboSpan" id="kobo.529.2">It’s important to keep an eye on key metrics such as broker health, partition balance, message flow, and consumer lag. </span><span class="koboSpan" id="kobo.529.3">Tools such as CMAK, Prometheus, and Grafana not only simplify these tasks but also provide in-depth visibility and analysis to turn raw data into actionable insights. </span><span class="koboSpan" id="kobo.529.4">By monitoring, potential issues can be spotted and addressed before they become major problems, ensuring the smooth operation of the Kafka </span><span class="No-Break"><span class="koboSpan" id="kobo.530.1">messaging pipeline.</span></span></p>
<p><span class="koboSpan" id="kobo.531.1">A monitored event-driven system</span><a id="_idIndexMarker639"/><span class="koboSpan" id="kobo.532.1"> is equipped to handle the complexities</span><a id="_idIndexMarker640"/><span class="koboSpan" id="kobo.533.1"> of modern data streams and workload requirements. </span><span class="koboSpan" id="kobo.533.2">It ensures that every part of the system functions reliably, maintaining the performance needed for today’s applications. </span><span class="koboSpan" id="kobo.533.3">Ultimately, the strength of the systems lies in paying attention to operational details—where monitoring isn’t just a routine but a vital aspect of system health </span><span class="No-Break"><span class="koboSpan" id="kobo.534.1">and longevity.</span></span></p>
<h1 id="_idParaDest-186"><a id="_idTextAnchor248"/><span class="koboSpan" id="kobo.535.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.536.1">As we wrap up this chapter, let’s take a moment to look back on the journey we’ve shared. </span><span class="koboSpan" id="kobo.536.2">We’ve dived into the world of Kafka and Spring Boot, putting together each piece of our event-driven system. </span><span class="koboSpan" id="kobo.536.3">Here’s what </span><span class="No-Break"><span class="koboSpan" id="kobo.537.1">we accomplished:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.538.1">Setting up Kafka and ZooKeeper</span></strong><span class="koboSpan" id="kobo.539.1">: We set up Kafka and ZooKeeper on our local machines using Docker, creating a robust backbone for our </span><span class="No-Break"><span class="koboSpan" id="kobo.540.1">messaging system.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.541.1">Building Spring Boot applications</span></strong><span class="koboSpan" id="kobo.542.1">: We built two Spring Boot applications from scratch, one as an event producer and the other as a consumer, learning how they work together to form a </span><span class="No-Break"><span class="koboSpan" id="kobo.543.1">responsive EDA.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.544.1">Monitoring the Kafka infrastructure</span></strong><span class="koboSpan" id="kobo.545.1">: We learned the importance of monitoring our Kafka infrastructure, using tools such as CMAK to keep a watchful eye on the health and performance of </span><span class="No-Break"><span class="koboSpan" id="kobo.546.1">our system.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.547.1">The insights explored in this chapter aren’t just theoretical; they translate into abilities that you can promptly utilize in real-world scenarios. </span><span class="koboSpan" id="kobo.547.2">These competencies are essential for ensuring your systems function and remain resilient, empowering them to adapt to the ever-changing data landscape with agility. </span><span class="koboSpan" id="kobo.547.3">The capability to set up, integrate, and manage systems is indispensable in today’s rapidly evolving </span><span class="No-Break"><span class="koboSpan" id="kobo.548.1">tech arena.</span></span></p>
<p><span class="koboSpan" id="kobo.549.1">By continuing your learning journey with us, you’re not just acquiring tools for your skillset; you’re improving your development workflow, making it more seamless and effective. </span><span class="koboSpan" id="kobo.549.2">You’re also strengthening the durability and manageability of your applications, providing an edge in the competitive </span><span class="No-Break"><span class="koboSpan" id="kobo.550.1">technology sector.</span></span></p>
<p><span class="koboSpan" id="kobo.551.1">As we move forward to the next chapter, we’ll delve into the details of advanced Spring Boot features that enhance your development process. </span><span class="koboSpan" id="kobo.551.2">You’ll discover the art of aspect-oriented programming for organizing code, leverage the Feign client for seamless HTTP API integration, and harness the capabilities of Spring Boot’s sophisticated auto-configuration features. </span><span class="koboSpan" id="kobo.551.3">The next chapter focuses on simplifying your tasks as a developer, making them more efficient and productive. </span><span class="koboSpan" id="kobo.551.4">Let’s move ahead together and expand our </span><span class="No-Break"><span class="koboSpan" id="kobo.552.1">knowledge further.</span></span></p>
</div>
</body></html>