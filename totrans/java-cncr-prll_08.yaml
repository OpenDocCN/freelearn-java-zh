- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices in the Cloud and Java’s Concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In today’s fast-evolving digital landscape, microservices have emerged as a
    game-changing architectural style, enabling organizations to enhance scalability,
    flexibility, and deployment speeds. Java, with its robust ecosystem and powerful
    concurrency tools, stands at the forefront of this transformation, facilitating
    the seamless integration of microservices into cloud environments. This chapter
    delves into how Java’s advanced features empower developers to build, deploy,
    and scale microservices more efficiently, making it an ideal choice for modern
    cloud-based applications.
  prefs: []
  type: TYPE_NORMAL
- en: By embracing Java-powered microservices, businesses can break down complex applications
    into manageable, independently deployable components that are tailored to specific
    business functions. This modularity not only accelerates development cycles but
    also improves system resilience and maintenance. Furthermore, Java’s concurrency
    utilities play a crucial role in optimizing these services to handle vast scales
    of operations with ease, ensuring high availability and responsiveness across
    distributed systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following key topics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Principles of microservices in the cloud**: Understand the architectural
    shifts that make microservices a preferred model in modern software development,
    focusing on their dynamic integration with cloud platforms'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Java’s concurrency essentials**: Dive into Java’s concurrency **Application
    Programming Interface** (**API**) to discover how these tools can dramatically
    improve the performance and scalability of your microservices'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Concurrency patterns and techniques**: Learn about advanced patterns such
    as circuit breakers and event-driven communication, which are essential for maintaining
    high service availability and robust error handling'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Best practices for microservices**: Explore strategic guidelines for deploying
    and scaling your microservices, ensuring they are optimized for the cloud environment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hands-on design and implementation**: Apply what you’ve learned through practical
    case studies and real-world applications that demonstrate effective microservice
    design using Java'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you’ll be well-equipped to leverage Java’s advanced
    features for designing, deploying, and managing microservices that are not only
    scalable and efficient but also resilient and easy to maintain. Prepare to transform
    theoretical knowledge into practical skills that will advance your capabilities
    in developing cloud-native applications.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**frameworkframework**For detailed setup instructions on microservices frameworks,
    refer to their official documentation. This chapter will focus on using Spring
    Boot for the microservice example.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the official documentation sites:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Spring** **Boot**: [https://spring.io/guides/gs/spring-boot](https://spring.io/guides/gs/spring-boot)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Micronaut**: [https://guides.micronaut.io/latest/creating-your-first-micronaut-app-maven-java.html](https://guides.micronaut.io/latest/creating-your-first-micronaut-app-maven-java.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quarkus**: [https://quarkus.io/get-started/](https://quarkus.io/get-started/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code in this chapter can be found on GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Java-Concurrency-and-Parallelism](https://github.com/PacktPublishing/Java-Concurrency-and-Parallelism)'
  prefs: []
  type: TYPE_NORMAL
- en: Core principles of microservices – architectural benefits in cloud platforms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Microservices architecture** offers a modern approach to software development,
    particularly in cloud environments. This architecture divides complex systems
    into smaller, independent services, providing flexibility and scalability. In
    this section, we will explore the foundational concepts of microservices architecture,
    its advantages over traditional designs, and how it integrates seamlessly into
    cloud ecosystems.'
  prefs: []
  type: TYPE_NORMAL
- en: Foundational concepts – microservices architecture and its benefits in the cloud
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Microservices architecture is a modern approach to software development that
    focuses on dividing complex systems into small, loosely coupled services. This
    architecture has proven especially beneficial in cloud environments, where its
    modularity and flexibility offer numerous advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Modularity**: Microservices architecture divides a system into independent,
    loosely coupled services, each with its own functionality. This modularity allows
    for granular control over each component, making it easier to develop, test, deploy,
    and maintain individual services. It also enables teams to work on different services
    simultaneously, promoting parallel development.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Communication**: Microservices communicate via lightweight, standardized
    protocols such as HTTP/REST or gRPC, allowing for efficient interaction between
    services. These communication patterns, both synchronous and asynchronous, enable
    the development of scalable systems that can handle increasing workloads. Services
    expose well-defined APIs, which act as contracts for communication and facilitate
    loose coupling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Independent deployment**: Microservices can be deployed, scaled, and updated
    independently without affecting the functionality of other services. This flexibility
    reduces downtime, enhances scalability, and simplifies the integration of new
    features. It also allows for the use of different technologies within each microservice.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resilience and fault isolation**: Microservices architecture promotes resilience
    by isolating failures within individual services. If one service fails, it doesn’t
    necessarily bring down the entire system. This fault isolation is achieved through
    design patterns such as circuit breakers and bulkheads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability**: Microservices can be scaled individually based on their specific
    resource requirements and demand patterns. This granular scalability allows for
    optimized resource allocation and cost-efficiency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By leveraging the benefits of modularity, communication, independent deployment,
    resilience, and scalability, microservices architecture enables the development
    of flexible, maintainable, and scalable systems in cloud environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1: A microservices architecture](img/B20937_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.1: A microservices architecture'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 8**.1* showcases a microservices architecture deployed in a cloud environment,
    highlighting the interplay between various services that cater to end user functionalities.
    It includes these key components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**User service**: Enables users to place orders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Order service**: Processes orders by interacting with the product service
    for product details and the inventory service for stock checks; if items are available,
    it proceeds to initiate payment via the payment service'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Payment service**: Handles payment processing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Notification service**: Alerts users about their order status once the payment
    is confirmed, facilitated by notifications sent from the order service'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inventory service**: Updates stock levels post-order to ensure accurate inventory
    management'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The architecture is built to be modular and scalable, with each service dedicated
    to a specific task and communicating through defined interfaces. This setup allows
    for flexibility in development and deployment, while the cloud environment supports
    scalability and robustness, adjusting to workload variations and ensuring system
    resilience.
  prefs: []
  type: TYPE_NORMAL
- en: Architectural comparison – differences between monolithic and microservices
    designs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Microservices architecture presents a modern alternative to traditional monolithic
    designs. However, each has its distinct benefits and drawbacks. Here we focus
    on contrasting these two architectural styles.
  prefs: []
  type: TYPE_NORMAL
- en: 'The details surrounding monolithic architecture are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Structure**: Monolithic designs are characterized by a single, unified codebase
    that houses all functionalities, including the **User Interface** (**UI**), business
    logic, data storage, and processing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment**: In a monolithic architecture, the entire application is deployed
    as a single entity. Any changes or updates necessitate redeploying the whole application,
    potentially causing downtime and limiting flexibility.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability**: Scaling monolithic applications can be cumbersome as it often
    involves scaling the whole system even if only specific functionalities require
    it. This can lead to inefficiency and the unnecessary use of resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Advantages**: Monolithic architectures are simpler in terms of development
    and deployment, which makes them ideal for smaller projects or for organizations
    that lack extensive resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s look at *Figure 8**.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2: A comparative overview of monolithic and microservices architectures](img/B20937_08_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.2: A comparative overview of monolithic and microservices architectures'
  prefs: []
  type: TYPE_NORMAL
- en: In the monolithic architecture, the application is constructed as a single unit,
    integrating UI, business logic, and data storage within one codebase. This approach
    is initially simpler for development and deployment but can become cumbersome
    as the application scales. Changes in one area can affect the entire system, and
    scaling necessitates deploying the whole application.
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, microservices architecture decomposes the application into small,
    autonomous services, each handling a distinct function. These services interact
    via defined interfaces, supporting loose coupling and independent development,
    deployment, and scaling. While this structure enhances agility and scalability,
    it also brings complexity in coordinating services and increases operational demands.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at some comparison and transition considerations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Complexity**: Monolithic architectures are simpler, but microservices increase
    in complexity with the need for detailed service orchestration. This can be mitigated
    with specific tools and frameworks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adoption**: Transitioning from monolithic to microservices architecture involves
    segmenting the existing codebase into separate services and establishing new patterns
    for inter-service communication.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The choice between these architectures should be guided by the application’s
    requirements for scale and complexity, as well as the organization’s strategic
    objectives. Often, businesses start with a monolithic design and evolve toward
    microservices as their operational needs grow.
  prefs: []
  type: TYPE_NORMAL
- en: Real-world examples – Netflix’s evolution and Amazon’s flexibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Netflix’s journey to microservices architecture began in 2009 when it faced
    rapid growth and scaling challenges. This transition was driven by the need to
    handle massive workloads and deliver content seamlessly to a global audience.
  prefs: []
  type: TYPE_NORMAL
- en: Netflix introduced adaptive streaming, allowing it to deliver video content
    with varying resolutions based on users’ internet speeds and devices. Microservices
    architecture allowed services such as video encoding, content delivery, and user
    profiling to work independently yet cohesively. Netflix’s microservices design
    also enabled the incorporation of a recommendation engine that suggests content
    based on users’ viewing history, enhancing user engagement.
  prefs: []
  type: TYPE_NORMAL
- en: Over time, Netflix’s architecture has allowed for the integration of additional
    services, such as multilingual support, regional content libraries, and offline
    viewing, demonstrating how microservices architecture accommodates evolving functionalities.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon’s transition to a microservices architecture has enabled it to scale
    its e-commerce platform efficiently, accommodating diverse functionalities and
    third-party services. Amazon’s microservices architecture enables integration
    with various third-party services, including payment gateways, analytics platforms,
    and customer review systems, allowing it to accommodate diverse user needs and
    incorporate new features.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon’s microservices design allows for the integration of different technologies
    and tools, enabling it to evolve its technology stack smoothly. The independent
    deployment capabilities of Amazon’s microservices architecture allow it to iterate
    rapidly, ensuring its e-commerce platform stays competitive and adapts to changing
    market demands.
  prefs: []
  type: TYPE_NORMAL
- en: Netflix and Amazon serve as powerful examples of how microservices architectures
    can be leveraged to address real-world challenges and drive business success.
    However, it’s important to note that these benefits are not limited to these tech
    giants, and that businesses across various industries are embracing microservices
    to build scalable, flexible, and resilient applications.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we delved into microservices architecture in the cloud, discussing
    its core principles, such as modularity and scalability, and contrasting these
    with monolithic designs. We highlighted how companies such as Netflix and Amazon
    have leveraged microservices to enhance business outcomes through real-world case
    studies. Moving forward, we will examine Java’s concurrency tools, which are essential
    for developing scalable and resilient microservices, and how they address the
    unique demands of cloud-based microservices architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Essential Java concurrency tools for microservice management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Java’s concurrency tools are vital for managing microservices in cloud environments,
    enabling efficient task management and **parallel processing**. In this section,
    we’ll explore how these tools facilitate the development of responsive and scalable
    microservices architectures, integrating seamlessly into modern cloud ecosystems.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency tools – an exploration of Java’s concurrency tools that are tailored
    for microservices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Java, concurrency tools such as **ExecutorService**, **parallel streams**,
    **CompletableFuture**, and the **Fork/Join frameworkframework** play crucial roles
    in microservices architectures. ExecutorService manages pools of worker threads
    for efficient task execution, while parallel streams expedite data processing
    tasks by operating concurrently, thereby enhancing performance. CompletableFuture
    supports asynchronous programming, facilitating non-blocking tasks and inter-service
    communication. The Fork/Join frameworkframework helps divide and conquer large
    tasks by breaking them down into smaller, parallelizable units, thus optimizing
    execution times. These tools are foundational for developing scalable and efficient
    microservices, and we will further explore their practical applications in enhancing
    cloud-based microservices management in upcoming sections.
  prefs: []
  type: TYPE_NORMAL
- en: Task parallelism – using Java’s concurrency mechanisms to manage microservices
    efficiently
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Task parallelism** is an essential aspect of managing microservices efficiently.
    Java’s concurrency mechanisms offer practical solutions to distribute workloads,
    handle multiple tasks concurrently, and ensure responsive microservices.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at a code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The provided code snippet demonstrates task parallelism using Java’s concurrency
    mechanisms within a microservices architecture. Here’s a concise analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '`List<Future<?>>` collects tasks submitted to an `executorService` for asynchronous
    execution. Tasks include inventory adjustments, invoice processing, and email
    confirmations related to an order.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `Future<?>` allows for tracking task outcomes and synchronizing them upon
    completion.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`get()`, ensuring that all operations finish before proceeding. This synchronization
    is critical for maintaining consistency and reliability in service response.*   **Handling
    failures**: Exceptions from tasks are caught, logged, and rethrown, demonstrating
    robust error handling that allows the system to maintain high fault tolerance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a microservices architecture, task parallelism enables different microservices
    to work concurrently, each focusing on its specific responsibility. This approach
    allows for efficient processing of requests and optimizes the overall performance
    of the system. By leveraging task parallelism, microservices can handle multiple
    tasks simultaneously, leading to faster response times and improved throughput.
  prefs: []
  type: TYPE_NORMAL
- en: However, task parallelism is just one aspect of achieving high performance in
    microservices. Another important concept is parallel processing, which involves
    breaking down a large task into smaller, independent subtasks that can be processed
    concurrently. In the next section, we will explore how parallel processing can
    be applied in microservices using Java’s parallel streams and the Fork/Join framework.
  prefs: []
  type: TYPE_NORMAL
- en: Parallel processing for responsive microservices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Parallel processing is a powerful technique for improving the performance and
    responsiveness of microservices. By breaking down large tasks into smaller, independent
    subtasks and processing them concurrently, microservices can handle data-intensive
    operations and computationally expensive tasks more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Java provides several tools for parallel processing, including parallel streams
    and the Fork/Join framework. Let’s explore how these tools can be used in a microservices
    context.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at a parallel stream example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the `processData()` method receives a list of Data objects.
    Instead of processing the data sequentially, it uses the `parallelStream()` method
    to create a parallel stream. The `map()` operation is applied to each data item,
    invoking the `processDataItem ()` method concurrently. Finally, the processed
    results are collected into a list.
  prefs: []
  type: TYPE_NORMAL
- en: By using parallel streams, the data processing can be distributed across multiple
    threads, allowing for faster execution and improved microservice responsiveness.
  prefs: []
  type: TYPE_NORMAL
- en: The Fork/Join framework is another powerful tool for parallel processing in
    Java. It is designed to efficiently handle recursive algorithms and divide-and-conquer
    scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of using the Fork/Join framework in a microservice to perform
    a complex computation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the `ComplexComputationService` uses the Fork/Join framework
    to perform a complex computation. The `computeResult()` method receives a `Problem`
    object and submits a `ComplexComputationTask` to the `ForkJoinPool`.
  prefs: []
  type: TYPE_NORMAL
- en: The `ComplexComputationTask` extends `RecursiveTask` and implements the `compute()`
    method. If the problem is simple, it solves it directly. Otherwise, it decomposes
    the problem into smaller subtasks, forks them for parallel execution, and then
    joins the results using the `join()` method. The results are combined using the
    `reduce()` operation.
  prefs: []
  type: TYPE_NORMAL
- en: By utilizing the Fork/Join framework, the microservice can efficiently solve
    complex problems by recursively dividing them into smaller subproblems and processing
    them in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: These examples demonstrate how parallel processing techniques, such as parallel
    streams and the Fork/Join framework, can be applied in microservices to achieve
    better performance and responsiveness. By leveraging the power of parallel processing,
    microservices can handle large-scale data processing and complex computations
    more efficiently, resulting in improved user experience and faster response times.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we examined Java’s concurrency tools and their role in microservices.
    We discussed how thread pools, parallel streams, and the Fork/Join framework enhance
    microservice performance through task parallelism, improving throughput and responsiveness.
    While beneficial, Java’s concurrency mechanisms also present challenges. Next,
    in the *Challenges and solutions in microservices concurrency* section, we will
    address common issues with concurrency in microservices and outline effective
    strategies and practices.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges and solutions in microservices concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices architectures offer unparalleled flexibility and scalability for
    modern applications, yet their concurrent nature presents unique challenges. This
    section delves into critical aspects of microservices concurrency, exploring potential
    bottlenecks, strategies for ensuring data consistency, approaches to achieving
    resilience, and practical solutions to these challenges through Java’s concurrency
    mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: Bottlenecks – diagnosing potential challenges in concurrent microservices architectures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The introduction of concurrency in microservices architectures often leads to
    challenges and potential bottlenecks. Efficiently identifying and resolving these
    bottlenecks is crucial for maintaining the performance and smooth operation of
    concurrent microservices. This section outlines tools and strategies for effectively
    diagnosing and mitigating these issues, with a focus on cloud-based utilities.
  prefs: []
  type: TYPE_NORMAL
- en: First, let us look at **API Gateway**.
  prefs: []
  type: TYPE_NORMAL
- en: 'API Gateway acts as the central hub for incoming requests. It manages the flow
    of traffic efficiently, ensuring smooth operation and preventing bottlenecks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Request throttling**: Imposes rate limits on requests to prevent service
    overload and ensure consistent performance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Traffic routing**: Directs traffic efficiently to the appropriate services,
    distributing loads evenly and reducing coordination and communication bottlenecks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Caching**: By caching responses to frequently accessed endpoints, the gateway
    lessens the load on backend services and enhances response times'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics collection**: Collects critical metrics such as response times, error
    rates, and request volumes, which are crucial for identifying and addressing bottlenecks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we will explore monitoring and logging tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'These tools are vital for diagnosing and resolving bottlenecks in microservices
    architectures:'
  prefs: []
  type: TYPE_NORMAL
- en: '**AWS CloudWatch**: This offers real-time monitoring and logging, enabling
    the tracking of metrics such as resource utilization and response times. Alarms
    can be configured to alert threshold breaches, helping promptly identify and address
    emerging bottlenecks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Monitor**: This provides comprehensive monitoring, alerting, and log
    analytics features, offering insights into potential contention points and communication
    delays.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Google Cloud Logging**: This captures logs from various microservices, offering
    insights into service interactions and identifying areas of latency or overhead.
    Log-based metrics help track specific bottleneck-inducing events.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These solutions enable ongoing tracking and analysis of performance metrics,
    revealing trends that can pinpoint bottlenecks. They also guide necessary architectural
    adjustments, such as implementing caching strategies, sharding databases, or modifying
    communication patterns to boost efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: By integrating API Gateways with robust monitoring tools, microservices architectures
    can proactively diagnose and resolve bottlenecks, thus ensuring enhanced performance,
    scalability, and resilience. This integrated approach ensures that concurrency
    challenges are managed effectively, fostering a robust environment for microservices
    operation.
  prefs: []
  type: TYPE_NORMAL
- en: Consistency – ensuring data consistency and smooth inter-service communication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ensuring consistency in microservices architecture, particularly given its distributed
    nature, is critical. This section delves into how distributed databases and message
    brokers are fundamental in achieving consistency across services.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start with distributed databases. Selecting the right distributed databases
    such as Amazon RDS, Google Cloud SQL, and Azure Database for PostgreSQL is key.
    These services ensure transactional consistency and **Atomicity, Consistency,
    Isolation, Durability** (**ACID**) compliance, which is crucial for operations
    that require reliable data handling. They manage data integrity across microservices
    by ensuring complete transactions before committing, and if a transaction fails,
    it is fully rolled back to maintain consistency.
  prefs: []
  type: TYPE_NORMAL
- en: These databases enhance scalability with features such as read replicas and
    sharding. They support robust data replication across zones or regions for improved
    availability and disaster recovery. Fully managed solutions reduce operational
    overhead, allowing teams to focus on core functionalities. Alternatives such as
    Apache Cassandra and Google Cloud Spanner, while offering less stringent consistency,
    excel in scenarios needing high scalability and low-latency access across geographic
    regions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s consider message brokers. Tools such as AWS SQS, Google Pub/Sub,
    Apache Kafka, and Azure Service Bus streamline inter-service communication by
    managing asynchronous message queues. They enhance consistency in the following
    ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Decoupling services**: These brokers allow services to operate independently,
    improving system uptime by maintaining functionality even when parts fail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reliable delivery**: They ensure that messages accurately reach intended
    services, supporting high-volume conditions. Kafka, for instance, is known for
    its durability, while Azure Service Bus offers reliability within its ecosystem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Event-driven architecture support**: They aid services in dynamically responding
    to changes, essential for maintaining consistency across services reacting to
    the same events.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'From a design perspective, the choice between using a **Relational Database
    Service** (**RDS**) or a message broker depends on the specific requirements of
    your application:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use RDS** for transactional data needs requiring ACID properties, complex
    data relationships needing strong integrity, or centralized data management, as
    well as when complex queries are necessary for analytics'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use message brokers** for asynchronous communication needs, event-driven
    architectures, scalability under varying loads, efficient high-volume traffic
    handling, or complex workflow orchestration across multiple microservices'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Often, the strengths of RDSs and message brokers complement each other in a
    microservices architecture, and they are not mutually exclusive. For example,
    you might use an RDS to manage transactional data integrity while using a message
    broker to handle events that result from changes in the data, thus combining reliable
    data management with reactive service orchestration. This approach leverages the
    strengths of both technologies to create a robust, scalable, and resilient architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at *Figure 8**.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3: A microservice architecture with an API Gateway, message broker,
    and RDS](img/B20937_08_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.3: A microservice architecture with an API Gateway, message broker,
    and RDS'
  prefs: []
  type: TYPE_NORMAL
- en: This figure depicts a microservice architecture design leveraging an RDS and
    a message broker to facilitate communication and data persistence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Key components of this design include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**UI layer**: Users interact here'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**API Gateway**: Routes requests to microservices'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Microservices**: Handle specific functionalities'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**RDS**: Stores data persistently (relational tables)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Message broker**: Enables asynchronous communication between microservices'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here’s how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: A user initiates a request through UI.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The API Gateway routes requests to the relevant microservice(s).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The microservice interacts with the RDS or publishes a message to the message
    broker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other microservices subscribed to the message broker receive and process the
    message.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data persistence might occur in an RDS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The microservice generates a response and sends it back to the user through
    the API gateway.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Its benefits are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Decoupling**: Microservices are loosely coupled and can scale independently'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data consistency**: Using RDS maintains data integrity across services'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In essence, the message broker fosters asynchronous communication, while the
    RDS offers persistent storage.
  prefs: []
  type: TYPE_NORMAL
- en: Resilience – achieving system resilience and fault tolerance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Achieving robustness in microservices involves implementing the following strategies
    that enhance system resilience and fault tolerance:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Circuit breakers**: Utilizing tools such as Netflix Hystrix or Resilience4j,
    circuit breakers help manage service failures gracefully. They prevent cascading
    failures by halting the propagation of faults across services, thus maintaining
    system functionality during partial outages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Load balancers**: Employing cloud-native load balancers assists in evenly
    distributing incoming traffic among available services. This not only enhances
    fault tolerance by avoiding overloading any single service but also helps in preventing
    bottlenecks, thus ensuring smoother operation and better response times across
    the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Circuit breakers and load balancers can work together to build resilient microservices.
    Load balancers distribute traffic, preventing bottlenecks and single points of
    failure. Circuit breakers provide additional protection by isolating failing services
    and preventing cascading failures.
  prefs: []
  type: TYPE_NORMAL
- en: This section has outlined the pivotal role of concurrency management in microservices,
    delving into the challenges and solutions related to potential bottlenecks and
    ensuring data consistency. We examined tools and strategies for mitigating issues
    such as traffic congestion and maintaining data integrity across distributed services,
    utilizing API gateways for traffic management, and utilizing message brokers for
    seamless inter-service communication. By integrating distributed databases and
    robust messaging systems, microservices can achieve enhanced performance, scalability,
    and resilience.
  prefs: []
  type: TYPE_NORMAL
- en: Moving forward, we will transition from theoretical concepts to practical applications.
    The upcoming section, *Hands-on – designing concurrent microservices in Java*,
    will provide a detailed guide on implementing these concurrency principles in
    Java.
  prefs: []
  type: TYPE_NORMAL
- en: Practical design and implementation – building effective Java microservices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section dives into practical Java code examples, showcasing how to tackle
    concurrency challenges in a microservices architecture using cloud utilities and
    mechanisms such as message brokers, distributed databases, and circuit breakers.
  prefs: []
  type: TYPE_NORMAL
- en: Use case 1 – e-commerce application – processing orders
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In an e-commerce application with a microservice for processing orders, concurrency
    challenges can arise due to multiple order requests trying to deduct from the
    same balance simultaneously, leading to inconsistencies and data integrity issues.
    To address these challenges, we can leverage the optimistic locking that is offered
    by most distributed databases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Optimistic locking uses a version number associated with the user’s account
    balance. When an update query is executed, it includes the expected version number.
    If the version in the database doesn’t match the expected version, it indicates
    that another transaction might have modified the balance first, causing the update
    to fail. This prevents race conditions and ensures data consistency. Here are
    steps involved in the code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the `pom.xml` file in the project’s root directory and add the following
    dependencies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the `UserAccount` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code defines a `UserAccount` JPA entity. It has a `@Version` number (version)
    for optimistic locking, ensuring data consistency during updates.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create the `AccountRepository` interface in the same package. This interface
    should extend `JpaRepository` and define the `deductBalance()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the `AccountService` class in the same package and inject an `AccountRepository`
    instance into it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: For optimistic locking, the method retrieves the current version number of the
    account being updated. It then invokes `accountRepository.deductBalance()` using
    the user ID, the amount to be deducted, and the expected version number. After
    this operation, the method checks the number of rows that were updated (`rowsUpdated`).
    A successful update — which is indicated by exactly one row being updated — allows
    the process to proceed. If the update affects either no rows or more than one
    row, it suggests that the account may have been concurrently modified by another
    process. In this case, an `OptimisticLockingException` is thrown, indicating that
    the update failed due to outdated data, prompting a retry to maintain data consistency.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we can use a message broker for asynchronous communication:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can create the `OrderService` class and inject a `MessageProducer`
    instance into it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The order processing microservice publishes a message to the message broker
    after successful validation and balance deduction. Separate services subscribed
    to the broker can then handle order confirmation and fulfillment asynchronously.
    This ensures that the order processing microservice isn’t blocked by these downstream
    tasks.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: These examples showcase how Java code can leverage cloud functionalities to
    address concurrency challenges in microservices. By combining optimistic locking
    and message brokers, you can build a more robust and scalable e-commerce application.
    These are simplified examples. Real-world implementations might involve additional
    error handling, logging, and configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Use case 2 – building a data processing pipeline with microservices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This case study delves into designing and implementing a data processing pipeline
    using a microservices architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to design the microservices. We’ll construct the pipeline
    with three distinct microservices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data ingestion service**: This service acts as the entry point, which is
    responsible for receiving and validating incoming data from external sources.
    Once validated, it publishes the data to an Amazon SQS queue for further processing.
    The service depends on the Amazon SQS client library.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data processing service**: This service subscribes to the Amazon SQS queue
    used by the data ingestion service. It consumes the data, applies business logic
    for transformation, and publishes the processed data to another SQS queue for
    persistence. This service relies on both the Amazon SQS client library and the
    AWS Glue SDK.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data persistence service**: The final service consumes the processed data
    from the second SQS queue. Its primary function is to store the data persistently
    in Amazon RDS for long-term accessibility. This service utilizes both the Amazon
    SQS client library and the Amazon RDS client library.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: By leveraging AWS services, we can build a scalable and efficient data processing
    solution that benefits from the modularity and flexibility inherent in a microservices
    architecture.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The next step is to set up the AWSs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Two AWS Simple Queue Service** (**SQS**) **queues** will be set up:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Initial data queue**: Create a queue intended for receiving initial unprocessed
    data'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Processed data queue**: Set up another queue for holding processed data ready
    for further actions or storage'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AWS RDS instance**: Set up an RDS instance to provide persistent storage
    for your application. You can choose MySQL, PostgreSQL, or any other available
    RDS database engine depending on your application requirements. This database
    will be used to store and manage the data processed by your application.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AWS Simple Notification Service** (**SNS**): Create an SNS topic to facilitate
    the notification process. This topic will be used to publish messages notifying
    subscribers of successful data processing events and other important notifications.
    Determine the subscribers to this topic, which could include email addresses,
    SMS, HTTP endpoints, or even other AWS services such as Lambda or SQS, depending
    on your notification requirements.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The third step is to set up a Maven project. Create a new Maven project for
    each microservice (DataIngestionService, DataProcessingLambda, and DataPersistenceService)
    in your preferred `pom.xml` file in each project’s root directory and add the
    related dependencies.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The fourth step is to implement the data ingestion service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The code represents the implementation of the data ingestion service, which
    is responsible for receiving incoming data, validating it, and publishing it to
    Amazon SQS for further processing.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `DataIngestionService` class is annotated with `@Service`, indicating that
    it is a Spring service component. It has a dependency on the `AmazonSQS client`,
    which is injected through the constructor.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `ingestData()` method takes a `data object` as input and performs data validation
    by calling the `isValid()` method. If the data is valid, it creates a `SendMessageRequest`
    object with the specified SQS queue URL and the data payload as the message body.
    The message is then sent to the SQS queue using the `sqsClient.sendMessage()`
    method.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The fifth step is to implement the data processing service using AWS Lambda:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This Lambda function, `DataProcessingLambda`, processes data from an Amazon
    SQS queue by implementing the `RequestHandler` interface to handle `SQSEvent`
    events. It initializes an Amazon SQS client in the constructor and uses it to
    send transformed data to another SQS queue for further processing or storage.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `handleRequest()` method, serving as the function’s entry point, processes
    each `SQSMessage` from the `SQSEvent`, extracting the data and transforming it
    directly within the function through the `transformData()` method. Here, the transformation
    appends a timestamp to the data as a simple example, but typically this would
    involve more complex operations tailored to specific data processing requirements.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Following the data transformation, the function sends the processed data to
    a specified SQS queue by invoking the `sendMessage()` method on the SQS client.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The next step is to create a Spring-managed service that handles storing processed
    data in a database and notifies subscribers via AWS SNS upon successful persistence:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`DataPersistenceService` is a Spring-managed bean responsible for handling
    data persistence and notifying other components or services via Amazon SNS. Here’s
    a step-by-step description of its functionality:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`AmazonSNS` client used for sending notifications.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`persistData()` method takes a `String data` parameter, which is the processed
    data. It creates a `Data entity`, sets the processed data, and saves it to the
    database using the `DataRepository`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sendNotification()` to notify other parts of the application. It constructs
    a `PublishRequest` with a `topic ARN (Amazon Resource Name)` and the message detailing
    the successful persistence. The message is then published to the specified SNS
    topic.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This service is particularly useful in microservice architectures where decoupled
    components must communicate state changes or updates. Using SNS for notifications
    enhances the reliability of the system by ensuring not only that data is persisted
    but also that relevant services or components are informed of the update through
    a robust, scalable messaging system.
  prefs: []
  type: TYPE_NORMAL
- en: This section details the practical application of Java to manage concurrency
    in a microservices architecture, particularly for an e-commerce application processing
    order. It explains how using optimistic locking with version numbers in a distributed
    database can prevent data inconsistencies during concurrent order processing.
    Additionally, the use of message brokers is discussed as a method for asynchronous
    communication, which aids in keeping microservices from being blocked by downstream
    tasks, thereby improving efficiency and scalability.
  prefs: []
  type: TYPE_NORMAL
- en: Moving forward, the next section will cover strategic best practices for deploying
    and scaling microservices. This includes leveraging cloud-native services and
    architectures to optimize performance, scalability, and reliability, as well as
    providing a comprehensive guide for developers and architects on how to effectively
    manage microservices in a cloud environment.
  prefs: []
  type: TYPE_NORMAL
- en: Strategic best practices – deploying and scaling microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When designing, deploying, and scaling microservices in a cloud environment,
    it’s essential to utilize cloud-native services and architectures to maximize
    performance, scalability, and reliability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a straightforward guide on best practices, tailored for developers and
    architects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Load balancing**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Purpose**: Distribute incoming traffic evenly across multiple microservice
    instances to enhance reliability and availability'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**How** **to implement**:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use cloud-managed load balancers such as AWS **Elastic Load Balancing** (**ELB)**,
    Azure Load Balancer, or Google Cloud Load Balancing, which can automatically adjust
    to traffic demands
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrate service discovery tools (e.g., AWS Cloud Map, Azure Service Discovery,
    or Google Cloud Service Directory) to dynamically manage service instances
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Caching solutions**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Purpose**: Reduce database load and speed up response times by caching frequently
    accessed data'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**How** **to implement**:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Opt for managed caching services such as Amazon ElastiCache, Azure Redis Cache,
    or Google Cloud Memorystore, which offer distributed caching capabilities
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Choose an appropriate caching strategy (local, distributed, or hybrid) and ensure
    proper management of cache coherence and expiration
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Managed databases**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Purpose**: Simplify database management tasks (scaling, backups, patching),
    allowing developers to concentrate on building functionalities'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**How** **to implement**:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement a database-per-service model using **Database as a Service** (**DBaaS**)
    solutions such as Amazon RDS, Azure SQL Database, or Google Cloud SQL to ensure
    resource isolation and optimized performance
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Leverage automated features within DBaaS for scaling, backups, and ensuring
    high availability
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Microservices** **architecture considerations**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maintain loose coupling among services to enable independent development, deployment,
    and scaling
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Apply **Domain-Driven Design** (**DDD**) principles by organizing microservices
    around business capabilities and defining clear bounded contexts
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment** **and scaling**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Containers and orchestration**: Deploy microservices using containerization
    with Kubernetes, which is supported by AWS EKS, Azure AKS, and Google GKE, to
    manage container lifecycles and automate scaling'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability**: Implement auto-scaling based on CPU, memory usage, or custom
    metrics aligned with your application’s needs'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring** **and logging**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Observability**: Implement comprehensive monitoring and logging to keep track
    of microservice performance and operational health; also, utilize tools such as
    AWS CloudWatch, Azure Monitor, or Google’s Operations Suite for real-time monitoring,
    performance tracking, and alert management'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Adhering to these best practices leverages the strengths of cloud computing,
    enhancing the resilience, performance, and scalability of your microservices architecture.
    This strategic approach not only ensures robust service delivery but also maintains
    the agility needed for continuous innovation and growth.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced concurrency patterns – enhancing microservice resilience and performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When developing microservices in Java, it is essential to employ concurrency
    patterns and techniques that enhance the application’s responsiveness, fault tolerance,
    and scalability. These patterns help manage the complexities inherent in distributed
    systems.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s a discussion on key concurrency and data management patterns applicable
    to microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Data management patterns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Understanding and implementing effective data management patterns is crucial
    for designing robust microservices. Let’s look at them one by one.
  prefs: []
  type: TYPE_NORMAL
- en: Command Query Responsibility Segregation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Command Query Responsibility Segregation** or **CQRS** separates the read
    and write operations of a data store to optimize performance, scalability, and
    security. This pattern allows reads and writes to be scaled independently. Let’s
    look at the details:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use case**: Useful in complex domains where the read operations significantly
    outnumber the write operations, or when they can be clearly differentiated'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implementation details**: *Figure 8**.4* shows a system using CQRS, which
    separates data updates (commands) from data retrieval (queries)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.4: CQRS architecture flow](img/B20937_08_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.4: CQRS architecture flow'
  prefs: []
  type: TYPE_NORMAL
- en: '**Command side**: Handles updates with a Command API, CommandHandler, and Write
    Database'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Query side**: Handles reads with a Query API and a separate Read Database
    optimized for fast reads'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This separation improves performance and scalability. Each side can be optimized
    for its task and scaled independently. Additionally, the Query Side can stay available
    during updates on the Write Side.
  prefs: []
  type: TYPE_NORMAL
- en: Event sourcing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Event sourcing** is a design pattern in which changes to the state of an
    application are stored as a sequence of events. Instead of storing just the current
    state of the data in a domain, event sourcing stores a sequence of state-changing
    events. Whenever the state of a business entity changes, a new event is appended
    to the list of events associated with that entity. This sequence of events serves
    as the principal source of truth and can be used to reconstruct past states of
    an entity. Let’s take a closer look:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use case**: Imagine a banking application that requires a robust mechanism
    for tracking the movement of funds between accounts, ensuring compliance with
    auditing standards, and the ability to revert or reconstruct account states during
    disputes or investigations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implementation details**: Let’s look at this diagram:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.5: The Event Sourcing pattern](img/B20937_08_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.5: The Event Sourcing pattern'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 8**.5* illustrates the Event Sourcing pattern in software architecture
    using a horizontal multi-level layout. Here’s a description of its components
    and flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Client**: Initiates the process by sending commands to the system'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Command handler**: Receives commands from the client and processes them;
    generates events based on the commands received'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Event store**: Captures and stores these events; this storage acts as the
    authoritative source of truth about the state of the system'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Event bus**: Distributes the stored events to appropriate handlers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Event handlers**: React to the events by processing them and potentially
    generating new events or commands'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Projections**: Update the read models based on the events processed by the
    event handlers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Read models**: Provide the updated state of the system back to the client
    based on the projections'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Client**: May query the read models to retrieve the current state or results
    of operations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Event sourcing pattern allows the system to maintain a full historical record
    of state changes, which is crucial for auditing and compliance. It also supports
    scalability by decoupling command processing from state storage and enabling asynchronous
    event processing.
  prefs: []
  type: TYPE_NORMAL
- en: API versioning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**API versioning** is a strategy employed to manage changes to an API. It allows
    for new features and changes without disrupting the existing user experience or
    requiring clients to make immediate upgrades. This approach is particularly crucial
    when introducing breaking changes that would otherwise compromise backward compatibility.
    Here’s a more detailed look:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use case**: Imagine a scenario where a financial services API needs to add
    new fields to a response object that could disrupt existing client applications.
    By introducing a new version of the API, the service can provide these enhancements
    while still supporting the older version, ensuring that existing applications
    continue to function without modification until they opt to upgrade.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/api/v1/users` for the first version and `/api/v2/users` for the second version.
    This method is transparent and easy to understand.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GET /api/users?version=1`. This keeps the URI clean and allows for more flexibility
    but can be less intuitive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Accept:application/vnd.myapi.v1+json`. This approach is less obtrusive and
    separates versioning from the business logic of the API.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s a basic example of how to implement API versioning in a web application
    using Spring Boot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In this example, different versions of the same endpoint are triggered based
    on the custom `X-API-Version` request header. This allows clients to specify which
    version of the API they wish to interact with, enabling backward compatibility
    while new features are rolled out.
  prefs: []
  type: TYPE_NORMAL
- en: Saga pattern
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The **Saga pattern** is a valuable approach for managing data consistency across
    multiple microservices in distributed transactions. It provides a way to handle
    long-running business processes that span multiple services, ensuring that each
    step is executed successfully or compensated if an error occurs. Let’s find out
    more:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use case**: The Saga pattern excels in coordinating long-running microservice
    workflows where each step requires confirmation. This is ideal for scenarios such
    as order processing (inventory, payment, and shipping) or hotel booking (reservation,
    payment, and confirmation). It ensures that the entire process succeeds or is
    rolled back if a step fails.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implementation details**: Let’s look at *Figure 8**.6*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.6: The Saga pattern](img/B20937_08_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.6: The Saga pattern'
  prefs: []
  type: TYPE_NORMAL
- en: 'This activity diagram demonstrates the Saga pattern, showing the flow of a
    transaction with potential compensating actions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Start transaction**: The process begins'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service 1**: The first service is called:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If Service 1 succeeds, it proceeds to Service 2
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If Service 1 fails, it triggers Compensate 1 and returns to the start
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service 2**: The second service is called:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If Service 2 succeeds, it proceeds to Service 3
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If Service 2 fails, it triggers Compensate 2 and returns to Compensate 1
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service 3**: The third service is called:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If Service 3 succeeds, the transaction ends
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If Service 3 fails, it triggers Compensate 3 and returns to Compensate 2
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**End transaction**: The process completes successfully'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compensation steps are taken to revert to previous steps when a failure occurs,
    ensuring that the system maintains consistency
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The Saga pattern allows for the coordination of complex transactions across
    multiple microservices while maintaining loose coupling and independence between
    the services. Each service performs its own local transaction and publishes events
    to trigger the next step in the Saga pattern. If any step fails, compensating
    actions are executed to roll back the previous steps, guaranteeing eventual consistency.
  prefs: []
  type: TYPE_NORMAL
- en: Database per service
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The **database per service** pattern is an architectural approach in which
    each microservice has its own dedicated database. Instead of sharing a single
    database across multiple services, each service owns and manages its own data
    store. This pattern promotes loose coupling, autonomy, and scalability in microservices
    architectures. Let’s take a closer look:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use case**: The Database per service pattern thrives when microservices have
    diverse data requirements. It empowers each service to leverage the most suitable
    database technology, optimize data models and queries, and scale independently
    based on its specific load. This approach fosters polyglot persistence and ensures
    strict data isolation, making it ideal for multi-tenant architectures and compliance-driven
    scenarios.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implementation strategies**: Let’s look at *Figure 8**.7*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.7: The Database per service pattern](img/B20937_08_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.7: The Database per service pattern'
  prefs: []
  type: TYPE_NORMAL
- en: 'This component diagram illustrates the *Database per service* architectural
    pattern, where each microservice operates with its own dedicated database. This
    design emphasizes loose coupling, autonomy, and scalability within a microservices
    architecture. Here’s a breakdown of the key components shown in the diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Microservices (A, B, and C)**: Each microservice is shown with its respective
    database. For example, Microservice A uses Database A, Microservice B uses Database
    B, and Microservice C uses Database C. This design ensures that each microservice
    can operate independently, manage its own data store, and use a database technology
    that best suits its needs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**API Gateway**: The API Gateway acts as an intermediary that external clients
    interact with. It abstracts the underlying microservices and provides a single
    point of entry into the system. Each microservice accesses the API Gateway, allowing
    for a simplified client interaction model and centralizing some cross-cutting
    concerns such as authentication and rate limiting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service mesh**: The service mesh is represented as facilitating communication
    between the microservices, API Gateway, and external systems. It helps manage
    service-to-service communications, ensuring reliable data transfer, and implements
    resilience patterns such as retries and circuit breakers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Change Data Capture** (**CDC**): A note on CDC is included to indicate its
    role in the architecture. CDC tools such as Debezium can be used to capture changes
    in each microservice’s database and propagate these changes to other services
    or external systems. This setup supports maintaining eventual consistency across
    the distributed data stores.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interactions**: The diagram shows the flow of data and interactions. Each
    microservice interacts with the API Gateway, which in turn communicates with the
    service mesh. The service mesh coordinates further interactions, potentially with
    external systems, and facilitates the implementation of CDC.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This diagram effectively communicates the separation of concerns and the independence
    of each microservice within the system, highlighting the advantages of the Database
    per service pattern in supporting diverse data requirements and scalability.
  prefs: []
  type: TYPE_NORMAL
- en: Shared database pattern
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The **shared database pattern** is an architectural approach in which each
    microservice has its own dedicated database. Instead of sharing a single database
    across multiple services, each service owns and manages its data store. This pattern
    promotes loose coupling, autonomy, and scalability in microservices architectures:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use case**: Shared databases excel in enterprises, real-time systems, and
    compliance-driven environments. They provide a single source of truth for organizations
    (e.g., customer data across sales, HR, and finance) and ensure consistent data
    for real-time applications. In regulated industries (such as finance and healthcare),
    they enforce compliance standards across services, simplifying audits. This pattern
    thrives where data consistency and integrity are paramount.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implementation strategies**: Let’s look at *Figure 8**.8*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.8: The shared database pattern](img/B20937_08_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.8: The shared database pattern'
  prefs: []
  type: TYPE_NORMAL
- en: 'The diagram represents the shared database pattern where multiple services
    (microservices A, B, and C) utilize a single, central database. This architecture
    is commonly adopted to maintain a unified source of truth across different parts
    of an organization, facilitating consistency and compliance in data management.
    Its key components include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A shared database**: All microservices access this single database for both
    reading and writing operations. This setup ensures data consistency and simplifies
    transaction management across services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Microservices (A, B, and C)**: These services are independent in functionality
    but share the same database for data operations. They represent different business
    capabilities within the organization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**An API layer for access**: An API layer abstracts the database interactions
    from the services. This layer helps enforce security, manage access patterns,
    and ensure that changes to the database schema do not directly impact service
    operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance optimization**: This note suggests the use of strategies such
    as connection pooling, creating read replicas, and caching to optimize database
    performance and handle high loads efficiently.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Java, the implementation of these patterns can be supported by various frameworks
    and libraries that facilitate asynchronous programming and provide tools for building
    resilient microservices. By selecting the appropriate patterns for specific challenges,
    developers can craft robust, scalable, and efficient microservice architectures.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored microservices in the cloud, as well as how Java’s
    concurrency tools can be leveraged to build and manage these services effectively.
    We discussed the principles of microservices, their advantages over monolithic
    architectures, and their integration into cloud environments. The key characteristics
    of microservices, such as modularity and loose coupling, were examined, highlighting
    their contribution to building resilient and scalable systems.
  prefs: []
  type: TYPE_NORMAL
- en: To develop high-performance microservices, we delved into Java’s concurrency
    essentials, including thread pools, parallel streams, and the Fork/Join framework.
    These tools enable developers to incorporate parallel processing and efficient
    task management techniques, thus optimizing microservice performance.
  prefs: []
  type: TYPE_NORMAL
- en: We also addressed potential bottlenecks and concurrency-related issues in microservices
    architectures, providing practical solutions using Java’s concurrent mechanisms.
    Strategies for ensuring smooth communication, data consistency, and resilience
    across services were also discussed.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices for designing, deploying, and scaling concurrent microservices
    in the cloud were covered, including load balancing, caching, and database management.
    Essential patterns for building resilient and fault-tolerant microservices, such
    as circuit breakers, bulkheads, and event-driven communication patterns, were
    explored.
  prefs: []
  type: TYPE_NORMAL
- en: Hands-on exercises and case studies demonstrated how to apply Java’s concurrency
    tools, best practices, and design patterns in real-world scenarios, allowing readers
    to gain practical experience in designing, deploying, and scaling concurrent microservices
    in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: As we conclude this chapter, readers should have a comprehensive understanding
    of creating scalable, resilient microservices using Java’s concurrency tools and
    design patterns in the cloud. They should be equipped with the knowledge and skills
    necessary to tackle the challenges of building high-performance, fault-tolerant
    microservices architectures.
  prefs: []
  type: TYPE_NORMAL
- en: Looking ahead, the next chapter, *Serverless Computing and Java’s Concurrent
    Capabilities*, will explore how Java’s concurrency features can be utilized in
    serverless environments, providing insights and practical guidance on harnessing
    Java’s concurrency tools to build high-performance, event-driven serverless applications.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is a key advantage of microservices architecture over monolithic architecture?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increased complexity and coupling
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Reduced flexibility and scalability
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Independent deployment and scalability
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Single point of failure
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which Java feature is essential for managing asynchronous tasks within microservices?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Java Virtual** **Machine** (**JVM**)'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Java Database** **Connectivity** (**JDBC**)'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: CompletableFuture
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: JavaBeans
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the primary role of a load balancer in a microservices architecture?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Encrypting data transfers
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Distributing incoming network traffic across multiple instances
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Data storage and management
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Error logging and handling
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which pattern helps prevent a network or service failure from cascading to other
    parts of the system in microservices?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Singleton pattern
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Factory pattern
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Circuit breaker pattern
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Builder pattern
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which best practice is recommended when implementing microservices in the cloud
    for handling data consistency?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using a single shared database for all services
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Employing different caching strategies for each microservice
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Assigning a separate managed database instance for each microservice
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Centralizing all data management in one microservice
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
