- en: Chapter 5. Artificial Intelligence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a reusable AI control class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sensing – vision
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sensing – hearing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision making – Finite State Machine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating the AI using cover
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating NavMesh in SDK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pathfinding – using NavMesh
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controlling groups of AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pathfinding – our own A* pathfinder
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Artificial Intelligence** (**AI**) is an extremely vast field. Even for games
    it can be very diverse, depending on the type of game and requirements.'
  prefs: []
  type: TYPE_NORMAL
- en: Many developers enjoy working with AI. It gives you a sense of creating something
    alive, something intelligent, and rational. A good question to ask before designing
    AI for a game is what the expected behavior should be, from a player's perspective.
    In an FPS, it might be the case that the AI can separate the friend from the foe,
    find cover when attacked, flee when injured, and not get stuck on things as they
    move around. AI in an RTS might need to not only evaluate the current situation,
    but also plan ahead and divide resources between aggressive and defensive behavior.
    A group of soldiers and a tactical shooter might have advanced and dynamic group
    behavior. Another option is to have individual behaviors that still make them
    appear to work together, to the player.
  prefs: []
  type: TYPE_NORMAL
- en: The recipes in this chapter will, in most cases, work with isolated functionality,
    but revolve around a central AI control class. As such, the results might not
    always be impressive on their own, but at the same time, it should be quite easy
    to combine several of them into a more powerful AI.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a reusable AI control class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will create a control that is going to steer an AI character.
    Using `Control` to do this is beneficial since it can add the AI functionality
    and be used together with other `Controls` in the game. We can use `GameCharacterControl`
    from [Chapter 2](ch02.html "Chapter 2. Cameras and Game Controls"), *Cameras and
    Game Controls* for both the player and AI characters by adding `AIControl` to
    its spatial. To get a quick and visual result, we'll apply it to the bullet-based
    `BetterCharacterControl` class in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We need to perform the following steps to get a basic, but functional attacking
    (or following) AI:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin by creating a new class called `AIControl`, extending `AbstractControl`.
    The core of the recipe will be based around an enum (enumeration) called `state`.
    For now it only needs two values: `Idle` and `Follow`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add fields for `BetterCharacterControl`, called `physicsCharacter`, Booleans
    `forward` and `backwards`, a `Vector3f` field for `walkDirection`, and another
    for `viewDirection`. If it's going to follow something, it also needs a `target`
    field, which can be `Spatial`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The bulk of the logic is carried out in a `switch` statement in the `controlUpdate`
    method, as shown in the following code. The first case is `Idle`. In this case,
    the AI shouldn''t do anything:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `Follow` case, we should first check whether `target` is set. If there
    is a target, we find the direction to the target and make the AI face it by setting
    `viewDirection`, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We check the distance to the target. If it''s more than `5` the AI will try
    to get closer. If the distance instead is less than `3`, it will try to back up
    a bit. The AI can also lose track of the target if it is more than 20 units away.
    In this case, it also changes state to `Idle`, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When it comes to movement, we can get the forward facing direction with the
    following line of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Depending on whether forward or backward is true, we can multiply this value
    with a suitable movement speed, and the call `setWalkDirection` on the `BetterCharacterControl`
    class with the result shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we should also call `setViewDirection`, as shown in the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using `BetterCharacterControl`, we get a lot of functionality for free. We only
    need a couple of Booleans to keep track of movement, and two `Vector3f` instances
    for directions. Target is what the AI will focus on (or follow, for now).
  prefs: []
  type: TYPE_NORMAL
- en: If we're familiar with `TestBetterCharacter` from jMonkeyEngine's test examples,
    we can recognize the movement handling from that class. For now, we only use the
    `forward`/`backward` functionality. It is a good idea to keep the rotation code
    as well, just in case we would like it to turn more smoothly in the future. The
    `walkDirection` vector is `0` by default. It can either be sent as it is sent
    to `physicsCharacter`, in which case the character will stop, or be modified to
    move in either direction. The `viewDirection` vector is simply set to look at
    the target for now, and passed on to `physicsCharacter`.
  prefs: []
  type: TYPE_NORMAL
- en: The logic in the `Follow` case mentioned previously is mostly there to have
    something to test with. Even so, it's AI behavior that seems to be sufficient
    for many MMOs. Once a target has been acquired, it will try to keep itself at
    a certain distance. It can also lose track of the target if it gets too far away.
    In this case, it falls back to the `Idle` state.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By linking this recipe together with [Chapter 4](ch04.html "Chapter 4. Mastering
    Character Animations"), *Mastering Character Animations*, we can easily make Jaime
    play some animations while he's moving.
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by adding the `AnimationManagerControl` class to the AI character using
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to tell it to play animations. In `AIControl`, find the forward and
    backwards brackets inside the `controlUpdate` method and add the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s create a test case world we can use for both this and many of the following
    recipes. First we need a world with physics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We will need some kind of object to stand on. The `PhysicsTestHelper` class
    has a few example worlds we can use.
  prefs: []
  type: TYPE_NORMAL
- en: 'We load up good old Jaime. Again, we use the `BetterCharacterControl` class
    since it offloads a lot of code for us. Since the Bullet physics world is different
    from the ordinary scenegraph, Jaime is added to `physicsSpace` as well as to the
    `rootNode`, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need to add our newly created AI control using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'There''s one more thing we need to do for this to work. The AI needs to track
    something. The easiest way we can get a moving target is to add a `CameraNode`
    class and supply `cam` from the application, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We set `camNode` to be the target, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: If we're familiar with cameras in OpenGL, we know they don't really have a physical
    existence. A `CameraNode` class in jMonkeyEngine gives us that. It tracks the
    camera's position and rotation, giving us something easy to measure. This will
    make it easier for us when we want the AI to follow it, since we can use the convenience
    of it being spatial.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, we can set `CameraNode` to be its target.
  prefs: []
  type: TYPE_NORMAL
- en: Sensing – vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'No matter how clever our AI is, it needs some senses to become aware of its
    surroundings. In this recipe, we''ll accomplish an AI that can look in a configurable
    arc in front of it, as shown in the following screenshot. It will build upon the
    AI control from the previous recipe, but the implementation should work well for
    many other patterns as well. The following screenshot shows Jaime with a visible
    representation of his line of sight:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Sensing – vision](img/6478OS_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To get our AI to sense something, we need to modify the `AIControl` class from
    the previous recipe by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: We need to define some values, a float called `sightRange`, for how far the
    AI can see, and an angle representing the field of view (to one side) in radians.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With this done, we create a `sense()` method. Inside we define a Quaternion
    called `aimDirection` that will be the ray direction relative to the AI's `viewDirection`
    field.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We convert the angle to a Quaternion and multiply it with `viewDirection` to
    get the direction of the ray, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We check whether the ray collides with any of the objects in our `targetableObjects`
    list using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If this happens, we set the target to be this object and exit the sensing loop,
    as shown in the following code. Otherwise, it should continue searching for it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If the sense method returns true, the AI now has a target, and should switch
    to the `Follow` state. We add a check for this in the `controlUpdate` method and
    the `Idle` case, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The AI begins in an idle state. As long as it has some items in the `targetableObjects`
    list, it will run the `sense` method on each update. If it sees anything, it will
    switch to the `Follow` state and stay there until it loses track of the target.
  prefs: []
  type: TYPE_NORMAL
- en: The `sense` method consists of a `for` loop that sends rays in an arc representing
    a field of view. Each ray is limited by `sightRange` and the loop will exit if
    a ray has collided with anything from the `targetableObjects` list.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Currently, it''s very difficult to visualize the results. Exactly what does
    the AI see? One way of finding out is to create `Lines` for each ray we cast.
    These should be removed before each new cast. By following this example, we will
    be able to see the extent of the vision. The following steps will give us a way
    of seeing the extent of an AI''s vision:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, we need to define an array for the lines; it should have the
    same capacity as the number of rays we''re going to cast. Inside the `for` loop,
    add the following code at the start and end:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `makeDebugLine` method that we mentioned previously will look like the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This simply takes each ray and makes something that can be seen by human eyes.
  prefs: []
  type: TYPE_NORMAL
- en: Sensing – hearing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The hearing we'll implement is one of the more basic models you can have. It's
    not as direct as vision, and requires a different approach. We'll assume that
    hearing is defined by `hearingRange`, and that the hearing ability has a linear
    fall off to that radius. We'll also assume that the sound emits something (in
    this case, footsteps), the volume of which is relative to the object's velocity.
    This would make sense in a stealth game, where sneaking should emit less sound
    than running. Sound is not blocked by obstacles or modified in any other way,
    apart from the distance between the target and the listener.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will start by defining a class that all objects emitting sounds will use.
    This will require the following steps to be performed:'
  prefs: []
  type: TYPE_NORMAL
- en: We create a class called `SoundEmitterControl`, extending `AbstractControl`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It needs three fields, a `Vector3f` called `lastPosition`, a float for `noiseEmitted`,
    and another float called `maxSpeed`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `controlUpdate` method, we sample the velocity the spatial has. This
    is the distance between the current `worldTranslation` and `lastPosition`. Divided
    by `tpf` (time-per-frame) we get the distance per second, as shown in the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If it''s actually moving, we see how much it moves compared to `maxSpeed`.
    Normalized between 0 and 1, this value becomes `noiseEmitted`, as shown in the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we set `lastPosition` to current `worldTranslation`. Now we will implement
    the changes to detect sound in `AIControl`. This will have five steps. We start
    by defining a float called `hearingRange`. In the `sense()` method, we parse the
    list of `targetableObjects` and see if they have `SoundEmitterControl`. If any
    does, we check the distance between it and the AI using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We get the `noiseEmitted` value from `SoundEmitterControl` and see how much
    is picked up by the AI, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If the threshold of 0.25f is exceeded, the AI has heard the sound and will react.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `SoundEmitterControl` class is meant to define how much sound a moving character
    makes. It does this by measuring the distance traveled each frame, and translates
    it to speed per second by dividing by the time-per-frame. It's been adapted slightly
    to work for the free-flying camera used in the test case. That's why `maxSpeed`
    is set to `25`. It uses `maxSpeed` to define how much noise the spatial is causing,
    on a scale of `0` to `1`.
  prefs: []
  type: TYPE_NORMAL
- en: In the AI control class, we use the `sense()` method to test whether the AI
    has heard anything. It has a `hearingRange` field, with the range falling in a
    linear fashion from the location of the AI. Outside this range, no sound would
    be detected by the AI.
  prefs: []
  type: TYPE_NORMAL
- en: The method measures the distance from the sound emitting spatial, and factors
    this with the noise value it emits. For this example, a threshold of 0.25 is used
    to define whether the sound is loud enough for the AI to react.
  prefs: []
  type: TYPE_NORMAL
- en: Decision making – Finite State Machine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Decision making for AI can be handled in many different ways, and one common
    way is to use a **Finite State Machine** (**FSM**). An FSM contains a number of
    predefined states. Each state has a set of functionality and behavior tied to
    it. Each state also has a number of conditions for when it can change to another
    state.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we'll define a state machine that will emulate a common AI behavior
    in games. In fact, it will be more advanced than many games, which usually have
    AI that can only either move around on a path, or attack. Our AI will have three
    states, **Patrol**, **Attack**, and **Retreat**, as shown in the following diagram:.
  prefs: []
  type: TYPE_NORMAL
- en: '![Decision making – Finite State Machine](img/6478OS_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: State diagram
  prefs: []
  type: TYPE_NORMAL
- en: The `PatrolState` will be the default and fallback state. It will perform random
    movement and will switch to `AttackState` if it spots an enemy.
  prefs: []
  type: TYPE_NORMAL
- en: The `AttackState` will handle firing and ammunition and will attack a target
    as long as it's visible and it has ammunition left. Then it will either return
    to `PatrolState` or flee using `RetreatState`.
  prefs: []
  type: TYPE_NORMAL
- en: The `RetreatState` will try to get away from a target for a set amount of time.
    After this, it will return to `PatrolState`, forgetting any fears it might previously
    have had.
  prefs: []
  type: TYPE_NORMAL
- en: All of our states will extend an abstract class called `AIState`, which we will
    also create in this recipe. This class in turn extends `AbstractControl`.
  prefs: []
  type: TYPE_NORMAL
- en: Worth noting is that all AI decision making and actions are handled from within
    the states. The states only relies on the AI control class to supply it with sensing
    updates (although this could also be handled by the states themselves).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will start by creating the `AIState` class. This will have two steps, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: We add a field to store `AIControl` and give it two abstract methods called
    `stateEnter` and `stateExit`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'These should be triggered when enabling and disabling the class, respectively.
    We override `setEnabled` to achieve this, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With `AIState` done, we can look at the first behavior, `PatrolState`. We can
    implement this by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: First of all we add a `Vector3f` field called `moveTarget`. This is the position
    it will try to reach, relative to the current position.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We add an `if` statement with three outcomes in the `controlUpdate` method,
    which is the main bulk of the logic in the class. The first clause should disable
    it and enable the `AttackState` if `AIControl` has found a suitable target using
    the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If its location is close enough to the `moveTarget` vector, it should pick
    a new one nearby, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Otherwise, it should keep moving towards the target, as shown in the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, in the `stateExit` method, we should make it stop moving using the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'That''s one state out of three; let''s look at the `AttackState`. We can implement
    this by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: The `AttackState` keeps track of values related to firing. It needs to have
    a float for `fireDistance`, which is how far the AI can fire; an integer called
    `clip`, which is how many rounds it has in the current clip; another integer called
    `ammo`, which defines how many rounds it has in total; and finally, a float called
    `fireCooldown`, which defines the time between each shot the AI fires.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `stateEnter` method, we give the AI some ammunition. This is mostly
    for testing purposes, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the state''s `controlUpdate` method, we do a number of checks. First we
    check whether `clip` is `0`. If this is true, we check whether `ammo` is also
    `0`. If this is also true, the AI must flee! We disable this state and enable
    `RetreatState` instead using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If the state still has ammo, it should refill the clip. We also set a longer
    time until it can fire again, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the main `if` statement, if the state has lost the target, it should disable
    the state and switch to `PatrolState`, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If it still has a target and is in a position to fire, it should fire, as shown
    in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, if it is still waiting for the weapon to cool down since the last
    shot, it should keep waiting, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The third and final state for our AI is `RetreatState`. We can implement this
    by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Like the `PatrolState`, it should have a `moveTarget` field that it tries to
    reach.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We also add a float called `fleeTimer` that defines for how long it will try
    to get away.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In its `controlUpdate` method, if `fleeTimer` has not reached `0` yet, and
    it still feels a threat, it will pick a location opposite from the target and
    move towards it, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Otherwise, it's all clear, and it will switch to `PatrolState`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first thing we did was define an abstract class called `AIState`. It's convenient
    to use the control pattern since it means we have access to the spatial and familiar
    ways to attach/detach states and turn them on and off.
  prefs: []
  type: TYPE_NORMAL
- en: The `stateEnter` and `stateExit` methods are called when the state is enabled
    and disabled, and happens on transition from and to other states. The class also
    expects there to be some kind of AI control class.
  prefs: []
  type: TYPE_NORMAL
- en: The first state extending `AIState` was the `PatrolState`. Its update method
    has three outcomes. If the AI has spotted something it can attack, it will change
    to the `AttackState`. Otherwise, if it's close to the place it has selected to
    move to, it will select a new target. Or, if it still has some way to go, it will
    just continue moving towards it.
  prefs: []
  type: TYPE_NORMAL
- en: The `AttackState` has a bit more functionality, as it also handles firing and
    ammunition management. Remember, if it has come here, the AI has already decided
    it should attack something. Hence, if it has no ammunition, it will switch to
    the `RetreatState` (although we generously give it some ammo every time it enters
    the state). Otherwise, it will attack or try attacking.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `RetreatState` only has one goal: to try to get as far away from the threat
    as possible. Once it has lost sight of the target, or has fled for the specified
    amount of time, it will switch to `PatrolState`.'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the logic is all contained within the associated state, which
    can be very convenient. The flow of the states will also always make sure the
    AI ends up in the `PatrolState` in the end.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the AI using cover
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having AI using cover is a huge step towards making characters seem more believable
    and it usually makes them more challenging as they don't die as quickly.
  prefs: []
  type: TYPE_NORMAL
- en: There are many ways to implement this functionality. In the simplest form, the
    AI is not aware of any cover. It's simply scripted (by a designer) to move to
    a predefined favorable position when they spot an enemy. A player playing the
    sequence for the first time can't possibly notice the difference between an AI
    taking the decision by itself. Hence, the task of creating a believable AI (for
    that situation) is accomplished.
  prefs: []
  type: TYPE_NORMAL
- en: A much more advanced way would be to use the same principles for cover, which
    was established in [Chapter 2](ch02.html "Chapter 2. Cameras and Game Controls"),
    *Cameras and Game Controls*. However, evaluating options also becomes far more
    complex and unpredictable. Unpredictable AI might be good from the player's perspective,
    but it's a nightmare from a designer's perspective.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we'll go for a middle ground. First of all, we will base the
    AI on the FSM created in the previous recipe, and add a new state that handles
    finding cover. We will then add cover points to a scene, from which the AI can
    pick a suitable one and move there before attacking.
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating the AI using cover](img/6478OS_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: State diagram
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s begin by defining a class called `CoverPoint`, extending `AbstractControl`
    by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: For now we can add a `Vector3f` called `coverDirection`. With getters and setters,
    that's all that's needed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We create a class called `SeekCoverState`, extending our `AIState` class from
    the previous recipe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It needs a list of `CoverPoints` called `availableCovers`, and a `CoverPoint`
    called `targetCover`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `stateEnter` method, it should look for a suitable cover point. We can
    do this with the following piece of code. It parses the list and takes the first
    `CoverPoint` where the dot product of the direction and `coverDirection` is positive:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the `controlUpdate` method, the AI should move towards `targetCover` if it
    has one.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once it gets close enough, `targetCover` should be set to null, indicating it
    should switch to `AttackState`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When this happens, `stateExit` should tell the AI to stop moving.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After adding the new state to the AI control class, to let it know it has the
    ability to seek cover, we also need to modify other states to enable it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Most suitable is `PatrolState`, where it can switch to `SeekCoverState` instead
    of `AttackState` when it spots a target.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If we have a test case for the Finite State Machine, all we would now need to
    do is to add some `CoverPoints` to a scene and see what happens.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `CoverPoint` class we created adds the behavior to any `Spatial` instances
    to act as a cover. In a game, you would most likely not see the `CoverPoint` spatial,
    but it's good for debug and editing purposes. The concept can be expanded to cover
    other types of interest points for AI, as well as modified to handle volumes,
    rather than points using the spatial's geometry.
  prefs: []
  type: TYPE_NORMAL
- en: Once the `SeekCoverState` is enabled, it will try to find a suitable cover point
    that's relative to the target's position (at that time). It does this using the
    dot product between `coverDirection` and the direction to the target. If this
    is positive, it means the target is in front of the cover, and it picks this as
    `targetCover`.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the AI reaches this, it sets `targetCover` to `null`. This means that
    when `controlUpdate` is called the next time, it will exit the state and enable
    `AttackState` instead. In a real game, the AI would most likely use some kind
    of navigation or pathfinding to get there. You can get an introduction to navigation
    in the next recipe. There is also the *Pathfinding: Our own A* pathfinder* recipe
    that covers implementing pathfinding later in the chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: With the current implementation of the AI, the result might be a bit erratic,
    since it doesn't remember the target's position. It might very well be that it
    doesn't see the target once it reaches the cover and instantly switches to `PatrolState`.
  prefs: []
  type: TYPE_NORMAL
- en: Generating NavMesh in SDK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Automatic NavMesh generation is a feature of the SDK available in the SceneExplorer.
    The NavMesh, as its name implies, is a mesh in which pathfinding can be applied
    to have AIs navigate through the game world. The generator takes a set of input
    values and, based on these, will create a mesh that stretches around obstacles.
    It can be seen as painted lines that the AI can use to know where it's safe to
    walk.
  prefs: []
  type: TYPE_NORMAL
- en: '![Generating NavMesh in SDK](img/6478OS_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: NavMesh on top of the terrain
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The feature is available through a plugin, which we have to download first.
    Refer to the *Downloading the plugins* section in [Appendix](apa.html "Appendix A. Information
    Fragments"), *Information Fragments*.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the plugin has been downloaded, we can open any scene in the **SceneComposer**
    window, as shown in the following screenshot:![How to do it...](img/6478OS_05_05.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **SceneExplorer** window, right-click on the top node, and navigate to
    **Add Spatial.. | NavMesh..** to bring up the **options** window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The simplest procedure from here is to click on **Finish** and see what happens.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A geometry called `NavMesh` will shortly appear in the list, and selecting it
    will display its reach. Blue lines indicate navigable paths.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If we're happy with it (which might be difficult to say if it's the first time
    we see one), we save the scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The method by which the generator works is controllable by the large number
    of settings available. It can be difficult to know how they all affect the result,
    and what kind of result we're after, anyway. The best way is simply to test different
    parameters until a desired result is achieved. Each line is a path the pathfinder
    can follow, and there should be no isolated islands. The less lines there are
    in the mesh, the more restricted the AI will be. Remember, that different settings
    are optimal for different scenes.
  prefs: []
  type: TYPE_NORMAL
- en: Pathfinding – using NavMesh
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pathfinding can be done in many different ways, and in this recipe we'll look
    at how to use the NavMesh generated in the previous recipe for pathfinding. We'll
    use jMonkeyEngine's AI plugin, which has a pathfinder designed to navigate NavMeshes.
  prefs: []
  type: TYPE_NORMAL
- en: We achieve this using the Control pattern, and will also implement a way to
    generate paths in a thread-safe way separate from the main update thread, to not
    impact the performance of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We'll need a scene with a NavMesh geometry in it. We also need to download the
    AI library plugin. Instructions on how to download a plugin in the SDK can be
    found in the *Downloading the plugins* section in [Appendix](apa.html "Appendix A. Information
    Fragments"), *Information Fragments*. The plugin is called `jME3 AI Library`.
    Once we have downloaded the plugin, we need to add it to the project. Right-click
    on the project and select **Properties**, then select **Libraries**, and then
    select **Add Library...**. Select **jME3 AI Library** and click on **Add Library**.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We start by defining the class that will generate the paths for us. This part
    will be implemented by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: We create a new class called `PathfinderThread`, which extends the `Thread`
    class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It needs a couple of fields, a `Vector3f` called `target`, a `NavMeshPathfinder`
    called `pathfinder`, and two Booleans, `pathfinding` and `running`, where `running`
    should be set to `true` by default.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The constructor should take a `NavMesh` object as input, and we instantiate
    the `pathfinder` with the same, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We override the `run` method to handle `pathfinding`. While running is `true`,
    the following logic should apply:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If `target` is not `null`, we set `pathfinding` to `true`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then we set the start position of the pathfinder to the AI''s current position,
    as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If the pathfinder can find a path, we set `target` to `null`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In either case, pathfinding is done, and `pathfinding` is set to `false`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, we tell the thread to sleep for one second until trying again, as
    shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'That''s the first step of the pathfinding handling. Next, we''ll define a class
    that will use this. This will be implemented by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: We create a new class that extends `AbstractControl` called `NavMeshNavigationControl`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It needs two fields, a `PathfinderThread` called `pathfinderThread` and a `Vector3f`
    called `waypointPosition`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Its constructor should take a node as input, and we use this to extract a `NavMesh`
    from, and pass it on to `pathfinderThread`, which is instantiated in the constructor
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we create a method to pass a position it should pathfind to using the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `controlUpdate` method is what does the bulk of the work.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We start by checking whether `waypointPosition` is `null`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If it is not null, we project `waypointPosition` and the spatials `worldTranslation`
    onto a 2D plane (by removing the `y` value), to see how far apart they are as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If the distance is more than `1f`, we tell the spatial to move in the direction
    of the waypoint. This recipe uses the `GameCharacterControl` class from [Chapter
    2](ch02.html "Chapter 2. Cameras and Game Controls"), *Cameras and Game Controls*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If the distance is less than `1f`, we set `waypointPosition` to `null`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If `waypointPosition` is null, and there is another waypoint to get from the
    pathfinder, we tell the pathfinder to step to the next waypoint and apply its
    value to our `waypointPosition` field as shown in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `PathfinderThread` handles pathfinding. To do this in a thread-safe way,
    we use the pathfinding Boolean to let other threads know it's currently busy,
    so that they don't try to read from the pathfinder.
  prefs: []
  type: TYPE_NORMAL
- en: Target is the position the pathfinder should try to reach. This is set externally
    and will be used to indicate whether the thread should attempt to pathfind or
    not. This is why we set it to null once pathfinding is successful.
  prefs: []
  type: TYPE_NORMAL
- en: We keep the thread running all the time, to avoid having to initialize it every
    time. The thread will wake up once a second to see whether there is any pathfinding
    to perform. If the delay was not there, it would use up resources, unnecessarily.
  prefs: []
  type: TYPE_NORMAL
- en: This class uses the `waypointPosition` field to store the current waypoint we're
    trying to reach. This is so that we don't need to look it up in the pathfinder
    every time, and thus risk interrupting an ongoing pathfinding. It also allows
    the AI to keep moving even if it's currently contemplating a new path.
  prefs: []
  type: TYPE_NORMAL
- en: The `controlUpdate` method first checks whether the `waypointPosition` is `null`.
    Null indicates it has no current goal, and should go to the pathfinder to see
    whether there is a new waypoint for it.
  prefs: []
  type: TYPE_NORMAL
- en: It can only get a new waypoint if `pathfinderThread` currently is not actively
    `pathfinding` and if there is a next waypoint to get.
  prefs: []
  type: TYPE_NORMAL
- en: If it already has a `waypointPosition` field, it will convert both the spatials
    position and the `waypointPosition` to 2D and see how far apart they are. This
    is necessary as we can't guarantee that `NavMesh` is exactly on the same plane
    as the spatial.
  prefs: []
  type: TYPE_NORMAL
- en: If it finds out that the distance is further than `1f`, it will find out the
    direction to the `waypointPosition` field and tell the spatial to move in that
    direction. Otherwise (if it's close enough), it will set the `waypointPosition`
    field to `null`.
  prefs: []
  type: TYPE_NORMAL
- en: Once it has reached the final waypoint, it will tell the spatial to stop.
  prefs: []
  type: TYPE_NORMAL
- en: Controlling groups of AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we'll kill two birds with one stone and implement both an interface
    for group AI management and look at weighted decision making.
  prefs: []
  type: TYPE_NORMAL
- en: In many ways, the architecture will be similar to the *Decision making – Finite
    State Machine* recipe. It's recommended to have a look at it before making this
    recipe. The big difference from the normal state machine is that instead of the
    states having definite outcomes, an AI Manager will look at the current needs,
    and assign units to different tasks.
  prefs: []
  type: TYPE_NORMAL
- en: This recipe will also make use of an `AIControl` class. This is also an extension
    of the `AIControl` that can be found in the *Creating a reusable AI control class*
    recipe.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, we'll use resource gathering units in an RTS. In this simplified
    game, there are two resources, wood and food. Food is consumed continuously by
    the workers and is the driving force behind the decision. The AI Manager will
    try to keep the levels of the food storage at a set minimum level, taking into
    account the current consumption rate. The scarcer the food becomes, the more units
    will be assigned to gather it. Any unit not occupied by food gathering will be
    assigned to wood gathering instead.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ll start by defining a `GatherResourceState` class. It extends the same
    `AIState` we defined in the *Decision making – Finite State Machine* recipe. This
    will be implemented by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: First of all it needs access to the AIControl called `aiControl`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It needs two additional fields, a `Spatial` defining something to pick up called
    `resource`, and an integer called `amountCarried`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In `controlUpdate` method, we define two branches. The first is for if the
    unit isn''t carrying anything, `amountCarried == 0`. In this case, the unit should
    move towards `resource`. Once it gets close enough, it should pick up some, and
    `amountCarried` should be increased, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the other case, `amountCarried` is more than `0`. Now, the unit should move
    towards the HQ instead. Once it's close enough, `finishTask()` is called.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `finishTask` method calls the AI Manager via `aiControl` to increase the
    resource amount that the state handles with the supplied amount as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Finally, we create two new classes that extend this class, namely `GatherFoodState`
    and `GatherWoodState`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'With the new state handled, we can focus on the `AIControl` class. It will
    follow the pattern established elsewhere in the chapter, but it needs some new
    functionality. This will be implemented by performing the following three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: It needs two new fields. The first is an `AIAppState` called `aiManager`. It
    also needs to keep track of its state in an `AIAppState` called `currentState`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `setSpatial` method, we add the two gathering states to our control,
    and make sure they''re disabled, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We also add a method to set the state, `setCurrentState`. Sidestepping conventions,
    it should not set an instance of a state, but enable an existing state the AI
    control class has, while disabling the previous state (if any), as shown in the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now we have to write a class that manages the units. It will be based on the
    `AppState` pattern, and consists of the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: We begin by creating a new class called `AIAppState` that extends `AbstractAppState`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It needs a `List<AIControl>` of the units it controls, called `aiList`. We also
    add `Map<Class<? extends AIStateRTS>`, `Spatial>` called `resources` that contains
    the resources in the world that can be gathered.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It then needs to keep track of its stock of `wood` and `food`. There are also
    fields for the current `foodConsumption` value per second, `minimumFoodStorage`
    it would like to keep, and a `timer` for how long before it wants to reevaluate
    its decisions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `update` method is pretty simple. It starts by subtracting `foodConsumption`
    from the storage. Then, if `timer` has reached `0`, it will call the `evaluate`
    method, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `evaluate` method, we begin by establishing the food requirement, as
    shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then we decide how urgent food gathering is, on a factor of 0.0 - 1.0, as shown
    in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now we decide how many workers should be assigned to food gathering by taking
    that factor and multiplying it by the total amount of workers, as shown in the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We create a helper method, called `workersByState`, that returns the number
    of workers assigned to a given state, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Comparing the current gathers with the required amount, we know whether to
    increase or decrease the number of food gatherers. We then set the state to change
    according to whether more or less food gatherers are required, as shown in the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can create another method, called `setWorkerState`, that loops through `aiList`
    and calls `setCurrentState` of the first available worker. It reruns `true` if
    it has successfully set the state of a unit, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The example implementation also requires that we set the resource for that
    state in the form of a spatial. This is so that the units know where they can
    pick up some of the resource. It can be set somewhere in the application, as shown
    in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the beginning of the game, we add one green food resource, and one brown
    wood resource, some distance away from the HQ (at 0,0,0). The `AIAppState` starts
    by looking at the current food storage, seeing it's low, it will assign an AI
    to go to the food resource and bring back food.
  prefs: []
  type: TYPE_NORMAL
- en: The `AIAppState` evaluate method starts by establishing the need for food gathering.
    It does this by dividing the food stores by the current requirement. By setting
    the food in the algorithm to not be able to exceed the requirement, we make sure
    we get a figure between 0.0 and 1.0.
  prefs: []
  type: TYPE_NORMAL
- en: It then takes the amount of units available, and decides how many of those should
    be gathering food, based on the `factorFood` figure, rounding it off to the nearest
    integer.
  prefs: []
  type: TYPE_NORMAL
- en: The result is compared to how many are currently on a food gathering mission,
    and adjusts the number to suit the current need, assigning them to either food
    or wood gathering.
  prefs: []
  type: TYPE_NORMAL
- en: The worker AI is completely controlled by the state they're set to by the manager,
    and in this recipe, all they can do is move to one resource or the other. They
    have no idle state, and are expected to always have some task.
  prefs: []
  type: TYPE_NORMAL
- en: The two states we use in the recipe are actually the same class. Both resources
    are gathered in the same way, and `GatherFoodState` and `GatherWoodState` are
    only used as identifiers. In a real game, they might well behave differently from
    each other. If not, it might be a good idea to use a parameterized version of
    `GatherResourceState` instead.
  prefs: []
  type: TYPE_NORMAL
- en: There's more
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This recipe only has two different states, where one is the deciding one. What
    do we do if we have, let''s say five equally important resources or tasks to consider?
    The principles are very much the same:'
  prefs: []
  type: TYPE_NORMAL
- en: Begin by normalizing the need for each task between 0.0 and 1.0\. This makes
    it easier to balance things.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, add all the values together, and divide each value by the sum. Now, each
    value is balanced with each other, and the total of all values is 1.0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this recipe, the evaluation is done continuously, but it might just as well
    be applied when an AI has finished a task, to see what it should do next. In that
    case, the task could be picked at random among the distributed values to make
    it more dynamic.
  prefs: []
  type: TYPE_NORMAL
- en: Pathfinding – our own A* pathfinder
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using the built-in functions of the `NavMesh` package might be enough for some,
    but in many cases we need customized pathfinding for our projects. Knowing how
    to implement, or even better, understanding A* (a-star) pathfinding, can take
    us a long way in our AI endeavors. It's easy to implement and very versatile.
    Correctly set up, it will always find the shortest path (and pretty fast too!).
    One of the drawbacks is that it can be memory-intensive in large areas if not
    kept in check.
  prefs: []
  type: TYPE_NORMAL
- en: A* is an algorithm that finds the shortest path in a graph. It's good at finding
    this quickly using **heuristics**, or an estimation of the cost to get from a
    position in the graph to the goal position.
  prefs: []
  type: TYPE_NORMAL
- en: Finding a good value for the heuristic (H) is very important in order to make
    it effective. In technical terms, H needs to be **admissible**. This means that
    the estimated cost should never exceed the actual cost.
  prefs: []
  type: TYPE_NORMAL
- en: Each position, called a node, will keep track of how the cost from the starting
    node to itself, using the current path. It will then choose the next node to go
    to base on this, cost plus the cost to the next node plus the estimated cost to
    the goal node.
  prefs: []
  type: TYPE_NORMAL
- en: A* could be said to work something like this; imagine that we're trying to find
    our way to a castle, through a maze. We're at an intersection, and can choose
    either the left path or the right path. We can see the castle in the distance
    to our left. We don't know anything about either path beyond the point where we're
    standing, but at least, taking the left path brings us closer to the castle, so
    it's natural to test that path.
  prefs: []
  type: TYPE_NORMAL
- en: Now, it could very well be that the left path is wrong, and much longer. That's
    the reason it also keeps track of how far it's travelled along the path. This
    is called G. The longer it travels along a path, the higher G will become. If
    the path also starts to deviate from the way to the castle, H will rise again.
    At some point G plus H might be higher than it would be at the entrance to the
    right path at the intersection. Then it will hop back to that point and see where
    the other path leads, until the point where G plus H along that path is higher.
  prefs: []
  type: TYPE_NORMAL
- en: This way, the AI using A* knows it's always traveled the shortest path once
    it exits the maze.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we'll use an estimated cost to the goal, H, that is the distance
    as-the-bird-flies between two nodes. This will guarantee that H is admissible
    and always equal to or less than the actual distance to travel.
  prefs: []
  type: TYPE_NORMAL
- en: We'll use the distance between nodes to calculate the cost to travel between
    them. This will be a lot to take in, but once done, we have a pathfinder we can
    use for many different applications.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ll start by defining the node object, in a bean pattern. This will be implemented
    by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: We create a new class called `WaypointNode` that extends `AbstractControl`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It needs three integers, `f`, `h`, and `g`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We also have to add two Booleans, `open` and `closed`, to aid the pathfinder,
    a list of other nodes, called `connections`, it's current position stored in `Vector3f`
    and another node as `parent`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now we can create the pathfinder itself. This will be implemented by performing
    the following steps. We create a new class called AStarPathfinder.
  prefs: []
  type: TYPE_NORMAL
- en: The pathfinder class needs a list of nodes, called `openList`, which are the
    nodes currently considered.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It has to know of the `startNode` and `goalNode`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `pathfind` method is the heart of the class. We can take a look at it in
    full, before explaining it, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It should begin by adding the `startNode` to `openList`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we define a while loop that always picks the first node in `openList`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Inside this loop, we create another `for` loop that iterates through all the
    currently selected connected nodes, called neighbors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If the neighboring node is not in `openList`, it should be added there. It
    should also set the current node to `parentNode` of the `neighbor` node, as shown
    in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'While doing this, `g` of the neighbor should be set to current node''s `G`
    plus the distance between the two nodes, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Also, if `H` has not already been calculated for `neighbor`, it should, by
    measuring the distance between `neighbor` and `goalNode`. `F` should be updated
    by adding `G` and `H` together, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It might also be that a shorter path has been discovered since `neighbor` was
    calculated. In this case, the neighbor should be updated again with the `current`
    node as `parent`. Do that and repeat the previous two steps.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If `neighbor` is closed, it shouldn't do anything with it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the neighbors have been parsed, the current node should be removed from
    `openList`. `openList` should then be reordered according to the total cost, `F`,
    of the nodes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The looping of `openList` should exit, either when it's empty, or when the `goalNode`
    has been reached, which is indicated by when it's closed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'When the pathfinding is done, the shortest path can be extracted by going through
    the parent nodes starting with the `goalNode`, as shown in the following code.
    Reversing the resulting list will yield the best path, from `startNode` to `goalNode`.
    This can be implemented as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The node bean that we created stores information about the state of the node,
    which is set by the pathfinder as it passes, or considers passing a node. The
    `g` value is the total cost to this node, along the current path, from the starting
    node. `h` is the estimated value left to the `goalNode`. In this recipe, it's
    the shortest distance possible. To be the most effective, it should be as close
    to the actual distance as possible, without exceeding it. This is to guarantee
    that it finds the shortest path. `F` is simply `g` and `h` added together, becoming
    the total estimated cost of the path using this node, and is the value used by
    the algorithm to consider.
  prefs: []
  type: TYPE_NORMAL
- en: These values are stored as integers, rather than floats. This is better both
    for memory and processing purposes. We get around lower-than-one distances by
    multiplying them with 100.
  prefs: []
  type: TYPE_NORMAL
- en: It also keeps track of whether it's currently open or closed. It's quicker to
    query the node itself, than seeing if the list contains it. The node actually
    has three states, either open, closed, or the standard, neither which is when
    it has not yet been considered for the path. The parent of a node defines from
    which other node the path came to this node.
  prefs: []
  type: TYPE_NORMAL
- en: '`openList` contains all the nodes the pathfinder is currently considering.
    It starts with only the `startNode`, adding all its neighbors, since none are
    either open or closed at this stage. It also sets the parent of the node, calculates
    the cost to get to this node, and estimates the cost left to the goal (if it has
    not been calculated before). It only needs to do this once per node, as long as
    the goal is not moving.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, `openList` has a few new nodes to work with, and the current node is removed
    from the list. At the end of the `while` loop, we sort `openList` according to
    `f-cost` of the nodes, so that it always starts looking at the node with the lowest
    total cost. This is to make sure it doesn't spend any unnecessary time looking
    at paths which are not optimal.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm can be considered to be successful once the `goalNode` has been
    put in `openList` and is set to closed. We can't end searching just because the
    `goalNode` enters `openList`. Since we also reconsider nodes if we find a shorter
    path to the node, we want to check all the `goalNodes` neighbors as well before
    ending the search.
  prefs: []
  type: TYPE_NORMAL
- en: If there is no path available to the `goalNode`, `openList` will become empty
    before the `goalNode` is closed, and the search will fail.
  prefs: []
  type: TYPE_NORMAL
