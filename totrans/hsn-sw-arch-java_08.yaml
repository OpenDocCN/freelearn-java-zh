- en: 'Chapter 6: Exploring Essential Java Architectural Patterns'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章：探索基本的Java架构模式
- en: In the last chapter, you had an overview of the most common development models,
    from the older (but still used) **Waterfall model** to the widely used and appreciated
    **DevOps** and **Agile**.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你对最常见的发展模型有了概述，从较老但仍被使用的**瀑布模型**到广泛使用且受到赞赏的**DevOps**和**敏捷**。
- en: In this chapter, you will have a look at some very common architectural patterns.
    These architectural definitions are often considered basic building blocks that
    are useful to know about in order to solve common architectural problems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将查看一些非常常见的架构模式。这些架构定义通常被认为是基本构建块，了解它们对于解决常见的架构问题非常有用。
- en: 'You will learn about the following topics in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将了解以下主题：
- en: Encapsulation and hexagonal architectures
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 封装和六边形架构
- en: Learning about multi-tier architectures
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解多层架构
- en: Exploring Model View Controller
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索模型-视图-控制器
- en: Diving into event-driven and reactive approaches
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入了解事件驱动和响应式方法
- en: Designing for large-scale adoption
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计适用于大规模采用
- en: Case studies and examples
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 案例研究和示例
- en: After reading this chapter, you'll know about some useful tools that can be
    used to translate requirements into well-designed software components that are
    easy to develop and maintain. All the patterns described in this chapter are,
    of course, orthogonal to the development models that we have seen in the previous
    chapters; in other words, you can use all of them regardless of the model used.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读本章后，你将了解一些有用的工具，可以将需求转换为易于开发和维护的精心设计的软件组件。本章中描述的所有模式当然都是与我们在前几章中看到的开发模型正交的；换句话说，你可以使用它们中的任何一个，无论使用哪种模型。
- en: 'Let''s start with one of the most natural architectural considerations: encapsulation
    and hexagonal architectures.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从最自然的架构考虑因素之一开始：封装和六边形架构。
- en: Encapsulation and hexagonal architectures
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 封装和六边形架构
- en: '**Encapsulation** is a concept taken for granted by programmers who are used
    to working with object-oriented programming and, indeed, it is quite a basic idea.
    When talking about encapsulation, your mind goes to the getters and setters methods.
    To put it simply, you can hide fields in your class, and control how the other
    objects interact with them. This is a basic way to protect the status of your
    object (internal data) from the outside world. In this way, you decouple the state
    from the behavior, and you are free to switch the data type, validate the input,
    change formats, and so on. In short, it''s easy to understand the advantages of
    this approach.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**封装**是习惯于使用面向对象编程的程序员所接受的概念，确实，它是一个非常基本的概念。当谈到封装时，你的思维会转向获取器和设置器方法。简单来说，你可以在你的类中隐藏字段，并控制其他对象如何与之交互。这是一种基本的方法，可以保护你的对象状态（内部数据）不受外界影响。这样，你就可以将状态与行为解耦，你可以自由地切换数据类型、验证输入、更改格式等等。简而言之，这种方法的优点很容易理解。'
- en: However, encapsulation is a concept that goes beyond simple getters and setters.
    I personally find some echoes of this concept in other modern approaches, such
    as APIs and microservices (more on this in [*Chapter 9*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230),
    *Designing Cloud-Native Architectures*). In my opinion, encapsulation (also known
    as **information hiding**) is all about modularization, in that it's about having
    objects talk to each other by using defined contracts.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，封装是一个超越简单获取器和设置器的概念。我个人在其他现代方法中找到了这个概念的回声，例如API和微服务（更多内容请参阅[*第9章*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230)，*设计云原生架构*）。在我看来，封装（也称为**信息隐藏**）完全是关于模块化的，因为它涉及到通过定义的合约让对象相互通信。
- en: If those contracts (in this case, normal method signatures) are stable and generic
    enough, objects can change their internal implementation or can be swapped with
    other objects without breaking the overall functionality. That is, of course,
    a concept that fits nicely with interfaces. An interface can be seen as a *super
    contract* (a set of methods) and a way to easily identify compatible objects.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这些合约（在这种情况下，普通方法签名）足够稳定和通用，对象可以更改其内部实现或与其他对象交换而不破坏整体功能。当然，这是一个非常适合接口的概念。接口可以被视为一种*超级合约*（一组方法）以及识别兼容对象的一种方式。
- en: 'In my personal view, the concept of encapsulation is extended with the idea
    of hexagonal architectures. Hexagonal architectures, theorized by Alistair Cockburn
    in 2005, visualize an application component as a hexagon. The following diagram
    illustrates this:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在我个人看来，封装的概念通过六边形架构的想法得到了扩展。六边形架构是由Alistair Cockburn在2005年提出的理论，它将应用程序组件可视化为六边形。以下图解说明了这一点：
- en: '![Figure 6.1 – Hexagonal architecture schema'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.1 – 六边形架构图'
- en: '](img/Figure_6.01_B16354.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_6.01_B16354.jpg)'
- en: Figure 6.1 – Hexagonal architecture schema
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1 – 六边形架构图
- en: 'As you can see in the preceding diagram, the business logic stays at the core
    of this representation:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，业务逻辑是这个表示的核心：
- en: '**Core**: The core can be intended to be the domain model, as seen in [*Chapter
    4*](B16354_04_Final_JM_ePUB.xhtml#_idTextAnchor089), *Best Practices for Design
    and Development*. It''s the real distinctive part of your application component
    – the one solving the business problem.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**核心**：核心可以是指领域模型，如在第[*第4章*](B16354_04_Final_JM_ePUB.xhtml#_idTextAnchor089)中看到的，*设计和开发最佳实践*。它是您应用程序组件的真实独特部分——解决业务问题的那部分。'
- en: '**Port**: Around the core, the ports are represented. The domain model uses
    the ports as a way to communicate with other application components, being other
    modules or systems (such as databases and other infrastructures). The ports are
    usually mapped to use cases of the module itself (such as sending payments). However,
    more technical interpretations of ports are not unusual (such as persisting to
    a database).'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端口**：在核心周围表示端口。领域模型使用端口作为与其他应用程序组件（如其他模块或系统，例如数据库和其他基础设施）通信的方式。端口通常映射到模块本身的用例（例如发送支付）。然而，端口的技术解释并不罕见（例如持久化到数据库）。'
- en: '**Adapter**: The layer outside the ports represents the adapters. The Adapter
    is a well-known pattern in which a piece of software acts as an interpreter between
    two different sides. In this case, it translates from the domain model to the
    outside world, and vice versa, according to what is defined in each port. While
    the diagram is in the shape of a hexagon, that''s not indicative of being limited
    to six ports or adapters. That''s just a graphical representation, probably related
    to the idea of representing the ports as discrete elements (which is hard to do
    if you represent the layers as concentric circles). The hexagonal architecture
    is also known as **Ports and Adapters**.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**适配器**：端口外层的层代表适配器。适配器是一种广为人知的模式，其中软件作为两个不同方面之间的解释器。在这种情况下，它根据每个端口中定义的内容将领域模型转换为外部世界，反之亦然。虽然这个图是六边形的形状，但这并不表明它仅限于六个端口或适配器。这只是一个图形表示，可能与其将端口表示为离散元素（如果你将层表示为同心圆则很难做到）的想法有关。六边形架构也被称为**端口和适配器**。'
- en: 'Important Note:'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示：
- en: 'There is another architectural model implementing encapsulation that is often
    compared to hexagonal architectures: **Onion architectures**. Whether the hexagonal
    architecture defines the roles mentioned earlier, such as core, ports, and adapters,
    the Onion architecture focuses the modeling on the concept of layers. There is
    an inner core (the Domain layer) and then a number of layers around it, usually
    including a repository (to access the data of the Domain layer), services (to
    implement business logic and other interactions), and a presentation layer (for
    interacting with the end user or other systems). Each layer is supposed to communicate
    only with the layer above itself.'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 另有一种实现封装的架构模型，常与六边形架构相比较：**洋葱架构**。无论六边形架构是否定义了之前提到的角色，如核心、端口和适配器，洋葱架构将建模重点放在层概念上。有一个内部核心（领域层），然后是围绕它的多个层，通常包括存储库（以访问领域层的数据）、服务（以实现业务逻辑和其他交互）和表示层（与最终用户或其他系统交互）。每个层只应与它上面的层进行通信。
- en: Hexagonal architectures and Domain Driven Design
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 六边形架构和领域驱动设计
- en: Encapsulation is a cross-cutting concern, applicable to many aspects of a software
    architecture, and hexagonal architectures are a way to implement this concept.
    As we have seen, encapsulation has many touchpoints with the concept of **Domain-Driven
    Design** (**DDD**). The core, as mentioned, can be seen as the domain model in
    DDD. The Adapter pattern is also very similar to the concept of the Infrastructure
    layer, which in DDD is the layer mapping the domain model with the underlying
    technology (and abstracting such technology details).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 封装是一个横切关注点，适用于软件架构的许多方面，而六边形架构是实现这一概念的一种方式。正如我们所见，封装与**领域驱动设计**（**DDD**）的概念有很多接触点。核心，正如所提到的，可以看作是DDD中的领域模型。适配器模式也非常类似于基础设施层的概念，在DDD中，这一层是将领域模型与底层技术（以及抽象这些技术细节）映射的层。
- en: It's then worth noticing that DDD is a way more complete approach, as seen in
    [*Chapter 4*](B16354_04_Final_JM_ePUB.xhtml#_idTextAnchor089), *Best Practices
    for Design and Development*, tackling things such as defining a language for creating
    domain model concepts and implementing some peculiar use cases (such as where
    to store data, where to store implementations, how to make different models talk
    to each other). Conversely, hexagonal architectures are a more practical, immediate
    approach that may directly address a concern (such as implementing encapsulation
    in a structured way), but do not touch other aspects (such as how to define the
    objects in the core).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，DDD是一种更完整的方法，如[*第4章*](B16354_04_Final_JM_ePUB.xhtml#_idTextAnchor089)，“设计和开发的最佳实践”中所示，它处理诸如定义创建领域模型概念的语言和实现一些特殊用例（如数据存储的位置、实现存储的位置、如何使不同的模型相互通信）等问题。相反，六边形架构是一种更实际、更直接的方法，可以直接解决一个关注点（如以结构化的方式实现封装），但不涉及其他方面（如如何定义核心中的对象）。
- en: Encapsulation and microservices
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 封装和微服务
- en: While we are going to talk about microservices in [*Chapter 9*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230),
    *Designing Cloud-Native Architectures*, I'm sure you are familiar with, or at
    least have heard about, the concept of microservices. In this section, it's relevant
    to mention that the topic of encapsulation is one of the core reasonings behind
    microservices. Indeed, a microservice is considered to be a disposable piece of
    software, easy to scale and to interoperate with other similar components through
    a well-defined API.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将在[*第9章*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230)，“设计云原生架构”中讨论微服务时，我相信你已经熟悉，或者至少听说过微服务的概念。在本节中，提到封装是微服务背后的核心理由之一是相关的。确实，一个微服务被认为是一块可丢弃的软件，易于扩展，并且可以通过一个定义良好的API与其他类似组件进行交互。
- en: Moreover, each microservice composing an application is (in theory) a product,
    with a dedicated team behind it and using a set of technologies (including the
    programming language itself) different from the other microservices around it.
    For all those reasons, encapsulation is the basis of the microservices applications,
    and the concepts behind it (as the ones that we have seen in the context of hexagonal
    architectures) are intrinsic in microservices.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，组成应用程序的每个微服务（在理论上）都是一个产品，它背后有一个专门的团队，并使用一套技术（包括编程语言本身），与周围的微服务不同。出于所有这些原因，封装是微服务应用程序的基础，其背后的概念（如我们在六边形架构的上下文中看到的）是微服务内在的。
- en: So, as you now know, the concept of modularization is in some way orthogonal
    to software entities. This need to define clear responsibilities and specific
    contracts is a common way to address complexity, and it has a lot of advantages,
    such as testability, scaling, extensibility, and more. Another common way to define
    roles in a software system is the multi-tier architecture.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，正如你现在所知道的，模块化的概念在某种程度上与软件实体是正交的。这种定义清晰责任和具体契约的需求是解决复杂性的常见方法，并且它有很多优点，如可测试性、可扩展性、可扩展性等。在软件系统中定义角色的另一种常见方法是多层架构。
- en: Learning about multi-tier architectures
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解多层架构
- en: '**Multi-tier architectures**, also known as **n-tier architectures**, are a
    way to categorize software architectures based on the number and kind of tiers
    (or layers) encompassing the components of such a system. A tier is a logical
    grouping of the software components, and it''s usually also reflected in the physical
    deployment of the components. One way of designing applications is to define the
    number of tiers composing them and how they communicate with each other. Then,
    you can define which component belongs to which tier. The most common types of
    multi-tier applications are defined in the following list:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**多层架构**，也称为**n层架构**，是根据包含系统组件的层数和类型来分类软件架构的一种方式。层是软件组件的逻辑分组，通常也反映在组件的物理部署中。设计应用程序的一种方法是为它们定义层数以及它们如何相互通信。然后，您可以定义哪个组件属于哪个层。以下列表中定义了最常见的多层应用程序类型：'
- en: The simplest (and most useless) examples are **single-tier applications**, where
    every component falls into the same layer. So, you have what is called a monolithic
    application.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最简单（也是最无用的）例子是**单层应用程序**，其中每个组件都属于同一层。因此，您拥有所谓的单体应用程序。
- en: Things get slightly more interesting in the next iteration, that is, **two-tier
    applications**. These are commonly implemented as client-server systems. You will
    have a layer including the components provided to end users, usually through some
    kind of graphical or textual user interfaces, and a layer including the backend
    systems, which normally implement the business rules and the transactional functionalities.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在下一个迭代中，事情会变得稍微有趣一些，即**两层应用程序**。这些通常作为客户端-服务器系统实现。您将有一个包含提供给最终用户的组件的层，通常通过某种图形或文本用户界面，以及一个包含后端系统的层，这些系统通常实现业务规则和事务功能。
- en: '**Three-tier applications** are a very common architectural setup. In this
    kind of design, you have a presentation layer taking care of interaction with
    end users. We also have a business logic layer implementing the business logic
    and exposing APIs consumable by the presentation layer, and a data layer, which
    is responsible for storing data in a persistent way (such as in a database or
    on a disk).'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**三层应用程序**是一种非常常见的架构设置。在这种设计中，您有一个负责与最终用户交互的表现层。我们还有一个实现业务逻辑并暴露给表现层使用的API的业务逻辑层，以及一个负责以持久方式存储数据的数据层（例如在数据库或磁盘上）。'
- en: More than three layers can be contemplated, but that is less conventional, meaning
    that the naming and roles may vary. Usually, the additional tiers are specializations
    of the business logic tier, which was seen in the previous point. An example of
    a four-tier application was detailed in [*Chapter 4*](B16354_04_Final_JM_ePUB.xhtml#_idTextAnchor089),
    *Best Practices for Design and Development*, when talking about the layered architecture
    of DDD.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以考虑超过三层，但这不太常见，意味着命名和角色可能有所不同。通常，额外的层是业务逻辑层的特殊化，这在前面已经提到。一个四层应用程序的例子在[*第4章*](B16354_04_Final_JM_ePUB.xhtml#_idTextAnchor089)，*设计和开发的最佳实践*中详细描述，当时讨论了DDD的分层架构。
- en: 'The following diagram illustrates the various types of multi-tier architectures:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图示展示了各种类型的多层架构：
- en: '![Figure 6.2 – Multi-tier architectures'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.2 – 多层架构'
- en: '](img/Figure_6.02_B16354.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_6.02_B16354.jpg)'
- en: Figure 6.2 – Multi-tier architectures
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 – 多层架构
- en: 'The advantages of a multi-tier approach are similar to those that you can achieve
    with the modularization of your application components (more on this in [*Chapter
    9*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230), *Designing Cloud-Native Architectures*).
    Some of the advantages are as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 多层架构的优点与通过模块化您的应用程序组件所能实现的优势相似（更多关于这一点请参阅[*第9章*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230)，*设计云原生架构*）。以下是一些优点：
- en: 'The most relevant advantage is probably **scalability**. This kind of architecture
    allows each layer to scale independently from each other. So, if you have more
    load on the business (or frontend, or database) layer, you can scale it (vertically,
    by adding more computational resources, or horizontally, by adding more instances
    of the same component) without having a huge impact on the other components. And
    that is also linked to increased stability overall: an issue on one of the layers
    is not so likely to influence the other layers.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最相关的优势可能是**可扩展性**。这种架构允许每一层独立于其他层进行扩展。因此，如果你在业务（或前端，或数据库）层有更多的负载，你可以对其进行扩展（垂直扩展，通过添加更多计算资源，或水平扩展，通过添加更多相同组件的实例），而不会对其他组件产生巨大影响。这也与整体稳定性的提高有关：一个层的问题不太可能影响其他层。
- en: Another positive impact is improved **testability**. Since you are forced to
    define clearly how the layers communicate with each other (such as by defining
    some APIs), it becomes easier to test each layer individually by using the same
    communication channel.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个积极的影响是提高了**可测试性**。由于你必须明确定义层之间如何通信（例如，通过定义一些API），因此使用相同的通信通道单独测试每个层变得更加容易。
- en: '**Modularity** is also an interesting aspect. Having layers talking to each
    other will enforce a well-defined API to decouple each other. For this reason,
    it is possible (and is very common) to have different actors on the same layer,
    interacting with the other layer. The most widespread example here is related
    to the frontend. Many applications have different versions of the frontend (such
    as a web GUI and a mobile app) interacting with the same underlying layer.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模块化**也是一个有趣的方面。层与层之间的交互将强制执行一个定义良好的API来解耦它们。因此，在同一层上可以有不同角色，与另一层交互。最普遍的例子是前端。许多应用程序有不同的前端版本（如Web
    GUI和移动应用）与同一底层层交互。'
- en: Last but not least, by **layering** your application, you will end up having
    more parallelization in the development process. Sub teams can work on a layer
    without interfering with each other. The layers, in most cases, can be released
    individually, reducing the risks associated with a big bang release.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，通过**分层**你的应用程序，你将在开发过程中获得更多的并行化。子团队可以在不相互干扰的情况下工作在某一层。在大多数情况下，层可以单独发布，从而降低与一次性发布相关联的风险。
- en: There are, of course, drawbacks to the multi-tier approach, and they are similar
    to the ones you can observe when adopting other modular approaches, such as microservices.
    The main disadvantage is to do with **tracing**.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，多级方法也有其缺点，它们与采用其他模块化方法时观察到的缺点相似，例如微服务。主要缺点与**跟踪**有关。
- en: It may become hard to understand the end-to-end path of each transaction, especially
    (as is common) if one call in a layer is mapped to many calls in other layers.
    To mitigate this, you will have to adopt specific monitoring to trace the path
    of each call; this is usually done by injecting unique IDs to correlate the calls
    to each other to help when troubleshooting is needed (such as when you want to
    spot where the transactions slow down) and in general to give better visibility
    into system behavior. We will study this approach (often referred to as tracing
    or observability) in more detail in [*Chapter 9*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230),
    *Designing Cloud-Native Architectures*.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 理解每个事务的端到端路径可能变得很困难，特别是如果一层中的一个调用映射到其他层中的多个调用（这是常见的）。为了减轻这种情况，你必须采用特定的监控来跟踪每个调用的路径；这通常是通过注入唯一的ID来关联调用，以帮助在需要故障排除时（例如，当你想找出事务变慢的地方）以及在一般情况下提供更好的系统行为可见性。我们将在[*第9章*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230)中更详细地研究这种方法（通常称为跟踪或可观察性），*设计云原生架构*。
- en: 'In the next section, we will have a look at a widespread pattern: Model View
    Controller.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨一个广泛使用的模式：模型-视图-控制器。
- en: Exploring Model View Controller
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索模型-视图-控制器
- en: At first glance, **Model View Controller** (**MVC**) may show some similarities
    with the classical three-tier architecture. You have the classification of your
    logical objects into three kinds and a clear separation between presentation and
    data layers. However, MVC and the three-tier architecture are two different concepts
    that often coexist.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 初看之下，**模型-视图-控制器**（**MVC**）可能显示出与经典三层架构的一些相似之处。你的逻辑对象被分为三类，并且表示层和数据层之间有明确的分离。然而，MVC和三层架构是两个不同的概念，它们经常共存。
- en: The three-tier architecture is an architectural style where the elements (presentation,
    business, and data) are split into different deployable artifacts (possibly even
    using different languages and technologies). These elements are often executed
    on different servers in order to achieve the already discussed goals of scalability,
    testability, and so on.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, MVC is not an architectural style, but a design pattern.
    For this reason, it does not suggest any particular deployment model regarding
    its components, and indeed, very often the Model, View, and Controller coexist
    in the same application layer.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Taking apart the *philosophical* similarity and differences, from a practical
    point of view, MVC is a common pattern for designing and implementing the presentation
    layer in a multi-tier architecture.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'In MVC, the three essential components are listed as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '**Model**: This component takes care of abstracting access to the data used
    by the application. There is no logic to the data presented here.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**View**: This component takes care of the interaction with the users (or other
    external systems), including the visual representation of data (if expected).'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Controller**: This component receives the commands (often mediated by the
    view) from the users (or other external systems) and updates the other two components
    accordingly. The **Controller** is commonly seen as a facilitator (or glue) between
    the **Model** and **View** components.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows you the essential components of MVC:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – MVC components'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.03_B16354.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.3 – MVC components
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'Another difference between MVC and the three-tier architecture is clear from
    the interaction of the three components described previously: in a three-tier
    architecture, the interaction is usually linear; that is, the presentation layer
    does not interact directly with the data layer. MVC classifies the kind and goal
    of each interaction but also allows all three components to interact with each
    other, forming a triangular model.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: MVC is commonly implemented by a framework or middleware and is used by the
    developer, specific interfaces, hooks, conventions, and more.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: In the real world, this pattern is commonly implemented either at the server
    side or the client side.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: Server-side MVC
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **Java Enterprise Edition** (**JEE**) implementation is a widely used example
    (even if not really a modern one) of an MVC server-side implementation. In this
    section, we are going to mention some *classical* Java implementations of web
    technologies (such as JSPs and servlets) that are going to be detailed further
    in [*Chapter 10*](B16354_10_Final_JM_ePUB.xhtml#_idTextAnchor250), *Implementing
    User Interaction*.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 'In terms of relevance to this chapter, it''s worthwhile knowing that in the
    JEE world, the MVC model is implemented using Java beans, the view is in the form
    of JSP files, and the controller takes the form of servlets, as shown in the following
    diagram:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4 – MVC with JEE'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.4 – 使用JEE的MVC'
- en: '](img/Figure_6.04_B16354.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_6.04_B16354.jpg)'
- en: Figure 6.4 – MVC with JEE
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4 – 使用JEE的MVC
- en: As you can see, in this way, the end user interacts with the web pages generated
    by the **JSPs** (the **View**), which are bound to the Java **Beans** (the **Model**)
    keeping the values displayed and collected. The overall flow is guaranteed by
    the **Servlets** (the **Controller**), which take care of things such as the binding
    of the Model and View, session handling, page routing, and other aspects that
    *glue* the application together. Other widespread Java MVC frameworks, such as
    **Spring MVC**, adopt a similar approach.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，通过这种方式，最终用户与由**JSPs**（视图）生成的网页交互，这些视图绑定到Java **Beans**（模型），保持显示和收集的值。整体流程由**Servlets**（控制器）保证，它们负责诸如模型和视图的绑定、会话处理、页面路由以及其他将应用程序粘合在一起的方面。其他广泛使用的Java
    MVC框架，如**Spring MVC**，采用类似的方法。
- en: Client-side MVC
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 客户端MVC
- en: MVC can also be completely implemented on the client side, which usually means
    that all three roles are played by a web browser. The de facto standard language
    for client-side MVC is **JavaScript**.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: MVC也可以完全在客户端实现，这通常意味着所有三个角色都由一个网络浏览器扮演。客户端MVC的事实标准语言是**JavaScript**。
- en: Client-side MVC is almost identical to **single-page applications**. We will
    see more about single-page applications in [*Chapter 10*](B16354_10_Final_JM_ePUB.xhtml#_idTextAnchor250),
    *Implementing User Interaction*, but basically, the idea is to minimize page changes
    and full-page reloads in order to provide a near-native experience to users while
    keeping the advantages of a web application (such as simplified distribution and
    centralized management).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端MVC几乎与**单页应用程序**相同。我们将在[*第10章*](B16354_10_Final_JM_ePUB.xhtml#_idTextAnchor250)中了解更多关于单页应用程序的内容，*实现用户交互*，但基本想法是尽量减少页面更改和完整页面重新加载，以便在保持Web应用程序（如简化分发和集中管理）优势的同时，为用户提供接近原生的体验。
- en: The single-page applications approach is not so different from server-side MVC.
    This technology commonly uses a templating language for views (similar to what
    we have seen with JSPs on the server side), a model implementation for keeping
    data and storing it in local browser storage or remotely calling the remaining
    APIs exposed from the backend, and controllers for navigation, session handling,
    and more support code.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 单页应用程序方法与服务器端MVC并没有太大的不同。这项技术通常使用模板语言来处理视图（类似于我们在服务器端看到的JSPs），用于保持数据和将其存储在本地浏览器存储或远程调用后端暴露的剩余APIs的模型实现，以及用于导航、会话处理和其他支持代码的控制器。
- en: In this section, you learned about MVC and related patterns, which are considered
    a classical implementation for applications and have been useful for nicely setting
    up all the components and interactions, separating the user interface from the
    implementation.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你了解了MVC和相关模式，这些被认为是应用程序的经典实现，并且对于很好地设置所有组件和交互、将用户界面与实现分离非常有用。
- en: In the next section, we will have a look at the event-driven and reactive approaches.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨事件驱动和响应式方法。
- en: Diving into event-driven and reactive approaches
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入探讨事件驱动和响应式方法
- en: '**Event-driven architecture** isn''t a new concept. My first experiences with
    it were related to GUI development (with **Java Swing**) a long time ago. But,
    of course, the concept is older than that. And the reason is that events, meaning
    *things that happen*, are a pretty natural phenomenon in the real world.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**事件驱动架构**不是一个新概念。我第一次接触它是在很久以前与GUI开发（使用**Java Swing**）相关。但当然，这个概念比那还要古老。原因是事件，即*发生的事情*，在现实世界中是一种相当自然的现象。'
- en: There is also a technological reason for the event-driven approach. This way
    of programming is deeply related to (or in other words, is most advantageous when
    used together with) asynchronous and non-blocking approaches, and these paradigms
    are inherently efficient in terms of the use of resources.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 事件驱动方法还有一个技术原因。这种编程方式与（或者说，最有利于与）异步和非阻塞方法密切相关，而这些范例在资源使用方面本质上效率很高。
- en: 'Here is a diagram representing the event-driven approach:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个表示事件驱动方法的图表：
- en: '![Figure 6.5 – Event -driven approach'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.5 – 事件驱动方法'
- en: '](img/Figure_6.05_B16354.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_6.05_B16354.jpg)'
- en: Figure 6.5 – Event-driven approach
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 – 事件驱动方法
- en: As shown in the previous diagram, the whole concept of the event-driven approach
    is to have our application architecture react to external events. When it comes
    to GUIs, such events are mostly user inputs (such as clicking a button, entering
    data in text fields, and so on), but events can be many other things, such as
    changes in the price of a stock option, a payment transaction coming in, data
    being collected from sensors, and so on.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，事件驱动方法的整体概念是让我们的应用程序架构对外部事件做出反应。当涉及到GUI时，这些事件主要是用户输入（如点击按钮、在文本字段中输入数据等），但事件可以是许多其他事情，如股票期权价格的变动、支付交易的到来、从传感器收集的数据等。
- en: Another pattern worth mentioning is the **actor model** pattern, which is another
    way to use messaging to maximize the concurrency and throughput of a software
    system.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得提到的模式是**actor模型**模式，这是另一种使用消息来最大化软件系统并发性和吞吐量的方式。
- en: I like to think that **reactive programming** is an evolution of all this. Actually,
    it is probably an evolution of many different techniques.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我喜欢认为**响应式编程**是这一切的进化。实际上，它可能是对许多不同技术的进化。
- en: It is a bit harder to define reactive, probably because this approach is still
    relatively new and less widespread. Reactive has its roots in functional programming,
    and it's a complete paradigm shift from the way you think about and write your
    code right now. While it's out of the scope of this book to introduce functional
    programming, we will try to understand some principles of reactive programming
    with the usual goal of giving you some more tools you can use in your day-to-day
    architect life and that you can develop further elsewhere if you find them useful
    for solving your current issues.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 定义响应式可能有点困难，可能是因为这种方法仍然相对较新且不太普及。响应式编程的根源在于函数式编程，并且它是一种从你现在思考和使用代码的方式的完全范式转变。虽然介绍函数式编程超出了本书的范围，但我们将尝试理解响应式编程的一些原则，以通常的目标为你提供一些你可以在日常架构生活中使用的工具，如果你发现它们对你的当前问题有用，你还可以在其他地方进一步开发。
- en: 'But first, let''s start with a cornerstone concept: events.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 但首先，让我们从一个基石概念开始：事件。
- en: Defining events, commands, and messages
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义事件、命令和消息
- en: From a technological point of view, an event can be defined as something that
    changes the status of something. In an event-driven architecture, such a change
    is then propagated (notified) as a message that can be picked up by components
    *interested* in that kind of event.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术角度来看，一个事件可以定义为改变某物状态的东西。在一个事件驱动的架构中，这种变化随后被传播（通知）为一个可以被对这种事件感兴趣的部分捕获的消息。
- en: For this reason, the terms **event-driven** and **message-driven** are commonly
    used interchangeably (even if the meaning may be slightly different).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，术语**事件驱动**和**消息驱动**通常可以互换使用（即使意义可能略有不同）。
- en: So, an **event** can be seen as a more abstract concept to do with new information,
    while a message can be seen as how this information is propagated throughout our
    system. Another core concept is the **command**. Roughly speaking, a command is
    the expression of an action, while an event is an expression of something happening
    (such as a change in the status of something).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一个**事件**可以被视为与新的信息有关的一个更抽象的概念，而一个消息可以被视为这种信息在我们系统中传播的方式。另一个核心概念是**命令**。简而言之，命令是对动作的表达，而事件是对发生的事情（如某物状态的改变）的表达。
- en: So, an event reflects a change in data (and somebody downstream may need to
    be notified of the change and need to do something accordingly), while a command
    explicitly asks for a specific action to be done by somebody downstream.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一个事件反映了数据的变化（并且下游的某人可能需要被通知这种变化并相应地采取行动），而一个命令明确要求某人下游执行特定的动作。
- en: Again, generally speaking, an event may have a broader audience (many consumers
    might be interested in it), while a command is usually targeted at a specific
    system. Both types of messages are a nice way to implement loose coupling, meaning
    it's possible to switch at any moment between producer and consumer implementations,
    given that the contract (the message format) is respected. It could be even done
    live with zero impact on system uptime. That's why the usage of messaging techniques
    is so important in application design.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Since these concepts are so important and there are many different variations
    on brokers, messages, and how they are propagated and managed, we will look at
    more on messaging in [*Chapter 8*](B16354_08_Final_JM_ePUB.xhtml#_idTextAnchor200),
    *Designing Application Integration and Business Automation*. Now, let's talk about
    the event-driven approach in detail.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the event-driven pattern and event-driven architecture
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **event-driven pattern** is a pattern and architectural style focused on
    reacting to things happening around (or inside of) our application, where notifications
    of actions to be taken appear in the form of events.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: In its simplest form, expressed in imperative languages (as is widespread in
    embedded systems), event-driven architecture is managed via infinite loops in
    code that continuously poll against event sources (queues), and actions are performed
    when messages are received.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: However, **event-driven architecture** is orthogonal to the programming style,
    meaning that it can be adopted both in imperative models and other models, such
    as object-oriented programming.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: With regard to **Object-Oriented Programming** (**OOP**), there are plenty of
    Java-based examples when it comes to user interface development, with a widely
    known one being the Swing framework. Here you have objects (such as buttons, windows,
    and other controls) that provide handlers for user events. You can register one
    or more handlers (consumers) with those events, which are then executed.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: From the point of view of the application flow, you are not defining the order
    in which the methods are executing. You are just defining the possibilities, which
    are then executed and composed according to the user inputs.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: But if you abstract a bit, many other aspects of Java programming are event-driven.
    Servlets inherently react to events (such as an incoming HTTP request), and even
    error handling, with try-catch, defines the ways to react if an unplanned event
    occurs. In those examples, however, the events are handled internally by the framework,
    and you don't have a centralized middleware operating them (such as a messaging
    broker or queue manager). Events are simply a way to define the behavior of an
    application.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Event-driven architecture can be extended as an architectural style. Simply
    put, an event-driven architecture prescribes that all interactions between the
    components of your software system are done via events (or commands). Such events,
    in this case, are mediated by a central messaging system (a broker, or bus).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: In this way, you can extend the advantages of the event-driven pattern, such
    as loose coupling, better scalability, and a more natural way to represent the
    use case, beyond a single software component. Moreover, you will achieve the advantage
    of greater visibility (as you can inspect the content and number of messages exchanged
    between the pieces of your architecture). You will also have better manageability
    and uptime (because you can start, stop, and change every component without directly
    impacting the others, as a consequence of loose coupling).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Challenges of the event-driven approach
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, we have seen the advantages of the event-driven approach. In my personal
    opinion, they greatly outweigh the challenges that it poses, so I strongly recommend
    using this kind of architecture wherever possible. As always, take into account
    that the techniques and advice provided in this book are seldom entirely prescriptive,
    so in the real world I bet you will use some bits of the event-driven pattern
    even if you are using other patterns and techniques as your main choice.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'However, for the sake of completeness, I think it is worth mentioning the challenges
    I have faced while building event-driven architectures in the past:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '**Message content**: It''s always challenging to define what should be inside
    a message. In theory, you should keep the message as simple and as light as possible
    to avoid hogging the messaging channels and achieve better performance. So, you
    usually have only a message type and references to data stored elsewhere.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, this means that downstream systems may not have all the data needed
    for the computation in the message, and so they would complete the data from external
    systems (typically, a database). Moreover, most of the messaging frameworks and
    APIs (such as **JMS**) allow you to complete your message with metadata, such
    as headers and attachments. I've seen endless discussions about what should go
    into a message and what the metadata is. Of course, I don't have an answer here.
    My advice, as always, is to keep it as simple as possible.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '**Message format**: Related to the previous point, the message format is also
    very relevant. Hence, after you establish what information type should be contained
    in each message, the next step is to decide the shape this information should
    have. You will have to define a message schema, and this should be understandable
    by each actor. Also, message validation could be needed (to understand whether
    each message is a formally valid one), and a schema repository could be useful,
    in order to have a centralized infrastructure that each actor can access to extract
    metadata about how each message should be formatted.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transactional behavior**: The write or read of a message, in abstract, constitutes
    access to external storage (not so different from accessing a database). For this
    reason, if you are building a traditional enterprise application, when you are
    using messaging, you will need to extend your transactional behavior.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's a very common situation that if your consumer needs to update the database
    as a consequence of receiving a message, you will have a transaction encompassing
    the read of the message and the write to the database. If the write fails, you
    will roll back the read of the message. In the Java world, you will implement
    this with a two-phase commit. While it's a well-known problem and many frameworks
    offer some facilities to do this, it's still not a simple solution; it can be
    hard to troubleshoot (and recover from) and can have a non-negligible performance
    hit.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '**Tracing**: If the system starts dispatching many messages between many systems,
    including intermediate steps such as message transformations and filtering, it
    may become difficult to reconstruct a user transaction end to end. This could
    lead to a lack of visibility (from a logical/use case point of view) and make
    troubleshooting harder. However, you can easily solve this aspect with the propagation
    of transaction identifiers in messages and appropriate logging.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security**: You will need to apply security practices at many points. In
    particular, you may want to authenticate the connections to the messaging system
    (both for producing and consuming messages), define access control for authorization
    (you can read and write only to authorized destinations), and even sign messages
    to ensure the identity of the sender. This is not a big deal, honestly, but is
    one more thing to take into account.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, the challenges are not impossible to face, and the advantages
    will probably outweigh them for you. Also, as we will see in [*Chapter 9*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230),
    *Designing Cloud-Native Architectures*, many of these challenges are not exclusive
    to event-driven architecture, as they are also common in distributed architectures
    such as microservices.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: Event-driven and domain model
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have already discussed many times the importance of correctly modeling a
    business domain, and how this domain is very specific to the application boundaries.
    Indeed, in [*Chapter 4*](B16354_04_Final_JM_ePUB.xhtml#_idTextAnchor089), *Best
    Practices for Design and Development*, we introduced the idea of bounded context.
    Event-driven architectures are dealing almost every time with the exchange of
    information between different bounded contexts.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: As already discussed, there are a number of techniques for dealing with such
    kinds of interactions between different bounded contexts, including the shared
    kernel, customer suppliers, conformity, and anti-corruption layer. As already
    mentioned, unfortunately, a perfect approach does not exist for ensuring that
    different bounded contexts can share meaningful information but stay correctly
    decoupled.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: My personal experience is that the often-used approach here is the shared kernel.
    In other words, a new object is defined and used as an event format. Such an object
    contains the minimum amount of information needed for the different bounded contexts
    to communicate. This does not necessarily mean that the communication will work
    in every case and no side effects will occur, but it's a solution good enough
    in most cases.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we are going to touch on a common implementation of the
    event-driven pattern, known as the actor model.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Building on the event-driven architecture – the actor model
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **actor model** is a stricter implementation of the event-driven pattern.
    In the actor model, the actor is the most elementary unit of computation, encapsulating
    the state and behavior. An actor can communicate with other actors only through
    messages.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: An actor can create other actors. Each actor encapsulates its internal status
    (no actor can directly manipulate the status of another actor). This is usually
    a nice and elegant way to take advantage of multithreading and parallel processing,
    thereby maintaining integrity and avoiding explicit locks and synchronizations.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: In my personal experience, the actor model is a bit too prescriptive when it
    comes to describing bigger use cases. Moreover, some requirements, such as session
    handling and access to relational databases, are not an immediate match with the
    actor model's logic (though they are still implementable within it). You will
    probably end up implementing some components (maybe core ones) with the actor
    model while having others that use a less rigorous approach, for the sake of simplicity.
    The most famous actor model implementation with Java is probably **Akka**, with
    some other frameworks, such as **Vert.x**, taking some principles from it.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have elaborated on generic messaging with both the event-driven approach
    and the actor model.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: It is now important, for the purpose of this chapter, to introduce the concept
    of **streaming**.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Introducing streaming
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Streaming** has grown more popular with the rise of Apache Kafka even if
    other popular alternatives, such as Apache Pulsar, are available. Streaming shares
    some similarities with messaging (there are still producers, consumers, and messages
    flowing, after all), but it also has some slight differences.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: From a purely technical point of view, streaming has one important difference
    compared with messaging. In a streaming system, messages persist for a certain
    amount of time (or, if you want, a specified number of messages can be maintained),
    regardless of whether they have been consumed or not.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: This creates a kind of *sliding window*, meaning that consumers of a streaming
    system can rewind messages, following the flow from a previous point to the current
    point. This means that some of the information is moved from the messaging system
    (the broker, or bus) to the consumers (which have to maintain a cursor to keep
    track of the messages read and can move back in time).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: This behavior also enables some advanced use cases. Since consumers can see
    a consolidated list of messages (the stream, if you like), complex logic can be
    applied to such messages. Different messages can be combined for computation purposes,
    different streams can be merged, and advanced filtering logic can be implemented.
    Moreover, the offloading of part of the logic from the server to the consumers
    is one factor that enables the management of high volumes of messages with low
    latencies, allowing for near real-time scenarios.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Given those technical differences, streaming also offers some conceptual differences
    that lead to use cases that are ideal for modeling with this kind of technology.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: With streams, the events (which are then propagated as messages) are seen as
    a whole information flow as they usually have a constant rate. And moreover, a
    single event is normally less important than the sequence of events. Last but
    not least, the ability to rewind the event stream leads to better consistency
    in distributed environments.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Imagine adding more instances of your application (scaling). Each instance can
    reconstruct the status of the data by looking at the sequence of messages collected
    until that moment, in an approach commonly defined as **Event Sourcing**. This
    is also a commonly used pattern to improve resiliency and return to normal operations
    following a malfunction or disaster event. This characteristic is one of the reasons
    for the rising popularity of streaming systems in microservice architectures.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Touching on reactive programming
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I like to think of **reactive programming** as event-driven architecture being
    applied to data streaming. However, I'm aware that that's an oversimplification,
    as reactive programming is a complex concept, both from a theoretical and technological
    point of view.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: To fully embrace the benefits of reactive programming, you have to both master
    the tools for implementing it (such as **RxJava**, **Vert.x**, or even **BaconJS**)
    and switch your reasoning to the reactive point of view. We can do this by modeling
    all our data as streams (including changes in variables content) and writing our
    code on the basis of a declarative approach.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Reactive programming considers data streams as the primary construct. This makes
    the programming style an elegant and efficient way to write asynchronous code,
    by observing streams and reacting to signals. I understand that this is not easy
    at all to grasp at first glance.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s also worth noting that the term *reactive* is also used in the context
    of reactive systems, as per the **Reactive** **Manifesto**, produced in 2014 by
    the community to implement responsive and distributed systems. The Reactive Manifesto
    focuses on building systems that are as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '**Responsive**: This means replying with minimal and predictable delays to
    inputs (in order to maximize the user experience).'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resilient**: This means that a failure in one of the components is handled
    gracefully and impacts the whole system''s availability and responsiveness as
    little as possible.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Elastic**: This means that the system can adapt to variable workloads, keeping
    constant response times.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Message-driven**: This means that systems that adhere to the manifesto use
    a message-driven communication model (hence achieving the same goals as described
    in the *Introducing the event-driven pattern and event-driven architecture* section).'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While some of the goals and techniques of the Reactive Manifesto resonate with
    the concepts we have explored so far, reactive systems and reactive programming
    are different things.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: The Reactive Manifesto does not prescribe any particular approach to achieve
    the preceding four goals, while reactive programming does not guarantee, per se,
    all the benefits pursued by the Reactive Manifesto.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: A bit confusing, I know. So, now that we've understood the differences between
    a reactive system (as per the Reactive Manifesto) and reactive programming, let's
    shift our focus back to reactive programming.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: As we have said, the concept of data streaming is central to reactive programming.
    Another fundamental ingredient is the **declarative approach** (something similar
    to functional programming). In this approach, you express what you want to achieve
    instead of focusing on all the steps needed to get there. You declare the final
    result (leveraging standard constructs such as filter, map, and join) and attach
    it to a stream of data to which it will be applied.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: The final result will be compact and elegant, even if it may not be immediate
    in terms of readability. One last concept that is crucial in reactive programming
    is **backpressure**. This is basically a mechanism for standardizing communication
    between producers and consumers in a reactive programming model in order to regulate
    flow control.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: This means that if a consumer can't keep up with the pace of messages received
    from the producer (typically because of a lack of resources), it can send a notification
    about the problem upstream so that it can be managed by the producer or any other
    intermediate entity in the stream chain (in reactive programming, an event stream
    can be manipulated by intermediate functions). In theory, backpressure can bubble
    up to the first producer, which can also be a human user in the case of interactive
    systems.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: When a producer is notified of backpressure, it can manage the issue in different
    ways. The most simple is to slow down the speed and just send less data, if possible.
    A more elaborate technique is to buffer the data, waiting for the consumer to
    get up to speed (for example, by scaling its resources). A more destructive approach
    (but one that is effective nevertheless) is to drop some messages. However, this
    may not be the best solution in every case.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: With that, we have finished our quick look at reactive programming. I understand
    that some concepts have been merely mentioned, and things such as the functional
    and declarative approaches may require at least a whole chapter on their own.
    However, a full deep dive into the topic is beyond the scope of this book. I hope
    I gave you some hints to orient yourself toward the best architectural approach
    when it comes to message- and event-centric use cases.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you learned about the basic concepts and terms to do with reactive
    and event-driven programming, which, if well understood and implemented, can be
    used to create high-performance applications.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will start discussing how to optimize our architecture
    for performance and scalability purposes.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Designing for large-scale adoption
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, in this chapter, we have discussed some widespread patterns and architectural
    styles that are well used in the world of enterprise Java applications.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: One common idea around the techniques that we have discussed is to organize
    the code and the software components not only for better readability, but also
    for performance and scalability.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: As you can see (and will continue to see) in this book, in current *web-scale*
    applications, it is crucial to think ahead in terms of planning to absorb traffic
    spikes, minimize resource usage, and ultimately have good performance. Let's have
    a quick look at what this all means in our context.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Defining performance goals
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Performance** is a very broad term. It can mean many different things, and
    often you will want to achieve all performance goals at once, which is of course
    not realistic.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: 'In my personal experience, there are some main performance indicators to look
    after, as they usually have a direct impact on the business outcome:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '**Throughput**: This is measured as the number of transactions that can be
    managed per time unit (usually in seconds). The tricky part here is to define
    exactly what a transaction is in each particular context, as probably your system
    will manage different transaction types (with different resources being needed
    for each kind of transaction). Business people understand this metric instantaneously,
    knowing that having a higher throughput means that you will spend less on hardware
    (or cloud) resources.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Response time**: This term means many different things. It usually refers
    to the time it takes to load your web pages or the time it takes to complete a
    transaction. This has to do with customer satisfaction (the quicker, the better).
    You may also have a contractual **Service** **Level** **Agreement** (**SLA**);
    for example, your system must complete a transaction in no more than *x* milliseconds.
    Also, you may want to focus on an average time or set a maximum time threshold.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Elapsed time**: This basically means the amount of time needed to complete
    a defined chunk of work. This is common for batch computations (such as in big
    data or other calculations). This is kind of a mix of the previous two metrics.
    If you are able to do more work in parallel, you will spend less on your infrastructure.
    You may have a fixed deadline that you have to honor (such as finishing all your
    computations before a branch opens to the public).'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance tuning** is definitely a broad topic, and there is no magic formula
    to easily achieve the best performance. You will need to get real-world experience
    by experimenting with different configurations and get a lot of production traffic,
    as each case is different. However, here are some general considerations for each
    performance goal that we have seen:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: To enhance throughput, your best bet is to parallelize. This basically means
    leveraging threading where possible. It's unbelievable how often we tend to chain
    our calls in a sequential way. Unless it is strictly necessary (because of data),
    we should parallelize as much as we can and then merge the results.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This entails, basically, splitting each call wherever possible (by delegating
    it to another thread), waiting for all the subcalls to complete in order to join
    the results in the main thread, and returning the main thread to the caller. This
    is particularly relevant where the subcalls involve calling to external systems
    (such as via web services). When parallelizing, the total elapsed time to answer
    will be equal to the longest subcall, instead of being the sum of the time of
    each subcall.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next diagram, you can see how parallelizing calls can help in reducing
    the total elapsed time needed to complete the execution of an application feature:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6 – Sequential versus parallel approach'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.06_B16354.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.6 – Sequential versus parallel approach
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: There should be a physical separation of our service based on the load and the
    performance expectations (something greatly facilitated by containers and microservices
    architecture). Instead of mixing all your APIs, you may want to dedicate more
    resources to the more critical ones (perhaps even dynamically, following the variation
    of traffic) by isolating them from the other services.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For better response times, async is the way to go. After reviewing the previous
    sections for advice, I suggest working with your business and functional analysts
    and fighting to have everything be as asynchronous as possible from a use case
    perspective.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is very uncommon to have really strict requirements in terms of checking
    everything on every backend system before giving feedback to your users. Your
    best bet is to do a quick validation and reply with an acknowledgment to the customer.
    You will, of course, need an asynchronous channel (such as an email, a notification,
    or a webhook) to notify regarding progression of the transaction. There are countless
    examples in real life; for example, when you buy something online, often, your
    card funds won't even be checked in the first interaction. You are then notified
    by email that the payment has been completed (or has failed). Then, the package
    is shipped, and so on. Moreover, optimizing access to data is crucial; caching,
    pre-calculating, and de-duplicating are all viable strategies.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: 'When optimizing for elapsed time, you may want to follow the advice previously
    given: parallelizing and optimizing access to data is key. Also, here, you may
    want to rely on specialized infrastructure, such as scaling to have a lot of hardware
    (maybe in the cloud) and powering it off when it is not needed, or using infrastructures
    optimized for input/output. But the best advice is to work on the use case to
    maximize the amount of parallelizable work, possibly duplicating part of the information.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will learn more about performance in [*Chapter 12*](B16354_12_Final_JM_ePUB.xhtml#_idTextAnchor292),
    *Cross-Cutting Concerns*. Let's now review some key concepts linked to scalability.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Stateless
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Stateless** is a very recurrent concept (we will see it again in [*Chapter
    9*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230), *Designing Cloud-Native Architectures*).
    It is difficult to define with simple words, however.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Let's take the example of an ATM versus a workstation.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Your workstation is something that is usually difficult to replace. Yes, you
    have backups and you probably store some of your data online (in your email inbox,
    on the intranet, or on shared online drives). But still, when you have to change
    your laptop for a new one, you lose some time ensuring that you have copied any
    local data. Then, you have to export and reimport your settings, and so on. In
    other words, your laptop is very much stateful. It has a lot of local data that
    you don't want to lose.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's think about an ATM. Before you insert your card, it is a perfectly
    empty machine. It then loads your data, allows cash withdrawal (or whatever you
    need), and then it goes back to the previous (empty) state, ready for the next
    client to serve. It is stateless from this point of view. It is also engineered
    to minimize the impact if something happens while you are using it. It's usually
    enough to end your current session and restart from scratch.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: 'But back to our software architecture: *how do we design an architecture to
    be stateless?*'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: 'The most common ways are as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '**Push the state to clients**: This can mean having a cookie in the customer
    browser or having your APIs carry a token (such as a **JWT**). Every time you
    get a request, you may get to choose the best instance for your software (be it
    a container, a new JVM instance, or simply a thread) to handle it – *which will
    it be: the closest to the customer, the closest to the data, or simply the one
    with the least amount of load at that moment?*'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Push the state to an external system**: You can offload the state to a dedicated
    system, such as a distributed cache. Your API (and business logic) only need to
    identify the user. All the session data is then loaded from a dedicated system.
    Any new instance can simply ask for the session data. Of course, your problem
    is then how to scale and maximize the uptime of such a caching system.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whatever your approach is, think always about the *phoenix*; that is, you should
    be able to reconstruct the data from the ashes (and quickly). In this way, you
    can maximize scaling, and as a positive side effect, you will boost availability
    and disaster recovery capabilities. As highlighted in the *Introducing streaming*
    section, events (and the event sourcing technique) are a good way to implement
    similar approaches. Indeed, provided that you have persisted all the changes in
    your data into a streaming system, such changes could be replayed in case of a
    disaster, and you can reconstruct the data from scratch.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Beware of the concept of **stickiness** (pointing your clients to the same instance
    whenever possible). It's a quick win at the beginning, but it may lead you to
    unbalanced infrastructure and a lack of scalability. The next foundational aspect
    of performance is data.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Data
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Data** is very often a crucial aspect of performance management. Slow access
    times to the data you need will frustrate all other optimizations in terms of
    parallelizing or keeping interactions asynchronous. Of course, each type of data
    has different optimization paths: indexing for relational databases, proximity
    for in-memory caching, and low-level tuning for filesystems.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: 'However, here are my considerations as regards the low-hanging fruit when optimizing
    access to data:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '**Sharding**: This is a foundational concept. If you can split your data into
    smaller chunks (such as by segmenting your users by geographical areas, sorting
    using alphabetical order, or using any other criteria compliant with your data
    model), you can dedicate a subset of the system (such as a database schema or
    a file) to each data shard.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This will boost your resource usage by minimizing the interference between different
    data segments. A common strategy to properly cluster data in shards is **hashing**.
    If you can define a proper hashing function, you will have a quick and reliable
    way to identify where your data is located by mapping the result of the hashing
    operation to a specific system (containing the realm that is needed). If you still
    need to access data across different shards (such as for performing computations
    or for different representations of data), you may consider a different sharding
    strategy or even duplicating your data (but this path is always complex and risky,
    so be careful with that).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '**Consistency point**: This is another concept to take care of. It may seem
    like a lower-level detail, but it''s worthwhile exploring. To put it simply: *how
    often do you need your data to persist?* Persistence particularly common in long
    transactions (such as ones involving a lot of submethods). Maybe you just don''t
    need to persist your data every time; you can keep it in the memory and batch
    all the persistence operations (this often includes writing to files or other
    intensive steps) together.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For sure, if the system crashes, you might lose your data (and whether to take
    this risk is up to you), but are you sure that incongruent data (which is what
    you'd have after saving only a part of the operations) is better than no data
    at all? Moreover, maybe you can afford a crash because your data has persisted
    elsewhere and can be recovered (think about streaming, which we learned about
    previously). Last but not least, *is it okay if your use case requires persistence
    at every step?* Just be aware of that. Very often, we simply don't care about
    this aspect, and we pay a penalty without even knowing it.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '**Caching**: This is the most common technique. Memory is cheap, after all,
    and almost always has better access times than disk storage. So, you may just
    want to have a caching layer in front of your persistent storage (database, filesystem,
    or whatever). Of course, you will end up dealing with stale data and the propagation
    of changes, but it''s still a simple and powerful concept, so it''s worth a try.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caching may be implemented in different ways. Common implementations include
    caching data in the working memory of each microservice (in other words, in the
    heap, in the case of Java applications), or relying on external caching systems
    (such as client-server, centralized caching systems such as Infinispan or Redis).
    Another implementation makes use of external tools (such as Nginx or Varnish)
    sitting in front of the API of each microservice and caching everything at that
    level.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: 'We will see more about data in [*Chapter 11*](B16354_11_Final_JM_ePUB.xhtml#_idTextAnchor271),
    *Dealing with Data*, but for now, let me give you a spoiler about my favorite
    takeaway here: you must have multiple ways of storing and retrieving data and
    using it according to the constraints of your use case. Your mobile application
    has a very different data access pattern from a batch computation system. Now,
    let''s go to the next section and have a quick overview of scaling techniques.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Scaling
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Scaling** has been the main mantra so far for reaching performance goals
    and is one of the key reasons why you would want to architect your software in
    a certain way (such as in a multi-tier or async fashion). And honestly, I''m almost
    certain that you already know what scaling is and why it matters. However, let''s
    quickly review the main things to consider when we talk about scaling:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '**Vertical scaling** is, somewhat, the most traditional way of scaling. To
    achieve better performance, you need to add more resources to your infrastructure.
    While it is still common and advisable in some scenarios (such as when trying
    to squeeze more performance from databases, caches, or other stateful systems),
    it is seldom a long-term solution.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will hit a blocking limit sooner or later. Moreover, vertical scaling is
    not very dynamic, as you may need to purchase new hardware or resize your virtual
    machine, and maybe downtime will be needed to make effective changes. It is not
    something you can do in a few seconds to absorb a traffic spike.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '**Horizontal scaling** is way more popular nowadays as it copes well with cloud
    and PaaS architectures. It is also the basis of stateless, sharding, and the other
    concepts discussed previously. You can simply create another instance of a component,
    and that''s it. In this sense, the slimmer, the better. If your service is very
    small and efficient and takes a very short time to start (*microservices,* *anyone?*),
    it will nicely absorb traffic spikes.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can take this concept to the extreme and shut down everything (thereby saving
    money) when you have no traffic. As we will see in [*Chapter 9*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230),
    *Designing Cloud-Native Architectures*, scaling to zero (so that no instance is
    running if there are no requests to work with) is the concept behind serverless.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: We are naturally led to think about scaling in a **reactive way**. You can get
    more traffic and react by scaling your components. The key here is identifying
    which metric to look after. It is usually the number of requests, but memory and
    CPU consumption are the other key metrics to look after. The advantage of this
    approach is that you will consume the resources needed for scaling *just in time*,
    hence you will mostly use it in an efficient way. The disadvantage is that you
    may end up suffering a bit if traffic increases suddenly, especially if the new
    instances take some time to get up and running.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The opposite of reactive scaling is, of course, **proactive scaling**. You may
    know in advance that a traffic spike is expected, such as in the case of Black
    Friday or during the tax payment season. If you manage to automate your infrastructure
    in the right way, you can schedule the proper growth of the infrastructure in
    advance. This may be even more important if scaling takes some time, as in vertical
    scaling. The obvious advantage of this approach is that you will be ready in no
    time in case of a traffic increase, as all the instances needed are already up
    and running. The disadvantage is that you may end up wasting resources, especially
    if you overestimate the expected traffic.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this section, we achieved the goals of this chapter. There was quite a
    lot of interesting content. We started with hexagonal architectures (an interesting
    example of encapsulation), before moving on to multi-tier architectures (a very
    common way to organize application components). Then, you learned about MVC (a
    widely used pattern for user interfaces), event-driven (an alternative way to
    design highly performant applications), and finally, we looked at some common-sense
    suggestions about building highly scalable and performant application architectures.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: It is not possible to get into all the details of all the topics discussed in
    this chapter. However, I hope to have given you the foundation you need to start
    experimenting and learning more about the topics that are relevant to you.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: And now, let's have a look at some practical examples.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Case studies and examples
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As with other chapters in this book, let's end this chapter with some practical
    considerations about how to apply the concepts we've looked at to our recurrent
    example involving a mobile payment solution. Let's start with encapsulation.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Encapsulating with a hexagonal architecture
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A common way to map hexagonal concepts in Java is to encompass the following
    concept representations:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: The core maps into the domain model. So, here you have the usual entities (**Payment**,
    in our example), services (**PaymentService**, in this case), value objects, and
    so on. Basically, all the elements in the core are **Plain Old Java Objects**
    (**POJOs**) and some business logic implementations.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, the ports are the interfaces. They are somewhere in the middle, between
    a logical concept in the domain realm (enquire, notify, and store, in our example)
    and the respective technical concepts. This will promote the decoupling of the
    business logic (in the core) and the specific technology (which may change and
    evolve).
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The adapters are implementations of such interfaces. So, an enquire interface
    will be implemented by **SoapAdapter**, **RestAdapter**, and **GraphQLAdapter**,
    in this particular case.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Outside of the hexagon, the external actors (such as the mobile app, databases,
    queues, or even external applications) interact with our application domain via
    the adapters provided.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the preceding points:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – Hexagonal architecture example'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.07_B16354.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.7 – Hexagonal architecture example
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some key considerations:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: The cardinality is completely arbitrary. You are not limited to six ports or
    adapters. Each port can map to one or more adapters. Each external system can
    be bound to one or more adapters. Each adapter can be consumed by more than one
    external system (they are not exclusive unless you want them to be).
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This logical grouping can be seen at the level that you want. This could be
    an application, meaning that everything inside the hexagon is deployed on a single
    artifact – an **Enterprise Application Archive** (**EAR**) or a **Java Application
    Archive** (**JAR**) – in a machine, or it could be a collection of different artifacts
    and machines (as in a microservices setup). In this case, most probably you will
    decouple your interfaces with REST or something similar, to avoid sharing dependencies
    across your modules.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: The advantage in terms of test coverage is obvious. You can switch each adapter
    into a mock system, to test in environments that don't have the complete infrastructure.
    So, you can test your notifications without the need for a queue, or test persistence
    without the need for a database. This, of course, will not replace end-to-end
    testing, in which you have to broaden your test and attach it to real adapters
    (such as in automating tests that call REST or SOAP APIs) or even external systems
    (such as in testing the mobile app or the web app itself).
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As usual, I think that considering hexagonal modeling as a tool can be useful
    when implementing software architecture. Let's now have a quick look at multi-tier
    architecture.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Componentizing with multi-tier architecture
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Multi-tier architecture** gives us occasion to think about componentization
    and, ultimately, the evolution of software architectures. If we think about our
    mobile payment application, a three-tier approach may be considered a good fit.
    And honestly, it is. Historically, you probably wouldn''t have had many other
    options than a pure, centralized, client-server application. Even with a modern
    perspective, starting with a less complex approach, such as the three-tier one,
    it can be a good choice for two reasons:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: It can be considered a *prototypization* phase, with the goal of building a
    **Minimum Viable Product** (**MVP**). You will have something to showcase and
    test soon, which means you can check whether you have correctly understood the
    requirements or whether users like (and use) your product. Moreover, if you designed
    your application correctly (using well-designed APIs), maybe you can evolve your
    backend (toward multi-tier or microservices) with minimal impact on the clients.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can be a good benchmark for your domain definition. As per the famous Martin
    Fowler article (*Monolith First*), you may want to start with a simpler, all-in-one
    architecture in order to understand the boundaries of your business logic, and
    then correctly decomponentize it in the following phase (maybe going toward a
    cloud-native approach).
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the next diagram, you can see a simple representation of an application''s
    evolution from three-tier to microservices:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – Tier segmentation evolution'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.08_B16354.jpg)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.8 – Tier segmentation evolution
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see in the previous diagram, each component change has a role and
    name. There are some key considerations to make about this kind of evolution:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: We will see more about microservices in [*Chapter 9*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230),
    *Designing Cloud-Native Architectures*. For now, consider the fact that this example
    will only represent architectural evolution over time and how your tier segmentation
    can evolve. Microservices is probably not similar to multi-tier architecture,
    as some concepts (such as responsibilities in terms of data representation in
    views) are orthogonal to it (in other words, you can still have concepts from
    three-tier on top of microservices).
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are starting with three tiers because it is simply an antipattern to have
    business logic mixed together with your data in terms of being deployed to the
    database (with stored procedures and such). However, in my opinion, having an
    external database does not constitute a data layer *per se*. So, in this example,
    the three-tier architecture can also be seen as a two-tier/client-server architecture,
    with the external database simply being a technological detail.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the real world, there is no defined boundary between one architectural view
    (such as three-tier) and another alternative (such as microservices). It's not
    as if one day you will transition from client-server (or three-tier) to microservices.
    You will probably start adding more layers, and then reorganize some capabilities
    into a complete microservice from the ground up and offload some capabilities
    to it.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In general, it is possible to have a few differing architectural choices coexisting
    in the same application, perhaps just for a defined (limited) time, leading to
    a transition to a completely different architecture. In other words, your three-tier
    architecture can start with some modularized microservices alongside tiers (making
    it a hybrid architecture, bringing different styles together), and then the tiered
    part can be progressively reduced and the microservices part increased, before
    a final and complete move to a microservices implementation.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Once again, this is designed to give you some food for thought as to how to
    use some key concepts seen in this chapter in the real world. It's important to
    understand that it's rare (and maybe wrong) to completely and religiously embrace
    just one model, for instance, starting with a pure three-tier model and staying
    with it even if the external conditions change (if you start using a cloud-like
    environment, for example).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: Planning for performance and scalability
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As seen in the previous sections, performance is a broad term. In our example,
    it is likely that we will want to optimize for both throughput and response time.
    It is, of course, a target that is not easy to reach, but it is a common request
    in this kind of project:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '**Throughput** means a more sustainable business, with a lower cost for each
    transaction (considering hardware, power, software licenses, and so on).'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Response time** means having a happier customer base and, ultimately, the
    success of the project. Being an online product, it is expected today that access
    to this kind of service (whether it is for making a payment or accessing a list
    of transactions) happens with zero delay; every hiccup could lead a customer to
    switch to alternative platforms.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, you may want to have a hard limit. It is common to have a timeout, meaning
    that if your payment takes more than 10 seconds, it is considered to have failed
    and is forcefully dropped. That's for limiting customer dissatisfaction and avoiding
    the overloading of the infrastructure.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '*But how do you design your software architecture to meet such objectives?*
    As usual, there is no magic recipe for this. Performance tuning is a continuous
    process in which you have to monitor every single component for performance and
    load, experiment to find the most efficient solution, and then switch to the next
    bottleneck. However, there are a number of considerations that can be made upfront:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: First of all, there is **transactional behavior**. We will see in [*Chapter
    9*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230), *Designing Cloud-Native Architectures*,
    how heavily decentralized architectures, such as microservices, do not cope well
    with long and distributed transactions. Even if you are not yet in such a situation
    and you are starting with a simpler, three-tier architecture, having long transaction
    boundaries will cause serialization in your code, penalizing your performance.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To avoid this, you have to restrict the transaction as much as possible and
    handle consistency in different ways wherever possible. You may want to have your
    transaction encompass the payment request and the check of monetary funds (as
    in the classic examples about transactions), but you can take most of the other
    operations elsewhere. So, notifications and updates of non-critical systems (such
    as CRMs or data sources only used for inquiries) can be done outside of the transactions
    and retried in the case of failures.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: As a follow-up from the previous point, it should be taken into account that
    you don't have to penalize the most common cases to avoid very remote cases unless
    they have dramatic consequences. So, it is okay to check funds before making the
    payments in a strict way (as in the same transaction), because a malfunction there
    can cause bad advertising and a loss of trust in your platform, with potentially
    devastating consequences.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: But you can probably afford to have a notification lost or sent twice from time
    to time if this means that 99% of the other transaction are performing better.
    And the rules can also be adapted to your specific context. Maybe the business
    can accept skipping some online checks (such as anti-fraud checks) in payment
    transactions of small amounts. The damage of some fraudulent transactions slipping
    through (or only being identified after the fact) may be lower than the benefit
    in terms of performance for the vast majority of licit traffic.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: In terms of **asynchronous behavior**, as has been seen, it is expected that
    you only do synchronously what's essential to do synchronously. So, apart from
    the obvious things such as notifications, every other step should be made asynchronous
    if possible – for example, updating downstream systems.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, in our use case, if we have a transactional database (or a legacy system)
    storing the user position that is used to authorize payments, it should be checked
    and updated synchronously to keep consistency. But if we have other systems, such
    as a CRM that stores the customer position, perhaps it's okay to place an update
    request in a queue and update that system after a few seconds, when the message
    is consumed and acted upon.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Last but not least, in terms of **scaling**, the more your component will be
    stateless, the better. So, if we have each step of the payment process carrying
    over all the data needed (such as the customer identifier and transaction identifier),
    maybe we can minimize the lookups and checks on the external systems.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the case of more load, we can (in advance, if it is planned, or reactively
    if it is an unexpected peak) create more instances of our components. Then, they
    will be immediately able to take over for the incoming requests, even if they
    originated from existing instances.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: So, if you imagine a payment transaction being completed in more than one step
    (as in first checking for the existence of the recipient, then making a payment
    request, then sending a confirmation), then it may be possible that each of those
    steps is worked on by different instances of the same component. Think about what
    would happen if you had to manage all those steps on the same instance that started
    the process because the component stored the data in an internal session. In cases
    of high traffic, new instances would not be able to help with the existing transactions,
    which would have to be completed where they originated. And the failure of one
    instance would likely create issues for users.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: This completes the content of this chapter. Let's quickly recap the key concepts
    that you have seen.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you have seen a lot of the cornerstone concepts when it comes
    to architectural patterns and best practices in Java. In particular, you started
    with the concept of encapsulation; one practical way to achieve it is the hexagonal
    architecture. You then moved to multi-tier architectures, which is a core concept
    in Java and JEE (especially the three-tier architecture, which is commonly implemented
    with beans, servlets, and JSPs).
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: There was a quick look at MVC, which is more a design pattern than an architectural
    guideline but is crucial to highlight some concepts such as the importance of
    separating presentation from business logic. You then covered the asynchronous
    and event-driven architecture concepts, which apply to a huge portion of different
    approaches that are popular right now in the world of Java. These concepts are
    known for their positive impacts on performance and scalability, which were also
    the final topics of this chapter.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: While being covered further in other chapters, such as [*Chapter 9*](B16354_09_Final_JM_ePUB.xhtml#_idTextAnchor230),
    *Designing Cloud-Native Architectures*, and [*Chapter 12*](B16354_12_Final_JM_ePUB.xhtml#_idTextAnchor292),
    *Cross-Cutting Concerns*, here you have seen some general considerations about
    architecture that will link some of the concepts that you've seen so far, such
    as tiering and asynchronous interactions, to specific performance goals.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look in more detail at what middleware is and how
    it's evolving.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Hexagonal architecture*, by Alistair Cockburn ([https://alistair.cockburn.us/hexagonal-architecture/](https://alistair.cockburn.us/hexagonal-architecture/))'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Java Performance: The Definitive Guide: Getting the Most Out of Your Code*,
    by Scott Oaks, published by O''Reilly Media (2014)'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kafka Streams in Action*, by William P. Bejeck Jr., published by Manning'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Scalability Rules 50 Principles for Scaling Web Sites*, by Martin L. Abbott
    and Michael T. Fisher, published by Pearson Education (2011)'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Monolith First*, by Martin Fowler ([https://www.martinfowler.com/bliki/MonolithFirst.html](https://www.martinfowler.com/bliki/MonolithFirst.html))'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
