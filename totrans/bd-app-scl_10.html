<html><head></head><body><div class="chapter" title="Chapter&#xA0;10.&#xA0; Scaling up" id="aid-3EK181"><div class="titlepage"><div><div><h1 class="title"><a id="ch10"/>Chapter 10.  Scaling up </h1></div></div></div><p>In the previous chapters, we built a Scala and Play framework application. We used the most effective frameworks and tools around the Scala ecosystem, such as Play framework and Akka; and we used the Reactive and Functional Programming techniques using Futures and RxScala. Additionally, we created reports with Jasper and Chat with WebSockets. This is the final chapter, and we will learn how to deploy and scale our application.</p><p>In this chapter, we will cover the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Standalone deploy</li><li class="listitem">Architecture principles</li><li class="listitem">Reactive drivers and discoverability</li><li class="listitem">Mid-Tier load-balancer, timeouts, Back pressure, and caching</li><li class="listitem">Scaling up microservices with an Akka cluster</li><li class="listitem">Scaling up the infrastructure with Docker and AWS cloud</li></ul></div><div class="section" title="Standalone deploy"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec108"/>Standalone deploy</h1></div></div></div><p>Throughout this book, we used the Activator and SBT build and development tools. However, when we talk about production, we can't run the application with SBT or Activator; we need to do a standalone deploy.</p><p>What about standard Java Servlet containers, such as Tomcat? Tomcat is great; however, Play is greater. You won't get better performance by deploying your app on Tomcat. The standalone play uses Netty, which has superior network stack.</p><p>There are some small changes that we will need to make in order to deploy our application for Jasper reports. Don't worry; these changes are very simple and straightforward.</p></div></div>
<div class="section" title="Reports folder" id="aid-3FIHQ1"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec109"/>Reports folder</h1></div></div></div><p>We need to move the reports template (JRXML files) from the source folder to the public folder. Why do we need to do this? Because when we generate the standalone deploy, they won't be included in the application jars. What is inside the public folder will be packed and deployed into a proper JAR file. That's why we need to make this change.</p><p>Create a folder called <code class="literal">reports</code> at <code class="literal">ReactiveWebStore/public/</code>. Then move all the JRXML files there.</p></div>
<div class="section" title="Changing report builder" id="aid-3GH2C1"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec110"/>Changing report builder</h1></div></div></div><p>As our templates will be inside a JAR file, we need to change the loading logic in order to get the templates properly. Under <code class="literal">ReactiveWebStore/app/report/</code>, we need to change <code class="literal">ReportBuilder.scala</code>, which should look something like this after editing:</p><pre class="programlisting">    package reports  
    object ReportBuilder {  
      private var reportCache:scala.collection.Map[String,Boolean] = 
      new scala.collection.mutable.HashMap[String,Boolean].empty  
      def generateCompileFileName(jrxml:String): String = 
      "/tmp/report_" + jrxml + "_.jasper"  
      def compile(jrxml:String){ 
        if(reportCache.get(jrxml).getOrElse(true)){ 
          val design:JasperDesign = JRXmlLoader.load( 
            Play.resourceAsStream("/public/reports/" + jrxml)
          (Play.current).get ) 
          JasperCompileManager.compileReportToFile(design, 
          generateCompileFileName(jrxml)) 
          reportCache += (jrxml -&gt; false) 
        } 
      }  
      def toPdf(jrxml:String):ByteArrayInputStream = { 
        try { 
          val os:OutputStream = new ByteArrayOutputStream() 
          val reportParams:java.util.Map[String,Object] = 
          new java.util.HashMap() 
          val con:Connection =     
          DriverManager.getConnection("jdbc:mysql://localhost/RWS_DB?
            user=root&amp;password=&amp;useUnicode=
            true&amp;useJDBCCompliantTimezoneShift=
            true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTC") 
          compile(jrxml) 
          val jrprint:JasperPrint = 
          JasperFillManager.fillReport(generateCompileFileName(jrxml),     
          reportParams, con) 
          val exporter:JRPdfExporter = new JRPdfExporter() 
          exporter.setExporterInput(new SimpleExporterInput(jrprint)); 
          exporter.setExporterOutput(
          new SimpleOutputStreamExporterOutput(os)); 
          exporter.exportReport() 
          new ByteArrayInputStream
          ((os.asInstanceOf[ByteArrayOutputStream]).toByteArray()) 
        }catch { 
          case e:Exception =&gt; throw new RuntimeException(e) 
          null 
        }
      }
    } 
</pre><p>The main changes that we made were around the <code class="literal">compile</code> function. Now, we are using the Jasper JRXmlLoader in order to load the Jasper template from an <code class="literal">InputStream</code> method. Passing the <code class="literal">InputStream</code> method provided by the <code class="literal">Play.resourceAsStream</code> function. As you can see, we are passing the new path, <code class="literal">/public/reports/</code>, in order to get the templates. The rest of the code is pretty much the same as the one we executed earlier.</p><p>Now we are ready to deploy. In order to do so, we will need to run a command on <code class="literal">activator</code>, which is as follows:</p><pre class="programlisting">
<span class="strong"><strong>$ activator universal:packageZipTarball</strong></span>
</pre><p>You will see the following result:</p><p>
</p><div class="mediaobject"><img src="../Images/image00332.jpeg" alt="Changing report builder"/></div><p style="clear:both; height: 1em;"> </p><p>
</p><p>As soon as the task is finished, our app will be packed into the <code class="literal">ReactiveWebStore/target/universal/</code> directory, and you will see a <code class="literal">reactivewebstore-1.0-SNAPSHOT.tgz</code> file.</p><p>Then you need to extract the file and you shall have the following directory:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"> <code class="literal">reactivewebstore-1.0-SNAPSHOT</code></li><li class="listitem"> <code class="literal">bin</code>: Scripts to run the app</li><li class="listitem"> <code class="literal">conf</code>: All config files: routes, logging, messages</li><li class="listitem"> <code class="literal">bib</code>: All JARs including third-party dependencies</li><li class="listitem"> <code class="literal">share</code>: All documentation about the app</li></ul></div></div>
<div class="section" title="Defining the secret" id="aid-3HFIU1"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec111"/>Defining the secret</h1></div></div></div><p>Before we run our standalone application, we will need to apply one more change. We need to change the default secret. Locate the <code class="literal">reactivewebstore-1.0-SNAPSHOT/conf/application.conf</code> file.</p><p>Change the secret to following in the <code class="literal">application.conf</code> file:</p><pre class="programlisting">play.crypto.secret = "changeme" 
</pre><p>You will need to provide a different value. It can be anything, as long as you don't call it <code class="literal">changeme</code>. If you don't change this, your application will not boot up. You can get more information at <a class="ulink" href="http://www.playframework.com/documentation/latest/ApplicationSecret">http://www.playframework.com/documentation/latest/ApplicationSecret</a>.</p><p>If you just want to test the deploy for now, let's call it <code class="literal">playworks</code>.</p><p>Now, we are all set to start the application.</p></div>
<div class="section" title="Running the standalone deploy" id="aid-3IE3G1"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec112"/>Running the standalone deploy</h1></div></div></div><p>In order to run the app, we will use the script generated by the universal task. Go to the <code class="literal">reactivewebstore-1.0-SNAPSHOT</code> directory and then run <code class="literal">$ bin/reactivewebstore</code>, which would look something like this:</p><p>
</p><div class="mediaobject"><img src="../Images/image00333.jpeg" alt="Running the standalone deploy"/></div><p style="clear:both; height: 1em;"> </p><p>
</p><p>Now, you can open your browser and go to <code class="literal">http://localhost:9000/</code>.</p><p>That's it; we have our app up and running. Feel free to test all the features we built--they all work!</p><p>It should look something like this:</p><p>
</p><div class="mediaobject"><img src="../Images/image00334.jpeg" alt="Running the standalone deploy"/></div><p style="clear:both; height: 1em;"> </p><p>
</p></div>
<div class="section" title="Architecture principles" id="aid-3JCK21"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec113"/>Architecture principles</h1></div></div></div><p>Scalability is about handling more users, traffic, and data; and in order to do it, we will need to apply some principles and techniques. Our application is already using the most modern techniques and technologies, such as functional and ReactiveX programming, RxScala, Akka framework, Play, and much more. However, in order to scale, we will need to have an infrastructure in place and other kinds of system that will allow us to handle more users.</p><p>A good application architecture should be created around the following principles:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Separation of Concerns</strong></span> (<span class="strong"><strong>SOC</strong></span>) (more details at <a class="ulink" href="https://en.wikipedia.org/wiki/Separation_of_concerns">https://en.wikipedia.org/wiki/Separation_of_concerns</a>)</li><li class="listitem">Service Orientation (SOA/microservices)</li><li class="listitem">Performance</li><li class="listitem">Scalability/Resiliency</li></ul></div><p>Let's see these principles in detail.</p><div class="section" title="Service orientation (SOA/microservices)"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec123"/>Service orientation (SOA/microservices)</h2></div></div></div><p>Service orientation is about having a higher level of abstraction, which is also called services or microservices. SOA is not about a specific technology, but about principles such as shared services, flexibility, and intrinsic operability. If you want to learn more about SOA, check out the SOA Manifesto at <a class="ulink" href="http://www.soa-manifesto.org/">http://www.soa-manifesto.org/</a>. Microservices is a particular flavor of SOA where the main difference is the focus on the granularity, autonomy, and isolation. If you want to learn more about microservices, you can check out <a class="ulink" href="https://www.linkedin.com/pulse/soa-microservices-isolation-evolution-diego-pacheco">https://www.linkedin.com/pulse/soa-microservices-isolation-evolution-diego-pacheco</a> as well as <a class="ulink" href="http://microservices.io/">http://microservices.io/</a>.</p></div><div class="section" title="Performance"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec124"/>Performance</h2></div></div></div><p>The right algorithm might make your application work smoothly and the wrong algorithm might make your users have a poor experience. Performance is achieved by design--first of all, choose the right set of collections and the right set of algorithms and frameworks. However, performance needs to be measured and tuned eventually. The practice you should do in your application with regard of performance is stress testing. The best stress testing tools in the Scala ecosystem is Gatling. Gatling (<a class="ulink" href="http://gatling.io/#/">http://gatling.io/#/</a>) allows you to code in Scala using a very simple yet powerful DSL. Gatling focuses on HTTP and latency percentiles and distributions, which is the right thing to do nowadays. Latency is not only used for the sake of performance and scalability, but it is also heavily related to user experience as everything is online.</p></div><div class="section" title="Scalability/Resiliency"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec125"/>Scalability/Resiliency</h2></div></div></div><p>Scalability is one of the main reasons why we do software architecture, because an architecture that does not scale does not have business value. We will continue talking about Scalability principles during this chapter. Resiliency is about how much the system can resist and keep operating under the most adverse situations, such as hardware failure or infrastructure failure. Resiliency is an old term. Currently, there is a new and more modern and accurate principle called antifragility. This principle was well developed and used in practice by Netflix. Antifragility is about systems and architecture that can adapt and fail over to other systems and other operational modes to keep working no matter what. If you want to know more about antifragility, you can visit <a class="ulink" href="http://diego-pacheco.blogspot.com.br/2015/09/devops-is-about-anti-fragility-not-only.html">http://diego-pacheco.blogspot.com.br/2015/09/devops-is-about-anti-fragility-not-only.html</a> and <a class="ulink" href="http://diego-pacheco.blogspot.com.br/2015/11/anti-fragility-requires-chaos.html">http://diego-pacheco.blogspot.com.br/2015/11/anti-fragility-requires-chaos.html</a>.</p></div></div>
<div class="section" title="Scalability principles"><div class="titlepage" id="aid-3KB4K2"><div><div><h1 class="title"><a id="ch10lvl1sec114"/>Scalability principles</h1></div></div></div><p>Having architecture around these principles makes it possible to scale your application up. However, we will still need to rely on other principles and techniques to scale it.</p><p>There are several principles and techniques for scalability, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Vertical and horizontal scaling (up and out)</li><li class="listitem">Caching</li><li class="listitem">Proxy</li><li class="listitem">Load balancer</li><li class="listitem">Throttling</li><li class="listitem">Database cluster</li><li class="listitem">Cloud computing/containers</li><li class="listitem">Auto Scaling</li><li class="listitem">Reactive drivers</li></ul></div><div class="section" title="Vertical and horizontal scaling (up and out)"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec126"/>Vertical and horizontal scaling (up and out)</h2></div></div></div><p>You can add more resources, have better hardware, or you can add more boxes. These are the two basic ways to scale. You can always improve and tune your app to use fewer resources and get more from a single box. Recently, there were several improvements in this area around reactive programming that uses fewer resources and delivers more throughput. However, there are always limits to which a single box can provide in sense of scaling up, which is why we always need to be able to scale out.</p></div><div class="section" title="Caching"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec127"/>Caching</h2></div></div></div><p>Databases are great. However, there is a latency cost to call a traditional database. A great way to fix this is having a memory cache, which you can use as a subset of your data and get the benefit of fast retrieval. Play framework has cache support. If you want to learn more, check out <a class="ulink" href="https://www.playframework.com/documentation/2.5.x/ScalaCache">https://www.playframework.com/documentation/2.5.x/ScalaCache</a>.</p><p>There are other options in sense of caching. There are lots of companies that use the memory as a definitive data store nowadays. For this, you can consider tools such as Redis (<a class="ulink" href="http://redis.io/">http://redis.io/</a>) and Memcached (<a class="ulink" href="https://memcached.org/">https://memcached.org/</a>). However, if you want to scale Redis and Memcached, you will need something like Netflix/Dynomite (<a class="ulink" href="https://github.com/Netflix/dynomite">https://github.com/Netflix/dynomite</a>). Dynomite provides a cluster based on AWS Dynamo paper for Redis, which has the following benefits:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">High throughput and low latency</li><li class="listitem">Multi-region support (AWS cloud)</li><li class="listitem">Token aware</li><li class="listitem">Consistent hashing</li><li class="listitem">Replication</li><li class="listitem">Sharding</li><li class="listitem">High availability</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note4"/>Note</h3><p>If you want to learn more about dynomite, check out <a class="ulink" href="https://github.com/Netflix/dynomite/wiki">https://github.com/Netflix/dynomite/wiki</a>.</p></div></div><div class="section" title="Load balancer"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec128"/>Load balancer</h2></div></div></div><p>A load balancer is a key tool to scale servers. So, let's say, you have 10 boxes with our Play framework application or 10 Docker containers. We will need something in front of our application to distribute the traffic. There are several servers that can do this, such as NGINX (<a class="ulink" href="https://nginx.org/">https://nginx.org/</a>) and Apache HTTP Server (<a class="ulink" href="https://httpd.apache.org/">https://httpd.apache.org/</a>). If you want to scale your application, this is the easiest solution for it. Configuration and more details can be found at <a class="ulink" href="https://www.playframework.com/documentation/2.5.x/HTTPServer#Setting-up-a-front-end-HTTP-server">https://www.playframework.com/documentation/2.5.x/HTTPServer#Setting-up-a-front-end-HTTP-server</a>.</p><p>Load balancers are often proxy servers as well. You can use them to have HTTPS support. If you want, you can have HTTPS on Play framework as well (<a class="ulink" href="https://www.playframework.com/documentation/2.5.x/ConfiguringHttps">https://www.playframework.com/documentation/2.5.x/ConfiguringHttps</a>). Keep in mind that you will need to change swagger embedded installation as all the code that we have points to the HTTP interface. If you are doing deploys in the AWS cloud, you will need to change some of the configuration to forward the proxies, which you can find at <a class="ulink" href="https://www.playframework.com/documentation/2.5.x/HTTPServer#Setting-up-a-front-end-HTTP-server">https://www.playframework.com/documentation/2.5.x/HTTPServer#Setting-up-a-front-end-HTTP-server</a>.</p></div><div class="section" title="Throttling"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec129"/>Throttling</h2></div></div></div><p>This is also known as Back pressure. We covered throttling in <a class="link" title="Chapter 9. Design Your REST API" href="part0110.xhtml#aid-38STS1">Chapter 9</a>, <span class="emphasis"><em>Design Your REST API</em></span>. You can get more details there. However, the main idea is to limit the request for each user. This is also a way to make sure that a single user does not steal all computational resources. This is also important from the security point of view, especially for the services that are Internet-facing or also known as edge. Another great way to protect and have this capability is using Netflix/Zuul (<a class="ulink" href="https://github.com/Netflix/zuul">https://github.com/Netflix/zuul</a>).</p></div><div class="section" title="Database cluster"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec130"/>Database cluster</h2></div></div></div><p>Sometimes, the problem is not on the application side, but in the database. When we talk about scalability, we need be able to scale everything. We need to have the same concepts for databases that we have for the Mid-Tier. For databases, it is important to work with the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Clustering</li><li class="listitem">Index</li><li class="listitem">Materialized views</li><li class="listitem">Data partition</li></ul></div><p>For our application, we used the MySQL database. Here are some resources that can help you scale the database and apply the previous concepts:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><a class="ulink" href="http://dev.mysql.com/doc/refman/5.7/en/faqs-mysql-cluster.html">http://dev.mysql.com/doc/refman/5.7/en/faqs-mysql-cluster.html</a></li><li class="listitem"><a class="ulink" href="http://www.fromdual.com/mysql-materialized-views">http://www.fromdual.com/mysql-materialized-views</a></li><li class="listitem"><a class="ulink" href="http://dev.mysql.com/doc/refman/5.7/en/optimization-indexes.html">http://dev.mysql.com/doc/refman/5.7/en/optimization-indexes.html</a></li><li class="listitem"><a class="ulink" href="http://dev.mysql.com/doc/refman/5.7/en/partitioning.html">http://dev.mysql.com/doc/refman/5.7/en/partitioning.html</a></li><li class="listitem"><a class="ulink" href="https://dev.mysql.com/doc/refman/5.7/en/partitioning-overview.html">https://dev.mysql.com/doc/refman/5.7/en/partitioning-overview.html</a></li></ul></div></div><div class="section" title="Cloud computing/containers"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec131"/>Cloud computing/containers</h2></div></div></div><p>Scaling up application in traditional data centers is always hard because we need to have the hardware in place. This gets done by the practice of capacity planning. Capacity planning is great to make sure we don't spend money beyond our budget. However, it is very hard to get it done right. Software is hard to predict, and that's a great advantage of the cloud. Cloud is just another level of abstraction. Hardware and networks become logical, and they are encapsulated behind APIs. This makes it easier to scale our application as we can rely on cloud elasticity and scale on demand when we need to. However, the architecture needs to be ready for this moment and use the tools and techniques described in this chapter. Currently, there are several public clouds; the best options are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">AWS--Amazon Cloud (<a class="ulink" href="https://aws.amazon.com/">https://aws.amazon.com/</a>)</li><li class="listitem">Google Cloud (<a class="ulink" href="https://cloud.google.com/">https://cloud.google.com/</a>)</li><li class="listitem">Microsoft Azure Cloud (<a class="ulink" href="https://azure.microsoft.com/en-us/">https://azure.microsoft.com/en-us/</a>)</li></ul></div><p>Today, Cloud is not the only big elephant in the room. We also have the Linux containers, such as Docker (<a class="ulink" href="https://www.docker.com/">https://www.docker.com/</a>) and LXC (<a class="ulink" href="https://linuxcontainers.org/">https://linuxcontainers.org/</a>). Containers provide another level of abstraction, and they can run on the cloud or on premises. This makes your application more portable and also more cost effective. Containers also scale. The main advantage around containers is speed and flexibility. It's way faster to boot up a container in comparison with a virtualized image in any public cloud. They are also portable and can run everywhere.</p></div><div class="section" title="Auto Scaling"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec132"/>Auto Scaling</h2></div></div></div><p>Currently, this is one of the greatest resources of cloud computing. Basically, you can define a base image, which is a state of an operational system such as Linux, and the cloud will create and destroy instances for you on demand. These instances can be created by the increase in computational resources, such as memory, CPU, network, or even based on custom rules. This is the key concern in order to have elasticity. If you want to learn more about Auto Scaling, check out <a class="ulink" href="https://aws.amazon.com/autoscaling/">https://aws.amazon.com/autoscaling/</a>.</p></div><div class="section" title="A note about automation"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec133"/>A note about automation</h2></div></div></div><p>In order to use all these techniques and technologies at scale, we need to have full automation (<a class="ulink" href="https://en.wikipedia.org/wiki/List_of_build_automation_software">https://en.wikipedia.org/wiki/List_of_build_automation_software</a>) because it is impossible to handle all this with manual work. When we are using the cloud or containers, there is no other way around; everything needs to be automated. There are several tools that help us achieve this goal, such as Ansible (<a class="ulink" href="https://www.ansible.com/">https://www.ansible.com/</a>).</p></div><div class="section" title="Don't forget about telemetry"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec134"/>Don't forget about telemetry</h2></div></div></div><p>When you have all infrastructures in place, you will also need to have monitoring, alerting, and proper dashboards. There are plenty of great tools for containers and public clouds, such as Sensu (<a class="ulink" href="https://sensuapp.org/">https://sensuapp.org/</a>) and Prometheus (<a class="ulink" href="https://prometheus.io/">https://prometheus.io/</a>).</p></div><div class="section" title="Reactive Drivers and discoverability"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec135"/>Reactive Drivers and discoverability</h2></div></div></div><p>
<span class="strong"><strong>Reactive Drivers</strong></span>: We talked a lot and did a lot of reactive code using Play framework and RxScala. However, to have full benefits of ReactiveX programming, you need to make sure everything is a non-blocking IO and reactive. In other words, we need to have all of our drivers reactive. Slick is great because it gives us reactivity with the MySQL database. We will need to apply the same principles everywhere we have a driver or connection point. There are lots of libraries becoming reactive these days. For instance, if you want to cache using Redis, you can use Lettuce (<a class="ulink" href="https://github.com/mp911de/lettuce">https://github.com/mp911de/lettuce</a>), which is reactive.</p><p>When we work with microservices, we tend to have hundreds of microservice instances. These microservices will run on containers and/or cloud computing units. You can't point to specific IPs because the code will not be managed and will not survive in a cloud/container environment. Cloud/container infrastructure is ephemeral, and you don't know when an instance will be terminated. That's why you need to be able to switch to another availability zone or region at any moment.</p><p>There are tools that can help us apply these changes in our code. These tools are Netflix/Eureka (<a class="ulink" href="https://github.com/Netflix/eureka">https://github.com/Netflix/eureka</a>) and Consul (<a class="ulink" href="https://www.consul.io/">https://www.consul.io/</a>), or even Apache Zookeeper (<a class="ulink" href="https://zookeeper.apache.org/">https://zookeeper.apache.org/</a>). Eureka has one advantage--it is easier to use and has tools around the JVM ecosystem, which was battle tested by Netflix.</p><p>Eureka is a central registry where microservices register their IP and metadata. Eureka has a REST API. Microservices can use the Eureka API to query and search existing applications. Eureka can run in a multi-vpc/multi-region environment. There are other JVM components, such as ribbon (<a class="ulink" href="https://github.com/Netflix/ribbon">https://github.com/Netflix/ribbon</a>) and karyon (<a class="ulink" href="https://github.com/Netflix/karyon">https://github.com/Netflix/karyon</a>), which can automatically register and retrieve eureka information and metadata.</p><p>Based on the Eureka information, you can perform microservice load balancing and fail over to other availability zones and regions automatically. Why use Eureka if I can use DNS? DNS for Mid-Tier load balancing is not the right choice as DNS is not flexible and the timeout is quite big. If you want know more about discoverability, check out <a class="ulink" href="http://microservices.io/patterns/service-registry.html">http://microservices.io/patterns/service-registry.html</a>.</p><p>
</p><div class="mediaobject"><img src="../Images/image00335.jpeg" alt="Reactive Drivers and discoverability"/><div class="caption"><p>Eureka overview - Eureka architecture overview on the AWS cloud</p></div></div><p style="clear:both; height: 1em;"> </p><p>
</p><p>As you can see in the preceding diagram, you will deploy the Eureka server at least in three <span class="strong"><strong>Availability Zones</strong></span> (<span class="strong"><strong>AZs</strong></span>) in order to have availability. Then, Eureka data will be replicated to each server. Our applications or microservices will register in Eureka, and other applications/microservices can retrieve this metadata, such as IP address, to them to the REST calls. If you want learn more, you can check out <a class="ulink" href="https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance">https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance</a>.</p></div></div>
<div class="section" title="Mid-Tier load balancer, timeouts, Back pressure, and caching" id="aid-3L9L61"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec115"/>Mid-Tier load balancer, timeouts, Back pressure, and caching</h1></div></div></div><p>Eureka, Zookeeper, or Consul are only one part of the equation. We still need some software on the client side that can use the Eureka information in order to do Mid-Tier load balancing, fail over, and caching. The Netflix stack has a component for that, which is called ribbon (<a class="ulink" href="https://github.com/Netflix/ribbon">https://github.com/Netflix/ribbon</a>). With ribbon, you can automatically resolve the microservice IPs from Eureka, do retries, and failover to other AZs and regions. Ribbon has a cache concept; however, it is on preloaded cache.</p><p>Ribbon ideas are simple. The great thing about ribbon is that everything is reactive, and you can use RxJava and RxScala in order to work with the stack. If you don't want to use ribbon, you can still create a simple integration layer with Scala and perform the same concerns, such as load balancing, failover, and caching.</p><p>What about Back pressure? Back pressure can be done with RxJava and Rxscala, and you will be able to do it on the client side as well. You can learn more about Back pressure in Rx at <a class="ulink" href="https://github.com/ReactiveX/RxJava/wiki/Backpressure">https://github.com/ReactiveX/RxJava/wiki/Backpressure</a>.</p><p>So, if I have client-side load balancing, failover, caching, and Back pressure, am I good to go? Yes, you are; however, we can always do better. Working with microservices is not easy as everything is a remote call, and remote calls can fail, hang, or timeout. These cons are hard and dangerous if not managed well. There is another solution that can help us a lot with this concept; it is called Hystrix (<a class="ulink" href="https://github.com/Netflix/Hystrix">https://github.com/Netflix/Hystrix</a>).</p><p>Hystrix is a library for the JVM designed for latency and fault tolerance protection. At a glance, Hystrix is a wrapper around any remote code that can take time or go wrong.</p><p>Hystrix has thread isolation and provides a dedicated thread pool for each resource. This is great because it prevents you from running out of resources. It has an execution pattern called circuit breaker. Circuit breaker will prevent requests from tearing down the whole system. Additionally, it has a dashboard where we can visualize the circuits, so, at runtime, we can see what's going on. This capability is great not only for sense of telemetry, but also because it is easy to troubleshoot and visualize where the problem is.</p><p>It can be further explained with the help of the following flowchart:</p><p>
</p><div class="mediaobject"><img src="../Images/image00336.jpeg" alt="Mid-Tier load balancer, timeouts, Back pressure, and caching"/></div><p style="clear:both; height: 1em;"> </p><p>
</p><p>The code you want to protect will be around a Hystrix command. This command can be manipulated in sync or async programming models. The first thing that Hystrix will check is if the circuit is closed, which is good, and how it should be. Then, it checks if there are threads available for that command, and if there are available threads, then the command will be executed. If this fails, it tries to get a fallback code, which is a second option that you can provide in case of failure. This fallback should be static; however, you can be loading data in the background and then return on the fallback. Another option is fallback to other AZ or Region.</p><p>Following is a snapshot of how a Hystrix dashboard circuit breaker view would work:</p><p>
</p><div class="mediaobject"><img src="../Images/image00337.jpeg" alt="Mid-Tier load balancer, timeouts, Back pressure, and caching"/></div><p style="clear:both; height: 1em;"> </p><p>
</p><p>In the preceding image, we can see the Hystrix dashboard sample, where we can visualize critical information, such as success and error rate and if the circuit is open or closed. If you want learn more about the Hystrix dashboard, check out <a class="ulink" href="https://github.com/Netflix/Hystrix/wiki/Dashboard">https://github.com/Netflix/Hystrix/wiki/Dashboard</a>.</p></div>
<div class="section" title="Scaling up microservices with an Akka cluster" id="aid-3M85O1"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec116"/>Scaling up microservices with an Akka cluster</h1></div></div></div><p>Our application also uses Akka. In order to scale Akka, we will need to use an Akka cluster. The Akka cluster allows us to clusterize several Actor systems in several machines. It has special Actor routers that are cluster aware, and we can use these Actors to route requests to the whole cluster; more details can be found at <a class="ulink" href="http://doc.akka.io/docs/akka/2.4.9/java/cluster-usage.html#Cluster_Aware_Routers">http://doc.akka.io/docs/akka/2.4.9/java/cluster-usage.html#Cluster_Aware_Routers</a>.</p><p>The Akka cluster provides membership protocol and life cycle. Basically, we can be notified by the cluster when a new member joins or when a member leaves the cluster. Given this capability, it is possible for us to code a scalable solution around these semantics. As we know when a member joins, we can deploy more nodes, and we can also drop nodes on demand.</p><p>A simple sample would be to create an Actor called frontend, and when we see this Actor, we could deploy three backend Actors across the cluster. If the frontend Actor leaves, we could undeploy the other Actors. All this logic can be archived using the membership protocol and clusters events that Akka generates for us. A frontend Actor is a not a UI or web application, it is just an Actor that receives work. So, let's say we want to generate analytics around our products catalog. We could have a frontend Actor who receives that request and delegates the work to backend Actors, which will be deployed across the cluster and deliver the analytical work.</p><p>The following image is the process view of an Akka cluster membership protocol:</p><p>
</p><div class="mediaobject"><img src="../Images/image00338.jpeg" alt="Scaling up microservices with an Akka cluster"/></div><p style="clear:both; height: 1em;"> </p><p>
</p><p>As you can see in the preceding image, there is a set of states. First of all, the node is joining the cluster; then the node can be up. Once the node is up, it can leave the cluster. There are intermediate states, such as leaving and existing.</p><p>The Akka cluster provides many options to scale our Actor system. Another interesting option is to use the pattern of distributed Pub/Sub. If you are familiar with JMS Topics, it is almost the same idea. For those who are not familiar, you can check out <a class="ulink" href="http://doc.akka.io/docs/akka/2.4.9/java/distributed-pub-sub.html">http://doc.akka.io/docs/akka/2.4.9/java/distributed-pub-sub.html</a>.</p><div class="note" title="Note"><h3 class="title"><a id="note5"/>Note</h3><p>If you want learn more about the Akka cluster, you can check out <a class="ulink" href="http://doc.akka.io/docs/akka/2.4.9/common/cluster.html">http://doc.akka.io/docs/akka/2.4.9/common/cluster.html</a>.</p></div></div>
<div class="section" title="Scaling up the infrastructure with Docker and AWS cloud" id="aid-3N6MA1"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec117"/>Scaling up the infrastructure with Docker and AWS cloud</h1></div></div></div><p>Scaling up with the AWS cloud is easy, as at any moment, with a simple click on the AWS console, you can change the hardware and use more memory, CPU, or better network. Scale-out is not hard; however, we need to have good automation in place. The key principle to scale is to have the Auto Scaling groups in place with good policies. You can learn more about it at <a class="ulink" href="http://docs.aws.amazon.com/autoscaling/latest/userguide/policy_creating.html">http://docs.aws.amazon.com/autoscaling/latest/userguide/policy_creating.html</a>.</p><p>There are other interesting services and components that can help you scale your application. However, you will need to keep in mind that this can lead to coupling. The IT industry is moving toward the container direction because it is faster, and it's easy to deploy in other public clouds.</p><p>We can scale out with Docker as well, because there are cluster managers that can help us scale our containers. Currently, there are several solutions. In the sense of capabilities and maturity, the following are the better solutions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Docker Swarm (<a class="ulink" href="https://docs.docker.com/swarm/overview/">https://docs.docker.com/swarm/overview/</a>)</li><li class="listitem">Kubernetes (<a class="ulink" href="http://kubernetes.io/">http://kubernetes.io/</a>)</li><li class="listitem">Apache Mesos (<a class="ulink" href="http://mesos.apache.org/">http://mesos.apache.org/</a>)</li></ul></div><p>
<span class="strong"><strong>Docker Swarm</strong></span>: This is a cluster for Docker. Docker Swarm is very flexible and integrates well with other Docker ecosystem tools, such as Docker machine, Docker compose, and Consul. It can handle hundreds of nodes, and you can learn more about them at <a class="ulink" href="https://blog.docker.com/2015/11/scale-testing-docker-swarm-30000-containers/">https://blog.docker.com/2015/11/scale-testing-docker-swarm-30000-containers/</a>.</p><p>
<span class="strong"><strong>Kubernetes</strong></span>: This was created by Google, and it is a full solution for development automation, operation, and scaling Docker containers. The Kubernetes cluster has two roles, a master node that coordinates the cluster, schedules applications, and keeps applications on a desired state; and there are nodes, that are workers that run applications. It can handle hundreds of containers and scale very well. To learn more about it, check out <a class="ulink" href="http://blog.kubernetes.io/2016/03/1000-nodes-and-beyond-updates-to-Kubernetes-performance-and-scalability-in-12.html">http://blog.kubernetes.io/2016/03/1000-nodes-and-beyond-updates-to-Kubernetes-performance-and-scalability-in-12.html</a>.</p><p>
<span class="strong"><strong>Apache Mesos</strong></span>: This was created by Twitter. It is very interesting, as you can run a bare metal on a premises datacenter or on a public cloud. Mesos allows you to use Docker containers as well. If you want to learn more about mesos, check out the following paper:</p><p>
<a class="ulink" href="http://mesos.berkeley.edu/mesos_tech_report.pdf">http://mesos.berkeley.edu/mesos_tech_report.pdf</a>
</p></div>
<div class="section" title="Summary" id="aid-3O56S1"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec118"/>Summary</h1></div></div></div><p>In this chapter, you learned how to deploy your Play framework application as a standalone distribution. Additionally, you learned several architectural principles, techniques, and tools, to help you scale out your application to thousands of users.</p><p>With this, we also reach the end of this book. I hope you enjoyed this journey. We built a nice application using Scala, Play Framework, Slick, REST, Akka, Jasper, and RxScala. Thank you for your time. I wish you the best in your coding career with the Scala language.</p></div></body></html>