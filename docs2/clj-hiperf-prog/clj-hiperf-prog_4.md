# 第四章：主机性能

在前面的章节中，我们提到了 Clojure 如何与 Java 交互。在本章中，我们将更深入地了解内部结构。我们将触及整个堆栈的几个层次，但我们的主要重点是 JVM，特别是 Oracle HotSpot JVM，尽管有多个 JVM 供应商可供选择([`en.wikipedia.org/wiki/List_of_Java_virtual_machines`](http://en.wikipedia.org/wiki/List_of_Java_virtual_machines))。在撰写本文时，Oracle JDK 1.8 是最新的稳定版本，并且有早期的 OpenJDK 1.9 构建可用。在本章中，我们将讨论：

+   从性能角度来看，硬件子系统是如何工作的

+   JVM 内部结构的组织以及它与性能的关系

+   如何测量堆中各种对象占用的空间量

+   使用 Criterium 对 Clojure 代码进行延迟分析

# 硬件

有各种硬件组件可能会以不同的方式影响软件的性能。处理器、缓存、内存子系统、I/O 子系统等，它们对性能的影响程度各不相同，这取决于具体的使用场景。在接下来的章节中，我们将探讨这些方面的每一个。

## 处理器

自 1980 年代末以来，微处理器一直采用流水线和指令级并行性来提高其性能。在 CPU 级别处理指令通常包括四个周期：**取指**、**解码**、**执行**和**回写**。现代处理器通过并行运行这些周期来优化它们——当一条指令正在执行时，下一条指令正在解码，再下一条正在取指，依此类推。这种风格被称为**指令流水线**。

在实践中，为了进一步加快执行速度，阶段被细分为许多更短的阶段，从而导致了更深的超级流水线架构。流水线中最长阶段的长度限制了 CPU 的时钟速度。通过将阶段拆分为子阶段，处理器可以以更高的时钟速度运行，每个指令需要更多的周期，但处理器仍然在每个周期内完成一条指令。由于现在每秒有更多的周期，尽管每个指令的延迟现在更高，但我们仍然在每秒吞吐量方面获得了更好的性能。

### 分支预测

即使处理器遇到条件`if-then`形式的指令，也必须提前取指和解码。考虑一个等价的 Clojure 表达式(`if (test a) (foo a) (bar a))`。处理器必须选择一个分支来取指和解码，问题是它应该取`if`分支还是`else`分支？在这里，处理器对要取指/解码的指令做出猜测。如果猜测是正确的，就像往常一样，这是一个性能提升；否则，处理器必须丢弃取指/解码过程的结果，并从另一个分支重新开始。

处理器使用片上分支预测表来处理分支预测。它包含最近的代码分支和每个分支两个比特位，指示分支是否被取用，同时也容纳了单次未取用的情况。

今天，分支预测在处理器性能方面非常重要，因此现代处理器专门分配硬件资源和特殊的预测指令来提高预测准确性并降低误预测的代价。

### 指令调度

高延迟指令和分支通常会导致指令流水线中的空循环，这些循环被称为**停顿**或**气泡**。这些循环通常被用来通过指令重排的方式执行其他工作。指令重排通过硬件层面的乱序执行和编译器层面的编译时指令调度（也称为**静态指令调度**）来实现。

处理器在执行乱序执行时需要记住指令之间的依赖关系。这种成本可以通过使用重命名寄存器来在一定程度上减轻，其中寄存器值被存储到/从内存位置加载，可能是在不同的物理寄存器上，这样它们就可以并行执行。这要求乱序处理器始终维护指令及其使用的相应寄存器的映射，这使得它们的设计复杂且功耗高。除了一些例外，今天几乎所有高性能 CPU 都具有乱序设计。

良好的编译器通常对处理器有极高的了解，并且能够通过重新排列处理器指令来优化代码，从而减少处理器指令流水线中的气泡。一些高性能 CPU 仍然只依赖于静态指令重排而不是乱序指令重排，从而简化设计并节省芯片面积——节省的面积被用来容纳额外的缓存或 CPU 核心。低功耗处理器，如 ARM 和 Atom 系列，使用顺序设计。与大多数 CPU 不同，现代 GPU 使用顺序设计，具有深管道，这通过非常快的上下文切换得到补偿。这导致 GPU 具有高延迟和高吞吐量。

### 线程和核心

通过上下文切换、硬件线程和核心实现并发和并行性在当今非常普遍，并且我们已经将其视为实现程序的标准。然而，我们应该理解为什么我们最初需要这样的设计。我们今天编写的绝大多数现实世界代码在指令级并行性方面并没有超过适度的范围。即使有基于硬件的乱序执行和静态指令重排，每个周期也真正并行执行的指令不超过两个。因此，除了当前运行的程序之外，另一个潜在的指令来源是可以流水线和并行执行的程序。

管道中的空闲周期可以专门用于其他正在运行的程序，这些程序假设有其他当前正在运行的程序需要处理器的关注。**同时多线程**（**SMT**）是一种硬件设计，它使这种类型的并行成为可能。英特尔在其某些处理器中实现了名为**HyperThreading**的 SMT。虽然 SMT 将单个物理处理器呈现为两个或更多逻辑处理器，但真正的多处理器系统每个处理器执行一个线程，从而实现同时执行。多核处理器每个芯片包含两个或更多处理器，但具有多处理器系统的特性。

通常，多核处理器在性能上显著优于 SMT 处理器。SMT 处理器的性能可能会根据用例而变化。在代码高度可变或线程不竞争相同硬件资源的情况下，性能达到峰值，而当线程在同一个处理器上缓存绑定时，性能会下降。同样重要的是，有些程序本身并不是本质上并行的。在这种情况下，如果没有在程序中显式使用线程，可能很难使它们更快。

## 内存系统

理解内存性能特性对于了解对我们所编写的程序可能产生的影响非常重要。那些既是数据密集型又是本质上并行的程序，例如音频/视频处理和科学计算，在很大程度上受到内存带宽的限制，而不是处理器的限制。除非内存带宽也增加，否则增加处理器并不会使它们更快。考虑另一类程序，例如主要受内存延迟限制但不受内存带宽限制的 3D 图形渲染或数据库系统。在这种情况下，SMT 可能非常适用，因为线程不会竞争相同的硬件资源。

内存访问大致占处理器执行的所有指令的四分之一。代码块通常以内存加载指令开始，其余部分取决于加载的数据。这会导致指令停滞，并防止大规模的指令级并行。更糟糕的是，即使是超标量处理器（每时钟周期可以发出多个指令）每周期最多也只能发出两个内存指令。构建快速内存系统受到自然因素的影响，例如光速。它影响信号往返到 RAM。这是一个自然的硬限制，任何优化都只能绕过它。

处理器和主板芯片组之间的数据传输是导致内存延迟的因素之一。这可以通过使用**更快的总线前端总线**（**FSB**）来抵消。如今，大多数现代处理器通过在芯片级别直接集成内存控制器来解决这个问题。处理器与内存延迟之间的显著差异被称为**内存墙**。由于处理器时钟速度达到功率和热量限制，近年来这一现象已经趋于平稳，但尽管如此，内存延迟仍然是一个重大问题。

与 CPU 不同，GPU 通常实现持续的高内存带宽。由于延迟隐藏，它们在高强度计算工作负载期间也利用带宽。

### 缓存

为了克服内存延迟，现代处理器在处理器芯片上或芯片附近放置了一种非常快速的内存。缓存的作用是存储最近使用过的内存数据。缓存有不同的级别：**L1** 缓存位于处理器芯片上；**L2** 缓存比 L1 更大，且距离处理器更远。通常还有一个 **L3** 缓存，它比 L2 更大，且距离处理器更远。在英特尔 Haswell 处理器中，L1 缓存的大小通常是 64 千字节（32 KB 指令加 32 KB 数据），L2 每核心 256 KB，L3 是 8 MB。

虽然内存延迟非常糟糕，幸运的是缓存似乎工作得非常好。L1 缓存比访问主内存要快得多。在现实世界的程序中报告的缓存命中率是 90%，这为缓存提供了强有力的论据。缓存就像是一个内存地址到数据值块的字典。由于值是一个内存块，因此相邻内存位置的缓存几乎没有额外的开销。请注意，L2 比 L1 慢且更大，L3 比 L2 慢且更大。在英特尔 Sandybridge 处理器上，寄存器查找是瞬时的；L1 缓存查找需要三个时钟周期，L2 需要九个，L3 需要 21 个，而主内存访问需要 150 到 400 个时钟周期。

### 互连

处理器通过两种类型的架构的互连与内存和其他处理器通信：**对称多处理**（**SMP**）和**非一致性内存访问**（**NUMA**）。在 SMP 中，总线通过总线控制器将处理器和内存互连。总线充当广播设备。当有大量处理器和内存银行时，总线往往会成为瓶颈。与 NUMA 相比，SMP 系统的构建成本更低，但扩展到大量核心更困难。在 NUMA 系统中，处理器和内存的集合通过点到点的方式连接到其他这样的处理器和内存组。每个这样的组被称为节点。节点的本地内存可以被其他节点访问，反之亦然。英特尔的 **HyperTransport** 和 **QuickPath** 互连技术支持 NUMA。

## 存储和网络

除了处理器、缓存和内存之外，存储和网络是最常用的硬件组件。许多现实世界中的应用程序往往比执行密集型应用程序更受 I/O 限制。这类 I/O 技术不断进步，市场上可供选择的组件种类繁多。考虑这类设备时，应基于具体的使用案例的性能和可靠性特性。另一个重要标准是了解它们在目标操作系统驱动程序中的支持程度。当前存储技术大多基于硬盘和固态硬盘。网络设备和协议的应用范围根据业务用例而大相径庭。I/O 硬件的详细讨论超出了本书的范围。

# Java 虚拟机

Java 虚拟机是一个以字节码为导向、具有垃圾回收功能的虚拟机，它定义了自己的指令集。这些指令具有等效的字节码，由**Java 运行时环境**（**JRE**）进行解释和编译，以适应底层的操作系统和硬件。对象通过符号引用来引用。在 JVM 中，数据类型在所有平台和架构上的所有 JVM 实现中都是完全标准化的，作为一个单一的规范。JVM 还遵循网络字节序，这意味着在不同架构上的 Java 程序之间可以使用大端字节序进行通信。**Jvmtop**（[`code.google.com/p/jvmtop/`](https://code.google.com/p/jvmtop/））是一个方便的 JVM 监控工具，类似于 Unix-like 系统中的 top 命令。

## 即时编译器

**即时编译器**（**JIT**）是 JVM 的一部分。当 JVM 启动时，即时编译器对正在运行的代码几乎一无所知，因此它只是简单地解释 JVM 字节码。随着程序的运行，即时编译器开始通过收集统计数据和分析调用和字节码模式来分析代码。当一个方法调用的次数超过某个阈值时，即时编译器会对代码应用一系列优化。最常见的优化是内联和本地代码生成。最终和静态方法和类是内联的绝佳候选者。即时编译并非没有成本；它占用内存来存储分析过的代码，有时它不得不撤销错误的推测性优化。然而，即时编译几乎总是通过长时间的代码执行来摊销成本。在罕见的情况下，如果代码太大或者由于执行频率低而没有热点，关闭即时编译可能是有用的。

一个 JRE 通常有两种 JIT 编译器：客户端和服务器。默认使用哪种 JIT 编译器取决于硬件和平台类型。客户端 JIT 编译器是为客户端程序，如命令行和桌面应用程序设计的。我们可以通过使用`-server`选项启动 JRE 来调用服务器 JIT 编译器，这实际上是为服务器上长时间运行程序设计的。服务器中 JIT 编译的阈值高于客户端。两种 JIT 编译器的区别在于，客户端针对的是低延迟，而服务器假定运行在高资源硬件上，并试图优化吞吐量。

Oracle HotSpot JVM 中的 JIT 编译器会观察代码执行以确定最频繁调用的方法，这些方法是热点。这些热点通常只是整个代码的一小部分，可以低成本地关注和优化。**HotSpot JIT**编译器是懒惰和自适应的。它是懒惰的，因为它只编译那些超过一定阈值的、已经调用的方法，而不是它遇到的全部代码。将代码编译成本地代码是一个耗时的过程，编译所有代码将是浪费。它是自适应的，因为它会逐渐增加对频繁调用代码编译的积极性，这意味着代码不是只优化一次，而是在代码重复执行的过程中多次优化。当一个方法调用超过第一个 JIT 编译器的阈值后，它将被优化，计数器重置为零。同时，代码的优化计数设置为 1。当调用再次超过阈值时，计数器重置为零，优化计数增加；这次应用更积极的优化。这个过程会一直持续到代码不能再优化为止。

HotSpot JIT 编译器执行了大量优化。其中一些最显著的优化如下：

+   **内联（Inlining）**: 方法的内联——非常小的方法、静态和 final 方法、final 类中的方法，以及只涉及原始数值的小方法，是内联的理想候选者。

+   **锁消除（Lock elimination）**: 锁定是一个性能开销。幸运的是，如果锁对象监视器无法从其他线程访问，则可以消除锁。

+   **虚拟调用消除（Virtual call elimination）**: 通常，程序中的一个接口只有一个实现。JIT 编译器会消除虚拟调用，并用类实现对象上的直接方法调用替换它。

+   **非易失性内存写入消除（Non-volatile memory write elimination）**: 对象中的非易失性数据成员和引用不保证对当前线程以外的线程可见。这个标准被用来不更新这样的引用在内存中，而是通过本地代码使用硬件寄存器或栈。

+   **本地代码生成**：JIT 编译器为频繁调用的方法及其参数生成本地代码。生成的本地代码存储在代码缓存中。

+   **控制流和局部优化**：JIT 编译器经常重新排序和拆分代码以提高性能。它还分析控制流的分支，并根据这些分支优化代码。

很少有理由禁用 JIT 编译，但可以通过在启动 JRE 时传递 `-Djava.compiler=NONE` 参数来实现。默认的编译阈值可以通过传递 `-XX:CompileThreshold=9800` 到 JRE 可执行文件来更改，其中 `9800` 是示例阈值。`XX:+PrintCompilation` 和 `-XX:-CITime` 选项使 JIT 编译器打印 JIT 统计信息和 JIT 所花费的时间。

## 内存组织

JVM 使用的内存被分为几个部分。作为基于栈的执行模型，JVM 中的一个内存部分是栈区域。每个线程都有一个栈，栈帧以**后进先出**（**LIFO**）的顺序存储在其中。栈包括一个**程序计数器**（**PC**），它指向 JVM 内存中当前正在执行的指令。当调用方法时，会创建一个新的栈帧，其中包含局部变量数组和操作数栈。与传统的栈不同，操作数栈包含加载局部变量/字段值和计算结果的指令——这种机制也用于在调用之前准备方法参数，并存储返回值。栈帧本身可能分配在堆上。检查当前线程中栈帧顺序的最简单方法是通过执行以下代码：

```java
(require 'clojure.repl)
(clojure.repl/pst (Throwable.))
```

当一个线程需要的栈空间超过 JVM 可以提供的空间时，会抛出`StackOverflowError`。

堆是对象和数组分配的主要内存区域。它在所有 JVM 线程之间共享。堆的大小可能是固定的或可扩展的，这取决于启动 JRE 时传递的参数。尝试分配比 JVM 能提供的更多堆空间会导致抛出`OutOfMemoryError`。堆中的分配受垃圾回收的影响。当一个对象不再通过任何引用可访问时，它将被垃圾回收，值得注意的是，弱、软和虚引用除外。由非强引用指向的对象在 GC 中的回收时间较长。

方法区域在逻辑上属于堆内存的一部分，包含诸如字段和方法信息、运行时常量池、方法代码和构造函数体等每个类的结构。它在所有 JVM 线程之间共享。在 Oracle HotSpot JVM（至版本 7）中，方法区域位于一个称为**永久代**的内存区域中。在 HotSpot Java 8 中，永久代被一个称为**元空间**的本地内存区域所取代。

![内存组织](img/3642_04_01.jpg)

JVM 包含提供给 Java API 实现和 JVM 实现的本地代码和 Java 字节码。每个线程堆栈维护一个独立的本地代码调用栈。JVM 堆栈包含 Java 方法调用。请注意，Java SE 7 和 8 的 JVM 规范不包含本地方法栈，但 Java SE 5 和 6 则包含。

## HotSpot 堆和垃圾回收

Oracle HotSpot JVM 使用代际堆。主要有三个代：**年轻代**、**持久代**（旧代）和**永久代**（仅限于 HotSpot JDK 1.7）。随着对象在垃圾回收中存活，它们从**Eden**移动到**Survivor**空间，再从**Survivor**空间移动到**持久代**空间。新实例在**Eden**段分配，这是一个非常便宜的操作（和指针增加一样便宜，比 C 的`malloc`调用更快），如果它已经有足够的空闲空间。当 Eden 区域没有足够的空闲空间时，会触发一次小型的垃圾回收。这次回收会将**Eden**中的活动对象复制到**Survivor**空间。在同样的操作中，活动对象会在**Survivor-1**中进行检查，并复制到**Survivor-2**，从而只保留**Survivor-2**中的活动对象。这种方案保持**Eden**和**Survivor-1**为空且无碎片，以便进行新的分配，这被称为**复制收集**。

![HotSpot 堆和垃圾回收](img/3642_04_02.jpg)

在年轻代达到一定的存活阈值后，对象会被移动到持久代/旧代。如果无法进行小型的垃圾回收，则会尝试进行一次大型的垃圾回收。大型垃圾回收不使用复制，而是依赖于标记-清除算法。我们可以使用吞吐量收集器（**Serial**、**Parallel**和**ParallelOld**）或低延迟收集器（**Concurrent**和**G1**）来处理旧代。以下表格显示了一些非详尽的选项，用于每个收集器类型：

| 收集器名称 | JVM 标志 |
| --- | --- |
| 序列 | -XX:+UseSerialGC |
| 并行 | -XX:+UseParallelGC |
| 并行压缩 | -XX:+UseParallelOldGC |
| 并发 | -XX:+UseConcMarkSweepGC-XX:+UseParNewGC-XX:+CMSParallelRemarkEnabled |
| G1 | -XX:+UseG1GC |

之前提到的标志可以用来启动 Java 运行时。例如，在以下命令中，我们使用并行压缩垃圾回收启动了一个 4GB 堆的服务器 JVM：

```java
java \
  -server \
  -Xms4096m -Xmx4096m \
  -XX:+UseParallelOldGC XX:ParallelGCThreads=4 \
  -jar application-standalone.jar
```

有时，由于多次运行完全垃圾回收，持久代可能变得非常碎片化，以至于可能无法将对象从 Survivor 空间移动到持久代空间。在这些情况下，会触发带有压缩的完全垃圾回收。在此期间，由于完全垃圾回收正在进行，应用程序可能看起来没有响应。

## 测量内存（堆/栈）使用情况

JVM 性能下降的一个主要原因是垃圾回收。了解我们创建的对象如何使用堆内存以及如何通过降低足迹来减少对 GC 的影响，这当然是有帮助的。让我们检查对象表示如何导致堆空间。

在 64 位 JVM 上，每个（未压缩的）对象或数组引用都是 16 字节长。在 32 位 JVM 上，每个引用都是 8 字节长。由于 64 位架构现在越来越普遍，64 位 JVM 更有可能在服务器上使用。幸运的是，对于高达 32GB 的堆大小，JVM（Java 7）可以使用压缩指针（默认行为），其大小仅为 4 字节。Java 8 虚拟机可以通过压缩指针访问高达 64GB 的堆大小，如下表所示：

|   | 未压缩 | 压缩 | 32 位 |
| --- | --- | --- | --- |
| 参考指针 | 8 | 4 | 4 |
| 对象头 | 16 | 12 | 8 |
| 数组头 | 24 | 16 | 12 |
| 超类填充 | 8 | 4 | 4 |

此表说明了不同模式下的指针大小（经 Attila Szegedi 授权复制：[`www.slideshare.net/aszegedi/everything-i-ever-learned-about-jvm-performance-tuning-twitter/20`](http://www.slideshare.net/aszegedi/everything-i-ever-learned-about-jvm-performance-tuning-twitter/20))。

我们在前一章中看到了每种原始类型占用多少字节。现在让我们看看在小于 32GB 的堆大小的 64 位 JVM 上，使用压缩指针（常见情况）的复合类型的内存消耗情况：

| Java 表达式 | 64 位内存使用量 | 描述（b = 字节，填充到内存字大小的近似 8 的倍数） |
| --- | --- | --- |
| `new Object()` | 16 字节 | 12 字节头 + 4 字节填充 |
| `new byte[0]` | 16 字节 | 12 字节`obj`头 + 4 字节`int`长度 = 16 字节数组头 |
| `new String("foo")` | 40 字节（字面量内部化） | 12 字节头 + (12 字节数组头 + 6 字节字符数组内容 + 4 字节长度 + 2 字节填充 = 24 字节) + 4 字节哈希 |
| `new Integer(3)` | 16 字节（装箱整数） | 12 字节头 + 4 字节`int`值 |
| `new Long(4)` | 24 字节（装箱长整型） | 12 字节头 + 8 字节`long`值 + 4 字节填充 |
| `class A { byte x; }` `new A();` | 16 字节 | 12 字节头 + 1 字节值 + 3 字节填充 |
| `class B extends A {byte y;}` `new B();` | 24 字节（子类填充） | 12 字节引用 + (1 字节值 + 7 字节填充 = 8 字节) 用于 A + 1 字节用于`y`的值 + 3 字节填充 |
| `clojure.lang.Symbol.intern("foo")`// clojure 'foo | 104 字节（40 字节内部化） | 12 字节头 + 12 字节命名空间引用 + (12 字节名称引用 + 40 字节内部字符) + 4 字节`int`哈希 + 12 字节元数据引用 + (12 字节`_str`引用 + 40 字节内部字符) – 40 字节内部`str` |
| `clojure.lang.Keyword.intern("foo")`// clojure :foo | 184 字节（由工厂方法完全内部化） | 12 字节引用 + (12 字节符号引用 + 104 字节内部值) + 4 字节`int`哈希 + (12 字节`_str`引用 + 40 字节内部`char`) |

比较由相同给定字符串创建的符号和关键字所占用的空间，可以说明尽管关键字相对于符号有轻微的额外开销，但关键字是完全内联的，并且会提供更好的内存消耗和随时间进行的垃圾回收保护。此外，关键字作为弱引用进行内联，这确保了当内存中没有任何关键字指向内联值时，它会被垃圾回收。

### 确定程序工作负载类型

我们经常需要确定一个程序是否受 CPU/缓存、内存、I/O 或竞争限制。当一个程序受 I/O 或竞争限制时，CPU 使用率通常较低。你可能需要使用分析器（我们将在第七章性能优化中看到这一点）来找出线程是否因为资源竞争而陷入停滞。当一个程序受 CPU/缓存或内存限制时，CPU 使用率可能不是瓶颈来源的明确指标。在这种情况下，你可能想要通过检查程序中的缓存未命中来进行有根据的猜测。在 Linux 系统上，如**perf** ([`perf.wiki.kernel.org/`](https://perf.wiki.kernel.org/))、**cachegrind** ([`valgrind.org/info/tools.html#cachegrind`](http://valgrind.org/info/tools.html#cachegrind))和**oprofile** ([`oprofile.sourceforge.net/`](http://oprofile.sourceforge.net/))等工具可以帮助确定缓存未命中的数量——更高的阈值可能意味着程序受内存限制。然而，由于 Java 的 JIT 编译器需要预热才能观察到有意义的行为，因此使用这些工具与 Java 结合并不简单。项目**perf-map-agent** ([`github.com/jrudolph/perf-map-agent`](https://github.com/jrudolph/perf-map-agent))可以帮助生成你可以使用`perf`实用程序关联的方法映射。

## 解决内存效率低下问题

在本章前面的部分，我们讨论了未经检查的内存访问可能成为瓶颈。截至 Java 8，由于堆和对象引用的工作方式，我们无法完全控制对象布局和内存访问模式。然而，我们可以关注频繁执行的代码块，以减少内存消耗，并尝试在运行时使它们成为缓存绑定而不是内存绑定。我们可以考虑一些降低内存消耗和访问随机性的技术：

+   JVM 中的原始局部变量（long、double、boolean、char 等）是在栈上创建的。其余的对象是在堆上创建的，并且只有它们的引用存储在栈上。原始变量具有较低的开销，并且不需要内存间接访问，因此推荐使用。

+   在主内存中以顺序方式布局的数据比随机布局的数据访问更快。当我们使用大型（比如说超过八个元素）持久映射时，存储在 tries 中的数据可能不会在内存中顺序布局，而是在堆中随机布局。此外，键和值都会被存储和访问。当你使用记录（`defrecord`）和类型（`deftype`）时，它们不仅提供了数组/类语义来布局其中的字段，而且它们不存储键，与常规映射相比，这非常高效。

+   从磁盘或网络读取大量内容可能会由于随机内存往返而对性能产生不利影响。在第三章《依赖 Java》中，我们简要讨论了内存映射字节数据缓冲区。您可以利用内存映射缓冲区来最小化堆上的碎片化对象分配/访问。虽然`nio`([`github.com/pjstadig/nio/`](https://github.com/pjstadig/nio/))和`clj-mmap`([`github.com/thebusby/clj-mmap`](https://github.com/thebusby/clj-mmap))等库帮助我们处理内存映射缓冲区，但`bytebuffer`([`github.com/geoffsalmon/bytebuffer`](https://github.com/geoffsalmon/bytebuffer))和`gloss`([`github.com/ztellman/gloss`](https://github.com/ztellman/gloss))让我们能够处理字节数据缓冲区。还有其他抽象，如 iota([`github.com/thebusby/iota`](https://github.com/thebusby/iota))，它帮助我们以集合的形式处理大文件。

由于内存瓶颈是数据密集型程序中潜在的性能问题，降低内存开销在很大程度上有助于避免性能风险。了解硬件、JVM 和 Clojure 实现的高级细节有助于我们选择适当的技巧来解决内存瓶颈问题。

# 使用 Criterium 测量延迟

Clojure 有一个叫做`time`的小巧的宏，它评估传递给它的代码的主体，然后打印出所花费的时间，并简单地返回值。然而，我们可以注意到，代码执行所需的时间在不同的运行中变化很大：

```java
user=> (time (reduce + (range 100000)))
"Elapsed time: 112.480752 msecs"
4999950000
user=> (time (reduce + (range 1000000)))
"Elapsed time: 387.974799 msecs"
499999500000
```

与这种行为变化相关的有几个原因。当 JVM 冷启动时，其堆段为空，并且对代码路径一无所知。随着 JVM 的持续运行，堆开始填满，GC 模式开始变得明显。JIT 编译器有机会分析不同的代码路径并进行优化。只有在经过相当多的 GC 和 JIT 编译轮次之后，JVM 的性能才变得不那么不可预测。

Criterium ([`github.com/hugoduncan/criterium`](https://github.com/hugoduncan/criterium))是一个 Clojure 库，用于在机器上科学地测量 Clojure 表达式的延迟。关于其工作原理的摘要可以在 Criterium 项目页面上找到。使用 Criterium 的最简单方法是将其与 Leiningen 一起使用。如果你想使 Criterium 仅在 REPL 中可用，而不是作为项目依赖项，请将以下条目添加到`~/.lein/profiles.clj`文件中：

```java
{:user {:plugins [[criterium "0.4.3"]]}}
```

另一种方法是在`project.clj`文件中包含`criterium`：

```java
:dependencies [[org.clojure/clojure "1.7.0"]
               [criterium "0.4.3"]]
```

完成文件编辑后，使用`lein repl`启动 REPL：

```java
user=> (require '[criterium.core :as c])
nil
user=> (c/bench (reduce + (range 100000)))
Evaluation count : 1980 in 60 samples of 33 calls.
             Execution time mean : 31.627742 ms
    Execution time std-deviation : 431.917981 us
   Execution time lower quantile : 30.884211 ms ( 2.5%)
   Execution time upper quantile : 32.129534 ms (97.5%)
nil
```

现在，我们可以看到，在某个测试机器上，平均而言，该表达式花费了 31.6 毫秒。

## Criterium 和 Leiningen

默认情况下，Leiningen 以低级编译模式启动 JVM，这使其启动更快，但会影响 JRE 在运行时可以执行的优化。为了在服务器端用例中使用 Criterium 和 Leiningen 运行测试时获得最佳效果，请确保在`project.clj`中覆盖默认设置，如下所示：

```java
:jvm-opts ^:replace ["-server"]
```

`^:replace`提示使 Leiningen 用`:jvm-opts`键下提供的选项替换其默认设置。你可能需要根据需要添加更多参数，例如运行测试的最小和最大堆大小。

# 摘要

软件系统的性能直接受其硬件组件的影响，因此了解硬件的工作原理至关重要。处理器、缓存、内存和 I/O 子系统具有不同的性能行为。Clojure 作为一种托管语言，了解宿主（即 JVM）的性能特性同样重要。Criterium 库用于测量 Clojure 代码的延迟——我们将在第六章“测量性能”中再次讨论 Criterium。在下一章中，我们将探讨 Clojure 的并发原语及其性能特性。
